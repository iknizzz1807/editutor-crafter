{
  "types": {
    "TokenType": "enumeration of token types",
    "SourceLocation": "fields: file str, line int, column int, length int",
    "Token": "fields: type TokenType, lexeme str, literal Optional[Any], location SourceLocation",
    "AstVisitor": "Abstract base class defining Visitor pattern interface",
    "Node": "fields: location SourceLocation, abstract method accept(visitor)",
    "Expression": "Abstract base class for expression nodes",
    "Statement": "Abstract base class for statement nodes",
    "BinaryExpr": "fields: left Expression, operator Token, right Expression",
    "UnaryExpr": "fields: operator Token, right Expression",
    "LiteralExpr": "field: value Any",
    "GroupingExpr": "field: expression Expression",
    "VariableExpr": "field: name Token",
    "AssignExpr": "fields: name Token, value Expression",
    "LogicalExpr": "fields: left Expression, operator Token, right Expression",
    "CallExpr": "fields: callee Expression, paren Token, arguments List[Expression]",
    "PrintStmt": "field: expression Expression",
    "ExpressionStmt": "field: expression Expression",
    "VarStmt": "fields: name Token, initializer Optional[Expression]",
    "BlockStmt": "field: statements List[Statement]",
    "IfStmt": "fields: condition Expression, then_branch Statement, else_branch Optional[Statement]",
    "WhileStmt": "fields: condition Expression, body Statement",
    "FunctionStmt": "fields: name Token, params List[Token], body BlockStmt",
    "ReturnStmt": "fields: keyword Token, value Optional[Expression]",
    "ParseError": "fields: message str, token Optional[Token]",
    "SyntaxError": "fields: message str, token Optional[Token]",
    "RecoveryError": "fields: message str, token Optional[Token]",
    "TokenStream": "fields: _tokens List[Token], _current int, _in_panic_mode bool",
    "ErrorHandler": "fields: _errors List[ParseError], _had_error bool, _panic_mode bool, _last_error_location Optional[SourceLocation]",
    "Parser": "fields: _stream TokenStream, _errors ErrorHandler",
    "ExpressionParser": "Parses expression grammar",
    "StatementParser": "fields: _stream TokenStream, _errors ErrorHandler, _expr_parser ExpressionParser",
    "DebugVisitor": "fields: indent_str str, current_indent int",
    "Associativity": "enumeration: LEFT, RIGHT",
    "PRECEDENCE": "Dict[TokenType, Tuple[int, Associativity]]",
    "AstPrinter": "fields: none, methods: visit_binary_expr, visit_unary_expr, visit_literal_expr",
    "TestExpressionParser": "fields: none, methods: test_literal_expression, test_binary_expression_precedence, test_parentheses_override_precedence, test_unary_operator_precedence, test_associativity_left, test_associativity_right, test_function_call, test_error_missing_right_operand",
    "TestErrorRecovery": "fields: none, methods: test_single_error_recovery, test_multiple_errors_collected, test_panic_mode_recovery, test_no_cascade_errors, test_synchronization_at_statement_boundary, test_synchronization_at_block_boundary",
    "TraceLogger": "fields: none",
    "AstVisualizer": "fields: none",
    "TypeExpression": "Base class for type expressions in annotations",
    "SimpleTypeExpr": "fields: name Token, Reference to simple type name",
    "GenericTypeExpr": "fields: base SimpleTypeExpr, type_arguments List[TypeExpression], Type with generic parameters",
    "FunctionTypeExpr": "fields: parameter_types List[TypeExpression], return_type TypeExpression, Function type signature",
    "LiteralPattern": "fields: value Any, Match exact literal values",
    "VariablePattern": "fields: name Token, Bind matched value to variable",
    "ConstructorPattern": "fields: constructor Token, arguments List[Pattern], Match structured data",
    "OrPattern": "fields: alternatives List[Pattern], Match any of several patterns",
    "WildcardPattern": "fields: none, Match anything without binding",
    "Pattern": "Base class for pattern matching AST nodes",
    "ListComprehensionExpr": "fields: element Expression, generators List[ComprehensionGenerator], Build list via transformation",
    "DictComprehensionExpr": "fields: key Expression, value Expression, generators List[ComprehensionGenerator], Build dictionary",
    "GeneratorExpr": "fields: element Expression, generators List[ComprehensionGenerator], Lazy sequence generator",
    "ComprehensionGenerator": "fields: target Pattern, iter Expression, conditions List[Expression], Single for...in...if clause",
    "AsyncFunctionStmt": "fields: function FunctionStmt, Async function wrapper",
    "AwaitExpr": "fields: expression Expression, await keyword applied to promise",
    "SpawnExpr": "fields: expression Expression, Launch concurrent task",
    "SelectStmt": "fields: arms List[SelectArm], Wait for first completed operation",
    "SelectArm": "fields: pattern Pattern, expression Expression, body BlockStmt, Case in select statement",
    "TextChange": "fields: start_line int, start_column int, end_line int, end_column int, new_text str, old_text str, Source code edit",
    "ChangeTracker": "fields: _changes List[TextChange], Track changes across edits",
    "GrammarDefinition": "Load and validate grammar rules from external definition",
    "RuleValidator": "Check grammar for ambiguities and left recursion",
    "DSLParser": "Dynamically configured parser for DSL subsets"
  },
  "methods": {
    "AstVisitor.visit_binary_expr(expr) returns Any": "Visitor method for BinaryExpr nodes",
    "Node.accept(visitor) returns Any": "Accept a visitor for double-dispatch",
    "TokenStream.peek() returns Token": "Return current token without consuming it",
    "TokenStream.consume() returns Token": "Consume and return current token, advancing stream",
    "Parser.parse() returns List[Statement]": "Main parsing entry point that parses a series of statements",
    "ErrorHandler.report(error)": "Records a parse error in the collection",
    "TokenStream.match(*expected_types) returns bool": "Check and consume token if it matches expected types",
    "TokenStream.synchronize(synchronization_points)": "Advance stream until a synchronization point",
    "SourceLocation.end_line() returns int": "Calculate ending line (same as start line for single-line tokens)",
    "SourceLocation.end_column() returns int": "Calculate ending column position",
    "TokenStream.synchronize(synchronization_points) returns None": "Enter panic mode recovery until synchronization point",
    "TokenStream._is_at_end() returns bool": "Check if stream has reached EOF",
    "TokenStream.previous() returns Optional[Token]": "Get most recently consumed token",
    "parse_expression() returns Expression": "Public entry point for parsing any expression",
    "_parse_precedence(min_precedence int) returns Expression": "Core precedence climbing implementation",
    "_parse_primary() returns Expression": "Parse literals, identifiers, groups, unary ops, calls",
    "_consume(expected_type TokenType, error_message str) returns Token": "Consume expected token or report error",
    "_error(token Token, message str) returns None": "Report syntax error and trigger recovery",
    "StatementParser.parse_statement() returns Optional[Statement]": "Main dispatch method for parsing a single statement",
    "StatementParser._parse_if_statement() returns IfStmt": "Parses an if statement with optional else",
    "StatementParser._parse_while_statement() returns WhileStmt": "Parses a while loop",
    "StatementParser._parse_variable_declaration() returns VarStmt": "Parses let/var/const declarations",
    "StatementParser._parse_block() returns BlockStmt": "Parses a block of statements enclosed in braces",
    "StatementParser._parse_function_declaration() returns FunctionStmt": "Parses a function definition",
    "StatementParser._parse_return_statement() returns ReturnStmt": "Parses a return statement",
    "StatementParser._parse_print_statement() returns PrintStmt": "Parses a print statement",
    "StatementParser._parse_expression_statement() returns ExpressionStmt": "Parses an expression followed by a semicolon",
    "StatementParser._consume(expected_type TokenType, error_message str) returns Token": "Consume expected token or report error",
    "StatementParser._error(token Token, message str) returns None": "Report syntax error and trigger recovery",
    "ErrorHandler.had_error() returns bool": "Returns True if any errors have been reported",
    "ErrorHandler.errors() returns List[ParseError]": "Returns the list of collected errors",
    "Parser._error(token, message, sync_points) returns None": "Report syntax error and initiate recovery",
    "Parser._consume(expected_type, message, sync_points) returns Token": "Consume expected token or report error and recover",
    "StatementParser._error(token, message, sync_points) returns None": "Report syntax error and trigger statement-level recovery",
    "Parser._synchronize(sync_points) returns None": "Panic-mode recovery discarding tokens until sync point",
    "ErrorHandler._is_cascade_error(error) returns bool": "Heuristic detection of cascading errors",
    "ErrorHandler.enter_panic_mode() returns None": "Enter error recovery state",
    "ErrorHandler.exit_panic_mode() returns None": "Exit error recovery state",
    "ErrorHandler.in_panic_mode() returns bool": "Check if currently recovering from error",
    "assert_ast_equal(actual, expected, message)": "Assert two ASTs are structurally equal",
    "create_token_stream(tokens)": "Create TokenStream from list of tokens for testing",
    "parse_and_get_ast(source)": "Parse source code and return AST, ignoring errors for test simplicity",
    "DebugVisitor.__init__(indent_str) returns": "Initialize debug visitor with indent string",
    "DebugVisitor._indent() returns str": "Return current indentation string",
    "DebugVisitor._enter_scope() returns None": "Increase indentation level",
    "DebugVisitor._exit_scope() returns None": "Decrease indentation level",
    "trace_parser(method_name) returns decorator": "Decorator factory for tracing parser method calls",
    "print_precedence_table() returns None": "Print operator precedence table for debugging",
    "parse_type_expression() returns Optional[TypeExpression]": "Parse a type expression",
    "_parse_simple_type() returns SimpleTypeExpr": "Parse simple type identifier",
    "add_change(change TextChange)": "Record a text change",
    "get_affected_ranges() returns List[Tuple[int, int]]": "Get token index ranges affected by changes",
    "affects_token(token_line int, token_col int, token_length int) returns bool": "Check if change affects given token"
  },
  "constants": {
    "TokenType.EOF": "End-of-file sentinel token type",
    "TokenType.SEMICOLON": "Semicolon token type",
    "TokenType.RIGHT_BRACE": "Right brace token type",
    "TokenType.IF": "If keyword token type",
    "TokenType.ELSE": "Else keyword token type",
    "TokenType.PLUS": "Plus operator token type",
    "TokenType.STAR": "Multiplication operator token type",
    "TokenType.RIGHT_PAREN": "Right parenthesis token type",
    "TokenType.COMMA": "Comma token type"
  },
  "terms": {
    "Abstract Syntax Tree (AST)": "Hierarchical tree representation of source code structure",
    "Recursive Descent": "Top-down parsing technique where each grammar production is implemented as a function",
    "Precedence Climbing": "Algorithm for parsing expressions that handles operator precedence and associativity",
    "Lookahead": "Examining the next token(s) in the stream without consuming it",
    "Visitor Pattern": "Behavioral design pattern separating operations from object structure",
    "Left Recursion": "A grammar rule where the first symbol on the right-hand side is the non-terminal being defined",
    "Dangling Else": "Grammatical ambiguity where else clause could belong to either of two nested if statements",
    "Panic Mode Recovery": "Error recovery strategy discarding tokens until synchronization point",
    "Token Stream": "Buffered sequence of tokens providing lookahead and consumption operations",
    "Semantic Analysis": "Validation of program meaning (types, scopes, etc.) performed after parsing",
    "Concrete Syntax Tree (CST)": "A parse tree containing every syntactic detail including punctuation and whitespace",
    "double dispatch": "Technique where method called depends on both visitor and node types",
    "Open/Closed Principle": "Software entities should be open for extension but closed for modification",
    "source span": "The range of source code covered by a token or AST node",
    "single-token lookahead": "Parsing strategy examining only current token to make decisions",
    "panic mode recovery": "Error recovery strategy discarding tokens until a known synchronization point",
    "synchronization points": "Token types indicating safe positions to resume parsing after error",
    "sentinel value": "Special marker value indicating terminal condition (EOF)",
    "precedence climbing": "Recursive descent algorithm for expressions using a precedence table",
    "right binding power": "The minimum precedence for parsing the right-hand side of an operator",
    "primary expression": "An atomic expression unit: literal, identifier, parenthesized expression, unary operation, or call",
    "dangling else": "Grammatical ambiguity where an 'else' clause could belong to either of two nested 'if' statements",
    "keyword-driven dispatch": "Parsing strategy where the first token (a keyword) determines the type of statement to parse",
    "block statement": "A statement that groups multiple statements within braces and establishes a new lexical scope",
    "expression statement": "A statement formed by an expression followed by a semicolon",
    "cascading errors": "Spurious errors reported as a consequence of an earlier error throwing the parser out of sync",
    "dangling else problem": "Grammatical ambiguity where an 'else' clause could belong to either of two nested 'if' statements",
    "fail-fast principle": "Identify violations immediately when grammatical expectation is violated",
    "Testing Pyramid": "Three-layer testing approach: unit tests (foundation), integration tests (middle), end-to-end tests (top)",
    "Golden Master Testing": "Testing approach comparing output against pre-verified reference files",
    "Property-Based Testing": "Testing approach generating random inputs and verifying properties hold",
    "Test-Driven Development": "Software development approach writing tests before implementation",
    "Cascade Errors": "Spurious errors reported as consequence of earlier error throwing parser out of sync",
    "Precedence Table": "Data structure mapping operators to precedence levels and associativity",
    "Debug Visitor": "Visitor pattern implementation for printing AST structure with indentation",
    "Parser Tracing": "Logging entry/exit of parser methods to understand parsing decisions",
    "Precedence Table Debugging": "Inspecting operator precedence and associativity configuration",
    "Step-by-Step Parsing Simulation": "Manual simulation of parser state changes to debug complex issues",
    "Pattern Matching": "Control flow construct that matches values against patterns",
    "Type Annotation": "Optional type specification for variables and functions",
    "Incremental Parsing": "Partial re-parsing of changed regions without full parse",
    "Grammar DSL": "Domain-Specific Language for defining parser grammar",
    "Canonical IR": "Language-neutral intermediate representation",
    "Parallel Parsing": "Using multiple threads/processes to parse concurrently",
    "Edit Resilience": "Parser's ability to handle incomplete or changing code"
  }
}