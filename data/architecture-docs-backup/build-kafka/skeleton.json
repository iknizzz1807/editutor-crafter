{
  "title": "Build Your Own Kafka: Design Document",
  "overview": "This document describes the design and implementation of a distributed message queue supporting partitioned topics, consumer groups, and replication. The key architectural challenge is maintaining ordered, durable message delivery across a scalable and fault-tolerant cluster of brokers, while navigating the inherent trade-offs between latency, throughput, and consistency.",
  "sections": [
    {
      "id": "context",
      "title": "1. Context and Problem Statement",
      "summary": "Explains the real-world need for a distributed message queue, the core problem of scalable event streaming, and the design philosophies behind Apache Kafka.",
      "subsections": [
        {
          "id": "context-analogy",
          "title": "1.1 The Centralized Ledger Analogy",
          "summary": "Introduces a mental model of a bank's ledger to explain topics, partitions, and ordering guarantees."
        },
        {
          "id": "context-problem",
          "title": "1.2 The Scalable Event Streaming Problem",
          "summary": "Defines the core requirements: high-throughput, ordered delivery, fault-tolerance, and decoupling of producers and consumers."
        },
        {
          "id": "context-existing",
          "title": "1.3 Existing Approaches & Trade-offs",
          "summary": "Compares the log-based design of Kafka with traditional message brokers (e.g., RabbitMQ) and other log systems."
        }
      ]
    },
    {
      "id": "goals",
      "title": "2. Goals and Non-Goals",
      "summary": "Clearly states what the system must achieve (Milestones 1-4) and explicitly what is out of scope for this educational project.",
      "subsections": [
        {
          "id": "goals-functional",
          "title": "2.1 Functional Goals",
          "summary": "Lists required features: partitioned topics, producer batching & acks, consumer groups, partition assignment, and leader-follower replication."
        },
        {
          "id": "goals-non-functional",
          "title": "2.2 Non-Functional Goals",
          "summary": "Describes desired system properties: durability, scalability, fault-tolerance, and understandability for learners."
        },
        {
          "id": "goals-non-goals",
          "title": "2.3 Explicit Non-Goals",
          "summary": "Defines out-of-scope items: full Kafka protocol compatibility, transactional producers, tiered storage, and production-grade security."
        }
      ]
    },
    {
      "id": "high-level-arch",
      "title": "3. High-Level Architecture",
      "summary": "Presents a bird's-eye view of the system components (Broker, Producer, Consumer, Coordinator) and their interactions, with a component diagram.",
      "subsections": [
        {
          "id": "high-level-overview",
          "title": "3.1 Component Overview & Responsibilities",
          "summary": "Describes the role of the Broker (log storage), Producer, Consumer, and Group Coordinator."
        },
        {
          "id": "high-level-structure",
          "title": "3.2 Recommended File/Module Structure",
          "summary": "Provides a suggested Go package layout for the codebase to organize core, network, and storage logic."
        },
        {
          "id": "high-level-flow",
          "title": "3.3 End-to-End Message Flow",
          "summary": "Walks through the simplified journey of a single message from producer to consumer."
        }
      ]
    },
    {
      "id": "data-model",
      "title": "4. Data Model",
      "summary": "Defines the core in-memory and on-disk data structures: Topic, Partition, Log Segment, Record, and Consumer Offset.",
      "subsections": [
        {
          "id": "data-model-core",
          "title": "4.1 Core Types and Relationships",
          "summary": "Describes the key types (Topic, Partition, RecordBatch, OffsetMetadata) and their relationships via tables and a class diagram."
        },
        {
          "id": "data-model-storage",
          "title": "4.2 On-Disk Storage Format",
          "summary": "Specifies the binary format for log segments, index files, and consumer offset storage."
        },
        {
          "id": "data-model-metadata",
          "title": "4.3 Cluster Metadata",
          "summary": "Defines the structure for broker, topic, and partition leadership metadata managed by the coordinator."
        }
      ]
    },
    {
      "id": "component-broker",
      "title": "5. Component Design: Broker and Topic Partitions",
      "summary": "Details the design of the broker, focusing on topic/partition management, the append-only log, and local offset tracking. (Corresponds to Milestone 1)",
      "subsections": [
        {
          "id": "component-broker-responsibility",
          "title": "5.1 Responsibility and Scope",
          "summary": "Defines the broker as the server storing partition logs and handling produce/fetch requests."
        },
        {
          "id": "component-broker-mental-model",
          "title": "5.2 Mental Model: The Immutable Ledger",
          "summary": "Explains the partition log as an immutable, append-only ledger of events."
        },
        {
          "id": "component-broker-interface",
          "title": "5.3 Public Interface (APIs)",
          "summary": "Describes the key broker RPC methods: CreateTopic, Produce, Fetch, GetOffsets, CommitOffsets."
        },
        {
          "id": "component-broker-internal",
          "title": "5.4 Internal Behavior: Log Management",
          "summary": "Outlines the algorithm for appending messages, rolling log segments, and serving reads."
        },
        {
          "id": "component-broker-adr-storage",
          "title": "5.5 ADR: Log Storage Backend",
          "summary": "Decision record comparing simple file-based logs vs. embedded KV store for segment storage."
        },
        {
          "id": "component-broker-pitfalls",
          "title": "5.6 Common Pitfalls",
          "summary": "Lists common mistakes: not handling file syncs, incorrect offset gaps, poor key hashing."
        },
        {
          "id": "component-broker-implementation",
          "title": "5.7 Implementation Guidance",
          "summary": "Provides Go starter code for a WAL wrapper and skeleton for the log manager with TODOs."
        }
      ]
    },
    {
      "id": "component-producer",
      "title": "6. Component Design: Producer",
      "summary": "Covers the producer client design, including batching, partitioner selection, acknowledgment handling, and retries. (Corresponds to Milestone 2)",
      "subsections": [
        {
          "id": "component-producer-responsibility",
          "title": "6.1 Responsibility and Scope",
          "summary": "Defines the producer as the client library that batches and sends messages to brokers."
        },
        {
          "id": "component-producer-mental-model",
          "title": "6.2 Mental Model: The Postal Batch Sorter",
          "summary": "Analogy of sorting mail into batches by destination (partition) before dispatching."
        },
        {
          "id": "component-producer-interface",
          "title": "6.3 Public Interface",
          "summary": "Describes the producer's API (Send, Flush, Close) and configuration (acks, retries, batch size)."
        },
        {
          "id": "component-producer-internal",
          "title": "6.4 Internal Behavior: Batching and Sending",
          "summary": "Outlines the algorithm for accumulating messages, selecting partitions, and managing in-flight requests."
        },
        {
          "id": "component-producer-adr-acks",
          "title": "6.5 ADR: Acknowledgment Semantics",
          "summary": "Decision record comparing fire-and-forget, leader-ack, and all-ISR-ack trade-offs for learners."
        },
        {
          "id": "component-producer-pitfalls",
          "title": "6.6 Common Pitfalls",
          "summary": "Lists common mistakes: blocking on full buffer, not handling leader changes, duplicate sends on retry."
        },
        {
          "id": "component-producer-implementation",
          "summary": "Provides Go skeleton code for the accumulator, partitioner, and sender with TODOs.",
          "title": "6.7 Implementation Guidance"
        }
      ]
    },
    {
      "id": "component-consumer",
      "title": "7. Component Design: Consumer and Consumer Groups",
      "summary": "Explains the design of consumer groups, including membership protocol, partition assignment strategies, offset commits, and rebalancing. (Corresponds to Milestone 3)",
      "subsections": [
        {
          "id": "component-consumer-responsibility",
          "title": "7.1 Responsibility and Scope",
          "summary": "Defines the consumer as a client that fetches messages and the group coordinator managing membership."
        },
        {
          "id": "component-consumer-mental-model",
          "title": "7.2 Mental Model: The Team Reading a Shared Book",
          "summary": "Analogy of a team splitting chapters (partitions) of a book (topic) to read in parallel."
        },
        {
          "id": "component-consumer-interface",
          "title": "7.3 Public Interface",
          "summary": "Describes consumer APIs (Subscribe, Poll, CommitSync) and coordinator APIs (JoinGroup, SyncGroup, Heartbeat)."
        },
        {
          "id": "component-consumer-internal",
          "title": "7.4 Internal Behavior: Group Membership & Rebalancing",
          "summary": "Outlines the state machine for group members and the algorithm for partition assignment."
        },
        {
          "id": "component-consumer-adr-assignment",
          "title": "7.5 ADR: Partition Assignment Strategy",
          "summary": "Decision record comparing Range and RoundRobin assignment for simplicity vs. balance."
        },
        {
          "id": "component-consumer-pitfalls",
          "title": "7.6 Common Pitfalls",
          "summary": "Lists common mistakes: rebalance storms, zombie consumers, offset commit races."
        },
        {
          "id": "component-consumer-implementation",
          "summary": "Provides Go skeleton code for the group coordinator and consumer fetcher with TODOs.",
          "title": "7.7 Implementation Guidance"
        }
      ]
    },
    {
      "id": "component-replication",
      "title": "8. Component Design: Replication",
      "summary": "Details the leader-follower replication protocol, ISR management, high watermark advancement, and leader election. (Corresponds to Milestone 4)",
      "subsections": [
        {
          "id": "component-replication-responsibility",
          "title": "8.1 Responsibility and Scope",
          "summary": "Defines the replication module that copies log data between brokers for fault tolerance."
        },
        {
          "id": "component-replication-mental-model",
          "title": "8.2 Mental Model: The Ship's Log Replica",
          "summary": "Analogy of a captain's log being copied to multiple first mates, with a consensus on the latest safe entry."
        },
        {
          "id": "component-replication-interface",
          "title": "8.3 Internal Broker-to-Broker API",
          "summary": "Describes the replication RPCs: LeaderForPartition, FetchReplica, UpdateISR."
        },
        {
          "id": "component-replication-internal",
          "title": "8.4 Internal Behavior: Follower Sync and ISR Management",
          "summary": "Outlines the algorithm for followers to fetch from leaders and for leaders to track ISR."
        },
        {
          "id": "component-replication-adr-election",
          "title": "8.5 ADR: Leader Election Trigger",
          "summary": "Decision record comparing explicit coordinator-managed election vs. follower-triggered election."
        },
        {
          "id": "component-replication-pitfalls",
          "title": "8.6 Common Pitfalls",
          "summary": "Lists common mistakes: allowing unclean election, ISR shrinking to zero, incorrect high watermark updates."
        },
        {
          "id": "component-replication-implementation",
          "summary": "Provides Go skeleton code for the replica manager and leader election logic with TODOs.",
          "title": "8.7 Implementation Guidance"
        }
      ]
    },
    {
      "id": "interactions",
      "title": "9. Interactions and Data Flow",
      "summary": "Illustrates how components communicate through sequence diagrams and defines the binary wire protocol for key operations.",
      "subsections": [
        {
          "id": "interactions-sequences",
          "title": "9.1 Key Sequence Diagrams",
          "summary": "Shows step-by-step flows for message production, consumption, and consumer group rebalancing."
        },
        {
          "id": "interactions-protocol",
          "title": "9.2 Wire Protocol Specification",
          "summary": "Defines the request/response binary format for Produce, Fetch, and JoinGroup APIs using tables."
        },
        {
          "id": "interactions-coordination",
          "title": "9.3 Coordination Service Abstraction",
          "summary": "Describes the minimal interface needed for a coordination service (like a simple in-memory store) to track brokers and leader elections."
        }
      ]
    },
    {
      "id": "error-handling",
      "title": "10. Error Handling and Edge Cases",
      "summary": "Catalogues expected failure modes (node failures, network partitions) and the system's recovery strategies.",
      "subsections": [
        {
          "id": "error-categories",
          "title": "10.1 Failure Mode Categories",
          "summary": "Classifies failures into broker crashes, network partitions, disk failures, and client timeouts."
        },
        {
          "id": "error-recovery",
          "title": "10.2 Recovery Strategies",
          "summary": "Describes how the system handles each failure: leader election, consumer rebalancing, producer retries."
        },
        {
          "id": "edge-cases",
          "title": "10.3 Edge Cases and Race Conditions",
          "summary": "Analyzes tricky scenarios: leader change during produce, duplicate consumer ID, partial write before crash."
        }
      ]
    },
    {
      "id": "testing",
      "title": "11. Testing Strategy",
      "summary": "Provides a guide for how to test the system, including unit tests, integration tests, and milestone verification checkpoints.",
      "subsections": [
        {
          "id": "testing-approach",
          "title": "11.1 Testing Approach",
          "summary": "Recommends a mix of unit tests for logic, integration tests with a in-process broker cluster, and property-based tests for edge cases."
        },
        {
          "id": "testing-milestone-checkpoints",
          "title": "11.2 Milestone Verification Checkpoints",
          "summary": "For each project milestone, describes a concrete test scenario and expected output to confirm correct implementation."
        },
        {
          "id": "testing-tools",
          "title": "11.3 Tools and Libraries",
          "summary": "Suggests Go testing libraries (testify, gomock) and patterns for network and concurrency testing."
        }
      ]
    },
    {
      "id": "debugging",
      "title": "12. Debugging Guide",
      "summary": "Helps learners diagnose common implementation bugs with symptom-cause-fix tables and logging advice.",
      "subsections": [
        {
          "id": "debugging-symptoms",
          "title": "12.1 Common Bug Symptoms",
          "summary": "Lists observable issues: messages lost, duplicates, consumers stuck, high latency."
        },
        {
          "id": "debugging-diagnosis",
          "title": "12.2 Diagnosis Techniques",
          "summary": "Suggests adding structured logs, inspecting internal state dumps, and using timeouts to identify bottlenecks."
        },
        {
          "id": "debugging-fixes",
          "title": "12.3 Symptom \u2192 Cause \u2192 Fix Table",
          "summary": "A table mapping common symptoms to their root causes and suggested fixes."
        }
      ]
    },
    {
      "id": "future",
      "title": "13. Future Extensions",
      "summary": "Suggests potential advanced features learners could add after completing the core milestones.",
      "subsections": [
        {
          "id": "future-extensions-list",
          "title": "13.1 Potential Feature Additions",
          "summary": "Lists ideas: compression, exactly-once semantics, quotas, log compaction, a custom RPC layer."
        },
        {
          "id": "future-design-considerations",
          "title": "13.2 Design Considerations for Extensions",
          "summary": "Discusses how the current design accommodates or would need modification for each extension."
        }
      ]
    },
    {
      "id": "glossary",
      "title": "14. Glossary",
      "summary": "Defines key terms, acronyms, and domain-specific vocabulary used throughout the document.",
      "subsections": [
        {
          "id": "glossary-terms",
          "title": "14.1 Terms and Definitions",
          "summary": "Alphabetical list of terms: Broker, Consumer Group, High Watermark, ISR, Offset, Partition, Topic, etc."
        }
      ]
    }
  ],
  "diagrams": [
    {
      "id": "diagram-system-component",
      "title": "System Component Overview",
      "description": "Shows the high-level components: multiple Brokers forming a cluster, Producers sending to topics, Consumer Groups reading, and the Group Coordinator managing membership. Include connections for data flow (produce/fetch) and control flow (heartbeat, metadata).",
      "type": "component",
      "relevant_sections": [
        "high-level-arch",
        "interactions"
      ]
    },
    {
      "id": "diagram-data-model",
      "title": "Data Model Relationships",
      "description": "A class diagram showing relationships: A Cluster has many Brokers. A Broker hosts many PartitionReplicas. A Topic has many Partitions. A Partition is a Log composed of LogSegments. A LogSegment contains RecordBatches. A ConsumerGroup has many Consumers and tracks Offsets per Partition.",
      "type": "class",
      "relevant_sections": [
        "data-model"
      ]
    },
    {
      "id": "diagram-producer-flow",
      "title": "Producer Send Sequence",
      "description": "Sequence diagram: Producer client -> (Metadata Cache) -> Broker Leader. Shows steps: 1) Get metadata for topic, 2) Choose partition, 3) Add to batch accumulator, 4) Send batch to leader, 5) Leader appends to log and responds with ack.",
      "type": "sequence",
      "relevant_sections": [
        "component-producer",
        "interactions"
      ]
    },
    {
      "id": "diagram-consumer-group-state",
      "title": "Consumer Group State Machine",
      "description": "State machine for a consumer group member: STARTING -> (JoinGroup request) -> AWAITING_ASSIGNMENT -> (SyncGroup request) -> STABLE -> (heartbeats). Transitions on: member joins, coordinator assigns, heartbeat fails (-> DEAD), rebalance triggered (-> AWAITING_ASSIGNMENT).",
      "type": "state-machine",
      "relevant_sections": [
        "component-consumer"
      ]
    },
    {
      "id": "diagram-replication-flow",
      "title": "Leader-Follower Replication Flow",
      "description": "Flowchart showing the loop for a Follower replica: 1) Send Fetch request to Leader, 2) Leader checks High Watermark and returns new records, 3) Follower appends to local log, 4) Follower updates its LEO, 5) On periodic check, Leader updates ISR if follower is caught up.",
      "type": "flowchart",
      "relevant_sections": [
        "component-replication"
      ]
    },
    {
      "id": "diagram-rebalance-sequence",
      "title": "Consumer Group Rebalance Sequence",
      "description": "Sequence diagram involving 2 Consumers and a Group Coordinator. Shows: Consumer 2 joins, Coordinator detects new member, tells all members to rejoin (JoinGroup), collects assignments, sends new assignment (SyncGroup), consumers acknowledge and start fetching.",
      "type": "sequence",
      "relevant_sections": [
        "component-consumer",
        "interactions"
      ]
    }
  ]
}