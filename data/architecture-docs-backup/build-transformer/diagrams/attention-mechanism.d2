direction: right

# Input embeddings
input: Input Embeddings {
  style.fill: "#1a1a2e"
  style.stroke: "#3fb950"
  style.font-color: "#e6edf3"
}

# Multi-head attention container
mha: Multi-Head Attention {
  style.fill: "#16213e"
  style.stroke: "#3fb950"
  style.font-color: "#e6edf3"
  style.bold: true
  
  # Linear projections
  proj: Projections {
    style.fill: "#0f3460"
    style.stroke: "#8b949e"
    style.font-color: "#e6edf3"
    
    wq: Linear Q {
      shape: rectangle
      style.fill: "#1a1a2e"
      style.stroke: "#3fb950"
      style.font-color: "#e6edf3"
    }
    wk: Linear K {
      shape: rectangle
      style.fill: "#1a1a2e"
      style.stroke: "#3fb950"
      style.font-color: "#e6edf3"
    }
    wv: Linear V {
      shape: rectangle
      style.fill: "#1a1a2e"
      style.stroke: "#3fb950"
      style.font-color: "#e6edf3"
    }
  }
  
  # Multiple attention heads
  heads: Attention Heads {
    style.fill: "#0f3460"
    style.stroke: "#8b949e"
    style.font-color: "#e6edf3"
    
    head1: Head 1\nScaled Dot-Product {
      shape: rectangle
      style.fill: "#1a1a2e"
      style.stroke: "#3fb950"
      style.font-color: "#e6edf3"
    }
    head2: Head 2\nScaled Dot-Product {
      shape: rectangle
      style.fill: "#1a1a2e"
      style.stroke: "#3fb950"
      style.font-color: "#e6edf3"
    }
    head3: Head h\nScaled Dot-Product {
      shape: rectangle
      style.fill: "#1a1a2e"
      style.stroke: "#3fb950"
      style.font-color: "#e6edf3"
    }
  }
  
  # Concatenation
  concat: Concatenate {
    shape: rectangle
    style.fill: "#1a1a2e"
    style.stroke: "#3fb950"
    style.font-color: "#e6edf3"
    style.bold: true
  }
  
  # Output projection
  wo: Linear Output {
    shape: rectangle
    style.fill: "#1a1a2e"
    style.stroke: "#3fb950"
    style.font-color: "#e6edf3"
  }
}

# Output
output: Multi-Head Output {
  style.fill: "#1a1a2e"
  style.stroke: "#3fb950"
  style.font-color: "#e6edf3"
}

# Connections
input -> mha.proj.wq: Q
input -> mha.proj.wk: K
input -> mha.proj.wv: V

mha.proj.wq -> mha.heads.head1: Q₁
mha.proj.wk -> mha.heads.head1: K₁
mha.proj.wv -> mha.heads.head1: V₁

mha.proj.wq -> mha.heads.head2: Q₂
mha.proj.wk -> mha.heads.head2: K₂
mha.proj.wv -> mha.heads.head2: V₂

mha.proj.wq -> mha.heads.head3: Qₕ
mha.proj.wk -> mha.heads.head3: Kₕ
mha.proj.wv -> mha.heads.head3: Vₕ

mha.heads.head1 -> mha.concat: Z₁
mha.heads.head2 -> mha.concat: Z₂
mha.heads.head3 -> mha.concat: Zₕ

mha.concat -> mha.wo: Concatenated
mha.wo -> output

# Attention formula note
formula: |md
  **Attention(Q,K,V) = softmax(QK^T/√d_k)V**
  
  Each head learns different relationships
| {
  shape: page
  style.fill: "#0f3460"
  style.stroke: "#3fb950"
  style.font-color: "#e6edf3"
}