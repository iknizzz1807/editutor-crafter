title: Tensor Shapes and Data Types {
  style.font-size: 20
  style.bold: true
  style.fill: "#1a1a2e"
  style.font-color: "#e6edf3"
}

config: Configuration Classes {
  style.fill: "#16213e"
  style.stroke: "#3fb950"
  style.font-color: "#e6edf3"
  
  ModelConfig: Model Configuration {
    shape: class
    style.fill: "#0f3460"
    style.stroke: "#3fb950"
    style.font-color: "#e6edf3"
    
    vocab_size: int
    d_model: int
    n_heads: int
    n_layers: int
    max_seq_len: int
    dropout: float
  }
  
  AttentionConfig: Attention Parameters {
    shape: class
    style.fill: "#0f3460"
    style.stroke: "#3fb950"
    style.font-color: "#e6edf3"
    
    d_k: int
    d_v: int
    scale: float
    causal_mask: bool
  }
}

tensors: Tensor Shapes {
  style.fill: "#16213e"
  style.stroke: "#3fb950"
  style.font-color: "#e6edf3"
  
  input_tokens: Input Tokens {
    shape: sql_table
    style.fill: "#0f3460"
    style.stroke: "#8b949e"
    style.font-color: "#e6edf3"
    
    tensor_shape: "[batch_size, seq_len]"
    dtype: "torch.long"
  }
  
  embeddings: Token Embeddings {
    shape: sql_table
    style.fill: "#0f3460"
    style.stroke: "#8b949e"
    style.font-color: "#e6edf3"
    
    tensor_shape: "[batch_size, seq_len, d_model]"
    dtype: "torch.float32"
  }
  
  attention_weights: Attention Weights {
    shape: sql_table
    style.fill: "#0f3460"
    style.stroke: "#8b949e"
    style.font-color: "#e6edf3"
    
    tensor_shape: "[batch_size, n_heads, seq_len, seq_len]"
    dtype: "torch.float32"
  }
  
  qkv_matrices: Query/Key/Value {
    shape: sql_table
    style.fill: "#0f3460"
    style.stroke: "#8b949e"
    style.font-color: "#e6edf3"
    
    tensor_shape: "[batch_size, seq_len, n_heads, d_k]"
    dtype: "torch.float32"
  }
}

params: Model Parameters {
  style.fill: "#16213e"
  style.stroke: "#3fb950"
  style.font-color: "#e6edf3"
  
  embedding_weights: Embedding Matrix {
    shape: sql_table
    style.fill: "#0f3460"
    style.stroke: "#8b949e"
    style.font-color: "#e6edf3"
    
    tensor_shape: "[vocab_size, d_model]"
    dtype: "torch.float32"
  }
  
  linear_weights: Linear Layer Weights {
    shape: sql_table
    style.fill: "#0f3460"
    style.stroke: "#8b949e"
    style.font-color: "#e6edf3"
    
    tensor_shape: "[d_model, d_model]"
    dtype: "torch.float32"
  }
  
  positional_encoding: Position Encoding {
    shape: sql_table
    style.fill: "#0f3460"
    style.stroke: "#8b949e"
    style.font-color: "#e6edf3"
    
    tensor_shape: "[max_seq_len, d_model]"
    dtype: "torch.float32"
  }
}

config.ModelConfig -> tensors.embeddings: "defines d_model" {
  style.stroke: "#3fb950"
  style.bold: true
}

config.ModelConfig -> tensors.attention_weights: "defines n_heads" {
  style.stroke: "#8b949e"
}

config.AttentionConfig -> tensors.qkv_matrices: "defines d_k, d_v" {
  style.stroke: "#8b949e"
}

tensors.input_tokens -> tensors.embeddings: "embedding lookup" {
  style.stroke: "#3fb950"
  style.bold: true
}

params.embedding_weights -> tensors.embeddings: "transforms" {
  style.stroke: "#8b949e"
}

tensors.embeddings -> tensors.qkv_matrices: "linear projection" {
  style.stroke: "#8b949e"
}

tensors.qkv_matrices -> tensors.attention_weights: "attention computation" {
  style.stroke: "#3fb950"
  style.bold: true
}

params.positional_encoding -> tensors.embeddings: "position info" {
  style.stroke: "#8b949e"
}

dimension_note: |md
  ## Key Relationships
  - **d_k = d_model / n_heads**
  - **batch_size**: Variable training batch
  - **seq_len â‰¤ max_seq_len**: Sequence length constraint
| {
  shape: page
  style.fill: "#1a1a2e"
  style.stroke: "#3fb950"
  style.font-color: "#e6edf3"
}