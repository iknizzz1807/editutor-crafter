{
  "types": {
    "Token": "fields: type str, lexeme str, position int",
    "ASTNode": "fields: (abstract base class)",
    "Number": "fields: value float",
    "BinaryOp": "fields: operator str, left ASTNode, right ASTNode",
    "UnaryOp": "fields: operator str, operand ASTNode",
    "Assign": "fields: name str, value ASTNode",
    "Variable": "fields: name str",
    "FunctionCall": "fields: name str, argument ASTNode",
    "Environment": "fields: variables dict[str, float], parent Environment",
    "LexerError": "fields: message str, position int",
    "Lexer": "fields: (none, state managed in tokenize method)",
    "SyntaxError": "fields: message str, position int",
    "Evaluator": "class with BUILTINS class variable and evaluate class method",
    "SemanticError": "fields: message str, position int",
    "RuntimeError": "fields: message str, position int",
    "CalculatorError": "fields: message str, position int",
    "ComparisonOp": "fields: operator str, left ASTNode, right ASTNode",
    "TernaryOp": "fields: condition ASTNode, true_expr ASTNode, false_expr ASTNode",
    "Program": "fields: statements list[ASTNode]",
    "Block": "fields: statements list[ASTNode]"
  },
  "methods": {
    "Lexer.tokenize(input: str) returns list[Token]": "Scans input string to tokens, raises LexerError on invalid characters",
    "Parser.parse(tokens: list[Token]) returns ASTNode": "Top-level method that builds AST from token stream",
    "Evaluator.evaluate(node: ASTNode, env: Environment) returns float": "Evaluates AST to number, may raise SemanticError or RuntimeError",
    "Environment.get(name: str) returns float": "Retrieves variable value, raises NameError if undefined",
    "Environment.set(name: str, value: float) returns None": "Assign or update variable value",
    "Lexer.tokenize(input_str: str) returns List[Token]": "Scans the entire input string and returns a list of tokens. The final token is always of type EOF.",
    "Parser.parse_assignment() returns ASTNode": "Parses assignment or expression",
    "Parser.parse_term() returns ASTNode": "Parses addition/subtraction",
    "Parser.parse_factor() returns ASTNode": "Parses multiplication/division",
    "Parser.parse_unary() returns ASTNode": "Parses unary plus/minus",
    "Parser.parse_power() returns ASTNode": "Parses exponentiation (right-associative)",
    "Parser.parse_primary() returns ASTNode": "Parses numbers, identifiers, parentheses, function calls",
    "Parser.current_token() returns Token": "Returns token at current position",
    "Parser.peek() returns Token": "Returns next token without consuming",
    "Parser.consume(expected_type: str, error_msg: str) returns Token": "Consumes token if type matches, else raises SyntaxError with position",
    "Parser.match(*types: str) returns bool": "Checks and consumes token if type matches any",
    "Parser.is_at_end() returns bool": "Checks if current token is EOF",
    "evaluate(node, env) returns float": "Recursively evaluates AST node to produce numeric result",
    "debug_print_tokens(tokens)": "Print token stream for debugging",
    "debug_print_ast(node, indent)": "Recursively print AST with indentation",
    "Lexer.tokenize(input) returns list[Token]": "Scans input string to tokens, raises LexerError on invalid characters",
    "Parser.parse(tokens) returns ASTNode": "Top-level method that builds AST from token stream",
    "Evaluator.evaluate(node, env) returns float": "Evaluates AST to number, may raise SemanticError or RuntimeError",
    "Environment.get(name) returns float": "Retrieves variable value, raises NameError if undefined",
    "Environment.set(name, value) returns None": "assign or update variable value",
    "Parser.consume(expected_type, error_msg) returns Token": "Consumes token if type matches, else raises SyntaxError with position",
    "Parser.match(*types) returns bool": "Checks and consumes token if type matches any",
    "CalculatorREPL.run() returns": "Starts the REPL loop",
    "CalculatorREPL._evaluate_line(line: str) returns": "Evaluates a single line of input"
  },
  "constants": {
    "PLUS": "'+' token type",
    "MINUS": "'-' token type",
    "STAR": "'*' token type",
    "SLASH": "'/' token type",
    "CARET": "'^' token type",
    "EQUAL": "'=' token type",
    "LPAREN": "'(' token type",
    "RPAREN": "')' token type",
    "NUMBER": "numeric literal token type",
    "IDENTIFIER": "variable/function name token type",
    "EOF": "end of input token type",
    "BUILTINS": "dictionary mapping function names to Python callables",
    "MODULO": "'%' token type",
    "FLOOR_DIV": "'//' token type",
    "COMMA": "',' token type",
    "QUESTION": "'?' token type",
    "COLON": "':' token type",
    "SEMICOLON": "';' token type"
  },
  "terms": {
    "precedence": "order of operator evaluation",
    "associativity": "direction of evaluation for same-precedence operators",
    "expression": "combination of values and operators that evaluates to a single value",
    "unary operator": "operator with one operand",
    "binary operator": "operator with two operands",
    "symbol table": "data structure mapping variable names to values",
    "intermediate representation (IR)": "a data structure (like the AST) that decouples parsing from execution",
    "separation of concerns": "Different components handle different error types",
    "lexeme": "The exact sequence of characters forming a token",
    "abstract syntax tree (AST)": "hierarchical tree representation of expression structure",
    "lexer": "Component that scans input string to produce tokens",
    "tokenizer": "Synonym for lexer",
    "scanner": "Synonym for lexer",
    "token": "A meaningful unit (type, lexeme, position) output by the lexer",
    "whitespace": "Spaces, tabs, newlines; ignored by the lexer",
    "greedy scanning": "The lexer consumes as many characters as possible to form a valid token",
    "parser": "Component that consumes tokens to build an AST",
    "recursive descent": "parsing technique using mutually recursive functions",
    "grammar": "Formal specification of the syntactic structure of valid expressions",
    "lookahead": "Inspecting the next token(s) without consuming them",
    "syntax error": "Error in the structure of an expression (e.g., mismatched parentheses)",
    "tree walk": "recursive traversal of AST to execute operations",
    "side effect": "modification of environment state during evaluation",
    "built-in function": "predefined mathematical function like sin or sqrt",
    "lexical error": "Error in character sequence, caught by lexer",
    "syntactic error": "Error in expression structure, caught by parser",
    "semantic error": "Error in expression meaning, caught by evaluator",
    "runtime error": "Error during computation, caught by evaluator",
    "position tracking": "Recording character index for error reporting",
    "error recovery": "Attempting to continue after error to find more issues",
    "regression test": "Test to ensure previously working functionality still works after changes",
    "unit test": "Test for individual component in isolation",
    "integration test": "Test for multiple components working together",
    "test coverage": "Measure of how much code is exercised by tests",
    "test fixture": "Fixed state used as baseline for running tests",
    "REPL": "Read-Eval-Print Loop: an interactive programming environment",
    "plugin architecture": "A system where functionality can be added via modular extensions",
    "short-circuit evaluation": "Evaluating only part of a logical expression when the result is already determined",
    "function call frames": "Data structure holding a function's local variables and return state during execution"
  }
}