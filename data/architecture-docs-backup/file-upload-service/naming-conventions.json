{
  "types": {
    "Config": "fields: Server ServerConfig, Storage StorageConfig, Security SecurityConfig, Cleanup CleanupConfig",
    "ServerConfig": "fields: Host string, Port int, ReadTimeout Duration, WriteTimeout Duration, MaxBodySize int64",
    "StorageConfig": "fields: Backend string, LocalPath string, S3Config *S3Config, Options map[string]string",
    "S3Config": "fields: Bucket string, Region string, AccessKeyID string, SecretAccessKey string, Endpoint string",
    "SecurityConfig": "fields: MaxFileSize int64, AllowedContentTypes []string, VirusScanEnabled bool, ClamAVSocket string",
    "CleanupConfig": "fields: SessionTTL Duration, CleanupInterval Duration, QuarantineTTL Duration",
    "UploadSession": "fields: ID string, Filename string, ContentType string, TotalSize int64, CurrentOffset int64, Status SessionStatus",
    "SessionStatus": "string enum for session states",
    "SessionManager": "fields: store StateStore, storage StorageBackend",
    "MemoryStore": "fields: sessions map[string]*UploadSession with mutex protection",
    "StorageBackend": "interface with StoreChunk, InitMultipart, CompleteMultipart",
    "MultipartUpload": "fields: ID string, Key string, Backend string, Metadata map[string]string, CreatedAt time.Time",
    "MultipartPart": "fields: PartNumber int, ETag string, Size int64, PartID string",
    "BackendFactory": "interface with CreateBackend, SupportedBackends",
    "Credentials": "fields: AccessKeyID string, SecretAccessKey string, SessionToken string, ExpiresAt time.Time, Region string",
    "CredentialProvider": "interface with GetCredentials, RefreshCredentials",
    "LocalBackend": "fields: rootPath string, mutex sync.RWMutex",
    "StorageError": "fields: Operation string, Key string, Backend string, Err error",
    "FileSignature": "fields: Pattern []byte, Offset int, MIME string, Extensions []string, Description string",
    "Detector": "fields: signatures []FileSignature",
    "ClamAVScanner": "fields: socketPath string, timeout time.Duration",
    "ScanResult": "fields: Clean bool, ThreatName string, Error error, ScanTime time.Duration",
    "FileValidator": "fields: detector *Detector, scanner Scanner, config *SecurityConfig",
    "ValidationResult": "fields: Passed bool, FileType string, ThreatName string",
    "UploadError": "fields: Category error, Component string, Operation string, SessionID string, Cause error, Retryable bool, RetryAfter int, Metadata map[string]interface{}, Timestamp time.Time",
    "CircuitBreaker": "fields: maxFailures int, resetTimeout time.Duration, failures int, lastFailTime time.Time, state CircuitState",
    "InitUploadRequest": "fields: Filename string, ContentType string, TotalSize int64, Metadata map[string]string",
    "InitUploadResponse": "fields: SessionID string, UploadURL string, ExpiresAt time.Time, ChunkSize int64, Metadata map[string]string",
    "ChunkUploadResponse": "fields: SessionID string, CurrentOffset int64, NextOffset int64, Completed bool",
    "ErrorResponse": "fields: Error string, ErrorCode string, SessionID string, RetryAfter int, Details interface{}",
    "FlowCoordinator": "fields: sessionManager *SessionManager, storageBackend StorageBackend, fileValidator *FileValidator, circuitBreaker *coordinator.CircuitBreaker",
    "CircuitState": "type: int enum",
    "ResourceMonitor": "fields: memoryWarning int64, memoryCritical int64, diskWarning int64, diskCritical int64, activeUploads int64, maxUploads int64, alerts chan ResourceAlert, circuitBreaker *CircuitBreaker",
    "ResourceStatus": "fields: MemoryUsed int64, MemoryTotal int64, MemoryPercent float64, DiskUsed int64, DiskTotal int64, DiskPercent float64, ActiveUploads int64",
    "RecoveryCoordinator": "fields: sessionManager *SessionManager, storageBackend StorageBackend, resourceMonitor *ResourceMonitor, circuitBreaker *CircuitBreaker, logger *StructuredLogger",
    "CorruptionRecovery": "fields: sessionManager *SessionManager, storage StorageBackend",
    "MockStorageBackend": "fields: chunks map, multipartUploads map, failureScenarios map, operationDelays map",
    "TusProtocolTester": "fields: baseURL string, httpClient *http.Client, t *testing.T",
    "LoadTestScenario": "fields: Name string, ConcurrentUsers int, TestDuration time.Duration",
    "MilestoneValidator": "fields: serverURL string, storageConfig StorageConfig, testDataPath string",
    "FailureScenario": "fields: Operation string, FailAfterOps int, ErrorType error",
    "StructuredLogger": "fields: logger *slog.Logger, component string, baseFields map[string]interface{}",
    "SessionInspector": "fields: sessionManager *SessionManager, storage StorageBackend, logger *StructuredLogger",
    "SessionDiagnostics": "fields: SessionID string, CurrentState SessionStatus, StateConsistent bool, StoredChunkCount int, RecordedOffset int64, ActualStoredSize int64, MissingChunks []ChunkRange, CorruptedChunks []CorruptionReport, RepairActions []RepairAction, Recommendations []string",
    "ExtensionConfig": "fields: ParallelUploads ParallelConfig, Compression CompressionConfig, Deduplication DeduplicationConfig, Encryption EncryptionConfig, CDNIntegration CDNConfig, Scaling ScalingConfig",
    "ParallelConfig": "fields: Enabled bool, MaxConcurrentChunks int, BufferSizeLimit int64, BackpressureThreshold int64",
    "CompressionConfig": "fields: Enabled bool, Algorithm string, CompressionLevel int, ChunkSizeMin int64, ChunkSizeMax int64",
    "DeduplicationConfig": "fields: Enabled bool, Scope string, HashAlgorithm string, IndexBackend string",
    "ScalingConfig": "fields: Mode string, ServiceDiscovery string, StateStore string, SessionAffinity string, ShardingEnabled bool, ShardCount int",
    "ParallelUploadCoordinator": "fields: ChunkBuffer map[int64]*ChunkMetadata, CompletionRanges []OffsetRange, ConcurrencyLimit int, BackpressureThreshold int64, AssemblyStrategy AssemblyMode",
    "CompressionCoordinator": "fields: compression strategy management",
    "ChunkSizeOptimizer": "fields: network condition analysis and recommendation",
    "DeduplicationManager": "fields: hashIndex HashIndex, refCounter ReferenceCounter, storageBackend StorageBackend, config *DeduplicationConfig, stats *DeduplicationStats",
    "EncryptionCoordinator": "fields: encryption strategy management",
    "EncryptedUploadSession": "fields: EncryptionMode EncryptionType, KeyDerivationInfo KeyDerivationParams, MetadataEncryption bool, ComplianceProfile string",
    "MetadataProcessor": "fields: content analysis and extraction",
    "MetadataExtractor": "interface for pluggable metadata processing",
    "MLScanningCoordinator": "fields: multiple detection strategy integration",
    "MLThreatAnalyzer": "fields: ModelVersion string, AnalysisDepth ScanDepth, ConfidenceThreshold float64, FallbackStrategy FallbackMode, LearningEnabled bool",
    "CDNCoordinator": "fields: distribution policy and edge synchronization",
    "ScalingCoordinator": "fields: InstanceID string, LoadBalancingStrategy LBStrategy, SessionAffinityMode AffinityMode, HeartbeatInterval time.Duration, FailoverTimeout time.Duration",
    "DistributedStateStore": "fields: redis RedisClient, database DatabaseClient, config *DistributedStateConfig, logger *StructuredLogger",
    "ShardingCoordinator": "fields: data distribution across storage partitions",
    "DiscoveryManager": "fields: instance registration and health monitoring",
    "HealthReporter": "fields: InstanceID string, StartTime time.Time, ActiveSessions int, ResourceUtilization ResourceStatus, LastHealthCheck time.Time, ServiceStatus ServiceState",
    "LoadBalancingCoordinator": "fields: AffinityStrategy AffinityType, MigrationEnabled bool, HealthCheckInterval time.Duration, LoadMetrics []MetricType",
    "SessionMigrationManager": "fields: session transfer coordination",
    "ParallelCoordinator": "fields: config *ParallelConfig, chunkPool *ChunkPool, sessionManagers map[string]*SessionParallelManager, mutex sync.RWMutex, resourceMonitor *ResourceMonitor",
    "SessionParallelManager": "fields: sessionID string, totalSize int64, chunkSize int64, completedRanges *RangeSet, pendingChunks map[int64]*PendingChunk, concurrencyLimit int, activeSemaphore chan struct{}, mutex sync.RWMutex",
    "PendingChunk": "fields: Offset int64, Size int64, Data []byte, Hash string, ReceivedAt time.Time, ProcessingStarted bool",
    "RangeSet": "fields: ranges []Range, mutex sync.RWMutex",
    "Range": "fields: Start int64, End int64"
  },
  "methods": {
    "LoadConfig(filename string) (*Config, error)": "loads configuration from JSON file with defaults",
    "NewMemoryStore() *MemoryStore": "creates in-memory state store for testing",
    "CreateSession(ctx Context, session *UploadSession) error": "stores new upload session in distributed state",
    "GetSession(ctx Context, sessionID string) (*UploadSession, error)": "retrieves upload session with cache-first strategy",
    "UpdateSession(ctx Context, session *UploadSession) error": "modifies existing session state across distributed stores",
    "DeleteSession(ctx Context, sessionID string) error": "removes upload session",
    "ListExpiredSessions(ctx Context, ttl Duration) ([]string, error)": "returns expired session IDs",
    "InitializeUpload(ctx Context, filename string, totalSize int64, metadata map[string]string) (*UploadSession, error)": "creates new upload session and prepares storage",
    "ProcessChunk(ctx Context, sessionID string, offset int64, data []byte, contentHash string) error": "handles incoming chunk upload",
    "GetUploadProgress(ctx Context, sessionID string) (*UploadSession, error)": "returns current upload status for resume",
    "ValidateRequirements() error": "checks configuration against functional and non-functional requirements",
    "NewLocalBackend(rootPath string) (*LocalBackend, error)": "creates local filesystem backend",
    "StoreChunk(ctx Context, key string, data io.Reader, size int64) error": "stores chunk data at key",
    "InitMultipart(ctx Context, key string, metadata map[string]string) (*MultipartUpload, error)": "begins multipart upload",
    "CompleteMultipart(ctx Context, upload *MultipartUpload, parts []*MultipartPart) error": "assembles multipart upload",
    "NewDetector() *Detector": "creates file type detector with default signatures",
    "DetectFromReader(reader io.Reader) (string, error)": "examines file content to determine MIME type",
    "DetectFromBytes(data []byte) string": "matches byte patterns against known signatures",
    "NewClamAVScanner(socketPath string, timeout time.Duration) *ClamAVScanner": "creates scanner connected to ClamAV daemon",
    "ScanStream(ctx Context, reader io.Reader) (*ScanResult, error)": "sends file data to ClamAV and returns scan results",
    "Ping() error": "tests connectivity to ClamAV daemon",
    "ValidateFile(ctx Context, sessionID string, reader io.Reader, metadata map[string]string) (*ValidationResult, error)": "runs complete validation pipeline",
    "EnforceResourceLimits(ctx Context, userID string, fileSize int64, contentType string) error": "checks upload against size and rate limits",
    "NewCircuitBreaker(maxFailures int, resetTimeout time.Duration) *CircuitBreaker": "creates circuit breaker with thresholds",
    "Execute(ctx context.Context, operation func() error) error": "runs operation through circuit breaker",
    "InitializeUpload(ctx context.Context, req *InitUploadRequest) (*InitUploadResponse, error)": "coordinates upload initialization flow",
    "ProcessChunkUpload(ctx context.Context, sessionID string, offset int64, data io.Reader, checksum string) (*ChunkUploadResponse, error)": "coordinates chunk validation and storage",
    "CompleteUpload(ctx context.Context, sessionID string) (*CompletionResponse, error)": "coordinates file assembly and validation",
    "NewUploadError(category error, component, operation, sessionID string, cause error) *UploadError": "creates categorized error with context",
    "GetCurrentStatus() *ResourceStatus": "returns comprehensive resource utilization information",
    "ShouldAcceptUpload() bool": "determines if system resources allow new upload acceptance",
    "HandleUploadError(ctx context.Context, err *UploadError) error": "implements comprehensive error handling with recovery attempts",
    "RecoverFromStorageFailure(ctx context.Context, sessionID string, operation string) error": "handles storage backend failures with failover",
    "HandleChunkCorruption(ctx context.Context, sessionID string, chunkOffset int64, expectedHash, actualHash string) error": "manages detection and recovery from data corruption",
    "VerifyAssemblyIntegrity(ctx context.Context, sessionID string) (*ValidationResult, error)": "performs integrity checking during assembly",
    "NewMockStorageBackend() *MockStorageBackend": "creates storage mock with fault injection capabilities",
    "InjectFailure(operation string, failAfter int, err error)": "configures mock to fail after specified operations",
    "TestCompleteUploadFlow()": "validates entire tus.io protocol sequence",
    "ExecuteScenario(ctx Context) (*LoadTestResults, error)": "runs comprehensive load testing scenario",
    "ValidateMilestone1() error": "automated validation for chunked upload protocol",
    "initializeUpload(filename, totalSize, metadata) string": "creates upload session via tus protocol",
    "uploadChunk(uploadID, offset, data)": "uploads single chunk with offset tracking",
    "getUploadProgress(uploadID) int": "queries current upload offset",
    "simulateRealisticUpload(ctx, pattern, results)": "simulates real-world upload behavior patterns",
    "NewStructuredLogger(component string, output io.Writer) *StructuredLogger": "creates logger with component-specific configuration",
    "LogUploadEvent(ctx context.Context, level slog.Level, message string, sessionID string, operation string, fields map[string]interface{})": "records significant upload operation events",
    "LogError(ctx context.Context, err error, sessionID string, component string, operation string, retryable bool)": "provides specialized error logging with categorization",
    "InspectSession(ctx context.Context, sessionID string) (*SessionDiagnostics, error)": "performs comprehensive analysis of session state",
    "AnalyzeInconsistency(session *UploadSession, storageChunks []ChunkInfo) []InconsistencyReport": "identifies specific types of session state problems",
    "MonitorResources(ctx context.Context) error": "runs continuous resource monitoring with alert generation",
    "LoadExtensionConfig(filename string) (*ExtensionConfig, error)": "loads extension configuration from JSON file",
    "NewParallelCoordinator(config *ParallelConfig, monitor *ResourceMonitor) *ParallelCoordinator": "creates coordinator for managing parallel uploads",
    "ProcessChunkParallel(ctx context.Context, sessionID string, offset int64, data []byte, hash string) error": "handles concurrent chunk processing with ordering",
    "ProcessChunkWithDeduplication(ctx context.Context, sessionID string, chunkData []byte, expectedHash string) (*ChunkProcessingResult, error)": "checks for existing chunks before storage",
    "CleanupUnreferencedChunks(ctx context.Context) error": "removes chunks that are no longer referenced",
    "SupportedTypes() []string": "returns MIME types this extractor can process",
    "ExtractMetadata(ctx Context, reader io.Reader, contentType string) (*MetadataResult, error)": "processes file content and returns extracted metadata",
    "EstimateProcessingTime(fileSize int64, contentType string) time.Duration": "provides time estimate for scheduling decisions",
    "RequiredResources(fileSize int64, contentType string) ResourceRequirements": "specifies CPU, memory needs for resource planning",
    "PrepareForMigration() error": "prepare session for transfer",
    "MigrateSession() error": "transfer session ownership",
    "ConfirmMigration() error": "verify successful transfer",
    "RollbackMigration() error": "handle migration failures"
  },
  "constants": {
    "SessionStatusInitialized": "initialized",
    "SessionStatusActive": "active session state",
    "SessionStatusCompleting": "completing",
    "SessionStatusCompleted": "completed session state",
    "SessionStatusFailed": "failed",
    "SessionStatusExpired": "expired",
    "ErrSessionNotFound": "session not found error",
    "ErrNotFound": "key not found error",
    "ErrAlreadyExists": "key already exists error",
    "ErrInsufficientSpace": "insufficient storage space error",
    "ErrNetworkTimeout": "network operation timeout error",
    "ErrAuthenticationFailed": "authentication failed error",
    "ErrInvalidMultipartState": "invalid multipart upload state error",
    "ErrFileTooLarge": "file exceeds size limits",
    "ErrSystemOverloaded": "system resources critically low",
    "ErrVirusScanTimeout": "virus scanning operation timed out",
    "ErrQuarantineRequired": "file must be quarantined",
    "ErrTransient": "transient error category",
    "ErrPermanent": "permanent error category",
    "ErrDataCorruption": "data corruption",
    "ErrSecurityViolation": "security violation",
    "ErrResourceExhaustion": "resource exhaustion",
    "ErrCircuitBreakerOpen": "circuit breaker open",
    "CircuitClosed": "circuit closed state",
    "CircuitOpen": "circuit open state",
    "CircuitHalfOpen": "circuit half-open state",
    "AssemblyMode": "assembly strategy enumeration",
    "EncryptionType": "encryption algorithm enumeration",
    "ScanDepth": "analysis thoroughness enumeration",
    "FallbackMode": "failure handling strategy enumeration",
    "LBStrategy": "load balancing strategy enumeration",
    "AffinityMode": "session affinity enumeration",
    "AffinityType": "affinity strategy enumeration",
    "MetricType": "load balancing metric enumeration",
    "ServiceState": "health status enumeration"
  },
  "terms": {
    "resumable upload": "file upload that can be interrupted and resumed from last offset",
    "chunked upload": "file upload split into multiple smaller pieces",
    "upload session": "server-side state tracking ongoing resumable upload",
    "session state management": "persistence and coordination of upload progress across failures",
    "offset tracking": "byte-level progress monitoring for precise resume capability",
    "tus.io protocol": "standardized resumable upload protocol specification",
    "storage backend abstraction": "interface allowing multiple storage systems behind common API",
    "chunk assembly": "process of combining uploaded chunks into final complete file",
    "state machine": "structured representation of session lifecycle with valid transitions",
    "multipart upload": "large file upload split into multiple parts",
    "credential provider": "source of authentication information for storage backends",
    "atomic operations": "file operations that complete entirely or not at all",
    "signed URL": "time-limited URL for secure access to stored files",
    "magic byte detection": "file type identification using binary signatures at file beginning",
    "virus scanning": "malware detection using signature-based analysis",
    "quarantine storage": "isolated storage for suspicious or infected files",
    "resource protection": "defense against denial-of-service through resource exhaustion",
    "forensic metadata": "detailed context information preserved for security investigations",
    "content-type validation": "verification of actual file type against declared MIME type",
    "policy enforcement": "application of configurable security rules and restrictions",
    "adaptive limits": "dynamic resource limits that adjust based on system load",
    "circuit breaker pattern": "failure isolation mechanism preventing cascading failures",
    "error propagation": "systematic handling and communication of failures between components",
    "component interactions": "structured communication patterns between system components",
    "message formats": "standardized data structures for inter-component communication",
    "flow coordination": "orchestration of multi-component operations",
    "cascading failure prevention": "techniques to prevent component failures from spreading system-wide",
    "resource exhaustion": "depletion of system resources like memory, disk space, or file descriptors",
    "graceful degradation": "reducing service functionality while maintaining core operations",
    "adaptive rate limiting": "dynamic rate limits that adjust based on system capacity",
    "corruption detection": "verification of data integrity through checksums and validation",
    "recovery coordination": "orchestrated restoration of service after failures",
    "bulkhead pattern": "isolation of resources to prevent failure propagation",
    "load shedding": "temporary reduction of system load to prevent overload",
    "protocol compliance": "adherence to tus.io specification requirements",
    "fault injection": "deliberate introduction of failures for testing resilience",
    "milestone validation": "progressive testing goals with clear success criteria",
    "performance baseline": "established metrics for acceptable system performance",
    "systematic troubleshooting": "structured approach to diagnosing and resolving upload service issues",
    "state synchronization failure": "mismatch between client state, server state, and storage backend state",
    "distributed tracing": "following upload operations across all system components",
    "chaos engineering": "controlled failure injection to verify system resilience",
    "parallel upload acceleration": "concurrent chunk processing for improved throughput",
    "bandwidth optimization": "techniques to reduce network usage and improve transfer efficiency",
    "content deduplication": "hash-based elimination of redundant chunk storage",
    "client-side encryption": "file encryption performed by client before upload",
    "metadata extraction": "automated analysis and indexing of file content",
    "ML-enhanced virus scanning": "machine learning augmented threat detection",
    "CDN integration": "content distribution network coordination for global access",
    "horizontal scaling": "multi-instance deployment with coordinated operation",
    "distributed state management": "session state coordination across multiple service instances",
    "service discovery": "dynamic instance registration and health monitoring",
    "session affinity": "binding uploads to specific service instances",
    "data partitioning": "distribution of session data across multiple storage systems",
    "sharding": "horizontal partitioning of data for scalability",
    "extension registry": "management system for optional advanced features",
    "compression coordination": "management of file compression during upload process",
    "encryption coordination": "management of file encryption during upload process",
    "adaptive chunk sizing": "dynamic optimization of chunk size based on network conditions",
    "deduplication index": "mapping of content hashes to storage locations",
    "reference counting": "tracking usage of deduplicated chunks for cleanup",
    "ML threat analyzer": "machine learning based malware detection system",
    "CDN coordinator": "manager for content distribution network integration",
    "scaling coordinator": "manager for multi-instance deployment coordination",
    "distributed state store": "session state management across multiple instances",
    "session migration": "transfer of active uploads between service instances",
    "load balancing coordinator": "manager for request distribution across instances",
    "service registry": "authoritative list of available service instances",
    "health reporter": "system for reporting instance status and metrics"
  }
}