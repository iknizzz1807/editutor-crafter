{
  "types": {
    "Job": "fields: ID string, Name string, CronExpression string, Priority int, Payload map[string]string, IdempotencyKey string, State JobState, WorkerID string, FencingToken string, ScheduledAt time.Time, ClaimedAt *time.Time, CompletedAt *time.Time, RetryCount int, MaxRetries int, CreatedAt time.Time, UpdatedAt time.Time",
    "Worker": "fields: ID string, Address string, Capacity int, CurrentJobs int, Capabilities []string, LastHeartbeat time.Time, State WorkerState, StartedAt time.Time, Metadata map[string]string",
    "Coordinator": "scheduler node responsible for job assignment and worker coordination",
    "CronExpression": "fields: Original string, Minutes []int, Hours []int, DaysOfMonth []int, Months []int, DaysOfWeek []int, Timezone *time.Location",
    "JobState": "enum for job execution state",
    "WorkerState": "enum for worker operational state",
    "Storage": "interface for data persistence",
    "ParseResult": "fields: Expression *CronExpression, Errors []ParseError, Warnings []string",
    "ParseError": "fields: Field string, Value string, Position int, Message string",
    "PriorityQueue": "interface for priority-based job queue",
    "DeduplicationChecker": "handles job duplicate detection",
    "JobHeap": "implements heap.Interface for priority-ordered jobs",
    "QueueConfig": "holds priority queue configuration",
    "RedisConfig": "holds Redis connection configuration",
    "HeartbeatMessage": "worker heartbeat data structure",
    "ETCDConfig": "etcd connection configuration",
    "CoordinatorConfig": "coordinator configuration",
    "WorkerConfig": "worker configuration",
    "JobAssignmentMessage": "complete job assignment with execution context",
    "MessageTransport": "abstraction for reliable message delivery",
    "JobProgress": "execution progress information",
    "ResourceMetrics": "worker resource utilization data",
    "ExecutionFlowCoordinator": "orchestrates end-to-end job execution",
    "RetryConfig": "fields: InitialDelay time.Duration, BackoffFactor float64, MaxDelay time.Duration, MaxAttempts int, JitterPercent float64",
    "RetryableError": "fields: Err error, Temporary bool, Backoff time.Duration",
    "CircuitBreaker": "fields: state CircuitState, failures int, lastFailure time.Time, config CircuitConfig",
    "CircuitState": "enum for circuit breaker states",
    "CircuitConfig": "fields: FailureThreshold int, RecoveryTimeout time.Duration, TestRequests int",
    "DeadLetterQueue": "fields: storage Storage, maxAge time.Duration, maxEntries int",
    "DeadLetterEntry": "fields: ID string, OriginalOp string, FailureReason string, Context map[string]string, RetryHistory []RetryAttempt, CreatedAt time.Time, RequiresManual bool",
    "RetryAttempt": "fields: Timestamp time.Time, Error string, Duration time.Duration",
    "FencingManager": "manages fencing token validation",
    "FailureDetector": "monitors worker health and detects failures",
    "JobRecovery": "handles job reassignment during failures",
    "TestHarness": "fields: t *testing.T, redis *miniredis.Miniredis, etcd *embed.Etcd, cleanup []func(), timeCtrl *TimeController",
    "TimeController": "fields: currentTime time.Time, callbacks []func(time.Time)",
    "CorrelatedLogger": "fields: logger *slog.Logger, component string, nodeID string",
    "SchedulerMetrics": "fields: JobSubmissionRate *prometheus.CounterVec, JobCompletionLatency *prometheus.HistogramVec, JobFailureRate *prometheus.CounterVec, JobQueueDepth *prometheus.GaugeVec, ActiveWorkerCount prometheus.Gauge, HeartbeatLatency *prometheus.HistogramVec, LeaderElectionCount prometheus.Counter, JobAssignmentLatency prometheus.Histogram, DeduplicationHitRate *prometheus.CounterVec, DelayedPromotionLag prometheus.Histogram, QueueOperationLatency *prometheus.HistogramVec, CoordinationServiceLatency *prometheus.HistogramVec, NetworkPartitionCount prometheus.Counter, MemoryUsage prometheus.Gauge",
    "DiagnosticCollector": "fields: component string, nodeID string, startTime time.Time",
    "SystemDiagnostics": "fields: Component string, NodeID string, Timestamp time.Time, Uptime time.Duration, MemoryStats runtime.MemStats, GoRoutines int, SystemInfo SystemInfo, CustomState map[string]interface{}",
    "SystemInfo": "fields: GoVersion string, OS string, Arch string, CPUs int",
    "DebugHandler": "fields: collector *DiagnosticCollector, stateProvider func() map[string]interface{}",
    "LogAnalyzer": "fields: correlationIndex map[string][]LogEntry, timeIndex []LogEntry",
    "LogEntry": "fields: Timestamp time.Time, Component string, NodeID string, CorrelationID string, Level string, Operation string, JobID string, WorkerID string, Message string, Attributes map[string]interface{}",
    "FailurePattern": "fields: FailureType string, RootCause string, ComponentPath []string, Duration time.Duration, Symptoms []string, Recommendation string",
    "ContextKey": "string-based context key type",
    "JobDependency": "fields: JobID string, JobName string, RequiredState JobState, DataPassing map[string]string, TimeoutAction TimeoutAction",
    "ResourceLimits": "fields: MaxMemoryMB int64, MaxCPUCores float64, MaxStorageGB int64",
    "ResourceAllocation": "fields: AllocatedMemoryMB int64, AllocatedCPUCores float64, AllocatedStorageGB int64, JobID string",
    "AffinityRule": "fields: RuleType AffinityRuleType, Key string, Values []string, Weight int",
    "WorkflowStep": "fields: StepID string, StepType StepType, JobTemplate *Job, Condition string, ParallelBranches [][]WorkflowStep, LoopCondition string, WaitDuration time.Duration, OnSuccess []string, OnFailure []string, RetryPolicy StepRetryPolicy",
    "AuditChange": "fields: Field string, OldValue string, NewValue string"
  },
  "methods": {
    "heartbeat()": "worker sends liveness signal to coordinator",
    "claimJob()": "atomic job assignment to worker with lease",
    "reportCompletion()": "worker reports job execution result with fencing token",
    "NewJob()": "creates job with validation",
    "ClaimForWorker()": "atomically assigns job to worker",
    "MarkExecuting()": "transitions job to executing state",
    "ReportCompletion()": "handles completion or failure",
    "NewWorker()": "creates worker with validation",
    "UpdateHeartbeat()": "records heartbeat and updates state",
    "IsHealthy()": "checks if worker is responsive",
    "CanAcceptJob()": "checks worker availability and capabilities",
    "ParseCronExpression()": "parses cron string into structured format",
    "NextExecutionTime()": "calculates next valid execution time",
    "ParseCronExpression(expr string) (*CronExpression, error)": "parses cron expression string into structured format",
    "NextExecutionTime(after time.Time) (time.Time, error)": "calculates next execution time after given timestamp",
    "parseField(field string, min int, max int) ([]int, error)": "parses single cron field into expanded integer list",
    "matchesConstraints(t time.Time) bool": "checks if timestamp satisfies all field constraints",
    "parseTimezone(expr string) (*time.Location, string, error)": "extracts timezone from cron expression",
    "convertToTimezone(utc time.Time, tz *time.Location) time.Time": "converts UTC to specified timezone",
    "convertToUTC(local time.Time) time.Time": "converts local time to UTC",
    "SubmitJob(ctx context.Context, job *Job) (*Job, error)": "adds job to queue with deduplication check",
    "ClaimJob(ctx context.Context, workerID string) (*Job, error)": "atomically assigns highest priority job to worker",
    "CompleteJob(ctx context.Context, jobID string, result map[string]string) error": "marks job as successfully completed",
    "FailJob(ctx context.Context, jobID string, reason string) error": "marks job as failed and handles retry logic",
    "PromoteDelayedJobs(ctx context.Context) (int, error)": "moves eligible delayed jobs to active queue",
    "CheckDuplicate(ctx context.Context, job *Job) (*Job, bool, error)": "performs comprehensive deduplication check",
    "computeContentHash(job *Job) string": "creates deterministic hash of job content",
    "Less(i, j int) bool": "compares two jobs for priority ordering",
    "NewJobHeap() *JobHeap": "creates initialized job heap",
    "heartbeat() error": "worker sends liveness signal to coordinator",
    "claimJob() (*Job, error)": "atomic job assignment to worker with lease",
    "reportCompletion() error": "worker reports job execution result with fencing token",
    "CanAcceptJob(capabilities []string) bool": "checks worker availability and capabilities",
    "UpdateHeartbeat(timestamp time.Time, status string) error": "records heartbeat and updates worker state",
    "IsHealthy(timeout time.Duration) bool": "checks if worker is responsive",
    "ProcessWorkerHeartbeat(*HeartbeatMessage) error": "handles incoming heartbeat from worker",
    "RecoverJobsFromWorker(workerID string) error": "handles job recovery when specific worker fails",
    "ValidateFencingToken(jobID, workerID, token string) (bool, error)": "checks worker authority for job operations",
    "GetCurrentJobCount() int": "returns number of jobs currently executing",
    "IsLeader() bool": "returns current leadership status",
    "GetFencingToken() int64": "returns current fencing token for job assignments",
    "ProcessHeartbeat(*HeartbeatMessage) error": "handles incoming heartbeat from worker",
    "AssignJobToWorker(workerID string) error": "coordinates job assignment to specific worker",
    "SendMessage(target string, message Message) error": "reliable message transmission",
    "Type() MessageType": "returns message type identifier",
    "Target() string": "returns message destination",
    "Payload() []byte": "returns serialized message content",
    "Validate() error": "validates message format and content",
    "RetryWithBackoff(ctx context.Context, config RetryConfig, operation func() error) error": "executes operation with exponential backoff retry logic",
    "IsRetryable(err error) bool": "returns true if error should be retried",
    "Execute(ctx context.Context, operation func() error) error": "runs operation with circuit breaker protection",
    "Add(ctx context.Context, entry *DeadLetterEntry) error": "stores failed operation for later resolution",
    "ValidateFencingToken(ctx context.Context, tokenType string, token int64) error": "checks if operation token is current and valid",
    "DetectWorkerFailure(ctx context.Context, workerID string) error": "monitors heartbeats and detects failed workers",
    "RecoverJobsFromFailedWorker(ctx context.Context, workerID string, reason string) error": "reassigns jobs when worker becomes unavailable",
    "NewTestHarness(t *testing.T) *TestHarness": "creates complete testing environment",
    "Now() time.Time": "returns current controlled time",
    "Advance(duration time.Duration)": "advances controlled time",
    "Cleanup()": "releases all test resources",
    "NewCorrelatedLogger(component, nodeID string) *CorrelatedLogger": "creates structured logger with component identification",
    "WithContext(ctx context.Context) *slog.Logger": "extracts correlation ID from context and adds to log entry",
    "JobOperation(ctx context.Context, level slog.Level, operation string, jobID string, attrs ...slog.Attr)": "logs job-related operations with standardized fields",
    "WorkerOperation(ctx context.Context, level slog.Level, operation string, workerID string, attrs ...slog.Attr)": "logs worker-related operations with standardized fields",
    "CoordinationOperation(ctx context.Context, level slog.Level, operation string, attrs ...slog.Attr)": "logs coordination protocol events",
    "NewSchedulerMetrics(component string) *SchedulerMetrics": "creates and registers all scheduler metrics with Prometheus",
    "RecordJobSubmission(component, priority, jobType string)": "records job submission event with priority and type labels",
    "RecordJobCompletion(component, priority string, duration time.Duration, success bool)": "records job completion timing with success indicator",
    "RecordJobFailure(component, failureType string, retriable bool)": "records job failure with categorization",
    "UpdateQueueDepth(component, priority, state string, depth float64)": "updates current queue depth for specific priority level",
    "RecordHeartbeat(component, workerID string, latency time.Duration, success bool)": "records worker heartbeat timing and success",
    "NewDiagnosticCollector(component, nodeID string) *DiagnosticCollector": "creates diagnostic collector for specified component",
    "CollectDiagnostics(customState map[string]interface{}) *SystemDiagnostics": "gathers comprehensive system diagnostic information",
    "NewDebugHandler(collector *DiagnosticCollector, stateProvider func() map[string]interface{}) *DebugHandler": "creates HTTP handler for debug endpoints",
    "ServeHTTP(w http.ResponseWriter, r *http.Request)": "handles diagnostic information requests",
    "NewLogAnalyzer() *LogAnalyzer": "creates log analysis utility with indexing capability",
    "ParseLogLine(line string) error": "parses structured JSON log entry and adds to indexes",
    "GetCorrelatedEntries(correlationID string) []LogEntry": "retrieves all log entries for specific correlation ID",
    "AnalyzeFailurePattern(entries []LogEntry) FailurePattern": "identifies common failure patterns in log sequences"
  },
  "constants": {
    "PENDING": "job state before worker assignment",
    "CLAIMED": "job state after worker assignment",
    "EXECUTING": "job state during processing",
    "COMPLETED": "job state after successful execution",
    "FAILED": "job state after all retries exhausted",
    "AVAILABLE": "worker ready to accept jobs",
    "BUSY": "worker at capacity",
    "UNAVAILABLE": "worker failed or shutdown",
    "MessageTypeHeartbeat": "heartbeat message type identifier",
    "MessageTypeJobAssignment": "job assignment message type identifier",
    "MessageTypeJobCompletion": "completion report message type identifier",
    "CircuitClosed": "circuit breaker closed state",
    "CircuitOpen": "circuit breaker open state",
    "CircuitHalfOpen": "circuit breaker half-open state",
    "CorrelationIDKey": "context key for correlation ID values"
  },
  "terms": {
    "exactly-once execution": "guarantee each job runs precisely once",
    "fencing token": "unique identifier preventing stale worker reports",
    "leader election": "process of selecting single coordinator node",
    "split-brain": "multiple coordinators thinking they are leader",
    "idempotency key": "client-provided identifier preventing duplicates",
    "at-least-once execution": "jobs may run multiple times but never lost",
    "deduplication": "preventing duplicate job submissions",
    "priority queue": "data structure that serves highest-priority jobs first",
    "delayed execution": "jobs that become eligible for execution at a future time",
    "worker coordination": "managing job distribution across workers",
    "heartbeat": "periodic liveness signal from worker",
    "fault tolerance": "continued operation despite failures",
    "cron expression": "time-based job scheduler pattern using five or six fields",
    "field constraint": "individual time component filter in cron expression",
    "timezone normalization": "converting all timestamps to UTC for consistent storage",
    "daylight saving time": "seasonal time adjustment creating temporal anomalies",
    "next execution time": "future timestamp when cron job should run",
    "calendar arithmetic": "mathematical operations involving dates and time periods",
    "pattern matching": "checking if current time satisfies cron expression constraints",
    "range expansion": "converting cron syntax like 1-5 to explicit value lists",
    "DST transition": "change between standard and daylight saving time",
    "UTC normalization": "storing all absolute times in coordinated universal time",
    "visibility timeout pattern": "jobs exist but remain invisible until scheduled time",
    "content hash": "deterministic hash of normalized job payload",
    "atomic operations": "operations completing entirely or not at all",
    "priority inversion": "high-priority work blocked by lower-priority tasks",
    "hash collision": "different inputs producing same hash value",
    "graceful shutdown": "completing current work before stopping",
    "capability matching": "ensuring workers can handle required job types",
    "message amplification": "excessive message retries during network issues",
    "coordination messages": "system control and status messages",
    "job assignment flow": "process of distributing work to workers",
    "execution monitoring": "tracking job progress and worker health",
    "exponential backoff": "progressive delay increase between retry attempts",
    "circuit breaker": "prevents cascade failures during sustained error conditions",
    "dead letter queue": "repository for operations that failed all retry attempts",
    "retry amplification": "multiple components retrying simultaneously create load spikes",
    "thundering herd": "multiple workers retry simultaneously after shared dependency recovers",
    "graduated failure detection": "escalating response based on failure duration",
    "jitter": "random variation in retry delays to prevent synchronization",
    "idempotency": "executing operation multiple times produces same result as once",
    "network partition": "network failure creating zones of connectivity",
    "unit testing": "testing individual components in isolation",
    "integration testing": "testing component interactions under realistic conditions",
    "milestone checkpoints": "structured validation points at each development stage",
    "failure injection": "systematic introduction of failures to test resilience",
    "end-to-end testing": "complete system validation from input to output",
    "race conditions": "timing-dependent bugs in concurrent code",
    "deterministic testing": "predictable test behavior through controlled environments",
    "test harness": "infrastructure providing consistent test environments",
    "structured logging": "logging with consistent data formats enabling programmatic analysis",
    "correlation ID": "unique identifier linking related operations across distributed system boundaries",
    "distributed tracing": "technique for tracking request flow across multiple service boundaries",
    "metrics collection": "systematic gathering of quantitative system performance data",
    "log aggregation": "centralized collection and indexing of log entries from multiple sources",
    "failure pattern analysis": "systematic identification of common failure sequences in distributed systems",
    "diagnostic endpoint": "HTTP endpoint providing system health and debug information",
    "trace correlation": "linking distributed trace spans to reconstruct complete operation flows",
    "time series metrics": "metrics collected and stored with timestamp information for trend analysis",
    "observability": "ability to understand system internal state through external outputs",
    "instrumentation": "code modifications to emit debugging and monitoring information",
    "alert threshold": "metric value boundary triggering automated notifications",
    "log parsing": "extraction of structured information from text-based log entries",
    "metric cardinality": "number of unique label combinations in time series metrics",
    "trace sampling": "selective collection of traces to balance information completeness with performance",
    "job dependencies": "prerequisite jobs that must complete before execution",
    "resource-aware scheduling": "job assignment considering memory, CPU, and resource constraints",
    "workflow orchestration": "coordinated execution of multi-job workflows with conditional logic",
    "horizontal sharding": "distributing jobs across multiple independent scheduler clusters",
    "multi-datacenter deployment": "scheduler operation across multiple geographic regions",
    "audit logging": "detailed trail of administrative actions and system events",
    "performance optimization": "enhancements to reduce latency and increase throughput",
    "consensus algorithms": "distributed protocols for agreement despite failures",
    "distributed locking": "mechanisms ensuring exclusive resource access across network",
    "failure detection": "mechanisms for identifying when components stop functioning",
    "job recovery": "reassigning jobs from failed workers to healthy workers"
  }
}