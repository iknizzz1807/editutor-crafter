direction: down

title: System Component Architecture {
  near: top-center
  style.font-size: 20
  style.bold: true
  style.font-color: "#e6edf3"
}

classes: {
  container: {
    style.fill: "#1a1a2e"
    style.stroke: "#3fb950"
    style.font-color: "#e6edf3"
    style.stroke-width: 2
  }
  component: {
    style.fill: "#16213e"
    style.stroke: "#3fb950"
    style.font-color: "#e6edf3"
    style.bold: true
  }
  data_flow: {
    style.stroke: "#8b949e"
    style.stroke-width: 2
  }
  critical_flow: {
    style.stroke: "#3fb950"
    style.stroke-width: 3
    style.bold: true
  }
}

source_text: Source Text {
  shape: page
  class: component
}

tokenizer: Tokenizer {
  shape: rectangle
  class: container
  
  lexer: Lexical Analyzer {
    class: component
  }
  token_stream: Token Stream {
    class: component
  }
}

tokens: Tokens {
  shape: cylinder
  class: component
}

parser: Parser {
  shape: rectangle
  class: container
  
  syntax_analyzer: Syntax Analyzer {
    class: component
  }
  ast_builder: AST Builder {
    class: component
  }
}

ast: Abstract Syntax Tree {
  shape: cylinder
  class: component
}

evaluator: Evaluator {
  shape: rectangle
  class: container
  
  expression_eval: Expression Evaluator {
    class: component
  }
  special_forms: Special Forms Handler {
    class: component
  }
  
  environment: Environment {
    shape: rectangle
    class: container
    
    symbol_table: Symbol Table {
      class: component
    }
    scope_chain: Scope Chain {
      class: component
    }
  }
  
  function_system: Function System {
    shape: rectangle
    class: container
    
    builtin_functions: Built-in Functions {
      class: component
    }
    user_functions: User Functions {
      class: component
    }
    closures: Closures {
      class: component
    }
  }
}

results: Final Results {
  shape: page
  class: component
}

# Main data flow
source_text -> tokenizer: Raw text {
  class: critical_flow
}

tokenizer -> tokens: Character stream {
  class: data_flow
}

tokens -> parser: Token sequence {
  class: critical_flow
}

parser -> ast: Parsed tokens {
  class: data_flow
}

ast -> evaluator: S-expressions {
  class: critical_flow
}

evaluator -> results: Computed values {
  class: critical_flow
}

# Internal tokenizer flow
tokenizer.lexer -> tokenizer.token_stream: Characters {
  class: data_flow
}

# Internal parser flow
parser.syntax_analyzer -> parser.ast_builder: Syntax tree {
  class: data_flow
}

# Internal evaluator interactions
evaluator.expression_eval -> evaluator.environment: Variable lookups {
  class: data_flow
}

evaluator.special_forms -> evaluator.environment: Scope management {
  class: data_flow
}

evaluator.expression_eval -> evaluator.function_system: Function calls {
  class: data_flow
}

evaluator.function_system -> evaluator.environment: Closure creation {
  class: data_flow
}

# Environment internal flow
evaluator.environment.symbol_table <-> evaluator.environment.scope_chain: Binding resolution {
  class: data_flow
}

# Function system internal flow
evaluator.function_system.builtin_functions -> evaluator.function_system.closures: Built-in wrapping {
  class: data_flow
}

evaluator.function_system.user_functions -> evaluator.function_system.closures: User function wrapping {
  class: data_flow
}