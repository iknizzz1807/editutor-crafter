{
  "types": {
    "MemoryMonitor": "baseline_gpu_memory Optional[int], baseline_system_memory int, measurements List[Dict]",
    "QuantizationConfig": "load_in_4bit bool, bnb_4bit_quant_type str, bnb_4bit_compute_dtype str, bnb_4bit_use_double_quant bool, bnb_4bit_quant_storage str",
    "LoRAConfig": "r int, alpha int, dropout float, target_modules Optional[List[str]], bias str, task_type str, lora_alpha_scaling bool, init_lora_weights Union[bool str]",
    "TrainingConfig": "model_name_or_path str, quantization QuantizationConfig, lora LoRAConfig, learning_rate float, num_train_epochs int",
    "FineTuningPipeline": "config TrainingConfig, memory_monitor MemoryMonitor, tokenizer Optional, model Optional",
    "ConversationSample": "conversation_id str, turns List[ConversationTurn], metadata Dict[str Any], total_tokens Optional[int], is_valid bool",
    "ConversationTurn": "role str, content str, turn_index int",
    "InstructionSample": "instruction str, response str, system_prompt Optional[str], input_context Optional[str], sample_id str, source str, quality_score Optional[float]",
    "TokenizedSample": "input_ids List[int], attention_mask List[int], labels List[int], prompt_length int, response_length int, total_length int",
    "TrainingMetrics": "step int, epoch float, loss float, learning_rate float, grad_norm Optional[float], timestamp float, gpu_memory_used Optional[float], samples_per_second float",
    "EvaluationMetrics": "eval_step int, eval_loss float, perplexity float, bleu_score Optional[float], rouge_scores Optional[Dict[str float]], exact_match Optional[float], eval_samples int, eval_runtime float, eval_samples_per_second float, timestamp float",
    "CheckpointMetadata": "checkpoint_path str, step int, epoch float, eval_loss Optional[float], is_best bool, model_config Dict[str Any], adapter_config Dict[str Any], optimizer_state_size int, save_timestamp float",
    "MemoryMetrics": "stage str, gpu_memory_allocated float, gpu_memory_cached float, gpu_memory_reserved float, system_memory_used float, timestamp float, details Optional[Dict[str Any]]",
    "QualityFilterStats": "fields: total_samples int, duplicates_removed int, length_filtered int, quality_filtered int, final_count int",
    "AdapterMetrics": "total_base_params int, total_adapter_params int, trainable_ratio float, memory_overhead_mb float, target_modules_count int, effective_rank_utilization Dict[str float], gradient_statistics Dict[str Dict[str float]]",
    "TargetModuleDetector": "model PreTrainedModel, architecture str",
    "AdapterManager": "base_model PreTrainedModel, lora_config LoRAConfig, peft_model Optional",
    "ParameterAnalyzer": "model PreTrainedModel, base_param_count Optional[int], adapter_param_count Optional[int]",
    "RankSelector": "model PreTrainedModel, available_memory float, model_size float",
    "PerplexityResult": "overall_perplexity float, prompt_perplexity float, response_perplexity float, token_count int, prompt_token_count int, response_token_count int, loss_values List[float]",
    "PerplexityCalculator": "model: PreTrainedModel, tokenizer: PreTrainedTokenizer",
    "TaskSpecificEvaluator": "model: PreTrainedModel, tokenizer: PreTrainedTokenizer, baseline_model: Optional[PreTrainedModel]",
    "ModelComparator": "fine_tuned_model: PreTrainedModel, baseline_model: PreTrainedModel, tokenizer: PreTrainedTokenizer",
    "AdapterMerger": "peft_model: PeftModel, base_model: PreTrainedModel",
    "ModelExporter": "model: PreTrainedModel, tokenizer: PreTrainedTokenizer",
    "PipelineState": "Enum with pipeline execution phases",
    "StateSnapshot": "state PipelineState, timestamp datetime, metrics Dict, metadata Dict",
    "StateManager": "Thread-safe coordination of pipeline state",
    "TrainingStabilityMonitor": "gradient_clip_norm float, loss_spike_threshold float, gradient_history deque, loss_history deque",
    "CheckpointManager": "checkpoint_dir Path, max_checkpoints int",
    "ErrorCategory": "Enum with error classification types",
    "ErrorContext": "category ErrorCategory, message str, stack_trace str, system_state Dict[str Any], recovery_actions List[str], timestamp float",
    "DistributedTrainingConfig": "fields: world_size int, local_rank int, backend str, gradient_compression bool, sync_frequency int",
    "MultiGPUTrainer": "base_trainer TrainingConfig, distributed_config DistributedTrainingConfig",
    "AdapterInterface": "abstract base class for adapter implementations",
    "AdaLoRAAdapter": "initial_rank int, target_rank int, rank_allocation_steps int",
    "DoRAAdapter": "rank int, magnitude_lr_scale float",
    "AdapterFactory": "class registry for adapter implementations",
    "EvaluationInterface": "abstract base class for evaluation methods",
    "SafetyEvaluator": "safety_datasets Dict, bias_detector Optional, toxicity_classifier Optional",
    "HumanEvaluator": "evaluation_platform str, num_raters int, calibration_results Dict",
    "ModelJudgeEvaluator": "judge_models List[str], evaluation_criteria Dict, loaded_judges Dict",
    "ComprehensiveEvaluationSuite": "evaluators List[EvaluationInterface], evaluation_results Dict"
  },
  "methods": {
    "capture_baseline() -> None": "record initial memory state before model loading",
    "measure_current_usage(stage: str) -> Dict[str, float]": "measure current memory and return usage statistics",
    "get_peak_usage() -> Dict[str, float]": "return peak memory usage across all measurements",
    "load_config_from_yaml(config_path: Path) -> TrainingConfig": "load and validate configuration from YAML file",
    "setup_model_and_tokenizer() -> None": "load quantized model and configure tokenizer",
    "setup_lora_adapters() -> None": "inject LoRA adapters into frozen base model",
    "prepare_datasets() -> None": "load and preprocess training data",
    "execute_training() -> str": "run training loop and return best checkpoint path",
    "evaluate_and_merge(checkpoint_path: str) -> Dict[str, Any]": "evaluate model and merge adapters",
    "run_complete_pipeline() -> Dict[str, Any]": "execute full pipeline from data to deployment",
    "effective_alpha() -> float": "calculate effective alpha scaling factor",
    "effective_batch_size() -> int": "calculate effective training batch size accounting for gradient accumulation",
    "apply_template(sample: InstructionSample) -> str": "applies chat template to instruction-response pair",
    "tokenize_sample(sample: InstructionSample) -> TokenizedSample": "converts formatted text to tokenized training sample",
    "split_dataset(samples, stratify_by) -> Tuple": "partitions dataset into train and validation sets",
    "filter_dataset(samples) -> Tuple": "applies quality filtering and returns filtered samples with stats",
    "load_data(file_path) -> Iterator": "loads data from file with format auto-detection",
    "format_sample(raw_data) -> InstructionSample": "converts raw dictionary to standardized InstructionSample",
    "from_task_complexity(complexity: str, available_memory_gb: float) -> LoRAConfig": "create LoRA config based on task complexity and memory constraints",
    "to_peft_config() -> Dict[str, Any]": "convert to PEFT library configuration format",
    "detect_attention_modules() -> List[str]": "find all attention projection modules",
    "detect_mlp_modules() -> List[str]": "find all MLP/feed-forward modules",
    "get_recommended_targets() -> List[str]": "get recommended target modules based on strategy",
    "analyze_module_dimensions() -> Dict[str, Dict[str, int]]": "analyze dimensions of target modules for rank planning",
    "inject_adapters() -> PreTrainedModel": "inject LoRA adapters into the base model",
    "freeze_base_parameters() -> None": "ensure base model parameters are frozen",
    "get_adapter_state_dict() -> Dict[str, torch.Tensor]": "extract only the adapter parameters",
    "merge_and_unload() -> PreTrainedModel": "merge adapter weights into base model and return standalone model",
    "estimate_memory_usage() -> Dict[str, float]": "estimate memory usage for adapters in MB",
    "analyze_parameter_distribution() -> Dict[str, Dict[str, int]]": "analyze distribution of trainable vs frozen parameters",
    "calculate_efficiency_metrics() -> Dict[str, float]": "calculate parameter efficiency metrics",
    "analyze_gradient_statistics() -> Dict[str, Dict[str, float]]": "analyze gradient statistics for adapter parameters",
    "estimate_effective_rank() -> Dict[str, float]": "estimate the effective rank utilization of adapters",
    "generate_efficiency_report() -> str": "generate a comprehensive efficiency analysis report",
    "recommend_rank_for_task() -> Tuple[int, int]": "recommend rank and alpha for a specific task",
    "analyze_memory_constraints() -> Dict[str, float]": "analyze memory requirements for given rank and targets",
    "find_optimal_rank() -> Tuple[int, int, Dict[str, float]]": "find optimal rank within memory constraints",
    "validate_configuration() -> bool": "validate that a rank/alpha configuration is feasible",
    "to_bitsandbytes_config() -> Dict[str, Any]": "convert to bitsandbytes BitsAndBytesConfig format",
    "estimate_memory_reduction(base_model_params: int) -> Dict[str, float]": "estimate memory savings from quantization",
    "from_model_size(model_size_gb: float, available_memory_gb: float) -> QuantizationConfig": "create optimized config based on model size and available memory",
    "train() -> str": "execute complete training loop and return best checkpoint path",
    "_train_epoch() -> float": "train for one complete epoch with gradient accumulation",
    "_train_step(batch) -> float": "execute one training step with gradient accumulation",
    "_evaluate() -> EvaluationMetrics": "run evaluation on validation dataset",
    "_save_checkpoint(eval_loss: float) -> CheckpointMetadata": "save training checkpoint with current state",
    "_should_evaluate(epoch: int) -> bool": "determine if evaluation should be performed",
    "_should_stop_early() -> bool": "check if early stopping conditions are met",
    "calculate_perplexity(samples: List[TokenizedSample]) -> PerplexityResult": "calculate perplexity across tokenized samples with prompt/response separation",
    "_compute_batch_loss(batch: Dict[str, torch.Tensor]) -> Tuple[float, float, int, int]": "compute loss for single batch with component separation",
    "evaluate_instruction_following(samples: List[InstructionSample], max_new_tokens: int) -> Dict[str, float]": "evaluate instruction following with multiple metrics",
    "_generate_response(instruction: str, model: PreTrainedModel) -> str": "generate single response using specified model",
    "run_comparative_evaluation(eval_samples: List[InstructionSample]) -> Dict[str, Any]": "comprehensive comparison between fine-tuned and baseline models",
    "merge_adapters(verification: bool) -> PreTrainedModel": "merge LoRA adapters into base model with optional verification",
    "_merge_module_weights(module_name: str, base_weight: torch.Tensor, lora_A: torch.Tensor, lora_B: torch.Tensor, alpha: float, scaling: float) -> torch.Tensor": "merge LoRA matrices into base weight for single module",
    "verify_merger_equivalence(merged_model: PreTrainedModel, test_inputs: List[torch.Tensor]) -> bool": "verify merged model produces equivalent outputs",
    "export_huggingface(output_path: str, push_to_hub: bool) -> str": "export model in HuggingFace format",
    "export_gguf(output_path: str, quantization: str) -> str": "export model in GGUF format for llama.cpp",
    "validate_export_quality(exported_model_path: str, export_format: str) -> Dict[str, float]": "validate exported model maintains acceptable quality",
    "transition_to(new_state: PipelineState, metrics: Optional[Dict], metadata: Optional[Dict])": "thread-safe state transition with validation",
    "get_current_state() -> StateSnapshot": "get immutable snapshot of current pipeline state",
    "set_shared_data(key: str, value: Any)": "thread-safe storage of shared data across components",
    "get_shared_data(key: str, default: Any) -> Any": "thread-safe retrieval of shared data",
    "check_gradient_stability(model) -> Dict[str, Any]": "monitor gradient norms and detect explosions",
    "handle_gradient_explosion(model, optimizer) -> bool": "handle detected gradient explosion with graduated intervention",
    "check_loss_stability(current_loss: float) -> Dict[str, Any]": "monitor loss values for spikes and degradation",
    "detect_nan_propagation(model, loss) -> bool": "detect NaN values in model parameters, gradients, or loss",
    "should_restore_checkpoint() -> bool": "determine if training instability requires checkpoint restoration",
    "save_checkpoint(model, optimizer, step, epoch, eval_loss, is_best) -> CheckpointMetadata": "save checkpoint with integrity verification",
    "load_checkpoint(checkpoint_path: str) -> Dict[str, Any]": "load checkpoint with integrity verification",
    "verify_checkpoint_integrity(checkpoint_path: str) -> bool": "verify checkpoint files are not corrupted",
    "find_latest_valid_checkpoint() -> Optional[str]": "find most recent checkpoint that passes integrity checks",
    "initialize_distributed() -> None": "set up distributed training environment",
    "synchronize_gradients(model) -> Dict[str, float]": "sync gradients across workers with compression",
    "distributed_evaluation(eval_dataset) -> Dict[str, Any]": "run distributed evaluation and aggregate results",
    "inject_adapters(model, config) -> nn.Module": "inject adapters into target model",
    "get_trainable_parameters() -> List[nn.Parameter]": "return trainable adapter parameters",
    "merge_adapters(model) -> nn.Module": "merge adapter weights into base model",
    "update_ranks(importance_scores) -> Dict[str, int]": "update adapter ranks based on importance",
    "create_adapter(adapter_type, **kwargs) -> AdapterInterface": "create adapter instance of specified type",
    "register_adapter(name, adapter_class) -> None": "register new adapter implementation",
    "evaluate(model, dataset) -> Dict[str, Any]": "run evaluation and return metrics",
    "evaluate_bias(model, prompts) -> Dict[str, float]": "evaluate model bias across demographics",
    "calibrate_raters(calibration_set) -> Dict[str, float]": "calibrate human raters on known examples",
    "single_judge_evaluation(judge_model, response, criteria) -> Dict[str, Any]": "get evaluation from single judge model",
    "run_comprehensive_evaluation(model, eval_datasets) -> Dict[str, Any]": "run all evaluations and aggregate results"
  },
  "constants": {
    "NF4_QUANTIZATION": "4-bit NormalFloat quantization type",
    "DEFAULT_LORA_RANK": "16 - typical rank for LoRA decomposition",
    "DEFAULT_LORA_ALPHA": "32 - typical alpha scaling parameter",
    "MEMORY_BASELINE_STAGE": "initial memory measurement point",
    "ATTENTION_PATTERNS": "regex patterns for attention module detection",
    "MLP_PATTERNS": "regex patterns for MLP module detection",
    "TASK_COMPLEXITY_RANKS": "mapping of task types to recommended rank ranges",
    "DEFAULT_MAX_NEW_TOKENS": "512 - default maximum tokens for response generation",
    "PERPLEXITY_TOLERANCE": "1e-5 - numerical tolerance for perplexity calculations",
    "MERGE_VERIFICATION_TOLERANCE": "1e-5 - tolerance for merged model equivalence testing",
    "EXPORT_QUALITY_THRESHOLD": "0.05 - maximum acceptable quality degradation for exports",
    "UNINITIALIZED": "pipeline has not started",
    "DATA_PREPARATION": "loading and formatting training data",
    "MODEL_LOADING": "loading base model with quantization",
    "TRAINING": "executing fine-tuning loop",
    "EVALUATION": "assessing model performance",
    "EXPORT": "converting to deployment formats",
    "COMPLETED": "pipeline finished successfully",
    "FAILED": "pipeline encountered unrecoverable error",
    "DEFAULT_GRADIENT_CLIP_NORM": "1.0 - default gradient clipping threshold",
    "LOSS_SPIKE_THRESHOLD": "2.0 - multiplier for detecting loss spikes",
    "INSTABILITY_THRESHOLD": "3 - number of instabilities before checkpoint restore",
    "DEFAULT_WORLD_SIZE": "number of distributed workers",
    "DEFAULT_SYNC_FREQUENCY": "gradient synchronization interval",
    "COMPRESSION_THRESHOLD": "minimum tensor size for compression",
    "BIAS_EVALUATION_CATEGORIES": "protected characteristics for bias testing",
    "SAFETY_EVALUATION_DOMAINS": "domains for comprehensive safety assessment",
    "JUDGE_MODEL_NAMES": "default LLM judge models",
    "INTER_RATER_AGREEMENT_THRESHOLD": "minimum agreement for valid human evaluation"
  },
  "terms": {
    "parameter-efficient fine-tuning": "methods that adapt models using far fewer trainable parameters than full fine-tuning",
    "low-rank adaptation": "decomposing weight updates into smaller matrices",
    "quantization": "reducing numerical precision to save memory",
    "catastrophic forgetting": "loss of previous knowledge when learning new tasks",
    "memory wall problem": "GPU memory requirements exceeding available hardware capacity",
    "double quantization": "quantizing the quantization constants for additional memory savings",
    "gradient accumulation": "simulating larger batch sizes across multiple forward passes",
    "adapter merging": "combining learned LoRA weights with base model parameters into unified model",
    "causal language modeling": "predicting next tokens in sequence with attention masks",
    "chat template": "model-specific format for structuring conversational data with special tokens",
    "instruction tuning": "fine-tuning approach that teaches models to follow instructions and generate appropriate responses",
    "data leakage": "when validation data contains information that appears in training data",
    "subword tokenization": "text encoding that splits words into smaller meaningful units",
    "target modules": "specific model layers where LoRA adapters are applied",
    "rank": "dimensionality of the low-rank decomposition controlling adapter capacity",
    "alpha parameter": "scaling factor controlling the influence of adapter outputs",
    "adapter injection": "process of inserting LoRA matrices into frozen model layers",
    "effective rank": "actual rank utilization of learned adapter matrices",
    "trainable parameter ratio": "percentage of total parameters that receive gradient updates",
    "mixed-precision training": "balancing 4-bit storage with float16/bfloat16 computation",
    "NormalFloat quantization": "4-bit quantization optimized for neural network weight distributions",
    "learning rate scheduling": "systematic adjustment of learning rate throughout training",
    "checkpoint management": "saving and loading training state for recovery and resumption",
    "early stopping": "terminating training when validation performance stops improving",
    "warmup scheduling": "gradually increasing learning rate from zero to target value",
    "cosine decay": "smooth learning rate reduction following cosine curve",
    "validation loss": "model performance on held-out data for generalization assessment",
    "trainer orchestration": "coordinated management of training process components",
    "perplexity": "measure of model uncertainty when predicting validation tokens - lower values indicate better language modeling",
    "task-specific evaluation": "assessment of functional capabilities like instruction following rather than just statistical fit",
    "export format": "deployment-ready model serialization optimized for specific inference environments",
    "baseline comparison": "side-by-side evaluation against original base model to quantify improvement",
    "numerical precision loss": "accuracy degradation from floating-point operations during weight combination",
    "evaluation data leakage": "contamination where evaluation samples overlap with or derive from training data",
    "format compatibility": "ability of exported models to load and function correctly in target inference systems",
    "equivalence verification": "testing that merged models produce identical outputs to unmerged versions",
    "quality validation": "confirmation that format conversion preserves model performance within acceptable bounds",
    "pipeline orchestration": "coordinated execution of multiple components in sequence",
    "state coordination": "managing shared state and dependencies between components",
    "error propagation": "passing error information up through component hierarchy",
    "graceful degradation": "maintaining functionality under resource constraints",
    "dependency resolution": "determining proper initialization order for components",
    "memory pressure": "approaching GPU memory limits requiring resource management",
    "checkpoint metadata": "information about saved model state including performance metrics",
    "component isolation": "keeping components independent while enabling coordination",
    "state synchronization": "ensuring consistent state across concurrent operations",
    "recovery strategy": "planned approach for handling component failures",
    "gradient explosion": "sudden increase in gradient norms that can destabilize training",
    "checkpoint corruption": "data integrity issues in saved training state",
    "NaN propagation": "spread of Not-a-Number values through neural network computations",
    "thermal throttling": "automatic performance reduction due to overheating",
    "hardware failure detection": "monitoring systems for identifying equipment malfunctions",
    "training instability": "erratic behavior during fine-tuning including loss spikes and gradient issues",
    "performance profiling": "systematic measurement of computational bottlenecks and resource usage",
    "systematic debugging": "methodical approach to isolating and identifying root causes of failures",
    "distributed training": "training across multiple GPUs or nodes",
    "gradient synchronization": "coordinating gradient updates across workers",
    "data parallelism": "distributing data across workers with model replication",
    "model parallelism": "distributing model layers across different devices",
    "pipeline parallelism": "sequential processing of model layers across devices",
    "tensor parallelism": "splitting individual tensors across multiple devices",
    "adaptive rank allocation": "dynamically adjusting LoRA ranks based on importance",
    "magnitude-direction decomposition": "separating weight updates into scale and direction components",
    "importance scoring": "measuring relative contribution of adapter components",
    "rank pruning": "removing less important low-rank components",
    "human evaluation calibration": "training raters on standardized examples",
    "inter-rater reliability": "consistency of evaluations across human raters",
    "model-based evaluation": "using LLMs to assess other model outputs",
    "safety benchmarking": "systematic testing for harmful or biased behaviors",
    "bias evaluation": "measuring unfair treatment across demographic groups",
    "toxicity detection": "identifying harmful or offensive content generation",
    "prompt injection resistance": "robustness against adversarial input techniques",
    "evaluation aggregation": "combining scores across multiple assessment methods"
  }
}