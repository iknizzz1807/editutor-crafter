title: Memory Alignment and SIMD Register Layout {
  style.font-size: 20
  style.bold: true
  near: top-center
}

classes: {
  memory_block: {
    style.fill: "#1a1a2e"
    style.stroke: "#3fb950"
    style.font-color: "#e6edf3"
  }
  aligned_section: {
    style.fill: "#0f3460"
    style.stroke: "#3fb950"
    style.font-color: "#e6edf3"
    style.bold: true
  }
  unaligned_section: {
    style.fill: "#2d3748"
    style.stroke: "#8b949e"
    style.font-color: "#e6edf3"
  }
  register_type: {
    style.fill: "#16213e"
    style.stroke: "#f39c12"
    style.font-color: "#e6edf3"
    style.bold: true
  }
  boundary: {
    style.stroke: "#e74c3c"
    style.stroke-width: 3
    style.stroke-dash: 5
  }
}

memory_layout: Memory Layout {
  class: memory_block
  
  addr_0x00: "0x00" { class: aligned_section }
  addr_0x10: "0x10" { class: aligned_section }
  addr_0x20: "0x20" { class: aligned_section }
  addr_0x30: "0x30" { class: aligned_section }
  
  boundary_16: "16-byte boundary" { 
    shape: text
    class: boundary
  }
  
  prologue: Prologue Data {
    class: unaligned_section
    bytes: "3 bytes unaligned"
  }
  
  main_data: Main SIMD Data {
    class: aligned_section
    chunks: "32 bytes (2x 16-byte loads)"
  }
  
  epilogue: Epilogue Data {
    class: unaligned_section
    bytes: "5 bytes remaining"
  }
}

simd_registers: SIMD Register Loading {
  class: memory_block
  
  xmm0: XMM0 Register {
    class: register_type
    content: "16 bytes: [0][1][2]...[15]"
    instruction: "_mm_load_si128()"
  }
  
  xmm1: XMM1 Register {
    class: register_type
    content: "16 bytes: [16][17][18]...[31]"
    instruction: "_mm_load_si128()"
  }
  
  xmm_unaligned: XMM_TEMP Register {
    class: register_type
    content: "Unaligned data"
    instruction: "_mm_loadu_si128()"
  }
}

processing_flow: Processing Strategy {
  class: memory_block
  
  step1: "1. Handle Prologue" {
    class: unaligned_section
    detail: "Scalar ops until aligned"
  }
  
  step2: "2. SIMD Main Loop" {
    class: aligned_section
    detail: "16-byte aligned loads"
  }
  
  step3: "3. Handle Epilogue" {
    class: unaligned_section
    detail: "Remaining bytes scalar"
  }
}

alignment_boundaries: Alignment Boundaries {
  class: memory_block
  
  byte_align: "1-byte (any address)" { class: unaligned_section }
  word_align: "2-byte (even addresses)" { class: unaligned_section }
  dword_align: "4-byte alignment" { class: unaligned_section }
  simd_align: "16-byte SIMD alignment" { class: aligned_section }
  avx_align: "32-byte AVX alignment" { class: aligned_section }
}

memory_layout.addr_0x00 -> simd_registers.xmm0: "aligned load"
memory_layout.addr_0x10 -> simd_registers.xmm1: "aligned load"
memory_layout.prologue -> simd_registers.xmm_unaligned: "unaligned load"
memory_layout.epilogue -> simd_registers.xmm_unaligned: "unaligned load"

processing_flow.step1 -> memory_layout.prologue: "handle"
processing_flow.step2 -> memory_layout.main_data: "vectorize"
processing_flow.step3 -> memory_layout.epilogue: "handle"

alignment_boundaries.simd_align -> simd_registers.xmm0: "optimal performance"
alignment_boundaries.avx_align -> simd_registers: "AVX2 operations"

performance_note: |md
  **Key Performance Insights:**
  - Aligned loads: 1 cycle latency
  - Unaligned loads: 2-3 cycle penalty
  - 16-byte boundaries critical for SSE
  - 32-byte boundaries optimal for AVX
| {
  shape: page
  class: memory_block
  near: bottom-center
}