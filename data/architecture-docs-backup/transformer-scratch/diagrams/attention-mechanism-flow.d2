title: Scaled Dot-Product Attention Flow

classes: {
  process: {
    style.fill: "#1a1a2e"
    style.stroke: "#3fb950"
    style.font-color: "#e6edf3"
    style.bold: true
  }
  matrix: {
    style.fill: "#16213e"
    style.stroke: "#8b949e"
    style.font-color: "#e6edf3"
  }
  decision: {
    style.fill: "#0f3460"
    style.stroke: "#3fb950"
    style.font-color: "#e6edf3"
    style.bold: true
  }
  input: {
    style.fill: "#2d3748"
    style.stroke: "#3fb950"
    style.font-color: "#e6edf3"
  }
}

input_x: Input X {
  class: input
}

linear_transforms: Linear Transformations {
  class: process
  wq: W_Q
  wk: W_K  
  wv: W_V
}

matrices: Matrix Results {
  q_matrix: Q (Queries) {
    class: matrix
  }
  k_matrix: K (Keys) {
    class: matrix
  }
  v_matrix: V (Values) {
    class: matrix
  }
}

matmul1: Q × K^T {
  class: process
}

scale: Scale by √d_k {
  class: process
}

mask_check: Apply Mask? {
  shape: diamond
  class: decision
}

add_mask: Add Mask\n(-∞ for masked positions) {
  class: process
}

softmax: Softmax {
  class: process
}

attention_weights: Attention Weights {
  class: matrix
}

matmul2: Weights × V {
  class: process
}

output: Attention Output {
  class: input
}

input_x -> linear_transforms
linear_transforms -> matrices.q_matrix
linear_transforms -> matrices.k_matrix  
linear_transforms -> matrices.v_matrix

matrices.q_matrix -> matmul1
matrices.k_matrix -> matmul1

matmul1 -> scale

scale -> mask_check

mask_check -> add_mask: Yes
mask_check -> softmax: No

add_mask -> softmax

softmax -> attention_weights

attention_weights -> matmul2
matrices.v_matrix -> matmul2

matmul2 -> output