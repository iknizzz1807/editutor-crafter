{
  "types": {
    "TestCase": "fields: test_name string, setup_data TestFixture, target_function callable, input_parameters dict, expected_result any, assertions list[callable], cleanup_actions list[callable], execution_status enum",
    "TestSuite": "fields: suite_name string, test_cases list[TestCase], setup_fixtures list[TestFixture], execution_order enum, parallel_execution boolean, timeout_seconds integer, result_aggregator TestResultCollector",
    "TestFixture": "fields: fixture_name string, scope enum, setup_function callable, teardown_function callable, cached_result any, dependencies list[string], auto_use boolean, parameters list[any]",
    "MockObject": "fields: name string, interface type, call_history list[CallRecord], configured_responses dict, side_effects dict, verification_rules list[Rule], strict_mode boolean, auto_spec boolean",
    "TestRunner": "engine that discovers and executes tests",
    "TestResultCollector": "aggregates test results and provides summary reporting",
    "AssertionError": "exception raised when assertion fails with detailed context",
    "ComparisonResult": "result of value comparison with formatting context",
    "ErrorFormatter": "formats assertion errors with rich contextual information",
    "ParameterSet": "fields: parameters dict, test_id string, skip_condition callable, expected_failure boolean, timeout_override integer",
    "FixtureScope": "enum: FUNCTION, CLASS, MODULE, SESSION",
    "VerifiableMock": "enhanced mock with fluent verification interface",
    "ConfigurableMock": "mock with fluent configuration interface",
    "TestContainer": "fields: dependencies dict[string, any], factories dict[string, callable], scopes dict[string, enum], overrides dict[string, any], initialization_order list[string]",
    "MockFactory": "factory for creating configured mock objects",
    "InteractionRecordingMock": "mock that records detailed interaction history",
    "TestDoubleInjector": "fields: patch_targets dict[string, string], active_patches list[PatchContext], patch_scopes dict[string, enum], original_objects dict[string, any], patch_stack list[string]",
    "MockVerifier": "fields: expected_calls list[CallExpectation], forbidden_calls list[CallExpectation], call_order_requirements list[CallSequence], call_count_requirements dict[string, int], argument_matchers dict[string, callable]",
    "CleanupAction": "individual cleanup operation with priority and dependencies",
    "CleanupManager": "orchestrates resource cleanup with error isolation",
    "TestCaseWrapper": "wraps test execution with error handling",
    "CleanupPriority": "enum: CRITICAL, HIGH, MEDIUM, LOW",
    "PropertyTestCase": "extends TestCase with property definition and input generators",
    "InputGenerator": "creates random or systematic input values within specified constraints",
    "ShrinkingEngine": "finds minimal failing example when property fails",
    "PropertyAssertion": "verifies property holds across generated inputs"
  },
  "methods": {
    "setUp() -> None": "prepare test environment before each test",
    "tearDown() -> None": "clean up test environment after each test",
    "assertEqual(expected, actual) -> None": "verify two values are equal with descriptive failure",
    "assertTrue(condition) -> None": "verify condition evaluates to true",
    "assertRaises(exception_type, callable) -> None": "verify callable raises expected exception",
    "discover_tests(pattern) -> List[TestCase]": "find and register test cases matching pattern",
    "execute_test_suite(suite) -> TestResultCollector": "run complete test suite and collect results",
    "_execute_single_test(test_case) -> TestCase": "execute individual test through complete lifecycle",
    "assertEqual(expected, actual)": "verify two values are equal with descriptive failure",
    "assertTrue(condition)": "verify condition evaluates to true",
    "assertRaises(exception_type, callable)": "verify callable raises expected exception",
    "assertAlmostEqual(first, second, places)": "verify floating-point values are equal within tolerance",
    "assertDictEqual(dict1, dict2)": "specialized dictionary comparison with detailed differences",
    "generate_parameter_sets(parameter_matrix, skip_conditions) -> Iterator[ParameterSet]": "create parameter combinations from matrix",
    "get_fixture(name, scope_context) -> Any": "retrieve cached fixture or create new instance",
    "cleanup_scope(scope) -> None": "clean up all fixtures in specified scope",
    "should_be_called_with(*args, **kwargs)": "verify mock was called with specific arguments",
    "should_be_called_times(count: int)": "verify mock was called specific number of times",
    "when_called_with(*args, **kwargs)": "configure response for specific arguments",
    "then_return(value)": "configure return value",
    "then_raise(exception)": "configure exception raising",
    "verify_interaction_sequence(expected_calls)": "verify calls occurred in specific sequence",
    "inject_mock(target_class, dependency_name, mock_object)": "inject mock object as dependency in target class",
    "was_called()": "verify mock was called at least once",
    "was_called_with(*args, **kwargs)": "verify mock was called with specific arguments",
    "execute_with_error_handling() -> TestCase": "execute test with full error handling and cleanup",
    "_execute_setup() -> List[Exception]": "execute setup with exception handling",
    "_execute_test_method() -> Optional[Exception]": "execute test method with timeout protection",
    "_execute_teardown() -> List[Exception]": "execute teardown with exception isolation",
    "register_cleanup(name, action, priority, dependencies)": "register cleanup action with dependency tracking",
    "execute_cleanup(scope) -> List[CleanupError]": "execute cleanup actions with error isolation",
    "format_assertion_error(comparison, context) -> str": "generate formatted assertion error",
    "format_exception_error(exception, context) -> str": "generate formatted exception error",
    "add_context(key, value)": "add contextual information to exception",
    "was_called_times(count: int)": "verify mock was called specific number of times",
    "was_called() -> bool": "verify mock was called at least once",
    "was_called_with(*args, **kwargs) -> bool": "verify mock was called with specific arguments"
  },
  "constants": {
    "PASSED": "test execution completed successfully",
    "FAILED": "test execution completed with assertion failure",
    "ERROR": "test execution failed due to unexpected exception",
    "SKIPPED": "test execution bypassed due to condition",
    "FUNCTION": "function-level fixture scope",
    "CLASS": "class-level fixture scope",
    "MODULE": "module-level fixture scope",
    "SESSION": "session-level fixture scope",
    "CRITICAL": "highest cleanup priority for system resources",
    "HIGH": "high cleanup priority for application resources",
    "MEDIUM": "medium cleanup priority for test data",
    "LOW": "low cleanup priority for convenience objects"
  },
  "terms": {
    "unit test": "automated test that verifies a single component in isolation",
    "test fixture": "known state setup for repeatable test execution",
    "assertion": "statement that verifies expected behavior and fails test if incorrect",
    "test double": "replacement object used in place of real dependencies during testing",
    "test isolation": "principle ensuring tests don't affect each other's execution or results",
    "behavioral contract": "external interface and expected behavior that components depend upon",
    "edge case": "boundary condition or unusual input that might cause unexpected behavior",
    "brittle test": "test that fails due to implementation changes without behavior changes",
    "test coverage": "measure of how much code is exercised by the test suite",
    "test discovery": "process of finding and identifying test functions and classes",
    "parameterization": "technique to run same test logic with multiple input sets",
    "fixture scope": "lifecycle duration determining how long fixture instances persist",
    "dependency injection": "pattern where dependencies are provided rather than created internally",
    "mock object": "test double that records interactions for verification",
    "stub": "test double that provides predefined responses",
    "spy": "test double that records method calls and parameters",
    "fake": "test double with working but simplified implementation",
    "interaction verification": "checking that mocks were called with expected parameters",
    "patch target": "import location where mock replacement occurs",
    "assertion failure": "controlled test failure when expected behavior doesn't match actual behavior",
    "exception failure": "uncontrolled test failure due to unexpected exception during execution",
    "timeout failure": "test failure due to execution exceeding configured time limits",
    "setup failure": "failure in test infrastructure that prevents test execution",
    "teardown failure": "failure in cleanup operations after test execution",
    "test pollution": "contamination of test environment by previous test failures",
    "cleanup isolation": "principle ensuring failure of one cleanup action doesn't prevent others",
    "exception chaining": "preserving multiple related exceptions with causal relationships",
    "resource state recovery": "detecting and recovering from shared resource corruption",
    "guaranteed teardown": "ensuring cleanup executes regardless of test failure mode",
    "error context preservation": "maintaining diagnostic information across exception boundaries",
    "property-based testing": "testing approach that verifies general properties across many generated inputs",
    "mutation testing": "technique that evaluates test quality by introducing bugs and checking if tests catch them",
    "test generation": "automated creation of test cases using various analysis techniques",
    "integration testing": "testing that verifies correct interaction between components",
    "contract testing": "verification that service interfaces meet expected behavioral contracts",
    "service virtualization": "simulation of external services with realistic behavior patterns",
    "component integration": "testing level that verifies groups of components working together",
    "end-to-end testing": "testing complete user workflows through entire system"
  }
}