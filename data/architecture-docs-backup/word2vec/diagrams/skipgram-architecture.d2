title: Skip-gram Neural Network Architecture {
  style.font-size: 20
  style.bold: true
  near: top-center
}

classes: {
  layer: {
    style.fill: "#1a1a2e"
    style.stroke: "#3fb950"
    style.font-color: "#e6edf3"
    style.bold: true
  }
  matrix: {
    style.fill: "#16213e"
    style.stroke: "#8b949e"
    style.font-color: "#e6edf3"
  }
  data_flow: {
    style.stroke: "#3fb950"
    style.stroke-width: 2
  }
  dimension: {
    style.fill: "#0f3460"
    style.stroke: "#3fb950"
    style.font-color: "#e6edf3"
    style.font-size: 12
  }
}

input_layer: Input Layer {
  class: layer
  
  one_hot: One-hot Vector {
    class: matrix
    shape: rectangle
  }
  
  input_dim: "V × 1" {
    class: dimension
    shape: oval
  }
}

embedding_layer: Embedding Layer {
  class: layer
  
  weight_matrix: "W₁ (Input Weights)" {
    class: matrix
    shape: rectangle
  }
  
  embedding_dim: "V × N" {
    class: dimension
    shape: oval
  }
  
  learned_embedding: Word Embedding {
    class: matrix
    shape: rectangle
  }
  
  embed_vec_dim: "N × 1" {
    class: dimension
    shape: oval
  }
}

hidden_layer: Hidden Layer {
  class: layer
  
  hidden_vector: "h = W₁ᵀ × x" {
    class: matrix
    shape: rectangle
  }
  
  hidden_dim: "N × 1" {
    class: dimension
    shape: oval
  }
}

output_layer: Output Layer {
  class: layer
  
  output_weights: "W₂ (Output Weights)" {
    class: matrix
    shape: rectangle
  }
  
  output_weight_dim: "N × V" {
    class: dimension
    shape: oval
  }
  
  scores: "u = W₂ × h" {
    class: matrix
    shape: rectangle
  }
  
  score_dim: "V × 1" {
    class: dimension
    shape: oval
  }
  
  softmax: "ŷ = softmax(u)" {
    class: matrix
    shape: rectangle
  }
  
  prob_dim: "V × 1" {
    class: dimension
    shape: oval
  }
}

vocabulary_note: |md
  **Dimensions:**
  - V = Vocabulary size
  - N = Embedding dimension
  - Input: Target word (one-hot)
  - Output: Context word probabilities
| {
  shape: page
  class: matrix
  near: top-left
}

input_layer.one_hot -> embedding_layer.weight_matrix: "Matrix multiplication" {
  class: data_flow
}

embedding_layer.weight_matrix -> embedding_layer.learned_embedding: "Extract row" {
  class: data_flow
}

embedding_layer.learned_embedding -> hidden_layer.hidden_vector: "h = W₁ᵀ × x" {
  class: data_flow
}

hidden_layer.hidden_vector -> output_layer.output_weights: "Forward pass" {
  class: data_flow
}

output_layer.output_weights -> output_layer.scores: "u = W₂ × h" {
  class: data_flow
}

output_layer.scores -> output_layer.softmax: "Activation" {
  class: data_flow
}

backprop_flow: output_layer.softmax -> embedding_layer.weight_matrix: "Gradient flow (backprop)" {
  class: data_flow
  style.stroke: "#d63031"
  style.stroke-dash: 5
}