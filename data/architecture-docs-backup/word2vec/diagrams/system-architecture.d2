title: Word2Vec System Architecture {
  style.font-size: 20
  style.bold: true
  style.font-color: "#e6edf3"
}

classes: {
  container_style: {
    style.fill: "#1a1a2e"
    style.stroke: "#3fb950"
    style.font-color: "#e6edf3"
    style.stroke-width: 2
  }
  
  component_style: {
    style.fill: "#16213e"
    style.stroke: "#8b949e"
    style.font-color: "#e6edf3"
  }
  
  data_style: {
    style.fill: "#0f3460"
    style.stroke: "#3fb950"
    style.font-color: "#e6edf3"
    style.italic: true
  }
  
  flow_style: {
    style.stroke: "#8b949e"
    style.font-color: "#8b949e"
  }
}

input: Raw Text Data {
  shape: page
  class: data_style
}

preprocessing: Text Preprocessing {
  class: container_style
  
  tokenizer: Tokenizer {
    class: component_style
  }
  
  cleaner: Text Cleaner {
    class: component_style
  }
  
  normalizer: Normalizer {
    class: component_style
  }
  
  tokenizer -> cleaner: tokens
  cleaner -> normalizer: cleaned tokens
}

vocab_builder: Vocabulary Builder {
  class: container_style
  
  freq_counter: Frequency Counter {
    class: component_style
  }
  
  vocab_filter: Vocabulary Filter {
    class: component_style
  }
  
  word_indexer: Word Indexer {
    class: component_style
  }
  
  freq_counter -> vocab_filter: word frequencies
  vocab_filter -> word_indexer: filtered vocab
}

skip_gram: Skip-gram Model {
  class: container_style
  
  input_layer: Input Layer {
    class: component_style
  }
  
  embedding_layer: Embedding Layer {
    class: component_style
  }
  
  output_layer: Output Layer {
    class: component_style
  }
  
  input_layer -> embedding_layer: word indices
  embedding_layer -> output_layer: hidden vectors
}

negative_sampler: Negative Sampler {
  class: container_style
  
  prob_table: Probability Table {
    class: component_style
  }
  
  sampler: Random Sampler {
    class: component_style
  }
  
  prob_table -> sampler: sampling probabilities
}

training: Training Engine {
  class: container_style
  
  loss_calc: Loss Calculator {
    class: component_style
  }
  
  optimizer: SGD Optimizer {
    class: component_style
  }
  
  loss_calc -> optimizer: gradients
}

evaluation: Evaluation {
  class: container_style
  
  similarity: Word Similarity {
    class: component_style
  }
  
  analogy: Analogy Tasks {
    class: component_style
  }
  
  clustering: Clustering {
    class: component_style
  }
}

word_vectors: Word Vectors {
  shape: cylinder
  class: data_style
}

input -> preprocessing: raw text {
  class: flow_style
}

preprocessing -> vocab_builder: processed tokens {
  class: flow_style
}

preprocessing -> skip_gram: training pairs {
  class: flow_style
}

vocab_builder -> skip_gram: vocabulary {
  class: flow_style
}

vocab_builder -> negative_sampler: word frequencies {
  class: flow_style
}

skip_gram -> training: model predictions {
  class: flow_style
}

negative_sampler -> training: negative samples {
  class: flow_style
}

training -> skip_gram: updated weights {
  class: flow_style
  style.stroke-dash: 3
}

skip_gram -> word_vectors: learned embeddings {
  class: flow_style
}

word_vectors -> evaluation: embeddings {
  class: flow_style
}