{
  "types": {
    "Trace": "fields: TraceID string, Spans []Span, StartTime time.Time, EndTime time.Time",
    "Span": "fields: SpanID string, TraceID string, ParentSpanID string, Name string, ServiceName string, StartTime time.Time, Duration time.Duration, Attributes map[string]string, Events []SpanEvent, Status SpanStatus",
    "Service": "fields: Name string, Operations []string",
    "Config": "fields: FailureThreshold int, SuccessThreshold int, Timeout time.Duration, HalfOpenMax int",
    "SamplingConfig": "fields: Probability float64, PerService map[string]float64",
    "StorageConfig": "fields: Type string, Endpoint string, Timeout time.Duration",
    "SpanEvent": "fields: Name string, Timestamp time.Time, Attributes map[string]string",
    "SpanStatus": "fields: Code int, Message string",
    "Collector": "fields: config *models.Config",
    "WALWriter": "fields: mu sync.RWMutex, file *os.File, filePath string, offset int64, maxFileSize int64, currentSize int64, rotateSignal chan struct{}, done chan struct{}",
    "BufferManager": "fields: maxSize int, ttl time.Duration, traces map[string]*TraceBuffer, accessTimes map[string]time.Time, evictionPolicy string",
    "TraceBuffer": "fields: spans []models.Span, firstSeen time.Time, lastSeen time.Time, isComplete bool",
    "TraceAssembler": "fields: maxTraceDuration time.Duration",
    "ServiceEdge": "fields: CallerService string, CalleeService string, WindowStart time.Time, WindowEnd time.Time, TotalCalls int64, ErrorCount int64, ErrorRate float64, P50Latency time.Duration, P95Latency time.Duration, P99Latency time.Duration, SampleTraceIDs []string",
    "ServiceNode": "fields: Name string, FirstSeen time.Time, LastSeen time.Time, TotalCalls int64",
    "ServiceGraph": "fields: Nodes []ServiceNode, Edges []ServiceEdge, GeneratedAt time.Time, WindowSize time.Duration",
    "EdgeStorage": "fields: (interface)",
    "MemoryEdgeStore": "fields: mu sync.RWMutex, edges []ServiceEdge, maxAge time.Duration",
    "EdgeAggregator": "fields: edgeStorage EdgeStorage, windowSize time.Duration, currentWindowStart time.Time, pendingEdges map[string]*ServiceEdge",
    "GraphBuilder": "fields: edgeStorage EdgeStorage",
    "ConsistentSampler": "fields: mu sync.RWMutex, rate float64, hashFunc func(string) uint64",
    "HeadSampler": "fields: mu sync.RWMutex, globalSampler *ConsistentSampler, serviceRates map[string]*ConsistentSampler, defaultRate float64, stats HeadSamplerStats",
    "HeadSamplerStats": "fields: TotalTraces int64, SampledTraces int64, PerService map[string]ServiceStats, LastReset time.Time",
    "ServiceStats": "fields: TracesSeen int64, TracesSampled int64",
    "TailSampler": "fields: rules []TailSamplingRule, evaluator *TraceEvaluator, buffer *TraceBuffer, timeout time.Duration, stats TailSamplerStats",
    "TailSamplingRule": "fields: Name string, Condition TraceCondition, Priority int, KeepIfMatch bool",
    "TraceEvaluator": "fields: errorWeight float64, latencyWeight float64, operationWeights map[string]float64, threshold float64",
    "TailSamplerStats": "fields: TotalEvaluated int64, HeadSampled int64, TailOverrides int64, PerRuleDecisions map[string]int64",
    "TDigestMetric": "fields: digest *tdigest.TDigest, mu sync.RWMutex, count int64, lastReset time.Time",
    "MetricPoint": "fields: Timestamp time.Time, Value float64, Labels map[string]string",
    "MemoryStore": "fields: buffers map[string]*ring.Ring, mu sync.RWMutex, maxPoints int, ttl time.Duration",
    "PercentileAggregator": "fields: digests map[string]*TDigestMetric, mu sync.RWMutex, window time.Duration",
    "Detector": "fields: baselineCalc BaselineCalculator, methods []DetectionMethod, thresholds map[string]float64",
    "AnomalyResult": "fields: Metric string, Labels map[string]string, Timestamp time.Time, Value float64, Expected float64, Confidence float64, Method string, Severity string",
    "Tracer": "fields: serviceName string, exporter SpanExporter, sampler HeadSampler",
    "WrappedTransport": "fields: Base http.RoundTripper, Tracer *tracer.Tracer",
    "TextMapCarrier": "fields: (interface)",
    "OTLPHandler": "fields: pipeline *ingestion.Pipeline, logger *zap.Logger",
    "Pipeline": "fields: validator *SpanValidator, bufferManager *BufferManager, headSampler *sampling.HeadSampler, tailSampler *sampling.TailSampler, storageWriter storage.Writer, metrics *PipelineMetrics",
    "PipelineMetrics": "fields: SpansReceived int64, SpansProcessed int64, SpansDropped int64, TracesAssembled int64, ProcessingTime time.Duration",
    "OTLPJSONRequest": "fields: ResourceSpans []ResourceSpan",
    "ResourceSpan": "fields: Resource Resource, ScopeSpans []ScopeSpan",
    "Resource": "fields: Attributes []KeyValue",
    "ScopeSpan": "fields: Spans []OTLPSpan",
    "OTLPSpan": "fields: TraceID string, SpanID string, ParentSpanID string, Name string, Kind string, StartTimeUnixNano string, EndTimeUnixNano string, Attributes []KeyValue, Status OTLPStatus",
    "KeyValue": "fields: Key string, Value Value",
    "Value": "fields: StringValue string, BoolValue bool, IntValue int64, DoubleValue float64, ArrayValue []Value",
    "OTLPStatus": "fields: Code string, Message string",
    "CircuitBreaker": "fields: mu sync.RWMutex, state State, failureThreshold int, successThreshold int, failureCount int, successCount int, timeout time.Duration, lastFailure time.Time, halfOpenMax int, halfOpenCount int32, onStateChange func(from, to State)",
    "BackpressureManager": "fields: mu sync.RWMutex, currentTier Tier, thresholds map[Tier]Thresholds, metrics *SystemMetrics, stateChan chan<- StateChange, lastCheck time.Time, checkInterval time.Duration",
    "SystemMetrics": "fields: MemoryUsedPercent float64, CPULoadPercent float64, QueueDepthPercent float64, StorageLatencyMS int64, SpansDroppedPerSec int64, ActiveTraces int64",
    "StateChange": "fields: Timestamp time.Time, FromTier Tier, ToTier Tier, Reason string, Metrics SystemMetrics",
    "HealthRegistry": "fields: mu sync.RWMutex, components map[string]ComponentStatus, overrides map[string]func() ComponentStatus, startTime time.Time",
    "ComponentStatus": "fields: Name string, Status HealthStatus, Details string, Since time.Time",
    "HealthResponse": "fields: Status HealthStatus, Timestamp time.Time, Components []ComponentStatus, Message string, DegradedSince *time.Time",
    "WALReader": "fields: file *os.File",
    "Thresholds": "fields: MemoryPercent float64, CPULoadPercent float64, QueueDepthPercent float64, StorageLatencyMS int64",
    "ComponentState": "fields: Name string, Health string, Metrics map[string]interface{}, LastUpdated time.Time",
    "StateDumper": "fields: mu sync.RWMutex, components map[string]func() ComponentState",
    "ContextLogger": "fields: logger *zap.Logger",
    "GeneratorConfig": "fields: Rate int, Duration time.Duration, Services []string, ErrorRate float64, MaxDepth int",
    "TraceGenerator": "fields: config GeneratorConfig, stats GeneratorStats",
    "RUMSpan": "fields: models.Span, BrowserInfo BrowserInfo, PageURL string, UserInteraction string, WebVitals WebVitals",
    "WebVitals": "fields: FCP time.Duration, LCP time.Duration, FID time.Duration, CLS float64",
    "BrowserInfo": "fields: (implied struct for browser metadata)",
    "TelemetrySource": "fields: (interface)",
    "AnalysisModule": "fields: (interface)",
    "VisualizationProvider": "fields: (interface)",
    "ExtensionRegistry": "fields: mu sync.RWMutex, sources map[string]TelemetrySource, analyzers map[string]AnalysisModule, visualizers map[string]VisualizationProvider",
    "UnifiedStorage": "fields: (interface)",
    "TraceWithContext": "fields: Trace *models.Trace, Logs []LogEntry, Metrics []MetricSample, Events []InfrastructureEvent",
    "RootCauseSuggestion": "fields: (implied struct)",
    "BusinessTransactionMonitor": "fields: (implied component)",
    "eBPFCollector": "fields: (implied component)",
    "ProfileStorage": "fields: (interface)",
    "Profiler": "fields: (implied component)"
  },
  "methods": {
    "Validate() error": "Validates configuration",
    "New(config *models.Config) (*Collector, error)": "Creates a new Collector instance",
    "Start(ctx context.Context) error": "Starts the telemetry source",
    "Stop()": "Gracefully stops the collector",
    "NewTraceFromSpans(spans []Span) (*Trace, error)": "Constructs a Trace view from a slice of spans with the same TraceID",
    "StoreSpan(ctx context.Context, span Span) error": "Persists a single span to storage",
    "GetTraceByID(ctx context.Context, traceID string) (*Trace, error)": "retrieves and assembles trace",
    "GetTracesByService(ctx context.Context, serviceName string, startTime time.Time, endTime time.Time, limit int) ([]*Trace, error)": "Returns traces that involve the given service within the specified time range",
    "GetTracesByTimeRange(ctx context.Context, startTime time.Time, endTime time.Time, limit int) ([]*Trace, error)": "Returns traces that started within the given time range",
    "GetServices(ctx context.Context) ([]*Service, error)": "Returns a list of all services that have emitted spans",
    "Close() error": "gracefully closes WAL writer",
    "NewWALWriter(filePath string) (*WALWriter, error)": "Creates a new WAL writer for the given file path",
    "Append(data []byte) (int64, error)": "writes record to WAL with length-prefixed format",
    "Rotate() (*os.File, error)": "Creates a new WAL file and returns the old file for cleanup",
    "NewServer(port int, handler http.Handler) *Server": "Creates a new HTTP server",
    "Start() error": "Starts the HTTP server",
    "Shutdown(ctx context.Context) error": "Gracefully shuts down the HTTP server",
    "HealthHandler(w http.ResponseWriter, r *http.Request)": "Provides health check endpoint",
    "NewTraceAssembler(maxTraceDuration time.Duration) *TraceAssembler": "Creates a new trace assembler with the given configuration",
    "AssembleTrace(ctx context.Context, spans []models.Span) (*models.Trace, error)": "builds trace hierarchy from spans",
    "IsTraceComplete(ctx context.Context, traceID string, spans []models.Span, firstSpanTime time.Time) bool": "Checks if we have all spans for a trace",
    "NewBufferManager(maxSize int, ttl time.Duration, evictionPolicy string) *BufferManager": "Creates a new buffer manager",
    "AddSpan(ctx context.Context, span models.Span) error": "Adds a span to the buffer for its trace",
    "evict(ctx context.Context) (int, error)": "Removes traces based on the configured eviction policy",
    "GetTraceSpans(ctx context.Context, traceID string) ([]models.Span, error)": "Returns all spans for a given trace ID",
    "NewMemoryEdgeStore(maxAge time.Duration) *MemoryEdgeStore": "Creates in-memory edge store with cleanup goroutine",
    "StoreEdge(ctx context.Context, edge ServiceEdge) error": "Stores or updates aggregated edge",
    "GetEdges(ctx context.Context, startTime, endTime time.Time) ([]ServiceEdge, error)": "Returns edges for time window",
    "NewEdgeAggregator(storage EdgeStorage, windowSize time.Duration) *EdgeAggregator": "Creates edge aggregator",
    "ProcessSpan(ctx context.Context, span models.Span) error": "adds span to edge aggregation",
    "FlushWindow(ctx context.Context, windowStart time.Time) error": "Persists aggregated edges for window",
    "BuildCurrentGraph(ctx context.Context, windowSize time.Duration) (*ServiceGraph, error)": "constructs service dependency graph",
    "DetectTopologyChanges(ctx context.Context, currentGraph, previousGraph *ServiceGraph) *TopologyChanges": "Compares graphs to find changes",
    "NewConsistentSampler(rate float64) *ConsistentSampler": "creates sampler with given rate",
    "ShouldSample(traceID string) bool": "deterministic head-based sampling decision",
    "SetRate(rate float64)": "updates sampling rate",
    "GetRate() float64": "returns current sampling rate",
    "NewHeadSampler(config *models.SamplingConfig) (*HeadSampler, error)": "creates head-based sampler",
    "Decide(ctx context.Context, traceID, serviceName string) bool": "makes head-based sampling decision",
    "UpdateRates(ctx context.Context, newGlobalRate float64, newServiceRates map[string]float64) error": "dynamically adjusts rates",
    "GetStats(ctx context.Context) HeadSamplerStats": "returns sampling statistics",
    "NewTailSampler(rules []TailSamplingRule, timeout time.Duration) (*TailSampler, error)": "creates tail-based sampler",
    "EvaluateTrace(ctx context.Context, trace *models.Trace, headDecision bool) bool": "examines completed trace",
    "ProcessCompletedTraces(ctx context.Context, traceCh <-chan *models.Trace) error": "runs evaluation goroutine",
    "AddTraceToBuffer(ctx context.Context, traceID string, spans []models.Span) error": "stores trace for later evaluation",
    "NewTDigestMetric(compression float64) (*TDigestMetric, error)": "creates a new metric with specified compression",
    "Add(value float64)": "adds a value to the distribution",
    "Quantile(q float64) float64": "returns estimated percentile from t-digest",
    "Count() int64": "returns the number of observations",
    "Reset()": "clears the distribution and resets counters",
    "NewMemoryStore(maxPoints int, ttl time.Duration) *MemoryStore": "creates a new in-memory store with given capacity",
    "Write(point MetricPoint) error": "adds a metric point to the appropriate ring buffer",
    "Read(labels map[string]string, start, end time.Time) ([]MetricPoint, error)": "returns all points within the time range for given labels",
    "hashKey(labels map[string]string) string": "creates a simple string key from labels map",
    "cleanup()": "removes expired buffers",
    "NewPercentileAggregator(window time.Duration) *PercentileAggregator": "creates a new aggregator with the given time window",
    "GetPercentiles(ctx context.Context, service, operation string) (p50, p95, p99 time.Duration, err error)": "returns current percentile values for a service/operation",
    "ResetWindow()": "clears all digests and starts a new aggregation window",
    "NewDetector(baselineCalc BaselineCalculator) *Detector": "creates a new anomaly detector with configured methods",
    "CheckMetric(ctx context.Context, metricName string, labels map[string]string, currentValue float64) ([]AnomalyResult, error)": "evaluates metric for anomalies",
    "Detect(current, historical []float64) (bool, float64, error)": "detects anomalies using specific algorithm",
    "Name() string": "Returns name of extension",
    "Calculate(ctx context.Context, metricName string, labels map[string]string, t time.Time) (float64, error)": "computes expected values from historical data",
    "ContextWithSpan(parentCtx context.Context, span *Span) context.Context": "returns a new context containing the given span",
    "SpanFromContext(ctx context.Context) *Span": "retrieves the active span from the context",
    "ExtractTraceContext(ctx context.Context, carrier TextMapCarrier) context.Context": "extracts W3C trace context from carrier into context",
    "InjectTraceContext(ctx context.Context, carrier TextMapCarrier) error": "injects current span context into carrier",
    "StartSpanFromContext(ctx context.Context, name string) (context.Context, *Span)": "creates a new span as child of active span in context",
    "End()": "finalizes the span and schedules it for export",
    "RoundTrip(req *http.Request) (*http.Response, error)": "executes HTTP request with tracing",
    "WrapDriver(baseDriver driver.Driver, driverName string, tracer *tracer.Tracer)": "registers an instrumented SQL driver",
    "NewOTLPHandler(pipeline *ingestion.Pipeline, logger *zap.Logger) *OTLPHandler": "creates a new HTTP handler for OTLP",
    "ServeHTTP(w http.ResponseWriter, r *http.Request)": "implements http.Handler for OTLP requests",
    "parseOTLPJSON(data []byte) ([]apm.Span, error)": "parses OTLP JSON format into internal Span objects",
    "parseOTLPProtobuf(data []byte) ([]apm.Span, error)": "parses OTLP protobuf format",
    "respondWithError(w http.ResponseWriter, code int, message string)": "sends an error response",
    "extractServiceName(resource Resource) string": "extracts service name from OTLP resource attributes",
    "convertOTLPSpan(otlpSpan OTLPSpan, serviceName string) (apm.Span, error)": "converts OTLP span to internal Span representation",
    "parseUnixNano(nsStr string) (time.Time, error)": "parses a string representing nanoseconds since Unix epoch",
    "valueToString(v Value) string": "converts OTLP AnyValue to string",
    "RegisterRoutes(router *mux.Router, pipeline *ingestion.Pipeline, logger *zap.Logger)": "registers the OTLP handler with the router",
    "NewPipeline(config *Config) (*Pipeline, error)": "creates a new ingestion pipeline",
    "ProcessSpan(ctx context.Context, span apm.Span) error": "processes a single span through the ingestion pipeline",
    "ProcessCompleteTrace(ctx context.Context, trace *apm.Trace) error": "called when a trace is assembled and ready for tail sampling",
    "NewWALWriter(dataDir string, maxFileSize int64) (*WALWriter, error)": "creates new WAL writer with automatic rotation",
    "NewWALReader(filePath string) (*WALReader, error)": "creates reader for replaying WAL entries",
    "ReadNext() ([]byte, error)": "reads next record from WAL",
    "NewCircuitBreaker(config Config) *CircuitBreaker": "creates new circuit breaker",
    "Execute(ctx context.Context, operation func() error) error": "runs operation with circuit breaker protection",
    "State() State": "returns current circuit breaker state",
    "SetStateChangeCallback(callback func(from, to State))": "sets callback for state changes",
    "NewBackpressureManager(initialThresholds map[Tier]Thresholds, checkInterval time.Duration) *BackpressureManager": "creates new backpressure manager",
    "CurrentTier() Tier": "returns current backpressure tier",
    "SetStateChangeChannel(ch chan<- StateChange)": "sets channel for state change notifications",
    "GetRecommendedSamplingRate(service string) float64": "returns sampling rate recommendation for current tier",
    "ShouldProcessSpan(span models.Span) bool": "determines if span should be processed in current tier",
    "NewHealthRegistry() *HealthRegistry": "creates new health registry",
    "RegisterComponent(name string, checkFunc func() ComponentStatus)": "adds component to health checks",
    "SetComponentStatus(name string, status HealthStatus, details string)": "manually sets component status",
    "HealthHandler(w http.ResponseWriter, req *http.Request)": "provides health check endpoint",
    "LivenessHandler(w http.ResponseWriter, req *http.Request)": "returns simple liveness check",
    "ReadinessHandler(w http.ResponseWriter, req *http.Request)": "returns readiness check",
    "BufferManagerStateProvider(bm *BufferManager) func() ComponentState": "Creates a state provider function for BufferManager",
    "WithContext(ctx context.Context) *zap.Logger": "Returns a logger with trace context fields added",
    "SampledDebug(ctx context.Context, msg string, fields ...zap.Field)": "Logs debug messages only for sampled traces",
    "GenerateTrace() *models.Trace": "Creates a single trace with realistic structure",
    "Run(ctx context.Context) error": "Generates traces at the configured rate",
    "AddBusinessContext(span *models.Span, transaction string, attributes map[string]string)": "Adds business context to span attributes",
    "GetTracesByBusinessTransaction(ctx context.Context, transaction string) ([]*models.Trace, error)": "Queries traces by business transaction attribute",
    "Stop() error": "Stops the telemetry source",
    "TelemetryChan() <-chan models.Span": "Returns channel for telemetry data",
    "Analyze(ctx context.Context, trace *models.Trace) (AnalysisResult, error)": "Analyzes trace for insights",
    "RequiredFields() []string": "Returns span fields needed for analysis",
    "Type() string": "Returns visualization type",
    "DataQuery(ctx context.Context, params map[string]string) ([]byte, error)": "Executes data query for visualization",
    "RenderOptions() map[string]interface{}": "Returns rendering options",
    "RegisterSource(source TelemetrySource)": "Registers a telemetry source extension",
    "Sources() []TelemetrySource": "Returns all registered telemetry sources",
    "GetTracesByBusinessTransaction(ctx context.Context, transaction string) ([]*Trace, error)": "Queries traces by business transaction attribute"
  },
  "constants": {
    "TRACE_ID_HEADER": "traceparent",
    "SPAN_ID_HEADER": "tracestate",
    "activeSpanKey": "private key for storing span in context.Context",
    "StateClosed": "circuit breaker closed state",
    "StateOpen": "circuit breaker open state",
    "StateHalfOpen": "circuit breaker half-open state",
    "ErrCircuitOpen": "circuit breaker is open error",
    "ErrTooManyRequests": "too many requests in half-open state",
    "TierNormal": "normal operation backpressure tier",
    "TierAdaptiveSampling": "adaptive sampling adjustment tier",
    "TierSelectiveShedding": "selective load shedding tier",
    "TierAggressiveDegradation": "aggressive degradation tier",
    "TierFailSafe": "fail-safe mode tier",
    "StatusHealthy": "healthy system status",
    "StatusDegraded": "degraded system status",
    "StatusUnhealthy": "unhealthy system status"
  },
  "terms": {
    "Distributed Tracing": "Method of tracking requests as they propagate through a distributed system",
    "Span": "A named, timed operation representing a unit of work in a trace",
    "Trace": "A collection of spans that represent a single request's path through a system",
    "APM": "Application Performance Monitoring - the practice of monitoring software applications for performance and availability",
    "Microservices": "An architectural style that structures an application as a collection of loosely coupled services",
    "Real User Monitoring (RUM)": "Instrumenting client-side web applications to capture browser performance and user interactions",
    "Log Aggregation": "Centralized collection, indexing, and search of unstructured log data",
    "Infrastructure Metrics": "System-level metrics like CPU, memory, disk I/O",
    "Continuous Profiling": "Periodic capture and analysis of CPU flame graphs and heap allocations",
    "Synthetic Monitoring": "Proactive simulation of user traffic to measure availability and performance",
    "OpenTelemetry": "A collection of APIs, SDKs, and tools for instrumenting, generating, collecting, and exporting telemetry data",
    "pipes and filters": "An architectural pattern where data flows through a series of processing components",
    "Service": "A logical component in a distributed system that emits spans",
    "WAL": "Write-Ahead Log - a durability mechanism where changes are written to a log before being applied",
    "Buffer Eviction": "The process of removing items from a buffer when it reaches capacity",
    "Clock Skew": "Difference in system clocks between different machines",
    "Head-of-Line Blocking": "When processing of one item delays processing of subsequent items",
    "Watermark Algorithm": "Algorithm marking point in stream after which no earlier data is expected",
    "Service Map": "Visual representation of service dependencies in a distributed system",
    "Edge Aggregation": "Process of combining multiple service calls into summarized metrics",
    "Time Window": "Fixed period (e.g., 1 minute) over which metrics are aggregated",
    "Topology Change": "Addition, removal, or modification of service dependencies",
    "Cycle Detection": "Algorithm to identify circular dependencies in service calls",
    "Head-Based Sampling": "Sampling decision made at trace creation using only initial context",
    "Tail-Based Sampling": "Sampling decision made after trace completion using full trace data",
    "Adaptive Sampling": "Dynamically adjusting sampling rates based on system load and trace value",
    "Consistent Hashing": "Deterministic hash function ensuring same decision for same trace ID",
    "Sampling Bias": "Statistical distortion from non-representative sampling",
    "PID Controller": "Control loop mechanism using proportional, integral, derivative terms",
    "t-digest": "probabilistic data structure for computing approximate percentiles from streaming data",
    "z-score": "statistical measurement describing a value's relationship to the mean of a group of values",
    "moving average": "A calculation to analyze data points by creating series of averages of different subsets",
    "seasonal decomposition": "Time series analysis method separating data into trend, seasonal, and residual components",
    "percentile": "A value below which a given percentage of observations fall",
    "baseline": "Historical performance data used as a reference for anomaly detection",
    "anomaly": "A data point or pattern that deviates significantly from expected behavior",
    "time-series database": "A database optimized for storing and retrieving time-stamped data",
    "ring buffer": "A circular buffer data structure that uses a single, fixed-size buffer",
    "Flight Data Recorder (FDR)": "analogy for the APM SDK's automatic, continuous monitoring",
    "Middleware": "technique to inject into a framework's request-handling pipeline",
    "Monkey Patching": "technique to replace library functions at runtime for instrumentation",
    "Context Propagation": "mechanism to carry trace context across process and service boundaries",
    "W3C Trace Context": "W3C standard headers for trace context propagation across HTTP",
    "SpanExporter": "component that sends completed spans to the collector",
    "OpenTelemetry Protocol (OTLP)": "standard protocol for telemetry data exchange defined by OpenTelemetry",
    "wire format": "serialized representation of data for transmission over network",
    "ingestion pipeline": "sequence of processing stages for incoming telemetry data",
    "context propagation": "mechanism for carrying trace context across process and service boundaries",
    "batch processing": "processing multiple items together for efficiency",
    "columnar storage": "storage format that stores data by columns rather than rows for analytical queries",
    "dictionary encoding": "compression technique that replaces repeated strings with integer IDs",
    "backpressure": "flow control mechanism to prevent overwhelming downstream components",
    "graceful degradation": "system continues operating with reduced functionality rather than failing completely",
    "circuit breaker pattern": "design pattern that prevents cascading failures by stopping calls to failing services",
    "Write-Ahead Log (WAL)": "durability mechanism where changes are written to a log before being applied",
    "cascading failures": "when failure in one component causes failures in dependent components",
    "health check": "endpoint that reports system health status",
    "liveness probe": "check if process is running",
    "readiness probe": "check if system is ready to receive traffic",
    "exponential backoff": "retry strategy with exponentially increasing wait times",
    "triage protocols": "prioritization rules for handling limited resources during overload",
    "Property-Based Testing": "testing method that verifies properties hold for a large number of randomly generated inputs",
    "Chaos Testing": "deliberately injecting failures to test system resilience",
    "Mock": "a simulated object that mimics the behavior of a real component in controlled ways",
    "Integration Test": "test that verifies multiple components work together correctly",
    "Load Test": "test that measures system performance under expected or peak load",
    "Circuit Breaker": "design pattern that prevents cascading failures by stopping calls to failing services",
    "Backpressure": "flow control mechanism to prevent overwhelming downstream components",
    "systems detective": "Analogy for debugging complex distributed systems by following clues to identify root causes",
    "X-ray machine": "Analogy for profiling tools that reveal internal application structure and hotspots",
    "dogfooding": "Practice of using your own product to monitor and debug itself",
    "system vitals monitor": "Analogy for diagnostic endpoints that expose critical system health metrics",
    "virtuous cycle": "Positive feedback loop where debugging improvements benefit both the system and its users",
    "eBPF": "Extended Berkeley Packet Filter - technology for running sandboxed programs in the Linux kernel",
    "Business Transaction Tracing": "Tagging traces with business context and monitoring business processes",
    "Multi-Tenancy": "Architectural pattern for serving multiple independent customers from a single deployment",
    "Flame Graph": "Visualization of hierarchical data showing resource consumption across call stacks",
    "Heat Map": "Data visualization using colors to represent values in a matrix",
    "Predictive Capacity Planning": "Using historical data to forecast future resource needs",
    "Unified Observability": "Correlating traces, logs, and metrics for complete system understanding",
    "Dependency Inversion": "Design principle where high-level modules depend on abstractions rather than low-level details"
  }
}