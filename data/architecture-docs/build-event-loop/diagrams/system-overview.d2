direction: right
vars: {
  d2-config: {
    layout-engine: elk
    theme-id: 3
  }
}
title: |md
  # Event Loop with epoll — Implementation-Ready System Blueprint
  **C | Linux | Reactor Pattern | C10K**
| {near: top-center}
classes: {
  milestone: {
    style: {
      fill: "#E8F4FD"
      stroke: "#2196F3"
      stroke-width: 2
      border-radius: 6
      font-size: 11
    }
  }
  struct_box: {
    style: {
      fill: "#FFF8E1"
      stroke: "#F57F17"
      stroke-width: 2
      border-radius: 4
      font-size: 11
      font: mono
    }
  }
  fn_box: {
    style: {
      fill: "#F3E5F5"
      stroke: "#7B1FA2"
      stroke-width: 2
      border-radius: 4
      font-size: 11
      font: mono
    }
  }
  kernel_box: {
    style: {
      fill: "#E8F5E9"
      stroke: "#2E7D32"
      stroke-width: 2
      border-radius: 4
      font-size: 11
    }
  }
  hw_box: {
    style: {
      fill: "#FCE4EC"
      stroke: "#880E4F"
      stroke-width: 2
      border-radius: 4
      font-size: 11
    }
  }
  error_path: {
    style: {
      stroke-dash: 5
      stroke: "#D32F2F"
      font-color: "#D32F2F"
      animated: false
    }
  }
  data_flow: {
    style: {
      stroke: "#1565C0"
      animated: true
      font-size: 10
    }
  }
}
# ═══════════════════════════════════════════════════════════
# LAYER 0 — HARDWARE / NIC
# ═══════════════════════════════════════════════════════════
hw_layer: "HARDWARE LAYER — NIC + CPU" {
  style: {
    fill: "#FFF3E0"
    stroke: "#E65100"
    stroke-width: 3
    border-radius: 8
    font-size: 13
    bold: true
  }
  nic: "NIC (Network Interface Card)" {
    class: hw_box
    desc: |md
      **RX Ring Buffer** — DMA write, no CPU
      **TX Ring Buffer** — DMA read, no CPU
      Interrupt → NAPI poll at high pps
      Line rate: 1 Gbps = 125 MB/s
      Segment size: 1500B MTU (Ethernet)
    |
  }
  cpu_cache: "CPU Cache Hierarchy" {
    class: hw_box
    desc: |md
      **L1d** 32–64 KB — ~4 cycles
      **L2**  256 KB–2 MB — ~12 cycles
      **L3**  8–32 MB — ~40 cycles
      **RAM** DRAM — ~200 cycles
      Cache line = **64 bytes**
      TLB miss ≈ 1–10 µs (page fault)
      Branch mispredict ≈ 15–20 cycles
    |
  }
  dma_note: |md
    **DMA**: NIC writes TCP payload
    directly to kernel sk_receive_queue
    — zero CPU involvement
    AVX2 memcpy: 32B/inst, ~64 inst
    for 4096B → ~20 ns @ 3 GHz
  |
}
# ═══════════════════════════════════════════════════════════
# LAYER 1 — KERNEL (epoll + TCP + vDSO)
# ═══════════════════════════════════════════════════════════
kernel_layer: "KERNEL LAYER — epoll + TCP Stack" {
  style: {
    fill: "#E8F5E9"
    stroke: "#1B5E20"
    stroke-width: 3
    border-radius: 8
    font-size: 13
    bold: true
  }
  epoll_instance: "epoll Instance (kernel fd)" {
    class: kernel_box
    syscalls: |c
      /* syscalls */
      epoll_create1(EPOLL_CLOEXEC) → int epfd
      epoll_ctl(epfd, OP, fd, *ev) → 0|-1
        OPS: EPOLL_CTL_ADD | MOD | DEL
      epoll_wait(epfd, *evs, max, ms) → n
    |
    internals: |md
      **interest list**: rb-tree of epitem
      **ready list** (rdllist): doubly-linked
      LT: fd re-added to rdllist if data remains
      ET: fd removed until new data arrives
      epitem size ≈ 128B each
      MAX_EVENTS=1024 → 12KB stack array (L1-hot)
    |
  }
  epoll_event_struct: "struct epoll_event" {
    class: struct_box
    layout: |c
      /* <sys/epoll.h> */
      struct epoll_event {
        uint32_t     events;   /* +0x00  4B */
        epoll_data_t data;     /* +0x04  8B */
      }; /* total: 12 bytes */
      /* events flags */
      EPOLLIN   = 0x001  /* readable      */
      EPOLLOUT  = 0x004  /* writable      */
      EPOLLERR  = 0x008  /* error         */
      EPOLLHUP  = 0x010  /* hangup        */
      EPOLLRDHUP= 0x2000 /* peer half-close */
      EPOLLET   = 1u<<31 /* edge-triggered */
      /* data union */
      union epoll_data_t {
        void    *ptr;  /* → fd_handler_t* (M3) */
        int      fd;   /* fd int (M1/M2)        */
        uint32_t u32;
        uint64_t u64;
      };
    |
  }
  tcp_stack: "TCP Stack (net/ipv4/tcp_input.c)" {
    class: kernel_box
    desc: |md
      sk_receive_queue — recv buffer (87KB default)
      sk_send_head — send buffer (87KB default)
      sock_def_readable() → wakes epoll
      sock_def_write_space() → triggers EPOLLOUT
      copy_to_user() — kernel→userspace memcpy
      TCP flow control: recv window advertisement
      TIME_WAIT: ~60s; bypass with SO_REUSEADDR
    |
  }
  vdso: "vDSO — clock_gettime" {
    class: kernel_box
    desc: |md
      CLOCK_MONOTONIC via vDSO
      Cost: ~30 ns (vs 200 ns real syscall)
      Never goes backward (NTP-safe)
      Used by timer_next_ms() every tick
      Returns: uint64_t ms = sec*1000 + ns/1e6
    |
  }
  socket_cfg: "Socket Configuration Syscalls" {
    class: kernel_box
    cfg: |c
      socket(AF_INET,
             SOCK_STREAM|SOCK_NONBLOCK|SOCK_CLOEXEC,
             0) → listen_fd
      setsockopt(fd, SOL_SOCKET,
                 SO_REUSEADDR, &1, 4)
      bind(fd, (sockaddr*)&addr, sizeof(addr))
      listen(fd, BACKLOG=128)
      accept4(listen_fd, &addr, &len,
              SOCK_NONBLOCK|SOCK_CLOEXEC) → client_fd
      /* non-blocking: returns EAGAIN if no pending */
      /* set_nonblocking(fd):                       */
      fcntl(fd, F_GETFL) → flags
      fcntl(fd, F_SETFL, flags|O_NONBLOCK)
    |
  }
}
# ═══════════════════════════════════════════════════════════
# LAYER 2 — M1: epoll Basics + Echo Server
# ═══════════════════════════════════════════════════════════
m1_layer: "M1: epoll Basics — LT vs ET Echo Server" {
  class: milestone
  style: {
    fill: "#E3F2FD"
    stroke: "#0D47A1"
    stroke-width: 3
    border-radius: 8
    font-size: 13
    bold: true
  }
  m1_files: "Files: reactor_core.h / reactor_core.c / echo_server.c" {
    style: { fill: "#BBDEFB"; stroke: "#1565C0"; border-radius: 4; font-size: 10 }
  }
  conn_state_m1: "conn_state_t — Per-Connection State Array" {
    class: struct_box
    layout: |c
      /* reactor_core.h — indexed by fd value */
      /* global: conn_state_t connections[MAX_FDS=65536] */
      /* RSS at 10K conns: 10000 × 4112 ≈ 40 MB         */
      typedef struct {
        char     read_buf[4096]; /* +0x0000 4096B 1-page */
        uint32_t read_len;       /* +0x1000    4B */
        int      fd;             /* +0x1004    4B */
        bool     is_active;      /* +0x1008    1B */
        uint8_t  _pad[7];        /* +0x1009    7B */
      } conn_state_t;            /* total: 4112 bytes */
      /* Cache: read_buf[0..63] = 1 cache line (64B)    */
      /* Sequential fill → hardware prefetch friendly    */
    |
  }
  lt_loop: "Level-Triggered Event Loop" {
    class: fn_box
    code: |c
      /* echo_server.c — run_event_loop_lt() */
      /* LT CONTRACT: re-notified while data remains */
      void run_event_loop_lt(int epfd, int lfd) {
        struct epoll_event evs[MAX_EVENTS=1024];
        /* Stack: 1024×12 = 12KB — fits L1 cache */
        for(;;) {
          int n = epoll_wait(epfd, evs,
                             MAX_EVENTS, -1);
          /* -1 = block forever; EINTR → continue  */
          for(int i=0; i<n; i++) {
            int fd = evs[i].data.fd;
            uint32_t ev = evs[i].events;
            if(fd == lfd)
              handle_new_conn_lt(epfd, lfd);
            else if(ev & (EPOLLERR|EPOLLHUP))
              conn_close(epfd, fd);
            else if(ev & EPOLLIN)
              handle_read_lt(epfd, fd);
          }
        }
      }
      /* Registration: epoll_add(epfd, fd, EPOLLIN) */
      /* NO EPOLLET flag → Level-Triggered          */
    |
  }
  et_loop: "Edge-Triggered Event Loop" {
    class: fn_box
    code: |c
      /* echo_server.c — run_event_loop_et() */
      /* ET CONTRACT: fire ONCE per state change    */
      /* MUST drain until EAGAIN or data is lost!   */
      /* handle_read_et — DRAIN LOOP (mandatory)    */
      void handle_read_et(int epfd, int fd) {
        for(;;) {
          char buf[READ_BUF_SIZE=4096];
          ssize_t n = read(fd, buf, sizeof(buf));
          if(n > 0) {
            write(fd, buf, n); /* echo (M2 buffers) */
            /* continue: may be MORE data in buffer  */
          } else if(n == 0) {
            conn_close(epfd, fd); return; /* EOF     */
          } else {
            if(errno==EAGAIN||errno==EWOULDBLOCK)
              break; /* DRAINED — exit loop          */
            conn_close(epfd, fd); return; /* error   */
          }
        }
      }
      /* Registration: EPOLLIN | EPOLLET             */
      /* Accept loop: also drain until EAGAIN!        */
    |
  }
  lt_vs_et: "LT vs ET Comparison" {
    style: { fill: "#E1F5FE"; stroke: "#01579B"; border-radius: 4; font-size: 10 }
    table: |md
      | Property          | LT              | ET (EPOLLET)        |
      |-------------------|-----------------|---------------------|
      | Read discipline   | Single read OK  | Drain until EAGAIN  |
      | Accept discipline | One per event   | Loop until EAGAIN   |
      | Partial read bug  | Re-notified     | SILENT DATA LOSS    |
      | Kernel overhead   | Slightly higher | Slightly lower      |
      | Used by           | Node.js/libuv   | NGINX, Redis        |
      | Pitfall           | Extra wakeups   | Deadlock if not drained |
    |
  }
  m1_pitfalls: "M1 Critical Pitfalls" {
    style: { fill: "#FFEBEE"; stroke: "#C62828"; border-radius: 4; font-size: 10 }
    p: |md
      **P1** ET + single read → silent data loss (deadlock)
      **P2** ET listen socket, no accept loop → missed connections
      **P3** EAGAIN treated as error → spurious close
      **P4** Blocking listen socket → stall on RST race
      **P5** MAX_EVENTS too small → extra epoll_wait round-trips
    |
  }
}
# ═══════════════════════════════════════════════════════════
# LAYER 3 — M2: Write Buffer + Timer Management
# ═══════════════════════════════════════════════════════════
m2_layer: "M2: Write Buffering + Timer Management" {
  class: milestone
  style: {
    fill: "#F3E5F5"
    stroke: "#6A1B9A"
    stroke-width: 3
    border-radius: 8
    font-size: 13
    bold: true
  }
  m2_files: "Files: write_buffer.h / write_buffer.c / timer_heap.h / timer_heap.c" {
    style: { fill: "#E1BEE7"; stroke: "#4A148C"; border-radius: 4; font-size: 10 }
  }
  write_buf_struct: "write_buf_t — Dynamic Output Queue" {
    class: struct_box
    layout: |c
      /* write_buffer.h */
      /* Invariant: data[offset..offset+len] = unsent */
      typedef struct {
        char     *data;   /* +0x00 8B heap-alloc     */
        uint32_t  len;    /* +0x08 4B buffered bytes  */
        uint32_t  cap;    /* +0x0C 4B total capacity  */
        uint32_t  offset; /* +0x10 4B first unsent idx*/
        uint8_t   _pad[4];/* +0x14 4B alignment       */
      } write_buf_t;       /* total: 24 bytes          */
      #define WRITE_BUF_INIT  (4*1024)    /*   4 KB */
      #define WRITE_BUF_MAX (256*1024)    /* 256 KB */
      /* Compaction: if offset > cap/2 && len>0:    */
      /*   memmove(data, data+offset, len); offset=0 */
      /* Growth: doubling strategy — O(log N) realloc*/
    |
  }
  conn_state_m2: "conn_state_t (M2 Extended)" {
    class: struct_box
    layout: |c
      typedef struct {
        char      read_buf[4096]; /* +0x0000 4096B */
        write_buf_t wbuf;         /* +0x1000   24B */
        uint32_t  read_len;       /* +0x1018    4B */
        int       fd;             /* +0x101C    4B */
        bool      is_active;      /* +0x1020    1B */
        bool      epollout_armed; /* +0x1021    1B */
        uint8_t   _pad[2];        /* +0x1022    2B */
        int       timer_idx;      /* +0x1024    4B (-1=none) */
        uint64_t  timer_expiry;   /* +0x1028    8B abs ms    */
      } conn_state_t;             /* total: ≈4152 bytes       */
      /* 10K conns × 4152B ≈ 40.5 MB RSS                     */
      /* wbuf.data: separate heap alloc (on-demand)           */
    |
  }
  conn_write_fn: "conn_write() — Buffered Write Path" {
    class: fn_box
    code: |c
      /* write_buffer.c */
      /* Returns 0=queued/sent, -1=overflow(close conn) */
      int conn_write(int epfd, conn_state_t *c,
                     const char *data, uint32_t n) {
        /* If buffer non-empty, maintain order: append */
        if(!wbuf_is_empty(&c->wbuf)) {
          if(wbuf_append(&c->wbuf,data,n) < 0)
            return -1; /* WRITE_BUF_MAX exceeded */
          return conn_flush(epfd, c);
        }
        /* Fast path: direct write (no buffer copy)    */
        ssize_t sent = 0;
        while((uint32_t)sent < n) {
          ssize_t w = write(c->fd, data+sent, n-sent);
          if(w > 0) { sent += w; continue; }
          if(errno==EAGAIN||errno==EWOULDBLOCK) {
            /* Buffer full → queue remainder            */
            wbuf_append(&c->wbuf,data+sent,n-sent);
            if(!c->epollout_armed) {
              /* ARM EPOLLOUT — critical step           */
              struct epoll_event ev;
              ev.events = EPOLLIN|EPOLLOUT;
              ev.data.fd = c->fd;
              epoll_ctl(epfd,EPOLL_CTL_MOD,c->fd,&ev);
              c->epollout_armed = true;
            }
            return 0;
          }
          return -1; /* EPIPE, ECONNRESET etc */
        }
        return 0; /* fully sent on fast path */
      }
    |
  }
  conn_flush_fn: "conn_flush() — Drain on EPOLLOUT" {
    class: fn_box
    code: |c
      /* CALLED WHEN: EPOLLOUT fires                  */
      /* CRITICAL: deregister EPOLLOUT when empty!    */
      /* Without deregister → 100% CPU busy-loop      */
      int conn_flush(int epfd, conn_state_t *c) {
        while(!wbuf_is_empty(&c->wbuf)) {
          const char *p = c->wbuf.data+c->wbuf.offset;
          ssize_t w = write(c->fd, p, c->wbuf.len);
          if(w > 0) {
            wbuf_consume(&c->wbuf, (uint32_t)w);
            continue;
          }
          if(errno==EAGAIN||errno==EWOULDBLOCK)
            return 0; /* still full, stay armed       */
          return -1;  /* real error                   */
        }
        /* Buffer empty — DEREGISTER EPOLLOUT         */
        if(c->epollout_armed) {
          struct epoll_event ev;
          ev.events = EPOLLIN; /* read only            */
          ev.data.fd = c->fd;
          epoll_ctl(epfd,EPOLL_CTL_MOD,c->fd,&ev);
          c->epollout_armed = false; /* RESET FLAG     */
        }
        return 0;
      }
    |
  }
  timer_entry_struct: "timer_entry_t — Min-Heap Node" {
    class: struct_box
    layout: |c
      /* timer_heap.h */
      typedef struct {
        uint64_t expiry_ms; /* +0x00 8B abs monotonic */
        int      fd;        /* +0x08 4B owning conn   */
        uint8_t  _pad[4];   /* +0x0C 4B alignment     */
      } timer_entry_t;       /* total: 16 bytes        */
      /* Heap storage:                                 */
      static timer_entry_t timer_heap[65536];
      static int timer_heap_size = 0;
      /* Full heap: 65536×16 = 1MB → fits L2 cache    */
      /* Parent of i: (i-1)/2                          */
      /* Left child:  2i+1   Right child: 2i+2         */
      /* Top 3 levels (15 nodes=240B) → 4 cache lines  */
      #define IDLE_TIMEOUT_MS 30000  /* 30 seconds     */
    |
  }
  timer_ops: "Timer Heap Operations" {
    class: fn_box
    code: |c
      /* timer_heap.c — O(log N) all operations       */
      /* heap_swap: MUST update connections[fd].timer_idx */
      static void heap_swap(int i, int j) {
        timer_entry_t tmp = timer_heap[i];
        timer_heap[i] = timer_heap[j];
        timer_heap[j] = tmp;
        connections[timer_heap[i].fd].timer_idx = i;
        connections[timer_heap[j].fd].timer_idx = j;
      }
      /* timer_set(fd, expiry_ms): insert/reset        */
      /* timer_cancel(fd): O(1) lookup via timer_idx   */
      /*   swap with last, sift_up+sift_down           */
      /* timer_next_ms() → int (for epoll_wait arg):   */
      int timer_next_ms(void) {
        if(timer_heap_size == 0) return -1;
        uint64_t now = now_ms(); /* vDSO ~30ns         */
        uint64_t exp = timer_heap[0].expiry_ms;
        if(exp <= now) return 0;
        uint64_t d = exp - now;
        return (d>INT_MAX) ? INT_MAX : (int)d;
      }
      /* timer_process_expired(epfd): while heap[0]<=now
         close connection, timer_cancel auto-called     */
    |
  }
  epollout_cycle: "EPOLLOUT Lifecycle (3-Step Cycle)" {
    style: { fill: "#EDE7F6"; stroke: "#4527A0"; border-radius: 4; font-size: 10 }
    desc: |md
      **Step 1 — Normal**: Only EPOLLIN registered. EPOLLOUT OFF.
      **Step 2 — write() EAGAIN**: Buffer remainder. epoll_ctl MOD → add EPOLLOUT. epollout_armed=true.
      **Step 3 — EPOLLOUT fires**: conn_flush(). If empty: epoll_ctl MOD → remove EPOLLOUT. epollout_armed=false.
      ⚠️ NEVER leave EPOLLOUT armed when buffer empty → 100% CPU spin
      ⚠️ write buffer overflow → close connection (slow loris defense)
    |
  }
  m2_pitfalls: "M2 Critical Pitfalls" {
    style: { fill: "#FFEBEE"; stroke: "#C62828"; border-radius: 4; font-size: 10 }
    p: |md
      **P1** EPOLLOUT armed when wbuf empty → CPU busy-loop
      **P2** Not processing all expired timers per tick → heap grows
      **P3** Missing timer_cancel in conn_close → use-after-free
      **P4** Closing conn without wbuf_free → memory leak (~4KB/conn)
      **P5** CLOCK_REALTIME for timers → NTP jump corrupts expiry
    |
  }
}
# ═══════════════════════════════════════════════════════════
# LAYER 4 — M3: Reactor API + Callback Dispatch
# ═══════════════════════════════════════════════════════════
m3_layer: "M3: Reactor API — Callback Dispatch + Safe Modification" {
  class: milestone
  style: {
    fill: "#E8EAF6"
    stroke: "#283593"
    stroke-width: 3
    border-radius: 8
    font-size: 13
    bold: true
  }
  m3_files: "Files: reactor.h / reactor_internal.h / reactor.c" {
    style: { fill: "#C5CAE9"; stroke: "#1A237E"; border-radius: 4; font-size: 10 }
  }
  reactor_api: "reactor.h — Public API (5 Functions)" {
    class: fn_box
    code: |c
      /* reactor.h — users NEVER touch epoll directly */
      typedef struct reactor reactor_t;
      /* Event flags (bitmask) */
      #define REACTOR_READABLE  (1u<<0)
      #define REACTOR_WRITABLE  (1u<<1)
      #define REACTOR_ERROR     (1u<<2)
      #define REACTOR_HANGUP    (1u<<3)
      /* Callback signatures */
      typedef void (*io_cb_fn)(int fd,
               uint32_t events, void *user_data);
      typedef void (*timer_cb_fn)(reactor_t *r,
               void *user_data);
      typedef void (*task_fn)(reactor_t *r,
               void *user_data);
      /* Lifecycle */
      reactor_t *reactor_create(void);   /* calloc */
      void       reactor_destroy(reactor_t *r);
      void       reactor_run(reactor_t *r);  /* blocks */
      void       reactor_stop(reactor_t *r); /* sets flag */
      /* I/O registration */
      int  reactor_register(reactor_t *r, int fd,
             uint32_t events, io_cb_fn cb, void *ud);
      void reactor_deregister(reactor_t *r, int fd);
      /* Timers */
      int  reactor_set_timeout(reactor_t *r, uint32_t ms,
             timer_cb_fn cb, void *ud);
      int  reactor_set_interval(reactor_t *r, uint32_t ms,
             timer_cb_fn cb, void *ud);
      void reactor_cancel_timer(reactor_t *r, int timer_id);
      /* Deferred tasks */
      void reactor_defer(reactor_t *r,
             task_fn fn, void *ud);
    |
  }
  fd_handler_struct: "fd_handler_t — Registration Record" {
    class: struct_box
    layout: |c
      /* reactor_internal.h */
      /* Array: fd_handler_t handlers[MAX_FDS=65536] */
      /* Size: 65536 × 24 = 1.5 MB                  */
      typedef struct {
        io_cb_fn callback;    /* +0x00 8B fn ptr    */
        void    *user_data;   /* +0x08 8B context   */
        uint32_t events;      /* +0x10 4B flags     */
        bool     is_registered;/* +0x14 1B liveness */
        bool     is_zombie;   /* +0x15 1B deferred-del*/
        uint8_t  _pad[2];     /* +0x16 2B alignment */
      } fd_handler_t;          /* total: 24 bytes   */
      /* data.ptr = &handlers[fd] in epoll_event    */
      /* Saves shl+add vs data.fd array lookup      */
      /* fd recovery: int fd = h - r->handlers;     */
    |
  }
  reactor_struct: "reactor_t — Internal State" {
    class: struct_box
    layout: |c
      struct reactor {
        int        epoll_fd;      /* kernel instance  */
        bool       is_running;    /* loop control     */
        bool       is_dispatching;/* guard flag       */
        uint8_t    _pad[2];
        fd_handler_t *handlers;   /* [65536] = 1.5MB  */
        timer_node_t *timer_heap; /* min-heap array   */
        deferred_mod_t *mod_queue;/* epoll_ctl queue  */
        deferred_task_t *task_queue; /* post-dispatch  */
        uint32_t timer_count;
        uint32_t mod_count;
        uint32_t task_count;
        int      next_timer_id;
      };
    |
  }
  reactor_run_fn: "reactor_run() — Main Dispatch Loop" {
    class: fn_box
    code: |c
      void reactor_run(reactor_t *r) {
        struct epoll_event evs[MAX_EVENTS];
        r->is_running = true;
        while(r->is_running) {
          /* 1. Compute timeout from timer heap       */
          int timeout = reactor_next_timeout(r);
          /* 2. Wait for I/O (blocks CPU efficiently) */
          int n = epoll_wait(r->epoll_fd, evs,
                             MAX_EVENTS, timeout);
          if(n < 0) {
            if(errno==EINTR) continue;
            break;
          }
          /* 3. TIMERS FIRST (time-sensitive)         */
          reactor_process_timers(r);
          /* 4. I/O DISPATCH — set guard flag         */
          r->is_dispatching = true;
          for(int i=0; i<n; i++) {
            fd_handler_t *h =
              (fd_handler_t*)evs[i].data.ptr;
            /* ZOMBIE CHECK — skip deregistered fds  */
            if(h->is_zombie || !h->is_registered)
              continue;
            uint32_t rv = map_epoll_to_reactor(
                            evs[i].events);
            int fd = (int)(h - r->handlers);
            h->callback(fd, rv, h->user_data);
          }
          r->is_dispatching = false;
          /* 5. Apply deferred epoll_ctl ops          */
          process_mod_queue(r);
          /* 6. Run deferred tasks (snapshot)         */
          reactor_run_deferred(r);
        }
      }
    |
  }
  zombie_mechanism: "Zombie + Deferred Mod — Use-After-Free Defense" {
    class: fn_box
    code: |c
      /* THE BUG: fd closed mid-dispatch → fd reused  */
      /* epoll_wait returned 8 events, processing [2] */
      /* callback closes fd=7, kernel reuses fd=7     */
      /* event [5] dispatches to NEW connection → UB  */
      void reactor_deregister(reactor_t *r, int fd) {
        fd_handler_t *h = &r->handlers[fd];
        if(!h->is_registered) return;
        if(r->is_dispatching) {
          /* CANNOT call epoll_ctl now safely          */
          h->is_zombie = true;    /* skip in loop     */
          enqueue_mod(r, MOD_DEL, fd, 0); /* deferred */
        } else {
          h->is_registered = false;
          h->is_zombie = false;
          epoll_ctl(r->epoll_fd,
                    EPOLL_CTL_DEL, fd, NULL);
        }
      }
      void reactor_register(reactor_t *r, int fd,
             uint32_t events, io_cb_fn cb, void *ud) {
        fd_handler_t *h = &r->handlers[fd];
        h->callback = cb;
        h->user_data = ud;
        h->events = events;
        h->is_registered = true;
        h->is_zombie = false; /* CLEAR zombie on re-reg */
        if(r->is_dispatching)
          enqueue_mod(r, was_reg?MOD_MOD:MOD_ADD, fd,
                      map_to_epoll(events));
        else
          /* direct epoll_ctl */;
      }
    |
  }
  deferred_task_fn: "reactor_defer() — Post-Dispatch Tasks" {
    class: fn_box
    code: |c
      /* Appends to task_queue. Runs AFTER all I/O    */
      /* in current batch. Before next epoll_wait.    */
      void reactor_defer(reactor_t *r,
                         task_fn fn, void *ud) {
        /* grow task_queue if needed (doubling)        */
        r->task_queue[r->task_count++] =
          (deferred_task_t){fn, ud};
      }
      /* Execution (snapshot prevents infinite loop): */
      static void reactor_run_deferred(reactor_t *r) {
        int count = r->task_count; /* snapshot         */
        r->task_count = 0;
        deferred_task_t *tasks = r->task_queue;
        /* swap to new buf so re-entrant defers work   */
        r->task_queue = malloc(...);
        for(int i=0; i<count; i++)
          tasks[i].fn(r, tasks[i].user_data);
        free(tasks);
      }
      /* USE CASE: close conn safely from callback     */
      /* reactor_defer(r, conn_close_deferred, conn);  */
    |
  }
  m3_tick_order: "Reactor Tick Ordering (Invariants)" {
    style: { fill: "#E8EAF6"; stroke: "#3949AB"; border-radius: 4; font-size: 10 }
    desc: |md
      **Tick Order (MANDATORY)**:
      1. `timer_next_ms()` → epoll_wait timeout
      2. `epoll_wait()` returns
      3. `reactor_process_timers()` — fires expired callbacks
      4. `is_dispatching = true` → iterate events, skip zombies
      5. `is_dispatching = false`
      6. `process_mod_queue()` → apply deferred epoll_ctl ops
      7. `reactor_run_deferred()` → run post-dispatch tasks
      8. Loop → next epoll_wait
      **Guarantees**: No fd reuse bugs | Deferred tasks see full event state
    |
  }
  m3_pitfalls: "M3 Critical Pitfalls" {
    style: { fill: "#FFEBEE"; stroke: "#C62828"; border-radius: 4; font-size: 10 }
    p: |md
      **P1** Modifying handler table during dispatch → UB, wrong callbacks
      **P2** Deferred tasks running inside I/O loop → sees partial state
      **P3** Interval timer cancels itself → heap corruption
      **P4** Not clearing zombie on re-registration → callback never fires
      **P5** EPOLLHUP without reading remaining data → dropped requests
    |
  }
}
# ═══════════════════════════════════════════════════════════
# LAYER 5 — M4: HTTP/1.1 Server
# ═══════════════════════════════════════════════════════════
m4_layer: "M4: HTTP/1.1 Static File Server — C10K" {
  class: milestone
  style: {
    fill: "#E0F2F1"
    stroke: "#004D40"
    stroke-width: 3
    border-radius: 8
    font-size: 13
    bold: true
  }
  m4_files: "Files: http_server.h / http_parser.c / http_core.c / http_connection.c / main.c" {
    style: { fill: "#B2DFDB"; stroke: "#00695C"; border-radius: 4; font-size: 10 }
  }
  http_state_enum: "conn_http_state — Protocol State Machine" {
    class: struct_box
    layout: |c
      /* http_server.h */
      typedef enum {
        HTTP_READING_HEADERS  = 0, /* scan for \r\n\r\n  */
        HTTP_READING_BODY     = 1, /* accumulate body    */
        HTTP_PROCESSING       = 2, /* generate response  */
        HTTP_WRITING_RESPONSE = 3, /* flush to wbuf      */
        HTTP_CLOSING          = 4, /* close after flush  */
      } conn_http_state;
      /* VALID TRANSITIONS:
       * READING_HEADERS → READING_BODY (if body)
       * READING_HEADERS → PROCESSING   (GET)
       * READING_BODY    → PROCESSING
       * PROCESSING      → WRITING_RESPONSE
       * WRITING_RESPONSE→ READING_HEADERS (keep-alive)
       * WRITING_RESPONSE→ CLOSING (Connection: close)
       * ANY             → CLOSING (error)
       */
    |
  }
  http_request_struct: "http_request_t — Parsed Request" {
    class: struct_box
    layout: |c
      typedef struct {
        char     method[10];   /* +0x000 10B "GET","HEAD"*/
        char     path[1024];   /* +0x00A 1024B URL path  */
        uint64_t content_length;/*+0x40A  8B body size   */
        uint64_t body_received; /*+0x412  8B bytes rcvd  */
        bool     keep_alive;   /* +0x41A  1B HTTP/1.1 dflt*/
        bool     is_complete;  /* +0x41B  1B parser flag */
      } http_request_t;        /* ≈ 1056 bytes total     */
    |
  }
  http_conn_struct: "http_conn_t — Connection Context (user_data)" {
    class: struct_box
    layout: |c
      /* http_connection.c — passed as void* user_data */
      /* calloc(1, sizeof(http_conn_t)) per connection  */
      typedef struct {
        char          read_buf[16384]; /*+0x0000 16KB   */
        write_buf_t   wbuf;            /*+0x4000 24B    */
        http_request_t req;            /*+0x4018 1056B  */
        uint32_t      read_pos;        /*+0x4438 4B     */
        int           fd;              /*+0x443C 4B     */
        conn_http_state state;         /*+0x4440 4B     */
        int           timer_id;        /*+0x4444 4B -1=none*/
        uint8_t       _pad[4];         /*+0x4448 4B     */
        reactor_t    *reactor_ref;     /*+0x4450 8B ptr */
      } http_conn_t;                   /* ≈ 17.5 KB     */
      /* 10K conns × 17.5KB ≈ 175 MB RSS               */
      /* read_buf=16KB covers typical HTTP headers       */
      /* (RFC 7230 allows servers to reject >16KB)       */
    |
  }
  http_parser: "http_parse_incremental() — State Machine Parser" {
    class: fn_box
    code: |c
      /* http_parser.c — INCREMENTAL: call after each read() */
      /* TCP delivers: partial headers across N reads         */
      /*   read1: "GET /index.html HTTP/1.1\r\nHost: exa"    */
      /*   read2: "mple.com\r\nConnection: keep-alive\r\n"   */
      /*   read3: "\r\n"   ← find_header_end fires here      */
      typedef enum {
        PARSE_OK=0, PARSE_AGAIN=-1, PARSE_ERROR=-2
      } parse_result_t;
      /* find_header_end: linear scan for \r\n\r\n           */
      /* Hardware prefetcher loads upcoming cache lines       */
      /* Production: SIMD _mm_cmpeq_epi8 scans 16B/2 cycles  */
      static int find_header_end(const char *buf, uint32_t n){
        if(n < 4) return -1;
        for(uint32_t i=0; i<=n-4; i++)
          if(buf[i]=='\r'&&buf[i+1]=='\n'&&
             buf[i+2]=='\r'&&buf[i+3]=='\n')
            return (int)(i+4);
        return -1;
      }
      parse_result_t http_parse_incremental(
                         http_conn_t *conn) {
        int end = find_header_end(conn->read_buf,
                                   conn->read_pos);
        if(end < 0) {
          if(conn->read_pos >= sizeof(conn->read_buf))
            return PARSE_ERROR; /* 413 Too Large  */
          return PARSE_AGAIN;   /* need more bytes */
        }
        /* Parse request line + header fields        */
        parse_request_line(...);
        parse_header_fields(...); /* Content-Length, Connection */
        /* memmove body bytes to front of read_buf  */
        uint32_t rem = conn->read_pos - (uint32_t)end;
        memmove(conn->read_buf,
                conn->read_buf+end, rem);
        conn->read_pos = rem;
        return PARSE_OK;
      }
    |
  }
  http_on_readable: "http_on_readable() — Read + Parse Loop" {
    class: fn_box
    code: |c
      /* http_core.c — registered with reactor as io_cb_fn */
      static void http_on_readable(int fd,
               uint32_t events, void *user_data) {
        http_conn_t *c = (http_conn_t*)user_data;
        reactor_t   *r = c->reactor_ref;
        if(events & (REACTOR_ERROR|REACTOR_HANGUP)) {
          reactor_defer(r, http_conn_close_deferred, c);
          return;
        }
        /* ET mode: drain until EAGAIN               */
        for(;;) {
          uint32_t space = sizeof(c->read_buf)
                           - c->read_pos;
          if(!space) {
            http_send_error(c, 413, "Too Large");
            return;
          }
          ssize_t n = read(fd,
                 c->read_buf+c->read_pos, space);
          if(n > 0) {
            c->read_pos += (uint32_t)n;
            /* Reset idle timer on each byte         */
            reactor_cancel_timer(r, c->timer_id);
            c->timer_id = reactor_set_timeout(r,
              IDLE_TIMEOUT_MS,
              http_idle_timeout_cb, c);
            /* TRY PARSE immediately (not at EAGAIN) */
            if(c->state == HTTP_READING_HEADERS) {
              parse_result_t pr =
                http_parse_incremental(c);
              if(pr == PARSE_ERROR) {
                http_send_error(c, 400, "Bad Request");
                return;
              }
              if(pr == PARSE_OK) {
                c->state = HTTP_PROCESSING;
                http_process_request(c);
              }
            }
          } else if(n == 0) {
            reactor_defer(r,
              http_conn_close_deferred, c);
            return;
          } else {
            if(errno==EAGAIN||errno==EWOULDBLOCK)
              break; /* ET drain complete             */
            reactor_defer(r,
              http_conn_close_deferred, c);
            return;
          }
        }
      }
    |
  }
  http_process_fn: "http_process_request() — File Serving" {
    class: fn_box
    code: |c
      /* http_core.c */
      static void http_process_request(http_conn_t *c){
        c->state = HTTP_WRITING_RESPONSE;
        /* Path sanitization (security-critical)       */
        char fpath[MAX_PATH+sizeof(STATIC_DIR)+16];
        if(build_safe_path(c->req.path,
                           fpath, sizeof(fpath))!=0){
          http_send_error(c, 400, "Bad Request");
          return;
        }
        /* REJECT any path containing ".."            */
        /* Never skip this → directory traversal vuln */
        struct stat st;
        if(stat(fpath,&st)!=0 || !S_ISREG(st.st_mode)){
          http_send_error(c, 404, "Not Found");
          return;
        }
        /* Build response headers → conn_write_buffered */
        char hdr[512];
        snprintf(hdr,sizeof(hdr),
          "HTTP/1.1 200 OK\r\n"
          "Content-Type: %s\r\n"
          "Content-Length: %lld\r\n"
          "Connection: %s\r\n\r\n",
          get_content_type(fpath),
          (long long)st.st_size,
          c->req.keep_alive?"keep-alive":"close");
        conn_write_buffered(c->reactor_ref, c,
                            hdr, strlen(hdr));
        /* Read file in 64KB chunks → wbuf            */
        /* Zero-copy opt: sendfile(2) — see KnowledgeCascade */
        int ffd = open(fpath, O_RDONLY|O_CLOEXEC);
        char fbuf[65536]; /* 64KB chunks              */
        ssize_t nr;
        while((nr=read(ffd,fbuf,sizeof(fbuf)))>0)
          conn_write_buffered(c->reactor_ref, c,
                               fbuf, (uint32_t)nr);
        close(ffd);
        /* Keep-alive: reset state machine            */
        if(c->req.keep_alive)
          http_conn_reset_for_keepalive(c);
        else
          c->state = HTTP_CLOSING;
      }
    |
  }
  http_conn_close: "http_conn_close_deferred() — Cleanup (ONLY valid close path)" {
    class: fn_box
    code: |c
      /* http_connection.c — ALWAYS call via reactor_defer */
      /* NEVER call close(fd) directly from I/O callback  */
      static void http_conn_close_deferred(
               reactor_t *r, void *arg) {
        http_conn_t *c = (http_conn_t*)arg;
        if(c->fd < 0) return; /* guard: double-close */
        /* MANDATORY ORDER:                            */
        /* 1. Cancel timer (prevents timer-after-free) */
        if(c->timer_id >= 0) {
          reactor_cancel_timer(r, c->timer_id);
          c->timer_id = -1;
        }
        /* 2. Deregister (epoll_ctl DEL)              */
        reactor_deregister(r, c->fd);
        /* 3. Free write buffer heap memory           */
        wbuf_free(&c->wbuf);
        /* 4. Close fd (kernel releases TCP state)    */
        close(c->fd);
        c->fd = -1;
        /* 5. Free struct                             */
        free(c);
      }
    |
  }
  m4_perf: "C10K Performance Targets" {
    style: { fill: "#E0F7FA"; stroke: "#006064"; border-radius: 4; font-size: 10 }
    targets: |md
      **Throughput**: 50,000–80,000 RPS @ 10K connections
      **p99 Latency**: < 100ms under wrk -c10000
      **Memory**: ~175 MB RSS @ 10K connections (17.5KB/conn)
      **CPU**: Single-threaded, should not exceed 1 core
      **Syscall**: epoll_wait + read + stat + open + write per request
      **Syscall cost**: ~200ns each → ~1ms total per request overhead
      **sendfile() opt**: eliminates 2× memcpy, saves ~30% CPU for files
      `ulimit -n 65536` REQUIRED before testing C10K
      `net.core.somaxconn=65535` for listen backlog
      `net.ipv4.tcp_tw_reuse=1` for TIME_WAIT reuse
    |
  }
  slow_loris: "Slow Loris Defense (Dual Timer)" {
    style: { fill: "#FFEBEE"; stroke: "#B71C1C"; border-radius: 4; font-size: 10 }
    desc: |md
      **Attack**: Client sends 1 byte/25s → parser never completes
      → holds 17.5KB + fd indefinitely → fd exhaustion
      **Defense 1**: IDLE_TIMEOUT_MS=30000 (reset on each read)
      **Defense 2**: MAX_HEADER_TIME_MS=60000 (absolute header deadline)
      **Defense 3**: WRITE_BUF_MAX=256KB (slow reader → close)
      conn_write returns -1 on overflow → caller must close connection
    |
  }
  m4_pitfalls: "M4 Critical Pitfalls" {
    style: { fill: "#FFEBEE"; stroke: "#C62828"; border-radius: 4; font-size: 10 }
    p: |md
      **P1** Expecting complete headers in 1 read() → fails at MTU boundary
      **P2** Write buffer growing unbounded for slow clients → OOM
      **P3** Keep-alive without resetting read_buf/req → stale data
      **P4** Path traversal (..) not rejected → /etc/passwd served
      **P5** Closing fd directly from callback → use-after-free
      **P6** Benchmarking without ulimit -n 65536 → EMFILE at conn 1025
    |
  }
}
# ═══════════════════════════════════════════════════════════
# CROSS-CUTTING — Scale Reference + Knowledge Cascade
# ═══════════════════════════════════════════════════════════
scale_ref: "Scale Reference Card" {
  style: {
    fill: "#FAFAFA"
    stroke: "#757575"
    stroke-width: 2
    border-radius: 6
    font-size: 10
  }
  table: |md
    | Object                        | Size           | Fits In   |
    |-------------------------------|----------------|-----------|
    | epoll_event struct            | 12 bytes       | 5×/cache line |
    | conn_state_t (M1)             | 4,112 bytes    | 64 cache lines |
    | conn_state_t (M2)             | 4,152 bytes    | 65 cache lines |
    | write_buf_t struct            | 24 bytes       | <1 cache line |
    | timer_entry_t                 | 16 bytes       | 4×/cache line |
    | fd_handler_t                  | 24 bytes       | 2×/cache line |
    | http_conn_t (M4)              | ~17,500 bytes  | ~274 cache lines |
    | handlers[65536] array         | 1.5 MB         | L2/L3 cache |
    | timer heap[65536]             | 1 MB (16B×65K) | L2 cache |
    | connections[65536] M1         | ~256 MB        | RAM only |
    | MAX_EVENTS=1024 events array  | 12 KB          | L1 cache |
    | TCP recv buffer default       | 87 KB          | kernel |
    | TCP send buffer default       | 87 KB          | kernel |
    | 10K conns M1 RSS              | ~40 MB         | L3+RAM |
    | 10K conns M4 RSS              | ~175 MB        | RAM |
  |
}
knowledge_cascade: "Knowledge Cascade — Real-World Connections" {
  style: {
    fill: "#F1F8E9"
    stroke: "#33691E"
    stroke-width: 2
    border-radius: 6
    font-size: 10
  }
  desc: |md
    **NGINX**: ET mode, drain discipline enforced by module API; ngx_handle_read_event()
    **Redis**: ae.c — same EPOLLOUT register-flush-deregister cycle; networking.c:writeToClient()
    **Node.js/libuv**: LT mode chosen deliberately; maintenance burden of ET drain too high
    **Go runtime**: netpoll_epoll.go — same epoll_wait timeout trick; time.go min-heap timers
    **io_uring** (Linux 5.1+): Proactor model; IORING_OP_READ submits op, completion fires when done
    **gRPC**: Length-prefix framing (5B header); same incremental parse discipline as HTTP
    **JS microtask queue**: reactor_defer ≡ Promise.then queue; runs after current task
    **Linux kernel bottom-half**: softirq ≡ reactor_defer; deferred from interrupt context
    **Game ECS**: Entity destroy during iteration ≡ zombie flag pattern (Flecs "deferred world")
    **Slow loris (2009)**: Exactly the accumulation window exploit you defend with dual timers
  |
}
# ═══════════════════════════════════════════════════════════
# DATA FLOW CONNECTIONS
# ═══════════════════════════════════════════════════════════
hw_layer.nic -> kernel_layer.tcp_stack: "TCP segment | 1-1500B | DMA write\nno CPU | NIC interrupt → NAPI" {
  style: { stroke: "#880E4F"; stroke-width: 2; animated: true; font-size: 10 }
}
kernel_layer.tcp_stack -> kernel_layer.epoll_instance: "sock_def_readable()\n→ epitem to rdllist\nO(1) insertion" {
  style: { stroke: "#1B5E20"; stroke-width: 2; font-size: 10 }
}
kernel_layer.epoll_instance -> m1_layer.lt_loop: "copy_to_user()\nevents[0..n-1]\n12KB array (L1-hot)" {
  style: { stroke: "#0D47A1"; stroke-width: 2; animated: true; font-size: 10 }
}
kernel_layer.epoll_instance -> m1_layer.et_loop: "copy_to_user()\nevents[0..n-1]\nFIRES ONCE per state change" {
  style: { stroke: "#0D47A1"; stroke-width: 2; animated: true; font-size: 10; stroke-dash: 4 }
}
kernel_layer.vdso -> m2_layer.timer_ops: "now_ms()\n~30ns vDSO\nCLOCK_MONOTONIC" {
  style: { stroke: "#4527A0"; stroke-width: 1; font-size: 10 }
}
m1_layer.conn_state_m1 -> m2_layer.conn_state_m2: "M1→M2: adds wbuf(24B)\nepollout_armed(1B)\ntimer_idx(4B)\ntimer_expiry(8B)" {
  style: { stroke: "#F57F17"; stroke-width: 2; font-size: 10 }
}
m2_layer.conn_write_fn -> m2_layer.conn_flush_fn: "EAGAIN path:\nwbuf_append(remaining)\nepoll_ctl MOD+EPOLLOUT" {
  style: { stroke: "#7B1FA2"; stroke-width: 2; animated: true; font-size: 10 }
}
m2_layer.conn_flush_fn -> kernel_layer.tcp_stack: "write(fd, ptr, n)\nkernel copies to\nsk_send_head → NIC DMA" {
  style: { stroke: "#1B5E20"; stroke-width: 2; font-size: 10 }
}
m2_layer.timer_ops -> m3_layer.reactor_run_fn: "timer_next_ms()\n→ epoll_wait timeout\ntick-less sleeping" {
  style: { stroke: "#283593"; stroke-width: 1; font-size: 10 }
}
m3_layer.reactor_api -> m3_layer.reactor_run_fn: "reactor_run() blocks\ncalls epoll_wait\ndispatches callbacks" {
  style: { stroke: "#283593"; stroke-width: 2; font-size: 10 }
}
m3_layer.fd_handler_struct -> m3_layer.zombie_mechanism: "is_zombie=true\nduring dispatch\nclears on re-register" {
  style: { stroke: "#283593"; stroke-width: 2; stroke-dash: 5; font-size: 10 }
}
m3_layer.zombie_mechanism -> m3_layer.deferred_task_fn: "MOD_DEL queued\napplied after loop\nreactor_defer for close" {
  style: { stroke: "#283593"; stroke-width: 2; font-size: 10 }
}
m3_layer.reactor_run_fn -> m4_layer.http_on_readable: "callback dispatch:\nfd_handler.callback(fd,\nevents, user_data)" {
  style: { stroke: "#004D40"; stroke-width: 2; animated: true; font-size: 10 }
}
m4_layer.http_on_readable -> m4_layer.http_parser: "read_buf[read_pos]\nread_pos += n\nparse after each read()" {
  style: { stroke: "#004D40"; stroke-width: 2; font-size: 10 }
}
m4_layer.http_parser -> m4_layer.http_process_fn: "PARSE_OK\nstate=HTTP_PROCESSING\nreq.method/path ready" {
  style: { stroke: "#004D40"; stroke-width: 2; font-size: 10 }
}
m4_layer.http_process_fn -> m2_layer.conn_write_fn: "conn_write_buffered()\nheaders: ~512B\nbody: file content" {
  style: { stroke: "#004D40"; stroke-width: 2; animated: true; font-size: 10 }
}
m4_layer.http_conn_close -> m3_layer.zombie_mechanism: "reactor_defer()\n→ deferred close\nnever direct close(fd)" {
  style: { stroke: "#C62828"; stroke-width: 2; stroke-dash: 5; font-size: 10 }
}
hw_layer.cpu_cache -> scale_ref: "Cache line=64B\nL1=32KB\nL2=256KB\nL3=8-32MB" {
  style: { stroke: "#880E4F"; stroke-width: 1; font-size: 9 }
}