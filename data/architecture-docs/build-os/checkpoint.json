{
  "project_id": "build-os",
  "meta": {
    "id": "build-os",
    "name": "Build Your Own OS",
    "description": "x86 operating system kernel with interrupts, memory management, and preemptive scheduling",
    "difficulty": "expert",
    "estimated_hours": "120-200",
    "essence": "Bootstrap from firmware to protected mode via GDT configuration, hardware interrupt handling through IDT and PIC/APIC, physical and virtual memory management with page tables and heap allocation, and preemptive process scheduling with context switching and user-mode transitions via TSS.\n",
    "why_important": "Building an OS kernel demystifies the abstraction layer between hardware and applications, teaching foundational systems concepts that underlie every modern computing platform \u2014 from interrupt handling to memory isolation to process scheduling.\n",
    "learning_outcomes": [
      "Implement a bootloader transitioning from real mode to 32-bit protected mode",
      "Configure GDT with proper segment descriptors for kernel and user mode",
      "Set up IDT and interrupt service routines for CPU exceptions and hardware IRQs",
      "Build physical memory allocators (bitmap or buddy)",
      "Implement virtual memory with page tables and demand paging",
      "Create process control blocks and preemptive context switching",
      "Set up TSS for ring 3 \u2192 ring 0 transitions",
      "Implement system call interface via software interrupts",
      "Debug with QEMU, serial port logging, and GDB stubs"
    ],
    "skills": [
      "x86 Assembly",
      "Hardware Interrupts (PIC, APIC)",
      "GDT/IDT/TSS Configuration",
      "Page Table Management",
      "Context Switching",
      "Kernel Programming (freestanding)",
      "Low-Level Debugging",
      "Linker Script Design"
    ],
    "tags": [
      "bootloader",
      "build-from-scratch",
      "c",
      "expert",
      "interrupts",
      "kernel",
      "rust",
      "scheduling",
      "systems",
      "zig"
    ],
    "architecture_doc": "architecture-docs/build-os/index.md",
    "languages": {
      "recommended": [
        "C",
        "Rust",
        "Zig"
      ],
      "also_possible": []
    },
    "resources": [
      {
        "type": "book",
        "name": "Operating Systems: Three Easy Pieces",
        "url": "https://pages.cs.wisc.edu/~remzi/OSTEP/"
      },
      {
        "type": "tutorial",
        "name": "Writing an OS in Rust (phil-opp)",
        "url": "https://os.phil-opp.com/"
      },
      {
        "type": "reference",
        "name": "OSDev Wiki",
        "url": "https://wiki.osdev.org/"
      },
      {
        "type": "reference",
        "name": "Intel Software Developer Manuals",
        "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html"
      }
    ],
    "prerequisites": [
      {
        "type": "skill",
        "name": "x86 assembly language (AT&T or NASM syntax)"
      },
      {
        "type": "skill",
        "name": "C programming (freestanding, no stdlib)"
      },
      {
        "type": "skill",
        "name": "Computer architecture (registers, stack, memory bus)"
      },
      {
        "type": "skill",
        "name": "Binary and hexadecimal arithmetic"
      }
    ],
    "milestones": [
      {
        "id": "build-os-m1",
        "name": "Bootloader, GDT, and Kernel Entry",
        "description": "Boot from BIOS, configure the GDT for protected mode, load the kernel into memory, and transfer control to kernel C code.\n",
        "acceptance_criteria": [
          "Bootloader code fits within MBR constraints (512 bytes with 0x55AA signature at bytes 510-511) or implements two-stage loading",
          "Bootloader reads kernel binary from disk using BIOS INT 13h and loads it to physical address 0x100000 (1MB mark)",
          "A20 line is successfully enabled using at least one method (BIOS INT 15h/2401, fast A20 via port 0x92, or keyboard controller)",
          "GDT is configured with exactly 5 entries: null descriptor (index 0), kernel code segment (ring 0, base=0, limit=4GB, executable+readable), kernel data segment (ring 0, base=0, limit=4GB, writable), user code segment (ring 3), user data segment (ring 3)",
          "GDTR is loaded with lgdt instruction before setting CR0.PE",
          "Protected mode is entered by setting CR0.PE bit (bit 0 of CR0) to 1",
          "Far jump (jmp 0x08:label) is executed after CR0.PE is set to load CS with kernel code selector and flush the instruction pipeline",
          "All data segment registers (DS, ES, FS, GS, SS) are loaded with kernel data selector (0x10) after protected mode entry",
          "32-bit stack pointer (ESP) is initialized to a valid memory region below 1MB or above kernel load address",
          "Kernel entry point (in assembly) zeroes the BSS section from __bss_start to __bss_end as defined in linker script",
          "C entry point function is called with proper stack alignment and direction flag cleared (cld)",
          "VGA text mode driver writes characters with color attributes to memory-mapped buffer at 0xB8000",
          "Serial port COM1 (0x3F8) is initialized with 115200 baud, 8N1 configuration",
          "kprintf-style function supports basic format specifiers (%c, %s, %d, %x, %p) and outputs to both VGA and serial",
          "Linker script places .text section at 0x100000 with proper section alignment (4KB page-aligned sections)",
          "Kernel boots successfully in QEMU and displays welcome message on both VGA console and serial output",
          "Build system produces valid bootable disk image with bootloader in sector 0 and kernel starting at sector 2"
        ],
        "pitfalls": [
          "GDT misconfiguration is the #1 cause of triple-faults; verify base=0, limit=0xFFFFF, granularity=4KB, and correct access bytes for each segment",
          "Forgetting the far jump after setting CR0.PE leaves the CPU in an inconsistent state with real-mode CS",
          "Not disabling interrupts (cli) before loading GDT and entering protected mode; stale IVT entries cause immediate faults",
          "Linker script must place kernel at the correct virtual/physical address; mismatch causes garbage execution",
          "BSS is not guaranteed to be zero on bare metal; zeroing it is the kernel's responsibility (no CRT0)",
          "A20 line must be enabled for addresses above 1MB; on some hardware it's disabled by default"
        ],
        "concepts": [
          "x86 boot process (BIOS \u2192 MBR \u2192 kernel)",
          "Global Descriptor Table and segmentation",
          "Real mode \u2192 protected mode transition",
          "Freestanding C environment"
        ],
        "skills": [
          "x86 assembly for boot code",
          "GDT configuration",
          "Linker script design",
          "Serial port I/O",
          "VGA text mode"
        ],
        "deliverables": [
          "Bootloader (stage1 + optional stage2) loading kernel from disk",
          "GDT with null, kernel code, kernel data, user code, user data descriptors",
          "Protected mode transition with far jump and segment register reload",
          "BSS zeroing and C entry point",
          "VGA text mode driver with color support",
          "Serial port debug output driver",
          "Linker script placing kernel sections at correct addresses"
        ],
        "estimated_hours": "20-30"
      },
      {
        "id": "build-os-m2",
        "name": "Interrupts, Exceptions, and Keyboard",
        "description": "Set up the IDT, PIC, interrupt handlers for CPU exceptions and hardware IRQs, and a PS/2 keyboard driver.\n",
        "acceptance_criteria": [
          "IDT contains 256 entries; entries 0-31 handle CPU exceptions (divide error, page fault, GPF, etc.) with descriptive error messages",
          "Interrupt handlers save all general-purpose registers on entry and restore them before iret; error code is popped for exceptions that push one",
          "PIC (8259) is remapped so IRQ0-7 map to vectors 32-39 and IRQ8-15 map to vectors 40-47, avoiding conflicts with CPU exception vectors 0-31",
          "EOI (End of Interrupt) is sent to the correct PIC (master or slave) at the end of each IRQ handler",
          "Timer interrupt (IRQ0, PIT channel 0) fires at a configurable frequency (e.g., 100Hz); a global tick counter is incremented on each interrupt",
          "Keyboard interrupt (IRQ1) reads PS/2 scancode from port 0x60 and converts to ASCII using a scancode-to-ASCII table; characters are placed in a keyboard buffer",
          "Double fault (exception 8) handler catches cascading faults and halts with a diagnostic message instead of triple-faulting",
          "Interrupts are enabled (sti) after IDT and PIC setup is complete",
          "IDT contains 256 entries with entries 0-31 configured for CPU exceptions including divide error, page fault, and general protection fault with descriptive error messages",
          "All interrupt handlers save general-purpose registers (pusha) and segment registers on entry and restore them before iret; handlers for exceptions 8, 10-14 account for the error code pushed by the CPU",
          "PIC 8259 is remapped so IRQ0-7 map to vectors 32-39 and IRQ8-15 map to vectors 40-47, avoiding conflicts with CPU exception vectors 0-31",
          "EOI is sent to the correct PIC (master for IRQ0-7, both master and slave for IRQ8-15) at the end of each IRQ handler before iret",
          "Timer interrupt (IRQ0 via PIT channel 0) fires at a configurable frequency (e.g., 100Hz) and increments a global tick counter on each interrupt",
          "Keyboard interrupt (IRQ1) reads PS/2 scancode from port 0x60, converts to ASCII using a scancode-to-ASCII table, and places characters in a circular keyboard buffer",
          "Double fault handler (exception 8) catches cascading faults, prints diagnostic information including error code, and halts the system instead of allowing a triple fault",
          "Interrupts are enabled (sti) only after IDT is loaded and PIC is remapped and configured"
        ],
        "pitfalls": [
          "Forgetting to send EOI causes the PIC to stop delivering interrupts; the system appears to hang",
          "PIC remapping: the default mapping overlaps CPU exceptions (IRQ0=vector 8=double fault); this must be remapped BEFORE enabling interrupts",
          "Not saving/restoring all registers in interrupt handlers causes mysterious register corruption in interrupted code",
          "Exceptions 8 (double fault), 10-14 push an error code; others don't; the handler must account for this or the stack frame is misaligned",
          "PS/2 keyboard sends make AND break codes; ignoring break codes causes repeated character issues"
        ],
        "concepts": [
          "Interrupt Descriptor Table",
          "Programmable Interrupt Controller (8259 PIC)",
          "CPU exception handling",
          "Hardware device drivers"
        ],
        "skills": [
          "IDT configuration",
          "PIC programming (ICW1-ICW4)",
          "Interrupt service routine development",
          "PS/2 keyboard protocol"
        ],
        "deliverables": [
          "IDT with 256 entries and proper gate types",
          "CPU exception handlers (0-31) with error messages",
          "PIC remapping and EOI handling",
          "PIT timer at configurable frequency with tick counter",
          "PS/2 keyboard driver with scancode-to-ASCII conversion",
          "Keyboard input buffer"
        ],
        "estimated_hours": "15-25"
      },
      {
        "id": "build-os-m3",
        "name": "Physical and Virtual Memory Management",
        "description": "Implement physical frame allocator, page tables for virtual memory, and a kernel heap allocator.\n",
        "acceptance_criteria": [
          "Physical memory map is obtained from multiboot info or E820 memory map; regions are classified as usable, reserved, or ACPI",
          "Physical frame allocator (bitmap or free-list) allocates and frees individual 4KB page frames; double-free and allocating reserved frames are prevented",
          "Page directory and page tables are set up for identity-mapping the first N MB (covering kernel + VGA + MMIO) and higher-half mapping the kernel (e.g., kernel at 0xC0000000 virtual)",
          "Paging is enabled by loading CR3 with the page directory physical address and setting CR0.PG bit",
          "TLB is flushed (invlpg or full CR3 reload) after modifying page table entries",
          "Page fault handler (exception 14) reads CR2 for faulting address and prints diagnostic info (address, error code: present/write/user)",
          "Kernel heap allocator (kmalloc/kfree) provides dynamic memory allocation from a dedicated virtual address range; uses the page allocator for backing frames",
          "Identity map is kept for low memory so VGA (0xB8000) and MMIO regions remain accessible at their physical addresses",
          "Physical memory map obtained from multiboot info or E820, with regions classified as usable/reserved/ACPI",
          "Physical frame allocator (bitmap or free-list) allocates and frees 4KB frames with double-free prevention",
          "Page directory and page tables configured for identity-mapping (kernel + VGA + MMIO) and higher-half kernel mapping (0xC0000000+)",
          "Paging enabled by loading CR3 with page directory physical address and setting CR0.PG bit",
          "TLB flushed with invlpg or CR3 reload after modifying page table entries",
          "Page fault handler reads CR2 for faulting address and prints diagnostic (address, error code bits for present/write/user)",
          "Kernel heap allocator (kmalloc/kfree) provides dynamic allocation from dedicated virtual range using page allocator for backing frames",
          "Identity map maintained for low memory so VGA (0xB8000) and MMIO regions remain accessible at physical addresses"
        ],
        "pitfalls": [
          "Enabling paging without identity-mapping the currently executing code causes an immediate page fault on the next instruction",
          "Not flushing the TLB after page table changes causes stale translations; invlpg flushes a single page, CR3 reload flushes all",
          "Page directory/table entries have specific flag bits (present, writable, user-accessible, write-through, cache-disable); wrong flags cause faults or security holes",
          "Physical frame allocator must not allocate frames used by the kernel binary, page tables, or multiboot data",
          "Higher-half kernel mapping requires the linker script to use virtual addresses while the boot code uses physical addresses until paging is on"
        ],
        "concepts": [
          "Physical memory allocation",
          {
            "x86 paging (two-level": "PD + PT on 32-bit)"
          },
          "Higher-half kernel mapping",
          "TLB management"
        ],
        "skills": [
          "Page table implementation",
          "Physical frame allocator",
          "CR3/CR0 register manipulation",
          "Kernel heap design"
        ],
        "deliverables": [
          "Memory map parser (E820 or multiboot)",
          "Physical frame allocator (bitmap-based)",
          "Page directory and page table setup",
          "Identity mapping + higher-half kernel mapping",
          "Paging enablement (CR0.PG + CR3)",
          "Page fault handler reading CR2",
          "Kernel heap allocator (kmalloc/kfree)"
        ],
        "estimated_hours": "30-45"
      },
      {
        "id": "build-os-m4",
        "name": "Processes and Preemptive Scheduling",
        "description": "Implement process control blocks, context switching, preemptive round-robin scheduling, TSS for ring transitions, and a basic system call interface.\n",
        "acceptance_criteria": [
          "Process control block (PCB) stores: PID, register state (EIP, ESP, EBP, general regs, EFLAGS), page directory pointer, process state (ready/running/blocked), and kernel stack pointer",
          "Context switch saves current process registers to its PCB and loads the next process's registers; implemented in assembly for correctness",
          "TSS (Task State Segment) is configured with the kernel stack pointer (SS0: ESP0) so the CPU knows which stack to use when transitioning from ring 3 to ring 0 on interrupt/syscall",
          "Timer interrupt (IRQ0) triggers the scheduler; scheduler selects the next ready process in round-robin order and performs a context switch",
          "At least 3 kernel-mode processes run concurrently, each printing to a different screen region, demonstrating preemptive multitasking",
          "User-mode processes: at least one process runs in ring 3 with its own page directory; accessing kernel memory from user mode triggers a page fault (user-bit not set)",
          "System call interface via INT 0x80: user-mode process triggers a software interrupt; kernel reads syscall number from EAX and arguments from EBX/ECX/EDX; at minimum implement sys_write and sys_exit",
          "TSS ESP0 is updated on every context switch to point to the current process's kernel stack top",
          "Process control block (PCB) stores PID, register state (EIP, ESP, EBP, general-purpose registers, EFLAGS), page directory pointer, process state (ready/running/blocked), and kernel stack pointer",
          "Context switch saves current process registers to its PCB and loads the next process's registers using assembly implementation for correctness",
          "TSS (Task State Segment) is configured with kernel stack pointer (SS0:ESP0) so the CPU knows which stack to use for ring 3 \u2192 ring 0 transitions",
          "Timer interrupt (IRQ0) triggers the scheduler which selects the next ready process in round-robin order and performs context switch",
          "User-mode processes run in ring 3 with their own page directory; accessing kernel memory triggers page fault due to supervisor-only bit",
          "System call interface via INT 0x80: kernel reads syscall number from EAX and arguments from EBX/ECX/EDX, implementing sys_write and sys_exit at minimum"
        ],
        "pitfalls": [
          "Context switch must save ALL registers including EFLAGS; missing a register causes subtle corruption that manifests much later",
          "TSS is required for ring 3 \u2192 ring 0 transitions; without it, the CPU doesn't know what kernel stack to use and triple-faults",
          "Stack corruption during context switch: each process needs its own kernel stack; reusing the same stack corrupts saved state",
          "Preemptive scheduling requires re-enabling interrupts after the context switch or the system freezes",
          "Not disabling interrupts during critical sections of the context switch causes nested interrupts and stack overflow",
          "User-mode processes need their own page directory with kernel pages mapped but marked supervisor-only"
        ],
        "concepts": [
          "Process control blocks",
          "Context switching (register save/restore)",
          "Preemptive scheduling with timer interrupts",
          "Task State Segment for privilege transitions",
          "System call interface"
        ],
        "skills": [
          "Context switch assembly",
          "TSS configuration",
          "Scheduler design",
          "Ring 0/Ring 3 transitions",
          "System call dispatch"
        ],
        "deliverables": [
          "Process control block structure",
          "Context switch routine (assembly)",
          "TSS setup and per-process ESP0 update",
          "Round-robin scheduler triggered by timer interrupt",
          "Kernel-mode multi-process demo",
          "User-mode process with ring 3 segments",
          "System call handler (INT 0x80) with sys_write and sys_exit"
        ],
        "estimated_hours": "35-55"
      }
    ],
    "domain": "systems"
  },
  "blueprint": {
    "title": "Build Your Own OS",
    "overview": "This project constructs an x86 operating system kernel from bare metal firmware through protected mode, hardware interrupt handling, virtual memory management, and preemptive multitasking with user-mode isolation. Starting from the very first byte the BIOS loads off disk, the learner will implement every layer that modern operating systems hide: the GDT that defines segmentation, the IDT that routes interrupts, the page tables that virtualize memory, and the TSS that enables privilege transitions. By the end, multiple user-mode processes will run concurrently under a preemptive round-robin scheduler, issuing system calls through INT 0x80.\n\nThe project is structured as four milestones that mirror the actual dependency chain of an x86 kernel: you cannot handle interrupts without a GDT, cannot manage memory without interrupt handlers for page faults, and cannot schedule processes without both memory isolation and timer interrupts. Each milestone builds precisely on the hardware mechanisms established in the previous one, creating a layered system where every abstraction is one the learner built themselves.\n\nThis is an expert-level, 120-200 hour endeavor in freestanding C (or Rust/Zig) and x86 assembly. The learner will debug triple-faults with QEMU and GDB, read Intel SDM entries for obscure register bits, and develop an intimate understanding of the contract between software and the x86 hardware platform.",
    "design_philosophy": "An operating system is the ultimate negotiation between software abstractions and hardware constraints. Every design decision \u2014 from GDT segment granularity to page table entry flags to TSS stack pointers \u2014 exists because the x86 CPU physically requires specific data structures at specific addresses with specific bit layouts before it will perform a privilege transition, translate a virtual address, or route an interrupt. This project teaches by forcing the learner to satisfy the CPU's requirements byte by byte, revealing that the 'magic' of modern OSes is actually an intricate but deterministic conversation with silicon. The atlas is structured to show not just what to build, but why the hardware demands it \u2014 connecting each software structure back to the CPU microarchitecture that consumes it.",
    "is_build_your_own": true,
    "prerequisites": {
      "assumed_known": [
        "x86 assembly language (AT&T or NASM syntax) \u2014 register operations, stack manipulation, addressing modes",
        "C programming in freestanding environments \u2014 no stdlib, manual memory management, volatile qualifiers",
        "Computer architecture fundamentals \u2014 registers, ALU, stack pointer, memory bus, instruction fetch cycle",
        "Binary and hexadecimal arithmetic \u2014 bit masking, shifting, two's complement",
        "Basic understanding of what an OS does from a user perspective (processes, files, memory)"
      ],
      "must_teach_first": [
        {
          "concept": "x86 privilege rings (ring 0 vs ring 3)",
          "depth": "intermediate",
          "when": "Milestone 1"
        },
        {
          "concept": "Segment descriptors and the flat memory model",
          "depth": "detailed",
          "when": "Milestone 1"
        },
        {
          "concept": "Real mode vs protected mode execution environment",
          "depth": "detailed",
          "when": "Milestone 1"
        },
        {
          "concept": "Interrupt descriptor types (trap gate, interrupt gate, task gate)",
          "depth": "intermediate",
          "when": "Milestone 2"
        },
        {
          "concept": "x86 two-level paging (PDE \u2192 PTE \u2192 physical frame)",
          "depth": "detailed",
          "when": "Milestone 3"
        },
        {
          "concept": "Hardware-enforced stack switching on privilege change",
          "depth": "detailed",
          "when": "Milestone 4"
        },
        {
          "concept": "Linker scripts for bare-metal \u2014 sections, VMA vs LMA",
          "depth": "basic",
          "when": "Milestone 1"
        }
      ]
    },
    "milestones": [
      {
        "id": "build-os-m1",
        "title": "Bootloader, GDT, and Kernel Entry",
        "anchor_id": "anchor-m1-bootloader-gdt",
        "summary": "Boot from BIOS, enable the A20 line, configure a 5-entry GDT for flat segmentation, transition from 16-bit real mode to 32-bit protected mode via CR0.PE and a far jump, load the kernel from disk to the 1MB mark, zero BSS, initialize VGA text mode and serial output, and call the C entry point. This milestone establishes the execution environment that every subsequent milestone depends on.",
        "misconception": "Developers assume protected mode is just 'bigger registers' \u2014 that switching from real mode to protected mode is like flipping a feature flag, and the CPU otherwise behaves the same way. They expect the transition to be: set a bit, done.",
        "reveal": "Protected mode is an entirely different CPU personality. The moment CR0.PE is set, every memory access is mediated through the GDT's segment descriptors. The instruction currently being fetched is still using a real-mode CS value \u2014 the CPU is in a schizophrenic half-state where the pipeline holds real-mode decoded instructions but the memory subsystem expects protected-mode segments. The far jump isn't a 'nice to have'; it's the only way to atomically load CS with a valid protected-mode selector and flush the prefetch queue. Without it, the very next instruction may decode against stale segment state and triple-fault. The GDT isn't configuration \u2014 it's the CPU's runtime data structure that it reads on every single memory access.",
        "cascade": [
          "Segment selectors \u2014 understanding that CS/DS/SS are indices into the GDT (not addresses) unlocks how ring 0 vs ring 3 isolation actually works at the hardware level",
          "Linker scripts (cross-domain: compiler toolchains) \u2014 VMA vs LMA distinction becomes obvious once you realize boot code runs at physical addresses but the kernel is linked at virtual addresses; this same concept appears in embedded firmware, PIC shared libraries, and UEFI applications",
          "CPU pipeline flush \u2014 the far jump requirement reveals that the x86 pipeline can hold inconsistent state, which connects to branch prediction, speculative execution, and even Spectre/Meltdown mitigations",
          "A20 line legacy \u2014 understanding the physical address wrapping of the 8086 connects to how backward compatibility constraints shape modern CPU design, similar to how UTF-8's design was constrained by ASCII compatibility",
          "Freestanding C runtime \u2014 realizing there's no CRT0 to zero BSS connects to how Go/Rust runtimes, JVM class loading, and even JavaScript engine initialization all bootstrap their own execution environments"
        ],
        "yaml_acceptance_criteria": [
          "Bootloader code fits within MBR constraints (512 bytes with 0x55AA signature at bytes 510-511) or implements two-stage loading",
          "Bootloader reads kernel binary from disk using BIOS INT 13h and loads it to physical address 0x100000 (1MB mark)",
          "A20 line is successfully enabled using at least one method (BIOS INT 15h/2401, fast A20 via port 0x92, or keyboard controller)",
          "GDT is configured with exactly 5 entries: null descriptor (index 0), kernel code segment (ring 0, base=0, limit=4GB, executable+readable), kernel data segment (ring 0, base=0, limit=4GB, writable), user code segment (ring 3), user data segment (ring 3)",
          "GDTR is loaded with lgdt instruction before setting CR0.PE",
          "Protected mode is entered by setting CR0.PE bit (bit 0 of CR0) to 1",
          "Far jump (jmp 0x08:label) is executed after CR0.PE is set to load CS with kernel code selector and flush the instruction pipeline",
          "All data segment registers (DS, ES, FS, GS, SS) are loaded with kernel data selector (0x10) after protected mode entry",
          "32-bit stack pointer (ESP) is initialized to a valid memory region below 1MB or above kernel load address",
          "Kernel entry point (in assembly) zeroes the BSS section from __bss_start to __bss_end as defined in linker script",
          "C entry point function is called with proper stack alignment and direction flag cleared (cld)",
          "VGA text mode driver writes characters with color attributes to memory-mapped buffer at 0xB8000",
          "Serial port COM1 (0x3F8) is initialized with 115200 baud, 8N1 configuration",
          "kprintf-style function supports basic format specifiers (%c, %s, %d, %x, %p) and outputs to both VGA and serial",
          "Linker script places .text section at 0x100000 with proper section alignment (4KB page-aligned sections)",
          "Kernel boots successfully in QEMU and displays welcome message on both VGA console and serial output",
          "Build system produces valid bootable disk image with bootloader in sector 0 and kernel starting at sector 2"
        ]
      },
      {
        "id": "build-os-m2",
        "title": "Interrupts, Exceptions, and Keyboard",
        "anchor_id": "anchor-m2-interrupts",
        "summary": "Set up the 256-entry IDT with proper gate descriptors, implement CPU exception handlers for vectors 0-31 (including the critical double fault handler), remap the 8259 PIC so hardware IRQs don't collide with CPU exceptions, implement PIT timer interrupts at 100Hz with a global tick counter, and build a PS/2 keyboard driver that converts scancodes to ASCII and buffers input. This milestone gives the kernel the ability to respond to hardware events \u2014 the foundation for everything from scheduling to I/O.",
        "misconception": "Developers think interrupts are like callbacks or event handlers in application programming \u2014 that they're just functions the OS 'registers' and the hardware 'calls' when something happens. They assume the CPU handles the mechanics of saving state, switching context, and returning cleanly.",
        "reveal": "The CPU does almost nothing automatically on interrupt entry beyond pushing 5 values (SS, ESP, EFLAGS, CS, EIP \u2014 and only SS/ESP if there's a privilege change) and optionally an error code. Everything else is YOUR responsibility: saving general-purpose registers, saving segment registers, acknowledging the interrupt controller (EOI), and restoring everything in exact reverse order. The error code asymmetry is particularly treacherous \u2014 exceptions 8, 10-14 push an error code but others don't, meaning your stack frame layout changes depending on which interrupt fired. If your handler assumes the wrong layout, it pops the error code as EIP and returns to a garbage address. Furthermore, the default PIC mapping puts IRQ0 at vector 8 \u2014 the same as the double fault exception \u2014 meaning a timer tick and a cascading CPU failure are literally indistinguishable until you remap the PIC.",
        "cascade": [
          "Interrupt latency and real-time systems \u2014 understanding the register save/restore overhead explains why RTOS kernels minimize ISR work and defer to bottom-half handlers, and why Linux has PREEMPT_RT patches",
          "EOI protocol and flow control (cross-domain: network protocols) \u2014 the PIC's EOI requirement is identical in concept to TCP ACKs: the sender (PIC) stops sending until the receiver (CPU) acknowledges, which is the same flow-control pattern used in USB, PCIe, and even HTTP/2 stream windowing",
          "Exception error codes and stack frame forensics \u2014 knowing that page faults (14) push an error code with present/write/user bits directly enables implementing demand paging, copy-on-write, and memory-mapped files in Milestone 3",
          "Circular buffer design \u2014 the keyboard buffer is a lock-free single-producer single-consumer ring buffer, the same structure used in io_uring, DPDK packet rings, and audio driver DMA buffers",
          "Double fault as a safety net \u2014 understanding exception 8 as the CPU's last-resort handler before triple-fault connects to watchdog timers, hardware NMI, and the broader concept of fail-safe hierarchies in distributed systems"
        ],
        "yaml_acceptance_criteria": [
          "IDT contains 256 entries; entries 0-31 handle CPU exceptions (divide error, page fault, GPF, etc.) with descriptive error messages",
          "Interrupt handlers save all general-purpose registers on entry and restore them before iret; error code is popped for exceptions that push one",
          "PIC (8259) is remapped so IRQ0-7 map to vectors 32-39 and IRQ8-15 map to vectors 40-47, avoiding conflicts with CPU exception vectors 0-31",
          "EOI (End of Interrupt) is sent to the correct PIC (master or slave) at the end of each IRQ handler",
          "Timer interrupt (IRQ0, PIT channel 0) fires at a configurable frequency (e.g., 100Hz); a global tick counter is incremented on each interrupt",
          "Keyboard interrupt (IRQ1) reads PS/2 scancode from port 0x60 and converts to ASCII using a scancode-to-ASCII table; characters are placed in a keyboard buffer",
          "Double fault (exception 8) handler catches cascading faults and halts with a diagnostic message instead of triple-faulting",
          "Interrupts are enabled (sti) after IDT and PIC setup is complete",
          "IDT contains 256 entries with entries 0-31 configured for CPU exceptions including divide error, page fault, and general protection fault with descriptive error messages",
          "All interrupt handlers save general-purpose registers (pusha) and segment registers on entry and restore them before iret; handlers for exceptions 8, 10-14 account for the error code pushed by the CPU",
          "PIC 8259 is remapped so IRQ0-7 map to vectors 32-39 and IRQ8-15 map to vectors 40-47, avoiding conflicts with CPU exception vectors 0-31",
          "EOI is sent to the correct PIC (master for IRQ0-7, both master and slave for IRQ8-15) at the end of each IRQ handler before iret",
          "Timer interrupt (IRQ0 via PIT channel 0) fires at a configurable frequency (e.g., 100Hz) and increments a global tick counter on each interrupt",
          "Keyboard interrupt (IRQ1) reads PS/2 scancode from port 0x60, converts to ASCII using a scancode-to-ASCII table, and places characters in a circular keyboard buffer",
          "Double fault handler (exception 8) catches cascading faults, prints diagnostic information including error code, and halts the system instead of allowing a triple fault",
          "Interrupts are enabled (sti) only after IDT is loaded and PIC is remapped and configured"
        ]
      },
      {
        "id": "build-os-m3",
        "title": "Physical and Virtual Memory Management",
        "anchor_id": "anchor-m3-memory",
        "summary": "Parse the E820 memory map to discover physical memory regions, implement a bitmap-based physical frame allocator for 4KB pages, construct two-level page tables (page directory + page tables) for both identity-mapping low memory and higher-half kernel mapping at 0xC0000000, enable paging via CR3/CR0.PG, implement a page fault handler that reads CR2 for diagnostic information, and build a kernel heap allocator (kmalloc/kfree) backed by the physical frame allocator. This milestone transforms the flat physical address space into an isolated virtual address space.",
        "misconception": "Developers think virtual memory is primarily about 'giving each process its own address space' \u2014 a software organizational tool. They assume the MMU is like a lookup table the OS consults, and that paging is mainly about isolation and convenience.",
        "reveal": "The MMU is not software consulting a table \u2014 it's dedicated hardware that intercepts every single memory access on every single instruction and translates it through the page table hierarchy before the access reaches the cache/memory bus. This happens on the critical path of every load, store, and instruction fetch. The page table isn't a data structure the OS 'uses'; it's a data structure the CPU hardware walks autonomously, in a format the silicon dictates down to individual bits. The TLB exists because this two-level walk (PDE \u2192 PTE \u2192 physical frame) would add 2 extra memory accesses to every instruction \u2014 a 3x slowdown \u2014 so the CPU caches translations. This means modifying a page table entry without flushing the TLB leaves the CPU using stale translations, and the resulting bugs are non-deterministic because TLB eviction depends on access patterns. The identity-mapping requirement during the paging transition reveals the deepest truth: the instruction enabling paging is fetched using a physical address, but the NEXT instruction is fetched using a virtual address. If the virtual mapping doesn't map that physical address to itself, the CPU faults on the instruction immediately after enabling paging.",
        "cascade": [
          "TLB shootdown and multicore scalability \u2014 understanding per-CPU TLBs explains why mmap/munmap are expensive on multi-core systems and why TLB shootdown IPIs are a major performance bottleneck in Linux, connecting to NUMA-aware allocation in databases like ScyllaDB",
          "Demand paging and copy-on-write (cross-domain: containerization) \u2014 the page fault handler you build here is the exact mechanism that enables fork(), lazy allocation, memory-mapped files, and Docker's overlay filesystem copy-on-write layers",
          "Cache coloring and page frame allocation \u2014 physical frame choice affects L1/L2 cache set mapping, connecting memory allocation to cache performance; jemalloc and mimalloc use this insight for arena design",
          "Higher-half kernel and ASLR \u2014 mapping the kernel at a fixed high address explains KASLR (randomizing that address), which connects to the broader security concept of address space layout randomization used in every modern OS and browser",
          "Hardware page table walkers \u2014 understanding that the CPU walks your data structure autonomously connects to how GPU texture samplers, IOMMU for DMA, and even network card descriptor rings all use hardware-walked in-memory data structures"
        ],
        "yaml_acceptance_criteria": [
          "Physical memory map is obtained from multiboot info or E820 memory map; regions are classified as usable, reserved, or ACPI",
          "Physical frame allocator (bitmap or free-list) allocates and frees individual 4KB page frames; double-free and allocating reserved frames are prevented",
          "Page directory and page tables are set up for identity-mapping the first N MB (covering kernel + VGA + MMIO) and higher-half mapping the kernel (e.g., kernel at 0xC0000000 virtual)",
          "Paging is enabled by loading CR3 with the page directory physical address and setting CR0.PG bit",
          "TLB is flushed (invlpg or full CR3 reload) after modifying page table entries",
          "Page fault handler (exception 14) reads CR2 for faulting address and prints diagnostic info (address, error code: present/write/user)",
          "Kernel heap allocator (kmalloc/kfree) provides dynamic memory allocation from a dedicated virtual address range; uses the page allocator for backing frames",
          "Identity map is kept for low memory so VGA (0xB8000) and MMIO regions remain accessible at their physical addresses",
          "Physical memory map obtained from multiboot info or E820, with regions classified as usable/reserved/ACPI",
          "Physical frame allocator (bitmap or free-list) allocates and frees 4KB frames with double-free prevention",
          "Page directory and page tables configured for identity-mapping (kernel + VGA + MMIO) and higher-half kernel mapping (0xC0000000+)",
          "Paging enabled by loading CR3 with page directory physical address and setting CR0.PG bit",
          "TLB flushed with invlpg or CR3 reload after modifying page table entries",
          "Page fault handler reads CR2 for faulting address and prints diagnostic (address, error code bits for present/write/user)",
          "Kernel heap allocator (kmalloc/kfree) provides dynamic allocation from dedicated virtual range using page allocator for backing frames",
          "Identity map maintained for low memory so VGA (0xB8000) and MMIO regions remain accessible at physical addresses"
        ]
      },
      {
        "id": "build-os-m4",
        "title": "Processes and Preemptive Scheduling",
        "anchor_id": "anchor-m4-processes",
        "summary": "Design and implement the process control block (PCB) storing PID, full register state, page directory pointer, and process state. Build an assembly context switch routine that saves and restores all registers including EFLAGS. Configure the TSS for ring 3 \u2192 ring 0 stack switching. Implement a round-robin scheduler triggered by the PIT timer interrupt. Create user-mode processes running in ring 3 with their own page directories, and implement a system call interface via INT 0x80 with at least sys_write and sys_exit. This milestone brings together every previous mechanism into a working multitasking kernel.",
        "misconception": "Developers think a context switch is like saving and loading a game \u2014 you serialize the 'state' of one process, deserialize another, and continue. They imagine it as a clean, well-defined operation with clear boundaries, like swapping JSON objects.",
        "reveal": "A context switch is a controlled explosion of paradoxes. The switch code itself is running as the OLD process when it starts and as the NEW process when it returns \u2014 the identity of 'who is running' changes mid-function. The stack pointer (ESP) swap is the moment of metamorphosis: before the swap, pushes/pops hit the old process's kernel stack; after the swap, they hit the new process's kernel stack. If you push 5 registers, swap ESP, then pop 5 registers, you pushed onto one process's stack and popped from a completely different process's stack \u2014 and this is correct behavior. The TSS adds another layer: it exists solely because when a user-mode process (ring 3) triggers an interrupt, the CPU needs to switch to a kernel stack BEFORE any interrupt handler code runs. The CPU reads ESP0 from the TSS hardware structure to find this stack \u2014 meaning the TSS must be updated on every context switch, or the next interrupt in the new process will use the OLD process's kernel stack, corrupting both. The scheduler runs inside a timer interrupt handler, meaning it must re-enable interrupts for the new process (or the system freezes) while keeping them disabled during the actual register swap (or nested interrupts corrupt the switch).",
        "cascade": [
          "Green threads and coroutines (cross-domain: Go/Rust/JavaScript) \u2014 understanding hardware context switching reveals that Go goroutines, Rust async tasks, and JavaScript promises all implement the same save/restore pattern in software, trading hardware privilege transitions for faster cooperative switching",
          "Spectre and Meltdown mitigations \u2014 per-process page directories and the ring 0/3 transition via TSS are exactly what KPTI (Kernel Page Table Isolation) modifies; understanding the normal mechanism makes the vulnerability and mitigation obvious",
          "Lock-free scheduling and priority inversion \u2014 the critical section during context switch (interrupts disabled) connects to real-time OS priority inversion problems, the Mars Pathfinder bug, and why Linux uses priority inheritance in futexes",
          "Container isolation \u2014 process page directories providing memory isolation is the same mechanism cgroups and namespaces extend for container runtimes like Docker/containerd; understanding ring 3 isolation explains what containers actually guarantee (and don't)",
          "System call overhead \u2014 understanding that INT 0x80 requires a full privilege transition (ring 3 \u2192 ring 0 via TSS, register save, dispatch, register restore, iret) explains why Linux added vDSO for gettimeofday and why io_uring batches syscalls"
        ],
        "yaml_acceptance_criteria": [
          "Process control block (PCB) stores: PID, register state (EIP, ESP, EBP, general regs, EFLAGS), page directory pointer, process state (ready/running/blocked), and kernel stack pointer",
          "Context switch saves current process registers to its PCB and loads the next process's registers; implemented in assembly for correctness",
          "TSS (Task State Segment) is configured with the kernel stack pointer (SS0: ESP0) so the CPU knows which stack to use when transitioning from ring 3 to ring 0 on interrupt/syscall",
          "Timer interrupt (IRQ0) triggers the scheduler; scheduler selects the next ready process in round-robin order and performs a context switch",
          "At least 3 kernel-mode processes run concurrently, each printing to a different screen region, demonstrating preemptive multitasking",
          "User-mode processes: at least one process runs in ring 3 with its own page directory; accessing kernel memory from user mode triggers a page fault (user-bit not set)",
          "System call interface via INT 0x80: user-mode process triggers a software interrupt; kernel reads syscall number from EAX and arguments from EBX/ECX/EDX; at minimum implement sys_write and sys_exit",
          "TSS ESP0 is updated on every context switch to point to the current process's kernel stack top",
          "Process control block (PCB) stores PID, register state (EIP, ESP, EBP, general-purpose registers, EFLAGS), page directory pointer, process state (ready/running/blocked), and kernel stack pointer",
          "Context switch saves current process registers to its PCB and loads the next process's registers using assembly implementation for correctness",
          "TSS (Task State Segment) is configured with kernel stack pointer (SS0:ESP0) so the CPU knows which stack to use for ring 3 \u2192 ring 0 transitions",
          "Timer interrupt (IRQ0) triggers the scheduler which selects the next ready process in round-robin order and performs context switch",
          "User-mode processes run in ring 3 with their own page directory; accessing kernel memory triggers page fault due to supervisor-only bit",
          "System call interface via INT 0x80: kernel reads syscall number from EAX and arguments from EBX/ECX/EDX, implementing sys_write and sys_exit at minimum"
        ]
      }
    ],
    "diagrams": [
      {
        "id": "diag-satellite-os-map",
        "title": "OS Kernel \u2014 Satellite System Map",
        "description": "The complete project-wide map showing all four milestones and their interdependencies. Shows the boot \u2192 interrupts \u2192 memory \u2192 processes pipeline, with data flow between components: GDT feeds into IDT gate descriptors, IDT page fault handler feeds into paging, PIT timer interrupt feeds into scheduler, page directories feed into per-process isolation. Every component ID is labeled and cross-referenced. This is the 'Home Base' diagram that orients the learner.",
        "anchor_target": "anchor-m1-bootloader-gdt",
        "level": "satellite"
      },
      {
        "id": "diag-m1-boot-sequence-timeline",
        "title": "x86 Boot Sequence \u2014 BIOS to C Entry Point",
        "description": "A detailed timeline/data_walk showing every step from power-on: BIOS POST \u2192 MBR load at 0x7C00 \u2192 stage2 load \u2192 INT 13h disk reads \u2192 A20 enable \u2192 GDT load \u2192 CR0.PE set \u2192 far jump \u2192 segment register reload \u2192 BSS zero \u2192 C entry. Each step annotated with the CPU mode (real/protected), address width (20-bit/32-bit), and what would happen if skipped.",
        "anchor_target": "anchor-m1-bootloader-gdt",
        "level": "street"
      },
      {
        "id": "diag-m1-memory-map-physical",
        "title": "Physical Memory Map at Boot",
        "description": "A structure_layout diagram showing the entire first 16MB of physical address space during boot: 0x0000-0x03FF (IVT), 0x0400-0x04FF (BDA), 0x7C00-0x7DFF (MBR), 0x7E00+ (stage2), 0xA0000-0xBFFFF (VGA), 0xB8000 (text mode buffer), 0x100000+ (kernel load address). Annotated with which regions are safe to use and which are reserved by BIOS/hardware.",
        "anchor_target": "anchor-m1-bootloader-gdt",
        "level": "microscopic"
      },
      {
        "id": "diag-m1-gdt-entry-bitfield",
        "title": "GDT Segment Descriptor \u2014 Byte-Level Layout",
        "description": "A structure_layout diagram showing the 8-byte GDT entry format with every bit field labeled: limit[0:15], base[0:15], base[16:23], access byte (P, DPL, S, E, DC, RW, A), flags (G, D/B, L, AVL), limit[16:19], base[24:31]. Shows the exact values for all 5 entries (null, kernel code 0x08, kernel data 0x10, user code 0x18, user data 0x20) with hex bytes. Highlights the non-contiguous layout of base and limit fields \u2014 a common source of bugs.",
        "anchor_target": "anchor-m1-bootloader-gdt",
        "level": "microscopic"
      },
      {
        "id": "diag-m1-real-to-protected-transition",
        "title": "Real Mode \u2192 Protected Mode \u2014 The Critical Transition",
        "description": "A before_after diagram showing CPU state immediately before and after the far jump. BEFORE: CR0.PE=1 but CS still holds real-mode value, prefetch queue contains real-mode decoded instructions, memory accesses use segment:offset. AFTER: CS=0x08 (kernel code selector), prefetch queue flushed, memory accesses go through GDT. Highlights the 'schizophrenic' half-state between CR0 set and far jump completed.",
        "anchor_target": "anchor-m1-bootloader-gdt",
        "level": "microscopic"
      },
      {
        "id": "diag-m1-segment-selector-resolution",
        "title": "Segment Selector \u2192 GDT \u2192 Linear Address Resolution",
        "description": "A data_walk showing how a segment selector value (e.g., 0x08) is decomposed into index (1), TI (0=GDT), RPL (0=ring 0), then used to index into the GDT to retrieve the base address and limit, producing a linear address. Shows the path for both kernel code (0x08) and user code (0x18 with RPL=3).",
        "anchor_target": "anchor-m1-bootloader-gdt",
        "level": "street"
      },
      {
        "id": "diag-m1-linker-script-sections",
        "title": "Linker Script \u2014 Section Layout and VMA vs LMA",
        "description": "A structure_layout showing the linker script's output sections (.text, .rodata, .data, .bss) mapped to virtual addresses starting at 0x100000, with 4KB page alignment. Shows __bss_start and __bss_end symbols, the VMA (where code thinks it runs) vs LMA (where bootloader loads it), and how the kernel entry point address is communicated to the bootloader.",
        "anchor_target": "anchor-m1-bootloader-gdt",
        "level": "street"
      },
      {
        "id": "diag-m1-vga-serial-output",
        "title": "VGA Text Buffer and Serial Port \u2014 Memory-Mapped vs Port I/O",
        "description": "A before_after/structure_layout showing VGA text buffer at 0xB8000 with the 2-byte per character format (ASCII byte + attribute byte with foreground/background color), contrasted with serial port COM1 at I/O port 0x3F8 using in/out instructions. Shows the 8N1 UART configuration registers (DLAB, divisor latch, LCR, IER).",
        "anchor_target": "anchor-m1-bootloader-gdt",
        "level": "microscopic"
      },
      {
        "id": "diag-m1-a20-line-wrapping",
        "title": "A20 Line \u2014 Address Wrapping Problem",
        "description": "A before_after diagram showing memory addressing with A20 disabled (addresses above 1MB wrap to 0x0) vs enabled (addresses above 1MB access real memory). Shows the historical 8086 wrapping behavior and why the keyboard controller is involved. Illustrates the three enable methods: BIOS INT 15h, fast A20 port 0x92, keyboard controller.",
        "anchor_target": "anchor-m1-bootloader-gdt",
        "level": "street"
      },
      {
        "id": "diag-m2-idt-entry-format",
        "title": "IDT Gate Descriptor \u2014 Byte-Level Layout",
        "description": "A structure_layout showing the 8-byte IDT entry: offset[0:15], segment selector (always 0x08 for kernel code), reserved byte, type/attributes (P, DPL, gate type: 0xE for 32-bit interrupt gate, 0xF for trap gate), offset[16:31]. Shows the split offset field and how the CPU reconstructs the full ISR address. Contrasts interrupt gate (clears IF) vs trap gate (leaves IF unchanged).",
        "anchor_target": "anchor-m2-interrupts",
        "level": "microscopic"
      },
      {
        "id": "diag-m2-interrupt-dispatch-flow",
        "title": "Interrupt Dispatch \u2014 Hardware to Handler and Back",
        "description": "A data_walk tracing a complete interrupt lifecycle: hardware signal \u2192 PIC arbitration \u2192 vector number on data bus \u2192 CPU reads IDT[vector] \u2192 pushes EFLAGS/CS/EIP (and error code for exceptions) \u2192 jumps to handler \u2192 handler pushes registers \u2192 handler body \u2192 EOI to PIC \u2192 pops registers \u2192 iret restores EFLAGS/CS/EIP. Shows exact stack contents at each stage.",
        "anchor_target": "anchor-m2-interrupts",
        "level": "street"
      },
      {
        "id": "diag-m2-interrupt-stack-frame",
        "title": "Interrupt Stack Frame \u2014 With and Without Error Code",
        "description": "A structure_layout showing two side-by-side stack frames: one for exceptions WITHOUT error code (e.g., divide error #0: EIP, CS, EFLAGS on stack) and one for exceptions WITH error code (e.g., page fault #14: error code, EIP, CS, EFLAGS). Shows how a unified handler stub must push a dummy error code for the no-error-code case to normalize the frame. Includes the extra SS/ESP pushed on privilege change.",
        "anchor_target": "anchor-m2-interrupts",
        "level": "microscopic"
      },
      {
        "id": "diag-m2-pic-remapping",
        "title": "8259 PIC Remapping \u2014 Before and After",
        "description": "A before_after diagram showing the default PIC mapping (IRQ0=vector 0, which collides with divide error; IRQ1=vector 1, colliding with debug exception, etc.) vs the remapped configuration (IRQ0-7 \u2192 vectors 32-39, IRQ8-15 \u2192 vectors 40-47). Shows the ICW1-ICW4 initialization sequence for both master and slave PICs, the cascade wiring (slave on IRQ2), and the OCW commands for masking and EOI.",
        "anchor_target": "anchor-m2-interrupts",
        "level": "street"
      },
      {
        "id": "diag-m2-pic-cascade-architecture",
        "title": "8259 PIC Master/Slave Cascade \u2014 Hardware Wiring",
        "description": "A structure_layout showing the dual-PIC architecture: master PIC at ports 0x20-0x21 with IRQ0-7, slave PIC at ports 0xA0-0xA1 with IRQ8-15, slave connected to master's IRQ2 input. Shows the EOI routing: IRQ0-7 need EOI to master only, IRQ8-15 need EOI to both slave AND master. Annotates which IRQ lines connect to which hardware (PIT=IRQ0, keyboard=IRQ1, cascade=IRQ2, COM ports, etc.).",
        "anchor_target": "anchor-m2-interrupts",
        "level": "microscopic"
      },
      {
        "id": "diag-m2-pit-timer-programming",
        "title": "PIT Channel 0 \u2014 Frequency Configuration",
        "description": "A trace_example showing how to program the PIT for 100Hz: write command byte 0x36 to port 0x43 (channel 0, lobyte/hibyte, mode 3 square wave), calculate divisor = 1193180 / 100 = 11932, write low byte to port 0x40, write high byte to port 0x40. Shows the relationship between base frequency (1.193182 MHz), divisor, and output frequency.",
        "anchor_target": "anchor-m2-interrupts",
        "level": "microscopic"
      },
      {
        "id": "diag-m2-keyboard-scancode-pipeline",
        "title": "PS/2 Keyboard \u2014 Scancode to ASCII Pipeline",
        "description": "A data_walk tracing a keypress from hardware to buffer: key down \u2192 PS/2 controller generates scancode set 1 \u2192 IRQ1 fires \u2192 handler reads port 0x60 \u2192 checks bit 7 for make/break \u2192 looks up scancode in ASCII table \u2192 pushes to circular buffer. Shows make code (0x1E for 'A') vs break code (0x9E), shift state tracking, and the ring buffer with read/write pointers.",
        "anchor_target": "anchor-m2-interrupts",
        "level": "street"
      },
      {
        "id": "diag-m2-exception-vector-table",
        "title": "CPU Exception Vectors 0-31 \u2014 Classification Table",
        "description": "A structure_layout showing all 32 CPU exceptions: vector number, name, type (fault/trap/abort), whether an error code is pushed, and brief description. Highlights the critical ones: #0 divide error, #6 invalid opcode, #8 double fault (abort), #13 general protection fault, #14 page fault. Color-codes by severity and groups by error-code/no-error-code.",
        "anchor_target": "anchor-m2-interrupts",
        "level": "street"
      },
      {
        "id": "diag-m2-double-fault-cascade",
        "title": "Exception Cascading \u2014 Fault \u2192 Double Fault \u2192 Triple Fault",
        "description": "A state_evolution diagram showing how a single fault (e.g., page fault while handling a GPF) escalates: original exception \u2192 CPU tries to invoke handler \u2192 second exception during handler dispatch \u2192 double fault (#8) \u2192 if double fault handler itself faults \u2192 triple fault \u2192 CPU reset. Shows why a working double fault handler is the last line of defense.",
        "anchor_target": "anchor-m2-interrupts",
        "level": "street"
      },
      {
        "id": "diag-m3-e820-memory-map",
        "title": "E820 Memory Map \u2014 Physical Memory Discovery",
        "description": "A structure_layout showing a typical E820 memory map from QEMU with 128MB RAM: 0x0-0x9FFFF (usable, 640KB), 0xA0000-0xFFFFF (reserved, VGA/ROM), 0x100000-0x7FFFFFF (usable, ~127MB), reserved ACPI regions. Shows the E820 entry structure (base, length, type) and how the frame allocator must skip reserved regions and the kernel's own memory.",
        "anchor_target": "anchor-m3-memory",
        "level": "street"
      },
      {
        "id": "diag-m3-bitmap-allocator",
        "title": "Bitmap Frame Allocator \u2014 Structure and Operations",
        "description": "A structure_layout showing the bitmap array where each bit represents a 4KB physical frame: bit 0 = frame at 0x0, bit 1 = frame at 0x1000, etc. Shows the initial state with kernel frames, page table frames, and reserved regions marked as allocated. Demonstrates alloc (find first zero bit, set it, return frame address) and free (clear bit with double-free check). Includes the byte offset calculation: frame_number / 8 = byte index, frame_number % 8 = bit index.",
        "anchor_target": "anchor-m3-memory",
        "level": "microscopic"
      },
      {
        "id": "diag-m3-two-level-page-table",
        "title": "x86 Two-Level Paging \u2014 Virtual Address Translation",
        "description": "A data_walk showing a 32-bit virtual address split into PD index (bits 31:22, 10 bits \u2192 1024 entries), PT index (bits 21:12, 10 bits \u2192 1024 entries), and page offset (bits 11:0, 12 bits \u2192 4096 bytes). Traces CR3 \u2192 page directory \u2192 PDE \u2192 page table \u2192 PTE \u2192 physical frame + offset. Shows the 4MB coverage per PDE (1024 PTEs \u00d7 4KB) and total 4GB addressable space (1024 PDEs \u00d7 4MB).",
        "anchor_target": "anchor-m3-memory",
        "level": "street"
      },
      {
        "id": "diag-m3-pde-pte-bitfield",
        "title": "Page Directory/Table Entry \u2014 Bit-Level Layout",
        "description": "A structure_layout showing the 32-bit PDE and PTE formats: physical address (bits 31:12, page-aligned), AVL (bits 11:9), G (bit 8), PAT/0 (bit 7), D dirty (bit 6, PTE only), A accessed (bit 5), PCD (bit 4), PWT (bit 3), U/S user/supervisor (bit 2), R/W read/write (bit 1), P present (bit 0). Shows example entries for kernel pages (P=1, R/W=1, U/S=0) vs user pages (P=1, R/W=1, U/S=1). Highlights that the address field is only 20 bits because pages are 4KB-aligned.",
        "anchor_target": "anchor-m3-memory",
        "level": "microscopic"
      },
      {
        "id": "diag-m3-identity-plus-higher-half",
        "title": "Dual Mapping \u2014 Identity Map + Higher-Half Kernel",
        "description": "A before_after diagram showing virtual address space layout. Shows the identity map (virtual 0x0 \u2192 physical 0x0 for first N MB) coexisting with the higher-half map (virtual 0xC0000000 \u2192 physical 0x100000 for kernel). Explains why both are needed during the transition: code executing at physical address must still work after paging is enabled (identity map), but the kernel's linked addresses are at 0xC0000000+ (higher-half). Shows which PDE entries are populated for each mapping.",
        "anchor_target": "anchor-m3-memory",
        "level": "street"
      },
      {
        "id": "diag-m3-paging-enable-moment",
        "title": "The Paging Enable Moment \u2014 CR3 and CR0.PG",
        "description": "A state_evolution diagram showing the exact sequence: 1) Build page tables in physical memory, 2) Load CR3 with page directory physical address, 3) Set CR0.PG \u2014 AT THIS EXACT INSTRUCTION the MMU activates: the instruction that set CR0.PG was fetched using a physical address, but the NEXT instruction is fetched using a virtual address. Shows why identity mapping the currently executing code is mandatory. Shows the subsequent jump to the higher-half address to 'escape' the identity map.",
        "anchor_target": "anchor-m3-memory",
        "level": "microscopic"
      },
      {
        "id": "diag-m3-tlb-flush-scenarios",
        "title": "TLB \u2014 Caching Translations and Flush Requirements",
        "description": "A before_after diagram showing the TLB as a cache of virtual\u2192physical translations. Shows a scenario where a page table entry is modified (e.g., changing permissions) but the TLB still holds the old translation, causing the CPU to use stale permissions. Demonstrates invlpg (flushes one entry) vs CR3 reload (flushes all entries). Annotates the performance trade-off: invlpg is O(1) but per-page, CR3 reload flushes everything including still-valid entries.",
        "anchor_target": "anchor-m3-memory",
        "level": "street"
      },
      {
        "id": "diag-m3-page-fault-error-code",
        "title": "Page Fault (#14) \u2014 CR2 and Error Code Decoding",
        "description": "A trace_example showing a page fault scenario: user process accesses 0xC0100000 (kernel memory) \u2192 CPU walks page table \u2192 PTE has U/S=0 (supervisor only) \u2192 page fault \u2192 CPU pushes error code (bits: P=1 present, W/R=0 read, U/S=1 user mode) and stores 0xC0100000 in CR2. Shows how to decode the error code bits to determine fault cause. Contrasts with a not-present fault (P=0) for demand paging.",
        "anchor_target": "anchor-m3-memory",
        "level": "microscopic"
      },
      {
        "id": "diag-m3-kernel-heap-architecture",
        "title": "Kernel Heap (kmalloc/kfree) \u2014 Virtual Memory Backing",
        "description": "A structure_layout showing the kernel heap occupying a virtual address range (e.g., 0xD0000000-0xDFFFFFFF), with the heap allocator (simple free-list or boundary-tag) managing sub-page allocations, and each page of heap space backed by a physical frame obtained from the bitmap allocator. Shows the layered relationship: kmalloc \u2192 heap free-list \u2192 page allocator \u2192 bitmap \u2192 physical frames.",
        "anchor_target": "anchor-m3-memory",
        "level": "street"
      },
      {
        "id": "diag-m3-virtual-address-space-layout",
        "title": "Complete Virtual Address Space Layout",
        "description": "A structure_layout showing the full 4GB virtual address space after paging is enabled: 0x0-0xBFFFFFFF (user space, 3GB), 0xC0000000-0xC0FFFFFF (kernel code/data, higher-half), 0xC1000000+ (kernel heap), VGA at identity-mapped 0xB8000, page tables recursively mapped (optional). Shows the clean separation between user and kernel memory regions.",
        "anchor_target": "anchor-m3-memory",
        "level": "street"
      },
      {
        "id": "diag-m4-pcb-structure-layout",
        "title": "Process Control Block \u2014 Byte-Level Structure",
        "description": "A structure_layout showing the PCB struct with exact field offsets: PID (offset 0, 4 bytes), state enum (offset 4, 4 bytes), EIP (offset 8), ESP (offset 12), EBP (offset 16), EAX-EDI (offsets 20-48), EFLAGS (offset 52), CR3/page_directory (offset 56), kernel_stack_top (offset 60), next pointer for ready queue (offset 64). Shows total size and cache line analysis (fits in 1-2 cache lines). Annotates which fields are saved by hardware vs software during context switch.",
        "anchor_target": "anchor-m4-processes",
        "level": "microscopic"
      },
      {
        "id": "diag-m4-context-switch-assembly",
        "title": "Context Switch \u2014 Register Save/Restore Trace",
        "description": "A data_walk tracing the assembly context switch instruction by instruction: push EAX through push EDI \u2192 save ESP to old_pcb.esp \u2192 load ESP from new_pcb.esp \u2192 pop EDI through pop EAX \u2192 ret (pops new EIP). Shows the stack contents at each step, highlighting the moment ESP changes as the 'identity swap'. Color-codes which stack is active (old process blue, new process green).",
        "anchor_target": "anchor-m4-processes",
        "level": "microscopic"
      },
      {
        "id": "diag-m4-context-switch-stacks",
        "title": "Two Kernel Stacks \u2014 The ESP Swap Moment",
        "description": "A before_after diagram showing two kernel stacks side by side. BEFORE: ESP points to process A's stack with saved registers. The single instruction 'mov esp, [new_pcb + ESP_OFFSET]' switches. AFTER: ESP points to process B's stack with its previously saved registers. Shows that push/pop before the swap affect stack A, and push/pop after affect stack B. This is the 'metamorphosis' moment.",
        "anchor_target": "anchor-m4-processes",
        "level": "street"
      },
      {
        "id": "diag-m4-tss-structure",
        "title": "Task State Segment \u2014 Structure and SS0:ESP0",
        "description": "A structure_layout showing the 104-byte TSS with all fields, highlighting SS0 (offset 0x08) and ESP0 (offset 0x04) as the critical fields for ring 3\u21920 transitions. Shows the TSS descriptor in the GDT (entry at index 5, selector 0x28), the ltr instruction to load it, and the requirement to update ESP0 on every context switch. All other TSS fields can be zero for software task switching.",
        "anchor_target": "anchor-m4-processes",
        "level": "microscopic"
      },
      {
        "id": "diag-m4-ring-transition-mechanism",
        "title": "Ring 3 \u2192 Ring 0 \u2014 The Complete Privilege Transition",
        "description": "A data_walk tracing a user-mode interrupt (INT 0x80 syscall): CPU detects CPL=3\u2192DPL=0 transition \u2192 reads SS0:ESP0 from TSS \u2192 switches to kernel stack \u2192 pushes user SS, user ESP, EFLAGS, user CS, user EIP \u2192 jumps to IDT handler \u2192 handler runs in ring 0. On return: iret pops EIP, CS, EFLAGS, ESP, SS \u2192 detects CPL change \u2192 switches back to user stack. Shows both stacks and all pushed/popped values.",
        "anchor_target": "anchor-m4-processes",
        "level": "street"
      },
      {
        "id": "diag-m4-scheduler-flow",
        "title": "Round-Robin Scheduler \u2014 Timer Interrupt to Context Switch",
        "description": "A state_evolution diagram showing the complete scheduling flow: Process A running \u2192 PIT fires IRQ0 \u2192 interrupt pushes registers \u2192 scheduler function called \u2192 scheduler picks next ready process (B) from circular queue \u2192 context switch to B \u2192 B's registers restored \u2192 iret returns to B's code. Shows the ready queue as a circular linked list of PCBs with the current pointer advancing on each tick.",
        "anchor_target": "anchor-m4-processes",
        "level": "street"
      },
      {
        "id": "diag-m4-process-states",
        "title": "Process State Machine \u2014 Ready, Running, Blocked",
        "description": "A state_evolution diagram showing process state transitions: CREATED \u2192 READY (added to ready queue), READY \u2192 RUNNING (selected by scheduler), RUNNING \u2192 READY (timer preemption), RUNNING \u2192 BLOCKED (waiting for I/O or syscall), BLOCKED \u2192 READY (I/O complete or event), RUNNING \u2192 TERMINATED (sys_exit). Annotates each transition with what triggers it and what kernel code performs it.",
        "anchor_target": "anchor-m4-processes",
        "level": "street"
      },
      {
        "id": "diag-m4-user-mode-page-directory",
        "title": "Per-Process Page Directory \u2014 User/Kernel Split",
        "description": "A structure_layout showing two page directories side by side (Process A and Process B). Both share the same kernel page table entries (PDEs 768-1023 for 0xC0000000+) but have different user-space entries (PDEs 0-767). Shows that kernel pages have U/S=0 (supervisor only) while user pages have U/S=1. Demonstrates how switching CR3 changes the user-space mapping while kernel space remains identical.",
        "anchor_target": "anchor-m4-processes",
        "level": "street"
      },
      {
        "id": "diag-m4-syscall-dispatch",
        "title": "System Call Dispatch \u2014 INT 0x80 to Handler Table",
        "description": "A data_walk showing a user process calling sys_write: user code sets EAX=1 (syscall number), EBX=fd, ECX=buffer pointer, EDX=length \u2192 INT 0x80 \u2192 ring transition via TSS \u2192 syscall handler reads EAX \u2192 indexes into syscall_table[EAX] \u2192 calls sys_write_impl(ebx, ecx, edx) \u2192 return value placed in EAX \u2192 iret back to user mode. Shows the syscall table as a function pointer array.",
        "anchor_target": "anchor-m4-processes",
        "level": "street"
      },
      {
        "id": "diag-m4-interrupt-reentrancy",
        "title": "Interrupt Enable/Disable \u2014 Critical Section During Switch",
        "description": "A trace_example showing the dangerous window: timer interrupt fires \u2192 scheduler begins context switch \u2192 if interrupts are enabled, another timer interrupt could fire mid-switch \u2192 nested switch corrupts partially-saved state. Shows the cli/sti placement: cli before saving registers, switch ESP, then sti after the new process is fully loaded. Annotates that EFLAGS.IF in the new process's saved state must have interrupts enabled or the process freezes.",
        "anchor_target": "anchor-m4-processes",
        "level": "microscopic"
      },
      {
        "id": "diag-m4-three-process-demo",
        "title": "Three-Process Demo \u2014 Interleaved Execution Timeline",
        "description": "A trace_example showing a timeline of three kernel-mode processes (A, B, C) each printing to different VGA screen regions. Shows timer ticks interleaving execution: A runs for 10ms \u2192 tick \u2192 switch to B \u2192 B runs 10ms \u2192 tick \u2192 switch to C \u2192 tick \u2192 back to A. Demonstrates preemptive behavior: processes don't yield voluntarily, the timer forces switches. Shows VGA output growing in three separate regions simultaneously.",
        "anchor_target": "anchor-m4-processes",
        "level": "street"
      }
    ]
  },
  "accumulated_md": "# Build Your Own OS\n\nThis project constructs an x86 operating system kernel from bare metal firmware through protected mode, hardware interrupt handling, virtual memory management, and preemptive multitasking with user-mode isolation. Starting from the very first byte the BIOS loads off disk, the learner will implement every layer that modern operating systems hide: the GDT that defines segmentation, the IDT that routes interrupts, the page tables that virtualize memory, and the TSS that enables privilege transitions. By the end, multiple user-mode processes will run concurrently under a preemptive round-robin scheduler, issuing system calls through INT 0x80.\n\nThe project is structured as four milestones that mirror the actual dependency chain of an x86 kernel: you cannot handle interrupts without a GDT, cannot manage memory without interrupt handlers for page faults, and cannot schedule processes without both memory isolation and timer interrupts. Each milestone builds precisely on the hardware mechanisms established in the previous one, creating a layered system where every abstraction is one the learner built themselves.\n\nThis is an expert-level, 120-200 hour endeavor in freestanding C (or Rust/Zig) and x86 assembly. The learner will debug triple-faults with QEMU and GDB, read Intel SDM entries for obscure register bits, and develop an intimate understanding of the contract between software and the x86 hardware platform.\n\n\n\n<!-- MS_ID: build-os-m1 -->\n# Milestone 1: Bootloader, GDT, and Kernel Entry\n\n![OS Kernel \u2014 Satellite System Map](./diagrams/diag-satellite-os-map.svg)\n\nBefore any interrupt fires, before any page table exists, before any process runs \u2014 there is this milestone. Every mechanism you will build in the next three milestones depends on a specific, precise contract being established here: the CPU must be in 32-bit protected mode, segment registers must point at valid GDT entries, and a C function must be reachable at a known physical address. Get this wrong by a single bit and the machine triple-faults silently. Get it right and you have created an execution environment from nothing.\nThis is the hardest kind of systems work: debugging code that runs before any debugger knows the machine exists.\n---\n## The World Before Your Kernel\n\n![x86 Boot Sequence \u2014 BIOS to C Entry Point](./diagrams/diag-m1-boot-sequence-timeline.svg)\n\nWhen you press the power button, the CPU starts executing at physical address `0xFFFFFFF0` \u2014 the very top of 32-bit addressable space. The chip at that address is not your operating system. It's firmware: on x86 systems, this is the BIOS (Basic Input/Output System \u2014 a ROM-resident program that has existed in essentially the same form since the IBM PC of 1981). The BIOS performs a Power-On Self-Test (POST), enumerates hardware, and then \u2014 crucially \u2014 searches for a bootable device.\nIt checks each storage device in order. For each disk, it reads the first 512-byte sector \u2014 the MBR, or Master Boot Record \u2014 and checks whether bytes 510 and 511 equal `0x55` and `0xAA`. If they do, the BIOS declares this sector executable, copies it to physical address `0x7C00`, and jumps to it.\nThe CPU at this point is running in **real mode**: a 16-bit execution environment with a 1 MB address limit, no memory protection, no virtual addressing, and a direct, unmediated view of physical hardware. Every program that ran on an original IBM PC ran in this mode. Your bootloader starts here.\n**The fundamental tension**: Your kernel is a substantial binary \u2014 potentially hundreds of kilobytes \u2014 that must eventually run in a fully-featured 32-bit environment. But you wake up with 512 bytes, a 1 MB address ceiling, no disk driver, no file system, and a CPU that has never heard of segments as protected-mode descriptors. You must bootstrap from this primitive state to a sophisticated one, using only the tools available at each stage to reach the tools needed for the next.\n---\n## Stage 1: The 512-Byte Problem\n{{DIAGRAM:diag-m1-memory-map-physical}}\nYour first constraint is absolute: the MBR is exactly 512 bytes, the last two of which must be `0x55AA`. Subtract 2 bytes for the signature, and you have 510 bytes in which to:\n- Set up a minimal stack\n- Enable the A20 address line\n- Read the kernel from disk\n- Transition to protected mode (or hand off to a stage-2 loader)\n- Jump to the kernel\n510 bytes is not enough to do all of this comfortably if your kernel requires disk reads with error handling, a full GDT setup, and a memory map query. This is why most real bootloaders (GRUB, SYSLINUX, U-Boot) use **two-stage loading**: the 512-byte stage 1 does the absolute minimum \u2014 load a larger stage 2 from a fixed disk location \u2014 and the stage 2 does everything else with far more room.\nFor this project, you have a choice:\n| Approach | Complexity | Flexibility | Used By |\n|---|---|---|---|\n| **Single-stage (stage 1 only)** | Lower | Limited to ~450 bytes | Minimal toy OSes |\n| **Two-stage \u2713** | Moderate | Stage 2 can be kilobytes | GRUB, SYSLINUX, most real OSes |\n| **GRUB/Multiboot** | Low (for your code) | Maximum | Linux, most production kernels |\nThe two-stage approach is the right learning experience. Stage 1 fits in 512 bytes, loads stage 2 from a known disk location (sectors 2\u2013N), and jumps to it. Stage 2 has kilobytes of room to set up the GDT properly, enable the A20 line with fallback methods, read the kernel, and perform the protected-mode transition.\n### Real Mode Addressing: How It Works\nIn real mode, the CPU computes physical addresses as:\n```\nphysical_address = segment_register \u00d7 16 + offset\n```\nSo `CS:IP = 0x07C0:0x0000` gives physical address `0x07C00`. This segmented addressing is why real mode can address only 1 MB: segments are 16-bit, so the maximum segment value is `0xFFFF`, the maximum offset is `0xFFFF`, and `0xFFFF \u00d7 16 + 0xFFFF = 0x10FFEF` \u2014 just over 1 MB. The A20 issue (coming shortly) is precisely about what happens to that extra bit.\nYour stage-1 bootsector will execute at `0x7C00`. Set up your stack immediately:\n```nasm\n[BITS 16]\n[ORG 0x7C00]\nstart:\n    cli                     ; Disable interrupts \u2014 we're touching segment regs\n    xor ax, ax\n    mov ds, ax\n    mov es, ax\n    mov ss, ax\n    mov sp, 0x7C00          ; Stack grows down from 0x7C00 (below our code)\n    sti\n    ; Load stage 2 from disk sectors 2-9 (8 sectors = 4KB)\n    mov bx, 0x7E00          ; Load stage 2 right after MBR\n    mov ah, 0x02            ; BIOS INT 13h function: read sectors\n    mov al, 8               ; Read 8 sectors\n    mov ch, 0               ; Cylinder 0\n    mov cl, 2               ; Start at sector 2 (sector 1 is the MBR)\n    mov dh, 0               ; Head 0\n    int 0x13                ; BIOS disk read\n    jc disk_error           ; CF set on error\n    jmp 0x0000:0x7E00       ; Jump to stage 2\ndisk_error:\n    hlt\ntimes 510 - ($ - $$) db 0  ; Pad to 510 bytes\ndw 0xAA55                   ; Boot signature (little-endian: 0x55, 0xAA)\n```\n> **Note on `dw 0xAA55` vs `db 0x55, 0xAA`**: x86 is little-endian. When you write `dw 0xAA55`, NASM stores the low byte (`0x55`) first, then the high byte (`0xAA`). The BIOS reads bytes 510 and 511 as `0x55` and `0xAA` respectively. Either form works; be aware of what you're writing.\n---\n## The A20 Line: A 40-Year-Old Backwards Compatibility Hack\n\n![A20 Line \u2014 Address Wrapping Problem](./diagrams/diag-m1-a20-line-wrapping.svg)\n\nHere is one of the most bizarre stories in PC history. The original Intel 8086 had a 20-bit address bus \u2014 address lines A0 through A19 \u2014 which allowed it to address exactly 1 MB (`2^20` bytes). Programs took advantage of a quirk: accessing memory above `0xFFFFF` (the top of 1 MB) would wrap around to address `0x00000 + overflow`. This was undefined behavior, but some 8086 programs accidentally relied on it.\nWhen the 80286 arrived with 24 address lines and the ability to address 16 MB, those programs broke \u2014 because now address `0x100000` was an actual, distinct memory location instead of wrapping to `0x00000`. IBM's solution was to gate the 21st address line (A20) through the keyboard controller: leave A20 disabled by default (forcing wrap-around, preserving 8086 behavior), and let software enable it when it needs to access memory above 1 MB.\nThis is why your bootloader must explicitly enable A20. Without it, any access to addresses `0x100000`\u2013`0x10FFEF` silently wraps to `0x00000`\u2013`0x0FFEF`. Your kernel will be loaded to `0x100000`, and that load will appear to overwrite low memory. The system will silently corrupt itself.\n**Three methods to enable A20**, in order of reliability:\n**Method 1: BIOS INT 15h, function 0x2401**\n```nasm\nmov ax, 0x2401\nint 0x15\njc a20_failed   ; Carry flag set on error\n```\nClean, but not all BIOS implementations support it. Try it first.\n**Method 2: Fast A20 via I/O port 0x92**\n```nasm\nin al, 0x92\nor al, 0x02     ; Set bit 1 (A20 enable)\nand al, 0xFE    ; Clear bit 0 (do NOT reset the machine!)\nout 0x92, al\n```\nSupported on most modern systems. Fast and simple, but originally a PS/2 extension.\n**Method 3: Keyboard controller (8042)**\n```nasm\ncall wait_kbd_cmd\nmov al, 0xAD        ; Disable keyboard\nout 0x64, al\ncall wait_kbd_cmd\nmov al, 0xD0        ; Read output port\nout 0x64, al\ncall wait_kbd_data\nin al, 0x60         ; Read current value\npush ax\ncall wait_kbd_cmd\nmov al, 0xD1        ; Write output port\nout 0x64, al\ncall wait_kbd_cmd\npop ax\nor al, 0x02         ; Set A20 bit\nout 0x60, al\ncall wait_kbd_cmd\nmov al, 0xAE        ; Enable keyboard\nout 0x64, al\nwait_kbd_cmd:\n    in al, 0x64\n    test al, 0x02   ; Wait until input buffer empty\n    jnz wait_kbd_cmd\n    ret\nwait_kbd_data:\n    in al, 0x64\n    test al, 0x01   ; Wait until output buffer full\n    jz wait_kbd_data\n    ret\n```\nThe most reliable method but verbose. Required on some older hardware.\n**Verify A20 is enabled**: Write a value to address `0x7DFE` (just below the bootsector) and check whether the same value appears at `0x17FFE` (`0x7DFE + 0x10000` \u2014 one segment above, with wrap-around). If they differ, A20 is active.\n> **Knowledge Cascade \u2014 Backwards Compatibility as CPU Design Constraint**: The A20 story is a microcosm of how x86 design has been shaped by backward compatibility obligations for 40 years. The same philosophy explains why modern x86 CPUs boot in 16-bit real mode (IBM PC compatibility), why the legacy 8259 PIC is still present alongside the APIC, and why the first 640 KB of physical memory is forever \"conventional memory.\" Understanding A20 helps you see that modern x86 CPUs are archaeological sites \u2014 each layer of hardware is partially constrained by decisions made in 1978. Compare this to UTF-8: designed to be backward-compatible with ASCII (0x00\u20130x7F are identical), which is why it became universal even though UCS-2 was technically cleaner.\n---\n## Loading the Kernel from Disk\nYour kernel binary must reach physical address `0x100000` (the 1 MB mark \u2014 chosen specifically to be above the BIOS data area, above the VGA memory at `0xB8000`, and above the initial stack). Use BIOS INT 13h extended read (function `0x42`) if available, which supports 28-bit LBA addressing:\n```nasm\n; Disk Address Packet for INT 13h extended read\ndap:\n    db 0x10         ; Size of DAP = 16 bytes\n    db 0            ; Reserved\n    dw 64           ; Number of sectors to read (64 \u00d7 512 = 32KB)\n    dw 0x0000       ; Target offset\n    dw 0x1000       ; Target segment (0x1000:0x0000 = physical 0x10000)\n                    ; NOTE: Use segment 0x1000 to reach 0x10000 first,\n                    ; then copy to 0x100000 after A20+protected mode\n    dd 2            ; LBA start sector (low 32 bits)\n    dd 0            ; LBA start sector (high 32 bits)\nload_kernel:\n    mov si, dap\n    mov ah, 0x42\n    mov dl, 0x80    ; Drive number (0x80 = first hard disk)\n    int 0x13\n    jc disk_error\n```\n> **Why not load directly to `0x100000`?** In real mode, segment registers are 16-bit, and the physical address formula limits you to a maximum of `0xFFFF0 + 0xFFFF = 0x10FFEF`. You can reach `0x100000` with segment `0x1000` and offset `0x0000` \u2014 but only after A20 is enabled. The BIOS INT 13h approach works fine for loading into the low megabyte. For kernels that must be above 1 MB, enable A20 first, then use the `unreal mode` trick (briefly enter protected mode to set descriptor cache registers, then return to real mode with 32-bit offsets) \u2014 or simply load low and copy high after entering protected mode. The simplest approach: load at `0x10000` (64KB), enter protected mode, then `rep movsd` the kernel to `0x100000`.\n---\n## The GDT: The CPU's Runtime Segmentation Database\nThis is where the real architecture begins. The Global Descriptor Table (GDT) is not configuration you write once and forget. It is a data structure the CPU **reads on every single memory access** to determine whether that access is permitted, what privilege level it requires, and how to translate segment-relative addresses.\n### Segment Descriptors: The 8-Byte Contract\n{{DIAGRAM:diag-m1-gdt-entry-bitfield}}\nEvery entry in the GDT is exactly 8 bytes (64 bits). The layout is, historically, bizarre \u2014 Intel spread the base address and limit fields across non-contiguous bytes for backward compatibility with the 80286's 24-bit descriptors. Understanding the bit layout is mandatory because you will construct these entries by hand.\n```\nByte:   7        6        5        4        3        2        1        0\n       [Base    ][Flags+  ][Access  ][Base   ][Base   ][Limit  ][Limit  ]\n       [31:24   ][Limit   ][Byte    ][23:16  ][15:08  ][15:08  ][07:00  ]\n                [19:16   ]\n```\nLet's decode each field:\n**Base (32 bits, split across bytes 2, 3, 4, 7)**: The physical starting address of this segment. For a flat memory model, this is always `0x00000000`.\n**Limit (20 bits, split across bytes 0\u20131 and the low 4 bits of byte 6)**: The maximum addressable unit within the segment. With granularity bit set (G=1), this is in 4KB pages \u2014 so a limit of `0xFFFFF` means `0xFFFFF \u00d7 4096 + 4095 = 0xFFFFFFFF` (all 4 GB).\n**Access byte (byte 5)**:\n```\nBit 7: Present (P) \u2014 must be 1 for valid descriptor\nBit 6-5: DPL \u2014 Descriptor Privilege Level (0 = ring 0/kernel, 3 = ring 3/user)\nBit 4: Descriptor type (1 = code/data segment, 0 = system descriptor)\nBit 3: Executable (1 = code segment, 0 = data segment)\nBit 2: Direction/Conforming \u2014 for data: grows down if 1; for code: conforming if 1\nBit 1: Readable/Writable (code: readable; data: writable)\nBit 0: Accessed \u2014 CPU sets this on access; leave 0\n```\n**Flags nibble (high 4 bits of byte 6)**:\n```\nBit 7 (G): Granularity \u2014 0 = limit in bytes, 1 = limit in 4KB pages\nBit 6 (D/B): Default operation size \u2014 1 = 32-bit segment\nBit 5 (L): 64-bit code segment (set for long mode; leave 0 for 32-bit)\nBit 4: Available for OS use\n```\n\n> **\ud83d\udd11 Foundation: x86 privilege rings**\n> \n> ## x86 Privilege Rings\n### What It Is\nThe x86 architecture enforces hardware-level isolation between software layers using a system of **privilege rings** \u2014 numbered 0 through 3, where lower numbers mean more privilege. Think of them as concentric security boundaries burned into the CPU itself.\n- **Ring 0 (kernel mode):** Unrestricted access. Code here can execute any instruction, access any memory, reprogram hardware, modify the CPU's own control registers (`CR0`, `CR3`, `CR4`), and install interrupt handlers. Your kernel runs here.\n- **Ring 3 (user mode):** Heavily restricted. Code here cannot execute privileged instructions (like `hlt`, `in`, `out`, or loading segment registers with kernel selectors), cannot directly access hardware, and is confined to its own virtual address space. Applications run here.\n- **Rings 1 and 2:** Defined by the architecture but almost universally unused in modern systems. Linux and Windows use only rings 0 and 3.\n### The Enforcement Mechanism: CPL, DPL, and RPL\nThe CPU enforces privilege through three values embedded in segment selectors and descriptors:\n| Field | Stands For | Where It Lives |\n|-------|-----------|----------------|\n| **CPL** | Current Privilege Level | Low 2 bits of `CS` register |\n| **DPL** | Descriptor Privilege Level | Inside the segment/gate descriptor in the GDT/LDT |\n| **RPL** | Requested Privilege Level | Low 2 bits of any segment selector |\n**The rule:** Access is granted only if `max(CPL, RPL) \u2264 DPL`.\nIn plain terms: to access a segment, the *least privileged* of the current code and the requestor must still be *at least as privileged as* the segment requires. DPL acts as a minimum-privilege gate.\n**Concrete example:** A kernel data segment has `DPL=0`. A user-mode process with `CPL=3` tries to load that segment selector into `DS`. The CPU computes `max(3, RPL) \u2265 1 > 0`, so it raises a **General Protection Fault (#GP)**. Hardware enforced, no software check needed.\n**How ring transitions happen:** You can't just jump to ring 0. Controlled transitions occur through:\n- **System calls** via `int 0x80`, `sysenter`, or `syscall` instructions \u2014 these atomically switch CPL, stack, and instruction pointer through a call gate or MSR-defined entry point.\n- **Interrupts and exceptions** \u2014 the CPU saves user state and switches to a kernel-defined handler at ring 0.\n- **`iret`** \u2014 returns from interrupt/exception, restoring the previous CPL.\n### Key Insight\n> **Rings are enforced by the CPU on every memory access and privileged instruction \u2014 not by software.** Your kernel doesn't check if user code is \"allowed\" to read kernel memory; the hardware simply won't allow it if the page tables and segment DPLs are set correctly. This is why a buggy kernel that accidentally maps kernel pages as user-accessible (`U/S` bit set in the page table) is a catastrophic security vulnerability \u2014 you've defeated the hardware guard yourself.\n\n### The Five Entries You Need\nYour GDT must have exactly these five entries:\n```c\n// Descriptor encoded as two 32-bit halves for clarity\nstruct gdt_entry {\n    uint16_t limit_low;     // Limit bits 0-15\n    uint16_t base_low;      // Base bits 0-15\n    uint8_t  base_mid;      // Base bits 16-23\n    uint8_t  access;        // Access byte\n    uint8_t  flags_limit;   // Flags[7:4] + Limit[19:16]\n    uint8_t  base_high;     // Base bits 24-31\n} __attribute__((packed));\n```\n| Index | Selector | Purpose | Base | Limit | Access | DPL |\n|---|---|---|---|---|---|---|\n| 0 | `0x00` | Null descriptor | 0 | 0 | `0x00` | \u2014 |\n| 1 | `0x08` | Kernel code | 0 | 4GB | `0x9A` | Ring 0 |\n| 2 | `0x10` | Kernel data | 0 | 4GB | `0x92` | Ring 0 |\n| 3 | `0x18` | User code | 0 | 4GB | `0xFA` | Ring 3 |\n| 4 | `0x20` | User data | 0 | 4GB | `0xF2` | Ring 3 |\nDecoding the access bytes:\n- `0x9A` = `1001 1010`: P=1, DPL=00 (ring 0), S=1 (code/data), E=1 (code), C=0, R=1 (readable), A=0\n- `0x92` = `1001 0010`: P=1, DPL=00 (ring 0), S=1, E=0 (data), D=0, W=1 (writable), A=0\n- `0xFA` = `1111 1010`: P=1, DPL=11 (ring 3), S=1, E=1 (code), C=0, R=1, A=0\n- `0xF2` = `1111 0010`: P=1, DPL=11 (ring 3), S=1, E=0 (data), D=0, W=1, A=0\nFor all segments, flags byte = `0xCF` (G=1 for 4KB granularity, D=1 for 32-bit, L=0, AVL=0) combined with limit bits `0xF` gives the upper byte `0xCF`.\nIn concrete C:\n```c\nstatic struct gdt_entry gdt[5];\nstatic struct gdtr {\n    uint16_t limit;\n    uint32_t base;\n} __attribute__((packed)) gdtr;\nstatic void set_gdt_entry(int i, uint32_t base, uint32_t limit,\n                          uint8_t access, uint8_t flags) {\n    gdt[i].base_low    = (base & 0xFFFF);\n    gdt[i].base_mid    = (base >> 16) & 0xFF;\n    gdt[i].base_high   = (base >> 24) & 0xFF;\n    gdt[i].limit_low   = (limit & 0xFFFF);\n    gdt[i].flags_limit = ((limit >> 16) & 0x0F) | (flags & 0xF0);\n    gdt[i].access      = access;\n}\nvoid gdt_init(void) {\n    set_gdt_entry(0, 0, 0,          0x00, 0x00); // Null\n    set_gdt_entry(1, 0, 0xFFFFFFFF, 0x9A, 0xCF); // Kernel code\n    set_gdt_entry(2, 0, 0xFFFFFFFF, 0x92, 0xCF); // Kernel data\n    set_gdt_entry(3, 0, 0xFFFFFFFF, 0xFA, 0xCF); // User code\n    set_gdt_entry(4, 0, 0xFFFFFFFF, 0xF2, 0xCF); // User data\n    gdtr.limit = sizeof(gdt) - 1;\n    gdtr.base  = (uint32_t)gdt;\n    lgdt(&gdtr); // Assembly: lgdt [gdtr]\n}\n```\n\n> **\ud83d\udd11 Foundation: Segment descriptors and the flat memory model**\n> \n> ## Segment Descriptors and the Flat Memory Model\n### What It Is\nIn protected mode, the x86 CPU doesn't let you use memory addresses directly \u2014 every memory access goes through a **segment**. A segment descriptor is an 8-byte structure stored in a table (the **Global Descriptor Table**, or GDT) that defines a segment's properties:\n```\nBits  63-56, 39-32 : Base address (split across the descriptor)\nBits  51-48, 15-0  : Limit (size of segment, in bytes or 4KB pages)\nBits  55-52        : Flags (granularity, 32/64-bit, etc.)\nBits  47-40        : Access byte (present, DPL, type, etc.)\n```\nWhen you load a selector (e.g., `mov ds, ax`), the CPU finds the corresponding descriptor in the GDT, reads the base and limit, and uses them to translate every logical address:\n```\nPhysical address = Segment Base + Offset\n```\nThe CPU also checks that `Offset \u2264 Limit` \u2014 violations raise a #GP or #SS fault.\n### The Flat Model: Making Segmentation Invisible\nModern 32-bit operating systems (Linux, Windows, your hobby kernel) use the **flat memory model**: every segment descriptor is configured with `Base = 0` and `Limit = 0xFFFFFFFF` (4 GB, using 4KB page granularity).\nWith this setup:\n```\nPhysical address = 0 + Offset = Offset\n```\nSegmentation becomes a no-op. The logical address *is* the linear address. You still need the GDT (the CPU requires it in protected mode), and you still get DPL/ring enforcement from the segment descriptors, but the base/limit translation does nothing useful \u2014 it spans all of memory.\nA minimal flat-model GDT has four entries:\n1. **Null descriptor** (index 0, required by the architecture \u2014 always all zeros)\n2. **Kernel code segment** \u2014 Base=0, Limit=4GB, DPL=0, executable/readable\n3. **Kernel data segment** \u2014 Base=0, Limit=4GB, DPL=0, readable/writable\n4. **User code/data segments** \u2014 same geometry, DPL=3\n### Why Paging Instead\nSegmentation has fundamental problems for modern OS design:\n- Segments must be **contiguous** in linear address space \u2014 you can't easily swap pieces to disk.\n- Sharing memory between segments is awkward.\n- The x86-64 (long mode) architecture **deprecated segmentation** \u2014 `CS`, `DS`, `ES`, `SS` bases are forced to 0 by the hardware regardless of descriptors (only `FS` and `GS` retain configurable bases, used for thread-local storage).\n**Paging**, by contrast, operates on fixed 4KB pages, supports non-contiguous physical allocation, enables demand paging, and provides fine-grained per-page permissions. Modern kernels do all meaningful memory isolation through the page tables, using segmentation only to satisfy the CPU's requirements and enforce the ring boundary.\n### Key Insight\n> **The flat model is a deliberate workaround:** the x86 CPU mandates segmentation, so instead of fighting it, every modern OS neutralizes it by making all segments span the entire address space. You set it up once (load the GDT, reload segment registers), confirm that logical = linear, and then forget about it \u2014 paging handles everything real. When you write your GDT setup code, you're not enabling a feature; you're satisfying a hardware prerequisite so you can get to the interesting part.\n\n### Segment Selectors: Not Addresses, Indices\n\n![Segment Selector \u2192 GDT \u2192 Linear Address Resolution](./diagrams/diag-m1-segment-selector-resolution.svg)\n\nWhen you load `0x08` into CS, you are not loading an address. You are loading a **segment selector**: a 16-bit value where bits 15\u20133 are the index into the GDT (index 1 = `0x08 >> 3`), bit 2 is the TI flag (0 = GDT, 1 = LDT), and bits 1\u20130 are the RPL (Requested Privilege Level).\n| Selector | Binary | GDT Index | TI | RPL |\n|---|---|---|---|---|\n| `0x00` | `0000 0000 0000 0000` | 0 (null) | 0 | 0 |\n| `0x08` | `0000 0000 0000 1000` | 1 | 0 | 0 |\n| `0x10` | `0000 0000 0001 0000` | 2 | 0 | 0 |\n| `0x1B` | `0000 0000 0001 1011` | 3 | 0 | **3** |\n| `0x23` | `0000 0000 0010 0011` | 4 | 0 | **3** |\nWhen a user-mode program (ring 3) loads a kernel data descriptor with RPL=0 into DS, the CPU's DPL/RPL/CPL comparison rules prevent the access. This is the hardware mechanism that makes ring isolation real \u2014 not a software convention, but a check the CPU performs on **every memory access**.\n---\n## The Revelation: Protected Mode Is a Different CPU Personality\nHere is what almost everyone gets wrong the first time they read about protected mode:\nThey picture it like enabling a feature flag. You set CR0.PE and the CPU gains bigger registers, segment protection, and 32-bit addressing. The CPU \"upgrades\" in place.\n**This model is completely wrong.**\nWhen you set CR0.PE, you do not change the CPU gradually. You trigger a fundamental mode switch in the CPU's internal state machine. From that moment, **every memory access is mediated through segment descriptors**. The instruction at CS:IP that is currently being fetched and decoded? The CPU is partway through fetching it using the real-mode CS register value. But the memory subsystem is now expecting that CS contains a protected-mode segment selector pointing at a GDT entry.\nThe CPU is in a schizophrenic half-state: the pipeline has decoded instructions using real-mode segment semantics, but the execution unit expects protected-mode descriptors.\n\n![Real Mode \u2192 Protected Mode \u2014 The Critical Transition](./diagrams/diag-m1-real-to-protected-transition.svg)\n\n**The far jump is not optional ceremony.** It is the only instruction that atomically:\n1. Loads CS with a new value (the kernel code selector `0x08`)\n2. Forces the CPU to validate CS against the GDT\n3. Flushes the instruction prefetch queue \u2014 discarding any partially-decoded real-mode instructions\nWithout the far jump, the instruction immediately after `mov cr0, eax` will execute with a CS that the CPU's protected-mode logic cannot validate. The result is a General Protection Fault. Which causes a Double Fault (because the IDT isn't set up yet). Which causes a Triple Fault. Which causes the CPU to reset.\nYou will never see an error message. The machine will simply restart.\nHere is the exact sequence, every line of which is mandatory:\n```nasm\n[BITS 16]\nprotected_mode_enter:\n    cli                         ; MUST disable interrupts \u2014 BIOS IVT is now invalid\n    lgdt [gdt_descriptor]       ; Load GDTR before setting CR0.PE\n    mov eax, cr0\n    or  eax, 0x01               ; Set CR0.PE (bit 0)\n    mov cr0, eax                ; We are now in protected mode\n                                ; But CS still holds real-mode value!\n    ; The far jump atomically loads CS with selector 0x08\n    ; and flushes the prefetch queue\n    jmp 0x08:protected_mode_entry\n[BITS 32]\nprotected_mode_entry:\n    ; CS = 0x08 (kernel code descriptor, ring 0)\n    ; Now load all data segment registers\n    mov ax, 0x10                ; Kernel data selector\n    mov ds, ax\n    mov es, ax\n    mov fs, ax\n    mov gs, ax\n    mov ss, ax\n    mov esp, 0x9FC00            ; Set 32-bit stack (just below EBDA)\n    ; Now we are fully in 32-bit protected mode\n    call kernel_main\n```\n> **Why `cli` before `lgdt`?** The BIOS set up an Interrupt Vector Table (IVT \u2014 the real-mode equivalent of the IDT) at address `0x0000`. If an interrupt fires after you've loaded the GDT but before you've set up the IDT, the CPU will try to dispatch the interrupt through the IVT... in protected mode. The IVT entries are real-mode far pointers, not IDT gate descriptors. The CPU will misinterpret them as protected-mode IDT entries and triple-fault. Disabling interrupts before touching GDT/CR0 buys you the time to set up the IDT properly. You will enable interrupts again (`sti`) only after the IDT is configured in Milestone 2.\n> **Knowledge Cascade \u2014 CPU Pipeline and Speculative Execution**: The far jump requirement reveals something fundamental about how CPUs work: the prefetch queue. Modern CPUs speculatively fetch and decode instructions several cycles ahead of the current execution point. When you change CR0.PE, the CPU's execution unit switches modes, but the prefetch queue may already contain instructions decoded under old assumptions. The far jump forces a pipeline flush. This same principle \u2014 that the CPU's pipeline holds state that is inconsistent with current reality \u2014 is the root mechanism behind Spectre and Meltdown. Both attacks exploit the CPU's willingness to speculatively execute instructions before validating permission bits, then observe the side effects through cache timing. Understanding the CR0.PE far jump teaches you the real shape of the CPU's execution model.\n\n> **\ud83d\udd11 Foundation: Real mode vs protected mode**\n> \n> ## Real Mode vs Protected Mode\n### What It Is\nThese are two fundamentally different CPU operating environments that the x86 processor supports. When your machine powers on, the CPU starts in **real mode** \u2014 a compatibility mode that mimics the original Intel 8086 from 1978. Your kernel's job is to leave real mode and enter **protected mode** (or long mode on 64-bit systems) as early as possible.\n---\n### Real Mode\n**Memory addressing:** Real mode uses *segmented* addressing with 16-bit registers. A physical address is computed as:\n```\nPhysical address = (Segment Register \u00d7 16) + Offset\n```\nExample: `CS = 0xF000`, `IP = 0xFFF0` \u2192 physical address `0xFFFF0` (the reset vector). This gives a maximum addressable space of **1 MB** (20-bit address bus, `0x00000`\u2013`0xFFFFF`).\n**Key characteristics:**\n- No memory protection whatsoever \u2014 any code can read/write anything.\n- No privilege levels \u2014 all code runs with full hardware access.\n- 16-bit registers and default operand sizes.\n- Direct hardware access through BIOS interrupt calls (`int 0x10` for video, `int 0x13` for disk, etc.).\n- No virtual memory, no paging.\nReal mode exists for historical compatibility and to give firmware (BIOS/UEFI) a known, simple environment to run before handing control to a bootloader.\n---\n### Protected Mode\nProtected mode is what makes a real OS possible. To enter it, you must:\n1. Disable interrupts (`cli`)\n2. Load a valid GDT (`lgdt`)\n3. Set bit 0 (`PE`) of control register `CR0`\n4. Perform a far jump to flush the instruction pipeline and load a new `CS` with a valid protected-mode selector\n```nasm\nmov eax, cr0\nor  eax, 0x1        ; set PE bit\nmov cr0, eax\njmp 0x08:protected_entry   ; far jump \u2014 selector 0x08 = kernel code segment\n```\n**What changes at the hardware level:**\n| Feature | Real Mode | Protected Mode |\n|---------|-----------|----------------|\n| Address space | 1 MB | 4 GB (32-bit) |\n| Addressing | Segment \u00d7 16 + Offset | GDT/LDT descriptor lookup |\n| Privilege levels | None | Rings 0\u20133 enforced by hardware |\n| Memory protection | None | Segmentation + (optionally) paging |\n| BIOS interrupts | Available | **Broken** \u2014 BIOS is 16-bit real-mode code |\n| Operand default | 16-bit | 32-bit |\n| Paging | No | Optional (enabled via `CR0.PG`) |\n**Critical gotcha:** Once you enter protected mode, BIOS interrupt calls no longer work. You must have already collected everything you need from the BIOS (memory map via `int 0x15/E820`, video mode info, etc.) *before* the mode switch, or use special techniques (vm86 mode, or just don't use BIOS at all).\n---\n### Key Insight\n> **The CPU mode switch is a one-way door you must prepare carefully before walking through.** Real mode is the staging area where you gather information (memory map, hardware parameters) and set up prerequisites (GDT, initial stack). Protected mode is where your kernel actually lives. The transition itself \u2014 setting `CR0.PE` and the far jump \u2014 takes less than five instructions, but those five instructions require that everything else already be correct. A missing or malformed GDT entry doesn't give you an error message; it causes an immediate fault with no handler, and the machine reboots. There's no debugger, no safety net \u2014 just you, the CPU, and the architecture manual.\n\n---\n## The Linker Script: Teaching the Toolchain About Physical Reality\n\n![Linker Script \u2014 Section Layout and VMA vs LMA](./diagrams/diag-m1-linker-script-sections.svg)\n\nYour C compiler doesn't know you're writing an operating system. It generates code using symbol addresses assigned by the linker. The linker doesn't know your kernel will be loaded at physical address `0x100000`. You must tell it \u2014 with a linker script.\n\n> **\ud83d\udd11 Foundation: Linker scripts for bare-metal**\n> \n> ## Linker Scripts for Bare-Metal Kernel Development\n### What It Is\nA linker script is a configuration file (typically with a `.ld` extension) that tells the linker **how to construct the final binary**: where to place each section of code and data in memory, what address the binary assumes it will run at, and where execution should begin. For normal userspace programs, the toolchain generates a default script that works with the OS's virtual memory layout. For a bare-metal kernel, there is no OS \u2014 *you* define the layout, and the linker script is how you do it.\nA minimal kernel linker script looks like this:\n```ld\nENTRY(_start)\nSECTIONS {\n    . = 0x100000;          /* Load kernel at 1MB physical */\n    .text : {\n        *(.text)           /* All code from all object files */\n    }\n    .rodata : {\n        *(.rodata)         /* Read-only data (string literals, const globals) */\n    }\n    .data : {\n        *(.data)           /* Initialized global/static variables */\n    }\n    .bss : {\n        _bss_start = .;\n        *(.bss)            /* Uninitialized globals (zeroed at startup) */\n        *(COMMON)\n        _bss_end = .;\n    }\n}\n```\n---\n### ENTRY(): The Execution Start Point\n`ENTRY(_start)` tells the linker which symbol is the **entry point** \u2014 the first instruction the CPU will execute. This is embedded in the ELF header. Your bootloader (or a tool like GRUB via Multiboot) reads this and jumps to that address.\nWithout `ENTRY()`, the linker may default to the beginning of `.text`, which might work \u2014 or might land in the middle of a function. For a kernel, you need this to be explicit and precise.\n---\n### VMA vs LMA: The Critical Distinction\nThis is the most important \u2014 and most confusing \u2014 concept in linker scripts:\n- **VMA (Virtual Memory Address):** The address the code *thinks* it's running at. All internal symbol references (function calls, global variable accesses) are resolved to VMA.\n- **LMA (Load Memory Address):** The address where the section is *physically stored* in the binary image \u2014 where it will be loaded into memory.\n**For a simple kernel loaded at a fixed physical address, VMA = LMA**, and you don't need to think about this. Set `. = 0x100000` and everything works.\n**VMA \u2260 LMA becomes critical** when:\n- Your kernel is a higher-half kernel (linked at `0xC0100000` VMA but loaded at `0x100000` LMA) \u2014 the kernel uses high virtual addresses but lives in low physical memory before paging is enabled.\n- You're copying initialized data from ROM (LMA in flash) to RAM (VMA in SRAM) on embedded systems.\nSyntax to specify both:\n```ld\n.data VMA_ADDRESS : AT(LMA_ADDRESS) {\n    *(.data)\n}\n```\n**Concrete higher-half example:**\n```ld\n. = 0xC0100000;   /* VMA: kernel thinks it's here */\n.text : AT(0x100000) {   /* LMA: actually loaded here */\n    *(.text)\n}\n```\nYour early boot code (before enabling paging) must use physical addresses directly. Once you enable paging with an identity map + higher-half map, the VMA addressing works correctly.\n---\n### SECTIONS{}: Controlling the Memory Map\nThe `SECTIONS` block defines every output section, in order. The location counter (`.`) tracks the current address and advances as sections are placed. You can:\n- Set it explicitly: `. = 0x100000;`\n- Align it: `. = ALIGN(4096);` (page-align for paging setup)\n- Export symbols to your kernel's C code: `_kernel_end = .;`\nThose exported symbols are **directly usable in C**:\n```c\nextern uintptr_t _bss_start, _bss_end;\n// Zero the BSS section at boot\nmemset(&_bss_start, 0, &_bss_end - &_bss_start);\n```\nThis is how your kernel knows its own layout at runtime without hardcoding addresses.\n---\n### Why the BSS Section Needs Special Attention\nThe `.bss` section holds uninitialized globals. The linker records its size but doesn't actually fill the binary with zeros (that would waste space in the image). **Your kernel's startup code must zero it manually** before calling any C code that relies on zero-initialized globals. The linker script gives you `_bss_start` and `_bss_end` symbols specifically for this purpose.\n---\n### Key Insight\n> **The linker script is the translation layer between \"I compiled some C files\" and \"a CPU can boot this.\"** It answers questions the linker cannot answer alone: Where in physical memory does this kernel live? What virtual address do symbols resolve to? Where does execution start? When VMA \u2260 LMA, it manages the split between where code is stored and where it runs \u2014 which is the core challenge of higher-half kernels and ROM-to-RAM systems. Get the linker script wrong, and your kernel jumps to the wrong address and triple-faults silently. Get it right, and every symbol, every section boundary, every page-alignment is exactly where your boot code expects it.\n\n**VMA vs LMA \u2014 the key distinction:**\n- **VMA (Virtual Memory Address)**: The address the code *thinks it's at* \u2014 what symbols resolve to, what pointers contain, what the compiler emits in its instructions.\n- **LMA (Load Memory Address)**: The address where the binary is *actually placed* in the file and loaded by the bootloader.\nFor Milestone 1, VMA = LMA = `0x100000` \u2014 the kernel runs at its load address. This will change in Milestone 3 (higher-half mapping), where the kernel will be linked at `0xC0100000` (VMA) but loaded at `0x100000` (LMA). Understanding VMA/LMA now prevents complete confusion later.\n```ld\n/* kernel.ld \u2014 Linker script for 32-bit x86 kernel */\nENTRY(kernel_entry)         /* Symbol called by bootloader far jump */\nSECTIONS {\n    . = 0x100000;           /* Load at 1MB physical */\n    .text ALIGN(4096) : {\n        *(.multiboot)       /* Multiboot header must be in first 8KB */\n        *(.text)\n        *(.text.*)\n    }\n    .rodata ALIGN(4096) : {\n        *(.rodata)\n        *(.rodata.*)\n    }\n    .data ALIGN(4096) : {\n        *(.data)\n        *(.data.*)\n    }\n    .bss ALIGN(4096) : {\n        __bss_start = .;    /* Symbol for BSS zero-ing */\n        *(.bss)\n        *(.bss.*)\n        *(COMMON)           /* Uninitialized global variables */\n        __bss_end = .;      /* Symbol for BSS zero-ing */\n    }\n    __kernel_end = .;       /* Useful for allocator in Milestone 3 */\n}\n```\n**Why 4KB alignment?** Because Milestone 3 will enable paging with 4KB pages. Having each section start on a page boundary makes it possible to give pages different permissions: `.text` pages marked execute-only, `.data` pages marked no-execute. This isn't enforced now, but your layout decisions now either enable or prevent it later.\n**Why must `__bss_start` and `__bss_end` be in the linker script?** The BSS section contains uninitialized global variables. On a normal system, the C runtime (CRT0 \u2014 the `_start` code that libc provides before calling `main()`) zeros BSS before your code runs. You are writing a freestanding kernel \u2014 there is no CRT0. The CPU loaded your binary from disk, and the disk image doesn't store zeros for the BSS section (a disk image only stores the initialized data). Whatever happened to be in RAM at those addresses is still there. Any global variable you declare as `int x;` may contain garbage. You must zero BSS yourself.\n---\n## Kernel Entry Point: The Assembly-to-C Bridge\nYour bootloader jumps to `kernel_entry`, which is an assembly function. This assembly stub handles the tasks that must happen before C can safely run:\n```nasm\n[BITS 32]\n[GLOBAL kernel_entry]\n[EXTERN kernel_main]\n[EXTERN __bss_start]\n[EXTERN __bss_end]\nkernel_entry:\n    ; Zero the BSS section\n    mov edi, __bss_start\n    mov ecx, __bss_end\n    sub ecx, edi            ; ECX = number of bytes to zero\n    xor eax, eax\n    rep stosb               ; Zero ECX bytes starting at EDI\n    ; Set up stack (linker script ensures this doesn't overlap kernel)\n    mov esp, kernel_stack_top\n    ; Clear direction flag (required for string operations, DF=0 by ABI)\n    cld\n    ; Call the C entry point\n    ; ABI note: EBP = 0 marks the end of the call chain for stack unwinding\n    xor ebp, ebp\n    call kernel_main\n    ; kernel_main should never return, but halt if it does\n.hang:\n    cli\n    hlt\n    jmp .hang\nsection .bss\nkernel_stack: resb 16384   ; 16 KB kernel stack\nkernel_stack_top:\n```\n**Why `cld`?** The x86 direction flag (DF) controls whether string instructions (`stosb`, `movsb`, `scasb`) increment or decrement their pointer registers. DF=0 means increment (forward direction); DF=1 means decrement (backward). The C ABI assumes DF=0 on function entry. If DF is set when you call C code, `memcpy`, `memset`, and any other code using `rep movs/stos` will run backwards and corrupt memory. The BIOS may have left DF in an indeterminate state. Clearing it explicitly costs one instruction and prevents a category of subtle bugs.\n**Why zero EBP?** The x86 calling convention uses EBP as the frame pointer. Stack unwinding (for debugging or backtraces) walks the chain of saved EBPs until it hits zero. Setting EBP=0 before calling `kernel_main` marks `kernel_main` as the bottom of the call stack, which makes backtraces work correctly.\n---\n## VGA Text Mode: Writing Directly to the Screen\n{{DIAGRAM:diag-m1-vga-serial-output}}\nThe VGA text mode buffer is memory-mapped at physical address `0xB8000`. No driver, no system call, no abstraction \u2014 you write directly to RAM and pixels appear on screen. This is the closest relationship between software and hardware you will encounter.\nThe buffer is organized as a 80\u00d725 grid. Each character cell is 2 bytes:\n- Byte 0: ASCII character code\n- Byte 1: Color attribute\nThe color attribute byte:\n```\nBits 7:4 \u2014 Background color (0-15)\nBits 3:0 \u2014 Foreground color (0-15)\n```\nColor values: 0=Black, 1=Blue, 2=Green, 3=Cyan, 4=Red, 5=Magenta, 6=Brown, 7=Light Gray, 8=Dark Gray, 9=Light Blue, 10=Light Green, 11=Light Cyan, 12=Light Red, 13=Light Magenta, 14=Yellow, 15=White.\n```c\n#define VGA_BUFFER ((volatile uint16_t *)0xB8000)\n#define VGA_WIDTH  80\n#define VGA_HEIGHT 25\n#define VGA_COLOR(fg, bg) ((bg << 4) | fg)\n#define VGA_ENTRY(ch, color) ((uint16_t)(color << 8) | (uint8_t)(ch))\nstatic int vga_row = 0, vga_col = 0;\nstatic uint8_t vga_color = VGA_COLOR(15, 0); // White on black\nvoid vga_clear(void) {\n    for (int i = 0; i < VGA_WIDTH * VGA_HEIGHT; i++)\n        VGA_BUFFER[i] = VGA_ENTRY(' ', vga_color);\n    vga_row = vga_col = 0;\n}\nvoid vga_putchar(char c) {\n    if (c == '\\n') {\n        vga_col = 0;\n        if (++vga_row == VGA_HEIGHT) vga_scroll();\n        return;\n    }\n    VGA_BUFFER[vga_row * VGA_WIDTH + vga_col] = VGA_ENTRY(c, vga_color);\n    if (++vga_col == VGA_WIDTH) {\n        vga_col = 0;\n        if (++vga_row == VGA_HEIGHT) vga_scroll();\n    }\n}\nstatic void vga_scroll(void) {\n    // Copy rows 1-24 up to rows 0-23\n    for (int i = 0; i < (VGA_HEIGHT - 1) * VGA_WIDTH; i++)\n        VGA_BUFFER[i] = VGA_BUFFER[i + VGA_WIDTH];\n    // Clear last row\n    for (int i = (VGA_HEIGHT - 1) * VGA_WIDTH; i < VGA_HEIGHT * VGA_WIDTH; i++)\n        VGA_BUFFER[i] = VGA_ENTRY(' ', vga_color);\n    vga_row = VGA_HEIGHT - 1;\n}\n```\n**Why `volatile`?** The compiler doesn't know that writing to `0xB8000` has observable side effects (pixels on screen). Without `volatile`, the compiler may optimize away writes it deems \"redundant\" (e.g., writing the same location twice \u2014 it might keep only the last write), or reorder them. With `volatile`, every write is performed in program order, exactly as written. This qualifier is mandatory for any memory-mapped I/O in a freestanding environment.\n> **Hardware Soul**: The VGA buffer at `0xB8000` is not ordinary RAM \u2014 it is memory-mapped I/O (MMIO). When your CPU writes to `0xB8000`, the memory controller routes that write not to a DRAM chip but to the VGA card's own framebuffer memory. The VGA hardware continuously scans this framebuffer to refresh the display. This is why the `volatile` qualifier matters at the hardware level: the \"side effect\" of a VGA write is a hardware register state change in the VGA controller, which the compiler cannot see or reason about. Without `volatile`, the compiler might prove that no C code reads back from `0xB8000` and eliminate the write as dead code.\n---\n## Serial Port: Debug Output That Never Lies\nVGA is great for showing output to a human. Serial port is better for debugging \u2014 it's simple enough to initialize in under 10 instructions, works before VGA is configured, and can pipe output to a file with QEMU (`-serial file:serial.log`).\nCOM1 is at I/O port base `0x3F8`. Initialize it to 115200 baud, 8N1 (8 data bits, No parity, 1 stop bit):\n```c\n#define COM1 0x3F8\nstatic inline void outb(uint16_t port, uint8_t val) {\n    __asm__ volatile (\"outb %0, %1\" : : \"a\"(val), \"Nd\"(port));\n}\nstatic inline uint8_t inb(uint16_t port) {\n    uint8_t val;\n    __asm__ volatile (\"inb %1, %0\" : \"=a\"(val) : \"Nd\"(port));\n    return val;\n}\nvoid serial_init(void) {\n    outb(COM1 + 1, 0x00); // Disable interrupts\n    outb(COM1 + 3, 0x80); // Enable DLAB (Divisor Latch Access Bit)\n    outb(COM1 + 0, 0x01); // Divisor low byte: 1 \u2192 115200 baud\n    outb(COM1 + 1, 0x00); // Divisor high byte\n    outb(COM1 + 3, 0x03); // 8N1: 8 data bits, no parity, 1 stop bit; disable DLAB\n    outb(COM1 + 2, 0xC7); // Enable FIFO, clear, 14-byte threshold\n    outb(COM1 + 4, 0x0B); // Enable IRQ, set RTS/DSR\n}\nvoid serial_putchar(char c) {\n    while (!(inb(COM1 + 5) & 0x20)); // Wait until transmit buffer empty\n    outb(COM1, c);\n}\n```\n**Why port-based I/O instead of memory-mapped?** x86 provides two I/O address spaces: memory (accessed via load/store instructions) and I/O ports (accessed via `in`/`out` instructions). The distinction is a hardware routing decision in the chipset. Legacy peripherals like the UART, PIC, PIT, and keyboard controller use port I/O. Modern devices (PCIe, framebuffers) use MMIO. The `in`/`out` instructions are privileged in protected mode \u2014 only ring 0 can execute them by default (controlled by the IOPL field in EFLAGS and the TSS I/O permission bitmap, which becomes relevant in Milestone 4).\n**Baud rate calculation**: The 8250/16550 UART has an internal clock of 115200 Hz divided by the divisor register. To achieve 115200 baud, set divisor = 115200 / 115200 = 1. For 9600 baud, divisor = 12.\n---\n## kprintf: The Kernel's Lifeline\n```c\n#include <stdarg.h>\nvoid kprintf(const char *fmt, ...) {\n    va_list args;\n    va_start(args, fmt);\n    for (; *fmt; fmt++) {\n        if (*fmt != '%') {\n            vga_putchar(*fmt);\n            serial_putchar(*fmt);\n            continue;\n        }\n        fmt++;\n        switch (*fmt) {\n            case 'c': {\n                char c = (char)va_arg(args, int);\n                vga_putchar(c); serial_putchar(c);\n                break;\n            }\n            case 's': {\n                const char *s = va_arg(args, const char *);\n                for (; *s; s++) { vga_putchar(*s); serial_putchar(*s); }\n                break;\n            }\n            case 'd': {\n                int n = va_arg(args, int);\n                if (n < 0) { vga_putchar('-'); serial_putchar('-'); n = -n; }\n                // Convert to decimal string\n                char buf[12]; int i = 0;\n                if (n == 0) buf[i++] = '0';\n                while (n > 0) { buf[i++] = '0' + (n % 10); n /= 10; }\n                while (i--) { vga_putchar(buf[i]); serial_putchar(buf[i]); }\n                break;\n            }\n            case 'x': case 'p': {\n                uint32_t n = va_arg(args, uint32_t);\n                if (*fmt == 'p') {\n                    vga_putchar('0'); serial_putchar('0');\n                    vga_putchar('x'); serial_putchar('x');\n                }\n                char hex[] = \"0123456789abcdef\";\n                for (int shift = 28; shift >= 0; shift -= 4) {\n                    char c = hex[(n >> shift) & 0xF];\n                    vga_putchar(c); serial_putchar(c);\n                }\n                break;\n            }\n            default:\n                vga_putchar('%'); serial_putchar('%');\n                vga_putchar(*fmt); serial_putchar(*fmt);\n        }\n    }\n    va_end(args);\n}\n```\n> **Why not use `sprintf` + then print?** No stdlib. `sprintf` lives in libc, which you don't have. Every function you call must be something you wrote. This is the freestanding constraint: you are the runtime, the standard library, and the operating system simultaneously. This same experience is what Go's runtime team faced bootstrapping the Go runtime without a C runtime (documented in `cmd/internal/obj`, the Go assembler), and what the JVM faces initializing the first classloader before any Java code can run.\n---\n## Build System: From Source to Bootable Image\nThe final deliverable of this milestone is a bootable disk image. Here is the complete build chain:\n```makefile\n# Toolchain (cross-compiler targeting i686-elf, no host OS assumptions)\nCC      = i686-elf-gcc\nAS      = nasm\nLD      = i686-elf-ld\nCFLAGS  = -m32 -ffreestanding -fno-stack-protector -fno-builtin \\\n          -nostdlib -nostdinc -Wall -Wextra -O2\nASFLAGS = -f elf32\nLDFLAGS = -T kernel.ld -nostdlib\nKERNEL_OBJS = kernel_entry.o kernel_main.o vga.o serial.o kprintf.o\n.PHONY: all clean run\nall: os.img\n# Compile kernel objects\n%.o: %.c\n\t$(CC) $(CFLAGS) -c $< -o $@\n%.o: %.asm\n\t$(AS) $(ASFLAGS) $< -o $@\n# Stage 1 bootloader (raw binary)\nstage1.bin: stage1.asm\n\t$(AS) -f bin stage1.asm -o stage1.bin\n# Stage 2 loader (raw binary)\nstage2.bin: stage2.asm\n\t$(AS) -f bin stage2.asm -o stage2.bin\n# Kernel ELF\nkernel.elf: $(KERNEL_OBJS)\n\t$(LD) $(LDFLAGS) -o $@ $^\n# Extract raw kernel binary from ELF\nkernel.bin: kernel.elf\n\tobjcopy -O binary $< $@\n# Assemble disk image:\n# Sector 0: stage1 (512 bytes)\n# Sector 1: padding (512 bytes, stage2 starts at sector 2 per INT 13h)\n# Sector 2-9: stage2 (8 sectors = 4KB)\n# Sector 10+: kernel\nos.img: stage1.bin stage2.bin kernel.bin\n\tdd if=/dev/zero of=os.img bs=512 count=2880      # 1.44MB blank disk\n\tdd if=stage1.bin of=os.img conv=notrunc           # Write MBR\n\tdd if=stage2.bin of=os.img conv=notrunc seek=2    # Stage 2 at sector 2\n\tdd if=kernel.bin of=os.img conv=notrunc seek=10   # Kernel at sector 10\nrun: os.img\n\tqemu-system-i386 -drive file=os.img,format=raw \\\n\t                 -serial stdio \\                   # Serial \u2192 terminal\n\t                 -d int,cpu_reset \\                # Log interrupts and resets\n\t                 -no-reboot                        # Don't reboot on triple-fault\n```\n**Critical compiler flags explained:**\n- `-ffreestanding`: Tells GCC it cannot assume a standard C library or runtime is available. Functions like `memcpy` will not be implicitly linked.\n- `-fno-stack-protector`: Stack canaries require `__stack_chk_fail` from libc. Without libc, linking fails.\n- `-fno-builtin`: Prevents GCC from replacing your `memset` calls with SIMD intrinsics that assume alignment or libc presence.\n- `-nostdlib -nostdinc`: Do not search for or link standard library headers or binaries.\n- `-m32`: Compile for 32-bit x86, not the host 64-bit target.\n**Why a cross-compiler?** You are compiling code for a 32-bit bare-metal environment using a compiler that runs on your 64-bit Linux/macOS host. The host compiler's default target includes the host OS's ABI, calling conventions, and runtime assumptions. `i686-elf-gcc` targets the `i686-elf` triple: 32-bit x86 processor with ELF binary format and no operating system. Build it with `crosstool-ng` or download a prebuilt binary. Using the host `gcc` with `-m32` is tempting but will generate code linked against the host's libc and ABI \u2014 it will break in subtle ways.\n---\n## Debugging with QEMU: Your Triple-Fault Survival Guide\nTriple-faults are silent. The machine resets without any error message. Your survival tools:\n**1. QEMU flags for debugging:**\n```bash\n-d int,cpu_reset    # Log every interrupt and CPU reset to stderr\n-no-reboot          # Halt instead of rebooting on triple-fault\n-S                  # Freeze CPU at startup (wait for GDB)\n-s                  # Listen for GDB on port 1234\n```\n**2. Attach GDB:**\n```bash\ngdb kernel.elf\n(gdb) target remote :1234\n(gdb) set architecture i386\n(gdb) break kernel_main\n(gdb) continue\n```\n**3. QEMU monitor (Ctrl+Alt+2 in windowed mode):**\n```\ninfo registers      # Dump all CPU registers\ninfo tlb            # Show TLB state\nxp /10i 0x100000   # Disassemble 10 instructions at physical 0x100000\n```\n**4. Read QEMU's `-d int` output**: A triple-fault will appear as a rapid succession of exceptions. Look for the first exception \u2014 that's your actual bug. The CPU exception number, the CS:EIP at the time, and the error code tell you exactly what went wrong.\n**Common failure modes:**\n| Symptom | Likely Cause |\n|---|---|\n| CPU reset immediately after MBR loads | Boot signature `0x55AA` missing or wrong endianness |\n| CPU reset after `lgdt` | GDT base address is wrong (physical address miscalculated) |\n| CPU reset after `jmp 0x08:` | GDT descriptor 1 has wrong access byte or granularity |\n| CPU reset in first C instruction | ESP points to unmapped or read-only memory |\n| Wild behavior in C | BSS not zeroed; global variables contain garbage |\n| VGA output garbled | `volatile` missing from VGA buffer pointer |\n| Serial output missing | COM1 initialization sequence out of order |\n---\n## System Awareness: Where You Stand\n\n![x86 Boot Sequence \u2014 BIOS to C Entry Point](./diagrams/diag-m1-boot-sequence-timeline.svg)\n\nAfter this milestone, you have built the foundation layer of the OS kernel map:\n**What exists**: A 32-bit protected-mode execution environment, a valid GDT (4 privilege-level ring 0/3 code and data descriptors), a kernel binary at physical `0x100000`, a zeroed BSS section, an initialized stack, VGA and serial output, and `kprintf`.\n**What does not exist yet**: The IDT (so any exception \u2014 including a NULL pointer dereference \u2014 will triple-fault silently), any memory allocator (your kernel has no `malloc`), page tables (you're running with paging disabled, accessing physical addresses directly), and any notion of a \"process.\"\n**Immediate dependency**: Milestone 2 will install the IDT immediately. Once you have an IDT, a divide-by-zero will print a helpful error message instead of silently resetting. This single change transforms debugging from archaeology to engineering.\n---\n## Knowledge Cascade\n**1. Segment selectors unlock ring isolation.** Understanding that `0x08` is an index into the GDT \u2014 not an address \u2014 is the insight that makes ring 0/ring 3 isolation make sense at the hardware level. When you later configure user-mode segments (selectors `0x1B` and `0x23` with RPL=3), the CPU enforces privilege by comparing the current ring (CPL, in CS bits 0-1) against the descriptor's DPL on every memory access. Ring isolation is not a software fiction \u2014 it is a per-instruction hardware check.\n**2. VMA/LMA and cross-domain firmware.** The VMA vs LMA distinction in your linker script is identical to the concept of Position-Independent Code (PIC) in shared libraries, boot-time relocation in UEFI firmware, and ROM vs RAM execution in embedded systems. In all cases: the code is physically at one address (LMA), believes it's at another (VMA), and needs either a relocation mechanism or identity mapping to reconcile them. When you enable higher-half mapping in Milestone 3, you will directly experience this \u2014 the kernel will be linked at `0xC0100000` but running at `0x100000`, and every absolute address reference will be wrong until paging bridges the gap.\n**3. Freestanding C runtime and language runtime bootstrapping.** Realizing that you must manually zero BSS because there's no CRT0 connects directly to how all language runtimes bootstrap themselves. The Go runtime's `runtime.schedinit()` performs the same job \u2014 initializing `m0` and `g0` before the scheduler can function \u2014 before calling `runtime.main()`. The JVM bootstraps the root classloader before any Java code runs. JavaScript engines initialize the heap and global scope before evaluating script. Every language runtime has its own \"zero BSS and set up the stack\" moment; yours is just more visible because you wrote it in assembly.\n**4. The far jump and speculative execution.** The requirement to flush the prefetch queue after setting CR0.PE is the same physical mechanism exploited by Spectre variant 1: the CPU speculatively executes instructions based on a prediction, then the actual permission check fails \u2014 but the speculative execution has already left a cache side-channel. Understanding that the CPU's pipeline maintains state independent of privilege enforcement is the conceptual key to understanding an entire class of microarchitectural vulnerabilities.\n**5. A20 and backwards compatibility as design constraint.** The 40-year persistence of the A20 workaround reflects how hardware design decisions compound over time. The same pattern appears in: x86's continued presence of 16-bit real mode (IBM PC compatibility), BIOS firmware surviving until UEFI (PC/AT compatibility), IPv4 NAT proliferating instead of IPv6 deploying (infrastructure compatibility), and JavaScript's retained quirks despite standardization. In each case, breaking backwards compatibility has a cost that the industry keeps deciding is too high to pay. A20 is a particularly vivid example because the workaround is mechanical \u2014 a gate on a wire \u2014 rather than software.\n---\n<!-- END_MS -->\n\n\n<!-- MS_ID: build-os-m2 -->\n<!-- MS_ID: build-os-m2 -->\n# Milestone 2: Interrupts, Exceptions, and Keyboard\n\n![OS Kernel \u2014 Satellite System Map](./diagrams/diag-satellite-os-map.svg)\n\nAt the end of Milestone 1, your kernel runs \u2014 but it runs blind and deaf. If you divide by zero, the CPU triple-faults and the machine resets without a word. If the timer fires, there is no handler \u2014 the CPU fetches a garbage IDT entry and resets again. You have built a structure that can exist, but cannot yet *react*. This milestone gives your kernel senses.\nThe ability to respond to hardware events is not a luxury feature you add after the kernel works. It is the prerequisite for *everything*. Preemptive scheduling (Milestone 4) requires a timer interrupt. Demand paging (Milestone 3) requires a page fault handler. Keyboard input requires an IRQ handler. The process of converting your static, \"start once and run forever\" kernel into a dynamic system that interacts with hardware begins here, with the Interrupt Descriptor Table.\n---\n## The Misconception You Must Shed First\nHere is what application programmers think interrupts are: **callbacks**. You register a function, and when the hardware event occurs, the CPU calls it \u2014 saving state, switching context, and restoring everything just like any other function call.\nThis model is completely wrong, and believing it will produce subtly broken interrupt handlers that corrupt process state in ways that manifest hours after the interrupt fired.\nHere is what interrupts actually are: **a violent, asynchronous transfer of control that the CPU initiates mid-instruction-stream, with almost no automatic cleanup.**\nWhen an interrupt fires, the CPU does five things automatically (on a privilege-level change):\n1. Pushes **SS** (stack segment)\n2. Pushes **ESP** (stack pointer)\n3. Pushes **EFLAGS** (processor flags)\n4. Pushes **CS** (code segment)\n5. Pushes **EIP** (instruction pointer \u2014 the return address)\nThat's it. Your general-purpose registers \u2014 EAX, EBX, ECX, EDX, ESI, EDI, EBP \u2014 are **untouched**. They contain whatever the interrupted code had in them. If your interrupt handler uses EAX to do its work without saving it first, you have silently destroyed a value that the interrupted code was about to use. The interrupted code will resume and find its data corrupted. You will spend hours debugging the resulting behavior before realizing the problem was in your interrupt handler, not in the code that crashed.\nThe additional brutality: **some exceptions push an error code, and some don't.** Exceptions 8 (double fault), 10 (invalid TSS), 11 (segment not present), 12 (stack fault), 13 (general protection fault), and 14 (page fault) push an additional value onto the stack before the handler receives control. If your handler assumes there's no error code and pops EIP from the wrong position, it jumps to garbage. The stack layout changes based on *which* interrupt fired \u2014 and you won't know which one at compile time.\nThis is the real shape of interrupt handling. Everything in this milestone flows from understanding these constraints precisely.\n---\n## The Interrupt Descriptor Table: 256 Gates to the Kernel\n{{DIAGRAM:diag-m2-idt-entry-format}}\nThe IDT (Interrupt Descriptor Table) is the protected-mode equivalent of the real-mode Interrupt Vector Table. Where the IVT held flat 16-bit far pointers, the IDT holds 8-byte **gate descriptors** \u2014 structured entries that tell the CPU where to find a handler, what privilege level is required to call it, and what kind of gate controls the transition.\nYou register the IDT's location and size with the `lidt` instruction, which takes a 6-byte IDTR structure (same structure as the GDTR you loaded in Milestone 1):\n```c\nstruct idtr {\n    uint16_t limit;  // Size of IDT in bytes minus 1\n    uint32_t base;   // Linear address of IDT\n} __attribute__((packed));\n```\nThe IDT can hold up to 256 entries. You need exactly 256. Vectors 0\u201331 are reserved for CPU exceptions (architected by Intel, cannot be reassigned). Vectors 32\u2013255 are available for software and hardware interrupts.\n### Gate Descriptor Format\nEach 8-byte IDT entry encodes: the handler address (split, like GDT base addresses, across two non-contiguous fields), the segment selector to use when calling the handler, and flags that control gate type and privilege:\n```\nBytes 7-4:\n  Bits 31-16: Handler address bits 31-16 (high word)\n  Bits 15:    Present bit (P) \u2014 must be 1\n  Bits 14-13: DPL \u2014 Descriptor Privilege Level\n  Bit 12:     0 (reserved, always 0)\n  Bits 11-8:  Gate type (1110 = 32-bit interrupt gate, 1111 = 32-bit trap gate)\n  Bits 7-5:   Reserved (must be 0)\n  Bits 4-0:   Reserved (must be 0)\nBytes 3-2: Segment selector (which GDT entry to use \u2014 0x08 for kernel code)\nBytes 1-0: Handler address bits 15-0 (low word)\n```\nIn C:\n```c\nstruct idt_entry {\n    uint16_t offset_low;   // Handler address bits 0-15\n    uint16_t selector;     // GDT selector (0x08 = kernel code segment)\n    uint8_t  reserved;     // Always 0\n    uint8_t  flags;        // P=1, DPL, gate type\n    uint16_t offset_high;  // Handler address bits 16-31\n} __attribute__((packed));\nstatic struct idt_entry idt[256];\nstatic struct idtr idtr;\nvoid idt_set_gate(int vec, uint32_t handler, uint16_t sel, uint8_t flags) {\n    idt[vec].offset_low  = handler & 0xFFFF;\n    idt[vec].selector    = sel;\n    idt[vec].reserved    = 0;\n    idt[vec].flags       = flags;\n    idt[vec].offset_high = (handler >> 16) & 0xFFFF;\n}\n```\n**Gate type: interrupt gate vs trap gate.** The flags byte encodes the gate type in bits 3\u20130 (with bit 4 always 0 for 32-bit descriptors, bit 11 set for 32-bit vs 16-bit):\n- **Interrupt gate** (`0x8E` = `1000 1110`): The CPU automatically clears the IF (interrupt flag) on entry, preventing nested interrupts. Use this for hardware IRQ handlers where you don't want re-entrant interrupts from the same device.\n- **Trap gate** (`0x8F` = `1000 1111`): The IF flag is **not** cleared. Interrupts can nest. Use this for software exceptions like the system call gate (`INT 0x80`) \u2014 you want the kernel to remain interruptible while processing a syscall.\nFor hardware IRQ handlers (timer, keyboard) and CPU exception handlers, use interrupt gates (`0x8E`). For the system call interface (Milestone 4), you'll use a trap gate with DPL=3 so user code can invoke it.\nThe DPL field controls who can *invoke* the gate with a software `int n` instruction. DPL=0 means only ring 0 code can use `int n` to trigger this vector. DPL=3 lets user-mode code trigger it. Hardware interrupts bypass this check entirely \u2014 they fire regardless of DPL.\n---\n## The Stack Frame Problem: Every Handler Must Know Its Layout\n\n![Interrupt Stack Frame \u2014 With and Without Error Code](./diagrams/diag-m2-interrupt-stack-frame.svg)\n\nBefore writing a single interrupt handler, you must understand exactly what the stack looks like when your handler receives control. This is the most error-prone part of interrupt handling, and getting it wrong produces stack corruption that is nearly impossible to debug.\n**Without error code (exceptions 0-7, 9, 15-31, and all IRQs):**\n```\n[ESP+16] EFLAGS\n[ESP+12] CS\n[ESP+8]  EIP       \u2190 return address\n[ESP+4]  (nothing \u2014 ESP was decremented to here)\n[ESP+0]  \u2190 ESP when handler is called (if you pushed nothing yet)\n```\nAfter `pusha` (which pushes EAX, ECX, EDX, EBX, ESP, EBP, ESI, EDI \u2014 32 bytes):\n```\n[ESP+48] EFLAGS\n[ESP+44] CS\n[ESP+40] EIP\n[ESP+36] EDI (from pusha)\n[ESP+32] ESI\n[ESP+28] EBP\n[ESP+24] old ESP (as it was before interrupt \u2014 pushed by pusha)\n[ESP+20] EBX\n[ESP+16] EDX\n[ESP+12] ECX\n[ESP+8]  EAX\n[ESP+0]  \u2190 ESP after pusha\n```\n**With error code (exceptions 8, 10-14):**\nThe CPU pushes the error code *before* the handler receives control, slipping it between EIP and the handler's own stack frame:\n```\n[ESP+16] EFLAGS\n[ESP+12] CS\n[ESP+8]  EIP\n[ESP+4]  Error code  \u2190 pushed by CPU for exceptions 8, 10-14\n[ESP+0]  \u2190 ESP when handler is called\n```\nAfter `pusha`:\n```\n[ESP+52] EFLAGS\n[ESP+48] CS\n[ESP+44] EIP\n[ESP+40] Error code\n[ESP+36] EDI\n...\n[ESP+0]  \u2190 ESP after pusha\n```\nThe error code must be removed from the stack before `iret` \u2014 otherwise `iret` pops it as EFLAGS and restores execution to a garbage address. You must either `pop` it (discard it or save it to a C variable) or `add esp, 4` before the `popa`/`iret` sequence.\n**The correct approach for a unified ISR stub system:**\nRather than writing 256 separate assembly stubs by hand, you write **two stub templates** \u2014 one for exceptions without error codes and one for exceptions with error codes \u2014 and use a macro to generate all 256:\n```nasm\n%macro ISR_NOERR 1\nisr_%1:\n    push dword 0        ; Push fake error code (maintain uniform stack layout)\n    push dword %1       ; Push interrupt number\n    jmp isr_common_stub\n%endmacro\n%macro ISR_ERR 1\nisr_%1:\n                        ; CPU already pushed error code\n    push dword %1       ; Push interrupt number\n    jmp isr_common_stub\n%endmacro\n```\nThe fake error code for ISR_NOERR is the key insight: by pushing `0` for exceptions that don't produce an error code, you make the stack frame **uniform**. Your C handler receives the same structure regardless of which exception fired:\n```c\nstruct interrupt_frame {\n    // Pushed by pusha (in reverse order \u2014 EDI pushed last, so lowest address)\n    uint32_t edi, esi, ebp, esp_dummy, ebx, edx, ecx, eax;\n    // Pushed by our stub\n    uint32_t int_no;\n    uint32_t err_code;  // 0 for exceptions that don't push one\n    // Pushed by CPU\n    uint32_t eip, cs, eflags;\n    uint32_t user_esp, user_ss;  // Only present if privilege level changed\n};\n```\nThe common stub:\n```nasm\nisr_common_stub:\n    pusha               ; Save all general-purpose registers (EDI, ESI, EBP, ESP, EBX, EDX, ECX, EAX)\n    push ds             ; Save segment registers\n    push es\n    push fs\n    push gs\n    mov ax, 0x10        ; Load kernel data segment\n    mov ds, ax\n    mov es, ax\n    mov fs, ax\n    mov gs, ax\n    push esp            ; Pass pointer to saved register frame as argument to C handler\n    call interrupt_dispatch ; C function: void interrupt_dispatch(struct interrupt_frame *)\n    add esp, 4          ; Clean up pushed argument\n    pop gs\n    pop fs\n    pop es\n    pop ds\n    popa\n    add esp, 8          ; Remove int_no and err_code from stack\n    iret                ; Restores EIP, CS, EFLAGS (and ESP, SS if privilege changed)\n```\nGenerate the 256 stubs with macros:\n```nasm\nISR_NOERR 0    ; Divide error\nISR_NOERR 1    ; Debug\nISR_NOERR 2    ; NMI\nISR_NOERR 3    ; Breakpoint\nISR_NOERR 4    ; Overflow\nISR_NOERR 5    ; Bound range exceeded\nISR_NOERR 6    ; Invalid opcode\nISR_NOERR 7    ; Device not available (FPU)\nISR_ERR   8    ; Double fault\nISR_NOERR 9    ; Coprocessor segment overrun (obsolete)\nISR_ERR   10   ; Invalid TSS\nISR_ERR   11   ; Segment not present\nISR_ERR   12   ; Stack fault\nISR_ERR   13   ; General protection fault\nISR_ERR   14   ; Page fault\nISR_NOERR 15   ; Reserved\nISR_NOERR 16   ; x87 floating-point exception\nISR_ERR   17   ; Alignment check\nISR_NOERR 18   ; Machine check\nISR_NOERR 19   ; SIMD floating-point exception\n; ... 20-31: ISR_NOERR\n; ... 32-255: IRQ handlers (ISR_NOERR, CPU doesn't push error codes for IRQs)\n```\nThen in your IDT initialization:\n```c\nvoid idt_init(void) {\n    // CPU exceptions\n    idt_set_gate(0,  (uint32_t)isr_0,  0x08, 0x8E);\n    idt_set_gate(1,  (uint32_t)isr_1,  0x08, 0x8E);\n    // ... all 256 entries\n    idt_set_gate(13, (uint32_t)isr_13, 0x08, 0x8E);\n    idt_set_gate(14, (uint32_t)isr_14, 0x08, 0x8E);\n    // IRQs (after PIC remapping \u2014 see next section)\n    idt_set_gate(32, (uint32_t)isr_32, 0x08, 0x8E); // Timer (IRQ0 \u2192 vector 32)\n    idt_set_gate(33, (uint32_t)isr_33, 0x08, 0x8E); // Keyboard (IRQ1 \u2192 vector 33)\n    // ...\n    idtr.limit = sizeof(idt) - 1;\n    idtr.base  = (uint32_t)idt;\n    __asm__ volatile (\"lidt [%0]\" : : \"r\"(&idtr));\n}\n```\n> **Hardware Soul**: Each IDT gate lookup requires the CPU to read an 8-byte structure from memory. This happens for every interrupt and exception. The IDT is almost always hot in L1 cache because it's accessed frequently \u2014 but the first lookup after a cache eviction costs a full memory read. The `idtr` register itself (a CPU internal register) holds the base and limit, so the CPU doesn't re-read the IDTR structure on every interrupt \u2014 only the table entry pointed to by `idtr.base + (vector \u00d7 8)`. On modern out-of-order CPUs, the interrupt arrival causes a pipeline flush (the interrupt itself is a control-flow redirect), costing 10-20 cycles before your handler begins executing, before any register saves. This overhead is fundamental and irreducible \u2014 it's why RTOS kernels measuring interrupt latency in microseconds treat every saved register as a real cost.\n---\n## CPU Exception Vectors: What Each One Means\n\n![CPU Exception Vectors 0-31 \u2014 Classification Table](./diagrams/diag-m2-exception-vector-table.svg)\n\nIntel defines 32 exception vectors (0\u201331). Understanding what triggers each one matters for debugging \u2014 when your kernel triple-faults during development, the specific exception number tells you exactly what went wrong:\n| Vector | Mnemonic | Cause | Error Code? | Type |\n|--------|----------|-------|-------------|------|\n| 0  | #DE | Division by zero or overflow | No | Fault |\n| 1  | #DB | Debug \u2014 breakpoint or single-step | No | Fault/Trap |\n| 2  | #NMI | Non-maskable interrupt (hardware failure) | No | Interrupt |\n| 3  | #BP | Breakpoint (`int3` instruction) | No | Trap |\n| 4  | #OF | Overflow (`into` instruction) | No | Trap |\n| 5  | #BR | BOUND range exceeded | No | Fault |\n| 6  | #UD | Invalid opcode | No | Fault |\n| 7  | #NM | Device not available (FPU/MMX) | No | Fault |\n| 8  | #DF | **Double fault** | Yes (always 0) | Abort |\n| 9  | \u2014 | Coprocessor overrun (obsolete) | No | Fault |\n| 10 | #TS | Invalid TSS | Yes | Fault |\n| 11 | #NP | Segment not present | Yes | Fault |\n| 12 | #SS | Stack segment fault | Yes | Fault |\n| 13 | #GP | **General protection fault** | Yes | Fault |\n| 14 | #PF | **Page fault** | Yes | Fault |\n| 15 | \u2014 | Reserved | \u2014 | \u2014 |\n| 16 | #MF | x87 floating-point exception | No | Fault |\n| 17 | #AC | Alignment check | Yes | Fault |\n| 18 | #MC | Machine check (hardware error) | No | Abort |\n| 19 | #XM | SIMD floating-point exception | No | Fault |\n| 20-31 | \u2014 | Reserved | \u2014 | \u2014 |\n**Fault vs Trap vs Abort:** These describe whether EIP points to the faulting instruction or the next one when the exception fires, and whether recovery is possible:\n- **Fault**: EIP points to the faulting instruction. The handler can fix the condition and restart the instruction (e.g., page fault \u2014 map the page, then re-execute the faulting memory access).\n- **Trap**: EIP points to the instruction *after* the trap. The instruction executed; the trap fires afterward (e.g., breakpoint \u2014 the `int3` ran, now you handle it).\n- **Abort**: The CPU cannot reliably save or restore state. Recovery is impossible; the system must halt (e.g., machine check, double fault).\n**The three exceptions you'll encounter most during development:**\n**#DE (0) \u2014 Divide by zero.** Null pointer arithmetic, integer division, or integer overflow via `idiv`. Easy to trigger with `int x = 1/0;`. Your handler should print a message and halt (or kill the current process in Milestone 4).\n**#GP (13) \u2014 General protection fault.** The catch-all for protection violations. Caused by: accessing a segment descriptor with wrong DPL, using a null segment selector, executing a privileged instruction from ring 3, or any number of other protection violations. The error code encodes which segment selector (if any) caused the fault. Print the error code and EIP from the interrupt frame to diagnose.\n**#PF (14) \u2014 Page fault.** Fired when an access violates page permissions or accesses an unmapped page. The faulting address is in CR2 (not the frame \u2014 you must read CR2 explicitly). The error code encodes: bit 0 (P) = page present when fault occurred (0 = page not mapped, 1 = permission violation), bit 1 (W) = write access, bit 2 (U) = user-mode access. In Milestone 3, your page fault handler will implement demand paging by inspecting these bits. For now, print them and halt.\nYour dispatch function in C:\n```c\nstatic const char *exception_names[] = {\n    \"Division Error\",          \"Debug\",\n    \"Non-Maskable Interrupt\",  \"Breakpoint\",\n    \"Overflow\",                \"Bound Range Exceeded\",\n    \"Invalid Opcode\",          \"Device Not Available\",\n    \"Double Fault\",            \"Coprocessor Segment Overrun\",\n    \"Invalid TSS\",             \"Segment Not Present\",\n    \"Stack Fault\",             \"General Protection Fault\",\n    \"Page Fault\",              \"Reserved\",\n    \"x87 Floating-Point\",      \"Alignment Check\",\n    \"Machine Check\",           \"SIMD Floating-Point\",\n    /* 20-31 reserved */\n};\nvoid interrupt_dispatch(struct interrupt_frame *frame) {\n    if (frame->int_no < 32) {\n        // CPU exception\n        kprintf(\"\\n\\033[31m[EXCEPTION #%d: %s]\\033[0m\\n\",\n                frame->int_no,\n                frame->int_no < 20 ? exception_names[frame->int_no] : \"Reserved\");\n        kprintf(\"  EIP=0x%x  CS=0x%x  EFLAGS=0x%x\\n\",\n                frame->eip, frame->cs, frame->eflags);\n        kprintf(\"  EAX=0x%x  EBX=0x%x  ECX=0x%x  EDX=0x%x\\n\",\n                frame->eax, frame->ebx, frame->ecx, frame->edx);\n        kprintf(\"  Error code: 0x%x\\n\", frame->err_code);\n        if (frame->int_no == 14) {\n            uint32_t cr2;\n            __asm__ volatile (\"mov %0, cr2\" : \"=r\"(cr2));\n            kprintf(\"  Page fault at address: 0x%x (P=%d W=%d U=%d)\\n\",\n                    cr2,\n                    frame->err_code & 1,\n                    (frame->err_code >> 1) & 1,\n                    (frame->err_code >> 2) & 1);\n        }\n        if (frame->int_no == 8) {\n            kprintf(\"  DOUBLE FAULT \u2014 halting\\n\");\n            for (;;) __asm__ volatile (\"cli; hlt\");\n        }\n        kprintf(\"  System halted.\\n\");\n        for (;;) __asm__ volatile (\"cli; hlt\");\n    } else if (frame->int_no < 48) {\n        // Hardware IRQ (32-47)\n        irq_dispatch(frame->int_no - 32, frame);\n    }\n}\n```\n---\n## The Double Fault: Your Last Line of Defense\n\n![Exception Cascading \u2014 Fault \u2192 Double Fault \u2192 Triple Fault](./diagrams/diag-m2-double-fault-cascade.svg)\n\nThe double fault (#DF, vector 8) deserves special attention because it is the CPU's emergency backstop before the catastrophic **triple fault** that resets the machine.\nHere is the cascade:\n1. An exception fires (e.g., #GP at vector 13).\n2. The CPU tries to call the handler at `idt[13]`.\n3. If *that* fails \u2014 because the IDT entry is invalid, the stack is corrupt, the handler address is unmapped \u2014 the CPU tries to invoke the double fault handler at `idt[8]`.\n4. If *that* fails \u2014 the double fault handler itself triggers an exception \u2014 the CPU has no recourse. It raises a **triple fault**, which is not an exception at all but a CPU reset signal. The machine reboots with no message.\nThe double fault handler protects you from triple faults during development. During the period when your IDT is partially set up, or when you introduce a bug that corrupts the stack, the double fault handler is the difference between \"kernel panics with a message\" and \"machine silently reboots.\"\nThe double fault always pushes error code `0` (it's fixed \u2014 the CPU can't tell you which original fault caused it). Your double fault handler should:\n```c\n// In interrupt_dispatch, for int_no == 8:\nkprintf(\"[DOUBLE FAULT] The kernel encountered an unrecoverable error.\\n\");\nkprintf(\"EIP=0x%x  ESP=0x%x  EFLAGS=0x%x\\n\",\n        frame->eip, frame->esp_dummy, frame->eflags);\nkprintf(\"This indicates stack corruption, invalid IDT entry,\\n\");\nkprintf(\"or an exception during exception handling.\\n\");\nkprintf(\"Error code (always 0): 0x%x\\n\", frame->err_code);\nfor (;;) __asm__ volatile (\"cli; hlt\");\n```\n> **Practical note on the double fault stack**: The double fault handler requires a valid stack to push its frame onto. If the original fault was caused by stack corruption (ESP pointing to unmapped memory), then the CPU may not even be able to deliver the double fault \u2014 triggering a triple fault immediately. The robust solution is a **dedicated double fault stack** referenced through a separate TSS. This is the Task Gate mechanism: `idt[8]` points to a Task Gate descriptor that performs a hardware task switch to a minimal TSS with its own stack. This is the only interrupt that conventionally uses a task gate on x86. For your implementation, a simple interrupt gate is fine for now \u2014 it handles the common debugging case where the fault was a logic error rather than stack pointer corruption.\n---\n## The PIC Crisis: Why Your Timer and Double Fault Collide\n{{DIAGRAM:diag-m2-pic-remapping}}\nThis is the most counterintuitive problem in x86 interrupt setup, and it affects every kernel implementer the first time they encounter it.\nThe Intel 8259 PIC (Programmable Interrupt Controller) is the chip that routes hardware interrupts \u2014 timer, keyboard, serial ports, disk controllers \u2014 to the CPU. Your system has two of them: a master PIC and a slave PIC cascaded together, collectively handling 16 IRQ lines (IRQ0\u2013IRQ15).\n{{DIAGRAM:diag-m2-pic-cascade-architecture}}\n**The original IBM PC mapped IRQs to CPU vectors starting at 8:**\n- Master PIC: IRQ0 (timer) \u2192 vector 8, IRQ1 (keyboard) \u2192 vector 9, ..., IRQ7 \u2192 vector 15\n- Slave PIC: IRQ8 \u2192 vector 70, ..., IRQ15 \u2192 vector 77\nIn real mode, this was fine. Vectors 0\u20137 were CPU exceptions in the real-mode IVT, but the IVT entries were just data \u2014 there was no hardware enforcement. Real-mode software could use both.\n**In protected mode, this mapping is catastrophic.**\nThe CPU defines vectors 0\u201331 as CPU exceptions with precise meanings. Vector 8 is **the double fault**. Vector 13 is **the general protection fault**. Vector 14 is **the page fault**.\nWith the default PIC mapping:\n- IRQ0 (timer tick) \u2192 vector 8 \u2192 **double fault**\n- IRQ1 (key pressed) \u2192 vector 9 \u2192 **coprocessor overrun**\nThe CPU cannot distinguish between \"the timer fired\" and \"the kernel has experienced a cascading fault.\" Your timer ISR would be called in what the CPU believes is a double fault context. If you enable interrupts before remapping the PIC, the first timer tick triggers what looks like a double fault, your double fault handler runs (if it exists), and everything is wrong.\n**The fix: remap both PICs before enabling interrupts.**\nThe 8259 PIC is configured through a sequence of Initialization Command Words (ICW1\u2013ICW4) written to specific I/O ports. You must reinitialize both PICs with new base vectors:\n- Master PIC: IRQ0\u2013IRQ7 \u2192 vectors 32\u201339\n- Slave PIC: IRQ8\u2013IRQ15 \u2192 vectors 40\u201347\n```c\n#define PIC_MASTER_CMD   0x20\n#define PIC_MASTER_DATA  0x21\n#define PIC_SLAVE_CMD    0xA0\n#define PIC_SLAVE_DATA   0xA1\n#define ICW1_INIT  0x10  // Initialization command\n#define ICW1_ICW4  0x01  // ICW4 is required\n#define ICW4_8086  0x01  // 8086/88 mode (as opposed to MCS-80 mode)\nstatic inline void io_wait(void) {\n    // Write to port 0x80 (unused) to introduce ~1-4\u03bcs delay\n    // Required for old ISA hardware that needs time to process commands\n    outb(0x80, 0);\n}\nvoid pic_remap(uint8_t master_offset, uint8_t slave_offset) {\n    // Save current interrupt masks\n    uint8_t master_mask = inb(PIC_MASTER_DATA);\n    uint8_t slave_mask  = inb(PIC_SLAVE_DATA);\n    // ICW1: Start initialization sequence (cascade mode)\n    outb(PIC_MASTER_CMD, ICW1_INIT | ICW1_ICW4);\n    io_wait();\n    outb(PIC_SLAVE_CMD,  ICW1_INIT | ICW1_ICW4);\n    io_wait();\n    // ICW2: Set vector offsets\n    outb(PIC_MASTER_DATA, master_offset); // Master: IRQ0 \u2192 vector 32\n    io_wait();\n    outb(PIC_SLAVE_DATA,  slave_offset);  // Slave: IRQ8 \u2192 vector 40\n    io_wait();\n    // ICW3: Tell master that slave is on IRQ2; tell slave its cascade identity\n    outb(PIC_MASTER_DATA, 0x04); // Master: slave connected at IRQ2 (bit 2 = 0b00000100)\n    io_wait();\n    outb(PIC_SLAVE_DATA,  0x02); // Slave: its cascade identity is IRQ2 (binary 010)\n    io_wait();\n    // ICW4: Set 8086 mode\n    outb(PIC_MASTER_DATA, ICW4_8086);\n    io_wait();\n    outb(PIC_SLAVE_DATA,  ICW4_8086);\n    io_wait();\n    // Restore interrupt masks\n    // (Mask all IRQs except timer (bit 0) and keyboard (bit 1))\n    outb(PIC_MASTER_DATA, master_mask);\n    outb(PIC_SLAVE_DATA,  slave_mask);\n}\n// Call this during kernel initialization, before sti\nvoid pic_init(void) {\n    pic_remap(0x20, 0x28); // Master starts at 32 (0x20), slave at 40 (0x28)\n    // Mask all IRQs initially, unmask only what we handle\n    outb(PIC_MASTER_DATA, 0xFC); // 1111 1100 = mask all except IRQ0 (timer) and IRQ1 (keyboard)\n    outb(PIC_SLAVE_DATA,  0xFF); // 1111 1111 = mask all slave IRQs\n}\n```\n> **Why `io_wait()`?** The old ISA bus (on which the 8259 PIC originated) runs at 8MHz, far slower than modern CPUs. Writing multiple bytes to PIC ports too quickly doesn't give the PIC time to process each command before the next arrives. The `io_wait()` function writes to port 0x80 \u2014 a port that doesn't correspond to any real hardware, used only as a delay mechanism \u2014 to burn a few hundred nanoseconds between writes. On modern systems this is rarely necessary, but it costs nothing and prevents mysterious failures on real hardware.\n---\n## The EOI Protocol: Acknowledgment as Flow Control\nAfter your IRQ handler runs, you must send an **End of Interrupt** (EOI) signal to the PIC. Without it, the PIC stops delivering interrupts \u2014 not just from the IRQ that fired, but all further interrupts at that priority level or lower.\nThe reason: the 8259 PIC uses **interrupt service register (ISR)** tracking. When it delivers an IRQ to the CPU, it sets the corresponding bit in its ISR register, which blocks further interrupts at that priority until the bit is cleared. The EOI command clears it. The PIC is literally waiting for your acknowledgment before it will deliver another interrupt.\nThis is the same flow-control pattern as TCP: the sender (PIC) cannot send more data (interrupts) until the receiver (CPU/kernel) acknowledges (EOI). The same concept appears in USB, PCIe, and HTTP/2 flow control windows \u2014 all prevent a fast producer from overwhelming a slow consumer.\n```c\n#define PIC_EOI 0x20\nvoid pic_send_eoi(uint8_t irq) {\n    if (irq >= 8) {\n        // Slave PIC also needs EOI for IRQ8-15\n        outb(PIC_SLAVE_CMD, PIC_EOI);\n    }\n    // Master PIC always gets EOI\n    outb(PIC_MASTER_CMD, PIC_EOI);\n}\n```\n**The master/slave distinction is critical.** For IRQ0\u2013IRQ7 (master only), send EOI only to the master. For IRQ8\u2013IRQ15 (slave PICs), send EOI to both slave and master \u2014 the slave must release the IRQ, and the master must release IRQ2 (the cascade line that the slave connects through).\nYour IRQ dispatch function:\n```c\nvoid irq_dispatch(uint8_t irq, struct interrupt_frame *frame) {\n    switch (irq) {\n        case 0: timer_handler(frame); break;\n        case 1: keyboard_handler(frame); break;\n        default: break; // Spurious or unhandled IRQ\n    }\n    pic_send_eoi(irq);\n}\n```\n**Spurious IRQs**: Sometimes the PIC reports an interrupt that didn't actually occur \u2014 a \"spurious IRQ.\" This happens when the CPU acknowledges an interrupt that the PIC has since cancelled (due to electrical noise or race conditions). IRQ7 (master spurious) and IRQ15 (slave spurious) are the designated spurious vectors. A robust kernel checks the PIC's In-Service Register (ISR) before processing these:\n```c\n// Read PIC In-Service Register\nuint16_t pic_get_isr(void) {\n    outb(PIC_MASTER_CMD, 0x0B); // OCW3: read ISR\n    outb(PIC_SLAVE_CMD,  0x0B);\n    return (inb(PIC_SLAVE_CMD) << 8) | inb(PIC_MASTER_CMD);\n}\n```\nIf bit 7 of the master ISR is not set when IRQ7 fires, it's spurious \u2014 don't send EOI, don't process. For IRQ15 spurious, send EOI only to the master (the slave didn't actually assert an interrupt).\n---\n## The PIT Timer: Heartbeat of Your Kernel\n{{DIAGRAM:diag-m2-pit-timer-programming}}\nThe PIT (Programmable Interval Timer, Intel 8253/8254) generates periodic interrupts on IRQ0. It is the clock source for your kernel tick \u2014 the regular interval at which the scheduler will run (Milestone 4) and from which all timekeeping derives.\nThe PIT has an internal oscillator running at exactly 1,193,182 Hz (this frequency comes from dividing the original IBM PC's 14.318 MHz crystal by 12, then by 4 \u2014 a chain of historical accidents that became a permanent standard). You program a **divisor**: the PIT divides its input frequency by your divisor and fires an interrupt at the resulting rate.\n```\nTimer frequency = 1,193,182 Hz / divisor\nDivisor = 1,193,182 / desired_frequency\n```\nFor 100Hz (10ms tick interval): divisor = 1193182 / 100 = 11931 (\u2248 11932).\n```c\n#define PIT_CHANNEL0  0x40  // Channel 0 data port\n#define PIT_COMMAND   0x43  // Mode/command register\nvoid pit_init(uint32_t frequency) {\n    uint16_t divisor = 1193182 / frequency;\n    // Command byte: channel 0, access mode=lo/hi byte, mode 3 (square wave), binary\n    // Bits: 7-6=channel(00), 5-4=access(11=lo+hi), 3-1=mode(011=square wave), 0=binary(0)\n    outb(PIT_COMMAND, 0x36);\n    // Write divisor: low byte first, then high byte\n    outb(PIT_CHANNEL0, divisor & 0xFF);\n    outb(PIT_CHANNEL0, (divisor >> 8) & 0xFF);\n}\n```\n**Mode 3 (square wave generator)** is the standard mode for a timer: it fires an interrupt every `divisor` input ticks, then reloads and repeats automatically. You set it once and it runs forever without further programming.\nYour timer handler:\n```c\nstatic volatile uint64_t tick_counter = 0;\nvoid timer_handler(struct interrupt_frame *frame) {\n    tick_counter++;\n    // In Milestone 4, this becomes: schedule(); (preempt current process)\n}\nuint64_t pit_get_ticks(void) {\n    return tick_counter;\n}\nuint64_t pit_get_ms(void) {\n    return tick_counter * 10; // At 100Hz, each tick = 10ms\n}\n```\n**Why `volatile`?** The `tick_counter` is modified in an interrupt handler (asynchronously) and read from non-interrupt code (synchronously). Without `volatile`, the compiler may cache the value in a register and never re-read it from memory, causing the non-interrupt code to see a stale value. `volatile` forces every read to fetch from memory.\n> **Interrupt Latency and Real-Time Systems**: The overhead you're experiencing \u2014 saving 8 general-purpose registers, 4 segment registers, plus the 5 values the CPU pushes automatically \u2014 is 17 values \u00d7 4 bytes = 68 bytes of stack writes on every interrupt. At 100Hz this costs effectively nothing. But consider a system with 10,000 interrupts/second (e.g., a network driver at 10Gbps with small packets): interrupt overhead becomes a measurable fraction of CPU time. This is why RTOS kernels (FreeRTOS, VxWorks, Zephyr) minimize what they save/restore in ISRs and immediately defer work to \"bottom-half\" handlers that run in a task context. Linux's softirq/tasklet system and the NET_RX_SOFTIRQ that processes network packets are direct responses to this overhead. The PREEMPT_RT patchset takes this further \u2014 making interrupt handlers themselves preemptible by converting them to kernel threads, reducing worst-case latency at the cost of some throughput.\n**Initialize everything, then enable interrupts:**\n```c\nvoid kernel_main(void) {\n    vga_clear();\n    serial_init();\n    kprintf(\"Kernel started.\\n\");\n    gdt_init();           // Already done in M1\n    idt_init();           // Set up all 256 IDT entries\n    pic_remap(0x20, 0x28); // Remap PICs BEFORE enabling interrupts\n    pit_init(100);        // 100Hz timer\n    __asm__ volatile (\"sti\"); // NOW it is safe to enable interrupts\n    kprintf(\"Interrupts enabled. Tick: %llu\\n\", pit_get_ticks());\n    for (;;) {\n        __asm__ volatile (\"hlt\"); // Wait for next interrupt\n    }\n}\n```\nThe `hlt` instruction in the main loop is intentional: it halts the CPU until the next interrupt, reducing power consumption and making QEMU simulation cheaper. The kernel's \"idle\" state is resting between interrupts.\n---\n## The PS/2 Keyboard Driver\n\n![PS/2 Keyboard \u2014 Scancode to ASCII Pipeline](./diagrams/diag-m2-keyboard-scancode-pipeline.svg)\n\nWhen you press a key on a PS/2 keyboard, the keyboard controller generates an IRQ1. Reading port `0x60` gives you a **scancode** \u2014 a hardware-specific code number that identifies which key was pressed or released, independent of any software notion of ASCII characters.\n### Scancodes: Make and Break\nPS/2 keyboards generate two scancodes per key event:\n- **Make code** (key press): The scancode for the key, e.g., `0x1E` for 'A'.\n- **Break code** (key release): The make code with bit 7 set, e.g., `0x9E` for releasing 'A'.\nYour driver must distinguish between these. Make code arrives with bit 7 clear. Break code arrives with bit 7 set (value \u2265 `0x80`). If you ignore break codes and treat every scancode as a key press, holding down 'A' generates a stream of make codes from the keyboard's autorepeat \u2014 which is correct \u2014 but releasing 'A' then sends `0x9E`, which your scancode table maps to nothing (or garbage) if you haven't masked bit 7. Even worse, if you track modifier key state (Shift, Ctrl, Alt), you must see the break code to know when the modifier was released.\n### Scancode Set 1 to ASCII\nThe mapping from PS/2 Set 1 scancodes to ASCII is a lookup table:\n```c\nstatic const char scancode_to_ascii[128] = {\n    0,   27, '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '-', '=',\n    '\\b', '\\t', 'q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p', '[', ']',\n    '\\n', 0, 'a', 's', 'd', 'f', 'g', 'h', 'j', 'k', 'l', ';', '\\'', '`',\n    0, '\\\\', 'z', 'x', 'c', 'v', 'b', 'n', 'm', ',', '.', '/', 0,\n    '*', 0, ' ', 0,  // Caps Lock, F1-F12, etc.\n    // ... entries 58-127 are function keys, numpad, etc. (0 = no ASCII representation)\n};\nstatic const char scancode_to_ascii_shift[128] = {\n    0,   27, '!', '@', '#', '$', '%', '^', '&', '*', '(', ')', '_', '+',\n    '\\b', '\\t', 'Q', 'W', 'E', 'R', 'T', 'Y', 'U', 'I', 'O', 'P', '{', '}',\n    '\\n', 0, 'A', 'S', 'D', 'F', 'G', 'H', 'J', 'K', 'L', ':', '\"', '~',\n    0, '|', 'Z', 'X', 'C', 'V', 'B', 'N', 'M', '<', '>', '?', 0,\n    '*', 0, ' ', 0,\n};\n```\nModifier tracking:\n```c\nstatic int shift_pressed = 0;\nstatic int ctrl_pressed  = 0;\nstatic int alt_pressed   = 0;\n#define SCANCODE_LSHIFT 0x2A\n#define SCANCODE_RSHIFT 0x36\n#define SCANCODE_LCTRL  0x1D\n#define SCANCODE_LALT   0x38\n#define SCANCODE_CAPS   0x3A\n```\n### Circular Keyboard Buffer\nThe keyboard driver must not block the IRQ handler. The handler's job is minimal: read the scancode, convert it to ASCII, and put it in a buffer. Something else \u2014 a `keyboard_read()` function called from kernel or user code \u2014 consumes from that buffer.\nThis is a **circular buffer** (also called a ring buffer): a fixed-size array where `head` tracks the next position to write and `tail` tracks the next position to read. When a pointer reaches the end of the array, it wraps back to 0.\n```c\n#define KEYBOARD_BUFFER_SIZE 256  // Must be power of 2 for efficient wrapping\ntypedef struct {\n    char    buf[KEYBOARD_BUFFER_SIZE];\n    uint8_t head;  // Next write position\n    uint8_t tail;  // Next read position\n} ring_buffer_t;\nstatic ring_buffer_t kbd_buf = {0};\nstatic int ring_full(ring_buffer_t *rb) {\n    return ((rb->head + 1) % KEYBOARD_BUFFER_SIZE) == rb->tail;\n}\nstatic int ring_empty(ring_buffer_t *rb) {\n    return rb->head == rb->tail;\n}\nstatic void ring_push(ring_buffer_t *rb, char c) {\n    if (!ring_full(rb)) {\n        rb->buf[rb->head] = c;\n        rb->head = (rb->head + 1) % KEYBOARD_BUFFER_SIZE;\n    }\n    // If full: silently drop. Real OSes might set a \"keyboard overrun\" flag.\n}\nstatic char ring_pop(ring_buffer_t *rb) {\n    if (ring_empty(rb)) return 0;\n    char c = rb->buf[rb->tail];\n    rb->tail = (rb->tail + 1) % KEYBOARD_BUFFER_SIZE;\n    return c;\n}\n```\n> **Circular buffers across the stack**: The keyboard buffer you just built is the same data structure that powers io_uring's submission and completion queues (the kernel shares ring buffer memory with user space \u2014 no syscall needed per I/O completion), DPDK's packet rings (NIC driver writes, application reads, both lock-free with a single producer and single consumer), Linux's `pipe` (reading and writing processes share a circular 64KB buffer), and audio driver DMA buffers (the sound card DMA-writes audio data into a ring; your driver reads it out). When the producer index (head) and consumer index (tail) are maintained by different \"actors\" \u2014 in your case, the IRQ handler and kernel code \u2014 the structure becomes a **lock-free single-producer single-consumer queue**, one of the few data structures that can be implemented safely without atomics when both producer and consumer run on the same CPU. This is because interrupt handlers can only *interrupt* running code \u2014 they can't run concurrently on a single-core system.\nThe complete keyboard IRQ handler:\n```c\nvoid keyboard_handler(struct interrupt_frame *frame) {\n    (void)frame;\n    uint8_t scancode = inb(0x60); // Read scancode from PS/2 data port\n    if (scancode & 0x80) {\n        // Break code (key release) \u2014 strip the high bit to get the key\n        uint8_t key = scancode & 0x7F;\n        if (key == SCANCODE_LSHIFT || key == SCANCODE_RSHIFT) shift_pressed = 0;\n        if (key == SCANCODE_LCTRL)  ctrl_pressed  = 0;\n        if (key == SCANCODE_LALT)   alt_pressed   = 0;\n        return; // Don't add to buffer on key release\n    }\n    // Make code (key press)\n    if (scancode == SCANCODE_LSHIFT || scancode == SCANCODE_RSHIFT) {\n        shift_pressed = 1;\n        return;\n    }\n    if (scancode == SCANCODE_LCTRL) { ctrl_pressed = 1; return; }\n    if (scancode == SCANCODE_LALT)  { alt_pressed  = 1; return; }\n    // Convert scancode to ASCII\n    char ascii;\n    if (shift_pressed) {\n        ascii = scancode_to_ascii_shift[scancode];\n    } else {\n        ascii = scancode_to_ascii[scancode];\n    }\n    if (ascii != 0) {\n        ring_push(&kbd_buf, ascii);\n    }\n    // EOI is sent by irq_dispatch after this returns\n}\n// Called by kernel or shell code to read a character (blocking)\nchar keyboard_getchar(void) {\n    while (ring_empty(&kbd_buf)) {\n        __asm__ volatile (\"hlt\"); // Wait for an interrupt to fill the buffer\n    }\n    return ring_pop(&kbd_buf);\n}\n```\n> **Hardware Soul**: Port 0x60 is the PS/2 controller data register. Reading it consumes the byte \u2014 the keyboard controller dequeues it and will not deliver the next scancode until the current one is read. This means if you fail to read port 0x60 in your IRQ handler (e.g., the handler doesn't execute because EOI was sent but data wasn't read), the keyboard controller holds the unread byte and the keyboard may stop generating interrupts until it's consumed. Always read port 0x60 in every keyboard IRQ handler, regardless of what you do with the byte. The controller at I/O port base 0x60/0x64 is the Intel 8042 (or a compatible implementation in the chipset), which mediates PS/2 protocol (a serial protocol at 10\u201313kHz) and presents data to the CPU through the familiar port interface.\n---\n## The Complete Initialization Sequence\nThe order of operations matters. Here is the canonical sequence, with the reasoning for each step:\n```c\nvoid kernel_main(void) {\n    // 1. VGA + serial (already working from M1)\n    vga_clear();\n    serial_init();\n    kprintf(\"[OK] Output subsystem initialized\\n\");\n    // 2. GDT (already loaded in bootloader, but reinitialize from C for cleanliness)\n    gdt_init();\n    kprintf(\"[OK] GDT loaded (%d entries)\\n\", 5);\n    // 3. IDT \u2014 set up gate descriptors, but DON'T enable interrupts yet\n    idt_init();\n    kprintf(\"[OK] IDT loaded (%d gates)\\n\", 256);\n    // 4. Remap PIC BEFORE enabling interrupts\n    // If we enabled interrupts before remapping, the first timer tick\n    // would fire at vector 8 (double fault). Disaster.\n    pic_remap(0x20, 0x28);\n    kprintf(\"[OK] PIC remapped: master=0x20, slave=0x28\\n\");\n    // 5. Program PIT to desired frequency\n    pit_init(100); // 100Hz = 10ms ticks\n    kprintf(\"[OK] PIT initialized at 100Hz\\n\");\n    // 6. Enable interrupts (sti)\n    // Everything must be in place before this instruction\n    __asm__ volatile (\"sti\");\n    kprintf(\"[OK] Interrupts enabled\\n\");\n    // 7. Test: wait a second, check tick counter\n    uint64_t start = pit_get_ticks();\n    while (pit_get_ticks() - start < 100) {\n        __asm__ volatile (\"hlt\");\n    }\n    kprintf(\"[OK] 1 second elapsed (100 ticks). Timer is working.\\n\");\n    // 8. Test keyboard\n    kprintf(\"Press any key: \");\n    char c = keyboard_getchar();\n    kprintf(\"Got: '%c' (0x%x)\\n\", c, (uint8_t)c);\n    // Idle loop\n    for (;;) __asm__ volatile (\"hlt\");\n}\n```\nThis sequence is the correct one. Every step before `sti` is preparation. `sti` is the moment you open the door to hardware reality.\n---\n## Debugging Interrupt Problems\nInterrupt bugs are notoriously difficult to diagnose because they are asynchronous. Here are the tools and patterns:\n**QEMU's `-d int` flag**: The most powerful debugging tool for interrupt problems. It logs every interrupt and exception to stderr, including the vector number, EIP, and error code. A triple fault will appear as a rapid sequence of exceptions. The *first* exception in the log is your actual bug.\n```bash\nqemu-system-i386 -d int,cpu_reset -no-reboot -drive file=os.img,format=raw 2>&1 | head -50\n```\n**Common failure modes and diagnoses:**\n| Symptom | Diagnosis |\n|---------|-----------|\n| Machine resets immediately on first timer tick | PIC not remapped; IRQ0 firing at vector 8 (double fault vector) |\n| `sti` causes immediate reset | IDT not loaded (`lidt` not called, or wrong IDTR) |\n| Interrupt fires but handler corrupts register state | `pusha`/`popa` missing or in wrong order |\n| Keyboard interrupt fires but no character appears | Break code not handled; scancode lookup table wrong |\n| Interrupts fire once then stop | EOI not sent; PIC waiting for acknowledgment |\n| Double fault on valid exception | Stack pointer corrupted before exception; IDT entry invalid |\n| Timer fires but tick counter never increments | `volatile` missing from `tick_counter` |\n| Wrong character for keypress | Not handling break codes correctly; shift state corrupted |\n**GDB debugging of interrupt handlers:**\n```bash\n# In one terminal:\nqemu-system-i386 -s -S -no-reboot -drive file=os.img,format=raw\n# In another:\ngdb kernel.elf\n(gdb) target remote :1234\n(gdb) set architecture i386\n(gdb) break isr_common_stub     # Break when any interrupt fires\n(gdb) break keyboard_handler\n(gdb) break timer_handler\n(gdb) continue\n```\nWhen GDB breaks inside your ISR, examine the stack frame:\n```gdb\n(gdb) info registers            # Current register state (post-pusha)\n(gdb) x/20x $esp                # Raw stack contents\n(gdb) p *((struct interrupt_frame *)$esp)  # Typed stack frame view\n```\n---\n## Three-Level View: What Happens When You Press 'A'\nThis is the most concrete trace of the hardware-to-software stack in this milestone.\n**Level 3 \u2014 Hardware:**\n1. You press 'A'. The key mechanism closes a circuit.\n2. The PS/2 keyboard's internal microcontroller detects the keypress, generates scancode `0x1E`, and serializes it onto the PS/2 clock/data lines at ~10kHz.\n3. The PS/2 host controller (Intel 8042 or chipset equivalent) receives the serial byte, buffers it in its output register, and asserts the keyboard interrupt line (IRQ1).\n4. The 8259 master PIC receives the IRQ1 signal. Since IRQ1 is not masked, it asserts the CPU's INTR pin.\n**Level 2 \u2014 CPU and Kernel:**\n5. The CPU, currently executing `hlt` in the idle loop, detects INTR asserted.\n6. The CPU finishes its current instruction (or `hlt` interruption is immediate), then:\n   - Checks IF (interrupt flag) in EFLAGS \u2014 it's set (we called `sti`), so proceed.\n   - Acknowledges the PIC via the INTA bus cycle; PIC responds with vector 33 (remapped IRQ1).\n   - Pushes EFLAGS, CS, EIP onto the kernel stack.\n   - Reads `idt[33].selector` and `idt[33].offset` \u2014 these point to `isr_33` in kernel code.\n   - Loads CS with the kernel code selector, EIP with the handler address.\n7. `isr_33` runs: pushes `0` (no error code) and `33` (interrupt number), jumps to `isr_common_stub`.\n8. `isr_common_stub`: `pusha`, push segment registers, reload kernel data segments, call `interrupt_dispatch`.\n9. `interrupt_dispatch` routes to `irq_dispatch(1, frame)`, which calls `keyboard_handler`.\n10. `keyboard_handler`: reads `0x1E` from port 0x60. Bit 7 clear = make code. `scancode_to_ascii[0x1E]` = `'a'`. Calls `ring_push(&kbd_buf, 'a')`.\n11. Returns through `irq_dispatch`, which calls `pic_send_eoi(1)` \u2014 writes `0x20` to port `0x20` (master PIC command).\n12. `isr_common_stub` restores: pop segment regs, `popa`, `add esp, 8`, `iret`.\n13. `iret` pops EIP, CS, EFLAGS \u2014 restoring the idle loop's `hlt`.\n**Level 1 \u2014 Application:**\n14. `keyboard_getchar()` finds `ring_empty()` is now false, calls `ring_pop()`, returns `'a'`.\n15. The kernel's test code prints the character.\nThirteen distinct steps from finger-press to character output. Every one of them is code you wrote.\n---\n## System Awareness: Where You Now Stand\n\n![OS Kernel \u2014 Satellite System Map](./diagrams/diag-satellite-os-map.svg)\n\nAfter this milestone, your kernel can:\n**React to hardware events.** The timer fires 100 times per second and you know it. A key pressed generates an ASCII character in a buffer. A divide-by-zero produces a diagnostic message instead of a silent reset.\n**Survive development bugs.** The double fault handler catches cascading faults and gives you a message. The exception handlers for #GP and #PF print EIP and the faulting address. Debugging has shifted from archaeology (guess what went wrong) to engineering (read the error message).\n**What's still missing.** You have no memory allocator \u2014 `kmalloc` doesn't exist. You have no process concept \u2014 only the single kernel thread running `kernel_main`. You have no virtual memory \u2014 physical and virtual addresses are the same thing. All of these come in Milestones 3 and 4.\n**The critical connection forward.** The page fault handler you wrote in this milestone \u2014 which currently just prints and halts \u2014 will become the most important function in Milestone 3. When you enable paging, every access to an unmapped page fires exception 14. Your handler will inspect CR2 and the error code, map the missing page, and return via `iret` to re-execute the faulting instruction. The handler you built here is the foundation that makes demand paging possible.\nThe timer interrupt you wrote \u2014 which currently only increments a counter \u2014 becomes the scheduler's trigger in Milestone 4. Every tick will call `schedule()`, which saves the current process's registers to a PCB and loads the next process's registers. The interrupt frame structure you defined in this milestone is the exact memory layout the context switcher will read and write.\n---\n## Knowledge Cascade\n**1. Interrupt latency and real-time operating systems.** Every register you push in `isr_common_stub` is a memory write with a cache-line cost. Eight GP registers + four segment registers = 12 writes. At 100Hz this is invisible. At 100,000 interrupts/second (a 10Gbps NIC receiving minimum-size frames), this overhead becomes the dominant CPU cost. RTOS kernels (Zephyr, FreeRTOS, VxWorks) respond by using **minimal ISR prologs** \u2014 saving only the registers actually used by the handler \u2014 and immediately deferring all real work to task context. Linux's **bottom-half** mechanism (softirqs, tasklets, workqueues) exists for exactly this reason: the hardware IRQ handler does the absolute minimum (acknowledge, enqueue data), and a \"softirq\" runs later in a schedulable context. The `PREEMPT_RT` patchset converts even these softirqs to preemptible kernel threads. Every design decision traces back to the fundamental question you just encoded in assembly: how many registers do you save?\n**2. EOI as flow control \u2014 a universal pattern.** The PIC stops delivering interrupts until it receives EOI. This is not a quirk of the 8259 \u2014 it is a **fundamental flow control pattern** that appears throughout systems design. TCP uses acknowledgment numbers (the receiver says \"I have processed up to byte N; you may send more\"). USB uses handshake packets (ACK, NAK, STALL) to confirm or reject each transfer. PCIe uses credit-based flow control (the receiver grants credits; the sender consumes them per packet; no new packets without credits). HTTP/2 uses stream windows. The 8259 PIC's EOI register is the simplest expression of this principle: a single-bit \"I'm done, send the next one.\" When you understand EOI, you understand the motivating principle behind every flow-control protocol you will ever encounter.\n**3. Exception error codes and stack forensics.** The page fault error code (present/write/user bits) is not merely debugging information. It is the **state machine input** for demand paging. When your Milestone 3 page fault handler receives a fault with P=0 (page not present), W=1 (was a write), U=0 (kernel access), it knows: allocate a new frame, map it into the page table at the faulting address (from CR2), and return via `iret` to re-execute the write. This is demand paging. The same mechanism implements copy-on-write: on a write fault to a shared page (P=1, W=1), allocate a new frame, copy the data, remap, and return. Memory-mapped files: on a page-not-present fault in the mmap region, read the file block into a new frame, map it, return. Every memory management technique in Linux and every modern OS is built on this single mechanism: a page fault handler that reads an error code, takes corrective action, and returns to retry the faulting instruction.\n**4. The double fault and fail-safe hierarchies.** The double fault handler is a specific instance of a general systems pattern: **layered fault containment**. The application has try/catch. The runtime has an unhandled exception handler. The OS has a process-level segfault handler. The CPU has the double fault. The system has watchdog timers and NMIs (Non-Maskable Interrupts \u2014 interrupts that cannot be masked even with `cli`, used for hardware-level fault detection). The PCIe bus has hardware error-correcting codes. DRAM has ECC. At each level, the goal is the same: catch failures that escaped the layer below, log diagnostic information, and either recover or fail cleanly. The double fault handler you built is the last software layer in this hierarchy. Below it is only hardware \u2014 and hardware failures (machine check exception #18, triple fault) produce resets, not error messages.\n**5. Circular buffers as the universal producer-consumer interface.** The keyboard ring buffer you built is architecturally identical to structures used throughout the OS stack. Linux `pipe(2)` is a 64KB circular buffer between two processes. `io_uring`'s submission queue and completion queue are lock-free circular buffers shared between kernel and user space via mmap \u2014 the user submits I/O descriptors by advancing the SQ head, the kernel consumes them; the kernel writes completions by advancing the CQ head, the user consumes them. DPDK's `rte_ring` is a lock-free circular buffer with SIMD-optimized bulk enqueue/dequeue, capable of millions of packets per second. The pattern is: fixed-size array, head (write position), tail (read position), full when `(head+1) % size == tail`, empty when `head == tail`. Your keyboard buffer has a single producer (IRQ handler) and single consumer (keyboard_getchar). This is the easiest case: no atomics needed on a single-core system. Multi-producer or multi-consumer rings require careful use of atomic compare-and-swap to avoid the ABA problem \u2014 this is what `rte_ring` solves with a two-phase enqueue protocol.\n---\n<!-- END_MS -->\n\n\n<!-- MS_ID: build-os-m3 -->\n<!-- MS_ID: build-os-m3 -->\n# Milestone 3: Physical and Virtual Memory Management\n\n![OS Kernel \u2014 Satellite System Map](./diagrams/diag-satellite-os-map.svg)\n\nAt the end of Milestone 2, your kernel can hear the hardware \u2014 timer ticks, keypresses, exceptions. But it is running in a world with no boundaries. Every address you use is a physical address. Your kernel, VGA buffer, stack, and any future process data all coexist in one flat, unprotected address space. There is no `malloc`, no isolation, no way to give a future process its own view of memory. This milestone changes all of that. You will teach the CPU to lie \u2014 to present every piece of software with a virtual address space that the hardware translates, transparently and continuously, to physical reality.\nThis is the milestone where your kernel transitions from \"a program that runs on bare metal\" to \"an operating system that controls the machine.\"\n---\n## The Revelation: The MMU Is Not a Software Lookup Table\nBefore we build anything, you need to shed a misconception that almost every developer carries when they first approach virtual memory.\nHere is what most people imagine: the OS maintains a table mapping virtual addresses to physical addresses. When the CPU needs to access memory, it checks this table \u2014 like a dictionary lookup \u2014 translates the address, and proceeds. The table is a data structure the OS \"uses\" on demand.\n**This model is completely wrong, and understanding why changes how you think about everything in this milestone.**\nThe Memory Management Unit (MMU) is not a software component. It is a dedicated circuit inside the CPU that intercepts **every single memory access** \u2014 every load, every store, every instruction fetch \u2014 and performs address translation **on the critical path** of execution. The CPU does not \"consult\" the page table; the MMU hardware walks it autonomously, in a format dictated down to individual bits by the silicon, before the access reaches any cache or the memory bus.\nThe implication is staggering. Your page directory and page tables are not arbitrary data structures you designed \u2014 they are a contract with the hardware, and the CPU walks them in a specific, mandatory sequence thousands of times per second, without asking your kernel for permission.\n**The TLB (Translation Lookaside Buffer) exists because of this.** A two-level page table walk requires two memory reads (one for the Page Directory Entry, one for the Page Table Entry) before the actual memory access. Without caching, every memory instruction would incur three total memory accesses \u2014 a 3\u00d7 slowdown on every instruction the CPU executes. The TLB is a small, fully-associative cache inside the CPU that stores recently-used virtual\u2192physical translations. When a translation is cached (TLB hit), the walk is bypassed entirely. When it's not (TLB miss), the CPU walks the page tables, stores the result in the TLB, and proceeds.\nThis creates the critical constraint that will shape much of your implementation: **modifying a page table entry without flushing the TLB leaves the CPU using a stale translation.** The bug this produces is non-deterministic, because TLB eviction depends on access patterns \u2014 the stale entry might be evicted immediately by other accesses, or it might persist for thousands of instructions, causing a fault in a completely unrelated code path. This is not a latent bug you can reason about statically. It is a Heisenbug that appears and disappears depending on what other code runs before the affected page is accessed.\nAnd there is one more truth, the deepest one, that the identity-mapping requirement will force you to confront directly: **the instruction that enables paging is fetched using a physical address. The next instruction is fetched using a virtual address.** If the virtual\u2192physical mapping for that next instruction address does not map to the same physical memory, the CPU faults on the instruction immediately after `mov cr0, eax`. There is no grace period, no transition period, no fallback. One instruction with physical addressing, the next with virtual \u2014 the boundary is absolute.\nNow you understand why identity mapping exists. Now let's build everything.\n---\n## Phase 1: Discovering Physical Memory with E820\n\n![E820 Memory Map \u2014 Physical Memory Discovery](./diagrams/diag-m3-e820-memory-map.svg)\n\nBefore you can allocate physical memory, you need to know how much you have and where it is. RAM is not a contiguous block from address 0 to the top. Physical address space has holes: regions reserved for BIOS ROMs, MMIO for hardware devices (VGA at `0xB8000`\u2013`0xBFFFF`), ACPI tables, and the Extended BIOS Data Area (EBDA) just below 1MB.\n**The E820 interface** (named for BIOS function INT 15h/EAX=0xE820) is the standardized way to query the BIOS for a physical memory map before leaving real mode. If you used GRUB as your bootloader, the Multiboot specification provides this information in the `multiboot_info` structure passed to your kernel. Either way, the result is a list of memory regions, each classified as one of:\n- **Type 1 (Usable)**: RAM your OS can use freely.\n- **Type 2 (Reserved)**: Firmware data, MMIO regions, ROM \u2014 do not touch.\n- **Type 3 (ACPI Reclaimable)**: ACPI tables; can be freed after the OS reads them.\n- **Type 4 (ACPI NVS)**: ACPI non-volatile storage; never reclaim.\n- **Type 5 (Bad Memory)**: Defective RAM reported by firmware.\nIf you're using GRUB + Multiboot (the recommended approach for this project), the bootloader fills in an `mmap_addr` field and `mmap_length` field in the Multiboot info structure:\n```c\n// Multiboot info structure (abbreviated \u2014 only fields we need)\ntypedef struct {\n    uint32_t flags;          // Bit flags indicating which fields are valid\n    // ... (memory, cmdline, mods fields) ...\n    uint32_t mmap_length;    // Total size of memory map entries in bytes\n    uint32_t mmap_addr;      // Physical address of first mmap entry\n} __attribute__((packed)) multiboot_info_t;\n// Each entry in the memory map\ntypedef struct {\n    uint32_t size;           // Size of this entry minus 4 (not including this field)\n    uint64_t base_addr;      // Starting physical address of region\n    uint64_t length;         // Length of region in bytes\n    uint32_t type;           // 1=usable, 2=reserved, 3=ACPI, 4=NVS, 5=bad\n} __attribute__((packed)) multiboot_mmap_entry_t;\n```\n> **Why `uint64_t` for addresses in a 32-bit kernel?** Even a 32-bit x86 CPU can address up to 64 GB of physical memory using PAE (Physical Address Extension). The BIOS reports 64-bit physical addresses because it must work with all CPU variants. Your simple 32-bit kernel will only use the low 32 bits, but you must read 64-bit values from the structure to correctly advance the pointer to the next entry.\nParse the memory map immediately in `kernel_main`, before any other initialization that touches memory:\n```c\n#define MBOOT_FLAG_MMAP  (1 << 6)  // Bit 6 of flags = mmap fields valid\ntypedef struct {\n    uint64_t base;\n    uint64_t length;\n    uint32_t type;\n} phys_region_t;\n#define MAX_REGIONS 64\nstatic phys_region_t phys_regions[MAX_REGIONS];\nstatic int phys_region_count = 0;\nvoid mmap_parse(multiboot_info_t *mbi) {\n    if (!(mbi->flags & MBOOT_FLAG_MMAP)) {\n        kprintf(\"[PANIC] Bootloader did not provide memory map\\n\");\n        for (;;) __asm__ volatile (\"hlt\");\n    }\n    multiboot_mmap_entry_t *entry =\n        (multiboot_mmap_entry_t *)(uintptr_t)mbi->mmap_addr;\n    uintptr_t end = mbi->mmap_addr + mbi->mmap_length;\n    kprintf(\"Physical memory map:\\n\");\n    while ((uintptr_t)entry < end) {\n        if (phys_region_count < MAX_REGIONS) {\n            phys_regions[phys_region_count].base   = entry->base_addr;\n            phys_regions[phys_region_count].length = entry->length;\n            phys_regions[phys_region_count].type   = entry->type;\n            phys_region_count++;\n        }\n        static const char *type_names[] = {\n            \"\", \"Usable\", \"Reserved\", \"ACPI Reclaim\", \"ACPI NVS\", \"Bad\"\n        };\n        uint32_t t = entry->type;\n        kprintf(\"  0x%08x - 0x%08x  %s\\n\",\n                (uint32_t)entry->base_addr,\n                (uint32_t)(entry->base_addr + entry->length - 1),\n                (t >= 1 && t <= 5) ? type_names[t] : \"Unknown\");\n        // Advance to next entry: size field + 4 bytes for the size field itself\n        entry = (multiboot_mmap_entry_t *)((uintptr_t)entry + entry->size + 4);\n    }\n}\n```\nA typical memory map on a 128MB QEMU machine looks like:\n```\nPhysical memory map:\n  0x00000000 - 0x0009FBFF  Usable        (low conventional memory: 639 KB)\n  0x0009FC00 - 0x0009FFFF  Reserved      (EBDA \u2014 Extended BIOS Data Area)\n  0x000F0000 - 0x000FFFFF  Reserved      (BIOS ROM)\n  0x00100000 - 0x07FDFFFF  Usable        (high memory: ~127 MB, your kernel lives here)\n  0x07FE0000 - 0x07FFFFFF  Reserved      (ACPI tables)\n  0xFFFC0000 - 0xFFFFFFFF  Reserved      (BIOS flash/ROM)\n```\nThis map tells you everything you need to bootstrap the physical frame allocator: which address ranges are safe to use, and which must be permanently forbidden.\n---\n## Phase 2: The Bitmap Frame Allocator\n\n![Bitmap Frame Allocator \u2014 Structure and Operations](./diagrams/diag-m3-bitmap-allocator.svg)\n\nYou know which physical memory regions are usable. Now you need a data structure that lets you allocate and free individual 4KB **page frames** \u2014 4KB-aligned chunks of physical memory that the MMU can map into page tables.\n> **Why 4KB?** The x86 page size is architecturally fixed at 4KB for standard (non-huge) pages. This comes from the page directory/table entry format, which stores 20-bit physical frame numbers \u2014 the remaining 12 bits of a 32-bit address are the offset within the page, giving 2\u00b9\u00b2 = 4096 bytes per page. This is not a design choice you make; it is the hardware contract.\n**The data structure: a bitmap.** One bit per 4KB frame. Bit = 0 means the frame is free; bit = 1 means it is used (or reserved). For 128MB of physical memory, you need 128MB / 4KB = 32,768 frames, which requires 32,768 / 8 = 4,096 bytes = 4KB for the bitmap. The bitmap fits in a single page \u2014 an elegant property of the data structure.\n```c\n#define PAGE_SIZE       4096\n#define FRAMES_PER_WORD 32           // 32-bit words\n#define MAX_FRAMES      (1024 * 1024 / 4)  // 4GB / 4KB = 1M frames max\n// The bitmap lives in BSS \u2014 zeroed by our boot stub\nstatic uint32_t frame_bitmap[MAX_FRAMES / FRAMES_PER_WORD];\nstatic uint32_t total_frames = 0;\nstatic uint32_t free_frames  = 0;\n// Mark a frame as used (set bit)\nstatic void frame_set(uint32_t frame) {\n    frame_bitmap[frame / 32] |= (1u << (frame % 32));\n}\n// Mark a frame as free (clear bit)\nstatic void frame_clear(uint32_t frame) {\n    frame_bitmap[frame / 32] &= ~(1u << (frame % 32));\n}\n// Test if a frame is used\nstatic int frame_test(uint32_t frame) {\n    return (frame_bitmap[frame / 32] >> (frame % 32)) & 1;\n}\n```\n**Initialization: reserve everything, then free the usable regions.** This is the safer invariant \u2014 start with all frames marked used, then free only what the memory map says is safe. Any region not explicitly freed remains permanently allocated, which prevents you from ever accidentally handing out MMIO space or BIOS ROM:\n```c\nvoid pmm_init(multiboot_info_t *mbi) {\n    // Calculate total frames from highest usable address\n    // (conservatively use 128MB or whatever the machine has)\n    uint64_t highest = 0;\n    for (int i = 0; i < phys_region_count; i++) {\n        uint64_t top = phys_regions[i].base + phys_regions[i].length;\n        if (top > highest) highest = top;\n    }\n    total_frames = (uint32_t)(highest / PAGE_SIZE);\n    // Start: mark ALL frames as used\n    // memset is fine here \u2014 we zeroed BSS, but frame_bitmap may not be in BSS\n    // if it's in .bss it's already zero... but we want all-used (0xFF not 0x00)\n    // So we set all bits to 1:\n    for (uint32_t i = 0; i < total_frames / 32 + 1; i++)\n        frame_bitmap[i] = 0xFFFFFFFF;\n    // Free frames from usable E820 regions\n    for (int i = 0; i < phys_region_count; i++) {\n        if (phys_regions[i].type != 1) continue;  // Skip non-usable\n        uint64_t base = phys_regions[i].base;\n        uint64_t len  = phys_regions[i].length;\n        // Align to 4KB boundaries (round base up, round length down)\n        uint32_t frame_start = (uint32_t)((base + PAGE_SIZE - 1) / PAGE_SIZE);\n        uint32_t frame_end   = (uint32_t)((base + len) / PAGE_SIZE);\n        for (uint32_t f = frame_start; f < frame_end; f++) {\n            frame_clear(f);\n            free_frames++;\n        }\n    }\n    // Re-mark frames occupied by the kernel binary as used\n    // __kernel_start and __kernel_end come from the linker script\n    extern uintptr_t __kernel_start, __kernel_end;\n    uint32_t kstart_frame = (uint32_t)&__kernel_start / PAGE_SIZE;\n    uint32_t kend_frame   = ((uint32_t)&__kernel_end + PAGE_SIZE - 1) / PAGE_SIZE;\n    for (uint32_t f = kstart_frame; f < kend_frame; f++) {\n        if (!frame_test(f)) { frame_set(f); free_frames--; }\n    }\n    // Re-mark frame 0 as used (BIOS data area, NULL pointer protection)\n    if (!frame_test(0)) { frame_set(0); free_frames--; }\n    kprintf(\"[PMM] %u KB total, %u KB free (%u frames)\\n\",\n            total_frames * 4, free_frames * 4, free_frames);\n}\n```\n**Allocation \u2014 first-fit scan:**\n```c\nuint32_t pmm_alloc_frame(void) {\n    // Scan bitmap for first free frame\n    for (uint32_t i = 0; i < total_frames / 32; i++) {\n        if (frame_bitmap[i] == 0xFFFFFFFF) continue; // All used, skip fast\n        // Found a word with at least one free bit\n        for (uint32_t bit = 0; bit < 32; bit++) {\n            if (!((frame_bitmap[i] >> bit) & 1)) {\n                uint32_t frame = i * 32 + bit;\n                frame_set(frame);\n                free_frames--;\n                return frame * PAGE_SIZE;  // Return physical address\n            }\n        }\n    }\n    // Out of memory\n    kprintf(\"[PMM] OUT OF PHYSICAL MEMORY\\n\");\n    for (;;) __asm__ volatile (\"hlt\");\n    return 0;\n}\nvoid pmm_free_frame(uint32_t phys_addr) {\n    uint32_t frame = phys_addr / PAGE_SIZE;\n    if (frame >= total_frames) {\n        kprintf(\"[PMM] free_frame: invalid address 0x%x\\n\", phys_addr);\n        return;\n    }\n    if (!frame_test(frame)) {\n        // Double-free detected \u2014 always a kernel bug\n        kprintf(\"[PMM] DOUBLE FREE: frame 0x%x (addr 0x%x)\\n\", frame, phys_addr);\n        for (;;) __asm__ volatile (\"hlt\");\n    }\n    frame_clear(frame);\n    free_frames++;\n}\n```\n> **Hardware Soul**: The word-level skip (`if (frame_bitmap[i] == 0xFFFFFFFF) continue`) is not just an optimization \u2014 it's essential for the allocator to remain fast as memory fills up. Scanning 32 bits at once is a single comparison and branch. Without it, a fully-allocated system doing a 32KB kernel stack allocation would scan 1 million bits before declaring OOM. With it, you scan at most 32K words (128KB of bitmap), which fits in L2 cache. This is the same principle behind the `__builtin_ctz` (count trailing zeros) optimization: `bit = __builtin_ctz(~frame_bitmap[i])` finds the first free bit in a word in O(1) using a single hardware instruction (BSF \u2014 Bit Scan Forward on x86). Consider using it.\n**Design decision: Bitmap vs Free List**\n| Approach | Allocation | Deallocation | Memory Overhead | Used By |\n|----------|-----------|--------------|-----------------|---------|\n| **Bitmap \u2713** | O(n) first-fit scan | O(1) | 1 bit/frame = 128KB for 4GB | Simple kernels, early allocators |\n| Free list (stack) | O(1) pop | O(1) push | One pointer/free frame | Linux zone allocator (fast path) |\n| Buddy system | O(log n) | O(log n) merge | Low | Linux buddy allocator, jemalloc |\nThe bitmap wins for clarity and double-free detection. Real OS kernels (Linux) use a buddy allocator for physical frames \u2014 it supports efficient allocation of contiguous multi-page blocks and merges adjacent freed blocks to combat fragmentation. For this milestone, the bitmap gives you everything you need.\n---\n## Phase 3: x86 Two-Level Paging \u2014 The Hardware's Point of View\n\n![x86 Two-Level Paging \u2014 Virtual Address Translation](./diagrams/diag-m3-two-level-page-table.svg)\n\nNow the architecture that makes virtual memory possible. On 32-bit x86, a virtual address is 32 bits wide. The MMU splits it into three fields:\n```\n31          22 21          12 11           0\n+-------------+--------------+-------------+\n| Dir Index   | Table Index  |   Offset    |\n|  10 bits    |   10 bits    |   12 bits   |\n+-------------+--------------+-------------+\n```\n- **Directory Index (bits 31\u201322)**: Which of 1024 entries in the Page Directory to use.\n- **Table Index (bits 21\u201312)**: Which of 1024 entries in the selected Page Table to use.\n- **Offset (bits 11\u20130)**: Byte offset within the 4KB page (2\u00b9\u00b2 = 4096 bytes, matching page size).\n**The walk proceeds in three steps:**\n1. The CPU reads CR3 to get the physical address of the Page Directory.\n2. Using the Directory Index, it reads the Page Directory Entry (PDE) from the Page Directory. The PDE contains the physical address of a Page Table (if present).\n3. Using the Table Index, it reads the Page Table Entry (PTE) from the Page Table. The PTE contains the physical address of the actual page frame.\n4. The final physical address is `PTE.frame_address | virtual_address.offset`.\n**Why two levels?** A single-level page table mapping all 4GB would require 4GB / 4KB = 1M entries \u00d7 4 bytes = 4MB of page table memory \u2014 **per process**. With 100 processes, that's 400MB just for page tables. Two-level paging solves this with **sparsity**: you only need to allocate Page Table pages for the virtual address regions a process actually uses. An address space that uses only 4MB needs one Page Directory + one Page Table = 8KB, not 4MB.\n\n![Page Directory/Table Entry \u2014 Bit-Level Layout](./diagrams/diag-m3-pde-pte-bitfield.svg)\n\n**Page Directory Entry (PDE) bit layout:**\n```c\ntypedef struct {\n    uint32_t present    : 1;  // Bit 0: 1 = this entry points to a valid page table\n    uint32_t writable   : 1;  // Bit 1: 1 = page table is writable\n    uint32_t user       : 1;  // Bit 2: 1 = accessible from ring 3 (user mode)\n    uint32_t write_thru : 1;  // Bit 3: write-through caching (usually 0)\n    uint32_t cache_dis  : 1;  // Bit 4: cache disable for this PDE (usually 0)\n    uint32_t accessed   : 1;  // Bit 5: set by CPU when PT is accessed\n    uint32_t _reserved  : 1;  // Bit 6: reserved (must be 0)\n    uint32_t page_size  : 1;  // Bit 7: 0 = 4KB pages, 1 = 4MB huge page\n    uint32_t _ignored   : 4;  // Bits 8-11: available for OS use\n    uint32_t frame      : 20; // Bits 12-31: physical address of page table >> 12\n} pde_t;\n```\n**Page Table Entry (PTE) bit layout:**\n```c\ntypedef struct {\n    uint32_t present    : 1;  // Bit 0: 1 = page is in physical memory\n    uint32_t writable   : 1;  // Bit 1: 0 = read-only, 1 = read/write\n    uint32_t user       : 1;  // Bit 2: 0 = kernel-only (ring 0), 1 = user-accessible\n    uint32_t write_thru : 1;  // Bit 3: write-through cache\n    uint32_t cache_dis  : 1;  // Bit 4: cache disable (set for MMIO regions)\n    uint32_t accessed   : 1;  // Bit 5: CPU sets on any read or write\n    uint32_t dirty      : 1;  // Bit 6: CPU sets on write\n    uint32_t _reserved  : 1;  // Bit 7: reserved (must be 0)\n    uint32_t global     : 1;  // Bit 8: don't flush from TLB on CR3 reload (for kernel pages)\n    uint32_t _avail     : 3;  // Bits 9-11: available for OS use\n    uint32_t frame      : 20; // Bits 12-31: physical address of mapped page >> 12\n} pte_t;\n```\nIn practice, working with bitfields can lead to surprising compiler-generated code. Most kernel developers use `uint32_t` with explicit masks and shifts:\n```c\n#define PTE_PRESENT   (1u << 0)\n#define PTE_WRITABLE  (1u << 1)\n#define PTE_USER      (1u << 2)\n#define PTE_CACHE_DIS (1u << 4)\n#define PTE_FRAME(addr)  ((addr) & 0xFFFFF000u)  // Mask off flag bits\ntypedef uint32_t pde_t;\ntypedef uint32_t pte_t;\n// A page directory: 1024 entries \u00d7 4 bytes = 4096 bytes = exactly one page\ntypedef pde_t page_directory_t[1024] __attribute__((aligned(4096)));\n// A page table: 1024 entries \u00d7 4 bytes = 4096 bytes = exactly one page\ntypedef pte_t page_table_t[1024] __attribute__((aligned(4096)));\n```\n**The `__attribute__((aligned(4096)))` is mandatory.** The CPU reads CR3 and treats the value as a physical address of the page directory. The hardware requires this address to be 4KB-aligned (the low 12 bits of CR3 carry flags, not address bits). If your page directory is not 4KB-aligned, CR3 will point to the wrong location and every memory access will use garbage translations.\n---\n## Phase 4: The Address Space Layout \u2014 Choosing Your Map\n\n![Dual Mapping \u2014 Identity Map + Higher-Half Kernel](./diagrams/diag-m3-identity-plus-higher-half.svg)\n\nBefore writing a single page table entry, you must decide on your virtual address space layout. This decision shapes everything \u2014 your linker script, your page fault handler, your future process isolation strategy.\nFor this kernel, you will use a **higher-half kernel** layout:\n```\nVirtual Address Space (32-bit: 0x00000000 - 0xFFFFFFFF)\n0x00000000 - 0x003FFFFF   Identity-mapped low memory (first 4MB)\n                           Covers: BIOS data area, VGA buffer (0xB8000),\n                           conventional memory, bootloader stack\n0x00400000 - 0xBFFFFFFF   Available for user processes (future)\n0xC0000000 - 0xC03FFFFF   Higher-half kernel (kernel code + data)\n                           Physical: 0x00100000 - 0x004FFFFF\n                           Linked at: 0xC0100000 (VMA)\n                           Loaded at: 0x00100000 (LMA)\n0xC0400000 - 0xCFFFFFFF   Kernel heap (kmalloc arena)\n                           Physical: allocated on demand by pmm_alloc_frame\n0xD0000000 - 0xFFBFFFFF   Reserved for future kernel use\n0xFFC00000 - 0xFFFFFFFF   Recursive page directory mapping (optional)\n```\n**Why `0xC0000000` (3GB)?** This is the classical 3GB/1GB split used by Linux 2.x kernels: user space gets the lower 3GB, the kernel occupies the upper 1GB of every process's address space. It is a trade-off \u2014 user processes are limited to 3GB virtual address space, but the kernel always has its full mapping present in every address space, eliminating TLB flushes on system calls. Linux x86 64-bit solved this by having an astronomically large 64-bit address space (128TB for user, 128TB for kernel), but on 32-bit the split is a genuine constraint.\n**The VMA/LMA disconnect.** Your linker script must link the kernel at `0xC0100000` (the virtual address it will use after paging is enabled), but the bootloader loaded it at `0x00100000` (physical). The linker emits code with virtual addresses \u2014 function pointers, global variable accesses, `call` instructions \u2014 all resolved to addresses above `0xC0000000`. Before paging is enabled, these addresses are nonsensical. Your pre-paging code (the boot stub that sets up the initial page directory) must work entirely with physical addresses and use position-independent techniques or explicit `- 0xC0000000` adjustments.\nUpdate your linker script:\n```ld\nENTRY(kernel_entry)\nKERNEL_VIRT_BASE = 0xC0000000;\nKERNEL_PHYS_BASE = 0x00100000;\nSECTIONS {\n    . = KERNEL_VIRT_BASE + KERNEL_PHYS_BASE;  /* 0xC0100000 */\n    .text ALIGN(4096) : AT(ADDR(.text) - KERNEL_VIRT_BASE) {\n        *(.multiboot)\n        *(.text)\n        *(.text.*)\n    }\n    .rodata ALIGN(4096) : AT(ADDR(.rodata) - KERNEL_VIRT_BASE) {\n        *(.rodata)\n    }\n    .data ALIGN(4096) : AT(ADDR(.data) - KERNEL_VIRT_BASE) {\n        *(.data)\n    }\n    .bss ALIGN(4096) : AT(ADDR(.bss) - KERNEL_VIRT_BASE) {\n        __bss_start = .;\n        *(.bss)\n        *(COMMON)\n        __bss_end = .;\n    }\n    __kernel_end = .;\n    __kernel_phys_end = __kernel_end - KERNEL_VIRT_BASE;\n}\n```\nThe `AT(...)` directive specifies the LMA (load address) as VMA minus the base offset, so the binary sections are stored at physical addresses while all symbol references use virtual addresses. `objcopy -O binary` strips the ELF headers and produces a flat binary at the physical addresses, which your bootloader loads to `0x100000`.\n---\n## Phase 5: Building the Initial Page Tables\n\n![The Paging Enable Moment \u2014 CR3 and CR0.PG](./diagrams/diag-m3-paging-enable-moment.svg)\n\nThis is the most delicate code you will write. The goal: construct page tables that map both the identity region (low 4MB, physical = virtual) and the higher-half region (kernel at `0xC0100000` \u2192 physical `0x00100000`), then atomically enable paging with CR3 and CR0.PG.\n**The boot page directory and tables must be statically allocated** \u2014 you cannot use `pmm_alloc_frame` before paging is enabled, because the PMM initialization itself requires knowing the memory map, which requires some kernel code to have run. The bootstrap page tables are `static` arrays in the `.data` or `.bss` section, placed at known physical addresses by the linker.\n```c\n// boot_paging.c \u2014 compiled and linked at virtual addresses,\n// but this code runs BEFORE paging is on, so we carefully\n// use physical addresses for the CR3 load.\n// Static page directory and two static page tables:\n// - pt_low:  identity-maps physical 0x00000000 - 0x003FFFFF (first 4MB)  \n// - pt_high: maps virtual 0xC0000000 - 0xC03FFFFF -> physical 0x00000000 - 0x003FFFFF\nstatic page_directory_t boot_pd  __attribute__((aligned(4096)));\nstatic page_table_t     pt_low   __attribute__((aligned(4096)));\nstatic page_table_t     pt_high  __attribute__((aligned(4096)));\n// Macro to convert a virtual address (after linking) to its physical address\n// before paging is enabled\n#define VIRT_TO_PHYS(addr) ((uint32_t)(addr) - 0xC0000000)\nvoid paging_init(void) {\n    // --- Step 1: Fill the low identity-map page table ---\n    // Maps virtual 0x00000000-0x003FFFFF -> physical 0x00000000-0x003FFFFF\n    // Required: this is where execution currently IS. Paging enable would fault\n    // on the very next instruction without this.\n    for (uint32_t i = 0; i < 1024; i++) {\n        pt_low[i] = (i * PAGE_SIZE) | PTE_PRESENT | PTE_WRITABLE;\n    }\n    // --- Step 2: Fill the high kernel page table ---\n    // Maps virtual 0xC0000000-0xC03FFFFF -> physical 0x00000000-0x003FFFFF\n    // Same physical frames as the identity map, different virtual addresses.\n    for (uint32_t i = 0; i < 1024; i++) {\n        pt_high[i] = (i * PAGE_SIZE) | PTE_PRESENT | PTE_WRITABLE;\n    }\n    // --- Step 3: Install page tables in the page directory ---\n    // Index for virtual 0x00000000: (0x00000000 >> 22) = 0\n    boot_pd[0] = VIRT_TO_PHYS((uint32_t)pt_low) | PDE_PRESENT | PDE_WRITABLE;\n    // Index for virtual 0xC0000000: (0xC0000000 >> 22) = 768\n    boot_pd[768] = VIRT_TO_PHYS((uint32_t)pt_high) | PDE_PRESENT | PDE_WRITABLE;\n    // --- Step 4: Load CR3 with the PHYSICAL address of the page directory ---\n    uint32_t pd_phys = VIRT_TO_PHYS((uint32_t)boot_pd);\n    __asm__ volatile (\n        \"mov cr3, %0\"\n        : : \"r\"(pd_phys) : \"memory\"\n    );\n    // --- Step 5: Enable paging by setting CR0.PG (bit 31) ---\n    // After this instruction, the MMU is active.\n    // The NEXT instruction is fetched at a virtual address.\n    // Because of the identity map in boot_pd[0], the physical code\n    // at 0x00100000 is also mapped at virtual 0x00100000 \u2014 so execution\n    // continues seamlessly.\n    uint32_t cr0;\n    __asm__ volatile (\"mov %0, cr0\" : \"=r\"(cr0));\n    cr0 |= (1u << 31);  // Set PG bit\n    __asm__ volatile (\n        \"mov cr0, %0\"\n        : : \"r\"(cr0) : \"memory\"\n    );\n    // --- Step 6: Long jump to higher-half virtual address ---\n    // We are now executing at physical 0x00100000 = virtual 0x00100000\n    // (through the identity map). We want to \"move\" to 0xC0100000.\n    // A far jump achieves this: load EIP with the virtual address.\n    //\n    // In C, we do this by calling a function through a pointer at the high address:\n    void (*kernel_high_entry)(void) = (void (*)(void))0xC0100000 + /* offset to func */;\n    // In practice, this is often done in assembly at the end of the boot stub.\n    // See the assembly snippet below.\n}\n```\n**The moment of transition \u2014 assembly for the high-jump:**\n```nasm\n; After enabling paging in C, control returns here.\n; EIP is currently ~0x00100xxx (physical = virtual via identity map).\n; We need to jump to the higher-half virtual address.\n    ; Calculate the high-half virtual address of 'kernel_main_high'\n    ; by adding the virtual base to the physical address.\n    ; KERNEL_VIRT_BASE = 0xC0000000\n    lea eax, [kernel_main_high]    ; EAX = virtual address from linker (0xC0100xxx)\n    jmp eax                        ; Jump to higher-half virtual address\nkernel_main_high:\n    ; We are now running at 0xC0100xxx.\n    ; The identity map (boot_pd[0]) is still present \u2014 we can remove it now\n    ; by clearing boot_pd[0] and flushing the TLB.\n    ; This makes the NULL page (and low 4MB) unmapped, catching null pointer dereferences.\n    ; Remove identity map\n    extern boot_pd\n    mov dword [boot_pd], 0          ; Clear PDE index 0\n    ; Flush TLB by reloading CR3 (write same value back)\n    mov eax, cr3\n    mov cr3, eax                    ; TLB is now fully flushed\n    ; Set up the kernel stack to the virtual address (linker gave us this)\n    mov esp, kernel_stack_top       ; This is now a virtual address ~0xC01xxxxx\n    ; Call kernel_main with the multiboot info pointer\n    ; Note: EBX was set by GRUB to point to the multiboot_info structure.\n    ; If you preserved it through the paging setup, pass it here.\n    push ebx\n    call kernel_main\n.hang:\n    cli\n    hlt\n    jmp .hang\n```\n> **The identity map removal is a safety mechanism, not ceremony.** After jumping to higher-half virtual addresses, the identity map (virtual 0x00000000 \u2192 physical 0x00000000) is no longer needed. Removing it makes virtual address 0x00000000 unmapped, which means a NULL pointer dereference immediately triggers a page fault \u2014 #PF with CR2=0. Without removing the identity map, a NULL pointer dereference silently reads whatever is at physical address 0, which is BIOS data, and returns garbage. The kernel proceeds as if nothing is wrong and crashes elsewhere, hours or thousands of instructions later. Removing the identity map converts a silent memory corruption into an immediate, diagnosable page fault. Always remove it.\n---\n## Phase 6: The TLB \u2014 Your Most Dangerous Invisible State\n\n![TLB \u2014 Caching Translations and Flush Requirements](./diagrams/diag-m3-tlb-flush-scenarios.svg)\n\nThe TLB deserves its own section because TLB-related bugs are among the most pernicious in operating system development. They are non-deterministic, they can lie dormant through extensive testing, and they manifest in seemingly unrelated code.\n**What the TLB caches:** Each TLB entry stores one virtual\u2192physical translation, plus the permission bits from that PTE (present, writable, user). When you modify a PTE \u2014 changing permissions, changing the mapped frame, or marking a page not present \u2014 the TLB may still hold the old translation. The CPU will use the stale entry until it is evicted, potentially allowing accesses that should fault, or faulting on accesses that should succeed.\n**When you must flush the TLB:**\n- After mapping a previously unmapped page (new PTE, present=0 \u2192 present=1): No flush needed for the newly mapped page \u2014 there's no stale entry because the page was never mapped. But if you install a new page table (new PDE) while old PDEs point to page tables you've modified, flush anyway to be safe.\n- After unmapping a page (present=1 \u2192 present=0): **Always flush.** Otherwise accesses may succeed using the stale TLB entry even though the page is logically unmapped.\n- After changing a page's permissions (e.g., read-only \u2192 writable or vice versa): **Always flush.** The TLB cached the old permissions.\n- After changing a page's frame (remapping a virtual address to a different physical frame): **Always flush.** The TLB has the wrong physical address.\n**The two flush mechanisms:**\n```c\n// Flush a single page from the TLB: use INVLPG\n// This is efficient \u2014 only evicts the one translation.\nstatic inline void tlb_flush_page(uint32_t virt_addr) {\n    __asm__ volatile (\"invlpg [%0]\" : : \"r\"(virt_addr) : \"memory\");\n}\n// Flush the entire TLB: reload CR3 with the same value\n// Every user-space translation is evicted. Kernel global pages\n// (with PTE_GLOBAL set) survive this on CPUs with PGE support.\nstatic inline void tlb_flush_all(void) {\n    uint32_t cr3;\n    __asm__ volatile (\"mov %0, cr3\" : \"=r\"(cr3));\n    __asm__ volatile (\"mov cr3, %0\" : : \"r\"(cr3) : \"memory\");\n}\n```\n**Prefer `invlpg` over full CR3 reloads.** A full TLB flush evicts all translations, including hot kernel mappings. Subsequent accesses to kernel code and data all miss the TLB initially, causing a burst of page table walks. On a kernel with 256KB of frequently-executed code, a full flush might evict 64 kernel translations \u2014 each costing two extra memory accesses on the next hit. At 1000 context switches per second with a full flush each time, this is measurable overhead. Use `invlpg` when you know which page changed. Use full CR3 reload only when switching address spaces (context switch to a different process).\n> **Knowledge Cascade \u2014 TLB Shootdown and Multicore Scalability**: On a single CPU, TLB management is simple \u2014 you flush your own TLB. On a multicore system, each CPU core has its own private TLB. When the kernel modifies a page table entry on CPU 0, CPU 1's TLB may still hold the stale translation. The kernel must send an **Inter-Processor Interrupt (IPI)** to every other CPU, instructing them to invalidate the affected TLB entries. This is called a **TLB shootdown**, and it is a notorious performance bottleneck. A Linux `munmap(2)` call that frees a large mapping must IPI every other core that might have that mapping in its TLB \u2014 and wait for all of them to acknowledge before completing. On a 64-core NUMA system, this serialization can cost microseconds. Database systems like ScyllaDB and FoundationDB are designed with this in mind: they minimize dynamic memory mapping/unmapping during steady-state operation to avoid TLB shootdown overhead. The HugePage (2MB/1GB pages) optimization partially addresses this \u2014 fewer TLB entries needed means less shootdown cost \u2014 which is why databases and JVMs benefit dramatically from huge pages. Your single-core kernel avoids all of this, but knowing it exists explains why mmap/munmap are \"expensive\" syscalls in production.\n---\n## Phase 7: The Dynamic Virtual Memory Mapper\nOnce the initial page tables are set up and paging is enabled, you need a function that can map any virtual address to any physical frame on demand. This is the engine your heap allocator (and eventually your process loader) will use:\n```c\n// Map a single virtual address to a physical frame\n// Creates the page table if it doesn't exist\nvoid paging_map(page_directory_t *pd, uint32_t virt, uint32_t phys, uint32_t flags) {\n    uint32_t pd_index = virt >> 22;           // Bits 31-22\n    uint32_t pt_index = (virt >> 12) & 0x3FF; // Bits 21-12\n    if (!(pd[pd_index] & PTE_PRESENT)) {\n        // Page table for this PDE doesn't exist \u2014 allocate one\n        uint32_t new_pt_phys = pmm_alloc_frame();\n        // Zero the new page table (critical \u2014 old memory may contain garbage)\n        page_table_t *new_pt = (page_table_t *)(new_pt_phys + 0xC0000000);\n        // ^ Map physical to virtual via known identity: in higher-half kernel,\n        //   kernel physical memory is at virt = phys + 0xC0000000\n        for (int i = 0; i < 1024; i++) (*new_pt)[i] = 0;\n        pd[pd_index] = new_pt_phys | PTE_PRESENT | PTE_WRITABLE | (flags & PTE_USER);\n    }\n    // Get the page table virtual address\n    uint32_t pt_phys = PTE_FRAME(pd[pd_index]);\n    page_table_t *pt = (page_table_t *)(pt_phys + 0xC0000000);\n    if ((*pt)[pt_index] & PTE_PRESENT) {\n        // Already mapped \u2014 this is a kernel bug, not a page fault\n        kprintf(\"[PAGING] WARNING: remapping already-mapped virt 0x%x\\n\", virt);\n    }\n    (*pt)[pt_index] = PTE_FRAME(phys) | PTE_PRESENT | flags;\n    // Flush TLB for this page\n    tlb_flush_page(virt);\n}\n// Unmap a virtual address (mark PTE not-present)\nvoid paging_unmap(page_directory_t *pd, uint32_t virt) {\n    uint32_t pd_index = virt >> 22;\n    uint32_t pt_index = (virt >> 12) & 0x3FF;\n    if (!(pd[pd_index] & PTE_PRESENT)) return; // PDE not present, nothing to unmap\n    uint32_t pt_phys = PTE_FRAME(pd[pd_index]);\n    page_table_t *pt = (page_table_t *)(pt_phys + 0xC0000000);\n    (*pt)[pt_index] = 0; // Clear entire entry, including present bit\n    // CRITICAL: flush TLB for this page BEFORE returning\n    // Without this, accesses to virt may continue using stale translation\n    tlb_flush_page(virt);\n}\n```\n**The `+ 0xC0000000` trick.** After paging is enabled with higher-half mapping, physical address `P` is accessible at virtual address `P + 0xC0000000` \u2014 for physical addresses in the kernel range (0x00000000\u20130x003FFFFF mapped to 0xC0000000\u20130xC03FFFFF). This gives you a simple, fast way to get a usable pointer to any newly allocated physical frame, without needing a separate \"map this frame so I can zero it\" step. This only works for physical addresses in your mapped range \u2014 for larger physical memory, you'd need a more sophisticated approach (like maintaining a permanent \"physical memory window\" mapping in high virtual address space). For this milestone, limit your allocations to the first 256MB and this pattern works cleanly.\n---\n## Phase 8: The Page Fault Handler \u2014 From Diagnostic to Demand Paging\n\n![Page Fault (#14) \u2014 CR2 and Error Code Decoding](./diagrams/diag-m3-page-fault-error-code.svg)\n\nIn Milestone 2, your page fault handler (#PF, exception 14) printed a message and halted. Now it has a new role: it is the **entry point for all demand paging**, the mechanism by which the OS lazily maps memory only when it's actually accessed.\n**Reading the fault information:**\n```c\nvoid page_fault_handler(struct interrupt_frame *frame) {\n    // CR2 contains the virtual address that caused the fault\n    uint32_t fault_addr;\n    __asm__ volatile (\"mov %0, cr2\" : \"=r\"(fault_addr));\n    // Decode the error code (pushed by CPU before calling handler)\n    int present  = (frame->err_code >> 0) & 1; // 0=not mapped, 1=protection violation\n    int write    = (frame->err_code >> 1) & 1; // 0=read, 1=write\n    int user     = (frame->err_code >> 2) & 1; // 0=kernel, 1=user mode\n    int reserved = (frame->err_code >> 3) & 1; // 1=reserved bit set in PTE (CPU bug?)\n    int ifetch   = (frame->err_code >> 4) & 1; // 1=instruction fetch (NX bit, if enabled)\n    kprintf(\"\\n[PAGE FAULT] at 0x%08x\\n\", fault_addr);\n    kprintf(\"  Access: %s %s from %s mode\\n\",\n            write ? \"Write\" : \"Read\",\n            ifetch ? \"(instruction fetch)\" : \"\",\n            user ? \"user\" : \"kernel\");\n    kprintf(\"  Cause: %s\\n\",\n            present ? \"Protection violation (page present, wrong permissions)\"\n                    : \"Page not mapped (present=0)\");\n    kprintf(\"  EIP=0x%x  EFLAGS=0x%x\\n\", frame->eip, frame->eflags);\n    // For now: if this is a kernel fault, halt\n    if (!user) {\n        kprintf(\"[KERNEL PAGE FAULT] \u2014 halting\\n\");\n        for (;;) __asm__ volatile (\"cli; hlt\");\n    }\n    // TODO (Milestone 4): If user fault, check if it's a valid demand-paged\n    // address, allocate a frame, map it, and return to retry.\n    // For now, kill the process (or halt).\n    kprintf(\"[USER PAGE FAULT] \u2014 process killed (unimplemented)\\n\");\n    for (;;) __asm__ volatile (\"cli; hlt\");\n}\n```\n**The error code is a state machine.** Consider what each combination means:\n- `present=0, write=0, user=0`: Kernel code accessed an unmapped page. This is always a kernel bug \u2014 a null pointer dereference, use-after-free, or uninitialized pointer.\n- `present=0, write=0, user=1`: User code accessed an unmapped page in a read. With demand paging, this is a valid trigger: allocate the page, map it, return. Without demand paging: segfault.\n- `present=1, write=1, user=1`: User code tried to write a read-only page. With copy-on-write (fork): duplicate the frame, remap. Without: segfault.\n- `present=0, write=0, user=0` at CR2=0x00000000: A null pointer dereference (after you removed the identity map). The most common kernel bug.\n> **Knowledge Cascade \u2014 Demand Paging and Copy-on-Write Across Domains**: The page fault handler you just built is the exact mechanism behind `fork()`, lazy allocation in `malloc`, memory-mapped files, and Docker's overlay filesystem. When Linux calls `fork()`, it doesn't copy the parent's memory \u2014 it marks every page in both processes as read-only and sets a copy-on-write flag. When either process writes to any page, a `present=1, write=1` page fault fires. The handler allocates a new frame, copies the page content, remaps the faulting process to the new frame with write permission, and returns. The write succeeds on retry. This means `fork()` is O(1) in the common case where the child immediately calls `exec()` \u2014 no data is ever copied. Docker's overlay filesystem extends this: each container layer is a set of copy-on-write page mappings; unmodified pages are shared at the physical level, modified pages get their own frames. The mechanism is identical to what you built, applied at the filesystem layer. `mmap(2)` for a 1GB file also uses this: no data is read at `mmap` time. Only accessed pages trigger faults that read disk sectors and map them. Your page fault handler is the architectural ancestor of all of this.\n---\n## Phase 9: The Kernel Heap \u2014 kmalloc and kfree\n\n![Kernel Heap (kmalloc/kfree) \u2014 Virtual Memory Backing](./diagrams/diag-m3-kernel-heap-architecture.svg)\n\nThe physical frame allocator gives you 4KB chunks. Your kernel code needs arbitrary-sized allocations \u2014 `uint8_t *buf = kmalloc(37)` for a PS/2 command buffer, `process_t *p = kmalloc(sizeof(process_t))` for a new PCB in Milestone 4. You need a heap.\n**The strategy: a simple slab-like allocator backed by the frame allocator.**\nReserve a range of virtual addresses for the kernel heap \u2014 say `0xC0400000`\u2013`0xCFFFFFFF` (252MB of virtual space). The heap manager maintains a pointer to the \"current brk\" (break pointer \u2014 the end of committed heap memory). On each `kmalloc`, if sufficient space is available in the committed region, serve from it. If not, call `pmm_alloc_frame` to get a new physical frame, use `paging_map` to commit it at the next virtual address, and advance the brk.\nFor this milestone, implement a simple **free-list heap allocator**:\n```c\n#define HEAP_START   0xC0400000\n#define HEAP_END     0xCFFF0000\n#define HEAP_MIN_SIZE 4096       // Grow heap in page increments\n// Each allocation has a header immediately before the returned pointer\ntypedef struct heap_block {\n    uint32_t         size;   // Size of data area (not including header)\n    uint32_t         magic;  // Sanity check against corruption\n    uint8_t          used;   // 1 = allocated, 0 = free\n    struct heap_block *next; // Next block in the free/used list\n    struct heap_block *prev;\n} heap_block_t;\n#define HEAP_MAGIC 0xDEADBEEF\nstatic heap_block_t *heap_head = NULL;\nstatic uint32_t heap_brk = HEAP_START;  // Current top of committed heap\n// Extend the heap by at least 'size' bytes (always extends by full pages)\nstatic heap_block_t *heap_extend(uint32_t size) {\n    uint32_t pages_needed = (size + sizeof(heap_block_t) + PAGE_SIZE - 1) / PAGE_SIZE;\n    uint32_t new_virt = heap_brk;\n    for (uint32_t i = 0; i < pages_needed; i++) {\n        if (heap_brk >= HEAP_END) {\n            kprintf(\"[HEAP] Out of virtual heap space\\n\");\n            return NULL;\n        }\n        uint32_t phys = pmm_alloc_frame();\n        paging_map(current_page_dir, heap_brk, phys, PTE_WRITABLE);\n        heap_brk += PAGE_SIZE;\n    }\n    // Initialize new block header at new_virt\n    heap_block_t *block = (heap_block_t *)new_virt;\n    block->size  = pages_needed * PAGE_SIZE - sizeof(heap_block_t);\n    block->magic = HEAP_MAGIC;\n    block->used  = 0;\n    block->next  = NULL;\n    block->prev  = NULL;\n    // Add to end of block list\n    if (!heap_head) {\n        heap_head = block;\n    } else {\n        heap_block_t *last = heap_head;\n        while (last->next) last = last->next;\n        last->next = block;\n        block->prev = last;\n    }\n    return block;\n}\nvoid *kmalloc(uint32_t size) {\n    if (size == 0) return NULL;\n    // Align size to 8 bytes for natural alignment\n    size = (size + 7) & ~7u;\n    // First-fit search for a free block\n    heap_block_t *block = heap_head;\n    while (block) {\n        if (block->magic != HEAP_MAGIC) {\n            kprintf(\"[HEAP] CORRUPTION: bad magic at 0x%x\\n\", (uint32_t)block);\n            for (;;) __asm__ volatile (\"hlt\");\n        }\n        if (!block->used && block->size >= size) {\n            // Found a suitable free block\n            // Split if remainder is large enough to hold a new block + min allocation\n            if (block->size >= size + sizeof(heap_block_t) + 8) {\n                heap_block_t *remainder =\n                    (heap_block_t *)((uint8_t *)(block + 1) + size);\n                remainder->size  = block->size - size - sizeof(heap_block_t);\n                remainder->magic = HEAP_MAGIC;\n                remainder->used  = 0;\n                remainder->next  = block->next;\n                remainder->prev  = block;\n                if (block->next) block->next->prev = remainder;\n                block->next = remainder;\n                block->size = size;\n            }\n            block->used = 1;\n            return (void *)(block + 1); // Return pointer past header\n        }\n        block = block->next;\n    }\n    // No suitable block found \u2014 extend the heap\n    block = heap_extend(size);\n    if (!block) return NULL;\n    return kmalloc(size); // Retry with new block\n}\nvoid kfree(void *ptr) {\n    if (!ptr) return;\n    heap_block_t *block = (heap_block_t *)ptr - 1; // Header is just before ptr\n    if (block->magic != HEAP_MAGIC) {\n        kprintf(\"[HEAP] kfree: bad magic at 0x%x (invalid or double-free?)\\n\",\n                (uint32_t)block);\n        for (;;) __asm__ volatile (\"hlt\");\n    }\n    if (!block->used) {\n        kprintf(\"[HEAP] kfree: double-free detected at 0x%x\\n\", ptr);\n        for (;;) __asm__ volatile (\"hlt\");\n    }\n    block->used = 0;\n    // Coalesce with next block if also free\n    if (block->next && !block->next->used &&\n        block->next->magic == HEAP_MAGIC) {\n        block->size += sizeof(heap_block_t) + block->next->size;\n        block->next  = block->next->next;\n        if (block->next) block->next->prev = block;\n    }\n    // Coalesce with previous block if also free\n    if (block->prev && !block->prev->used &&\n        block->prev->magic == HEAP_MAGIC) {\n        block->prev->size += sizeof(heap_block_t) + block->size;\n        block->prev->next  = block->next;\n        if (block->next) block->next->prev = block->prev;\n    }\n}\n```\n**Memory layout of an allocated block:**\n```\n| heap_block_t header (20 bytes) | user data (size bytes, aligned to 8) |\n^                                 ^\nblock                             ptr returned to caller\n```\n**The magic value `0xDEADBEEF` catches common corruption.** If a buffer overrun writes into the header of the next block, the magic field is corrupted. On the next `kmalloc` or `kfree` that encounters that block, the magic check fires and you get a diagnostic message pointing to the corrupted block's address. This is a lightweight version of what jemalloc calls \"freelist integrity checking\" \u2014 the production version includes cryptographic checksums and red zones around each allocation.\n> **Hardware Soul**: Each `kmalloc` allocation involves a first-fit linear scan of the free list \u2014 O(n) in the number of live allocations. For a kernel with dozens of active allocations, this is perfectly acceptable. At thousands of allocations, it becomes a bottleneck because the free list is an unpredictable, pointer-chasing linked list \u2014 the worst possible memory access pattern for a cache. Every `block->next` dereference risks a cache miss because the next block is at an arbitrary address. This is why production kernel allocators (jemalloc, mimalloc, the Linux slab allocator) use **size-class segregation**: separate free lists for 8B, 16B, 32B, 64B, ... allocations. Allocating 37 bytes rounds up to the 64-byte class, returning from that class's freelist in O(1). The physical locality of same-size objects also improves cache behavior: objects of similar size tend to be used together, so keeping them in the same page maximizes cache line utilization. Mimalloc additionally uses \"mimalloc segments\" \u2014 4MB regions of physically-contiguous memory \u2014 to ensure that all objects from the same thread live in the same NUMA node, eliminating cross-NUMA memory bus latency. Your heap allocator is the slab allocator's humble ancestor.\n> **Knowledge Cascade \u2014 Cache Coloring and Physical Frame Choice**: Your `pmm_alloc_frame` always returns the first available frame. This is correct for correctness, but suboptimal for performance. The physical frame number determines which cache set in the L1/L2 cache the page maps to \u2014 this is called the **cache set index** and is computed from address bits above the cache line offset. If every allocation returns frames with the same lower bits, all allocations compete for the same cache sets \u2014 causing excessive cache evictions even when total working set fits in cache. **Cache coloring** is the technique of varying the frame number's lower bits across successive allocations so that different objects map to different cache sets. jemalloc implements a version of this through its arena design: each arena's `sbrk`-extended memory has a different alignment, spreading allocations across the 8-way L1 cache. PostgreSQL uses huge pages specifically to reduce the number of TLB entries needed for its buffer pool, since fewer but larger pages occupy fewer TLB entries. These are the same insights your bitmap allocator will need if you push performance \u2014 but for this milestone, first-fit correctness is the goal.\n---\n## Phase 10: Complete Initialization Sequence\n{{DIAGRAM:diag-m3-virtual-address-space-layout}}\nHere is the complete, correct initialization order, with the reason each step must precede the next:\n```c\nvoid kernel_main(multiboot_info_t *mbi) {\n    // NOTE: We are now running at virtual address 0xC0100xxx\n    // The identity map has been removed. NULL dereference = page fault.\n    // 1. Output subsystem (already initialized in boot stub or reinit here)\n    vga_clear();\n    serial_init();\n    kprintf(\"=== Kernel Milestone 3: Memory Management ===\\n\");\n    // 2. GDT and IDT from Milestones 1-2\n    gdt_init();\n    idt_init();\n    // 3. Parse the physical memory map\n    //    Must happen before PMM init, which needs to know memory regions\n    mmap_parse(mbi);\n    // 4. Initialize the physical frame allocator\n    //    Must happen before any paging_map calls\n    pmm_init(mbi);\n    // 5. Paging is already enabled (done in boot stub)\n    //    Install the full page fault handler (which now has PMM available)\n    idt_set_gate(14, (uint32_t)isr_14, 0x08, 0x8E);\n    // 6. Initialize the kernel heap\n    //    Must happen after PMM (heap uses pmm_alloc_frame) and\n    //    after paging (heap uses paging_map)\n    heap_init();  // Sets heap_brk = HEAP_START, heap_head = NULL\n    // 7. PIC and timer from Milestone 2\n    pic_remap(0x20, 0x28);\n    pit_init(100);\n    // 8. Enable interrupts\n    __asm__ volatile (\"sti\");\n    // 9. Test the memory subsystem\n    kprintf(\"\\n--- Memory Subsystem Tests ---\\n\");\n    // Test 1: Basic allocation\n    void *a = kmalloc(64);\n    void *b = kmalloc(128);\n    kprintf(\"kmalloc(64)  = 0x%x\\n\", a);\n    kprintf(\"kmalloc(128) = 0x%x\\n\", b);\n    // Test 2: Write to allocations (touches physical frames \u2014 would page fault if broken)\n    __builtin_memset(a, 0xAA, 64);\n    __builtin_memset(b, 0xBB, 128);\n    kprintf(\"Memory write: OK\\n\");\n    // Test 3: Free and reallocate\n    kfree(a);\n    void *c = kmalloc(32);  // Should reuse a's block (it's larger, will be split)\n    kprintf(\"After kfree+kmalloc(32): c=0x%x (expect near a=0x%x)\\n\", c, a);\n    // Test 4: Physical frame allocator stats\n    kprintf(\"\\nPMM: %u KB free\\n\", pmm_free_frames() * 4);\n    // Test 5: Trigger a page fault deliberately (if you're brave)\n    // volatile uint32_t x = *(volatile uint32_t *)0x00000000;  // NULL deref\n    // This should print a page fault diagnostic and halt \u2014 do NOT uncomment yet\n    kprintf(\"\\n[OK] Memory management initialized.\\n\");\n    for (;;) __asm__ volatile (\"hlt\");\n}\n```\n---\n## Debugging Memory Management: Survival Guide\nMemory bugs in kernel development manifest as either immediate crashes (page faults, triple faults) or silent corruption (wrong data, hung system) depending on where in the initialization sequence the error occurs.\n**QEMU monitor commands for memory debugging:**\n```\n(QEMU) info mem           # Show all virtual memory mappings\n(QEMU) info tlb           # Dump TLB contents\n(QEMU) xp /10x 0x100000  # Examine 10 words at physical 0x100000\n(QEMU) x  /10x 0xC0100000 # Examine 10 words at virtual 0xC0100000 (paging must be on)\n(QEMU) info pg            # Print the page tables (extremely useful)\n```\n**GDB with paging enabled:**\n```bash\n(gdb) target remote :1234\n(gdb) set architecture i386\n# After paging is enabled, GDB uses virtual addresses:\n(gdb) x/10x 0xC0100000    # Examine kernel code\n(gdb) p boot_pd[768]      # Inspect PDE for 0xC0000000 region\n(gdb) p *(page_table_t*)0xC0004000  # Inspect a page table\n```\n**Common failures and diagnoses:**\n| Symptom | Diagnosis |\n|---------|-----------|\n| Triple fault immediately on `mov cr0, eax` (enabling PG) | Identity map missing in page directory; instruction after CR0 write faults |\n| Triple fault on the `jmp` to higher-half address | PDE 768 missing or incorrect physical address in PTE_FRAME |\n| `kmalloc` returns 0 or causes fault | PMM ran out of frames; or `paging_map` failed to commit the heap page |\n| Double-free detected immediately at kernel start | BSS not zeroed; heap `used` field contains garbage; `heap_head` uninitialized |\n| Page fault at CR2=0xDEADBEEF or similar | Freed pointer used after free; magic value overwritten user data |\n| Page fault at CR2 = VGA address (0xB8000) | Identity map removed before VGA access, or VGA not identity-mapped |\n| Everything works in debug build, fails in optimized | `volatile` missing from MMIO pointers; compiler reordered CR3/CR0 writes without `\"memory\"` barrier |\n**The `\"memory\"` clobber in inline assembly** (`__asm__ volatile (\"...\" : : : \"memory\")`) tells the compiler that this instruction may read or write any memory location. It prevents the compiler from reordering memory accesses across the instruction barrier. This is critical for CR3 and CR0 writes \u2014 the compiler must not reorder page table modifications to happen after CR3 is loaded, or the CPU walks a partially-constructed table.\n---\n## System Awareness: Where You Now Stand\n\n![OS Kernel \u2014 Satellite System Map](./diagrams/diag-satellite-os-map.svg)\n\nAfter this milestone, your kernel has fundamentally changed character. It no longer lives in a flat physical address space \u2014 it inhabits an isolated, structured virtual space that the hardware enforces.\n**What you have built:**\n- A physical memory map parser that classifies every byte of physical RAM\n- A bitmap allocator with double-free detection that hands out 4KB frames\n- Two-level page tables that implement both identity mapping and higher-half kernel mapping\n- The paging enable sequence with the precise identity\u2192higher-half handoff\n- TLB management with `invlpg` for targeted flushes\n- A page fault handler that decodes CR2 and the error code\n- A kernel heap allocator with coalescing and corruption detection\n**What connects forward to Milestone 4:**\nThe page directory you created is the first **process address space**. When Milestone 4 introduces processes, each process will have its own page directory. The kernel mapping (PDE 768) will be replicated into every process's page directory \u2014 so the kernel is always accessible for system calls and interrupts \u2014 while the user region (PDEs 0\u2013767) will be unique per process. The page fault handler's `present=0` case will become the demand-pager, and the `present=1, write=1` case will implement copy-on-write for `fork()`.\nThe `kmalloc` you built will immediately serve Milestone 4's first need: allocating `process_t` structures and kernel stacks for new processes.\n**What did not exist before that now does:** Memory isolation. Write to a page mapped read-only and you get a fault. Access an unmapped address and you get a fault. NULL pointer dereferences are caught. The kernel has spatial boundaries that the hardware enforces.\n---\n## Knowledge Cascade\n**1. Higher-Half Kernel and KASLR.** Your kernel maps at `0xC0000000` \u2014 a fixed, known virtual address. This predictability is a security vulnerability: an attacker who knows the kernel is always at `0xC0000000` can use this in exploits (kernel ROP chains, return-to-kernel attacks). **KASLR (Kernel Address Space Layout Randomization)** randomizes this base address at boot time, chosen from a range of possible positions. The mechanism is identical to what you built \u2014 the linker script is parameterized with a base address, and the boot stub sets up page tables using the randomly chosen base. Linux implements KASLR since 3.14; macOS kASLR since 10.8. The same principle applies to user space \u2014 ASLR randomizes the base addresses of the stack, heap, and libraries, defeating hardcoded address attacks. Your understanding of how page tables implement a specific mapping is the prerequisite for understanding how randomizing those mappings improves security.\n**2. Demand Paging and Container Copy-on-Write.** The page fault handler you built \u2014 specifically the path that fires when a not-present page is accessed \u2014 is the mechanism that makes every major memory management optimization possible. `malloc` in modern libc doesn't call `mmap` and touch every allocated byte; it maps virtual pages and lets page faults commit physical frames only as data is written. `fork()` uses the same mechanism via copy-on-write to give a child process a read-only snapshot of the parent's address space in O(1) time. Docker's overlay filesystem \u2014 the mechanism that lets containers share base layers \u2014 is copy-on-write at the filesystem layer using the same principle: shared pages are read-only; the first write to a shared block allocates a new copy. Your page fault handler is architecturally the common ancestor of all of these.\n**3. Hardware Page Table Walkers \u2014 Beyond the CPU.** The CPU's MMU autonomously walking your `page_directory_t` / `page_table_t` data structures is a specific instance of a broader hardware pattern: **hardware-walked in-memory descriptor rings**. GPU texture samplers walk texture descriptor tables to fetch texel data for shader cores \u2014 the format is different but the principle is identical: software prepares a structured table, hardware reads it autonomously. The **IOMMU** (Input/Output Memory Management Unit) provides DMA isolation: it sits between PCIe devices and physical memory, using page tables to restrict what addresses a NIC or GPU can DMA-read/write, preventing a compromised device from reading kernel memory. Network cards use descriptor rings (TX and RX queues) that are hardware-walked by the NIC DMA engine to send and receive packets without CPU involvement. In all cases: software defines a structure in memory; hardware reads and walks it autonomously; the structure format is a hardware contract, not a software choice. Your x86 page table is the most fundamental example.\n**4. jemalloc, mimalloc, and Cache-Aware Allocation.** Your `kmalloc` is a correct but naive free-list allocator. Its O(n) scan and pointer-chasing access pattern are the exact pathologies that jemalloc and mimalloc were designed to eliminate. jemalloc (created for FreeBSD, adopted by Firefox and Meta) uses size-class segregation with per-thread caches to achieve O(1) allocation with minimal lock contention. mimalloc (Microsoft Research) adds \"mimalloc segments\" \u2014 large, physically-contiguous arenas that improve TLB coverage and enable branch-prediction-friendly allocation patterns. The key insight both share: **physical locality matters more than logical simplicity**. Objects used together should live on the same cache lines; objects of similar size should live in the same page; all allocations from a thread should live in the same NUMA node. Your bitmap allocator's na\u00efve first-fit is where the optimization journey starts.\n**5. The TLB and NUMA-Aware Database Design.** TLB misses are invisible \u2014 they don't cause explicit faults, they just add latency to memory accesses. But on large in-memory databases (Redis, ScyllaDB, MemSQL), TLB pressure is measurable and optimizable. ScyllaDB pins each shard to a NUMA node and uses huge pages (2MB) for its memory pool: 2MB pages require 512\u00d7 fewer TLB entries than 4KB pages for the same total memory. With a 1536-entry L2 TLB and 4KB pages, ScyllaDB's 64GB shard would require 16M TLB entries \u2014 an impossible load. With 2MB huge pages, it needs only 32K. The TLB becomes sufficient, and memory accesses stop incurring translation misses. Understanding that the TLB has a finite capacity \u2014 and that every allocated page consumes one entry \u2014 is the insight behind this optimization, and you now understand why from silicon level up.\n---\n<!-- END_MS -->\n\n\n<!-- MS_ID: build-os-m4 -->\n<!-- MS_ID: build-os-m4 -->\n# Milestone 4: Processes and Preemptive Scheduling\n\n![OS Kernel \u2014 Satellite System Map](./diagrams/diag-satellite-os-map.svg)\n\nEvery mechanism you built in the previous three milestones was preparation for this moment. The GDT established privilege rings. The IDT gave you hardware interrupt handling. The page tables gave each address space its own identity. Now you will combine all of it into the one abstraction that defines what an operating system actually *is*: the **process**.\nBut before you write a single line of code, you need to confront the deepest conceptual challenge of this milestone \u2014 one that trips up nearly every developer who approaches it with intuitions borrowed from userspace programming.\n---\n## The Revelation: A Context Switch Is Not What You Think It Is\nHere is what most developers imagine when they picture a context switch. They think of it like saving and loading a game: you serialize the \"state\" of one process into some data structure, then deserialize another process's state and resume it. Clean, well-defined, like swapping JSON objects. One process's record is written; another is read; execution continues.\n**This model is wrong in a way that will cause you to write broken code if you rely on it.**\nA context switch is a controlled explosion of paradoxes. The function that performs the switch begins its execution *as the old process* and returns *as a completely different process* \u2014 the identity of \"who is running\" changes inside a single function call. Specifically, the identity changes at the moment you swap the stack pointer (ESP). Before the swap, every push and pop touches the old process's kernel stack. After the swap, they touch the new process's kernel stack. This means you can push five registers onto what is unambiguously Process A's stack, swap ESP, and then pop five registers from what is unambiguously Process B's stack \u2014 and this is not a bug. This is the entire mechanism working correctly.\nThink about what this means concretely. The context switch function has a local variable for `current_process` and `next_process`. It calls `context_switch(next)`. Inside that function, it saves registers to `current->context.esp`, then loads `next->context.esp` into ESP. The CPU is now on next's stack. The function then does `ret` \u2014 which pops the return address from next's stack (a return address that was pushed there the last time *next* was switched out). The function returns \u2014 to *next's* suspended call site, not to the caller that invoked it for the current process.\nThe caller that invoked `context_switch(next)` for the current process will eventually see a return \u2014 but only the next time the scheduler decides to run the current process again. At that point, control will reappear at the instruction after the `context_switch` call, but ESP will be back on the current process's stack, and all of the current process's registers will be restored. From the perspective of the current process, `context_switch` just returned (perhaps thousands of timer ticks later) as if nothing happened.\nThe TSS (Task State Segment) adds another layer of strangeness. When a ring-3 user process is interrupted by a hardware interrupt, the CPU must switch to a kernel stack to run the interrupt handler. But at the moment the interrupt fires, the CPU is executing user code \u2014 it has no idea which kernel stack to use. This is precisely what the TSS is for: a hardware structure that the CPU reads during a privilege transition to find the kernel stack pointer. The field it reads is `SS0:ESP0` \u2014 the kernel stack segment and pointer.\nThe brutal implication: **the TSS must be updated on every context switch.** When you switch from Process A to Process B, you must update the TSS's `ESP0` field to point to Process B's kernel stack top. If you don't, the next interrupt while Process B is running will have the CPU switch to Process A's kernel stack \u2014 corrupting whatever state A had saved there. The system will not crash immediately. It will corrupt data silently and crash unpredictably later. This category of bug is among the hardest to diagnose in operating system development.\nThese three paradoxes \u2014 the identity-change mid-function, the push-on-one-stack-pop-from-another, the TSS ESP0 update requirement \u2014 are what make context switching genuinely difficult to reason about. Once you internalize them, the implementation becomes clear. Let's build it.\n---\n## Phase 1: Designing the Process Control Block\n\n![Process Control Block \u2014 Byte-Level Structure](./diagrams/diag-m4-pcb-structure-layout.svg)\n\nThe Process Control Block (PCB) is the kernel's complete record of a process. Everything the kernel needs to suspend a process and later resume it as if nothing happened lives in the PCB. Every field has a precise reason for existing.\n```c\n// process.h\n#include <stdint.h>\n// Process states \u2014 the nodes of the state machine\ntypedef enum {\n    PROCESS_READY    = 0,  // In the run queue, waiting for CPU time\n    PROCESS_RUNNING  = 1,  // Currently executing on the CPU\n    PROCESS_BLOCKED  = 2,  // Waiting for an event (I/O, sleep, etc.)\n    PROCESS_DEAD     = 3,  // Exited; slot can be reclaimed\n} process_state_t;\n// The saved CPU register context \u2014 exactly what we need to restart a process\n// This layout must match the order of pushes/pops in context_switch.asm\ntypedef struct {\n    uint32_t edi;       // General purpose registers (saved by software)\n    uint32_t esi;\n    uint32_t ebx;\n    uint32_t ebp;       // Frame pointer\n    uint32_t esp;       // Stack pointer \u2014 the linchpin of context switching\n    uint32_t eip;       // Instruction pointer \u2014 where to resume execution\n    uint32_t eflags;    // CPU flags \u2014 including the interrupt enable flag (IF)\n} cpu_context_t;\n// Memory layout of cpu_context_t:\n// Offset  0: edi    (4 bytes)\n// Offset  4: esi    (4 bytes)\n// Offset  8: ebx    (4 bytes)\n// Offset 12: ebp    (4 bytes)\n// Offset 16: esp    (4 bytes)  \u2190 THE PIVOT POINT\n// Offset 20: eip    (4 bytes)\n// Offset 24: eflags (4 bytes)\n// Total: 28 bytes\n#define KERNEL_STACK_SIZE  8192   // 8 KB per process kernel stack\n#define MAX_PROCESSES      64\ntypedef struct process {\n    // Identity\n    uint32_t         pid;           // Process ID (unique, monotonically increasing)\n    char             name[32];      // Human-readable name for debugging\n    // Scheduler state\n    process_state_t  state;         // Current state in the process lifecycle\n    // Saved CPU state (valid only when process is not RUNNING)\n    cpu_context_t    context;       // Register snapshot from last context switch\n    // Memory management\n    uint32_t        *page_directory; // Physical address of this process's page directory\n                                     // Loaded into CR3 on context switch\n    // Kernel stack \u2014 used for interrupt handling and system calls when this process\n    // is the current process. The kernel runs on this stack, not the user stack,\n    // during privilege transitions.\n    uint8_t         *kernel_stack;      // Pointer to bottom of kernel stack allocation\n    uint32_t         kernel_stack_top;  // ESP0 value for TSS \u2014 top of kernel stack\n    // User-mode state (only meaningful for ring-3 processes)\n    uint32_t         user_esp;      // User-mode stack pointer (saved on interrupt entry)\n    // Scheduling metadata\n    uint32_t         ticks_remaining; // Remaining time slice (for future priority scheduler)\n    uint32_t         total_ticks;     // Total CPU ticks consumed (for accounting)\n    // Linked list for run queue\n    struct process  *next;          // Next process in the circular ready queue\n} process_t;\n// The run queue: a circular singly-linked list of READY processes\nextern process_t *current_process;\nextern process_t *process_list_head;\n```\n**Why save EIP separately?** When a process is running normally and gets preempted by a timer interrupt, the CPU automatically pushes EIP (and CS, EFLAGS) onto the kernel stack as part of the interrupt entry sequence. The context switch happens *inside the interrupt handler*, so the EIP that needs to be saved is the EIP of the interrupted instruction \u2014 already on the kernel stack. For the first time a process is ever scheduled, though, we need to *fabricate* an initial context where EIP points to the process's entry function. We do this by initializing the EIP field manually when creating the process. This asymmetry \u2014 EIP is sometimes saved by hardware (real interruption) and sometimes set by software (first scheduling) \u2014 is elegantly handled by how we initialize the kernel stack, which we'll cover shortly.\n**Why `page_directory` stores a physical address?** CR3 must contain a physical address \u2014 the MMU reads it before the TLB has any valid entries for the new address space. If you stored the virtual address of the page directory and wrote it to CR3, you'd be loading a virtual address into a register that expects physical. The result is a page fault on the very first memory access the MMU attempts. Always track physical addresses for hardware registers.\n**Why `kernel_stack_top` as a separate field?** The top of the kernel stack changes as the stack is used (ESP moves down). But the TSS `ESP0` should always be the *initial* top \u2014 the empty, unused value \u2014 so the CPU knows where the fresh kernel stack begins for the next interrupt. If the process is currently blocked in kernel code (e.g., waiting for keyboard input), the actual ESP is deep in the stack, but TSS ESP0 should still be the original top. This is the value we update the TSS with on every switch.\n---\n## Phase 2: Understanding Hardware Stack Switching \u2014 The TSS\n\n![Task State Segment \u2014 Structure and SS0:ESP0](./diagrams/diag-m4-tss-structure.svg)\n\nThe Task State Segment is an x86 hardware structure that has been part of the architecture since the 80286. Intel originally designed it to support full hardware multitasking \u2014 the CPU would automatically save and restore the entire CPU state on a \"task switch\" instruction. Modern operating systems don't use hardware task switching (it's too slow and inflexible), but the TSS is still required for one specific purpose that cannot be avoided: **telling the CPU which kernel stack to use when a ring-3 process is interrupted**.\nHere is precisely what happens when a timer interrupt fires while a user-mode process is running:\n1. The CPU detects the interrupt signal on the INTR pin.\n2. The CPU is currently executing at ring 3 (user mode), with ESP pointing into the user process's stack.\n3. Before any interrupt handler code can run, the CPU must switch to the kernel stack \u2014 because running interrupt handlers on the user's stack would let user code observe or manipulate kernel state.\n4. **The CPU reads the TSS.** Specifically, it reads the `SS0` and `ESP0` fields from the TSS. These give it the kernel stack segment selector and the kernel stack pointer to switch to.\n5. The CPU pushes SS (user stack segment), ESP (user stack pointer), EFLAGS, CS, and EIP onto the *kernel* stack (at the address it just read from the TSS).\n6. Now the kernel stack has the user state saved on it, and the CPU is running at ring 0 with ESP pointing into the kernel stack.\nIf the TSS `ESP0` is wrong \u2014 pointing to the old process's kernel stack \u2014 the CPU pushes the interrupt frame there, corrupting whatever that process had stored. The wrong stack is now used for the interrupt handler, EFLAGS gets corrupted, and the system exhibits mysterious behavior. This is why TSS `ESP0` **must** be updated on every context switch.\nThe TSS structure for 32-bit protected mode:\n```c\n// tss.h\n// The Task State Segment \u2014 hardware-defined structure, fields at fixed offsets\n// Only SS0 and ESP0 are used by modern kernels (software task switching)\n// All other fields are zeroed and ignored\ntypedef struct {\n    uint32_t prev_tss;   // Offset 0:  Link to previous TSS (unused, 0)\n    uint32_t esp0;       // Offset 4:  Kernel stack pointer \u2190 THE KEY FIELD\n    uint32_t ss0;        // Offset 8:  Kernel stack segment (0x10 = kernel data)\n    uint32_t esp1;       // Offset 12: Ring 1 stack (unused, 0)\n    uint32_t ss1;        // Offset 16: Ring 1 stack segment (unused, 0)\n    uint32_t esp2;       // Offset 20: Ring 2 stack (unused, 0)\n    uint32_t ss2;        // Offset 24: Ring 2 stack segment (unused, 0)\n    uint32_t cr3;        // Offset 28: CR3 for hardware task switch (we handle this)\n    uint32_t eip;        // Offset 32: EIP for hardware task switch (unused)\n    uint32_t eflags;     // Offset 36: (unused)\n    uint32_t eax;        // Offset 40: (unused)\n    uint32_t ecx;        // Offset 44: (unused)\n    uint32_t edx;        // Offset 48: (unused)\n    uint32_t ebx;        // Offset 52: (unused)\n    uint32_t esp;        // Offset 56: (unused)\n    uint32_t ebp;        // Offset 60: (unused)\n    uint32_t esi;        // Offset 64: (unused)\n    uint32_t edi;        // Offset 68: (unused)\n    uint16_t es;         // Offset 72: (unused)\n    uint16_t _pad0;\n    uint16_t cs;         // Offset 76: (unused)\n    uint16_t _pad1;\n    uint16_t ss;         // Offset 80: (unused)\n    uint16_t _pad2;\n    uint16_t ds;         // Offset 84: (unused)\n    uint16_t _pad3;\n    uint16_t fs;         // Offset 88: (unused)\n    uint16_t _pad4;\n    uint16_t gs;         // Offset 92: (unused)\n    uint16_t _pad5;\n    uint16_t ldt;        // Offset 96: LDT selector (unused, 0)\n    uint16_t _pad6;\n    uint16_t trap;       // Offset 100: trap on task switch (0)\n    uint16_t iomap_base; // Offset 102: I/O permission bitmap base (0xFFFF = disabled)\n} __attribute__((packed)) tss_t;\nstatic tss_t kernel_tss;\n// Initialize the TSS and register it in the GDT\nvoid tss_init(void) {\n    // Zero everything \u2014 most fields are unused in software task switching\n    __builtin_memset(&kernel_tss, 0, sizeof(tss_t));\n    // The kernel uses selector 0x10 (GDT entry 2) as the data segment\n    kernel_tss.ss0       = 0x10;\n    // esp0 will be set per-process on each context switch \u2014 leave 0 for now\n    kernel_tss.esp0      = 0;\n    // I/O permission bitmap: set base to just past the TSS limit \u2192 no I/O allowed\n    // from ring 3 by default (only ring 0 can use in/out instructions)\n    kernel_tss.iomap_base = sizeof(tss_t);\n    // Register the TSS descriptor in the GDT (GDT entry 5, selector 0x28)\n    // The TSS descriptor is a special \"system\" descriptor (type = 0x89 for 32-bit TSS)\n    // Unlike code/data segments, the base is the actual address of the TSS structure\n    uint32_t base  = (uint32_t)&kernel_tss;\n    uint32_t limit = sizeof(tss_t) - 1;\n    gdt_set_tss_entry(5, base, limit); // You'll add entry 5 to the GDT\n    // Load the TSS selector into the TR (Task Register)\n    // The selector 0x28 with RPL=0: (5 << 3) | 0 = 0x28\n    // The '| 3' is NOT needed here \u2014 the TR is a privileged register\n    __asm__ volatile (\"ltr %0\" : : \"r\"((uint16_t)0x28));\n}\n// Called on every context switch to update ESP0\nvoid tss_set_kernel_stack(uint32_t esp0) {\n    kernel_tss.esp0 = esp0;\n}\n```\n**Adding the TSS descriptor to the GDT:** The GDT currently has 5 entries (null, kernel code, kernel data, user code, user data). You need to add a 6th \u2014 the TSS descriptor. Unlike code and data descriptors that use the S=1 (system=code/data) bit, the TSS descriptor is a **system descriptor** (S=0) with type `0x9` for an available 32-bit TSS:\n```c\nvoid gdt_set_tss_entry(int index, uint32_t base, uint32_t limit) {\n    // type=9 (32-bit TSS, available), S=0 (system descriptor), DPL=0, P=1\n    // access byte = 0x89: Present=1, DPL=0, S=0, Type=1001 (TSS32 available)\n    set_gdt_entry(index, base, limit, 0x89, 0x00);\n    // Note: flags=0x00 because TSS uses byte granularity, not page granularity\n}\n```\n**The GDT now has 6 entries:**\n| Index | Selector | Purpose |\n|-------|----------|---------|\n| 0 | `0x00` | Null descriptor |\n| 1 | `0x08` | Kernel code (ring 0) |\n| 2 | `0x10` | Kernel data (ring 0) |\n| 3 | `0x18` | User code (ring 3, with RPL=3 \u2192 `0x1B`) |\n| 4 | `0x20` | User data (ring 3, with RPL=3 \u2192 `0x23`) |\n| 5 | `0x28` | TSS descriptor |\n> **\ud83d\udd11 Two-level paging and how the TSS interacts with it:** When you switch processes, you load the new process's page directory into CR3. But the TSS itself lives at a kernel virtual address. After the CR3 switch, the TSS must still be accessible \u2014 which means the kernel's virtual address mappings must be present in every process's page directory. This is why your Milestone 3 design replicated the kernel PDEs (entries 768 onward in the page directory) into every process's page directory. The TSS, interrupt handlers, GDT, and IDT all live at kernel virtual addresses that must be reachable from any address space.\n---\n## Phase 3: The Context Switch \u2014 Assembly as the Only Option\n\n![Context Switch \u2014 Register Save/Restore Trace](./diagrams/diag-m4-context-switch-assembly.svg)\n\n\n![Two Kernel Stacks \u2014 The ESP Swap Moment](./diagrams/diag-m4-context-switch-stacks.svg)\n\nThis is the function that cannot be written in C. C compilers assume full control over register usage and stack management. A context switch by definition violates those assumptions: it deliberately changes ESP to point somewhere completely different, and the compiler cannot generate correct code for that without knowing what you're doing. You must write this in assembly.\nThe conceptual sequence of a context switch from Process A to Process B:\n1. **Save A's registers** onto A's kernel stack (or into A's `cpu_context_t`)\n2. **Store A's ESP** into `A->context.esp`\n3. **Load B's ESP** from `B->context.esp` \u2190 **the identity swap happens here**\n4. **Restore B's registers** from B's kernel stack\n5. **Return** \u2014 which pops B's saved EIP and resumes B's execution\n```nasm\n; context_switch.asm\n; Calling convention: void context_switch(cpu_context_t *old_ctx, cpu_context_t *new_ctx)\n; Arguments on stack: [ESP+4] = old_ctx, [ESP+8] = new_ctx\n; (Recall: cdecl calling convention \u2014 caller pushes args right-to-left before call)\n[BITS 32]\n[GLOBAL context_switch_asm]\ncontext_switch_asm:\n    ; \u2500\u2500 SAVE OLD PROCESS CONTEXT \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    ; At this point: ESP points to old process's kernel stack\n    ; The call instruction already pushed the return EIP onto the stack\n    ; Save callee-saved registers per cdecl ABI:\n    ; EBX, EBP, ESI, EDI must be preserved across function calls.\n    ; EAX, ECX, EDX are caller-saved \u2014 the caller already saved them if needed.\n    push ebx\n    push esi\n    push edi\n    push ebp\n    ; Push EFLAGS \u2014 critical! Includes the Interrupt Flag (IF).\n    ; If IF is set in old process's EFLAGS but we forget to save/restore it,\n    ; the new process might run with interrupts disabled forever.\n    pushfd              ; Push EFLAGS onto stack\n    ; Save old process's ESP into old_ctx->esp\n    ; old_ctx is at [original_ESP + 4 + 20] = [ESP+24] after the 5 pushes above\n    ; Wait \u2014 we need to be careful: after pushfd, ESP has moved.\n    ; Let's track: original ESP = ESP0\n    ;   push ebx  \u2192 ESP = ESP0 - 4\n    ;   push esi  \u2192 ESP = ESP0 - 8\n    ;   push edi  \u2192 ESP = ESP0 - 12\n    ;   push ebp  \u2192 ESP = ESP0 - 16\n    ;   pushfd    \u2192 ESP = ESP0 - 20\n    ; The function argument old_ctx was at [ESP0+4] (4 bytes for return address)\n    ; Now it's at [ESP + 24]: current ESP is ESP0-20, so ESP0+4 = ESP+24\n    mov eax, [esp + 24]     ; EAX = old_ctx (first argument)\n    mov [eax + 16], esp     ; old_ctx->esp = current ESP (offset 16 in cpu_context_t)\n                            ; This captures the entire saved state on the stack\n    ; \u2500\u2500 SWITCH TO NEW PROCESS CONTEXT \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    ; Load new process's ESP. After this instruction, we are on the new stack.\n    mov eax, [esp + 28]     ; EAX = new_ctx (second argument, now at ESP+28)\n                            ; Why +28? The arguments were pushed BEFORE our saves,\n                            ; so relative to CURRENT esp:\n                            ; [esp+0]  = EFLAGS (just pushed)\n                            ; [esp+4]  = EBP\n                            ; [esp+8]  = EDI\n                            ; [esp+12] = ESI\n                            ; [esp+16] = EBX\n                            ; [esp+20] = return EIP (pushed by 'call')\n                            ; [esp+24] = old_ctx (first arg)\n                            ; [esp+28] = new_ctx (second arg)\n    mov esp, [eax + 16]     ; ESP = new_ctx->esp \u2190 IDENTITY SWAP HAPPENS HERE\n                            ; We are now on the new process's kernel stack\n    ; \u2500\u2500 RESTORE NEW PROCESS CONTEXT \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    ; The new process's stack has (from bottom): EFLAGS, EBP, EDI, ESI, EBX, EIP\n    ; (exactly what the old process pushed the last time IT was switched out)\n    popfd               ; Restore EFLAGS (including IF \u2014 re-enables interrupts if set)\n    pop ebp\n    pop edi\n    pop esi\n    pop ebx\n    ; The 'ret' instruction pops EIP from the new stack.\n    ; This is the EIP that was pushed when the new process last called context_switch_asm\n    ; (or the fabricated initial EIP set up by process_create).\n    ; Execution resumes at the new process's last suspension point.\n    ret\n```\n**Mapping the stack layout to `cpu_context_t` offsets:**\n```\ncpu_context_t field:    Stack position (when saved):\n  edi     offset 0   \u2192 [esp+8]  after all saves (we use explicit mov, not struct)\n  esi     offset 4   \u2192 [esp+12]\n  ebx     offset 8   \u2192 [esp+16]\n  ebp     offset 12  \u2192 [esp+4]\n  esp     offset 16  \u2192 saved explicitly with mov [eax+16], esp\n  eip     offset 20  \u2192 [esp+20] (return address from 'call')\n  eflags  offset 24  \u2192 [esp+0] (pushed by pushfd)\n```\n> **Wait \u2014 we're saving ESP into a struct field but popping registers from the stack, not from the struct.** This is a deliberate design choice. Instead of copying 7 registers into the struct and then copying them back out, we save the *stack pointer* that points to where all those registers live. When we restore, we just load the saved ESP and then pop \u2014 the registers are already on the stack in the right order from when they were pushed. The struct only needs to store ESP (plus EIP and EFLAGS for the first-time setup case). This is the minimal representation \u2014 the stack *is* the saved context. This is exactly how Linux saves kernel thread contexts in `struct thread_struct`.\n**C wrapper for the scheduler:**\n```c\n// Declared in process.h, implemented in context_switch.asm\nextern void context_switch_asm(cpu_context_t *old_ctx, cpu_context_t *new_ctx);\nvoid context_switch(process_t *old, process_t *new) {\n    // 1. Update the current page directory if processes differ\n    if (old->page_directory != new->page_directory) {\n        uint32_t pd_phys = (uint32_t)new->page_directory; // already physical\n        __asm__ volatile (\"mov cr3, %0\" : : \"r\"(pd_phys) : \"memory\");\n    }\n    // 2. Update TSS ESP0 to point to the new process's kernel stack top\n    //    This MUST happen before the context switch so that any interrupt\n    //    arriving while the new process runs uses the right kernel stack.\n    tss_set_kernel_stack(new->kernel_stack_top);\n    // 3. Update the current_process pointer\n    //    This happens before context_switch_asm so that any code running\n    //    immediately after the switch (in the new process's context) sees\n    //    current_process correctly.\n    current_process = new;\n    // 4. Perform the actual register swap\n    //    After this call returns, we are the NEW process.\n    //    The OLD process will resume here (from ITS perspective) next time\n    //    it is scheduled.\n    context_switch_asm(&old->context, &new->context);\n}\n```\n---\n## Phase 4: Creating a Process \u2014 Fabricating the Initial Context\n\n![Process State Machine \u2014 Ready, Running, Blocked](./diagrams/diag-m4-process-states.svg)\n\nWhen you create a process for the first time, it has never run, so there are no \"saved registers\" to restore. You must fabricate a kernel stack that *looks exactly like* what the context switch code would have saved for a suspended process. When the scheduler first picks this process and calls `context_switch_asm`, it will pop these fabricated values and `ret` to the fabricated EIP \u2014 launching the process as if it had always existed.\n```c\nprocess_t *process_create(const char *name, void (*entry)(void),\n                           uint32_t *page_dir, int is_user) {\n    // Allocate the PCB from the kernel heap\n    process_t *proc = kmalloc(sizeof(process_t));\n    if (!proc) return NULL;\n    __builtin_memset(proc, 0, sizeof(process_t));\n    // Assign identity\n    static uint32_t next_pid = 1;\n    proc->pid   = next_pid++;\n    proc->state = PROCESS_READY;\n    __builtin_strncpy(proc->name, name, sizeof(proc->name) - 1);\n    // Allocate and set up the kernel stack\n    // This is the stack the process will use when it's in kernel mode\n    // (either because it IS a kernel process, or because it entered via interrupt/syscall)\n    proc->kernel_stack = kmalloc(KERNEL_STACK_SIZE);\n    if (!proc->kernel_stack) { kfree(proc); return NULL; }\n    __builtin_memset(proc->kernel_stack, 0, KERNEL_STACK_SIZE);\n    // kernel_stack_top is the address just past the top of the allocated buffer\n    // (stacks grow downward, so the initial ESP is at the high end)\n    proc->kernel_stack_top = (uint32_t)(proc->kernel_stack) + KERNEL_STACK_SIZE;\n    // Set the page directory\n    proc->page_directory = page_dir;\n    // \u2500\u2500 Fabricate the initial kernel stack frame \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    // We need to set up the stack so that when context_switch_asm restores\n    // this process for the first time, it looks like the process was suspended\n    // in the middle of a context_switch_asm call, with EIP pointing to 'entry'.\n    //\n    // The stack (growing downward from kernel_stack_top) must contain:\n    // [top-4]  EFLAGS  (popfd will load this; bit 9 = IF = 1 for interrupts enabled)\n    // [top-8]  EBP     (pop ebp)\n    // [top-12] EDI     (pop edi)\n    // [top-16] ESI     (pop esi)\n    // [top-20] EBX     (pop ebx)\n    // [top-24] entry   (ret will pop this as EIP \u2014 this is where execution starts!)\n    //\n    // After context_switch_asm pops these and executes 'ret', the process\n    // begins running at 'entry' with a clean register state.\n    uint32_t *stack = (uint32_t *)proc->kernel_stack_top;\n    *--stack = 0x00000202;   // EFLAGS: IF=1 (interrupts enabled), reserved bits set\n                              // bit 1 is always 1; bit 9 (IF) must be 1 or the\n                              // process will run with interrupts permanently disabled\n    *--stack = 0;             // EBP = 0 (bottom of call stack, for backtraces)\n    *--stack = 0;             // EDI = 0 (undefined at process start, initialize cleanly)\n    *--stack = 0;             // ESI = 0\n    *--stack = 0;             // EBX = 0\n    *--stack = (uint32_t)entry; // EIP \u2014 where the process will start executing\n    // Save ESP to point to the fabricated stack frame\n    // When context_switch_asm loads this ESP and begins popping,\n    // it will pop the values we just pushed above.\n    proc->context.esp = (uint32_t)stack;\n    // For user-mode processes, set up the user-mode stack separately\n    if (is_user) {\n        // Allocate a user-mode stack page\n        uint32_t user_stack_phys = pmm_alloc_frame();\n        // Map it into the process's address space at a standard user stack address\n        uint32_t user_stack_virt = 0xBFFFF000; // Top of user address space, one page\n        paging_map((page_directory_t *)page_dir, user_stack_virt,\n                   user_stack_phys, PTE_PRESENT | PTE_WRITABLE | PTE_USER);\n        proc->user_esp = user_stack_virt + PAGE_SIZE - 4; // Start at top, push downward\n    }\n    return proc;\n}\n```\n> **Why `EFLAGS = 0x00000202`?** Let's decode this: binary `0000 0000 0000 0000 0000 0010 0000 0010`. Bit 1 is always 1 (reserved, must be set). Bit 9 is the Interrupt Flag (IF) \u2014 setting it means interrupts are enabled when this process starts running. If you forget IF, the process runs with interrupts permanently disabled: the timer never fires, the scheduler never preempts, the system freezes. This is one of the most common bugs when first implementing processes, and it's invisible \u2014 the first process to run just never yields, and nothing else ever executes. Always check IF when your scheduler appears to work for one process but never switches.\n---\n## Phase 5: The Round-Robin Scheduler\n\n![Round-Robin Scheduler \u2014 Timer Interrupt to Context Switch](./diagrams/diag-m4-scheduler-flow.svg)\n\nThe scheduler is the policy layer of process management. It answers one question: given that the timer just fired, which process should run next?\nFor this milestone, you implement **round-robin scheduling**: maintain a circular linked list of READY processes and advance to the next one on each timer tick. Every process gets equal CPU time. No priorities, no starvation.\n```c\n// scheduler.c\nprocess_t *current_process   = NULL;\nprocess_t *process_list_head = NULL;  // Head of the circular ready queue\nvoid scheduler_add_process(process_t *proc) {\n    proc->state = PROCESS_READY;\n    if (!process_list_head) {\n        process_list_head = proc;\n        proc->next = proc;  // Circular: points to itself\n    } else {\n        // Insert after current position to maintain order\n        process_t *tail = process_list_head;\n        while (tail->next != process_list_head) tail = tail->next;\n        tail->next = proc;\n        proc->next = process_list_head;\n    }\n}\n// Called from the timer IRQ handler (IRQ0 \u2192 vector 32)\n// IMPORTANT: Interrupts are DISABLED when this runs (we're inside an interrupt gate)\nvoid scheduler_tick(struct interrupt_frame *frame) {\n    if (!current_process) return;\n    // Accounting: track how long this process has run\n    current_process->total_ticks++;\n    // Find the next READY process in the circular list\n    process_t *next = current_process->next;\n    int iterations = 0;\n    while (next->state != PROCESS_READY && next->state != PROCESS_RUNNING) {\n        next = next->next;\n        if (++iterations > MAX_PROCESSES) {\n            // No runnable process found \u2014 this shouldn't happen if we have an idle process\n            kprintf(\"[SCHED] No runnable process!\\n\");\n            return;\n        }\n        if (next == current_process) return; // Only one runnable process; no switch needed\n    }\n    if (next == current_process) return; // Same process \u2014 no context switch needed\n    // Transition states\n    process_t *old = current_process;\n    old->state = PROCESS_READY;\n    next->state = PROCESS_RUNNING;\n    // Perform the context switch\n    // After this call returns (possibly much later), we are back to 'old'\n    context_switch(old, next);\n    // When we reach here, this process has been rescheduled and is running again.\n    // Interrupts may have been re-enabled by popfd in context_switch_asm\n    // (if EFLAGS.IF was set in old's saved context \u2014 and it should be).\n}\n```\n**The critical timing constraint \u2014 when interrupts are enabled.** The timer handler runs with interrupts disabled (we used interrupt gates, which clear IF on entry). The context switch's `popfd` instruction restores the new process's EFLAGS, which has IF=1 set (we initialized it that way). This means after the `popfd` in `context_switch_asm`, interrupts are re-enabled for the new process. This is correct \u2014 the new process should be interruptible. But it also means you cannot do anything interrupt-sensitive between the `popfd` and the `ret` in the context switch code. Since the only remaining instruction is `ret`, this is fine.\n**Interrupts during the switch itself** (between the CR3 load, TSS update, and the register swap) must not happen. Since we entered the scheduler from an interrupt handler (interrupts disabled), we are safe. Never call `sti` inside the context switch path.\n\n![Interrupt Enable/Disable \u2014 Critical Section During Switch](./diagrams/diag-m4-interrupt-reentrancy.svg)\n\n**Connecting the timer interrupt to the scheduler:**\n```c\n// In your IRQ dispatch (from Milestone 2), add this case:\nvoid timer_handler(struct interrupt_frame *frame) {\n    tick_counter++;\n    scheduler_tick(frame);  // This is the only addition needed\n    // pic_send_eoi(0) is called by irq_dispatch after this returns\n}\n```\nThe elegance here: you built the timer interrupt in Milestone 2, never knowing exactly what would go in `timer_handler`. Now you know. The infrastructure was always ready.\n---\n## Phase 6: Three Kernel Processes \u2014 The First Multitasking Demo\n\n![Three-Process Demo \u2014 Interleaved Execution Timeline](./diagrams/diag-m4-three-process-demo.svg)\n\nBefore touching user mode, verify that kernel-mode preemptive multitasking works. Three kernel processes running concurrently, each writing to a different column of the VGA screen \u2014 a visual demonstration that is unambiguous: if all three columns are filling simultaneously, preemption is working.\n```c\n// demo_processes.c\n// Process A: writes 'A' to the left third of the screen (columns 0-26)\nstatic void process_a(void) {\n    int row = 0;\n    while (1) {\n        if (row >= 25) row = 0;\n        for (int col = 0; col < 26; col++) {\n            // Write directly to VGA buffer at process A's columns\n            volatile uint16_t *vga = (volatile uint16_t *)0xC00B8000;\n            // 0xC00B8000 = 0xB8000 + 0xC0000000 (higher-half mapped VGA)\n            vga[row * 80 + col] = (0x0A << 8) | 'A'; // Green 'A'\n        }\n        // Voluntary yield simulation: just let the timer preempt us\n        // In a real kernel, there would be a sleep() syscall here\n        for (volatile int i = 0; i < 10000; i++);\n        row++;\n    }\n}\nstatic void process_b(void) {\n    int row = 0;\n    while (1) {\n        if (row >= 25) row = 0;\n        for (int col = 27; col < 53; col++) {\n            volatile uint16_t *vga = (volatile uint16_t *)0xC00B8000;\n            vga[row * 80 + col] = (0x0C << 8) | 'B'; // Red 'B'\n        }\n        for (volatile int i = 0; i < 10000; i++);\n        row++;\n    }\n}\nstatic void process_c(void) {\n    int row = 0;\n    while (1) {\n        if (row >= 25) row = 0;\n        for (int col = 54; col < 80; col++) {\n            volatile uint16_t *vga = (volatile uint16_t *)0xC00B8000;\n            vga[row * 80 + col] = (0x0B << 8) | 'C'; // Cyan 'C'\n        }\n        for (volatile int i = 0; i < 10000; i++);\n        row++;\n    }\n}\nvoid demo_kernel_processes(void) {\n    // Use the kernel's own page directory \u2014 all kernel processes share it\n    extern page_directory_t boot_pd;\n    uint32_t *kpd = (uint32_t *)VIRT_TO_PHYS((uint32_t)&boot_pd);\n    process_t *pa = process_create(\"proc_a\", process_a, kpd, 0); // is_user=0\n    process_t *pb = process_create(\"proc_b\", process_b, kpd, 0);\n    process_t *pc = process_create(\"proc_c\", process_c, kpd, 0);\n    scheduler_add_process(pa);\n    scheduler_add_process(pb);\n    scheduler_add_process(pc);\n    // Bootstrap: manually start the first process\n    // current_process must be set before the timer fires\n    current_process = pa;\n    pa->state = PROCESS_RUNNING;\n    // We need to \"jump into\" process A without returning.\n    // Load PA's ESP and simulate a return from context_switch_asm.\n    // This is the initial scheduling bootstrap \u2014 only done once.\n    __asm__ volatile (\n        \"mov esp, %0\\n\"   // Switch to process A's kernel stack (with fabricated frame)\n        \"popfd\\n\"         // Restore EFLAGS (enables interrupts)\n        \"pop ebp\\n\"\n        \"pop edi\\n\"\n        \"pop esi\\n\"\n        \"pop ebx\\n\"\n        \"ret\\n\"           // \"Return\" to process_a \u2014 the fabricated EIP\n        : : \"r\"(pa->context.esp)\n    );\n    // Unreachable \u2014 ret jumps to process_a\n}\n```\n**The bootstrap `__asm__` block** is doing exactly what `context_switch_asm` does in its restore phase \u2014 but without a corresponding save phase. We don't need to save anything because the code that runs this is the kernel's initialization path, which has served its purpose and will never be resumed. After `ret` jumps to `process_a`, the kernel main stack is effectively abandoned (it's still mapped, but no process will use it). Process A's kernel stack becomes the current kernel stack. From this moment, preemptive multitasking is running.\n---\n## Phase 7: User-Mode Processes \u2014 Ring 3 Isolation\n\n![Per-Process Page Directory \u2014 User/Kernel Split](./diagrams/diag-m4-user-mode-page-directory.svg)\n\n\n![Ring 3 \u2192 Ring 0 \u2014 The Complete Privilege Transition](./diagrams/diag-m4-ring-transition-mechanism.svg)\n\nThe jump to user mode is the most hardware-intensive transition in your kernel. You cannot simply call a function \u2014 user mode requires specific segment register values, specific EFLAGS settings, and a precise stack layout. The only instruction that can perform this transition is `iret` \u2014 the interrupt return instruction \u2014 which atomically loads CS, EIP, SS, ESP, and EFLAGS from the stack in a way that correctly establishes ring 3.\n> **[[EXPLAIN: x86-hardware-stack-switching-privilege]] x86 hardware-enforced stack switching on privilege change:**\n> When the CPU transitions between privilege levels \u2014 either entering ring 0 from ring 3 (on interrupt/syscall) or returning to ring 3 from ring 0 (on `iret`) \u2014 it automatically switches the active stack. This is a hardware mechanism, not something your code initiates. On a ring 3 \u2192 ring 0 transition (e.g., a timer interrupt fires while user code runs): the CPU reads `SS0:ESP0` from the TSS, atomically switches ESP to the kernel stack, then pushes `SS_user`, `ESP_user`, `EFLAGS`, `CS_user`, and `EIP_user` onto the kernel stack. On a ring 0 \u2192 ring 3 transition (`iret` with a ring-3 CS on the stack): the CPU pops `EIP`, `CS`, `EFLAGS` from the kernel stack, then \u2014 seeing that CS has RPL=3 \u2014 also pops `ESP` and `SS` and switches the stack to the user stack. This is how user code gets its own stack and kernel code gets its own stack, with the hardware enforcing the boundary.\n**Per-process page directory for user mode:**\nA user-mode process must have its own page directory so its memory is isolated from other processes. However, the kernel must still be accessible when interrupts or system calls bring execution into ring 0 \u2014 otherwise the interrupt handler would immediately fault on its first instruction. The solution: copy the kernel PDEs into every process's page directory, but mark user-space pages with `PTE_USER` and kernel pages without it (supervisor-only).\n```c\n// Create a new user-mode page directory with kernel mappings inherited\nuint32_t *create_user_page_directory(void) {\n    // Allocate one page for the new page directory\n    uint32_t pd_phys = pmm_alloc_frame();\n    // Get a virtual address to initialize it\n    page_directory_t *pd = (page_directory_t *)(pd_phys + KERNEL_VIRT_BASE);\n    // Zero all entries \u2014 user space starts empty\n    __builtin_memset(pd, 0, PAGE_SIZE);\n    // Copy kernel PDE entries (indices 768-1023, covering 0xC0000000-0xFFFFFFFF)\n    // These must be identical in all page directories so the kernel is always\n    // reachable, regardless of which process is currently running.\n    extern page_directory_t boot_pd;\n    page_directory_t *kernel_pd = (page_directory_t *)(\n        VIRT_TO_PHYS((uint32_t)&boot_pd) + KERNEL_VIRT_BASE\n    );\n    for (int i = 768; i < 1024; i++) {\n        (*pd)[i] = (*kernel_pd)[i]; // Copy the PDE (including the page table pointer)\n        // Note: We copy the PDE (pointer to page table), not the page table itself.\n        // All processes share the same kernel page tables \u2014 modifications to kernel\n        // mappings are visible to all processes immediately.\n    }\n    // Return the PHYSICAL address \u2014 this is what goes into CR3\n    return (uint32_t *)pd_phys;\n}\n```\n**The `iretd` sequence to enter user mode for the first time:**\n```c\n// Enter user mode for the first time in a newly created user process.\n// Called as the LAST THING in the user process's kernel initialization,\n// from within the process's own kernel stack context (i.e., after the scheduler\n// has switched to this process at least once in kernel mode).\nvoid enter_user_mode(uint32_t user_eip, uint32_t user_esp) {\n    // Disable interrupts before building the iret frame on the kernel stack\n    __asm__ volatile (\"cli\");\n    // Build the stack frame that iret expects for a ring-3 transition:\n    // When iret sees a CS with RPL=3, it additionally pops ESP and SS.\n    // The stack must look like (top to bottom, i.e., pushed in this order):\n    //\n    //   [TOP OF KERNEL STACK - just before iret]\n    //   SS     (user data segment selector with RPL=3: 0x23)\n    //   ESP    (user stack pointer)\n    //   EFLAGS (with IF=1: interrupts enabled in user mode)\n    //   CS     (user code segment selector with RPL=3: 0x1B)\n    //   EIP    (user entry point)\n    //   [iret pops these five values]\n    //\n    // The selectors 0x1B and 0x23 are GDT indices 3 and 4 with RPL=3:\n    //   0x1B = (3 << 3) | 3 = 0b0001_1011\n    //   0x23 = (4 << 3) | 3 = 0b0010_0011\n    __asm__ volatile (\n        // Load all data segment registers with the user data selector\n        // This is required before iret, because after iret CS=0x1B,\n        // and DS/ES/FS/GS must already be valid user-mode selectors.\n        \"mov ax, 0x23\\n\"    // User data selector (ring 3)\n        \"mov ds, ax\\n\"\n        \"mov es, ax\\n\"\n        \"mov fs, ax\\n\"\n        \"mov gs, ax\\n\"\n        // Build iret frame: push in REVERSE order of what iret pops\n        \"push 0x23\\n\"       // SS (user stack segment)\n        \"push %1\\n\"         // ESP (user stack pointer)\n        \"pushfd\\n\"          // EFLAGS \u2014 current value, but we'll OR in IF\n        \"pop eax\\n\"         // Get EFLAGS into EAX\n        \"or eax, 0x200\\n\"   // Set IF (bit 9): user code starts with interrupts enabled\n        \"push eax\\n\"        // Push modified EFLAGS back\n        \"push 0x1B\\n\"       // CS (user code segment, RPL=3)\n        \"push %0\\n\"         // EIP (user entry point)\n        // The iret instruction atomically:\n        // 1. Pops EIP, CS \u2192 CPU is now \"logically\" at ring 3\n        // 2. Sees CS.RPL=3 > current CPL=0, so also pops ESP, SS\n        // 3. Switches the stack to the user stack\n        // 4. CPU is now executing user code with ring-3 privileges\n        \"iretd\\n\"\n        :\n        : \"r\"(user_eip), \"r\"(user_esp)\n        : \"eax\"\n    );\n    // Unreachable \u2014 iretd does not return\n}\n```\n**Verifying isolation \u2014 the supervisor bit test:**\nOnce a user-mode process is running, you can verify that kernel memory is protected by having the user process attempt to read a kernel virtual address. The page tables mark kernel pages without `PTE_USER` (the User/Supervisor bit, bit 2 of the PTE, is 0 for kernel pages). When user code (CPL=3) accesses such a page, the MMU checks the U/S bit: if U=0 and CPL=3, it raises page fault #14 with error code bit 2 (U bit) set to 1 (user-mode access) and bit 0 (P bit) set to 1 (page is present, but forbidden). Your page fault handler should print:\n```\n[PAGE FAULT] at 0xC0100000\n  Access: Read from user mode\n  Cause: Protection violation (page present, wrong permissions)\n  \u2192 User process attempted kernel memory access \u2014 kill process\n```\nThis test is the definitive proof that your ring 3 isolation works.\n---\n## Phase 8: The System Call Interface \u2014 INT 0x80\n\n![System Call Dispatch \u2014 INT 0x80 to Handler Table](./diagrams/diag-m4-syscall-dispatch.svg)\n\nSystem calls are the controlled, audited path through which user-mode processes request kernel services. A user process cannot call `vga_putchar` directly \u2014 that function lives in kernel address space, inaccessible from ring 3. Instead, it issues a software interrupt: `int 0x80`. The CPU treats this like any other interrupt, transitioning to ring 0, loading the kernel stack from the TSS, and calling the IDT handler at vector 128 (`0x80`).\n**Why `int 0x80`?** Historical Unix convention on x86. Linux used `int 0x80` from its first public release through kernel 2.5 (when `sysenter` was added as a faster alternative). The number `0x80` (128) was chosen to be safely away from both CPU exception vectors (0\u201331) and hardware IRQ vectors (32\u201347). For your kernel, `int 0x80` is the clearest mechanism to implement because it uses the exact same IDT machinery you built in Milestone 2.\n**IDT entry for the system call gate:**\nThe system call gate must use DPL=3 (so user code can invoke it via `int 0x80`) and should be a **trap gate** (type `0x8F`) rather than an interrupt gate \u2014 trap gates do not clear the interrupt flag, meaning the kernel remains interruptible during system call processing:\n```c\n// In idt_init(), add:\n// Vector 0x80 = 128: system call gate\n// flags = 0xEF: P=1, DPL=3 (user can invoke), type=1111 (32-bit trap gate)\nidt_set_gate(0x80, (uint32_t)isr_128, 0x08, 0xEF);\n```\n**The calling convention \u2014 registers as arguments:**\n```\nEAX = syscall number\nEBX = argument 1\nECX = argument 2\nEDX = argument 3\nESI = argument 4 (if needed)\nEDI = argument 5 (if needed)\n```\n**Syscall numbers:**\n```c\n#define SYS_EXIT    1\n#define SYS_WRITE   4\n// (following Linux's historical numbering for familiarity)\n```\n**The system call dispatcher:**\n```c\n// syscall.c\ntypedef int32_t (*syscall_handler_t)(uint32_t, uint32_t, uint32_t);\nstatic int32_t sys_exit(uint32_t exit_code, uint32_t _unused1, uint32_t _unused2) {\n    kprintf(\"[SYSCALL] Process %u exited with code %u\\n\",\n            current_process->pid, exit_code);\n    // Mark the current process as dead\n    current_process->state = PROCESS_DEAD;\n    // Remove from the ready queue\n    // Find the previous node in the circular list and bypass current\n    process_t *prev = current_process;\n    while (prev->next != current_process) prev = prev->next;\n    if (prev == current_process) {\n        // Last process \u2014 kernel should enter idle or halt\n        kprintf(\"[KERNEL] All processes exited.\\n\");\n        for (;;) __asm__ volatile (\"cli; hlt\");\n    }\n    prev->next = current_process->next;\n    if (process_list_head == current_process) {\n        process_list_head = current_process->next;\n    }\n    // Switch to the next process immediately\n    // We do this by forcing a schedule \u2014 pick next from the list\n    process_t *next = prev->next;\n    next->state = PROCESS_RUNNING;\n    // Can't call context_switch(current, next) because current is DEAD \u2014\n    // its context doesn't need saving. Use a simplified switch:\n    tss_set_kernel_stack(next->kernel_stack_top);\n    current_process = next;\n    // Load new CR3\n    __asm__ volatile (\"mov cr3, %0\" : : \"r\"(next->page_directory) : \"memory\");\n    // Jump directly into the new process's saved context\n    __asm__ volatile (\n        \"mov esp, %0\\n\"\n        \"popfd\\n\"\n        \"pop ebp\\n\"\n        \"pop edi\\n\"\n        \"pop esi\\n\"\n        \"pop ebx\\n\"\n        \"ret\\n\"\n        : : \"r\"(next->context.esp)\n    );\n    __builtin_unreachable();\n}\n// sys_write: write bytes to a file descriptor\n// For now: fd=1 (stdout) writes to VGA/serial; everything else returns -1\nstatic int32_t sys_write(uint32_t fd, uint32_t buf_virt, uint32_t count) {\n    if (fd != 1) return -1; // Only stdout supported for now\n    // Validate the user pointer: it must be in user address space\n    // A simple check: must be below 0xC0000000 (kernel base)\n    if (buf_virt >= 0xC0000000) {\n        kprintf(\"[SYSCALL] sys_write: invalid user pointer 0x%x\\n\", buf_virt);\n        return -1; // EFAULT\n    }\n    // buf_virt is a virtual address in the user's address space.\n    // Since we share the same CR3 (we're in kernel mode but user's page dir is loaded),\n    // we can access it directly \u2014 the user pages are mapped with PTE_USER, and\n    // kernel code (CPL=0) can always access user pages regardless of the U/S bit.\n    const char *buf = (const char *)buf_virt;\n    uint32_t written = 0;\n    for (uint32_t i = 0; i < count; i++) {\n        char c = buf[i];\n        vga_putchar(c);\n        serial_putchar(c);\n        written++;\n    }\n    return (int32_t)written;\n}\n// Syscall dispatch table\nstatic syscall_handler_t syscall_table[] = {\n    NULL,       // 0: unused\n    sys_exit,   // 1: exit\n    NULL,       // 2: fork (unimplemented)\n    NULL,       // 3: read (unimplemented)\n    sys_write,  // 4: write\n};\n#define SYSCALL_COUNT (sizeof(syscall_table) / sizeof(syscall_table[0]))\n// Called from interrupt_dispatch when int_no == 0x80\nvoid syscall_dispatch(struct interrupt_frame *frame) {\n    uint32_t syscall_no = frame->eax;\n    uint32_t arg1       = frame->ebx;\n    uint32_t arg2       = frame->ecx;\n    uint32_t arg3       = frame->edx;\n    if (syscall_no >= SYSCALL_COUNT || !syscall_table[syscall_no]) {\n        kprintf(\"[SYSCALL] Unknown syscall %u from PID %u\\n\",\n                syscall_no, current_process->pid);\n        frame->eax = (uint32_t)-1; // Return -ENOSYS\n        return;\n    }\n    // Call the handler \u2014 the return value goes into EAX (by the C ABI)\n    // We write it back to frame->eax so iret restores it in the user's EAX\n    int32_t result = syscall_table[syscall_no](arg1, arg2, arg3);\n    frame->eax = (uint32_t)result;\n    // iret in isr_common_stub will restore the updated frame,\n    // including the modified EAX \u2014 so the user process sees the return value.\n}\n```\n**In `interrupt_dispatch`, add the syscall case:**\n```c\nvoid interrupt_dispatch(struct interrupt_frame *frame) {\n    if (frame->int_no < 32) {\n        // CPU exceptions (existing from Milestone 2)\n        // ...\n    } else if (frame->int_no < 48) {\n        // Hardware IRQs (existing from Milestone 2)\n        irq_dispatch(frame->int_no - 32, frame);\n    } else if (frame->int_no == 0x80) {\n        // System call \u2014 no EOI needed (software interrupt, not hardware)\n        syscall_dispatch(frame);\n    }\n}\n```\n**A complete user-mode process:**\n```c\n// This code runs in ring 3. It cannot call kernel functions directly.\n// It must use system calls via int 0x80.\n// User-space \"stdlib\" shim:\nstatic void user_write(const char *str, uint32_t len) {\n    __asm__ volatile (\n        \"int 0x80\"\n        :\n        : \"a\"(4),        // EAX = SYS_WRITE\n          \"b\"(1),        // EBX = fd 1 (stdout)\n          \"c\"(str),      // ECX = buffer pointer\n          \"d\"(len)       // EDX = length\n    );\n}\nstatic void user_exit(uint32_t code) {\n    __asm__ volatile (\n        \"int 0x80\"\n        :\n        : \"a\"(1),    // EAX = SYS_EXIT\n          \"b\"(code)  // EBX = exit code\n    );\n    // If exit returns (shouldn't), spin\n    while(1);\n}\n// The actual user process entry point\nvoid user_process_entry(void) {\n    user_write(\"Hello from ring 3!\\n\", 19);\n    // Try to prove ring 3 is isolated:\n    // The next line would cause a page fault if uncommented:\n    // volatile uint32_t x = *(volatile uint32_t *)0xC0100000; // FORBIDDEN\n    user_write(\"About to exit.\\n\", 15);\n    user_exit(0);\n    // Never reached\n}\n```\n> **Hardware Soul \u2014 The cost of INT 0x80**: Every system call via `int 0x80` incurs:\n> 1. **Interrupt dispatch**: CPU reads IDT entry (likely L1 cache hit after first call).\n> 2. **Privilege transition**: CPU checks CPL vs DPL, reads TSS for ESP0 (~5 memory accesses if TLB-cold). If TLB-warm: ~2 cycles. If cold: 10-30 cycles with memory latency.\n> 3. **Stack switch**: CPU pushes SS, ESP, EFLAGS, CS, EIP onto kernel stack.\n> 4. **ISR execution**: Your `isr_common_stub` runs `pusha` (8 pushes), pushes segment registers (4 pushes), calls `interrupt_dispatch`.\n> 5. **Syscall handler**: Your C handler runs.\n> 6. **Return**: `popa`, restore segments, `iretd` \u2014 same hardware work in reverse.\n>\n> Total on a modern CPU: ~100\u2013300 ns per syscall. Linux `gettimeofday()` was called so frequently (every log line, every network packet) that Linus added the **vDSO** (virtual Dynamic Shared Object): a kernel-provided shared library mapped into user address space that implements `gettimeofday` by reading a memory-mapped counter \u2014 no privilege transition at all. `clock_gettime(CLOCK_MONOTONIC)` via vDSO takes ~15 ns vs ~250 ns via syscall \u2014 a 16\u00d7 difference. `io_uring` takes this further: batch thousands of I/O operations into a shared ring buffer (from Milestone 2 \u2014 same circular buffer!), and the kernel processes them all in one pass. One syscall's worth of overhead for thousands of I/O operations.\n---\n## Phase 9: Complete Initialization Sequence\nBringing everything together in the correct order:\n```c\nvoid kernel_main(multiboot_info_t *mbi) {\n    // Milestone 1 subsystems\n    vga_clear();\n    serial_init();\n    kprintf(\"=== Kernel Milestone 4: Processes and Scheduling ===\\n\");\n    // Milestone 2 subsystems\n    gdt_init();              // GDT: now includes TSS descriptor at entry 5\n    idt_init();              // IDT: now includes vector 0x80 for syscalls\n    pic_remap(0x20, 0x28);\n    pit_init(100);           // 100Hz timer \u2192 scheduler at 10ms intervals\n    // Milestone 3 subsystems (paging already active from boot stub)\n    mmap_parse(mbi);\n    pmm_init(mbi);\n    // (heap was already initialized; we can kmalloc now)\n    // Milestone 4: TSS, processes, scheduler\n    tss_init();              // Register TSS in GDT, load TR register\n    kprintf(\"[OK] TSS initialized (selector 0x28)\\n\");\n    // Create the kernel idle process (runs when nothing else is ready)\n    // This process MUST exist \u2014 if all other processes block, the scheduler\n    // needs something to run. The idle process just halts between ticks.\n    extern void idle_process(void);\n    extern page_directory_t boot_pd;\n    uint32_t *kpd_phys = (uint32_t *)VIRT_TO_PHYS((uint32_t)&boot_pd);\n    process_t *idle = process_create(\"idle\", idle_process, kpd_phys, 0);\n    scheduler_add_process(idle);\n    // Create the three kernel demo processes\n    process_t *pa = process_create(\"proc_a\", process_a, kpd_phys, 0);\n    process_t *pb = process_create(\"proc_b\", process_b, kpd_phys, 0);\n    process_t *pc = process_create(\"proc_c\", process_c, kpd_phys, 0);\n    scheduler_add_process(pa);\n    scheduler_add_process(pb);\n    scheduler_add_process(pc);\n    // Create a user-mode process\n    uint32_t *upd = create_user_page_directory();\n    // Map the user process code into the user page directory\n    // (In a real OS, this loads an ELF binary; here we just map a known function)\n    uint32_t user_code_phys = VIRT_TO_PHYS((uint32_t)user_process_entry);\n    uint32_t user_code_virt = 0x00400000; // Standard user code address\n    paging_map((page_directory_t *)(user_code_phys + KERNEL_VIRT_BASE),\n               user_code_virt, user_code_phys,\n               PTE_PRESENT | PTE_USER); // Readable by user, not writable\n    process_t *upr = process_create(\"user_proc\", (void *)user_code_virt, upd, 1);\n    scheduler_add_process(upr);\n    kprintf(\"[OK] Processes created. Starting scheduler...\\n\");\n    // Enable interrupts AND bootstrap the first process\n    // The timer will immediately begin firing and the scheduler will run\n    __asm__ volatile (\"sti\");\n    // Bootstrap into the idle process (or the first non-idle process)\n    // After this, kernel_main's stack is abandoned\n    current_process = pa; // Start with proc_a\n    pa->state = PROCESS_RUNNING;\n    tss_set_kernel_stack(pa->kernel_stack_top); // TSS must be correct before first interrupt\n    __asm__ volatile (\n        \"mov esp, %0\\n\"\n        \"popfd\\n\"\n        \"pop ebp\\n\"\n        \"pop edi\\n\"\n        \"pop esi\\n\"\n        \"pop ebx\\n\"\n        \"ret\\n\"\n        : : \"r\"(pa->context.esp)\n    );\n    __builtin_unreachable();\n}\nvoid idle_process(void) {\n    while (1) __asm__ volatile (\"hlt\");\n}\n```\n---\n## Debugging This Milestone\n\n![Two Kernel Stacks \u2014 The ESP Swap Moment](./diagrams/diag-m4-context-switch-stacks.svg)\n\nContext switch bugs are uniquely difficult to debug because they are stateful and timing-dependent. Here are the most common failure modes and how to diagnose each:\n**System freezes immediately after first scheduling:**\n- *Cause*: EFLAGS saved with IF=0. `popfd` in context_switch_asm restores it, leaving interrupts permanently disabled.\n- *Diagnosis*: QEMU `-d int` will show zero interrupts after the freeze. Print `frame->eflags & 0x200` before the first switch \u2014 it must be nonzero.\n- *Fix*: Ensure fabricated EFLAGS has bit 9 set: `0x00000202`.\n**System triple-faults on first timer interrupt in a user process:**\n- *Cause*: TSS `ESP0` not updated, or TSS not loaded (`ltr` not called). CPU uses wrong kernel stack.\n- *Diagnosis*: QEMU `-d int` shows fault at the exact timer tick after context switch.\n- *Fix*: Verify `tss_init()` calls `ltr`; verify `tss_set_kernel_stack` is called in `context_switch`.\n**User process causes page fault immediately on entry:**\n- *Cause*: `enter_user_mode` uses wrong CS/SS selector values, or user code page was mapped with supervisor-only permissions (missing `PTE_USER`).\n- *Diagnosis*: Page fault handler prints CR2 \u2014 if CR2 equals `user_code_virt`, the PTE_USER bit is missing. If CR2 is a garbage address, EIP was wrong.\n- *Fix*: Verify `paging_map` call for user code uses `PTE_PRESENT | PTE_USER`. Verify CS = 0x1B not 0x18.\n**`sys_write` causes page fault on user buffer access:**\n- *Cause*: User passes a kernel virtual address, or the buffer crosses a page boundary where only the first page is mapped.\n- *Diagnosis*: CR2 in the fault handler shows the address that was accessed. Compare to what the user passed in ECX.\n- *Fix*: User pointer validation \u2014 reject addresses >= 0xC0000000. For multi-page buffers, validate each page.\n**Processes corrupt each other's output or crash each other:**\n- *Cause*: Wrong page directory loaded, or kernel PDE sharing broken. Process B's writes affect process A's mapped pages.\n- *Diagnosis*: QEMU `info pg` after a context switch \u2014 verify CR3 matches the expected process's PD physical address.\n- *Fix*: Verify that `create_user_page_directory` correctly copies kernel PDEs without sharing user PTEs.\n**GDB for context switch debugging:**\n```bash\n(gdb) target remote :1234\n(gdb) set architecture i386\n(gdb) break context_switch_asm\n(gdb) commands\n> info registers\n> x/20x $esp\n> continue\n> end\n(gdb) continue\n```\nExamining the stack at the point of the ESP swap:\n```gdb\n(gdb) break *context_switch_asm+32   # Breakpoint at 'mov esp, [eax+16]'\n(gdb) p $esp                          # Before swap: old process's ESP\n(gdb) stepi                           # Execute the swap\n(gdb) p $esp                          # After swap: new process's ESP\n(gdb) x/6x $esp                       # Inspect new stack: should show EFLAGS, EBP, EDI, ESI, EBX, EIP\n```\n---\n## Three-Level View: What Happens Every 10ms\nAt 100Hz, every 10ms, a timer interrupt fires. Here is the complete hardware-to-software trace:\n**Level 3 \u2014 Hardware:**\nThe PIT's channel 0 counter reaches zero, asserts its output line. The 8259 master PIC sees IRQ0 active, checks that it's not masked, asserts the CPU's INTR pin. The CPU finishes its current user-mode instruction, detects INTR, checks that EFLAGS.IF=1, signals acknowledgment. The PIC provides vector 32. The CPU looks up IDT[32], reads the interrupt gate descriptor (handler address + selector `0x08`). CPL (from CS bits 0-1) = 3, IDT gate DPL = 0 \u2192 privilege change required. CPU reads TSS.ESP0 (\u2248 current process's kernel stack top). CPU pushes: old SS (0x23), old ESP (user stack pointer), old EFLAGS, old CS (0x1B), old EIP (interrupted user instruction) \u2014 onto the kernel stack at TSS.ESP0. CPU loads CS = 0x08, EIP = handler address, ESP = TSS.ESP0 - 20 (below the five pushed values).\n**Level 2 \u2014 Kernel:**\n`isr_32` runs: pushes 0 (no error code) and 32 (interrupt number). `isr_common_stub`: `pusha`, push segment regs, reload kernel data segments (0x10), push ESP (pointer to full saved frame), call `interrupt_dispatch`. Dispatch routes to `irq_dispatch(0, frame)` \u2192 `timer_handler(frame)` \u2192 `tick_counter++` \u2192 `scheduler_tick(frame)`. Scheduler finds next READY process (different PID). Sets old state = READY, new state = RUNNING. Calls `context_switch(old, new)`: updates CR3, updates TSS.ESP0, updates `current_process`, calls `context_switch_asm`. `context_switch_asm` pushes EBX, ESI, EDI, EBP, EFLAGS (of the timer handler, i.e., kernel state with IF=0 since we're in an interrupt gate), saves old ESP. Loads new ESP (the new process's kernel stack). Pops EFLAGS (new process's: IF=1 \u2192 interrupts re-enabled), EBP, EDI, ESI, EBX. `ret` pops new process's saved EIP \u2014 either the address after `context_switch_asm` from when new was previously preempted, or `isr_common_stub`'s return path. That path pops segment regs, `popa`, `add esp, 8`, `iretd`. `iretd` pops EIP (user code instruction pointer), CS (0x1B \u2192 ring 3), EFLAGS (user's, with IF=1), ESP (user stack), SS (0x23 \u2192 user stack).\n**Level 1 \u2014 User Process:**\nThe user process resumes at the exact instruction where it was interrupted, with all its registers restored exactly as they were. From the process's perspective, nothing happened. Time has passed (the tick counter advanced), but the process has no observable evidence of having been preempted. This is the fundamental illusion of multitasking: the hardware mechanisms you just built make each process believe it owns the CPU.\n---\n## System Awareness: The Complete Picture\n\n![OS Kernel \u2014 Satellite System Map](./diagrams/diag-satellite-os-map.svg)\n\nYou have now built an operating system. Not a complete one \u2014 there is no filesystem, no networking, no device driver framework \u2014 but all of the mechanisms that define what an OS fundamentally is:\n**What you have:** Hardware interrupt handling that preempts any process at any time. Page tables that isolate each process's address space in hardware. A scheduler that maintains the illusion of concurrent execution across multiple processes. A TSS that enables safe ring 0/ring 3 transitions. A system call interface that is the controlled bridge between user and kernel. A kernel heap that provides dynamic memory to kernel subsystems.\n**The dependency chain, complete:** You cannot have system calls without TSS (ring 3 interrupts need a kernel stack). You cannot have user-mode processes without page directories (ring 3 needs isolated address spaces). You cannot have page directories without the frame allocator (page tables need physical frames). You cannot have the frame allocator without interrupt handling (page faults need a handler). You cannot have interrupt handling without the GDT (IDT gates need valid segment selectors). Every milestone was load-bearing. Nothing was decorative.\n**What you could build next:** A filesystem (read disk sectors, parse a simple format like FAT16 or ext2). A `fork()` syscall (duplicate the current process's page directory using copy-on-write). An `exec()` syscall (load an ELF binary into the current address space). POSIX pipes (two processes sharing a circular buffer \u2014 you built this in Milestone 2). TCP/IP networking (a NIC interrupt handler feeding packets into a ring buffer). You now have the machinery to implement any of these.\n---\n## Knowledge Cascade\n**1. Green Threads, Goroutines, and Async/Await \u2014 Software Context Switching.**\nThe hardware context switch you just implemented \u2014 save registers, swap ESP, restore registers \u2014 is the exact same logical operation performed by Go's goroutine scheduler, Rust's async executor, and JavaScript's event loop. Go's `runtime.mcall()` and `runtime.goexit0()` do in software what your `context_switch_asm` does with hardware assistance. The difference: hardware context switches happen at any instruction (preemptive, timer-driven), while Go's scheduler is cooperative-with-preemption (since Go 1.14, goroutines can be preempted at function call sites via signal-based preemption \u2014 a software approximation of your hardware timer interrupt). JavaScript promises are cooperative and single-threaded: `yield`/`await` are explicit register saves to a heap-allocated coroutine frame. Understanding that `await` is just \"save my registers to the heap, give the scheduler my continuation\" \u2014 and that your PCB is the heap-allocated continuation frame \u2014 makes the entire async ecosystem legible. The Go scheduler's P/M/G model (Goroutine/Machine/Processor) is a software implementation of exactly the process/CPU-thread/scheduler structure you just built in hardware.\n**2. Spectre, Meltdown, and KPTI \u2014 When the Normal Mechanism Becomes the Vulnerability.**\nYour per-process page directories and the ring 0/3 transition via the TSS are the exact mechanisms that Meltdown exploited and KPTI (Kernel Page Table Isolation) was designed to patch. Meltdown worked because the kernel was mapped in every process's page directory (you did this \u2014 \"copy kernel PDEs into every user page directory\"). Even though user mode can't read kernel pages (supervisor bit), speculative execution would *temporarily* access them anyway, leaving cache timing side channels. KPTI's fix: maintain two page directories per process \u2014 one for user mode (minimal kernel mapping, just enough for the syscall entry point) and one for kernel mode (full mapping). On every `iret` to user mode, CR3 switches to the minimal page directory. On every interrupt/syscall, CR3 switches back to the full kernel directory. This costs a TLB flush on every ring transition \u2014 hence the 5\u201330% performance overhead KPTI introduced, which is why server workloads (many syscalls) were hit hardest. You now understand the mechanism well enough that the vulnerability and the mitigation are both obvious.\n**3. The Mars Pathfinder Bug \u2014 Priority Inversion and Real-Time Scheduling.**\nThe critical section during your context switch (interrupts disabled while swapping ESP) is the same primitive that caused the famous Mars Pathfinder mission to reset repeatedly in 1997. Pathfinder's VxWorks kernel had a shared resource (an information bus) accessed by a high-priority meteorological task, a medium-priority communications task, and a low-priority data-collection task. The low-priority task held a mutex when it was preempted by the medium-priority task, which couldn't acquire the mutex, blocking it indefinitely because the medium-priority task was *still running* and preventing the low-priority task from releasing the mutex. The high-priority meteorological task, waiting for the bus, triggered a watchdog timer. The fix was **priority inheritance**: when a low-priority task holds a resource needed by a high-priority task, temporarily elevate the low-priority task's priority until it releases the resource. Linux implements this in futexes (`FUTEX_LOCK_PI`). Your context switch's `cli`/`sti` pairing is a very short critical section \u2014 only a few instructions \u2014 specifically to avoid exactly this class of hazard. Real-time kernels (Zephyr, FreeRTOS) are engineered to keep critical sections bounded to microseconds for this reason.\n**4. Container Isolation \u2014 What Docker Actually Guarantees (and Doesn't).**\nYour user-mode processes running in ring 3 with per-process page directories give you **memory isolation**: one process cannot read or write another's memory (hardware enforced via the supervisor bit, as you demonstrated with the intentional page fault test). Docker containers add a second layer: **namespace isolation** (separate PID, network, mount, and user namespaces via Linux `clone(CLONE_NEWPID|CLONE_NEWNET|...)`), and **resource control** (cgroups limit CPU, memory, and I/O). But the underlying isolation mechanism is exactly what you built: each container process runs in ring 3, the kernel enforces address space isolation through page tables, and system calls are the audited path through which container processes request kernel services. What containers do NOT provide (unlike virtual machines): separate page tables for kernel memory (all containers share the same kernel, including kernel vulnerabilities), and hardware-enforced CPU privilege separation between container and host OS. The Meltdown vulnerability (mentioned above) affected containers because they share a kernel. VMs (with KPTI-like VM/hypervisor page tables) are substantially more isolated. Your PCB-per-process is the atomic unit that container runtimes wrap with namespace and cgroup metadata.\n**5. io_uring and the Anatomy of System Call Overhead.**\nEvery `int 0x80` in your implementation burns a ring transition: ~100\u2013300 ns of privilege switching, TLB pressure from TSS reads, and the `pusha`/`popa` overhead in `isr_common_stub`. For `sys_write` called once per log line, this is negligible. For a web server handling 100,000 requests/second, it is a bottleneck. Linux's response was `io_uring` (2019), which uses two shared ring buffers between kernel and user space \u2014 a Submission Queue and a Completion Queue, the exact circular buffer structure from your Milestone 2 keyboard driver. User code posts I/O descriptors to the SQ (no syscall, just memory writes). The kernel polls the SQ periodically (or when explicitly entered) and posts completions to the CQ. One `io_uring_enter` syscall can process thousands of I/O operations. The syscall overhead is amortized to near-zero per operation. DPDK (the Data Plane Development Kit for high-performance networking) goes further: it bypasses the kernel entirely, having user-space drivers poll NIC hardware directly \u2014 eliminating the ring transition for network I/O entirely. Both approaches are responses to the fundamental cost you just measured: a ring transition is not free, and when done millions of times per second, it matters.\n---\n<!-- END_MS -->\n",
  "current_ms_index": 4,
  "diagrams_to_generate": [],
  "diagram_attempt": 0,
  "current_diagram_code": null,
  "current_diagram_meta": null,
  "last_error": null,
  "status": "tdd_visualizing",
  "phase": "tdd",
  "tdd_blueprint": {
    "project_title": "Build Your Own OS",
    "design_vision": "A bottom-up implementation of a 32-bit x86 kernel decomposed into four load-bearing milestones. Each milestone is a prerequisite for the next: GDT enables IDT, IDT enables page-fault recovery, page-fault recovery enables process isolation, and process isolation enables preemptive scheduling. Every module is specified to the byte-offset and hardware-register level required to pass on bare metal and in QEMU with GDB attached.",
    "modules": [
      {
        "id": "build-os-m1",
        "name": "Bootloader, GDT, and Kernel Entry",
        "description": "Bootstraps the CPU from BIOS real mode through A20 enablement, BIOS disk load, GDT construction, and the CR0.PE+far-jump protected-mode transition. Provides VGA text-mode driver, serial COM1 driver, kprintf, BSS zeroing, and a cross-compiled freestanding build system producing a bootable disk image. Does NOT include IDT, paging, interrupts, or any dynamic memory.",
        "specs": {
          "inputs": "BIOS execution environment at 0x7C00 (real mode, 16-bit, 1 MB address space); kernel ELF binary on disk sectors 10+",
          "outputs": "CPU in 32-bit protected mode; kernel mapped at physical 0x100000; CR0.PE=1; GDT loaded (5 descriptors); all segment registers loaded with kernel data selector 0x10; valid kernel stack; BSS zeroed; VGA+serial output operational; kprintf supporting %c %s %d %x %p",
          "abstractions": "Stage1 MBR bootsector (512 B), Stage2 loader (4 KB), GDT descriptor table, GDTR pseudo-descriptor, segment selector, VGA cell (char+attribute byte), serial UART register map, freestanding C runtime stub, linker script sections (.text .rodata .data .bss), disk address packet (DAP) for INT 13h extended read",
          "error_categories": [
            "Triple-fault on CR0.PE set (GDT misconfigured, missing far jump, or interrupts enabled)",
            "A20 not enabled \u2014 kernel load silently wraps to low memory",
            "Disk read failure \u2014 INT 13h carry flag set, kernel never loaded",
            "BSS not zeroed \u2014 global variables contain garbage",
            "Linker address mismatch \u2014 symbol addresses don't match load address",
            "Missing boot signature 0x55AA \u2014 BIOS does not boot sector",
            "Stack pointer in unmapped or read-only region \u2014 immediate fault in first C code",
            "Direction flag DF=1 \u2014 string operations run backward, corrupting memory"
          ],
          "concurrency_model": "None \u2014 single CPU, interrupts disabled (CLI) for entire milestone; IDT not yet installed",
          "performance_targets": [
            "Stage1 binary <= 510 bytes (MBR constraint)",
            "Kernel load from disk < 32 KB in initial implementation (expandable)",
            "VGA putchar: direct MMIO write, < 10 ns per character",
            "Serial putchar: polling loop < 1 \u03bcs at 115200 baud",
            "Total boot-to-kprintf < 500 ms including QEMU BIOS POST"
          ]
        },
        "implementation_phases": [
          {
            "phase": 1,
            "name": "Stage1 MBR + disk load + A20",
            "estimated_hours": "4-6"
          },
          {
            "phase": 2,
            "name": "GDT construction and protected-mode transition",
            "estimated_hours": "4-6"
          },
          {
            "phase": 3,
            "name": "Linker script + kernel entry assembly (BSS zero, stack, cld, call)",
            "estimated_hours": "3-5"
          },
          {
            "phase": 4,
            "name": "VGA text driver + serial UART driver",
            "estimated_hours": "3-4"
          },
          {
            "phase": 5,
            "name": "kprintf implementation + build system + bootable image",
            "estimated_hours": "4-6"
          },
          {
            "phase": 6,
            "name": "QEMU + GDB integration, triple-fault debugging",
            "estimated_hours": "2-3"
          }
        ],
        "diagrams": [
          {
            "id": "tdd-diag-1",
            "title": "Physical Memory Map at Boot Time",
            "description": "Annotated physical address space from 0x00000 to 0x110000 showing: IVT at 0x0000, BDA at 0x0400, conventional RAM 0x0500-0x7BFF, MBR load point 0x7C00, stage2 at 0x7E00, EBDA at 0x9FC00, VGA framebuffer at 0xB8000, BIOS ROM at 0xF0000, and kernel at 0x100000. Each region labeled with size and access restrictions. Marks the A20 line boundary at 0x100000 and shows wrap-around overlap without A20.",
            "type": "memory_layout",
            "anchor_target": "build-os-m1"
          },
          {
            "id": "tdd-diag-2",
            "title": "Two-Stage Boot Sequence Timeline",
            "description": "Sequential steps from power-on to kernel_main call: BIOS POST \u2192 BIOS reads MBR \u2192 stage1 at 0x7C00 \u2192 cli/stack setup \u2192 A20 enable (three method waterfall: INT 15h \u2192 port 0x92 \u2192 8042 KBC) \u2192 INT 13h disk read \u2192 jmp to stage2 \u2192 GDT construction \u2192 lgdt \u2192 cli \u2192 CR0.PE=1 \u2192 far jmp 0x08:protected_entry \u2192 segment register reload \u2192 call kernel_entry \u2192 BSS zero \u2192 cld \u2192 call kernel_main. Each step shows register values and failure modes.",
            "type": "sequence",
            "anchor_target": "build-os-m1"
          },
          {
            "id": "tdd-diag-3",
            "title": "GDT Entry Byte-Level Bit Field",
            "description": "64-bit segment descriptor laid out as 8 labeled bytes at offsets 0-7. Bytes 0-1: limit[15:0]. Bytes 2-3: base[15:0]. Byte 4: base[23:16]. Byte 5 (access): P(7), DPL(6:5), S(4), E(3), DC(2), RW(1), A(0) \u2014 each bit annotated with its name and value for all five GDT entries. Byte 6 (flags+limit): G(7), DB(6), L(5), AVL(4), limit[19:16](3:0). Byte 7: base[31:24]. Shows concrete hex values for null(0x00/0x00), kernel code(0x9A/0xCF), kernel data(0x92/0xCF), user code(0xFA/0xCF), user data(0xF2/0xCF).",
            "type": "memory_layout",
            "anchor_target": "build-os-m1"
          },
          {
            "id": "tdd-diag-4",
            "title": "Segment Selector to GDT Descriptor Resolution",
            "description": "Shows a 16-bit selector value (e.g., 0x08) decomposed into index(15:3)=1, TI(2)=0, RPL(1:0)=0. Arrow to GDTR register (base, limit). Index\u00d78 offset into GDT array. Arrow to selected 8-byte descriptor. Descriptor fields decoded to base=0, limit=4GB, DPL=0. Final linear address = base(0) + logical offset. Parallel path for user selector 0x1B showing RPL=3 and DPL=3 check. Marks the CPL/DPL comparison that hardware performs on every memory access.",
            "type": "data_flow",
            "anchor_target": "build-os-m1"
          },
          {
            "id": "tdd-diag-5",
            "title": "Real Mode to Protected Mode \u2014 CPU State Machine",
            "description": "State machine with four states: REAL_MODE (16-bit, IVT active, 1MB limit), TRANSITION_UNSAFE (CR0.PE=1 but CS still real-mode \u2014 exists for one instruction), PROTECTED_MODE_PARTIAL (after far jump, CS=0x08, but DS/ES/FS/GS/SS still old), PROTECTED_MODE_FULL (all segment registers loaded, 32-bit stack set). Transitions labeled with exact instructions. ILLEGAL transition shown: enabling interrupts while in TRANSITION_UNSAFE. Shows that missing far jump leaves CPU in TRANSITION_UNSAFE indefinitely, causing GPF.",
            "type": "state_machine",
            "anchor_target": "build-os-m1"
          },
          {
            "id": "tdd-diag-6",
            "title": "Linker Script Section Layout \u2014 VMA vs LMA",
            "description": "Two parallel columns: VMA (virtual, what code sees) and LMA (physical, where binary is stored). For Milestone 1 they are identical at 0x100000. .text starts at 0x100000, 4KB-aligned. .rodata follows page-aligned. .data follows. .bss: shows __bss_start and __bss_end symbols, marks that LMA image contains no bytes for BSS (saves disk space) but VMA region must be zeroed by kernel_entry. __kernel_end symbol at top. Annotated with linker script syntax for each section. Notes where higher-half kernel (M3) will diverge VMA from LMA.",
            "type": "memory_layout",
            "anchor_target": "build-os-m1"
          },
          {
            "id": "tdd-diag-7",
            "title": "VGA Text Mode Buffer Layout",
            "description": "80\u00d725 grid mapped at physical 0xB8000. Each cell is 2 bytes: byte 0 = ASCII code, byte 1 = attribute (bits 7:4=background, 3:0=foreground). Memory layout shows cell at (row, col) = offset (row*80+col)*2. Color attribute byte decomposed with all 16 color values listed. Shows volatile uint16_t* pointer arithmetic for row/col indexing. Notes that writes must be volatile (compiler optimization hazard for MMIO). Shows scroll operation as memmove of rows 1-24 to 0-23.",
            "type": "memory_layout",
            "anchor_target": "build-os-m1"
          },
          {
            "id": "tdd-diag-8",
            "title": "Kernel Entry Stack Frame Setup",
            "description": "Step-by-step stack diagram for kernel_entry assembly stub. Before BSS zero: ESP = kernel_stack_top (uninitialized region below). After BSS zero (rep stosb from __bss_start to __bss_end). Stack after 'mov esp, kernel_stack_top': empty 16KB stack. Stack after 'xor ebp, ebp': EBP=0 marks call chain bottom. Stack after 'call kernel_main': return address pushed, EIP=kernel_main. Shows .bss section containing kernel_stack (16384 bytes) and kernel_stack_top label at high address. Labels each byte region.",
            "type": "algorithm_steps",
            "anchor_target": "build-os-m1"
          }
        ]
      },
      {
        "id": "build-os-m2",
        "name": "Interrupts, Exceptions, and Keyboard",
        "description": "Installs a 256-entry IDT with interrupt and trap gates. Remaps the 8259 PIC (master: IRQ0-7 \u2192 vectors 32-39, slave: IRQ8-15 \u2192 vectors 40-47). Implements assembly ISR stubs with unified stack frame using a fake error code for exceptions without one. Handles CPU exceptions 0-31 with diagnostic messages. Programs the PIT to 100 Hz. Implements PS/2 keyboard driver with scancode-to-ASCII conversion and a circular ring buffer. Does NOT include paging, processes, or syscalls.",
        "specs": {
          "inputs": "Protected-mode kernel from M1; GDT with kernel code/data selectors; kernel stack at known address; no IDT yet loaded",
          "outputs": "IDTR loaded with 256-entry IDT; PIC remapped (master offset 0x20, slave offset 0x28); PIT at 100 Hz with volatile tick_counter; CPU exceptions 0-31 print diagnostic (int_no, EIP, error code, CR2 for #PF); keyboard ring buffer populated on IRQ1; sti executed after full setup",
          "abstractions": "IDT gate descriptor (8 bytes), IDTR pseudo-descriptor, interrupt stack frame struct (with/without error code), ISR assembly stub macro (ISR_NOERR / ISR_ERR), 8259 PIC ICW1-ICW4 initialization sequence, EOI protocol, PIT channel 0 divisor register, PS/2 scancode set 1, circular ring buffer (head/tail/buf[])",
          "error_categories": [
            "Triple-fault on sti if PIC not remapped (IRQ0 fires at vector 8 = #DF)",
            "Register corruption if pusha/popa missing or misordered in ISR stub",
            "Infinite interrupt lockout if EOI never sent to PIC",
            "Wrong ASCII if break codes not masked (bit 7) before table lookup",
            "Stack misalignment if error-code exceptions treated as no-error-code",
            "Double-fault caused by corrupt stack pointer before exception handler runs",
            "Spurious IRQ7/IRQ15 if ISR bit not checked in PIC ISR register before EOI",
            "tick_counter stale reads if volatile qualifier omitted"
          ],
          "concurrency_model": "Single CPU; interrupt handlers run with IF=0 (interrupt gates clear IF on entry); keyboard ring buffer is single-producer (IRQ handler) single-consumer (keyboard_getchar) \u2014 safe without atomics on single core",
          "performance_targets": [
            "Interrupt dispatch latency: < 1 \u03bcs from INTR pin assertion to first C instruction",
            "Timer ISR execution: < 500 ns (increment tick_counter only in M2)",
            "Keyboard ISR: < 2 \u03bcs (port read + table lookup + ring push)",
            "PIT accuracy: 100 Hz \u00b1 0.5% (divisor = 11932)",
            "Ring buffer capacity: 256 characters without blocking (overflow silently dropped)"
          ]
        },
        "implementation_phases": [
          {
            "phase": 1,
            "name": "IDT structure + idt_set_gate + lidt",
            "estimated_hours": "2-3"
          },
          {
            "phase": 2,
            "name": "ISR assembly stubs (macro-generated, 256 entries) + isr_common_stub",
            "estimated_hours": "4-6"
          },
          {
            "phase": 3,
            "name": "interrupt_dispatch C handler + exception messages + page fault CR2 read",
            "estimated_hours": "3-4"
          },
          {
            "phase": 4,
            "name": "PIC remapping (ICW1-ICW4) + EOI protocol + spurious IRQ handling",
            "estimated_hours": "3-4"
          },
          {
            "phase": 5,
            "name": "PIT initialization (100 Hz) + timer handler + tick_counter",
            "estimated_hours": "2-3"
          },
          {
            "phase": 6,
            "name": "PS/2 keyboard driver + scancode tables + circular ring buffer + keyboard_getchar",
            "estimated_hours": "3-4"
          }
        ],
        "diagrams": [
          {
            "id": "tdd-diag-9",
            "title": "IDT Gate Descriptor Byte-Level Layout",
            "description": "8-byte IDT entry laid out at byte offsets 0-7. Bytes 0-1: handler offset[15:0]. Bytes 2-3: segment selector (0x08 = kernel code). Byte 4: reserved = 0. Byte 5 (flags): P(7), DPL(6:5), 0(4), type(3:0). Shows type values: 1110=32-bit interrupt gate (0x8E), 1111=32-bit trap gate (0x8F). Byte 6-7: handler offset[31:16]. Concrete hex values for a kernel exception gate (0x8E, DPL=0) vs syscall trap gate (0xEF, DPL=3). Shows idt_set_gate() field assignments with bit masks.",
            "type": "memory_layout",
            "anchor_target": "build-os-m2"
          },
          {
            "id": "tdd-diag-10",
            "title": "Interrupt Stack Frame \u2014 With vs Without Error Code",
            "description": "Two side-by-side stack diagrams after CPU interrupt delivery and pusha. Left (no error code, e.g., IRQ0): [ESP+48]=EFLAGS, [ESP+44]=CS, [ESP+40]=EIP, [ESP+36..0]=pusha regs + int_no + fake_err_code(0). Right (with error code, e.g., #GP=13): same layout but err_code is CPU-pushed value, not zero. Middle panel shows the interrupt_frame struct with byte offsets for each field matching the stack layout. Red annotation on the 'add esp, 8' instruction in isr_common_stub that cleans int_no and err_code before iret.",
            "type": "memory_layout",
            "anchor_target": "build-os-m2"
          },
          {
            "id": "tdd-diag-11",
            "title": "8259 PIC Cascade Architecture and Vector Remapping",
            "description": "Hardware block diagram: Master PIC (ports 0x20/0x21) receiving IRQ0-IRQ7. Slave PIC (ports 0xA0/0xA1) receiving IRQ8-IRQ15, connected to Master via IRQ2 cascade. Before remapping: IRQ0\u2192vector8(#DF), IRQ1\u2192vector9(#NP), ... IRQ7\u2192vector15. After remapping: IRQ0\u2192vector32, IRQ1\u2192vector33, ..., IRQ7\u2192vector39, IRQ8\u2192vector40, ..., IRQ15\u2192vector47. ICW1-ICW4 byte sequence with port addresses and timing (io_wait between writes). EOI rules: master-only for IRQ0-7, both slave+master for IRQ8-15.",
            "type": "architecture",
            "anchor_target": "build-os-m2"
          },
          {
            "id": "tdd-diag-12",
            "title": "ISR Stub Assembly \u2014 Stack State Before/After Each Instruction",
            "description": "Step-by-step stack diagram tracing isr_common_stub execution. Initial state: CPU pushed SS/ESP/EFLAGS/CS/EIP (privilege change case) or EFLAGS/CS/EIP (same privilege). ISR_NOERR stub pushed fake_err=0 and int_no. After pusha: 8 GP registers on stack. After push ds/es/fs/gs: 4 segment registers. After 'push esp': frame pointer argument. Highlights the critical 'mov ax, 0x10; mov ds,ax' reload \u2014 without this, kernel data access uses user-mode segment and faults. iret unwinding shown in reverse.",
            "type": "algorithm_steps",
            "anchor_target": "build-os-m2"
          },
          {
            "id": "tdd-diag-13",
            "title": "Exception Cascade: Fault \u2192 Double Fault \u2192 Triple Fault",
            "description": "State machine with four states: NORMAL_EXECUTION, HANDLING_EXCEPTION (first fault, IDT[n] invoked), DOUBLE_FAULT (second fault during handler \u2014 IDT[8] invoked, always error_code=0), TRIPLE_FAULT (fault during #DF handler \u2014 CPU resets, no recovery). Transitions labeled with triggering conditions. ILLEGAL path: raising an exception while HANDLING_EXCEPTION with a corrupt stack bypasses DOUBLE_FAULT and goes directly to TRIPLE_FAULT. Shows that #DF handler needs a dedicated stack (Task Gate) for robustness against stack corruption faults.",
            "type": "state_machine",
            "anchor_target": "build-os-m2"
          },
          {
            "id": "tdd-diag-14",
            "title": "PS/2 Keyboard Scancode-to-ASCII Pipeline",
            "description": "Data flow from physical key press to ring buffer entry. Stage 1: Key closes circuit \u2192 PS/2 serial protocol at 10 kHz \u2192 8042 KBC buffers byte. Stage 2: 8042 asserts IRQ1 \u2192 PIC delivers vector 33 \u2192 keyboard_handler called. Stage 3: inb(0x60) reads scancode byte. Stage 4: bit 7 check \u2014 if set, break code: update shift/ctrl/alt state, return. Stage 5: make code \u2192 check modifier state \u2192 index into scancode_to_ascii or scancode_to_ascii_shift table. Stage 6: non-zero result \u2192 ring_push(). Stage 7: keyboard_getchar() \u2014 ring_empty spin \u2192 ring_pop(). Shows circular buffer head/tail movement.",
            "type": "data_flow",
            "anchor_target": "build-os-m2"
          },
          {
            "id": "tdd-diag-15",
            "title": "Circular Ring Buffer Memory Layout and Head/Tail Invariants",
            "description": "256-byte circular array with head (write index) and tail (read index) as uint8_t (natural modulo 256 arithmetic). Four annotated states: EMPTY (head==tail), PARTIAL (tail < head, normal case), WRAPPED (head < tail, wrap case), FULL ((head+1)%SIZE==tail \u2014 one slot always wasted). Shows ring_push advancing head; ring_pop advancing tail. Diagrams the race-condition-free property on single-core: IRQ handler (producer) can only interrupt consumer code between ring_empty check and ring_pop, but tail is only modified by consumer \u2014 invariants preserved. Notes failure mode if SIZE is not power of 2.",
            "type": "memory_layout",
            "anchor_target": "build-os-m2"
          }
        ]
      },
      {
        "id": "build-os-m3",
        "name": "Physical and Virtual Memory Management",
        "description": "Parses the E820/Multiboot memory map to classify physical regions. Implements a bitmap-based physical frame allocator with double-free detection. Constructs two-level x86 page tables (PD + PT) implementing an identity map of the first 4 MB and a higher-half kernel mapping at 0xC0000000. Enables paging via CR3 load and CR0.PG, removes the identity map post-jump, and implements TLB management (invlpg + CR3 reload). Provides kmalloc/kfree kernel heap backed by the frame allocator. Does NOT include process isolation or user-mode page directories.",
        "specs": {
          "inputs": "Protected-mode kernel with interrupts working (M2); multiboot_info_t pointer in EBX; paging disabled; physical address == virtual address",
          "outputs": "CR0.PG=1; CR3 loaded with boot_pd physical address; kernel mapped at 0xC0100000 (VMA) = 0x100000 (LMA); identity map of first 4 MB removed post-jump; bitmap PMM with alloc/free/double-free-panic; kmalloc/kfree with free-list coalescing and HEAP_MAGIC corruption detection; page fault handler decoding CR2, present/write/user error code bits",
          "abstractions": "multiboot_mmap_entry_t, phys_region_t, frame_bitmap (uint32_t[]), page_directory_t (uint32_t[1024] __aligned(4096)), page_table_t (uint32_t[1024] __aligned(4096)), PTE/PDE bit flags (PRESENT/WRITABLE/USER/CACHE_DIS), heap_block_t (size/magic/used/next/prev), HEAP_MAGIC sentinel",
          "error_categories": [
            "Triple-fault on CR0.PG=1 if identity map missing (next fetch uses virtual addr with no mapping)",
            "Triple-fault on higher-half jump if PDE[768] not installed before enabling paging",
            "TLB stale translation after PTE modification without invlpg (non-deterministic corruption)",
            "PMM double-free: kernel bug \u2014 halt with diagnostic",
            "PMM allocating kernel-occupied frames (not excluded during init)",
            "Heap HEAP_MAGIC corruption: buffer overrun or use-after-free \u2014 halt with diagnostic",
            "NULL dereference after identity map removal produces #PF at CR2=0 (desired \u2014 catchable)",
            "Page directory not 4KB-aligned: CR3 low bits interpreted as flags, translations garbage"
          ],
          "concurrency_model": "Single CPU, single address space during init; interrupts enabled (sti) after paging + heap init; page fault handler can allocate frames (reentrant PMM forbidden \u2014 no nested allocations during fault handling)",
          "performance_targets": [
            "pmm_alloc_frame: O(n/32) scan with 32-bit word skip; < 1 \u03bcs for < 4 GB RAM",
            "paging_map: O(1) with existing PT, O(1) PMM alloc + page zero if new PT needed; < 2 \u03bcs",
            "kmalloc first-fit scan: O(live_allocs); < 5 \u03bcs for < 1000 live allocations",
            "TLB invlpg: single instruction, < 10 ns; full CR3 reload flushes ~1500 entries, < 50 ns",
            "Page fault handler dispatch: < 500 ns to C handler (same as generic interrupt)"
          ]
        },
        "implementation_phases": [
          {
            "phase": 1,
            "name": "E820/Multiboot memory map parser + phys_regions[] classification",
            "estimated_hours": "3-5"
          },
          {
            "phase": 2,
            "name": "Bitmap PMM: init (reserve-all then free usable), alloc, free, double-free detection",
            "estimated_hours": "4-6"
          },
          {
            "phase": 3,
            "name": "Linker script update (VMA=0xC0100000, LMA=0x100000) + VIRT_TO_PHYS macro",
            "estimated_hours": "2-3"
          },
          {
            "phase": 4,
            "name": "Static boot_pd/pt_low/pt_high setup + CR3 load + CR0.PG enable + higher-half jump",
            "estimated_hours": "6-10"
          },
          {
            "phase": 5,
            "name": "Identity map removal + TLB flush + invlpg/CR3 reload utilities",
            "estimated_hours": "2-3"
          },
          {
            "phase": 6,
            "name": "Dynamic paging_map/paging_unmap with PT allocation from PMM",
            "estimated_hours": "3-5"
          },
          {
            "phase": 7,
            "name": "Page fault handler: CR2 read + error code decode + kernel vs user path",
            "estimated_hours": "2-3"
          },
          {
            "phase": 8,
            "name": "kmalloc/kfree: heap_block_t free-list, split, coalesce, HEAP_MAGIC check",
            "estimated_hours": "4-6"
          },
          {
            "phase": 9,
            "name": "Integration test: alloc/free/write/realloc sequence + QEMU info pg validation",
            "estimated_hours": "2-3"
          }
        ],
        "diagrams": [
          {
            "id": "tdd-diag-16",
            "title": "Bitmap Physical Frame Allocator \u2014 Memory Layout and Word-Skip Algorithm",
            "description": "frame_bitmap[] array at a known BSS address. Each bit represents one 4 KB frame: bit=0 free, bit=1 used. Shows total_frames=32768 for 128 MB RAM, bitmap size=4096 bytes=1 page. alloc algorithm: outer loop over uint32_t words \u2014 if word==0xFFFFFFFF skip (all used); else inner loop finds first zero bit using __builtin_ctz(~word); returns frame_index * PAGE_SIZE. free algorithm: compute frame=addr/4096; check frame_test() for double-free; frame_clear(). Shows init sequence: memset(0xFF) then frame_clear() for usable E820 regions then re-frame_set() for kernel frames [kstart..kend] and frame 0.",
            "type": "algorithm_steps",
            "anchor_target": "build-os-m3"
          },
          {
            "id": "tdd-diag-17",
            "title": "x86 Two-Level Page Table Walk \u2014 Virtual Address Decomposition",
            "description": "32-bit virtual address split: bits 31-22 (10-bit PD index), bits 21-12 (10-bit PT index), bits 11-0 (12-bit page offset). Step 1: CR3 \u2192 physical address of Page Directory (4KB-aligned, 1024 entries \u00d7 4 bytes). Step 2: PD[pd_index] \u2192 PDE with physical address of Page Table (bits 31-12) + flags (bits 11-0). Step 3: PT[pt_index] \u2192 PTE with physical frame address (bits 31-12) + flags. Step 4: physical_addr = PTE.frame | virtual.offset. TLB cache shown as a bypass path that short-circuits steps 1-3 on hit. TLB miss path shown walking all three steps.",
            "type": "data_flow",
            "anchor_target": "build-os-m3"
          },
          {
            "id": "tdd-diag-18",
            "title": "PDE and PTE Bit-Field Layout",
            "description": "Two 32-bit registers shown with all bit fields labeled. PDE (bits 31-12=page_table_phys_addr, 11-9=avail, 8=global, 7=page_size(0=4KB), 6=reserved, 5=accessed, 4=cache_disable, 3=write_through, 2=user/supervisor, 1=writable, 0=present). PTE (bits 31-12=frame_phys_addr, 11-9=avail, 8=global, 7=reserved, 6=dirty, 5=accessed, 4=cache_disable, 3=write_through, 2=user/supervisor, 1=writable, 0=present). Concrete values shown for: kernel identity-map PTE (0x00003 = present+writable, no user), user page PTE (0x00007 = present+writable+user), MMIO page PTE (0x01B = present+writable+cache_disable+write_through).",
            "type": "memory_layout",
            "anchor_target": "build-os-m3"
          },
          {
            "id": "tdd-diag-19",
            "title": "Virtual Address Space Layout \u2014 Identity + Higher-Half Mapping",
            "description": "Full 32-bit virtual address space (0x00000000 to 0xFFFFFFFF) divided into labeled regions: 0x00000000-0x003FFFFF (identity map, 4 MB \u2014 VGA, BIOS, stack); 0x00400000-0xBFFFFFFF (future user space, 3 GB); 0xC0000000-0xC03FFFFF (higher-half kernel, 4 MB \u2014 kernel code/data); 0xC0400000-0xCFFFFFFF (kernel heap, 252 MB); 0xD0000000-0xFFBFFFFF (reserved); 0xFFC00000-0xFFFFFFFF (recursive PD mapping, optional). Arrow showing physical 0x00000000-0x003FFFFF maps to both VA 0x00000000 (identity) and VA 0xC0000000 (kernel). Red cross over identity map after removal.",
            "type": "memory_layout",
            "anchor_target": "build-os-m3"
          },
          {
            "id": "tdd-diag-20",
            "title": "Paging Enable Moment \u2014 Instruction-Level Transition",
            "description": "Five sequential CPU states with register values and address space interpretation. State 1: paging off, EIP=0x001xxxxx (physical=virtual). State 2: CR3 loaded with boot_pd_phys; paging still off \u2014 CR3 write is safe. State 3: CR0.PG=1 set \u2014 paging NOW active; EIP still at physical 0x001xxxxx but now interpreted as virtual 0x001xxxxx (identity-mapped by boot_pd[0] \u2014 execution continues). State 4: 'lea eax, [kernel_main_high]' loads 0xC01xxxxx. State 5: 'jmp eax' \u2014 EIP=0xC01xxxxx, fetched via PDE[768]\u2192pt_high. State 6: 'mov [boot_pd+0], 0' + CR3 reload \u2014 identity map gone; NULL deref now causes #PF. Red vertical line at the CR0.PG instruction marks the paging-active boundary.",
            "type": "algorithm_steps",
            "anchor_target": "build-os-m3"
          },
          {
            "id": "tdd-diag-21",
            "title": "TLB Flush Decision Tree \u2014 invlpg vs Full CR3 Reload",
            "description": "Decision tree starting at 'Page table entry modified'. Branch: single page changed? \u2192 Yes \u2192 use invlpg(virt_addr) \u2014 evicts one entry, O(1), ~10 ns. Branch: multiple pages in same PT changed? \u2192 loop invlpg per page. Branch: switching address spaces (new CR3)? \u2192 full CR3 reload \u2014 flushes all non-global entries. Branch: kernel mapping changed (shared across all PDs)? \u2192 full CR3 reload in current process + IPI to other CPUs (SMP, future). Shows which scenarios require action and which are safe to skip (mapping a previously-unmapped page: no stale entry exists, no flush needed). Annotated with cost in cycles for each path.",
            "type": "algorithm_steps",
            "anchor_target": "build-os-m3"
          },
          {
            "id": "tdd-diag-22",
            "title": "Page Fault Error Code \u2014 CR2 and Error Code Bit Decode",
            "description": "interrupt_frame shown with err_code field. Error code bit decomposition: bit 0 (P): 0=page not present, 1=protection violation. Bit 1 (W): 0=read access, 1=write access. Bit 2 (U): 0=kernel mode, 1=user mode. Bit 3 (RSVD): reserved bit set in PTE. Bit 4 (I/D): instruction fetch. CR2 register = faulting virtual address (must be read inside handler before any other memory op that might overwrite it). Truth table showing 8 common combinations with diagnosis: (0,0,0)=kernel null deref, (0,0,1)=user null deref/demand page, (1,1,1)=user write to read-only=COW trigger, (1,0,0)=kernel protection violation=kernel bug.",
            "type": "data_flow",
            "anchor_target": "build-os-m3"
          },
          {
            "id": "tdd-diag-23",
            "title": "Kernel Heap Block Layout and Free-List Coalescing",
            "description": "Linear virtual address range 0xC0400000-0xCFFF0000 shown as a sequence of heap_block_t headers interleaved with data regions. heap_block_t struct at byte offsets: 0=size(4B), 4=magic(4B, 0xDEADBEEF), 8=used(1B), 9-11=padding, 12=next*(4B), 16=prev*(4B). Total header=20 bytes. Three scenarios shown as before/after diagrams: (1) Split: large free block \u2192 allocated block + smaller free block. (2) Coalesce-forward: free block adjacent to next free block \u2192 merged block. (3) Coalesce-backward: freed block with previous free block \u2192 merged. Shows heap_brk advance when no free block satisfies request: pmm_alloc_frame() + paging_map() called to commit new page, heap_extend() creates new free block.",
            "type": "memory_layout",
            "anchor_target": "build-os-m3"
          }
        ]
      },
      {
        "id": "build-os-m4",
        "name": "Processes and Preemptive Scheduling",
        "description": "Implements process control blocks with full CPU context capture, an assembly context switch routine that performs register save/restore and ESP swap, TSS setup with per-switch ESP0 update, a circular round-robin scheduler triggered by the PIT IRQ0, per-process page directories (user-space isolation with shared kernel PDEs), the iretd-based ring-3 entry sequence, and INT 0x80 system calls (sys_write, sys_exit). Does NOT include fork, exec, filesystem, signals, or blocking I/O primitives beyond the keyboard spin-wait.",
        "specs": {
          "inputs": "Fully operational M1+M2+M3 kernel: GDT with 5 entries, IDT, PIC, PIT at 100 Hz, PMM, paging enabled at 0xC0100000, kmalloc/kfree; multiboot_info_t pointer",
          "outputs": "TSS registered in GDT (selector 0x28), TR loaded; at least 3 concurrent kernel processes demonstrated visually; at least 1 user-mode process in ring 3 with isolated page directory; INT 0x80 syscall gate (DPL=3, trap gate); sys_write(fd=1,buf,len) outputs to VGA+serial; sys_exit(code) removes process and schedules next; accessing kernel VA from ring 3 triggers #PF with U=1 error code",
          "abstractions": "process_t PCB, cpu_context_t (edi/esi/ebx/ebp/esp/eip/eflags), tss_t (SS0/ESP0 fields), page_directory_t per process, kernel_stack (8 KB per process from kmalloc), fabricated initial stack frame, circular process list (process_t->next), interrupt_frame struct reuse from M2, syscall dispatch table (syscall_handler_t[])",
          "error_categories": [
            "Scheduler freeze: EFLAGS.IF=0 in fabricated initial context \u2014 timer never fires again",
            "TSS ESP0 not updated on switch: CPU pushes interrupt frame onto wrong kernel stack \u2014 silent corruption",
            "Missing CR3 update on switch: processes access each other's memory",
            "Context switch saves/restores wrong register count: misaligned stack on resume",
            "User-mode iretd with wrong CS selector (0x18 not 0x1B): #GP on iretd \u2014 privilege mismatch",
            "User buffer pointer validation absent in sys_write: kernel reads arbitrary memory",
            "process_t not on kernel heap \u2014 PCB in BSS with kmalloc not called: structure alignment issues",
            "Scheduler called with interrupts already disabled: nested CLI causes permanent lockout",
            "process_t->next circular list broken after sys_exit: dangling pointer crash on next schedule"
          ],
          "concurrency_model": "Single CPU preemptive; scheduler runs in IRQ0 handler (interrupts disabled via interrupt gate); context_switch_asm executes atomically from perspective of interrupted code; TSS.ESP0 update must complete before iretd restores user mode; no SMP, no spinlocks required \u2014 all critical sections protected by CLI from interrupt gate entry",
          "performance_targets": [
            "Context switch latency (kernel-to-kernel): < 500 ns (5 pushes + 5 pops + CR3 write + TSS write)",
            "Context switch with address space change (user-to-user): < 2 \u03bcs (includes CR3 reload = full TLB flush)",
            "sys_write throughput: limited by VGA/serial; < 5 \u03bcs per call for short strings",
            "Scheduler tick overhead at 100 Hz: < 100 \u03bcs CPU time consumed per second (0.01% overhead)",
            "Process creation (process_create): < 10 \u03bcs (kmalloc \u00d7 2 + paging_map for user stack)"
          ]
        },
        "implementation_phases": [
          {
            "phase": 1,
            "name": "TSS structure + gdt_set_tss_entry + ltr instruction + tss_set_kernel_stack",
            "estimated_hours": "3-5"
          },
          {
            "phase": 2,
            "name": "process_t PCB + cpu_context_t layout + KERNEL_STACK_SIZE + process_create with fabricated stack frame",
            "estimated_hours": "4-7"
          },
          {
            "phase": 3,
            "name": "context_switch_asm (NASM) + context_switch C wrapper (CR3 + TSS + current_process update)",
            "estimated_hours": "6-10"
          },
          {
            "phase": 4,
            "name": "Round-robin scheduler + scheduler_add_process + scheduler_tick in timer_handler",
            "estimated_hours": "3-5"
          },
          {
            "phase": 5,
            "name": "Bootstrap sequence (first process entry from kernel_main) + three-process VGA demo",
            "estimated_hours": "3-5"
          },
          {
            "phase": 6,
            "name": "create_user_page_directory (copy kernel PDEs) + user stack allocation + paging_map with PTE_USER",
            "estimated_hours": "4-6"
          },
          {
            "phase": 7,
            "name": "enter_user_mode via iretd (build stack frame: SS/ESP/EFLAGS/CS/EIP, reload DS/ES/FS/GS=0x23)",
            "estimated_hours": "4-6"
          },
          {
            "phase": 8,
            "name": "INT 0x80 syscall gate (IDT[0x80], DPL=3, trap gate 0xEF) + syscall_dispatch + sys_write + sys_exit",
            "estimated_hours": "5-8"
          },
          {
            "phase": 9,
            "name": "Ring-3 isolation test (deliberate kernel memory access from user \u2192 verify #PF U=1) + debugging",
            "estimated_hours": "3-5"
          }
        ],
        "diagrams": [
          {
            "id": "tdd-diag-24",
            "title": "Process Control Block (process_t) \u2014 Byte-Level Field Map",
            "description": "process_t struct with byte offset for every field. Offset 0: pid (4B). Offset 4: name[32] (32B). Offset 36: state (4B enum). Offset 40: cpu_context_t context (28B): sub-offsets edi=0, esi=4, ebx=8, ebp=12, esp=16, eip=20, eflags=24. Offset 68: page_directory* (4B, physical address). Offset 72: kernel_stack* (4B). Offset 76: kernel_stack_top (4B \u2014 ESP0 value for TSS). Offset 80: user_esp (4B). Offset 84: ticks_remaining (4B). Offset 88: total_ticks (4B). Offset 92: next* (4B). Total struct size annotated. Notes which fields are valid in each process state (READY/RUNNING/BLOCKED/DEAD).",
            "type": "memory_layout",
            "anchor_target": "build-os-m4"
          },
          {
            "id": "tdd-diag-25",
            "title": "Task State Segment (tss_t) \u2014 Critical Fields and GDT Descriptor",
            "description": "tss_t struct with all 26 fields and byte offsets 0-103. Highlights ESP0 (offset 4) and SS0 (offset 8) in red as the only operationally significant fields. All other fields shown as 0/unused. GDT entry 5 shown as a system descriptor (S=0, type=0x9=32-bit TSS available) with base=&kernel_tss and limit=sizeof(tss_t)-1. Contrast with code/data descriptors (S=1). Shows ltr instruction loading selector 0x28 into the TR (Task Register). Sequence diagram: timer interrupt fires while ring-3 process runs \u2192 CPU reads tss.esp0 \u2192 switches stack \u2192 pushes SS/ESP/EFLAGS/CS/EIP at that address.",
            "type": "memory_layout",
            "anchor_target": "build-os-m4"
          },
          {
            "id": "tdd-diag-26",
            "title": "context_switch_asm \u2014 Stack State Trace at Each Instruction",
            "description": "Two parallel stack columns (OLD process stack on left, NEW process stack on right). Traces every push/pop/mov in context_switch_asm with ESP values. Left column: initial ESP (kernel stack in timer ISR context). After push ebx: ESP-4. After push esi: ESP-8. After push edi: ESP-12. After push ebp: ESP-16. After pushfd: ESP-20 = saved EFLAGS. 'mov [old_ctx+16], esp': stores this ESP into cpu_context_t.esp. 'mov esp, [new_ctx+16]': ESP jumps to new process's stack (right column). Right column now active: shows NEW's stack with its previously saved EFLAGS/EBP/EDI/ESI/EBX/EIP. popfd: restores new EFLAGS (including IF=1). pop ebp/edi/esi/ebx. ret: pops new EIP. Red vertical line at the ESP swap instruction marks identity change.",
            "type": "algorithm_steps",
            "anchor_target": "build-os-m4"
          },
          {
            "id": "tdd-diag-27",
            "title": "Fabricated Initial Kernel Stack Frame for First Process Schedule",
            "description": "process_create() builds a fake 'return from context_switch_asm' frame on the new process's kernel_stack buffer (8 KB, from kmalloc). Shows kernel_stack + KERNEL_STACK_SIZE = kernel_stack_top. Stack built downward from kernel_stack_top: [top-4]=0x00000202 (EFLAGS: IF=1, reserved bit 1 set); [top-8]=0 (EBP); [top-12]=0 (EDI); [top-16]=0 (ESI); [top-20]=0 (EBX); [top-24]=entry_point (EIP \u2014 the process function). context.esp = kernel_stack_top - 24. When context_switch_asm restores this process: popfd loads 0x202 (enables interrupts), pops zero regs, ret jumps to entry_point. Comparison: real saved frame vs fabricated frame \u2014 structurally identical.",
            "type": "algorithm_steps",
            "anchor_target": "build-os-m4"
          },
          {
            "id": "tdd-diag-28",
            "title": "Process State Machine \u2014 All States and Legal Transitions",
            "description": "State machine with four nodes: READY (in run queue, waiting for CPU), RUNNING (executing on CPU), BLOCKED (waiting for event \u2014 keyboard, sleep), DEAD (exited, slot recyclable). Legal transitions with labels: READY\u2192RUNNING (scheduler_tick selects this process), RUNNING\u2192READY (timer preempts \u2014 scheduler_tick context switch), RUNNING\u2192BLOCKED (process calls blocking operation, e.g., keyboard_getchar spin), BLOCKED\u2192READY (event arrives \u2014 keyboard char available), RUNNING\u2192DEAD (sys_exit called). ILLEGAL transitions shown with red X: BLOCKED\u2192RUNNING (must pass through READY), DEAD\u2192any (no resurrection). Notes that only one process can be in RUNNING state at any time on single-core.",
            "type": "state_machine",
            "anchor_target": "build-os-m4"
          },
          {
            "id": "tdd-diag-29",
            "title": "Round-Robin Scheduler \u2014 Circular List and Timer-Driven Preemption",
            "description": "Circular linked list of process_t nodes (process_a\u2192process_b\u2192process_c\u2192idle\u2192process_a). current_process pointer shown advancing on each tick. Timer IRQ0 fires \u2192 scheduler_tick() \u2192 advance current_process->next (skip BLOCKED/DEAD) \u2192 context_switch(old, next). Shows tick_counter and total_ticks per process increasing. Sequence diagram for a preemption event: (1) process_a running, (2) timer fires, (3) ISR saves process_a's kernel regs, (4) scheduler selects process_b, (5) TSS.ESP0 = process_b.kernel_stack_top, (6) CR3 = process_b.page_directory, (7) context_switch_asm swaps ESP, (8) isr_common_stub iretd restores process_b's user regs, (9) process_b runs.",
            "type": "sequence",
            "anchor_target": "build-os-m4"
          },
          {
            "id": "tdd-diag-30",
            "title": "Per-Process Page Directory \u2014 Kernel Shared / User Isolated",
            "description": "Two page directory arrays side by side (kernel_pd and user_proc_pd). Each has 1024 entries. PDE indices 0-767 (virtual 0x00000000-0xBFFFFFFF): kernel_pd has only kernel mapping; user_proc_pd has user-specific mappings (PTE_USER set). PDE indices 768-1023 (virtual 0xC0000000-0xFFFFFFFF): both PDs contain IDENTICAL entries pointing to the same physical page tables (shared kernel pages, PTE_USER NOT set). Shows that modifying a kernel page table entry is immediately visible to all processes because they share the same physical PT. User pages: different physical frames, different virtual addresses, PTE_USER=1 allows ring-3 access. Kernel pages: PTE_USER=0, ring-3 access \u2192 #PF with U=1.",
            "type": "architecture",
            "anchor_target": "build-os-m4"
          },
          {
            "id": "tdd-diag-31",
            "title": "Ring 3 Entry via iretd \u2014 Stack Layout and CPU State Transitions",
            "description": "enter_user_mode() function execution trace. Before iretd, kernel stack contains (from top/low address): [ESP+0]=user_EIP, [ESP+4]=user_CS(0x1B), [ESP+8]=user_EFLAGS(IF=1), [ESP+12]=user_ESP, [ESP+16]=user_SS(0x23). Segment registers DS/ES/FS/GS loaded with 0x23 (user data) before iretd. iretd execution: CPU pops EIP=user_EIP, CS=0x1B (CPL becomes 3), EFLAGS (IF=1), ESP=user_ESP, SS=0x23. CPU state after: ring-3, user stack active, all data segs=0x23, kernel stack abandoned. Selector values decoded: 0x1B=(3<<3)|3=index3,RPL3,TI0; 0x23=(4<<3)|3=index4,RPL3,TI0. Shows the ILLEGAL alternatives that cause #GP.",
            "type": "algorithm_steps",
            "anchor_target": "build-os-m4"
          },
          {
            "id": "tdd-diag-32",
            "title": "INT 0x80 Syscall \u2014 Full Round-Trip from User to Kernel and Back",
            "description": "Sequence diagram spanning user_process \u2192 CPU \u2192 isr_128 \u2192 interrupt_dispatch \u2192 syscall_dispatch \u2192 sys_write \u2192 VGA/serial \u2192 return. User code: 'mov eax,4; mov ebx,1; mov ecx,buf; mov edx,len; int 0x80'. CPU: reads IDT[128] (DPL=3 trap gate, so user can invoke; IF not cleared because trap gate). Pushes EFLAGS/CS/EIP onto kernel stack (privilege change: also pushes user SS+ESP). Loads kernel CS=0x08, EIP=isr_128. isr_128: push 0 (fake err), push 128, jmp isr_common_stub. isr_common_stub: pusha, push segs, reload DS=0x10, push ESP, call interrupt_dispatch. interrupt_dispatch: int_no==0x80 \u2192 syscall_dispatch(frame). syscall_dispatch: EAX=4=sys_write, call sys_write(EBX,ECX,EDX). sys_write: validate ECX<0xC0000000, write chars. Return: frame->eax = written_count. isr_common_stub: pop segs, popa, add esp 8, iretd. User code: EAX = return value.",
            "type": "sequence",
            "anchor_target": "build-os-m4"
          },
          {
            "id": "tdd-diag-33",
            "title": "Interrupt Enable/Disable Windows During Context Switch",
            "description": "Timeline showing IF (interrupt flag) value across the context switch critical path. Zone 1: Timer ISR entry \u2014 IF=0 (interrupt gate cleared it). Zone 2: scheduler_tick() \u2014 IF=0 (safe to call context_switch). Zone 3: context_switch C wrapper \u2014 IF=0; CR3 written; TSS.ESP0 written; current_process updated. Zone 4: context_switch_asm \u2014 IF=0 throughout register save and ESP swap. Zone 5: popfd in restore phase \u2014 IF restored from new process's EFLAGS (0x202, IF=1). Zone 6: ret to new process's ISR path \u2014 IF=1 from this point. Zone 7: iretd to user mode \u2014 IF=1. Annotates the window (zones 3-4) where CR3, TSS, and ESP changes must be atomic with respect to interrupts \u2014 violation causes TSS.ESP0 pointing to wrong stack on next interrupt.",
            "type": "algorithm_steps",
            "anchor_target": "build-os-m4"
          },
          {
            "id": "tdd-diag-34",
            "title": "TSS ESP0 Update Requirement \u2014 Correct vs Incorrect Sequence",
            "description": "Two side-by-side sequence diagrams. CORRECT: context_switch() updates TSS.ESP0 = new_proc.kernel_stack_top BEFORE calling context_switch_asm. Timer fires while new process runs \u2192 CPU reads TSS.ESP0 \u2192 kernel stack for new process \u2713. INCORRECT: TSS.ESP0 not updated. Timer fires while new process runs \u2192 CPU reads stale TSS.ESP0 (old process's kernel stack) \u2192 pushes EFLAGS/CS/EIP onto old process's kernel stack \u2192 when old process is rescheduled and its timer ISR completes, the extra frame corrupts its return address \u2192 delayed crash in unrelated code. Diagram makes the time-distance between cause (missed update) and effect (crash) visually explicit.",
            "type": "sequence",
            "anchor_target": "build-os-m4"
          }
        ]
      }
    ]
  },
  "tdd_accumulated_md": "\n\n# TDD\n\nA bottom-up implementation of a 32-bit x86 kernel decomposed into four load-bearing milestones. Each milestone is a prerequisite for the next: GDT enables IDT, IDT enables page-fault recovery, page-fault recovery enables process isolation, and process isolation enables preemptive scheduling. Every module is specified to the byte-offset and hardware-register level required to pass on bare metal and in QEMU with GDB attached.\n\n\n\n<!-- TDD_MOD_ID: build-os-m1 -->\n# Technical Design Specification: Bootloader, GDT, and Kernel Entry (`build-os-m1`)\n---\n## 1. Module Charter\nThis module bootstraps an x86 system from the first byte the BIOS executes at `0x7C00` through to a fully operational 32-bit protected-mode C environment. It encompasses: a two-stage bootloader (MBR + 4 KB stage2) that enables A20, reads the kernel from disk using BIOS INT 13h, constructs a five-entry GDT, performs the CR0.PE transition with a far jump, and calls a C kernel entry point with zeroed BSS, a valid stack, and the direction flag cleared. It also provides a VGA text-mode driver (memory-mapped at `0xB8000`), a serial COM1 UART driver at 115200/8N1, and a `kprintf` supporting `%c`, `%s`, `%d`, `%x`, `%p`.\nThis module does **not** install an IDT, enable interrupts (`sti` is never called), set up paging, implement any dynamic memory allocation, or handle CPU exceptions. Interrupts remain permanently disabled (`cli`) from the first instruction through the end of this milestone.\n**Upstream dependency:** BIOS firmware \u2014 provides INT 13h (disk), INT 15h (A20), and the real-mode execution environment. **Downstream dependency:** Milestone 2 (IDT, PIC) \u2014 requires GDT to be loaded and segment registers correct; requires `kprintf` for diagnostic output.\n**Invariants that must hold throughout:** CR0.PE=1 and all segment registers loaded with valid GDT selectors before any C code runs. EFLAGS.IF=0 for the entire milestone. BSS section zero-filled before `kernel_main` is called. ESP points into a writable, fully-mapped region. EFLAGS.DF=0 before and throughout C execution.\n---\n## 2. File Structure\nCreate files in this exact order:\n```\nbuild-os/\n\u251c\u2500\u2500 01  boot/\n\u2502   \u251c\u2500\u2500 01  stage1.asm          # MBR bootsector (512 bytes, NASM -f bin)\n\u2502   \u2514\u2500\u2500 02  stage2.asm          # Stage2 loader (4 KB max, NASM -f bin)\n\u251c\u2500\u2500 02  kernel/\n\u2502   \u251c\u2500\u2500 01  kernel_entry.asm    # Protected-mode entry: BSS zero, stack, cld, call\n\u2502   \u251c\u2500\u2500 02  kernel.ld           # Linker script: places kernel at 0x100000\n\u2502   \u251c\u2500\u2500 03  kernel.h            # Shared integer types (uint8_t \u2026 uint32_t, uintptr_t)\n\u2502   \u251c\u2500\u2500 04  gdt.h               # GDT struct declarations + gdt_init prototype\n\u2502   \u251c\u2500\u2500 05  gdt.c               # GDT initialization and lgdt wrapper\n\u2502   \u251c\u2500\u2500 06  vga.h               # vga_clear, vga_putchar, vga_set_color\n\u2502   \u251c\u2500\u2500 07  vga.c               # VGA text driver (80\u00d725, memory-mapped 0xB8000)\n\u2502   \u251c\u2500\u2500 08  serial.h            # serial_init, serial_putchar\n\u2502   \u251c\u2500\u2500 09  serial.c            # COM1 UART driver (115200 / 8N1)\n\u2502   \u251c\u2500\u2500 10  kprintf.h           # kprintf declaration\n\u2502   \u251c\u2500\u2500 11  kprintf.c           # kprintf: %c %s %d %x %p\n\u2502   \u2514\u2500\u2500 12  kernel_main.c       # C entry point; calls gdt_init, vga_clear, kprintf\n\u2514\u2500\u2500 13  Makefile                # Build system \u2192 os.img\n```\n---\n## 3. Complete Data Model\n### 3.1 GDT Descriptor\nEach GDT entry is exactly **8 bytes** (64 bits). The layout is fragmented for historical reasons; fields must be assembled manually.\n\n![Physical Memory Map at Boot Time](./diagrams/tdd-diag-1.svg)\n\n**Byte-offset table (one GDT entry, `struct gdt_entry`):**\n| Byte offset | Bits | Field | Description |\n|-------------|------|-------|-------------|\n| 0\u20131 | 15:0 | `limit_low` | Segment limit bits 15:0 |\n| 2\u20133 | 15:0 | `base_low` | Segment base bits 15:0 |\n| 4 | 7:0 | `base_mid` | Segment base bits 23:16 |\n| 5 | 7:0 | `access` | Present, DPL, S, Type, A (see below) |\n| 6 | 7:4 | `flags` | G, D/B, L, AVL (upper nibble) |\n| 6 | 3:0 | `limit_high` | Segment limit bits 19:16 (lower nibble) |\n| 7 | 7:0 | `base_high` | Segment base bits 31:24 |\nC declaration:\n```c\n// gdt.h\ntypedef struct {\n    uint16_t limit_low;    // Offset 0\n    uint16_t base_low;     // Offset 2\n    uint8_t  base_mid;     // Offset 4\n    uint8_t  access;       // Offset 5\n    uint8_t  flags_limit;  // Offset 6: flags[7:4] | limit[19:16] in [3:0]\n    uint8_t  base_high;    // Offset 7\n} __attribute__((packed)) gdt_entry_t; // sizeof == 8, verified by compile-time assert\n```\n**GDTR pseudo-descriptor (6 bytes):**\n| Byte offset | Bits | Field |\n|-------------|------|-------|\n| 0\u20131 | 15:0 | `limit` \u2014 size of GDT in bytes minus 1 = `5*8 - 1 = 39` |\n| 2\u20135 | 31:0 | `base` \u2014 linear (physical before paging) address of GDT array |\n```c\ntypedef struct {\n    uint16_t limit;\n    uint32_t base;\n} __attribute__((packed)) gdtr_t;\n```\n**Access byte field breakdown (byte 5 of each descriptor):**\n| Bit(s) | Name | Kernel code | Kernel data | User code | User data |\n|--------|------|-------------|-------------|-----------|-----------|\n| 7 | P (Present) | 1 | 1 | 1 | 1 |\n| 6:5 | DPL | 00 | 00 | 11 | 11 |\n| 4 | S (code/data=1) | 1 | 1 | 1 | 1 |\n| 3 | E (executable) | 1 | 0 | 1 | 0 |\n| 2 | DC (direction/conforming) | 0 | 0 | 0 | 0 |\n| 1 | RW (readable/writable) | 1 | 1 | 1 | 1 |\n| 0 | A (accessed, CPU sets) | 0 | 0 | 0 | 0 |\n| **hex** | | **0x9A** | **0x92** | **0xFA** | **0xF2** |\n**Flags nibble (upper 4 bits of byte 6):**\n| Bit | Name | Value for all five entries |\n|-----|------|--------------------------|\n| 7 | G (granularity: 1=4 KB pages) | 1 |\n| 6 | D/B (32-bit segment) | 1 |\n| 5 | L (64-bit; 0 for 32-bit mode) | 0 |\n| 4 | AVL (available) | 0 |\n| **hex** | | **0xC** (upper nibble of byte 6) |\nCombined `flags_limit` byte 6 value for full 4 GB limit (`limit_bits_19_16 = 0xF`): `0xCF`.\n**Complete five-entry GDT:**\n| Index | Selector | Name | Base | Limit | Access | flags_limit |\n|-------|----------|------|------|-------|--------|-------------|\n| 0 | `0x00` | Null | 0 | 0 | `0x00` | `0x00` |\n| 1 | `0x08` | Kernel code (ring 0) | 0 | `0xFFFFFFFF` | `0x9A` | `0xCF` |\n| 2 | `0x10` | Kernel data (ring 0) | 0 | `0xFFFFFFFF` | `0x92` | `0xCF` |\n| 3 | `0x18` | User code (ring 3) | 0 | `0xFFFFFFFF` | `0xFA` | `0xCF` |\n| 4 | `0x20` | User data (ring 3) | 0 | `0xFFFFFFFF` | `0xF2` | `0xCF` |\nTotal GDT size: 40 bytes.\n---\n### 3.2 Disk Address Packet (DAP) for INT 13h Extended Read\n| Byte offset | Size | Field | Value for kernel load |\n|-------------|------|-------|----------------------|\n| 0 | 1 | `size` | `0x10` (16 bytes) |\n| 1 | 1 | reserved | `0x00` |\n| 2\u20133 | 2 | `sector_count` | 64 (32 KB; expand as needed) |\n| 4\u20135 | 2 | `dest_offset` | `0x0000` |\n| 6\u20137 | 2 | `dest_segment` | `0x1000` \u2192 physical `0x10000` |\n| 8\u201311 | 4 | `lba_low` | `10` (sector 10 on disk) |\n| 12\u201315 | 4 | `lba_high` | `0` |\n---\n### 3.3 VGA Text Cell\nEach cell in the 80\u00d725 VGA text buffer is 2 bytes at physical `0xB8000`:\n| Byte | Bits | Field |\n|------|------|-------|\n| +0 | 7:0 | ASCII character code |\n| +1 | 7:4 | Background color (0\u201315) |\n| +1 | 3:0 | Foreground color (0\u201315) |\nBuffer address formula: `0xB8000 + (row * 80 + col) * 2`\n```c\n// vga.h\n#define VGA_BUFFER   ((volatile uint16_t *)0xB8000)\n#define VGA_WIDTH    80\n#define VGA_HEIGHT   25\n// Combine foreground and background into a color attribute byte\nstatic inline uint8_t vga_color(uint8_t fg, uint8_t bg) {\n    return (uint8_t)((bg << 4) | (fg & 0x0F));\n}\n// Pack char + attribute into a 16-bit VGA cell (little-endian: char in low byte)\nstatic inline uint16_t vga_entry(char c, uint8_t color) {\n    return (uint16_t)((uint16_t)color << 8 | (uint8_t)c);\n}\n```\nColor constants (standard VGA palette):\n```c\n#define VGA_BLACK        0\n#define VGA_BLUE         1\n#define VGA_GREEN        2\n#define VGA_CYAN         3\n#define VGA_RED          4\n#define VGA_MAGENTA      5\n#define VGA_BROWN        6\n#define VGA_LIGHT_GRAY   7\n#define VGA_DARK_GRAY    8\n#define VGA_LIGHT_BLUE   9\n#define VGA_LIGHT_GREEN  10\n#define VGA_LIGHT_CYAN   11\n#define VGA_LIGHT_RED    12\n#define VGA_LIGHT_MAGENTA 13\n#define VGA_YELLOW       14\n#define VGA_WHITE        15\n```\n---\n### 3.4 COM1 UART Register Map\nBase I/O port: `0x3F8`. All access via `outb`/`inb`.\n| Port offset | DLAB | Direction | Register | Value for 115200/8N1 init |\n|-------------|------|-----------|----------|--------------------------|\n| `+0` | 0 | W | Transmit Holding Register | \u2014 |\n| `+0` | 1 | W | Divisor Latch Low | `0x01` |\n| `+1` | 0 | W | Interrupt Enable Register | `0x00` (disable all) |\n| `+1` | 1 | W | Divisor Latch High | `0x00` |\n| `+2` | \u2014 | W | FIFO Control Register | `0xC7` |\n| `+3` | \u2014 | W | Line Control Register (set DLAB=1 first, then DLAB=0) | `0x80` \u2192 `0x03` |\n| `+4` | \u2014 | W | Modem Control Register | `0x0B` |\n| `+5` | \u2014 | R | Line Status Register | bit 5 = THRE (TX empty) |\nBaud rate calculation: internal clock = 115200 Hz. Divisor = 115200 / baud. At 115200 baud: divisor = 1 (low byte = 0x01, high byte = 0x00).\n---\n## 4. Interface Contracts\n### 4.1 GDT\n```c\n// gdt.c / gdt.h\n// Internal helper \u2014 not exposed outside gdt.c\nstatic void gdt_set_entry(int idx, uint32_t base, uint32_t limit,\n                          uint8_t access, uint8_t flags);\n// Preconditions:  idx in [0,4]; flags = 0xCF for all code/data; limit = 0xFFFFFFFF\n// Postconditions: gdt[idx] fully populated per encoding rules above\n// Errors:         none (no runtime checks; any wrong idx is a bug, not a runtime error)\n// Public API:\nvoid gdt_init(void);\n// Preconditions:  CPU must be in protected mode (CR0.PE=1) OR this may be called just\n//                 before the far jump as long as lgdt is issued and interrupts are off.\n//                 In this milestone gdt_init() is called from kernel_main (post-CR0.PE).\n// Postconditions: gdt[0..4] set per table above; GDTR loaded; all segment registers\n//                 reloaded with selector 0x10 (kernel data); CS already holds 0x08\n//                 (set by the far jump in stage2).\n// Side effects:   Executes 'lgdt'; reloads DS, ES, FS, GS, SS via assembly.\n// Errors:         None; correctness is verified via compile-time assert on struct sizes.\n```\nAssembly helper required (in `gdt.c` or a dedicated `.asm`):\n```asm\n; gdt_flush(gdtr_t *gdtr_ptr)  \u2014 called from gdt_init()\n; Loads GDTR and reloads all data segment registers\ngdt_flush:\n    mov eax, [esp+4]      ; pointer to gdtr_t\n    lgdt [eax]\n    ; Reload data segments with kernel data selector 0x10\n    mov ax, 0x10\n    mov ds, ax\n    mov es, ax\n    mov fs, ax\n    mov gs, ax\n    mov ss, ax\n    ret\n; Note: CS is NOT reloaded here (that was done by the far jump in stage2)\n```\n---\n### 4.2 VGA Driver\n```c\nvoid vga_clear(void);\n// Preconditions:  VGA buffer at 0xB8000 is identity-mapped (it always is before paging)\n// Postconditions: All 2000 cells filled with ' ' + current vga_color; cursor at (0,0)\n// Side effects:   Writes 4000 bytes to MMIO; volatile guarantees hardware visibility\n// Errors:         None\nvoid vga_set_color(uint8_t fg, uint8_t bg);\n// Postconditions: Global color attribute updated; subsequent putchar calls use new color\nvoid vga_putchar(char c);\n// Preconditions:  none\n// Behavior:\n//   '\\n'  \u2192 col=0, row++; if row==VGA_HEIGHT, call vga_scroll()\n//   '\\t'  \u2192 advance col to next multiple of 8; wrap if needed\n//   other \u2192 write vga_entry(c, color) to VGA_BUFFER[row*80+col]; advance col\n//           if col==VGA_WIDTH: col=0, row++; if row==VGA_HEIGHT: vga_scroll()\n// Errors:         None; never writes outside [0, VGA_WIDTH*VGA_HEIGHT)\nstatic void vga_scroll(void);\n// Effect: copies rows 1..24 to rows 0..23 (memmove semantics on volatile uint16_t*);\n//         fills row 24 with ' '+color; sets row=24\n// Implementation: must use a temporary uint16_t copy or explicit byte moves;\n//                 volatile semantics mean no compiler optimization of overlapping writes\nvoid vga_write_string(const char *s);\n// Calls vga_putchar for each byte until '\\0'; exposed for kprintf internal use\n```\n---\n### 4.3 Serial Driver\n```c\nvoid serial_init(void);\n// Exact initialization sequence (order is mandatory):\n//   1. outb(COM1+1, 0x00)   disable interrupts\n//   2. outb(COM1+3, 0x80)   set DLAB=1 to access divisor\n//   3. outb(COM1+0, 0x01)   divisor low = 1 \u2192 115200 baud\n//   4. outb(COM1+1, 0x00)   divisor high = 0\n//   5. outb(COM1+3, 0x03)   8N1; clears DLAB\n//   6. outb(COM1+2, 0xC7)   enable+clear FIFO; 14-byte threshold\n//   7. outb(COM1+4, 0x0B)   RTS+DTR; IRQ enable bit (harmless, IRQ not used)\n// Postconditions: COM1 transmits at 115200 baud, 8N1, polling mode\n// Errors:         None (no loopback test in this milestone)\nvoid serial_putchar(char c);\n// Behavior: spin on (inb(COM1+5) & 0x20) == 0 (THRE not set);\n//           once set: outb(COM1, c)\n// '\\n' handling: emit '\\r' before '\\n' for terminal compatibility\n// Errors: None (blocking spin; if UART is absent, spins forever)\n//         \u2192 acceptable for a debug-only driver\nvoid serial_write_string(const char *s);\n// Iterates serial_putchar until '\\0'\n```\n---\n### 4.4 kprintf\n```c\nvoid kprintf(const char *fmt, ...);\n// Behavior: iterates fmt byte by byte\n//   Non-'%' characters: emit to both VGA and serial\n//   '%' sequences:\n//     %c  \u2192 va_arg(int) cast to char; emit single character\n//     %s  \u2192 va_arg(const char*); emit until '\\0'; NULL ptr \u2192 emit \"(null)\"\n//     %d  \u2192 va_arg(int); handle INT_MIN edge case; emit sign if negative;\n//            convert to decimal using divide-by-10 loop; emit digits\n//     %x  \u2192 va_arg(uint32_t); emit exactly 8 hex digits (zero-padded); lowercase a-f\n//     %p  \u2192 va_arg(uint32_t); emit \"0x\" prefix then 8 hex digits; same as %x + prefix\n//     %%  \u2192 emit literal '%'\n//     any other char after '%' \u2192 emit '%' + that char verbatim\n// Output: both vga_putchar() and serial_putchar() for every emitted character\n// Errors: None; does not return error codes\n// Limitations: no field width, no precision, no %u, no %l in this milestone\n// Stack usage: local char buf[12] for integer\u2192decimal conversion; no heap\n```\n**%d implementation \u2014 INT_MIN edge case:**\n`INT_MIN` is `\u22122147483648`. Negating it overflows `int`. Detect with `n == INT_MIN`, print \"-2147483648\" directly, return. For all other negative values, flip sign, convert, prepend '-'.\n**%x/%p implementation:**\nEmit exactly 8 nibbles from most significant to least. Do NOT suppress leading zeros (consistency with pointer display).\n---\n### 4.5 Inline I/O Port Primitives\nThese are used throughout and must be defined in `kernel.h`:\n```c\nstatic inline void outb(uint16_t port, uint8_t val) {\n    __asm__ volatile (\"outb %0, %1\" : : \"a\"(val), \"Nd\"(port) : \"memory\");\n}\nstatic inline uint8_t inb(uint16_t port) {\n    uint8_t val;\n    __asm__ volatile (\"inb %1, %0\" : \"=a\"(val) : \"Nd\"(port) : \"memory\");\n    return val;\n}\n```\nThe `\"memory\"` clobber prevents the compiler from reordering MMIO/port accesses across these calls.\n---\n## 5. Algorithm Specification\n### 5.1 Stage1 MBR Bootstrap\n\n![Two-Stage Boot Sequence Timeline](./diagrams/tdd-diag-2.svg)\n\n**Exact instruction sequence:**\n```nasm\n[BITS 16]\n[ORG 0x7C00]\n_start:\n    cli                     ; (1) Disable interrupts: real-mode IVT cannot be trusted\n                            ;     after we touch segment registers\n    xor  ax, ax\n    mov  ds, ax             ; (2) DS = 0\n    mov  es, ax             ; (3) ES = 0\n    mov  ss, ax             ; (4) SS = 0  (tri-instruction sequence avoids fault window)\n    mov  sp, 0x7C00         ; (5) Stack grows downward from 0x7C00\n                            ;     Region 0x0500\u20130x7BFF is safe for stack; 0x7C00\u20130x7DFF is MBR code\n    sti                     ; (6) Re-enable interrupts for BIOS calls\n    mov  [boot_drive], dl   ; (7) BIOS puts boot drive number in DL; save it\n                            ;     dl=0x00 floppy, dl=0x80 first HDD\n    ; Load stage2: 8 sectors starting at LBA 2, destination ES:BX = 0x0000:0x7E00\n    ; This places stage2 at physical 0x7E00, immediately after the MBR\n    mov  ah, 0x02           ; INT 13h function 2: Read Sectors (CHS)\n    mov  al, 8              ; Sector count: 8 \u00d7 512 = 4096 bytes\n    mov  ch, 0              ; Cylinder 0\n    mov  cl, 2              ; Sector 2 (1-indexed; sector 1 is MBR)\n    mov  dh, 0              ; Head 0\n    mov  bx, 0x7E00         ; Destination offset (ES=0 \u2192 physical 0x7E00)\n    int  0x13\n    jc   disk_error         ; CF=1 on failure\n    jmp  0x0000:0x7E00      ; Far jump to stage2\ndisk_error:\n    ; Print 'E' on screen via BIOS (TTY mode) as a minimal error indicator\n    mov  ah, 0x0E\n    mov  al, 'E'\n    int  0x10\n.halt:\n    cli\n    hlt\n    jmp  .halt\nboot_drive: db 0\n    ; Pad MBR to 512 bytes with zeros; last two bytes are boot signature\n    times 510-($-$$) db 0\n    dw   0xAA55             ; Boot signature: BIOS reads bytes 510=0x55, 511=0xAA (little-endian)\n```\n**Constraint:** `$ - $$` is the size of all content before the padding directive. It must be \u2264 510. With the code above it will be well under 50 bytes. Verify with `nasm -f bin stage1.asm -o stage1.bin && wc -c stage1.bin` \u2192 must print `512`.\n---\n### 5.2 A20 Enablement (Stage2)\n{{DIAGRAM:tdd-diag-3}}\nTry methods in order. After each method, verify A20 before proceeding.\n**Verification procedure:**\n```nasm\n; Returns: ZF=1 if A20 is OFF (wrapping), ZF=0 if A20 is ON\ncheck_a20:\n    push ds\n    push es\n    push di\n    push si\n    xor  ax, ax             ; Segment 0x0000\n    mov  es, ax\n    mov  di, 0x0500         ; Physical 0x0500\n    mov  ax, 0xFFFF         ; Segment 0xFFFF\n    mov  ds, ax\n    mov  si, 0x0510         ; Physical 0xFFFF0 + 0x0510 = 0x10500\n                            ; If A20 is off, 0x10500 wraps to 0x0500\n    mov  al, byte [es:di]   ; Save original value at 0x0500\n    push ax\n    mov  al, byte [ds:si]   ; Save original value at 0x10500\n    push ax\n    mov  byte [es:di], 0x00\n    mov  byte [ds:si], 0xFF\n    cmp  byte [es:di], 0xFF ; If wrapping, write to 0x10500 = write to 0x0500\n    pop  ax\n    mov  byte [ds:si], al   ; Restore\n    pop  ax\n    mov  byte [es:di], al   ; Restore\n    pop  si\n    pop  di\n    pop  es\n    pop  ds\n    ret                     ; ZF=1 \u2192 A20 disabled; ZF=0 \u2192 A20 enabled\n```\n**Method 1 \u2014 BIOS INT 15h/2401:**\n```nasm\ntry_a20_bios:\n    mov  ax, 0x2401\n    int  0x15\n    jc   try_a20_fast       ; BIOS doesn't support: try next method\n    call check_a20\n    jnz  a20_enabled\n```\n**Method 2 \u2014 Fast A20 (port 0x92):**\n```nasm\ntry_a20_fast:\n    in   al, 0x92\n    test al, 0x02\n    jnz  .already_set\n    or   al, 0x02\n    and  al, 0xFE           ; CRITICAL: bit 0 = system reset; must NOT set it\n    out  0x92, al\n.already_set:\n    call check_a20\n    jnz  a20_enabled\n```\n**Method 3 \u2014 Keyboard controller (8042):**\n```nasm\ntry_a20_kbd:\n    call kbd_wait_cmd\n    mov  al, 0xAD           ; Disable keyboard\n    out  0x64, al\n    call kbd_wait_cmd\n    mov  al, 0xD0           ; Read output port\n    out  0x64, al\n    call kbd_wait_data\n    in   al, 0x60\n    push ax\n    call kbd_wait_cmd\n    mov  al, 0xD1           ; Write output port\n    out  0x64, al\n    call kbd_wait_cmd\n    pop  ax\n    or   al, 0x02           ; Set bit 1 = A20\n    out  0x60, al\n    call kbd_wait_cmd\n    mov  al, 0xAE           ; Re-enable keyboard\n    out  0x64, al\n    ; Small delay (I/O to 0x80 = ~1 \u00b5s)\n    mov  cx, 100\n.delay: out 0x80, al\n    loop .delay\n    call check_a20\n    jnz  a20_enabled\na20_failed:\n    ; Print 'A' (A20 failure) and halt\n    mov  ah, 0x0E\n    mov  al, 'A'\n    int  0x10\n    cli\n    hlt\na20_enabled:\n    ; A20 is active; continue to kernel load\nkbd_wait_cmd:               ; Wait until keyboard controller input buffer empty\n    in   al, 0x64\n    test al, 0x02\n    jnz  kbd_wait_cmd\n    ret\nkbd_wait_data:              ; Wait until keyboard controller output buffer full\n    in   al, 0x64\n    test al, 0x01\n    jz   kbd_wait_data\n    ret\n```\n---\n### 5.3 Kernel Load from Disk (Stage2, after A20)\n```nasm\n; Load kernel from LBA 10, 64 sectors (32 KB), destination physical 0x10000\n; Use INT 13h extended read (function 0x42) for LBA addressing\nload_kernel:\n    mov  si, dap\n    mov  ah, 0x42\n    mov  dl, [boot_drive]   ; Drive number preserved from stage1 via memory\n    int  0x13\n    jc   load_error\n    ; After load: kernel binary is at 0x10000-0x17FFF\n    ; After entering protected mode, copy it to 0x100000\n    ; OR: load it directly into a buffer above 1 MB using unreal mode\n    ; For simplicity: load at 0x10000 first, then relocate after protected mode transition\n    jmp  setup_gdt\nload_error:\n    mov  ah, 0x0E\n    mov  al, 'L'\n    int  0x10\n    cli\n    hlt\n; Disk Address Packet \u2014 must be in stage2's data section\ndap:\n    db 0x10         ; size of DAP (16 bytes)\n    db 0x00         ; reserved\n    dw 64           ; read 64 sectors = 32 KB\n    dw 0x0000       ; destination offset\n    dw 0x1000       ; destination segment \u2192 physical 0x1000*16 = 0x10000\n    dd 10           ; LBA start sector (low 32 bits)\n    dd 0            ; LBA start sector (high 32 bits, always 0 here)\nboot_drive: db 0x80 ; default; overwritten by stage1 at runtime\n```\n---\n### 5.4 GDT Construction and Protected-Mode Transition\n{{DIAGRAM:tdd-diag-4}}\n**Stage2 assembly \u2014 GDT and mode switch:**\n```nasm\n; Stage2 continues here after kernel load\nsetup_gdt:\n    cli                     ; MANDATORY: disable interrupts before touching GDT\n                            ; A stale real-mode IVT entry processed in protected mode = triple fault\n    lgdt [gdt_descriptor]   ; Load GDTR with GDT base and limit\n    mov  eax, cr0\n    or   eax, 0x01          ; Set CR0.PE (bit 0)\n    mov  cr0, eax           ; CPU is now in protected mode\n                            ; CS still contains real-mode value; prefetch queue may have\n                            ; real-mode-decoded instructions \u2014 far jump flushes both\n    ; Far jump: atomically loads CS=0x08 (kernel code selector) AND flushes pipeline\n    jmp  0x08:protected_mode_entry\n[BITS 32]\nprotected_mode_entry:\n    ; CS = 0x08 (kernel code, ring 0)\n    ; Now load all data segment registers with kernel data selector\n    mov  ax, 0x10\n    mov  ds, ax\n    mov  es, ax\n    mov  fs, ax\n    mov  gs, ax\n    mov  ss, ax\n    ; Set up 32-bit stack pointer (just below EBDA at 0x9FC00)\n    mov  esp, 0x9FC00\n    ; Copy kernel from 0x10000 to 0x100000 (the 1 MB mark)\n    ; 32 KB = 8192 dwords\n    mov  esi, 0x10000       ; Source: where we loaded it\n    mov  edi, 0x100000      ; Destination: standard kernel load address\n    mov  ecx, 8192          ; 32 KB / 4 bytes per dword\n    cld                     ; Direction flag clear: forward copy\n    rep  movsd\n    ; Jump to kernel entry point\n    jmp  0x100000\n; GDT table (in stage2 data section, accessible before protected mode)\ngdt_start:\n    ; Entry 0: Null descriptor (8 bytes of zeros \u2014 mandatory)\n    dd 0x00000000\n    dd 0x00000000\n    ; Entry 1: Kernel code (selector 0x08)\n    ; Base=0, Limit=0xFFFFF, G=1, D=1, P=1, DPL=0, S=1, E=1, R=1\n    dw 0xFFFF       ; limit_low\n    dw 0x0000       ; base_low\n    db 0x00         ; base_mid\n    db 0x9A         ; access: P=1 DPL=0 S=1 E=1 DC=0 R=1 A=0\n    db 0xCF         ; flags=0xC (G=1 D=1 L=0 AVL=0), limit_high=0xF\n    db 0x00         ; base_high\n    ; Entry 2: Kernel data (selector 0x10)\n    dw 0xFFFF\n    dw 0x0000\n    db 0x00\n    db 0x92         ; P=1 DPL=0 S=1 E=0 D=0 W=1 A=0\n    db 0xCF\n    db 0x00\n    ; Entry 3: User code (selector 0x18)\n    dw 0xFFFF\n    dw 0x0000\n    db 0x00\n    db 0xFA         ; P=1 DPL=3 S=1 E=1 DC=0 R=1 A=0\n    db 0xCF\n    db 0x00\n    ; Entry 4: User data (selector 0x20)\n    dw 0xFFFF\n    dw 0x0000\n    db 0x00\n    db 0xF2         ; P=1 DPL=3 S=1 E=0 D=0 W=1 A=0\n    db 0xCF\n    db 0x00\ngdt_end:\ngdt_descriptor:\n    dw gdt_end - gdt_start - 1     ; Limit = 39\n    dd gdt_start                    ; Base = linear address of gdt_start\n```\n---\n### 5.5 Kernel Entry Assembly (`kernel_entry.asm`)\n```nasm\n[BITS 32]\n[GLOBAL kernel_entry]\n[EXTERN kernel_main]\n[EXTERN __bss_start]\n[EXTERN __bss_end]\nkernel_entry:\n    ; \u2500\u2500 1. Zero the BSS section \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    ; No CRT0 exists; BSS is not zero-initialized on bare metal.\n    ; __bss_start and __bss_end are linker-script-defined symbols.\n    mov  edi, __bss_start\n    mov  ecx, __bss_end\n    sub  ecx, edi           ; ECX = byte count to zero\n    test ecx, ecx\n    jz   .bss_done\n    xor  eax, eax\n    rep  stosb              ; Zero ECX bytes from EDI; DF must be 0 (set below)\n.bss_done:\n    ; \u2500\u2500 2. Establish kernel stack \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    ; kernel_stack is in .bss (now zeroed); kernel_stack_top is its end\n    mov  esp, kernel_stack_top\n    ; \u2500\u2500 3. Clear direction flag (DF) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    ; C ABI requires DF=0 on function entry. The BIOS may have left it set.\n    ; rep stosb above needed DF=0 as well \u2014 clear before it, not after.\n    ; *** Move cld BEFORE the BSS loop ***\n    ; (The code above must be preceded by cld; see corrected sequence below)\n    ; \u2500\u2500 4. Clear EBP (marks bottom of call stack for unwinding) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    xor  ebp, ebp\n    ; \u2500\u2500 5. Call kernel_main \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    call kernel_main\n    ; \u2500\u2500 6. kernel_main must not return; halt defensively \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n.hang:\n    cli\n    hlt\n    jmp  .hang\n; Kernel stack in BSS (zeroed by the code above)\nsection .bss\nalign 16\nkernel_stack: resb 16384           ; 16 KB kernel stack\nkernel_stack_top:                  ; ESP initialized to this address\n```\n**Corrected order (cld must precede rep stosb):**\n```nasm\nkernel_entry:\n    cld                     ; (A) Clear DF FIRST \u2014 rep stosb requires DF=0\n    mov  edi, __bss_start   ; (B) BSS zero loop\n    mov  ecx, __bss_end\n    sub  ecx, edi\n    xor  eax, eax\n    rep  stosb\n    mov  esp, kernel_stack_top  ; (C) Stack\n    xor  ebp, ebp           ; (D) Mark call chain bottom\n    call kernel_main        ; (E) Enter C\n.hang:\n    cli\n    hlt\n    jmp  .hang\n```\n---\n### 5.6 Linker Script (`kernel.ld`)\n{{DIAGRAM:tdd-diag-5}}\n```ld\n/* kernel.ld \u2014 x86 32-bit freestanding kernel at physical 0x100000 */\nENTRY(kernel_entry)\nSECTIONS {\n    . = 0x100000;                   /* Physical load address = VMA in this milestone */\n    .text ALIGN(4096) : {\n        *(.multiboot)               /* Multiboot header must be in first 8 KB of image */\n        *(.text)\n        *(.text.*)\n    }\n    .rodata ALIGN(4096) : {\n        *(.rodata)\n        *(.rodata.*)\n    }\n    .data ALIGN(4096) : {\n        *(.data)\n        *(.data.*)\n    }\n    .bss ALIGN(4096) : {\n        __bss_start = .;            /* Symbol referenced by kernel_entry.asm */\n        *(.bss)\n        *(.bss.*)\n        *(COMMON)\n        __bss_end = .;\n    }\n    __kernel_end = .;               /* Used in Milestone 3 by physical frame allocator */\n}\n```\n**Alignment rationale:** 4 KB page-alignment enables Milestone 3 to assign per-section permissions (`.text` execute-only, `.data` no-execute) without modifying the linker script. Cost: < 16 KB of padding in total.\n---\n## 6. GDT Initialization in C (gdt.c)\n{{DIAGRAM:tdd-diag-6}}\n```c\n// gdt.c\n#include \"kernel.h\"\n#include \"gdt.h\"\n// Compile-time assertion: struct must be exactly 8 bytes\ntypedef char gdt_entry_size_check[(sizeof(gdt_entry_t) == 8) ? 1 : -1];\ntypedef char gdtr_size_check[(sizeof(gdtr_t) == 6) ? 1 : -1];\nstatic gdt_entry_t gdt[5];\nstatic gdtr_t      gdtr;\nstatic void gdt_set_entry(int idx, uint32_t base, uint32_t limit,\n                           uint8_t access, uint8_t flags) {\n    gdt[idx].limit_low   = (uint16_t)(limit & 0xFFFF);\n    gdt[idx].base_low    = (uint16_t)(base  & 0xFFFF);\n    gdt[idx].base_mid    = (uint8_t)((base  >> 16) & 0xFF);\n    gdt[idx].access      = access;\n    // flags occupies bits 7:4 of flags_limit; limit bits 19:16 occupy bits 3:0\n    gdt[idx].flags_limit = (uint8_t)((flags & 0xF0) | ((limit >> 16) & 0x0F));\n    gdt[idx].base_high   = (uint8_t)((base  >> 24) & 0xFF);\n}\n// Defined in gdt_flush.asm (or inline asm below)\nextern void gdt_flush(gdtr_t *gdtr_ptr);\nvoid gdt_init(void) {\n    gdt_set_entry(0, 0, 0,          0x00, 0x00); // Null\n    gdt_set_entry(1, 0, 0xFFFFFFFF, 0x9A, 0xCF); // Kernel code\n    gdt_set_entry(2, 0, 0xFFFFFFFF, 0x92, 0xCF); // Kernel data\n    gdt_set_entry(3, 0, 0xFFFFFFFF, 0xFA, 0xCF); // User code\n    gdt_set_entry(4, 0, 0xFFFFFFFF, 0xF2, 0xCF); // User data\n    gdtr.limit = (uint16_t)(sizeof(gdt) - 1);    // = 39\n    gdtr.base  = (uint32_t)(uintptr_t)gdt;\n    gdt_flush(&gdtr);\n    // After gdt_flush: DS, ES, FS, GS, SS = 0x10; CS = 0x08 (set by far jump)\n}\n```\n**Why call `gdt_init()` from `kernel_main` when GDT was already loaded in stage2?** Resilience and correctness: stage2's GDT lived in low memory (below `0x10000`), which may be overwritten by stack growth or future drivers. Reinitializing from C ensures the GDT lives in the BSS/data section of the kernel binary at `0x100000+`, where it will survive. The `lgdt` in `gdt_flush` also reloads the GDTR to point to the new location.\n---\n## 7. Error Handling Matrix\n| Error | Detection Point | Recovery | User-Visible? |\n|-------|----------------|----------|---------------|\n| Boot signature `0xAA55` wrong/missing | BIOS (before MBR runs) | BIOS skips device; no output | BIOS UI: \"No bootable device\" |\n| INT 13h carry flag set (disk read fail) | stage1 `jc disk_error` | Print 'E' via BIOS INT 10h TTY; `cli; hlt` | 'E' on screen |\n| A20 all three methods fail | `check_a20` returns ZF=1 after method 3 | Print 'A' via BIOS INT 10h; `cli; hlt` | 'A' on screen |\n| Kernel load fails (INT 13h AH=0x42) | `jc load_error` | Print 'L'; `cli; hlt` | 'L' on screen |\n| GDT entry misconfigured (wrong access byte) | CPU on first memory access post-CR0.PE | Triple fault \u2192 machine reset | None (silent reset) |\n| Far jump missing after CR0.PE set | CPU pipeline inconsistency | Triple fault \u2192 machine reset | None |\n| Interrupts not disabled before lgdt+CR0.PE | Stale IVT entry dispatched in protected mode | Triple fault | None |\n| BSS not zeroed | Garbage in global variables | Undefined behavior; kprintf may crash | Garbled output or fault |\n| ESP pointing to unmapped/read-only region | First push in kernel_main | Triple fault | None |\n| DF=1 on entry to C | First rep movs/stos in compiler-emitted code | Memory corruption | Crashes later, hard to diagnose |\n| VGA `volatile` missing | Compiler eliminates writes as dead code | No screen output | Blank screen |\n| Serial DLAB not cleared after divisor write | UART misinterprets data register as divisor | No serial output, possible garbage | No serial |\n| `kprintf` NULL `%s` argument | `va_arg(const char*)` returns NULL | Emit literal string `\"(null)\"` | \"(null)\" in output |\n| INT_MIN negation overflow in `%d` | Special-case check in kprintf | Emit \"-2147483648\" directly | Correct output |\n---\n## 8. Implementation Sequence with Checkpoints\n### Phase 1 \u2014 Stage1 MBR + Disk Load + A20 (4\u20136 hours)\n1. Install NASM and `i686-elf-gcc` cross-compiler toolchain.\n2. Write `boot/stage1.asm` (MBR skeleton, INT 13h CHS read for stage2, `dw 0xAA55`).\n3. Write `boot/stage2.asm` skeleton (no GDT yet): just `jmp $` (spin loop).\n4. Write `Makefile` targets: `stage1.bin`, `stage2.bin`, `os.img` (dd commands), `run` (qemu).\n5. Implement A20 check and all three enable methods in stage2.\n**Checkpoint 1A:** `make os.img && make run` \u2192 QEMU boots, stage2 spins. QEMU monitor (`Ctrl+Alt+2`): `info registers` shows `CS=0x0000 EIP=0x7E00`. Confirms stage1 loaded stage2.\n**Checkpoint 1B:** After A20 code: `make run` with QEMU `-d int` \u2192 no exceptions during A20 sequence. Add `mov byte [0x10500], 0xFF` followed by `cmp byte [0x0500], 0xFF` \u2014 in QEMU they should differ (A20 active). Verify via QEMU monitor: `xp /1xb 0x0500` and `xp /1xb 0x10500` show different values.\n---\n### Phase 2 \u2014 GDT Construction and Protected-Mode Transition (4\u20136 hours)\n1. Add GDT table and descriptor to stage2 after A20 code.\n2. Implement `setup_gdt`, `lgdt`, CR0.PE set, far jump sequence.\n3. Add `[BITS 32]` protected-mode stub that loads segment registers and copies kernel to `0x100000`.\n4. Add `jmp 0x100000` at the end of the copy (kernel entry not yet written \u2014 stage2 will fault here).\n**Checkpoint 2A:** In stage2, after `jmp 0x100000`, insert a VGA write (write `'P'` with attribute `0x0F` to `0xB8000`): `mov dword [0xB8000], 0x0F500F50`. If 'P' appears at top-left of QEMU screen, protected mode is working and the VGA MMIO region is accessible.\n**Checkpoint 2B:** QEMU monitor `info registers` while CPU is running: `CS=0x0008` confirms kernel code selector; `DS=0x0010` confirms kernel data selector; `EFLAGS` bit 0 (PE) = 1.\n---\n### Phase 3 \u2014 Linker Script + Kernel Entry Assembly (3\u20135 hours)\n1. Write `kernel/kernel.ld`.\n2. Write `kernel/kernel_entry.asm` with `cld`, BSS zero loop, stack setup, `xor ebp,ebp`, `call kernel_main`.\n3. Write stub `kernel/kernel_main.c` with `void kernel_main(void) { while(1) {} }`.\n4. Add Makefile rules: compile `.c` and `.asm` \u2192 `.o`; link with `kernel.ld` \u2192 `kernel.elf`; `objcopy -O binary` \u2192 `kernel.bin`; `dd` into `os.img` at sector 10.\n**Checkpoint 3A:** `readelf -S kernel.elf` \u2192 `.text` section VMA = `0x100000`. `readelf -s kernel.elf | grep bss` \u2192 `__bss_start` and `__bss_end` symbols are present at correct addresses.\n**Checkpoint 3B:** `objdump -d kernel.elf | head -40` \u2192 first instruction is `cld`. Confirms linker placed `kernel_entry` at `0x100000` and it appears first.\n**Checkpoint 3C:** `make run` with QEMU `-d int -no-reboot`. No exceptions printed. GDB: `break kernel_main` \u2192 hits. `print (void*)$esp` \u2192 value near `0x9FC00`. The kernel is running in C.\n---\n### Phase 4 \u2014 VGA + Serial Drivers (3\u20134 hours)\n1. Write `vga.c` / `vga.h`: `vga_clear`, `vga_putchar`, `vga_scroll`, `vga_set_color`.\n2. Write `serial.c` / `serial.h`: `serial_init`, `serial_putchar`.\n3. Call `vga_clear()` and `serial_init()` from `kernel_main`; then `vga_putchar('K')` and `serial_putchar('K')`.\n**Checkpoint 4A:** `make run` \u2192 QEMU screen shows blank (from `vga_clear`) then the letter 'K' at row 0, col 0 in white-on-black. No garbage characters from before `vga_clear`.\n**Checkpoint 4B:** `make run` with `-serial stdio` \u2192 terminal shows 'K'. Alternatively `-serial file:serial.log` \u2192 `cat serial.log` shows 'K'.\n---\n### Phase 5 \u2014 kprintf + Build System Hardening + Disk Image (4\u20136 hours)\n1. Write `kprintf.c` / `kprintf.h`: implement all six format specifiers.\n2. Write comprehensive `kernel_main.c` that calls `gdt_init()`, `vga_clear()`, `serial_init()`, then `kprintf(...)` tests for each specifier.\n3. Harden Makefile: add `.PHONY`, dependency tracking, cross-compiler flags verification.\n**Checkpoint 5A:** `make run` with `-serial stdio` \u2192 terminal shows:\n```\n[OK] GDT initialized: 5 descriptors\n[OK] VGA driver: 80x25 text mode at 0xB8000\n[OK] Serial COM1: 115200 baud 8N1\nTest %%d: -2147483648 (INT_MIN)\nTest %%x: 0x00100000\nTest %%p: 0x000b8000\nTest %%s: hello\nTest %%c: K\n```\nVerify: `%d` with INT_MIN outputs `-2147483648`; `%x` zero-pads to 8 digits; `%p` prepends `0x`.\n---\n### Phase 6 \u2014 QEMU + GDB Integration (2\u20133 hours)\n1. Add Makefile `debug` target: `qemu-system-i386 -s -S -no-reboot -drive file=os.img,format=raw -serial stdio -d int,cpu_reset`.\n2. Write `.gdbinit` for automatic connection.\n3. Verify GDB can break at `kernel_main`, inspect VGA buffer, disassemble stage2.\n**Checkpoint 6 (final milestone checkpoint):** Run `make debug` in one terminal; `gdb kernel.elf` in another \u2192 GDB connects, breaks at `kernel_main`. In GDB:\n```gdb\n(gdb) info registers\n```\nVerify: `CS=0x8`, `DS=0x10`, `SS=0x10`, `EFLAGS` bit 1 (reserved, always 1) and bit 0 (PE) = 1.\n```gdb\n(gdb) x/4c 0xB8000\n```\nVerify: ASCII values match the characters printed by `vga_putchar`.\n```gdb\n(gdb) x/10i 0x100000\n```\nVerify: first instruction is `cld` (opcode `0xFC`).\n---\n## 9. Test Specification\n### 9.1 Static / Build-Time Tests\n```makefile\ntest-sizes:\n    # Stage1 must be exactly 512 bytes\n    @test $$(wc -c < stage1.bin) -eq 512 || (echo \"FAIL: stage1 size\"; exit 1)\n    # Boot signature: byte 510=0x55, byte 511=0xAA\n    @python3 -c \"d=open('stage1.bin','rb').read(); \\\n        assert d[510]==0x55 and d[511]==0xAA, 'FAIL: boot sig'\"\n    # Kernel ELF: entry point = 0x100000\n    @readelf -h kernel.elf | grep \"Entry point\" | grep -q \"0x100000\" || \\\n        (echo \"FAIL: entry not 0x100000\"; exit 1)\n    # BSS symbols present\n    @nm kernel.elf | grep -q \"__bss_start\" || (echo \"FAIL: no __bss_start\"; exit 1)\n    @nm kernel.elf | grep -q \"__bss_end\"   || (echo \"FAIL: no __bss_end\";   exit 1)\n    # Struct sizes (use a test harness linked freestanding)\n    @echo \"PASS: all static checks\"\n```\n### 9.2 VGA Driver Tests\n| Test | Input | Expected |\n|------|-------|----------|\n| `vga_clear()` | \u2014 | All 2000 cells = `' '` + current color; `vga_row=0, vga_col=0` |\n| `vga_putchar('A')` | \u2014 | `VGA_BUFFER[0] = (color<<8) | 'A'`; col advances to 1 |\n| `vga_putchar('\\n')` at col=0 | \u2014 | row increments; col stays 0 |\n| 80 chars on one row | 80\u00d7 `vga_putchar('X')` | Row 0 full; col wraps to 0; row=1 |\n| Write to last row then `'\\n'` | 25 rows filled, then `'\\n'` | `vga_scroll()` called; row 0 now has old row 1's data |\n| `vga_putchar('\\t')` at col=0 | \u2014 | col advances to 8 |\n| `vga_putchar('\\t')` at col=7 | \u2014 | col advances to 8 (next tab stop) |\n### 9.3 Serial Driver Tests\n| Test | Input | Expected |\n|------|-------|----------|\n| `serial_init()` | \u2014 | `inb(COM1+5) & 0x20` returns nonzero within 1 ms (THRE set) |\n| `serial_putchar('K')` | \u2014 | 'K' appears in QEMU `-serial stdio` output |\n| `serial_putchar('\\n')` | \u2014 | '\\r' then '\\n' appear in output (two characters) |\n### 9.4 kprintf Tests\n| Test | Format | Args | Expected output |\n|------|--------|------|-----------------|\n| Char | `\"%c\"` | `'Z'` | `\"Z\"` |\n| String | `\"%s\"` | `\"hello\"` | `\"hello\"` |\n| NULL string | `\"%s\"` | `NULL` | `\"(null)\"` |\n| Positive int | `\"%d\"` | `42` | `\"42\"` |\n| Negative int | `\"%d\"` | `-1` | `\"-1\"` |\n| INT_MIN | `\"%d\"` | `INT_MIN` | `\"-2147483648\"` |\n| Zero | `\"%d\"` | `0` | `\"0\"` |\n| Hex (zero-padded) | `\"%x\"` | `0xDEAD` | `\"0000dead\"` |\n| Hex (all zeros) | `\"%x\"` | `0` | `\"00000000\"` |\n| Hex (all Fs) | `\"%x\"` | `0xFFFFFFFF` | `\"ffffffff\"` |\n| Pointer | `\"%p\"` | `0xB8000` | `\"0x000b8000\"` |\n| Literal percent | `\"100%%\"` | \u2014 | `\"100%\"` |\n| Unknown specifier | `\"%q\"` | \u2014 | `\"%q\"` |\n| Mixed | `\"pid=%d addr=%x\"` | `1, 0x100000` | `\"pid=1 addr=00100000\"` |\n### 9.5 GDT Tests (via QEMU monitor / GDB)\n```gdb\n; After gdt_init() runs, inspect GDT in memory:\n(gdb) set $gdt_addr = &gdt\n; Entry 1 (kernel code): bytes at gdt_addr+8\n; Expected: FF FF 00 00 00 9A CF 00\n(gdb) x/8bx $gdt_addr+8\n; Entry 2 (kernel data): bytes at gdt_addr+16\n; Expected: FF FF 00 00 00 92 CF 00\n(gdb) x/8bx $gdt_addr+16\n; Segment registers:\n(gdb) info registers\n; CS=0x8 DS=0x10 ES=0x10 FS=0x10 GS=0x10 SS=0x10\n```\n### 9.6 Protected-Mode Transition Test\nQEMU `-d int` output must show **zero** exceptions from start through `kernel_main`. Command:\n```bash\nqemu-system-i386 -drive file=os.img,format=raw -serial stdio \\\n    -d int -no-reboot 2>&1 | grep -c \"^check_exception\"\n```\nExpected output: `0` (or only intentionally-triggered exceptions from test code).\n---\n## 10. Performance Targets\n| Operation | Target | Measurement Method |\n|-----------|--------|--------------------|\n| Stage1 binary size | \u2264 510 bytes (strict MBR constraint) | `wc -c stage1.bin` |\n| Stage2 binary size | \u2264 4096 bytes (8 sectors \u00d7 512) | `wc -c stage2.bin` |\n| Kernel load (64 sectors via INT 13h) | < 200 ms | QEMU `-d int` timestamps; human-observable |\n| `vga_putchar` latency | < 10 ns per call | Direct MMIO: 1 volatile 16-bit write; no branch on common path |\n| `serial_putchar` latency | < 1 \u00b5s at 115200 baud | 1 byte \u00d7 (1/115200) \u2248 8.7 \u00b5s wire time; polling loop overhead < 100 ns |\n| Boot-to-kprintf | < 500 ms including QEMU BIOS POST | Human stopwatch; `-d int` trace |\n| `kprintf` for 80-char string | < 1 ms | No syscalls, no allocation; VGA+serial writes |\n| BSS zero loop | < 1 ms for \u2264 1 MB BSS | `rep stosb` at 4 GB/s bus speed: 1 MB < 0.5 ms |\n---\n## 11. Makefile (Complete)\n{{DIAGRAM:tdd-diag-7}}\n```makefile\n# Cross-compiler targeting bare i686-elf (no OS assumptions)\nCC      := i686-elf-gcc\nAS      := nasm\nLD      := i686-elf-ld\nOBJCOPY := i686-elf-objcopy\nCFLAGS  := -m32 -ffreestanding -fno-stack-protector -fno-builtin \\\n           -fno-omit-frame-pointer -nostdlib -nostdinc \\\n           -Wall -Wextra -Werror -O2 -std=c99 \\\n           -Ikernel\nASFLAGS_ELF := -f elf32\nLDFLAGS     := -T kernel/kernel.ld -nostdlib -static\nKERNEL_C_SRCS   := kernel/gdt.c kernel/vga.c kernel/serial.c \\\n                   kernel/kprintf.c kernel/kernel_main.c\nKERNEL_ASM_SRCS := kernel/kernel_entry.asm\nKERNEL_OBJS     := $(KERNEL_C_SRCS:.c=.o) $(KERNEL_ASM_SRCS:.asm=.o)\n.PHONY: all clean run debug test-sizes\nall: os.img\n# Stage1: raw MBR binary (must be exactly 512 bytes)\nboot/stage1.bin: boot/stage1.asm\n\t$(AS) -f bin $< -o $@\n\t@test $$(wc -c < $@) -eq 512 || (echo \"ERROR: stage1.bin is not 512 bytes\"; exit 1)\n# Stage2: raw binary (max 4096 bytes)\nboot/stage2.bin: boot/stage2.asm\n\t$(AS) -f bin $< -o $@\n\t@test $$(wc -c < $@) -le 4096 || (echo \"ERROR: stage2.bin > 4096 bytes\"; exit 1)\n# Kernel: ELF then flat binary\n%.o: %.c\n\t$(CC) $(CFLAGS) -c $< -o $@\n%.o: %.asm\n\t$(AS) $(ASFLAGS_ELF) $< -o $@\nkernel.elf: $(KERNEL_OBJS)\n\t$(LD) $(LDFLAGS) -o $@ $^\n\t@readelf -h $@ | grep \"Entry point\" | grep -q \"0x100000\" || \\\n\t    (echo \"ERROR: kernel entry point is not 0x100000\"; exit 1)\nkernel.bin: kernel.elf\n\t$(OBJCOPY) -O binary $< $@\n# Disk image layout:\n#   Sector 0     (bytes 0-511):     stage1 (MBR)\n#   Sector 1     (bytes 512-1023):  unused (reserved)\n#   Sectors 2-9  (bytes 1024-5119): stage2 (4 KB)\n#   Sectors 10+  (bytes 5120+):     kernel\nos.img: boot/stage1.bin boot/stage2.bin kernel.bin\n\tdd if=/dev/zero    of=$@            bs=512 count=2880 status=none\n\tdd if=$<           of=$@ conv=notrunc bs=512 count=1     status=none\n\tdd if=boot/stage2.bin of=$@ conv=notrunc bs=512 seek=2   status=none\n\tdd if=kernel.bin   of=$@ conv=notrunc bs=512 seek=10     status=none\nrun: os.img\n\tqemu-system-i386 \\\n\t    -drive file=$<,format=raw,if=ide \\\n\t    -serial stdio \\\n\t    -d int,cpu_reset \\\n\t    -no-reboot \\\n\t    -display sdl\ndebug: os.img\n\tqemu-system-i386 \\\n\t    -drive file=$<,format=raw,if=ide \\\n\t    -serial stdio \\\n\t    -d int,cpu_reset \\\n\t    -no-reboot \\\n\t    -s -S \\\n\t    -display sdl\nclean:\n\trm -f boot/stage1.bin boot/stage2.bin\n\trm -f $(KERNEL_OBJS) kernel.elf kernel.bin os.img\ntest-sizes: boot/stage1.bin boot/stage2.bin kernel.elf\n\t@echo \"stage1.bin: $$(wc -c < boot/stage1.bin) bytes (must be 512)\"\n\t@echo \"stage2.bin: $$(wc -c < boot/stage2.bin) bytes (must be \u2264 4096)\"\n\t@nm kernel.elf | grep \"__bss_start\"\n\t@nm kernel.elf | grep \"__bss_end\"\n\t@nm kernel.elf | grep \"__kernel_end\"\n```\n---\n## 12. QEMU and GDB Integration\n{{DIAGRAM:tdd-diag-8}}\n**`.gdbinit` file (place in project root):**\n```gdb\nset architecture i386\nset disassembly-flavor intel\ntarget remote :1234\nsymbol-file kernel.elf\nbreak kernel_main\ncontinue\n```\n**GDB commands for debugging triple faults:**\n```bash\n# Start QEMU in debug mode, then in a second terminal:\ngdb kernel.elf\n# Inside GDB:\n(gdb) target remote :1234\n(gdb) set architecture i386\n# Step through protected mode transition (set breakpoint in stage2 at GDT load)\n# Note: stage2 has no symbols; use absolute addresses from objdump\n(gdb) break *0x7E00           # Start of stage2\n(gdb) break *0x100000         # Kernel entry point\n(gdb) break kernel_main       # C entry point\n# Verify segment registers after protected-mode transition\n(gdb) info registers          # Inspect CS, DS, SS, ESP, EFLAGS\n# Inspect GDT contents\n(gdb) x/40xb &gdt             # Dump all 5 GDT entries (40 bytes)\n# Inspect VGA buffer\n(gdb) x/8xh 0xB8000           # First 8 VGA cells\n# Inspect BSS is zeroed\n(gdb) x/16xb &__bss_start\n# Check boot signature\n(gdb) x/2xb 0x7C00+510        # Must be 0x55 0xAA\n```\n**Interpreting QEMU `-d int` for triple faults:**\nTriple fault appears in QEMU output as:\n```\ncheck_exception old: 0x8 new 0xd   \u2190 double fault (8) while handling another exception\nCPU Reset\n```\nThe *first* exception in the trace (before any `check_exception` line) is the root cause. Look for lines like:\n```\n     0: v=0d e=0052 i=0 cpl=0 IP=0008:00100000 pc=00100000 SP=0010:00007c00\n```\nThis shows: exception vector `0x0d` (general protection fault), error code `0x0052` (selector index 10, GDT, external event), at `CS:EIP=0008:0x100000`. Decode error code: `0x0052 >> 3 = 10` \u2192 GDT index 10 \u2192 invalid selector. Root cause: segment register holds a selector beyond the GDT limit.\n---\n## 13. Common Pitfalls and Resolutions\n| Pitfall | Detection | Resolution |\n|---------|-----------|------------|\n| `dw 0x55AA` instead of `dw 0xAA55` in MBR | BIOS does not boot; QEMU \"No bootable device\" | x86 is little-endian: `dw 0xAA55` stores `0x55` at byte 510, `0xAA` at 511. Use `dw 0xAA55` or `db 0x55, 0xAA` |\n| Far jump immediately after CR0.PE without `cli` | Random triple faults | Add `cli` before `lgdt`; keep interrupts off until M2 IDT is ready |\n| Missing `cld` before `rep stosb` | BSS zero loop runs backward; writes to wrong addresses | Add `cld` as the absolute first instruction in `kernel_entry` |\n| GDT in stage2 binary gets overwritten by stack | Crash occurs after kernel copy | GDT must be in the kernel binary's `.data` section, not in stage2 memory. Stage2 GDT is temporary; `gdt_init()` in C reinitializes from permanent location |\n| `kernel_main` not `__attribute__((noreturn))` | Compiler may generate epilogue that returns; `kernel_entry`'s `jmp .hang` is bypassed | Mark `kernel_main` as `void kernel_main(void) __attribute__((noreturn))` |\n| Kernel binary compiled for host architecture | GCC emits 64-bit instructions; kernel faults | Always use `i686-elf-gcc`, never host `gcc`. Verify: `i686-elf-gcc --version` |\n| `volatile` missing on `VGA_BUFFER` | Compiler eliminates writes; blank screen | Mandatory: `volatile uint16_t *` casts all VGA accesses |\n| Kernel loaded at wrong disk offset | Execution jumps to wrong code | `dd` `seek` value is in 512-byte blocks. Kernel at sector 10: `seek=10` |\n---\n<!-- END_TDD_MOD -->\n\n\n<!-- TDD_MOD_ID: build-os-m2 -->\n# Technical Design Specification: Interrupts, Exceptions, and Keyboard (`build-os-m2`)\n---\n## 1. Module Charter\nThis module transforms the static protected-mode kernel from Milestone 1 into a reactive system capable of handling hardware interrupts and CPU exceptions. It installs a 256-entry Interrupt Descriptor Table (IDT) using 8-byte gate descriptors, remaps the 8259A dual-PIC cascade so hardware IRQs occupy vectors 32\u201347 (never colliding with CPU exception vectors 0\u201331), generates 256 macro-expanded assembly ISR stubs that impose a uniform stack frame regardless of whether the CPU pushes an error code, dispatches to a C handler that prints diagnostic messages for all 32 CPU exceptions and reads CR2 for page faults, programs PIT channel 0 to 100 Hz, and installs a PS/2 keyboard driver backed by a 256-byte circular ring buffer. The module concludes with a single `sti` instruction, leaving the system fully interrupt-driven.\nThis module does **not** enable paging, implement a heap allocator, create processes, handle ring-3 transitions, program the APIC, implement the system call interface, or service any IRQ beyond IRQ0 (timer) and IRQ1 (keyboard). The `tick_counter` incremented by the timer handler is the only global scheduler primitive; actual context switching belongs to Milestone 4.\n**Upstream dependency:** Milestone 1 must deliver a 32-bit protected-mode kernel with CR0.PE=1, all segment registers holding valid GDT selectors (CS=0x08, DS/ES/FS/GS/SS=0x10), `kprintf` operational on both VGA and serial, the BSS zeroed, and EFLAGS.IF=0. No IDT has been loaded.\n**Downstream dependency:** Milestone 3 (memory management) requires the page fault handler installed here (`idt[14]`) to read CR2 and print the fault address; Milestone 4 (scheduling) requires the timer handler to call `scheduler_tick()`.\n**Invariants that must always hold:** (1) IDTR is loaded and points to a 256-entry, 2048-byte IDT before `sti`. (2) Both PIC master and slave are remapped to offsets 0x20/0x28 before any IRQ can be delivered. (3) Every IDT entry 0\u2013255 has a non-null handler \u2014 no vector is left as a zero-filled descriptor after `idt_init` completes. (4) Every IRQ handler sends EOI to the correct PIC(s) before returning. (5) EFLAGS.IF remains 0 throughout the PIC remapping sequence.\n---\n## 2. File Structure\nCreate files in this exact order:\n```\nbuild-os/\n\u251c\u2500\u2500 kernel/\n\u2502   \u251c\u2500\u2500 13  idt.h               # IDT entry struct, IDTR struct, idt_set_gate prototype, idt_init prototype\n\u2502   \u251c\u2500\u2500 14  idt.c               # IDT table, IDTR, idt_set_gate, idt_init, lidt wrapper\n\u2502   \u251c\u2500\u2500 15  isr_stubs.asm       # 256 ISR stubs (macro-generated) + isr_common_stub\n\u2502   \u251c\u2500\u2500 16  interrupt.h         # interrupt_frame_t struct, interrupt_dispatch prototype, irq_dispatch prototype\n\u2502   \u251c\u2500\u2500 17  interrupt.c         # interrupt_dispatch, exception names, page fault CR2, irq_dispatch\n\u2502   \u251c\u2500\u2500 18  pic.h               # PIC port constants, pic_remap, pic_send_eoi, pic_get_isr prototypes\n\u2502   \u251c\u2500\u2500 19  pic.c               # pic_remap (ICW1-ICW4), pic_send_eoi, pic_get_isr, io_wait\n\u2502   \u251c\u2500\u2500 20  pit.h               # pit_init prototype, pit_get_ticks, pit_get_ms\n\u2502   \u251c\u2500\u2500 21  pit.c               # pit_init (100 Hz), timer_handler, volatile tick_counter\n\u2502   \u251c\u2500\u2500 22  keyboard.h          # ring_buffer_t, keyboard_handler prototype, keyboard_getchar prototype\n\u2502   \u251c\u2500\u2500 23  keyboard.c          # scancode tables, modifier state, ring_buffer ops, keyboard_getchar\n\u2502   \u2514\u2500\u2500 24  kernel_main.c       # UPDATED: adds idt_init, pic_remap, pit_init, sti, test loop\n\u2514\u2500\u2500 Makefile                    # UPDATED: add isr_stubs.o, idt.o, interrupt.o, pic.o, pit.o, keyboard.o\n```\n---\n## 3. Complete Data Model\n### 3.1 IDT Gate Descriptor (8 bytes)\n{{DIAGRAM:tdd-diag-9}}\nEvery IDT entry is exactly **8 bytes**. The handler address is split across two non-contiguous fields \u2014 same historical fragmentation as GDT base addresses.\n**Byte-offset table:**\n| Byte offset | Bits | Field | Description |\n|---|---|---|---|\n| 0\u20131 | 15:0 | `offset_low` | Handler virtual address bits 15:0 |\n| 2\u20133 | 15:0 | `selector` | GDT segment selector for handler (always `0x08` = kernel code) |\n| 4 | 7:0 | `reserved` | Must be zero; CPU behavior undefined otherwise |\n| 5 | 7:0 | `flags` | Gate type, DPL, present bit (see breakdown below) |\n| 6\u20137 | 15:0 | `offset_high` | Handler virtual address bits 31:16 |\n**Flags byte breakdown (byte 5):**\n| Bit(s) | Name | Interrupt Gate | Trap Gate |\n|---|---|---|---|\n| 7 | P (Present) | 1 | 1 |\n| 6:5 | DPL | 0 for kernel handlers; 3 for INT 0x80 in M4 | 3 for syscall gate |\n| 4 | 0 (reserved) | 0 | 0 |\n| 3:0 | Gate type | `0xE` (32-bit interrupt gate) | `0xF` (32-bit trap gate) |\n| **Full byte** | | **`0x8E`** (P=1, DPL=0, type=1110) | **`0x8F`** (P=1, DPL=0, type=1111) |\n**Gate type semantics:**\n- **Interrupt gate (`0x8E`):** CPU atomically clears EFLAGS.IF on entry, preventing re-entrant interrupts. Use for all hardware IRQ handlers and CPU exception handlers.\n- **Trap gate (`0x8F`):** EFLAGS.IF is preserved. Use for software-invoked vectors (INT 0x80 system call in M4). Not used in this milestone; all 256 entries use `0x8E`.\nC declaration:\n```c\n// idt.h\ntypedef struct {\n    uint16_t offset_low;  // Offset 0: handler bits 15:0\n    uint16_t selector;    // Offset 2: GDT selector (0x08)\n    uint8_t  reserved;    // Offset 4: always 0\n    uint8_t  flags;       // Offset 5: P, DPL, type\n    uint16_t offset_high; // Offset 6: handler bits 31:16\n} __attribute__((packed)) idt_entry_t;\n// Compile-time size verification\ntypedef char idt_entry_size_check[(sizeof(idt_entry_t) == 8) ? 1 : -1];\n```\n### 3.2 IDTR Pseudo-Descriptor (6 bytes)\nIdentical structure to GDTR:\n| Byte offset | Bits | Field | Value |\n|---|---|---|---|\n| 0\u20131 | 15:0 | `limit` | `256 * 8 - 1 = 2047` (0x07FF) |\n| 2\u20135 | 31:0 | `base` | Linear (physical before paging) address of `idt[0]` |\n```c\n// idt.h\ntypedef struct {\n    uint16_t limit;\n    uint32_t base;\n} __attribute__((packed)) idtr_t;\ntypedef char idtr_size_check[(sizeof(idtr_t) == 6) ? 1 : -1];\n```\n### 3.3 Interrupt Stack Frame\n{{DIAGRAM:tdd-diag-10}}\nThis is the single most important data structure in this milestone. The CPU pushes a partial frame automatically; the ISR stub pushes the rest. The final layout, after `isr_common_stub` executes through `push esp` (pointer to frame), must be:\n**Stack contents when `interrupt_dispatch` is called (ESP points to frame pointer argument):**\n```\nHigh address (pushed first, lower on stack)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 user_ss          \u2502 \u2190 only present on ring-3\u2192ring-0 privilege change (M4)\n\u2502 user_esp         \u2502 \u2190 only present on privilege change (M4)\n\u2502 eflags           \u2502 \u2190 pushed by CPU (always)\n\u2502 cs               \u2502 \u2190 pushed by CPU (always)\n\u2502 eip              \u2502 \u2190 pushed by CPU (return address)\n\u2502 err_code         \u2502 \u2190 pushed by CPU (exceptions 8,10-14) OR pushed as 0 by ISR_NOERR macro\n\u2502 int_no           \u2502 \u2190 pushed by ISR stub (0-255)\n\u2502 gs               \u2502 \u2190 pushed by isr_common_stub\n\u2502 fs               \u2502\n\u2502 es               \u2502\n\u2502 ds               \u2502\n\u2502 edi              \u2502 \u2190 pusha: EDI pushed last by pusha (lowest address in pusha block)\n\u2502 esi              \u2502\n\u2502 ebp              \u2502\n\u2502 esp_dummy        \u2502 \u2190 pusha pushes ESP value *before* pusha ran (not useful, pad)\n\u2502 ebx              \u2502\n\u2502 edx              \u2502\n\u2502 ecx              \u2502\n\u2502 eax              \u2502 \u2190 pusha: EAX pushed first by pusha (highest address in pusha block)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nLow address (ESP here when interrupt_dispatch is called with frame ptr)\n```\n**C struct mapping (byte offsets from the ESP value when interrupt_dispatch receives the pointer):**\n```c\n// interrupt.h\ntypedef struct {\n    // Pushed by pusha \u2014 offsets 0-31 (32 bytes)\n    uint32_t edi;        // offset 0\n    uint32_t esi;        // offset 4\n    uint32_t ebp;        // offset 8\n    uint32_t esp_dummy;  // offset 12 (ESP as it was before pusha \u2014 unreliable, ignore)\n    uint32_t ebx;        // offset 16\n    uint32_t edx;        // offset 20\n    uint32_t ecx;        // offset 24\n    uint32_t eax;        // offset 28\n    // Pushed by isr_common_stub \u2014 offsets 32-47 (16 bytes)\n    uint32_t ds;         // offset 32\n    uint32_t es;         // offset 36\n    uint32_t fs;         // offset 40\n    uint32_t gs;         // offset 44\n    // Pushed by ISR stub macros \u2014 offsets 48-55 (8 bytes)\n    uint32_t int_no;     // offset 48\n    uint32_t err_code;   // offset 52 (0 for exceptions that don't push one)\n    // Pushed by CPU \u2014 offsets 56-68 (12 bytes, same-privilege)\n    uint32_t eip;        // offset 56\n    uint32_t cs;         // offset 60\n    uint32_t eflags;     // offset 64\n    // Only present on privilege-level change (ring 3\u2192ring 0; M4 only):\n    uint32_t user_esp;   // offset 68\n    uint32_t user_ss;    // offset 72\n} __attribute__((packed)) interrupt_frame_t;\n```\n**Critical note on `pusha` register order:** The `pusha` instruction pushes registers in this order: EAX, ECX, EDX, EBX, ESP (pre-push value), EBP, ESI, EDI. Since the stack grows downward and each push decrements ESP first, the memory layout from low to high address after `pusha` is: EDI, ESI, EBP, ESP_dummy, EBX, EDX, ECX, EAX. The struct field order must match this exactly for the `push esp` frame pointer to be valid.\n### 3.4 Ring Buffer (PS/2 Keyboard)\n```c\n// keyboard.h\n#define KEYBOARD_BUF_SIZE 256  // Must be a power of 2 for modulo-via-AND optimization\ntypedef struct {\n    char    buf[KEYBOARD_BUF_SIZE];\n    uint8_t head;  // Next write position (producer: IRQ handler)\n    uint8_t tail;  // Next read position  (consumer: keyboard_getchar)\n} ring_buffer_t;\n```\n**Memory layout:**\n| Field | Offset | Size | Notes |\n|---|---|---|---|\n| `buf[0..255]` | 0 | 256 bytes | Character storage; indices wrap via `& (KEYBOARD_BUF_SIZE-1)` |\n| `head` | 256 | 1 byte | Wraps naturally at 256 (uint8_t overflow = modulo 256) |\n| `tail` | 257 | 1 byte | Wraps naturally at 256 |\n| _pad_ | 258 | 6 bytes | Compiler may insert; `sizeof(ring_buffer_t)` = 258 or 264 |\n**Invariants:**\n- Full condition: `(head + 1) % KEYBOARD_BUF_SIZE == tail` \u2014 equivalently `(uint8_t)(head + 1) == tail` since size=256=uint8_t overflow.\n- Empty condition: `head == tail`\n- Capacity: 255 characters (one slot always empty to distinguish full from empty)\n- **Thread safety:** Safe without atomics on single-core when producer is exclusively the IRQ handler and consumer is exclusively non-IRQ code. The IRQ handler cannot be re-entered (IF=0 inside interrupt gate). `volatile` must be applied to `head` and `tail` to prevent the compiler from caching them in registers.\n### 3.5 PIC State After Remapping\n**Master 8259A (ports 0x20/0x21):**\n| IRQ | Signal | Remapped Vector | Default Mask After Init |\n|---|---|---|---|\n| IRQ0 | PIT channel 0 timer | 32 (0x20) | **Unmasked** |\n| IRQ1 | PS/2 keyboard | 33 (0x21) | **Unmasked** |\n| IRQ2 | Cascade to slave | 34 | Unmasked (required for slave) |\n| IRQ3 | COM2 serial | 35 | Masked |\n| IRQ4 | COM1 serial | 36 | Masked |\n| IRQ5 | LPT2 | 37 | Masked |\n| IRQ6 | Floppy | 38 | Masked |\n| IRQ7 | LPT1 / Spurious | 39 | Masked |\n**Slave 8259A (ports 0xA0/0xA1):** All masked. IRQ8\u2013IRQ15 map to vectors 40\u201347.\n**Master data port mask value after `pic_init()`:** `0xFC` (binary: `1111 1100`) \u2014 unmasks IRQ0 (bit 0) and IRQ1 (bit 1), masks all others.\n**Slave data port mask value:** `0xFF` \u2014 all slave IRQs masked.\n---\n## 4. Interface Contracts\n### 4.1 IDT\n```c\n// idt.h\nvoid idt_set_gate(uint8_t vector, uint32_t handler_addr,\n                  uint16_t selector, uint8_t flags);\n```\n- **Preconditions:** `handler_addr` is a valid virtual address of an ISR stub defined in `isr_stubs.asm`; `selector` is `0x08` (kernel code segment); `flags` is `0x8E` for interrupt gates.\n- **Postconditions:** `idt[vector]` fully populated: `offset_low = handler_addr & 0xFFFF`, `selector = 0x08`, `reserved = 0`, `flags = flags`, `offset_high = (handler_addr >> 16) & 0xFFFF`.\n- **Errors:** None at runtime. Passing a null `handler_addr` is a programming error; the CPU will triple-fault when that vector fires.\n- **Thread safety:** Call only before `sti`.\n```c\nvoid idt_init(void);\n```\n- **Preconditions:** CPU in protected mode (CR0.PE=1); EFLAGS.IF=0; GDT loaded with valid kernel code descriptor at selector `0x08`.\n- **Postconditions:** All 256 `idt[]` entries populated with correct gate descriptors pointing to the corresponding `isr_0` through `isr_255` stubs; `idtr.limit = 2047`; `idtr.base = (uint32_t)idt`; `lidt` instruction executed.\n- **Errors:** No runtime error return. If called before GDT is valid, the `lidt` may succeed but `iretd` inside the first ISR will fault \u2014 verify GDT before calling.\n- **Side effects:** Writes to `idt[0..255]` and `idtr`; executes `lidt [idtr]` inline assembly.\n### 4.2 PIC\n```c\nvoid pic_remap(uint8_t master_offset, uint8_t slave_offset);\n```\n- **Preconditions:** EFLAGS.IF=0 (must not be called with interrupts enabled). `master_offset` must be `0x20` (32); `slave_offset` must be `0x28` (40). Both must be multiples of 8 (hardware requirement for PIC vector base alignment).\n- **Postconditions:** Both PICs reinitialised in 8086 mode; master IRQ0\u2013IRQ7 mapped to `master_offset` through `master_offset+7`; slave IRQ8\u2013IRQ15 mapped to `slave_offset` through `slave_offset+7`; saved masks restored to both PICs.\n- **Errors:** None returned. If ports 0x20/0xA0 are unresponsive (not possible in QEMU), ICW sequence will complete anyway with undefined PIC state.\n- **Side effects:** 8 `outb` calls to master ports, 8 `outb` calls to slave ports, 2 `inb` reads to save masks, 2 `outb` writes to restore masks, 10 `io_wait()` calls.\n```c\nvoid pic_send_eoi(uint8_t irq);\n```\n- **Preconditions:** `irq` is in range 0\u201315; must be called at end of every IRQ handler before `iret`. **Never** call for spurious IRQ7 or IRQ15 without checking ISR first.\n- **Postconditions:** If `irq < 8`: writes `0x20` to master command port (0x20). If `irq >= 8`: writes `0x20` to slave command port (0xA0) first, then `0x20` to master command port (0x20).\n- **Why both for slave IRQs:** The slave PIC signals the master through the cascade line (IRQ2). The master must release IRQ2, and the slave must release the slave IRQ. Both require their own EOI.\n```c\nuint16_t pic_get_isr(void);\n```\n- **Returns:** Bits 15:8 = slave ISR register; bits 7:0 = master ISR register. A set bit at position N indicates IRQ N is currently being serviced.\n- **Usage:** Called before processing IRQ7 or IRQ15 to detect spurious interrupts. If bit 7 (master) is not set when handling vector 39, it is spurious \u2014 do not send EOI to master, do not process. If bit 15 (slave) is not set when handling vector 47, it is spurious \u2014 send EOI to master only (the master's IRQ2 was asserted), not to slave.\n- **Implementation:** Issues `outb(0x20, 0x0B)` (OCW3: read ISR) and `outb(0xA0, 0x0B)`, then reads back the result. Requires a small delay between write and read on real hardware (covered by `io_wait`).\n### 4.3 PIT\n```c\nvoid pit_init(uint32_t frequency_hz);\n```\n- **Preconditions:** PIC remapping already done; `frequency_hz` in range 19\u20131193182 Hz (divisor must fit in uint16_t and be \u2265 1).\n- **Postconditions:** PIT channel 0 programmed in mode 3 (square wave); divisor = `1193182 / frequency_hz` (integer division, truncated); IRQ0 fires at approximately `frequency_hz` interrupts per second. `tick_counter` initialized to 0.\n- **At 100 Hz:** divisor = `1193182 / 100 = 11931` (QEMU timer is accurate to < 0.05% at this divisor; 11932 is equally valid \u2014 choose one and document it).\n- **Errors:** If `frequency_hz` is 0, the expression is undefined. Guard: `if (frequency_hz == 0) frequency_hz = 100;`.\n- **Accuracy:** At divisor 11932: actual frequency = 1193182 / 11932 \u2248 99.997 Hz (error < 0.003%). This is within the \u00b10.5% performance target.\n```c\nuint64_t pit_get_ticks(void);\nuint64_t pit_get_ms(void);\n```\n- `pit_get_ticks()`: Returns `tick_counter` atomically. On single-core x86 with IF=0 or a single reader, a simple load of a `volatile uint64_t` is safe. However, since `tick_counter` is 64-bit and reads are 32-bit operations on x86-32, there is a read-tearing risk: the high word might be stale. **Guard:** either disable interrupts around the read, or use two separate `uint32_t` fields and detect carry.\n  Recommended implementation for M2 (single-core, correctness over performance):\n  ```c\n  uint64_t pit_get_ticks(void) {\n      uint32_t lo, hi;\n      __asm__ volatile (\"cli\");\n      lo = (uint32_t)(tick_counter & 0xFFFFFFFF);\n      hi = (uint32_t)(tick_counter >> 32);\n      __asm__ volatile (\"sti\");\n      return ((uint64_t)hi << 32) | lo;\n  }\n  ```\n- `pit_get_ms()`: Returns `pit_get_ticks() * 10` at 100 Hz (each tick = 10 ms).\n### 4.4 Keyboard\n```c\nvoid keyboard_handler(interrupt_frame_t *frame);\n```\n- **Preconditions:** Called from `irq_dispatch` with IRQ number 1. EFLAGS.IF=0 (inside interrupt gate). Port 0x60 has a byte ready to read.\n- **Postconditions:** Scancode read from port 0x60 (consuming it from the PS/2 controller's buffer). If break code (bit 7 set): modifier state updated if applicable; function returns without pushing to ring buffer. If make code: converted to ASCII via scancode table; if ASCII != 0, `ring_push` called. Modifier state (shift, ctrl, alt) updated as appropriate.\n- **Errors:** If ring buffer is full, character is silently dropped. No error return.\n- **Side effects:** Reads port 0x60 (consuming the scancode \u2014 **must always be read**, even if result is discarded, or the PS/2 controller stalls).\n```c\nchar keyboard_getchar(void);\n```\n- **Behavior:** Blocking. Spins calling `__asm__ volatile (\"hlt\")` in a loop while `ring_empty()` is true. When a character is available, calls `ring_pop()` and returns it.\n- **Preconditions:** EFLAGS.IF=1 (interrupts must be enabled, or `hlt` will never be interrupted and the function will block forever).\n- **Returns:** ASCII character (non-zero); never returns 0.\n- **Blocking behavior:** `hlt` reduces CPU load to near-zero while waiting. The timer or keyboard interrupt will wake the CPU.\n---\n## 5. Algorithm Specification\n### 5.1 ISR Stub Generation (NASM Macros)\n{{DIAGRAM:tdd-diag-11}}\nThe goal is 256 stubs with a **uniform stack frame** regardless of whether the CPU pushes an error code. The solution: ISR_NOERR pushes a fake zero error code; ISR_ERR does not (CPU already pushed the real one). Both then push the interrupt number and jump to the shared `isr_common_stub`.\n**Exceptions that push an error code (use ISR_ERR):** 8, 10, 11, 12, 13, 14, 17. All others (0\u20137, 9, 15, 16, 18\u201331, 32\u2013255) use ISR_NOERR.\n```nasm\n; isr_stubs.asm\n[BITS 32]\n; \u2500\u2500\u2500 Macro definitions \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n%macro ISR_NOERR 1\n[GLOBAL isr_%1]\nisr_%1:\n    push dword 0        ; fake error code \u2014 makes stack frame uniform\n    push dword %1       ; interrupt number\n    jmp  isr_common_stub\n%endmacro\n%macro ISR_ERR 1\n[GLOBAL isr_%1]\nisr_%1:\n                        ; CPU has already pushed error code onto stack\n    push dword %1       ; interrupt number\n    jmp  isr_common_stub\n%endmacro\n; \u2500\u2500\u2500 CPU Exceptions 0\u201331 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nISR_NOERR  0    ; #DE Divide Error\nISR_NOERR  1    ; #DB Debug\nISR_NOERR  2    ; NMI\nISR_NOERR  3    ; #BP Breakpoint\nISR_NOERR  4    ; #OF Overflow\nISR_NOERR  5    ; #BR BOUND Range Exceeded\nISR_NOERR  6    ; #UD Invalid Opcode\nISR_NOERR  7    ; #NM Device Not Available (FPU)\nISR_ERR    8    ; #DF Double Fault          (error code = 0, always)\nISR_NOERR  9    ; Coprocessor Segment Overrun (obsolete)\nISR_ERR   10    ; #TS Invalid TSS\nISR_ERR   11    ; #NP Segment Not Present\nISR_ERR   12    ; #SS Stack Fault\nISR_ERR   13    ; #GP General Protection Fault\nISR_ERR   14    ; #PF Page Fault\nISR_NOERR 15    ; Reserved\nISR_NOERR 16    ; #MF x87 Floating-Point Exception\nISR_ERR   17    ; #AC Alignment Check\nISR_NOERR 18    ; #MC Machine Check\nISR_NOERR 19    ; #XF SIMD Floating-Point Exception\nISR_NOERR 20    ; Reserved\nISR_NOERR 21    ; Reserved\nISR_NOERR 22    ; Reserved\nISR_NOERR 23    ; Reserved\nISR_NOERR 24    ; Reserved\nISR_NOERR 25    ; Reserved\nISR_NOERR 26    ; Reserved\nISR_NOERR 27    ; Reserved\nISR_NOERR 28    ; Reserved\nISR_NOERR 29    ; Reserved\nISR_NOERR 30    ; #SX Security Exception\nISR_NOERR 31    ; Reserved\n; \u2500\u2500\u2500 Hardware IRQs 32\u201347 (after PIC remapping) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n; CPU never pushes error codes for hardware interrupts\nISR_NOERR 32    ; IRQ0: PIT Timer\nISR_NOERR 33    ; IRQ1: PS/2 Keyboard\nISR_NOERR 34    ; IRQ2: PIC Cascade (should not fire normally)\nISR_NOERR 35    ; IRQ3: COM2\nISR_NOERR 36    ; IRQ4: COM1\nISR_NOERR 37    ; IRQ5: LPT2\nISR_NOERR 38    ; IRQ6: Floppy\nISR_NOERR 39    ; IRQ7: LPT1 / Spurious Master\nISR_NOERR 40    ; IRQ8: RTC\nISR_NOERR 41    ; IRQ9: ACPI\nISR_NOERR 42    ; IRQ10: Available\nISR_NOERR 43    ; IRQ11: Available\nISR_NOERR 44    ; IRQ12: PS/2 Mouse\nISR_NOERR 45    ; IRQ13: FPU / Coprocessor\nISR_NOERR 46    ; IRQ14: Primary ATA\nISR_NOERR 47    ; IRQ15: Secondary ATA / Spurious Slave\n; \u2500\u2500\u2500 Vectors 48\u2013255: unhandled; dispatch will print warning and return \u2500\u2500\u2500\u2500\u2500\u2500\n; Generate remaining stubs with NASM %rep\n%assign i 48\n%rep 208\nISR_NOERR i\n%assign i i+1\n%endrep\n```\n### 5.2 `isr_common_stub` \u2014 The Unified Entry/Exit Path\n```nasm\n; isr_common_stub \u2014 entered from all 256 ISR stubs via 'jmp isr_common_stub'\n; Stack state on entry:\n;   [ESP+0]  = int_no     (pushed by ISR stub)\n;   [ESP+4]  = err_code   (pushed by CPU for ERR exceptions, or 0 by ISR_NOERR)\n;   [ESP+8]  = EIP        (pushed by CPU)\n;   [ESP+12] = CS         (pushed by CPU)\n;   [ESP+16] = EFLAGS     (pushed by CPU)\n;   [ESP+20] = user_ESP   (only if privilege change; otherwise not present)\n;   [ESP+24] = user_SS    (only if privilege change)\n[EXTERN interrupt_dispatch]\nisr_common_stub:\n    ; \u2500\u2500 1. Save all general-purpose registers \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    ; pusha pushes: EAX, ECX, EDX, EBX, ESP(before), EBP, ESI, EDI\n    ; After pusha, stack layout (low\u2192high): EDI,ESI,EBP,ESP_dummy,EBX,EDX,ECX,EAX,...\n    pusha\n    ; \u2500\u2500 2. Save segment registers \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    ; Push as 32-bit values (push the 16-bit register zero-extended)\n    push ds\n    push es\n    push fs\n    push gs\n    ; \u2500\u2500 3. Load kernel data segments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    ; Interrupt may have fired while user-mode code ran (M4). In M2 (kernel-only),\n    ; DS is already 0x10, but establishing this explicitly is future-safe.\n    mov  ax, 0x10\n    mov  ds, ax\n    mov  es, ax\n    mov  fs, ax\n    mov  gs, ax\n    ; \u2500\u2500 4. Pass frame pointer to C handler \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    ; ESP currently points to the base of the saved frame (just after push gs).\n    ; Passing ESP as a pointer to interrupt_frame_t.\n    push esp                          ; argument: pointer to interrupt_frame_t\n    call interrupt_dispatch\n    add  esp, 4                       ; callee-saved via cdecl; clean up argument\n    ; \u2500\u2500 5. Restore segment registers \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    pop  gs\n    pop  fs\n    pop  es\n    pop  ds\n    ; \u2500\u2500 6. Restore general-purpose registers \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    popa\n    ; \u2500\u2500 7. Remove int_no and err_code from stack \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    ; These were pushed by the ISR stub (8 bytes total)\n    add  esp, 8\n    ; \u2500\u2500 8. Return from interrupt \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    ; iretd pops EIP, CS, EFLAGS (and ESP, SS if privilege change occurred)\n    iretd\n```\n**Stack verification trace (M2, kernel-only, no privilege change):**\nAfter `push int_no` and `push err_code` in the stub, before `isr_common_stub` runs:\n- ESP = X\n- [X+0]: int_no, [X+4]: err_code, [X+8]: EIP, [X+12]: CS, [X+16]: EFLAGS\nAfter `pusha` (pushes 8 \u00d7 4 = 32 bytes):\n- ESP = X - 32\n- [X-32]: EDI through [X-4+28=X+24]: EAX (pusha layout above)\nAfter 4 segment register pushes (16 bytes):\n- ESP = X - 48\n- [X-48]: GS, [X-44]: FS, [X-40]: ES, [X-36]: DS\nAfter `push esp`:\n- ESP = X - 52\n- [X-52]: (X - 48) = pointer to interrupt_frame_t\nWhen `interrupt_dispatch(frame)` runs, `frame` points to the GS field. The `interrupt_frame_t` struct aligns with this: EDI at offset 0 means GS push is offset 44, DS is offset 32 \u2014 **wait, this reverses the order**. The struct must list fields in the same order as the ACTUAL stack layout from low address to high:\nThe stack, from LOW address (current ESP) to HIGH address after all pushes:\n- [lowest] GS \u2192 [+4] FS \u2192 [+8] ES \u2192 [+12] DS (segment regs, pushed last)\n- [+16] EDI, [+20] ESI, [+24] EBP, [+28] ESP_dummy, [+32] EBX, [+36] EDX, [+40] ECX, [+44] EAX (from pusha \u2014 EDI is lowest because pusha pushed EAX first, then... see below)\n**Critical clarification on `pusha` stack order:** `pusha` pushes in this fixed order: EAX, ECX, EDX, EBX, original-ESP, EBP, ESI, EDI. Each push decrements ESP then stores. So after `pusha`:\n- [ESP+0]  = EDI (last pushed = lowest address)\n- [ESP+4]  = ESI\n- [ESP+8]  = EBP\n- [ESP+12] = ESP_dummy (original ESP value before pusha)\n- [ESP+16] = EBX\n- [ESP+20] = EDX\n- [ESP+24] = ECX\n- [ESP+28] = EAX (first pushed by pusha = highest address in pusha block)\nSo the complete frame from ESP after all pushes (before `push esp`):\n```\nESP+0:  GS         \u2190 frame->gs     (pushed last of seg regs)\nESP+4:  FS         \u2190 frame->fs\nESP+8:  ES         \u2190 frame->es\nESP+12: DS         \u2190 frame->ds\nESP+16: EDI        \u2190 frame->edi\nESP+20: ESI        \u2190 frame->esi\nESP+24: EBP        \u2190 frame->ebp\nESP+28: ESP_dummy  \u2190 frame->esp_dummy\nESP+32: EBX        \u2190 frame->ebx\nESP+36: EDX        \u2190 frame->edx\nESP+40: ECX        \u2190 frame->ecx\nESP+44: EAX        \u2190 frame->eax\nESP+48: int_no     \u2190 frame->int_no\nESP+52: err_code   \u2190 frame->err_code\nESP+56: EIP        \u2190 frame->eip\nESP+60: CS         \u2190 frame->cs\nESP+64: EFLAGS     \u2190 frame->eflags\n```\nUpdate `interrupt_frame_t` to match this exact layout:\n```c\ntypedef struct {\n    uint32_t gs;         // offset 0  \u2014 pushed last by isr_common_stub\n    uint32_t fs;         // offset 4\n    uint32_t es;         // offset 8\n    uint32_t ds;         // offset 12\n    uint32_t edi;        // offset 16 \u2014 pusha: EDI at lowest address\n    uint32_t esi;        // offset 20\n    uint32_t ebp;        // offset 24\n    uint32_t esp_dummy;  // offset 28\n    uint32_t ebx;        // offset 32\n    uint32_t edx;        // offset 36\n    uint32_t ecx;        // offset 40\n    uint32_t eax;        // offset 44 \u2014 pusha: EAX at highest address\n    uint32_t int_no;     // offset 48 \u2014 pushed by ISR stub\n    uint32_t err_code;   // offset 52\n    uint32_t eip;        // offset 56 \u2014 pushed by CPU\n    uint32_t cs;         // offset 60\n    uint32_t eflags;     // offset 64\n    uint32_t user_esp;   // offset 68 \u2014 only on privilege change (M4)\n    uint32_t user_ss;    // offset 72\n} __attribute__((packed)) interrupt_frame_t;\n```\n### 5.3 PIC Remapping \u2014 ICW Sequence\n{{DIAGRAM:tdd-diag-12}}\nThe 8259A requires a precise initialization sequence. Writing to port 0x20 or 0xA0 with bit 4 set triggers initialization mode; subsequent writes to the data ports (0x21, 0xA1) are treated as ICW2, ICW3, ICW4 in order.\n```c\nvoid pic_remap(uint8_t master_offset, uint8_t slave_offset) {\n    // Save existing interrupt masks\n    uint8_t master_mask = inb(0x21);\n    uint8_t slave_mask  = inb(0xA1);\n    // ICW1: Initialize both PICs (cascade mode, ICW4 required)\n    // Bit 4 (0x10) = initialization command\n    // Bit 0 (0x01) = ICW4 will be sent\n    outb(0x20, 0x11); io_wait();   // Master ICW1\n    outb(0xA0, 0x11); io_wait();   // Slave ICW1\n    // ICW2: Set interrupt vector offsets\n    outb(0x21, master_offset); io_wait();  // Master: IRQ0 \u2192 vector 32\n    outb(0xA1, slave_offset);  io_wait();  // Slave:  IRQ8 \u2192 vector 40\n    // ICW3: Cascade configuration\n    // Master: tell it the slave is connected at IRQ2 (bit 2 = 0b00000100)\n    outb(0x21, 0x04); io_wait();\n    // Slave: cascade identity = 2 (connected to master IRQ2, binary value)\n    outb(0xA1, 0x02); io_wait();\n    // ICW4: Set 8086/88 mode (required for modern operation)\n    // Bit 0 (0x01) = 8086 mode (as opposed to MCS-80 mode)\n    outb(0x21, 0x01); io_wait();\n    outb(0xA1, 0x01); io_wait();\n    // Restore masks\n    outb(0x21, master_mask);\n    outb(0xA1, slave_mask);\n}\n```\n**`io_wait()` implementation:**\n```c\nstatic inline void io_wait(void) {\n    // Write to unused port 0x80 \u2014 introduces ~1\u20134 \u00b5s delay on real hardware\n    // Port 0x80 is used by BIOS POST diagnostic codes; safe to write on modern hardware\n    outb(0x80, 0x00);\n}\n```\n**Why ICW3 values differ:** The master PIC's ICW3 is a bitmask \u2014 bit N set means a slave PIC is connected to IRQ N. Value `0x04` = bit 2 set = slave on IRQ2. The slave PIC's ICW3 is a binary number \u2014 its cascade identity (which IRQ line of the master it's connected to). Value `0x02` = IRQ2.\n### 5.4 EOI Protocol\n```c\nvoid pic_send_eoi(uint8_t irq) {\n    // For slave IRQs (8\u201315): must EOI the slave first, then the master\n    // The slave signals through the master's IRQ2 cascade line.\n    // Failure to EOI slave: slave re-asserts IRQ2 immediately.\n    // Failure to EOI master: master blocks all further interrupts at IRQ2 priority.\n    if (irq >= 8) {\n        outb(0xA0, 0x20);  // Slave EOI (non-specific: clears current ISR bit)\n    }\n    outb(0x20, 0x20);      // Master EOI (always required)\n}\n```\n**Spurious IRQ handling:**\n```c\nuint16_t pic_get_isr(void) {\n    outb(0x20, 0x0B);  // OCW3 to master: read ISR\n    outb(0xA0, 0x0B);  // OCW3 to slave: read ISR\n    io_wait();\n    return ((uint16_t)inb(0xA0) << 8) | inb(0x20);\n}\n// In irq_dispatch, before processing IRQ7 or IRQ15:\nstatic void handle_irq7_spurious(void) {\n    uint16_t isr = pic_get_isr();\n    if (!(isr & (1 << 7))) {\n        // Spurious: master IRQ7 not actually asserted\n        // Do NOT send EOI \u2014 the PIC did not set the ISR bit\n        return;\n    }\n    // Real IRQ7 (LPT1) \u2014 process normally and send EOI\n    pic_send_eoi(7);\n}\nstatic void handle_irq15_spurious(void) {\n    uint16_t isr = pic_get_isr();\n    if (!(isr & (1 << 15))) {\n        // Spurious slave IRQ15: slave ISR bit not set\n        // Send EOI only to master (master's IRQ2 was asserted by the spurious slave signal)\n        outb(0x20, 0x20);  // Master EOI only \u2014 slave gets nothing\n        return;\n    }\n    pic_send_eoi(15);\n}\n```\n### 5.5 PIT Initialization\n{{DIAGRAM:tdd-diag-13}}\n```c\n// pit.c\n#define PIT_CHANNEL0_DATA  0x40\n#define PIT_COMMAND        0x43\n#define PIT_BASE_FREQ      1193182  // Hz\nvolatile uint64_t tick_counter = 0;\nvoid pit_init(uint32_t frequency_hz) {\n    if (frequency_hz == 0) frequency_hz = 100;\n    uint16_t divisor = (uint16_t)(PIT_BASE_FREQ / frequency_hz);\n    // Command byte: 0x36\n    // Bits 7:6 = 00 \u2192 channel 0\n    // Bits 5:4 = 11 \u2192 access mode: lobyte/hibyte (write low byte then high byte)\n    // Bits 3:1 = 011 \u2192 mode 3 (square wave generator, auto-reload)\n    // Bit 0    = 0   \u2192 binary counting (not BCD)\n    outb(PIT_COMMAND, 0x36);\n    // Write divisor: low byte first, then high byte\n    outb(PIT_CHANNEL0_DATA, (uint8_t)(divisor & 0xFF));\n    outb(PIT_CHANNEL0_DATA, (uint8_t)((divisor >> 8) & 0xFF));\n}\n```\n**Timer ISR (registered in interrupt_dispatch):**\n```c\n// pit.c\nvoid timer_handler(interrupt_frame_t *frame) {\n    (void)frame;        // Unused in M2; used by scheduler in M4\n    tick_counter++;\n    // NOTE: pic_send_eoi(0) is called by irq_dispatch AFTER this returns\n}\n```\n**Why `volatile uint64_t tick_counter`:** The IRQ handler (which runs asynchronously from the perspective of non-IRQ code) increments `tick_counter`. Non-IRQ code reads it. Without `volatile`, the compiler may legally hoist the read out of a polling loop, caching it in a register indefinitely. `volatile` forces a memory read on every access. The 64-bit width requires two 32-bit reads on x86-32; protect against tearing as described in \u00a74.3.\n### 5.6 Interrupt Dispatch C Handler\n```c\n// interrupt.c\nstatic const char *exception_names[32] = {\n    \"Division Error (#DE)\",            // 0\n    \"Debug (#DB)\",                     // 1\n    \"Non-Maskable Interrupt\",          // 2\n    \"Breakpoint (#BP)\",                // 3\n    \"Overflow (#OF)\",                  // 4\n    \"BOUND Range Exceeded (#BR)\",      // 5\n    \"Invalid Opcode (#UD)\",            // 6\n    \"Device Not Available (#NM)\",      // 7\n    \"Double Fault (#DF)\",              // 8\n    \"Coprocessor Segment Overrun\",     // 9\n    \"Invalid TSS (#TS)\",               // 10\n    \"Segment Not Present (#NP)\",       // 11\n    \"Stack Fault (#SS)\",               // 12\n    \"General Protection Fault (#GP)\",  // 13\n    \"Page Fault (#PF)\",                // 14\n    \"Reserved\",                        // 15\n    \"x87 Floating-Point (#MF)\",        // 16\n    \"Alignment Check (#AC)\",           // 17\n    \"Machine Check (#MC)\",             // 18\n    \"SIMD Floating-Point (#XF)\",       // 19\n    \"Reserved\", \"Reserved\", \"Reserved\", \"Reserved\",  // 20-23\n    \"Reserved\", \"Reserved\", \"Reserved\", \"Reserved\",  // 24-27\n    \"Reserved\", \"Reserved\",            // 28-29\n    \"Security Exception (#SX)\",        // 30\n    \"Reserved\",                        // 31\n};\nvoid interrupt_dispatch(interrupt_frame_t *frame) {\n    uint32_t vec = frame->int_no;\n    if (vec < 32) {\n        // CPU exception\n        kprintf(\"\\n[EXCEPTION #%u: %s]\\n\", vec, exception_names[vec]);\n        kprintf(\"  EIP=0x%p  CS=0x%x  EFLAGS=0x%x\\n\",\n                frame->eip, frame->cs, frame->eflags);\n        kprintf(\"  EAX=0x%x EBX=0x%x ECX=0x%x EDX=0x%x\\n\",\n                frame->eax, frame->ebx, frame->ecx, frame->edx);\n        kprintf(\"  ESI=0x%x EDI=0x%x EBP=0x%x\\n\",\n                frame->esi, frame->edi, frame->ebp);\n        kprintf(\"  Error code: 0x%x\\n\", frame->err_code);\n        if (vec == 14) {\n            // Page fault: CR2 contains the faulting virtual address\n            uint32_t cr2;\n            __asm__ volatile (\"mov %0, cr2\" : \"=r\"(cr2));\n            kprintf(\"  Page fault address: 0x%p\\n\", cr2);\n            kprintf(\"  Flags: P=%u W=%u U=%u RSVD=%u ID=%u\\n\",\n                    frame->err_code & 1,\n                    (frame->err_code >> 1) & 1,\n                    (frame->err_code >> 2) & 1,\n                    (frame->err_code >> 3) & 1,\n                    (frame->err_code >> 4) & 1);\n        }\n        if (vec == 8) {\n            // Double fault: irrecoverable \u2014 halt immediately\n            kprintf(\"  DOUBLE FAULT \u2014 system halted (stack may be corrupt)\\n\");\n            __asm__ volatile (\"cli; hlt\");\n            for (;;) __asm__ volatile (\"hlt\");\n        }\n        // All other exceptions: halt (no process termination in M2)\n        kprintf(\"  System halted.\\n\");\n        __asm__ volatile (\"cli\");\n        for (;;) __asm__ volatile (\"hlt\");\n    } else if (vec < 48) {\n        // Hardware IRQ (vectors 32\u201347 = IRQ0\u2013IRQ15)\n        irq_dispatch((uint8_t)(vec - 32), frame);\n    } else {\n        // Unhandled vector 48\u2013255: log and continue\n        kprintf(\"[IRQ] Unhandled vector %u \u2014 ignored\\n\", vec);\n    }\n}\nvoid irq_dispatch(uint8_t irq, interrupt_frame_t *frame) {\n    switch (irq) {\n        case 0:  timer_handler(frame);    break;\n        case 1:  keyboard_handler(frame); break;\n        case 7:  handle_irq7_spurious();  return; // EOI handled inside\n        case 15: handle_irq15_spurious(); return; // EOI handled inside\n        default: break; // Unhandled IRQ: send EOI and continue\n    }\n    pic_send_eoi(irq);\n}\n```\n### 5.7 PS/2 Keyboard Driver\n{{DIAGRAM:tdd-diag-14}}\n**Scancode Set 1 \u2192 ASCII table (make codes 0x00\u20130x58):**\n```c\n// keyboard.c\nstatic const char scancode_ascii[128] = {\n/*00*/  0,   27,  '1', '2', '3', '4', '5', '6',   // 0x00\u20130x07\n/*08*/  '7', '8', '9', '0', '-', '=', '\\b', '\\t',  // 0x08\u20130x0F\n/*10*/  'q', 'w', 'e', 'r', 't', 'y', 'u', 'i',   // 0x10\u20130x17\n/*18*/  'o', 'p', '[', ']', '\\n', 0,  'a', 's',    // 0x18\u20130x1F (0x1D=LCTRL)\n/*20*/  'd', 'f', 'g', 'h', 'j', 'k', 'l', ';',   // 0x20\u20130x27\n/*28*/  '\\'','`',  0,  '\\\\','z', 'x', 'c', 'v',   // 0x28\u20130x2F (0x2A=LSHIFT)\n/*30*/  'b', 'n', 'm', ',', '.', '/', 0,   '*',    // 0x30\u20130x37 (0x36=RSHIFT)\n/*38*/  0,   ' ', 0,   0,   0,   0,   0,   0,      // 0x38\u20130x3F (0x38=LALT, 0x3A=CAPS)\n/*40*/  0,   0,   0,   0,   0,   0,   0,   '7',    // 0x40\u20130x47 (F1-F10, numpad)\n/*48*/  '8', '9', '-', '4', '5', '6', '+', '1',   // 0x48\u20130x4F\n/*50*/  '2', '3', '0', '.', 0,   0,   0,   0,      // 0x50\u20130x57\n/*58*/  0,                                          // 0x58\u20130x7F all 0\n        [0x59 ... 0x7F] = 0\n};\nstatic const char scancode_ascii_shift[128] = {\n/*00*/  0,   27,  '!', '@', '#', '$', '%', '^',\n/*08*/  '&', '*', '(', ')', '_', '+', '\\b', '\\t',\n/*10*/  'Q', 'W', 'E', 'R', 'T', 'Y', 'U', 'I',\n/*18*/  'O', 'P', '{', '}', '\\n', 0,  'A', 'S',\n/*20*/  'D', 'F', 'G', 'H', 'J', 'K', 'L', ':',\n/*28*/  '\"', '~',  0,  '|', 'Z', 'X', 'C', 'V',\n/*30*/  'B', 'N', 'M', '<', '>', '?', 0,   '*',\n/*38*/  0,   ' ', 0,   0,   0,   0,   0,   0,\n/*40*/  0,   0,   0,   0,   0,   0,   0,   '7',\n/*48*/  '8', '9', '-', '4', '5', '6', '+', '1',\n/*50*/  '2', '3', '0', '.', 0,   0,   0,   0,\n/*58*/  0,\n        [0x59 ... 0x7F] = 0\n};\n// Modifier scancode constants (Set 1 make codes)\n#define SC_LSHIFT  0x2A\n#define SC_RSHIFT  0x36\n#define SC_LCTRL   0x1D\n#define SC_LALT    0x38\n#define SC_CAPSLOCK 0x3A\nstatic volatile int shift_down  = 0;\nstatic volatile int ctrl_down   = 0;\nstatic volatile int alt_down    = 0;\nstatic volatile int caps_active = 0;\nstatic ring_buffer_t kbd_ring = {0};\nvoid keyboard_handler(interrupt_frame_t *frame) {\n    (void)frame;\n    // MUST read port 0x60 unconditionally \u2014 PS/2 controller stalls if not read\n    uint8_t sc = inb(0x60);\n    uint8_t key    = sc & 0x7F;  // Strip break bit to get key code\n    int     is_break = (sc & 0x80) != 0;  // Bit 7 set = key release\n    if (is_break) {\n        // Key release: update modifier state only\n        if (key == SC_LSHIFT || key == SC_RSHIFT) shift_down = 0;\n        if (key == SC_LCTRL)  ctrl_down = 0;\n        if (key == SC_LALT)   alt_down  = 0;\n        // Note: CapsLock does not reset on break \u2014 it toggles on make only\n        return;\n    }\n    // Key press (make code)\n    if (key == SC_LSHIFT || key == SC_RSHIFT) { shift_down = 1; return; }\n    if (key == SC_LCTRL)  { ctrl_down  = 1; return; }\n    if (key == SC_LALT)   { alt_down   = 1; return; }\n    if (key == SC_CAPSLOCK) {\n        caps_active ^= 1;  // Toggle\n        return;\n    }\n    // Translate to ASCII\n    int use_upper = shift_down ^ caps_active;  // XOR: shift inverts caps\n    char ascii = use_upper ? scancode_ascii_shift[key] : scancode_ascii[key];\n    if (ascii != 0) {\n        // Push to ring buffer; silently drop if full\n        uint8_t next_head = (uint8_t)(kbd_ring.head + 1);\n        if (next_head != kbd_ring.tail) {  // Not full\n            kbd_ring.buf[kbd_ring.head] = ascii;\n            kbd_ring.head = next_head;\n        }\n        // If full: drop. No error signaling in M2.\n    }\n    // pic_send_eoi(1) called by irq_dispatch after return\n}\nchar keyboard_getchar(void) {\n    // Spin until ring buffer is non-empty\n    while (kbd_ring.head == kbd_ring.tail) {\n        // hlt: halt CPU until next interrupt; reduces power consumption\n        // Requires EFLAGS.IF=1 (guaranteed by the time this is called)\n        __asm__ volatile (\"hlt\");\n    }\n    char c = kbd_ring.buf[kbd_ring.tail];\n    kbd_ring.tail = (uint8_t)(kbd_ring.tail + 1);\n    return c;\n}\n```\n**Ring buffer full/empty condition explanation with KEYBOARD_BUF_SIZE=256:**\nSince `head` and `tail` are `uint8_t`, they wrap automatically at 256 via arithmetic overflow \u2014 equivalent to `% 256` but free. Full condition: `(uint8_t)(head + 1) == tail`. Empty condition: `head == tail`. This naturally uses 255 of 256 slots (one always sacrificed to distinguish states). No masking needed because 256 = 2^8 = uint8_t range.\n---\n## 6. Error Handling Matrix\n| Error | Detection Point | Recovery | User-Visible? |\n|---|---|---|---|\n| `sti` before PIC remapping: IRQ0 fires at vector 8 (#DF) | First timer tick after `sti` | Triple fault \u2192 machine reset | Silent QEMU reset; QEMU `-d int` shows `v=08` followed by `v=08` (double fault on double fault) |\n| IDT entry not installed for a vector that fires | CPU reads zero-filled descriptor (P=0) | General protection fault \u2192 double fault \u2192 triple fault | Silent reset; QEMU `-d int` shows `v=0d` then `v=08` |\n| `pusha`/`popa` misordered or missing | Register corruption in interrupted code | Undefined behavior; may not crash immediately | Random crashes in unrelated code paths, hours later |\n| EOI never sent (missing `pic_send_eoi`) | PIC ISR bit stays set; no further IRQs delivered | System appears to run but timer never fires again | Timer-dependent tests hang; keyboard appears dead |\n| Break code not checked (bit 7): passed to table lookup | `scancode_ascii[sc]` where `sc >= 0x80` \u2192 always 0 (table is 128 bytes) | Silently dropped (returns 0 from table) | Only lost break detection; no crash. Modifiers would never release \u2192 sticky Shift |\n| Error-code exception (e.g., #GP=13) handled by ISR_NOERR stub | ISR_NOERR pushes `0` then `int_no` when CPU already pushed error code | Stack frame shifted by 4 bytes; EIP reads as error code; CS reads as EIP | Wrong EIP in diagnostic; return to garbage address; likely fault |\n| Stack pointer corrupted before exception | Stack too small or ESP overwritten by bug | Double fault (CPU can't push frame); triple fault if TSS-less double fault handler also faults | Silent reset |\n| `volatile` missing from `tick_counter` | Compiler hoists read into register; loop never sees updates | Infinite loop in `pit_get_ticks` polling loop | Tests that poll `pit_get_ticks` hang indefinitely |\n| Spurious IRQ7 handled as real (EOI sent): no effect in M2 | IRQ7 fires occasionally; ISR bit not set | Harmless in M2 (no handler action; spurious EOI to master is benign) | No visible effect; becomes issue when LPT1 added |\n| Spurious IRQ15 EOI sent to slave: slave ISR bit not set | Slave receives spurious EOI; undefined state | Slave may behave erratically for subsequent slave IRQs | Slave IRQs (ATA, PS/2 mouse) may misfire; not observable in M2 since all slave IRQs are masked |\n| `keyboard_getchar()` called before `sti` | `hlt` never exits; EFLAGS.IF=0 | Hang | Console appears frozen |\n| PIC ICW sequence sent with interrupts enabled | IRQ fires mid-initialization; PIC is in inconsistent state | Random interrupt routing; unpredictable vector assignment | Unpredictable exception or wrong handler called |\n| NASM `%rep` count wrong (not 208 for vectors 48\u2013255) | Missing or extra ISR stubs; IDT entries point to wrong addresses | Some vectors unhandled or mishandled | Vector-specific bugs |\n---\n## 7. Implementation Sequence with Checkpoints\n### Phase 1 \u2014 IDT structure + `idt_set_gate` + `lidt` (2\u20133 hours)\n1. Create `idt.h` with `idt_entry_t`, `idtr_t`, and compile-time size assertions.\n2. Create `idt.c` with `static idt_entry_t idt[256]` and `static idtr_t idtr` in `.bss`/`.data` sections.\n3. Implement `idt_set_gate` exactly as specified (byte-level field assignment).\n4. Implement `idt_init` skeleton: call `idt_set_gate(0, 0, 0x08, 0x8E)` for all 256 entries (placeholder handler address 0 \u2014 intentionally invalid, will fix in Phase 2). Load IDTR via `lidt` inline assembly.\n5. Call `idt_init()` from `kernel_main` **before** `sti` (which is still never called in this phase).\n**Checkpoint 1:** `make run` with `qemu -d int`. GDB: `x/16xb &idt[13]` \u2014 should show `00 00 08 00 00 8E 00 00` (offset=0, selector=0x08, reserved=0, flags=0x8E, offset_high=0). `info registers` shows no change (IDT loaded but `sti` not called; no interrupts fire). QEMU `-d int` should show zero exception entries during boot.\n---\n### Phase 2 \u2014 ISR Assembly Stubs + `isr_common_stub` (4\u20136 hours)\n1. Create `isr_stubs.asm` with `ISR_NOERR` and `ISR_ERR` macros as specified.\n2. Expand all 256 stubs (0\u201331 CPU exceptions with correct NOERR/ERR assignment; 32\u201347 IRQs; 48\u2013255 via `%rep`).\n3. Implement `isr_common_stub` as specified with `pusha`, segment saves, kernel segment load, `push esp`, `call interrupt_dispatch`, cleanup, `popa`, `add esp, 8`, `iretd`.\n4. Create `interrupt.h` with `interrupt_frame_t` struct (exact byte-offset layout verified against \u00a75.2).\n5. Create stub `interrupt.c` with `interrupt_dispatch` that just calls `kprintf(\"INT %u\\n\", frame->int_no)` and halts.\n6. Update `idt_init` to install real stub addresses: replace placeholder `0` with `(uint32_t)isr_0` through `(uint32_t)isr_255`.\n7. Update Makefile to assemble `isr_stubs.asm` with `-f elf32` and link `isr_stubs.o`.\n**Checkpoint 2A \u2014 Stack frame verification:** In `interrupt_dispatch`, temporarily print `frame->int_no`, `frame->eip`, `frame->eflags`. Add a deliberate `int3` (breakpoint, vector 3) call in `kernel_main`: `__asm__ volatile (\"int3\")`. Run with QEMU `-d int`. Expected: `int_no=3`, `eip` = address after the `int3` instruction (trap: EIP points to next instruction), `eflags` with IF=0 (interrupt gate cleared it). Verify with GDB: `break interrupt_dispatch`, `print frame->int_no` \u2192 3. `print frame->eip` \u2192 address of the instruction after `int3` in `kernel_main`.\n**Checkpoint 2B \u2014 Error code exception:** Add `__asm__ volatile (\"int $13\")` (note: this may itself be caught as a #GP if IDT DPL=0, which is correct behavior; use QEMU `-d int` to see the delivery). Alternatively, force a #GP by executing a privileged instruction: `__asm__ volatile (\"hlt\")` is ring-0-legal, so use `__asm__ volatile (\"lidt [0]\")` \u2014 this should #GP with error code 0. Verify `frame->err_code` is present and `frame->eip` is correct.\n---\n### Phase 3 \u2014 `interrupt_dispatch` C handler + exception messages + CR2 (3\u20134 hours)\n1. Complete `interrupt_dispatch` in `interrupt.c`: implement all exception messages per \u00a75.6.\n2. Add CR2 read for vector 14 (#PF): `__asm__ volatile (\"mov %0, cr2\" : \"=r\"(cr2))`.\n3. Add double-fault halt path (vector 8): `cli; hlt` infinite loop.\n4. Add `irq_dispatch` stub that only calls `pic_send_eoi(irq - 32)` (PIC not yet remapped \u2014 do NOT call `pic_send_eoi` yet; leave `irq_dispatch` as a no-op for now).\n**Checkpoint 3:** Force each exception type manually:\n- Division by zero: `int x = 0; int y = 1/x;` \u2014 triggers #DE (0); kprintf shows \"Division Error (#DE)\"\n- Null pointer: add `*(volatile int*)0 = 5;` \u2014 triggers #PF (14) with CR2=0, P=0 (not present), W=1 (write)\n- Invalid opcode: `__asm__ volatile (\".byte 0x0F, 0x0B\")` (UD2 instruction) \u2014 triggers #UD (6)\nEach should print the correct exception name, EIP, and error code. None should triple-fault (double fault handler catches any secondary fault).\n---\n### Phase 4 \u2014 PIC remapping + EOI protocol + spurious IRQ handling (3\u20134 hours)\n1. Create `pic.h` and `pic.c` with all PIC constants, `pic_remap`, `pic_send_eoi`, `pic_get_isr`, `io_wait`.\n2. Call `pic_remap(0x20, 0x28)` from `kernel_main` **before** `sti` and **before** `pit_init`.\n3. Add IRQ mask initialization in `pic_remap` epilogue: `outb(0x21, 0xFC)` (unmask IRQ0+IRQ1); `outb(0xA1, 0xFF)` (all slave masked).\n4. Complete `irq_dispatch` with `pic_send_eoi` calls.\n5. Add spurious IRQ7 and IRQ15 handlers using `pic_get_isr`.\n**Checkpoint 4A \u2014 PIC remapping verification:** After `pic_remap` (still no `sti`): `inb(0x21)` should return the saved mask with bits 0\u20131 clear (IRQ0 and IRQ1 unmasked). `inb(0xA1)` should return `0xFF`.\n**Checkpoint 4B \u2014 No triple fault on sti:** Add `__asm__ volatile (\"sti\")` and immediately `__asm__ volatile (\"hlt\")` in `kernel_main`. The timer will fire. Without `pit_init`, the timer fires at the PIT's default rate (~18.2 Hz). QEMU `-d int` should show vector 32 firing, NOT vector 8 (no more double fault on timer tick). **This is the most critical checkpoint of the milestone.**\n---\n### Phase 5 \u2014 PIT initialization + timer handler + `tick_counter` (2\u20133 hours)\n1. Create `pit.h` and `pit.c` with `pit_init`, `timer_handler`, `pit_get_ticks`, `pit_get_ms`.\n2. Declare `volatile uint64_t tick_counter = 0` in `pit.c`.\n3. Call `pit_init(100)` from `kernel_main` after `pic_remap`, before `sti`.\n4. Register `timer_handler` via `irq_dispatch` case 0.\n**Checkpoint 5:** After `sti`, add a wait loop:\n```c\nuint64_t start = pit_get_ticks();\nwhile (pit_get_ticks() - start < 100) {\n    __asm__ volatile (\"hlt\");\n}\nkprintf(\"1 second elapsed: %u ticks\\n\", (uint32_t)pit_get_ticks());\n```\nExpected: prints approximately `100` ticks (\u00b15 in QEMU). QEMU `-d int` shows exactly 100 vector-32 entries in the interval. Serial output shows the message.\n---\n### Phase 6 \u2014 PS/2 keyboard driver + ring buffer + `keyboard_getchar` (3\u20134 hours)\n1. Create `keyboard.h` with `ring_buffer_t` struct and function prototypes.\n2. Create `keyboard.c` with scancode tables, modifier state, `keyboard_handler`, `keyboard_getchar`.\n3. Register `keyboard_handler` in `irq_dispatch` case 1.\n**Checkpoint 6A \u2014 Break code filtering:** In QEMU, press and hold a key. Verify: exactly one character appears in the ring buffer per keypress (not one per make+break). Press Shift+A: verify 'A' (uppercase). Press 'a': verify 'a' (lowercase). Shift state persists correctly through rapid keypresses.\n**Checkpoint 6B \u2014 Full integration test:** Final `kernel_main` calls:\n```c\nkprintf(\"Press 5 keys: \");\nfor (int i = 0; i < 5; i++) {\n    char c = keyboard_getchar();\n    kprintf(\"%c\", c);\n}\nkprintf(\"\\nDone. Ticks: %u\\n\", (uint32_t)pit_get_ticks());\n```\nEach of the 5 keys pressed appears immediately. Final tick count > 0 (timer still running).\n---\n## 8. Test Specification\n### 8.1 IDT Gate Encoding Tests\n| Test | Setup | Expected |\n|---|---|---|\n| `idt_set_gate(0, 0xDEADBEEF, 0x08, 0x8E)` | Inspect `idt[0]` bytes | `[EF,BE,08,00,00,8E,AD,DE]` (little-endian offset split) |\n| `idt_set_gate(14, handler_pf, 0x08, 0x8E)` | Inspect `idt[14]` selector | `idt[14].selector == 0x08` |\n| `idt_set_gate(255, addr, 0x08, 0x8E)` | Inspect `idt[255].reserved` | `== 0` |\n| IDTR after `idt_init` | GDB: `p idtr` | `idtr.limit == 2047`, `idtr.base == (uint32_t)idt` |\n| Compile-time size check | Build | Build succeeds (no `-1` size array) |\n### 8.2 Interrupt Stack Frame Tests\n| Test | How to Verify | Expected |\n|---|---|---|\n| `frame->int_no` correct | `int3` \u2192 check `frame->int_no` | `== 3` |\n| `frame->eip` points after `int3` | GDB `print frame->eip` | Address of instruction following `int3` (trap: EIP advances) |\n| `frame->eip` points AT faulting instruction | #DE via `idiv` \u2192 check `frame->eip` | Address of the `idiv` instruction (fault: EIP does not advance) |\n| `frame->err_code == 0` for ISR_NOERR | `int3` (vector 3, ISR_NOERR) | `frame->err_code == 0` |\n| `frame->err_code != 0` for #GP with selector | Load invalid selector into DS | `frame->err_code` encodes the selector index |\n| EFLAGS.IF == 0 in handler | `print (frame->eflags >> 9) & 1` | `== 0` (interrupt gate cleared IF) |\n| Segment regs restored after `iretd` | Check DS after returning from non-faulting `int3` handler (modified to return) | `DS == 0x10` unchanged |\n### 8.3 PIC Remapping Tests\n| Test | Verification | Expected |\n|---|---|---|\n| Master offset correct | QEMU `-d int` after `sti` + timer fires | Vector 32 in log, NOT vector 8 |\n| Slave offset correct | Read `inb(0xA0)` after `pic_remap` (undocumented but works in QEMU) | Slave vector base = 0x28 in PIC state |\n| Master mask after init | `inb(0x21)` | `== 0xFC` (bits 0,1 clear = IRQ0,IRQ1 unmasked) |\n| Slave mask after init | `inb(0xA1)` | `== 0xFF` |\n| Timer fires at vector 32 (not 8) | QEMU `-d int` | Lines show `v=20` (decimal 32 = 0x20) |\n### 8.4 PIT Timer Tests\n| Test | Method | Expected |\n|---|---|---|\n| 100 ticks in ~1 second | Poll `pit_get_ticks` for 100 increments, measure wall time | 1.00s \u00b1 0.05s in QEMU |\n| `tick_counter` monotonically increases | Read twice; second > first | Always true |\n| Divisor at 100 Hz | Compute `1193182 / 100 = 11931`; verify written to port 0x40 | GDB watchpoint on `outb(0x40, ...)` shows `0x2B` (low byte of 11931) then `0x2E` (high byte of 11931) |\n| `volatile` prevents stale read | Disassemble `pit_get_ticks` | `mov eax, [tick_counter+4]` appears \u2014 no register caching |\n### 8.5 Keyboard Driver Tests\n| Test | Input | Expected |\n|---|---|---|\n| Unshifted letter | Press 'a' (scancode 0x1E) | Ring contains `'a'` |\n| Shifted letter | Press Shift, then 'a' | Ring contains `'A'` |\n| CapsLock toggle | Press CapsLock, then 'a' | Ring contains `'A'` |\n| CapsLock + Shift | Press CapsLock+Shift+'a' | Ring contains `'a'` (double inversion) |\n| Break code ignored | Press then release 'a' | Exactly ONE character in ring |\n| Modifier break clears state | Press Shift, release Shift, press 'a' | Ring contains `'a'` (not uppercase) |\n| Ring buffer full (255 chars) | Fill buffer, push one more | Buffer stays at 255; new char dropped silently |\n| Ring buffer empty | `keyboard_getchar` before any keypress | Blocks (CPU halts) until keypress |\n| Non-ASCII scancode (F1 = 0x3B) | Press F1 | Ring unchanged (0 from table \u2192 not pushed) |\n| NULL character prevention | Explicitly check | `ring_push` skips if `ascii == 0` |\n### 8.6 Exception Handler Tests\n| Exception | How to Trigger | Expected Output Contains |\n|---|---|---|\n| #DE (0) | `volatile int x=1; x /= 0;` | \"Division Error (#DE)\", EIP of idiv |\n| #BP (3) | `__asm__ volatile (\"int3\")` | \"Breakpoint (#BP)\" |\n| #UD (6) | `__asm__ volatile (\".byte 0x0F,0x0B\")` | \"Invalid Opcode (#UD)\" |\n| #GP (13) | Load invalid descriptor into DS | \"General Protection Fault (#GP)\", err_code |\n| #PF (14) | `*(volatile int*)0xDEAD0000 = 1;` | \"Page Fault\", CR2=0xDEAD0000, P=0, W=1, U=0 |\n| #DF (8) | Corrupt stack pointer, trigger exception | \"DOUBLE FAULT\", halts (no triple fault) |\n---\n## 9. Performance Targets\n{{DIAGRAM:tdd-diag-15}}\n| Operation | Target | Measurement Method |\n|---|---|---|\n| Interrupt dispatch latency (INTR \u2192 first C instruction) | < 1 \u00b5s | QEMU `info profile` or cycle-counter difference (M4 adds rdtsc) |\n| `isr_common_stub` overhead (pusha + seg saves + push esp) | 13 instructions \u00d7 ~1 cycle each \u2248 15\u201320 cycles \u2248 5\u20137 ns at 3 GHz | Disassemble and count; or QEMU instruction tracing |\n| `timer_handler` execution time (tick_counter++ only) | < 500 ns | QEMU cycle count: `inc [tick_counter]` = 1 instruction |\n| `keyboard_handler` execution time (port read + table + ring push) | < 2 \u00b5s | QEMU `-d in_asm` shows ISR path length \u2248 30\u201350 instructions \u2248 50\u2013100 ns |\n| PIT accuracy at 100 Hz | \u00b1 0.5% (actual: \u00b10.003% at divisor 11932) | Measure 1000 ticks wall time in QEMU: should be 10.000s \u00b1 0.05s |\n| Ring buffer push (single character, non-full) | < 50 ns | 4 array accesses + 2 uint8_t increments = ~6 instructions |\n| `keyboard_getchar` latency from keypress to return | < 5 \u00b5s | Hardware: PS/2 clock period \u2248 80\u2013100 \u00b5s; ISR adds <2 \u00b5s; getchar returns within first tick |\n| IDT lookup per interrupt | 1 cache line read (8-byte entry; IDT cold-fits in ~32 L1 cache lines for 256 entries) | IDT = 256 \u00d7 8 = 2048 bytes = 32 \u00d7 64-byte cache lines; hot in L1 after first use |\n| Ring buffer capacity | 255 characters without blocking | Static: KEYBOARD_BUF_SIZE=256, uint8_t head/tail, capacity = 255 |\n---\n## 10. Concurrency Specification\n**Model:** Single CPU; no SMP in M2. Interrupt handlers run with EFLAGS.IF=0 (interrupt gate clears IF on entry). This means:\n- **No concurrent interrupt handlers:** The timer handler and keyboard handler cannot run simultaneously. An ISR cannot be re-entered.\n- **Ring buffer safety:** The keyboard ring buffer has one producer (IRQ1 handler, `keyboard_handler`) and one consumer (`keyboard_getchar`, called from non-IRQ context). On single-core with IF=0 in the producer, the consumer can never interrupt the producer. The consumer reads `head` only after the producer wrote it. **No atomic instructions required.**\n- **`tick_counter` safety:** Single writer (timer ISR), single reader (non-IRQ code). The 64-bit read tearing risk is addressed by the `cli`/`sti` guard in `pit_get_ticks`.\n- **Modifier state (`shift_down`, etc.):** Modified exclusively in IRQ1 handler. Read exclusively in IRQ1 handler. No concurrent access risk.\n- **`volatile` requirement:** Fields shared between IRQ context and non-IRQ context (`tick_counter`, `kbd_ring.head`, `kbd_ring.tail`) must be `volatile` to prevent compiler register caching.\n**Lock ordering:** Not applicable in M2 (no mutexes, no multiple threads).\n**Illegal concurrent operations:** Calling `keyboard_getchar` from within an ISR \u2014 it will spin with IF=0 and deadlock. This is a programming error; not protected against in M2.\n---\n<!-- END_TDD_MOD -->\n\n\n<!-- TDD_MOD_ID: build-os-m3 -->\n# Technical Design Specification: Physical and Virtual Memory Management (`build-os-m3`)\n---\n## 1. Module Charter\nThis module transitions the kernel from a flat physical address space to a fully virtualized memory environment. It parses the Multiboot/E820 physical memory map to classify regions, implements a bitmap-based physical frame allocator (PMM) with double-free detection, constructs static two-level x86 page tables mapping the first 4 MB as an identity map and the kernel binary at virtual `0xC0100000` \u2192 physical `0x00100000`, enables paging via CR3 and CR0.PG, performs the higher-half jump, removes the identity map, and provides a `kmalloc`/`kfree` kernel heap backed by the PMM. The page fault handler (#PF, vector 14) is upgraded to decode CR2 and the error code's present/write/user bits.\nThis module does **not** implement per-process page directories, user-mode memory isolation, demand paging (page-not-present faults remain fatal), copy-on-write, memory-mapped files, swap, NUMA awareness, huge pages, PAE, or any form of multi-core TLB shootdown. All initialization runs single-threaded with a single address space; `sti` is called only after paging and the heap are both fully operational.\n**Upstream dependency:** Milestone 2 must deliver CR0.PE=1, a valid GDT (CS=0x08, DS/ES/FS/GS/SS=0x10), a working IDT with all 256 gates installed (in particular vector 14 for page faults), PIC remapped so IRQ0\u2192vector 32, PIT at 100 Hz, `kprintf` operational, and EFLAGS.IF=0 at the point this module's init code runs. The multiboot bootloader (GRUB or equivalent) places a pointer to `multiboot_info_t` in EBX on kernel entry; this pointer is passed through `kernel_entry.asm` and received by `kernel_main`.\n**Downstream dependency:** Milestone 4 (processes and scheduling) requires `kmalloc`/`kfree` (for PCBs and kernel stacks), `paging_map`/`paging_unmap` (for per-process page directories), `pmm_alloc_frame`/`pmm_free_frame` (for user stack frames), and the `create_user_page_directory` function. The page fault handler's kernel-fault path must remain a halt; the user-fault path will be extended in M4 to perform demand paging.\n**Invariants that must hold throughout:**\n1. After `paging_init` returns, CR0.PG=1 and CR3 holds the physical address of `boot_pd`.\n2. Virtual address `V` in `[0xC0000000, 0xC03FFFFF]` maps to physical `V \u2212 0xC0000000` at all times after the higher-half jump.\n3. Virtual address `0x00000000` is unmapped (no present PTE) after identity map removal.\n4. Every `pmm_alloc_frame` return value is 4KB-aligned, nonzero, and was marked free before the call.\n5. Every `kfree(p)` where `p` was not returned by `kmalloc`, or was already freed, produces a halt with a diagnostic message before any further state is modified.\n6. The `heap_block_t` magic field equals `HEAP_MAGIC` for every live allocation; corruption is detected on the next `kmalloc` or `kfree` that touches the corrupted block.\n---\n## 2. File Structure\nCreate files in this exact order:\n```\nbuild-os/\n\u251c\u2500\u2500 kernel/\n\u2502   \u251c\u2500\u2500 25  mmap.h              # multiboot_info_t, multiboot_mmap_entry_t, phys_region_t\n\u2502   \u251c\u2500\u2500 26  mmap.c              # mmap_parse(): iterate E820 map, populate phys_regions[]\n\u2502   \u251c\u2500\u2500 27  pmm.h               # frame_bitmap extern, pmm_init, pmm_alloc_frame,\n\u2502   \u2502                           #   pmm_free_frame, pmm_free_frames, FRAME_TO_PHYS,\n\u2502   \u2502                           #   PHYS_TO_FRAME macros\n\u2502   \u251c\u2500\u2500 28  pmm.c               # bitmap allocator: init/alloc/free + double-free panic\n\u2502   \u251c\u2500\u2500 29  paging.h            # page_directory_t, page_table_t, PDE_*/PTE_* flag\n\u2502   \u2502                           #   constants, VIRT_TO_PHYS macro, boot_pd extern,\n\u2502   \u2502                           #   paging_init, paging_map, paging_unmap,\n\u2502   \u2502                           #   tlb_flush_page, tlb_flush_all prototypes\n\u2502   \u251c\u2500\u2500 30  paging.c            # boot_pd, pt_low, pt_high static arrays; paging_init;\n\u2502   \u2502                           #   higher-half jump; identity map removal; paging_map;\n\u2502   \u2502                           #   paging_unmap; tlb utilities\n\u2502   \u251c\u2500\u2500 31  paging_boot.asm     # Assembly trampoline: enables CR0.PG, executes far jump\n\u2502   \u2502                           #   to higher-half virtual address, removes identity map\n\u2502   \u251c\u2500\u2500 32  heap.h              # heap_block_t, HEAP_MAGIC, HEAP_START, HEAP_END,\n\u2502   \u2502                           #   kmalloc, kfree, heap_init prototypes\n\u2502   \u251c\u2500\u2500 33  heap.c              # free-list heap: heap_init, kmalloc (first-fit + split),\n\u2502   \u2502                           #   kfree (coalesce prev+next), HEAP_MAGIC checks\n\u2502   \u251c\u2500\u2500 34  interrupt.c         # UPDATED: page fault handler reads CR2 + decodes bits\n\u2502   \u251c\u2500\u2500 35  kernel.ld           # UPDATED: VMA=0xC0100000, LMA=0x100000, AT() directives\n\u2502   \u2514\u2500\u2500 36  kernel_main.c       # UPDATED: receives mbi*, calls mmap_parse, pmm_init,\n\u2502                               #   paging_init (which calls paging_boot.asm trampoline),\n\u2502                               #   heap_init, pic_remap, pit_init, sti, test sequence\n\u2514\u2500\u2500 Makefile                    # UPDATED: add mmap.o pmm.o paging.o paging_boot.o heap.o\n```\n---\n## 3. Complete Data Model\n### 3.1 Multiboot Structures\nThe Multiboot 1 specification defines the information structure placed in memory by the bootloader. All fields are little-endian 32-bit unless noted.\n```c\n// mmap.h\n// Multiboot 1 info structure (abbreviated \u2014 only fields consumed by this module)\ntypedef struct {\n    uint32_t flags;          // Offset  0: bit-field indicating which fields are valid\n    uint32_t mem_lower;      // Offset  4: lower memory in KB (valid if flags[0])\n    uint32_t mem_upper;      // Offset  8: upper memory in KB (valid if flags[0])\n    uint32_t boot_device;    // Offset 12: (unused)\n    uint32_t cmdline;        // Offset 16: (unused)\n    uint32_t mods_count;     // Offset 20: (unused)\n    uint32_t mods_addr;      // Offset 24: (unused)\n    uint32_t syms[4];        // Offset 28: (unused)\n    uint32_t mmap_length;    // Offset 44: byte length of memory map array\n    uint32_t mmap_addr;      // Offset 48: physical address of first mmap entry\n    // ... further fields unused in M3\n} __attribute__((packed)) multiboot_info_t;\n#define MBOOT_FLAG_MMAP  (1u << 6)   // Bit 6: mmap_length/mmap_addr fields are valid\n// Each entry in the Multiboot memory map.\n// NOTE: 'size' does NOT include the 4 bytes of the 'size' field itself.\n// Advance to next entry: (uintptr_t)entry + entry->size + 4\ntypedef struct {\n    uint32_t size;           // Offset 0: size of this entry minus 4 (usually 20)\n    uint64_t base_addr;      // Offset 4: physical base address (64-bit for PAE compat)\n    uint64_t length;         // Offset 12: length in bytes (64-bit)\n    uint32_t type;           // Offset 20: region type (1=usable, 2=reserved, 3=ACPI, ...)\n} __attribute__((packed)) multiboot_mmap_entry_t;\n// sizeof(multiboot_mmap_entry_t) == 24 (without the 4-byte size field prefix)\n// The 'size' field at offset 0 is WITHIN the struct; the struct pointer already\n// points to it. Entry advance = (uint8_t*)entry + entry->size + sizeof(uint32_t)\n#define MMAP_TYPE_USABLE    1\n#define MMAP_TYPE_RESERVED  2\n#define MMAP_TYPE_ACPI      3\n#define MMAP_TYPE_NVS       4\n#define MMAP_TYPE_BAD       5\n```\n**Physical region classification record:**\n```c\n// mmap.h\n#define MAX_PHYS_REGIONS  64  // Sufficient for any realistic machine\ntypedef struct {\n    uint64_t base;    // Starting physical address (may exceed 32-bit if PAE; clamp to 32-bit)\n    uint64_t length;  // Length in bytes\n    uint32_t type;    // MMAP_TYPE_* constant\n} phys_region_t;\nextern phys_region_t phys_regions[MAX_PHYS_REGIONS];\nextern int           phys_region_count;\n```\n**Byte-offset table for `phys_region_t`:**\n| Offset | Size | Field | Notes |\n|--------|------|-------|-------|\n| 0 | 8 | `base` | Physical start; 64-bit to match E820 source |\n| 8 | 8 | `length` | Byte count; 64-bit |\n| 16 | 4 | `type` | `MMAP_TYPE_*` constant |\n| 20 | 4 | (pad) | Compiler alignment to 8-byte boundary |\n`sizeof(phys_region_t)` = 24 bytes.\n---\n### 3.2 Physical Frame Allocator \u2014 Bitmap\n{{DIAGRAM:tdd-diag-16}}\n```c\n// pmm.h\n#define PAGE_SIZE         4096u\n#define PAGE_SHIFT        12u\n#define FRAMES_PER_WORD   32u\n#define MAX_PHYS_FRAMES   (1024u * 1024u)  // 4 GB / 4 KB = 1M frames maximum\n// frame_bitmap[i] bit j = 1 means frame (i*32+j) is IN USE or RESERVED\n// frame_bitmap[i] bit j = 0 means frame (i*32+j) is FREE\n// Array lives in kernel .bss (zeroed by kernel_entry) \u2014 starts all-zero.\n// pmm_init sets all bits to 1, then clears bits for usable regions.\nextern uint32_t frame_bitmap[MAX_PHYS_FRAMES / FRAMES_PER_WORD];  // 128 KB\nextern uint32_t total_frames;   // Total frames in physical address space\nextern uint32_t free_frames;    // Current free frame count (decrements on alloc)\n// Conversion macros (inline, no function call overhead)\n#define PHYS_TO_FRAME(phys)   ((uint32_t)(phys) >> PAGE_SHIFT)\n#define FRAME_TO_PHYS(frame)  ((uint32_t)(frame) << PAGE_SHIFT)\n```\n**Bitmap memory layout:**\n| Total physical RAM | Frames needed | Bitmap size |\n|-------------------|---------------|-------------|\n| 64 MB | 16,384 | 512 B |\n| 128 MB | 32,768 | 1 KB |\n| 256 MB | 65,536 | 2 KB |\n| 4 GB (max) | 1,048,576 | 128 KB |\nThe bitmap array (`128 KB`) lives in `.bss` at a known virtual address after the higher-half jump. It is zeroed by `kernel_entry.asm`'s `rep stosb` before `kernel_main` is called. `pmm_init` subsequently sets all bits to 1 (all frames reserved) and then clears bits for usable regions.\n---\n### 3.3 Page Directory and Page Table Entries\n{{DIAGRAM:tdd-diag-17}}\nx86 32-bit paging uses two levels. Both PDEs and PTEs are 32-bit values with the same flag bit layout in bits 11:0; the physical frame number occupies bits 31:12.\n**PDE/PTE flag bits (shared layout):**\n| Bit | Mask | Name | Meaning |\n|-----|------|------|---------|\n| 0 | `0x001` | `PRESENT` | Entry maps a valid frame/PT (must be 1 to be used by MMU) |\n| 1 | `0x002` | `WRITABLE` | Writes permitted (0 = read-only) |\n| 2 | `0x004` | `USER` | Accessible from ring 3 (0 = supervisor/kernel only) |\n| 3 | `0x008` | `WRITE_THRU` | Write-through cache (0 = write-back) |\n| 4 | `0x010` | `CACHE_DIS` | Disable caching (set for MMIO regions like VGA) |\n| 5 | `0x020` | `ACCESSED` | CPU sets on any read; SW may clear |\n| 6 | `0x040` | `DIRTY` (PTE) / `reserved 0` (PDE) | CPU sets on write (PTE only) |\n| 7 | `0x080` | `PAT` (PTE) / `PAGE_SIZE` (PDE) | PDE: 0=4KB pages, 1=4MB huge page |\n| 8 | `0x100` | `GLOBAL` | Don't flush this TLB entry on CR3 reload (requires CR4.PGE=1) |\n| 11:9 | `0xE00` | `AVAIL` | Available for OS use |\n| 31:12 | `0xFFFFF000` | `FRAME` | Physical address of page table (PDE) or page frame (PTE), shifted right 12 |\n```c\n// paging.h\ntypedef uint32_t pde_t;\ntypedef uint32_t pte_t;\n// Arrays must be exactly 4096 bytes and 4096-byte aligned\n// (CR3 requires page-directory physical address to be 4KB-aligned)\ntypedef pde_t page_directory_t[1024] __attribute__((aligned(4096)));\ntypedef pte_t page_table_t[1024]     __attribute__((aligned(4096)));\n// Flag constants\n#define PTE_PRESENT    (1u << 0)\n#define PTE_WRITABLE   (1u << 1)\n#define PTE_USER       (1u << 2)\n#define PTE_WRITE_THRU (1u << 3)\n#define PTE_CACHE_DIS  (1u << 4)\n#define PTE_ACCESSED   (1u << 5)\n#define PTE_DIRTY      (1u << 6)\n#define PTE_GLOBAL     (1u << 8)\n// Extract/set physical frame address in an entry\n#define PTE_GET_FRAME(entry)       ((entry) & 0xFFFFF000u)\n#define PTE_SET_FRAME(phys, flags) (((phys) & 0xFFFFF000u) | ((flags) & 0x00000FFFu))\n// Virtual address decomposition macros\n#define VADDR_PD_INDEX(va)  (((uint32_t)(va)) >> 22)          // Bits 31:22 (0\u20131023)\n#define VADDR_PT_INDEX(va)  ((((uint32_t)(va)) >> 12) & 0x3FF) // Bits 21:12 (0\u20131023)\n#define VADDR_OFFSET(va)    (((uint32_t)(va)) & 0xFFF)         // Bits 11:0\n// Kernel virtual base (must match linker script KERNEL_VIRT_BASE)\n#define KERNEL_VIRT_BASE   0xC0000000u\n#define KERNEL_PHYS_BASE   0x00100000u\n// Convert a kernel virtual address to its physical address (valid only for\n// addresses in the statically-mapped kernel region before pmm is available)\n#define VIRT_TO_PHYS(va)   ((uint32_t)(va) - KERNEL_VIRT_BASE)\n#define PHYS_TO_VIRT(pa)   ((uint32_t)(pa) + KERNEL_VIRT_BASE)\n// VGA physical address \u2014 must remain identity-mapped OR re-mapped in higher-half PT\n#define VGA_PHYS_ADDR     0x000B8000u\n```\n**Virtual address space layout after paging_init:**\n| Virtual Range | Physical Range | Purpose |\n|---------------|---------------|---------|\n| `0x00000000`\u2013`0x003FFFFF` | **UNMAPPED** (after jump) | NULL protection; was identity map |\n| `0x00400000`\u2013`0xBFFFFFFF` | \u2014 | Reserved for future user processes |\n| `0xC0000000`\u2013`0xC03FFFFF` | `0x00000000`\u2013`0x003FFFFF` | Higher-half kernel + VGA MMIO |\n| `0xC0400000`\u2013`0xCFFF0000` | Allocated on demand | Kernel heap (`kmalloc` arena) |\n| `0xD0000000`\u2013`0xFFFFFFFF` | \u2014 | Reserved |\n---\n### 3.4 Boot Page Tables (Static)\nThree statically-allocated, 4KB-aligned page structures handle the bootstrap paging setup:\n```c\n// paging.c (static, not exported \u2014 accessed via VIRT_TO_PHYS before paging on)\nstatic page_directory_t boot_pd   __attribute__((aligned(4096)));  // 4096 bytes in .bss\nstatic page_table_t     pt_low    __attribute__((aligned(4096)));  // 4096 bytes in .bss\nstatic page_table_t     pt_high   __attribute__((aligned(4096)));  // 4096 bytes in .bss\n```\n**`boot_pd` after `paging_init` (before identity map removal):**\n| PD Index | Virtual Base | Points To | Flags |\n|----------|-------------|-----------|-------|\n| 0 | `0x00000000` | `pt_low` (physical) | `PRESENT\\|WRITABLE` |\n| 1\u2013767 | ... | Not present (0) | \u2014 |\n| 768 | `0xC0000000` | `pt_high` (physical) | `PRESENT\\|WRITABLE` |\n| 769\u20131023 | ... | Not present (0) | \u2014 |\n**After identity map removal (`boot_pd[0] = 0`):**\n| PD Index | Virtual Base | Status |\n|----------|-------------|--------|\n| 0 | `0x00000000` | **NOT PRESENT** \u2014 NULL deref \u2192 #PF |\n| 768 | `0xC0000000` | `pt_high` (present) |\n---\n### 3.5 Heap Block Header\n{{DIAGRAM:tdd-diag-18}}\n```c\n// heap.h\n#define HEAP_MAGIC  0xDEADBEEFu\n#define HEAP_START  0xC0400000u   // Virtual address: start of kmalloc arena\n#define HEAP_END    0xCFFF0000u   // Virtual address: end of kmalloc arena (252 MB virtual)\n#define HEAP_ALIGN  8u            // All allocations aligned to 8 bytes\ntypedef struct heap_block {\n    uint32_t          magic;   // Offset 0: always HEAP_MAGIC; corruption sentinel\n    uint32_t          size;    // Offset 4: data region size in bytes (NOT incl. header)\n    uint8_t           used;    // Offset 8: 0=free, 1=allocated\n    uint8_t           _pad[3]; // Offset 9: padding to align next pointer\n    struct heap_block *next;   // Offset 12: next block in doubly-linked list\n    struct heap_block *prev;   // Offset 16: previous block\n} heap_block_t;\n// sizeof(heap_block_t) == 20 bytes (on 32-bit with 4-byte pointers)\n// All user allocations start at (heap_block_t*)ptr + 1\n// i.e., ptr_returned_to_caller = (uint8_t*)block + sizeof(heap_block_t)\n```\n**`heap_block_t` byte-offset table:**\n| Offset | Size | Field | Constraints |\n|--------|------|-------|-------------|\n| 0 | 4 | `magic` | Always `0xDEADBEEF`; if wrong \u2192 halt |\n| 4 | 4 | `size` | Bytes in data region; multiple of `HEAP_ALIGN` |\n| 8 | 1 | `used` | `0` or `1` only |\n| 9 | 3 | `_pad` | Zeroed; ignored |\n| 12 | 4 | `next` | Virtual pointer to next `heap_block_t`; NULL if last |\n| 16 | 4 | `prev` | Virtual pointer to prev `heap_block_t`; NULL if first |\n`sizeof(heap_block_t)` = 20 bytes.\n**Memory layout of a 64-byte allocation:**\n```\n[Virtual Heap]\n0xC0400000: heap_block_t header  (20 bytes)\n  magic  = 0xDEADBEEF\n  size   = 64\n  used   = 1\n  next   = 0xC0400054  \u2190 points past this block's data\n  prev   = NULL\n0xC0400014: [user data \u2014 64 bytes]     \u2190 returned pointer\n0xC0400054: next heap_block_t header\n```\n---\n## 4. Interface Contracts\n### 4.1 Memory Map Parser\n```c\n// mmap.h\nvoid mmap_parse(multiboot_info_t *mbi);\n```\n- **Preconditions:** `mbi` is a valid virtual pointer to the Multiboot info structure. Because paging is **not yet enabled** when this is first called (it runs early in `kernel_main` before `paging_init`), `mbi` is a physical address passed as a pointer \u2014 valid because physical = virtual before paging. After paging is enabled and before `sti`, the Multiboot structure at its physical address is accessible only if that region is identity-mapped or otherwise mapped. **Implementation requirement:** call `mmap_parse` before `paging_init`. Store results in global `phys_regions[]` which lives in `.bss` (zeroed, accessible after jump via kernel virtual addresses).\n- **Postconditions:** `phys_regions[0..phys_region_count-1]` populated; `phys_region_count \u2264 MAX_PHYS_REGIONS`. Regions are stored in the order the BIOS reported them (unsorted). At least one region with `type == MMAP_TYPE_USABLE` exists or `kprintf` error and halt.\n- **Edge cases:**\n  - `!(mbi->flags & MBOOT_FLAG_MMAP)`: kprintf error message and `cli; hlt`. Do not proceed.\n  - `phys_region_count == MAX_PHYS_REGIONS` before all entries parsed: stop and log truncation warning; continue with what was stored.\n  - Entry with `base_addr > 0xFFFFFFFF`: skip (beyond 32-bit address space, no PAE in this kernel).\n  - Entry with `base_addr + length > 0xFFFFFFFF`: clamp length to `0xFFFFFFFF - base_addr`.\n- **Errors:** No return value. Fatal errors halt via `for(;;) { cli; hlt; }`.\n- **Side effects:** Writes `phys_regions[]` and `phys_region_count`. Calls `kprintf` to print the map.\n---\n### 4.2 Physical Frame Allocator\n```c\n// pmm.h\nvoid pmm_init(multiboot_info_t *mbi);\n```\n- **Preconditions:** `mmap_parse(mbi)` has been called; `phys_regions[]` is populated. Must be called before `paging_init` (uses physical addresses directly). `frame_bitmap` lives in `.bss`; all bits are 0 (free) at entry to `pmm_init` \u2014 function sets them all to 1 first.\n- **Postconditions:** `frame_bitmap` correctly marks every frame: 1=reserved, 0=free. Specifically: all frames start as 1; usable E820 regions are freed (set to 0); then the following are re-marked as 1: frame 0 (BIOS data area / NULL protection), frames occupied by the kernel binary (`__kernel_start / PAGE_SIZE` through `ceil(__kernel_end / PAGE_SIZE)`), frames occupied by `frame_bitmap` itself (bitmap lives at a virtual address; compute its physical range from `VIRT_TO_PHYS`), and frames occupied by the boot page tables (`boot_pd`, `pt_low`, `pt_high` \u2014 physical addresses). `total_frames` set to the frame index of the highest physical byte. `free_frames` set accurately.\n- **Algorithm \u2014 re-marking kernel frames:** The linker exports `__kernel_start` and `__kernel_end` as virtual addresses (after the higher-half linker script update). At `pmm_init` time (before paging), these virtual addresses minus `KERNEL_VIRT_BASE` give physical addresses. Use `VIRT_TO_PHYS((uint32_t)&__kernel_start)`.\n```c\n// pmm.h\nuint32_t pmm_alloc_frame(void);\n```\n- **Preconditions:** `pmm_init` has been called.\n- **Returns:** Physical address of an allocated 4KB frame (always a multiple of 4096 and \u2265 `PAGE_SIZE`). The returned frame is immediately marked used in `frame_bitmap`.\n- **Error:** If no free frame exists: `kprintf(\"[PMM] OUT OF MEMORY\\n\"); for(;;){cli;hlt;}`. Never returns 0 on success (frame 0 is always reserved).\n- **Algorithm:** Scan `frame_bitmap` word-by-word. If word == `0xFFFFFFFF`, skip (all used). Otherwise, find first 0-bit via `__builtin_ctz(~word)`, compute frame number, set the bit, decrement `free_frames`, return `FRAME_TO_PHYS(frame)`. Scan starts from word index 0 each call (no free-list pointer in M3; O(n/32) acceptable).\n- **Thread safety:** Single-core; IF=0 during critical allocations. Page fault handler must NOT call `pmm_alloc_frame` in M3 (no demand paging yet). **Do not call from IRQ handlers.**\n```c\nvoid pmm_free_frame(uint32_t phys_addr);\n```\n- **Preconditions:** `phys_addr` is 4KB-aligned; was previously returned by `pmm_alloc_frame`; has not been freed since.\n- **Postconditions:** The corresponding frame bit is 0; `free_frames` incremented.\n- **Double-free detection:** Before clearing the bit, test it. If the bit is already 0: `kprintf(\"[PMM] DOUBLE FREE: phys=0x%x frame=%u\\n\", phys_addr, PHYS_TO_FRAME(phys_addr)); for(;;){cli;hlt;}`.\n- **Invalid address detection:** If `phys_addr & (PAGE_SIZE-1) != 0` or `PHYS_TO_FRAME(phys_addr) >= total_frames`: same halt pattern.\n```c\nuint32_t pmm_free_frames(void);  // Returns current free_frames count\n```\n---\n### 4.3 Paging\n```c\n// paging.h\nvoid paging_init(multiboot_info_t *mbi);\n```\n- **Preconditions:** `pmm_init` has been called. EFLAGS.IF=0. EBX preserved from multiboot entry (or passed through `kernel_main`). Physical address = virtual address (paging off).\n- **Postconditions:** `boot_pd[0]` = physical `pt_low` | `PRESENT|WRITABLE`; `boot_pd[768]` = physical `pt_high` | `PRESENT|WRITABLE`; all 1024 PTEs in `pt_low` map frames 0\u20131023 (physical `0x000000`\u2013`0x3FFFFF`) with `PRESENT|WRITABLE`; special: PTE for VGA region (`0xB8000 >> 12 = 0xB8` = frame 184) additionally has `CACHE_DIS` set; all 1024 PTEs in `pt_high` identically map frames 0\u20131023; CR3 loaded with `VIRT_TO_PHYS(boot_pd)`; CR0.PG set; far jump to higher-half virtual address executed; `boot_pd[0]` cleared; TLB fully flushed; identity map confirmed absent; higher-half addresses verified accessible.\n- **After return:** All subsequent pointer dereferences use virtual addresses. `PHYS_TO_VIRT(phys)` gives a valid pointer for physical addresses in `[0, 0x3FFFFF]`.\n- **Errors:** Any step failure \u2192 triple fault (before IDT is in higher-half virtual memory space). This is expected behaviour during development; QEMU `-d int` diagnoses it.\n```c\nvoid paging_map(page_directory_t *pd,\n                uint32_t virt_addr,\n                uint32_t phys_addr,\n                uint32_t flags);\n```\n- **Preconditions:** Paging enabled; `pd` is a virtual pointer to a page directory (must be accessible); `virt_addr` and `phys_addr` are 4KB-aligned; `flags` is a combination of `PTE_*` constants (must include `PTE_PRESENT`).\n- **Behavior:**\n  1. Compute `pd_idx = VADDR_PD_INDEX(virt_addr)`, `pt_idx = VADDR_PT_INDEX(virt_addr)`.\n  2. If `pd[pd_idx]` has `PTE_PRESENT` clear: allocate a new page table frame via `pmm_alloc_frame()`, zero it (via `PHYS_TO_VIRT` pointer), install `pd[pd_idx] = phys_of_new_pt | PTE_PRESENT | PTE_WRITABLE | (flags & PTE_USER)`.\n  3. Compute virtual address of the page table: `page_table_t *pt = (page_table_t*)PHYS_TO_VIRT(PTE_GET_FRAME(pd[pd_idx]))`.\n  4. If `(*pt)[pt_idx]` already has `PTE_PRESENT` set: `kprintf` warning (remapping); do not halt (caller may intentionally remap). Clear existing entry first.\n  5. Set `(*pt)[pt_idx] = PTE_SET_FRAME(phys_addr, flags)`.\n  6. Call `tlb_flush_page(virt_addr)`.\n- **Errors:** If `pmm_alloc_frame` returns (it halts on OOM \u2014 see above), this function always succeeds. If `virt_addr` is not page-aligned: `kprintf` error + halt. If `virt_addr >= 0xC0000000` and the caller is trying to map into kernel reserved space, allow it (kernel heap setup requires this).\n```c\nvoid paging_unmap(page_directory_t *pd, uint32_t virt_addr);\n```\n- **Preconditions:** Paging enabled; `virt_addr` 4KB-aligned.\n- **Postconditions:** If the PDE or PTE is not present, returns silently (idempotent). Otherwise: clears `(*pt)[pt_idx]` to 0 (removes `PTE_PRESENT`); calls `tlb_flush_page(virt_addr)`. Does NOT free the physical frame (caller's responsibility). Does NOT free the page table even if it becomes empty (M3 simplification).\n```c\nvoid tlb_flush_page(uint32_t virt_addr);\n```\n- **Implementation:** `__asm__ volatile (\"invlpg [%0]\" : : \"r\"(virt_addr) : \"memory\");`\n- **Must be called:** After any modification to a PTE that was previously present (permission change, frame remap, or clearing present bit).\n```c\nvoid tlb_flush_all(void);\n```\n- **Implementation:** Reload CR3 with the same value. This evicts all non-global TLB entries.\n- **Use:** After modifying multiple PTEs (e.g., identity map removal); after switching page directories in M4.\n---\n### 4.4 Kernel Heap\n```c\n// heap.h\nvoid heap_init(void);\n```\n- **Preconditions:** Paging enabled; `paging_map` operational; `pmm_alloc_frame` operational.\n- **Postconditions:** `heap_brk = HEAP_START`; `heap_head = NULL`. No physical frames allocated yet (lazy). The first `kmalloc` call triggers the first frame allocation.\n- **Side effects:** Writes two global variables. Does not touch page tables.\n```c\nvoid *kmalloc(uint32_t size);\n```\n- **Preconditions:** `heap_init` called; `size > 0`; paging and PMM operational.\n- **Returns:** Pointer to `size` bytes of writable kernel virtual memory, 8-byte aligned. Never returns NULL (OOM halts). Returned pointer points to the byte immediately after the `heap_block_t` header.\n- **Algorithm (detailed in \u00a75.5):** Align size to `HEAP_ALIGN`. First-fit scan of free-list. If found: split if remainder \u2265 `sizeof(heap_block_t) + HEAP_ALIGN`. Mark used. Return data pointer. If not found: call `heap_extend(size)` to commit new pages, then retry (exactly once; the newly committed block is guaranteed to fit).\n- **Corruption check:** On every visited block during scan: verify `block->magic == HEAP_MAGIC`. If not: `kprintf(\"[HEAP] CORRUPTION at 0x%x: magic=0x%x\\n\", block, block->magic); for(;;){cli;hlt;}`.\n- **Edge case:** `size == 0`: return a valid unique non-NULL pointer (allocate `HEAP_ALIGN` bytes). This matches historical `malloc(0)` behavior and avoids NULL return.\n```c\nvoid kfree(void *ptr);\n```\n- **Preconditions:** `ptr` was returned by a previous `kmalloc` call and has not been freed.\n- **Algorithm:** `block = (heap_block_t*)ptr - 1`. Verify `block->magic == HEAP_MAGIC` (corruption: halt). Verify `block->used == 1` (double-free: `kprintf(\"[HEAP] DOUBLE FREE: ptr=0x%x\\n\", ptr); for(;;){cli;hlt;}`). Set `block->used = 0`. Coalesce forward: if `block->next != NULL && block->next->magic == HEAP_MAGIC && !block->next->used`: merge. Coalesce backward: if `block->prev != NULL && block->prev->magic == HEAP_MAGIC && !block->prev->used`: merge. Never return physical frames to PMM (M3 simplification; heap memory is permanently committed).\n- **Errors:** NULL `ptr`: return immediately (no-op, same as `free(NULL)` in C standard).\n---\n## 5. Algorithm Specification\n### 5.1 E820 Map Parser\n**Input:** `multiboot_info_t *mbi` \u2014 physical address of Multiboot info.\n**Output:** `phys_regions[]` populated; `phys_region_count` set.\n```\nPROCEDURE mmap_parse(mbi):\n  1. IF NOT (mbi->flags & MBOOT_FLAG_MMAP):\n       kprintf error; cli; hlt\n  2. entry = (multiboot_mmap_entry_t*)(uintptr_t)mbi->mmap_addr\n     end   = mbi->mmap_addr + mbi->mmap_length\n     phys_region_count = 0\n  3. WHILE (uintptr_t)entry < end:\n       a. IF phys_region_count < MAX_PHYS_REGIONS:\n            IF entry->base_addr > 0xFFFFFFFF: GOTO advance  // skip >4GB\n            base = (uint32_t)entry->base_addr\n            len  = (uint64_t)entry->length\n            IF base + len > 0x100000000ULL: len = 0x100000000ULL - base\n            phys_regions[phys_region_count] = {base, len, entry->type}\n            phys_region_count++\n       b. kprintf one line per entry (base, end, type string)\n       advance:\n       c. entry = (multiboot_mmap_entry_t*)((uintptr_t)entry + entry->size + 4)\n  4. IF phys_region_count == 0: kprintf error; cli; hlt\n  5. RETURN\n```\n**Why `entry->size + 4`:** The `size` field at offset 0 gives the length of the remaining entry fields. Adding 4 skips the `size` field itself. This matches the Multiboot 1 spec: the structure pointer includes the `size` field, but `size` does not count itself.\n---\n### 5.2 PMM Initialization\n**Input:** `multiboot_info_t *mbi` (used for multiboot modules list, to avoid allocating their frames).\n**Pre-state:** `frame_bitmap` all-zero (from BSS), `total_frames=0`, `free_frames=0`.\n```\nPROCEDURE pmm_init(mbi):\n  1. highest_phys = 0\n     FOR each region in phys_regions[0..phys_region_count-1]:\n       top = region.base + region.length\n       IF top > highest_phys: highest_phys = top\n  2. total_frames = highest_phys / PAGE_SIZE\n     (clamp to MAX_PHYS_FRAMES if larger)\n  3. // Mark ALL frames as used (set all bits to 1)\n     words_needed = (total_frames + 31) / 32\n     FOR i = 0 TO words_needed-1: frame_bitmap[i] = 0xFFFFFFFF\n     free_frames = 0\n  4. // Free frames from usable E820 regions\n     FOR each region in phys_regions[]:\n       IF region.type != MMAP_TYPE_USABLE: CONTINUE\n       frame_start = CEILING(region.base, PAGE_SIZE) / PAGE_SIZE\n       frame_end   = FLOOR(region.base + region.length, PAGE_SIZE) / PAGE_SIZE\n       FOR f = frame_start TO frame_end-1:\n         IF frame_bitmap[f/32] & (1 << (f%32)):\n           frame_bitmap[f/32] &= ~(1u << (f%32))\n           free_frames++\n  5. // Re-reserve critical physical regions:\n     // 5a. Frame 0 (IVT + BDA, also NULL pointer protection)\n     pmm_mark_used(0, 1)\n     // 5b. Kernel binary [__kernel_start, __kernel_end)\n     kphys_start = VIRT_TO_PHYS((uint32_t)&__kernel_start) / PAGE_SIZE\n     kphys_end   = CEILING(VIRT_TO_PHYS((uint32_t)&__kernel_end), PAGE_SIZE) / PAGE_SIZE\n     pmm_mark_used(kphys_start, kphys_end - kphys_start)\n     // 5c. frame_bitmap array itself\n     bm_phys_start = VIRT_TO_PHYS((uint32_t)frame_bitmap) / PAGE_SIZE\n     bm_size_frames = CEILING(sizeof(frame_bitmap), PAGE_SIZE) / PAGE_SIZE\n     pmm_mark_used(bm_phys_start, bm_size_frames)\n     // 5d. Boot page tables (boot_pd, pt_low, pt_high \u2014 each 4KB, 4KB-aligned)\n     pmm_mark_used(VIRT_TO_PHYS((uint32_t)&boot_pd)  / PAGE_SIZE, 1)\n     pmm_mark_used(VIRT_TO_PHYS((uint32_t)&pt_low)   / PAGE_SIZE, 1)\n     pmm_mark_used(VIRT_TO_PHYS((uint32_t)&pt_high)  / PAGE_SIZE, 1)\n     // 5e. Multiboot info structure (protect from accidental allocation)\n     pmm_mark_used((uint32_t)mbi / PAGE_SIZE, 1)\n  6. kprintf(\"[PMM] %u MB physical; %u frames free\\n\",\n             total_frames*4/1024, free_frames)\n```\n**`pmm_mark_used(frame_start, count)` helper (static, not exported):**\n```c\nstatic void pmm_mark_used(uint32_t frame_start, uint32_t count) {\n    for (uint32_t f = frame_start; f < frame_start + count && f < total_frames; f++) {\n        if (!(frame_bitmap[f / 32] & (1u << (f % 32)))) {\n            frame_bitmap[f / 32] |= (1u << (f % 32));\n            if (free_frames > 0) free_frames--;\n        }\n        // If already marked used: silently ignore (double-reservation is not a bug here)\n    }\n}\n```\n---\n### 5.3 `pmm_alloc_frame` \u2014 First-Fit Bitmap Scan\n```c\nuint32_t pmm_alloc_frame(void) {\n    uint32_t words = (total_frames + 31) / 32;\n    for (uint32_t i = 0; i < words; i++) {\n        if (frame_bitmap[i] == 0xFFFFFFFF) continue;  // All used \u2014 fast skip\n        // At least one free bit in this word\n        uint32_t bit = (uint32_t)__builtin_ctz(~frame_bitmap[i]); // First 0-bit\n        uint32_t frame = i * 32 + bit;\n        if (frame >= total_frames) break;  // Shouldn't happen; safety check\n        frame_bitmap[i] |= (1u << bit);   // Mark used\n        free_frames--;\n        return FRAME_TO_PHYS(frame);       // Return physical address\n    }\n    kprintf(\"[PMM] OUT OF PHYSICAL MEMORY (%u frames total)\\n\", total_frames);\n    for (;;) { __asm__ volatile (\"cli; hlt\"); }\n    return 0; // Unreachable\n}\n```\n**`__builtin_ctz` note:** GCC/Clang intrinsic for \"count trailing zeros\" \u2014 compiles to a single `BSF` (Bit Scan Forward) instruction on x86. Behavior is undefined if the argument is 0; the `== 0xFFFFFFFF` check above guarantees `~frame_bitmap[i] != 0` before `__builtin_ctz` is called.\n---\n### 5.4 Paging Bootstrap and Higher-Half Jump\n{{DIAGRAM:tdd-diag-19}}\nThis is the most critical sequence in the milestone. Every step must be performed in exact order.\n**Phase A \u2014 Build page tables in C (before paging enabled):**\nAll addresses here are physical = virtual (paging off).\n```c\nvoid paging_init(multiboot_info_t *mbi) {\n    (void)mbi;\n    // Step 1: Fill pt_low \u2014 identity map first 4 MB\n    // Maps virtual 0x00000000\u20130x003FFFFF \u2192 physical 0x00000000\u20130x003FFFFF\n    // Required: execution is currently at physical 0x001xxxxx = virtual 0x001xxxxx\n    // Without this map, the first fetch after CR0.PG=1 faults.\n    for (uint32_t i = 0; i < 1024; i++) {\n        uint32_t phys = i * PAGE_SIZE;\n        uint32_t flags = PTE_PRESENT | PTE_WRITABLE;\n        // VGA MMIO: disable cache to guarantee writes hit hardware\n        if (phys >= 0xB8000 && phys < 0xC0000) flags |= PTE_CACHE_DIS;\n        pt_low[i] = PTE_SET_FRAME(phys, flags);\n    }\n    // Step 2: Fill pt_high \u2014 kernel higher-half map\n    // Maps virtual 0xC0000000\u20130xC03FFFFF \u2192 physical 0x00000000\u20130x003FFFFF\n    // Same physical frames as pt_low; different virtual base address.\n    for (uint32_t i = 0; i < 1024; i++) {\n        uint32_t phys = i * PAGE_SIZE;\n        uint32_t flags = PTE_PRESENT | PTE_WRITABLE;\n        if (phys >= 0xB8000 && phys < 0xC0000) flags |= PTE_CACHE_DIS;\n        pt_high[i] = PTE_SET_FRAME(phys, flags);\n    }\n    // Step 3: Install PTEs in page directory\n    // PD index 0   \u2192 covers virtual 0x00000000 (identity map)\n    // PD index 768 \u2192 covers virtual 0xC0000000 (higher half, 0xC0000000>>22 = 768)\n    uint32_t pt_low_phys  = VIRT_TO_PHYS((uint32_t)pt_low);\n    uint32_t pt_high_phys = VIRT_TO_PHYS((uint32_t)pt_high);\n    boot_pd[0]   = PTE_SET_FRAME(pt_low_phys,  PTE_PRESENT | PTE_WRITABLE);\n    boot_pd[768] = PTE_SET_FRAME(pt_high_phys, PTE_PRESENT | PTE_WRITABLE);\n    // All other PD entries are 0 (not present) \u2014 already zeroed by BSS.\n    // Step 4: Call assembly trampoline (cannot be done in C)\n    uint32_t pd_phys = VIRT_TO_PHYS((uint32_t)boot_pd);\n    paging_enable_and_jump(pd_phys);\n    // NEVER RETURNS to this call site.\n    // After the assembly trampoline runs, execution resumes at\n    // paging_high_entry() below (virtual address).\n}\n```\n**Phase B \u2014 Assembly trampoline (`paging_boot.asm`):**\n```nasm\n; paging_boot.asm\n[BITS 32]\n[GLOBAL paging_enable_and_jump]\n[EXTERN paging_high_entry]     ; C function at virtual 0xC01xxxxx\npaging_enable_and_jump:\n    ; Argument: [esp+4] = physical address of boot_pd\n    mov  eax, [esp+4]\n    ; \u2500\u2500 Step 5: Load CR3 with physical address of page directory \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    ; CR3 bits 31:12 = page directory physical address (4KB-aligned, so bits 11:0 must be 0)\n    ; CR3 bits 11:0 = cache control flags (0 = write-back, not disabled)\n    ; Since boot_pd is 4KB-aligned, the physical address has bits 11:0 = 0.\n    mov  cr3, eax\n    ; \u2500\u2500 Step 6: Enable paging by setting CR0.PG (bit 31) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    ; Also ensure CR0.WP (bit 16) is set \u2014 write-protect kernel pages from kernel\n    ; (optional in M3 but good practice)\n    mov  eax, cr0\n    or   eax, 0x80000001       ; Set PG (bit 31) and ensure PE (bit 0) still set\n    mov  cr0, eax\n    ; <<< PAGING IS NOW ACTIVE >>>\n    ; The NEXT instruction is fetched at the current EIP using virtual addressing.\n    ; Current EIP \u2248 0x001xxxxx (physical). Because boot_pd[0] maps\n    ; virtual 0x001xxxxx \u2192 physical 0x001xxxxx (identity map), this fetch succeeds.\n    ; \u2500\u2500 Step 7: Far jump to higher-half virtual address \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    ; This serves two purposes:\n    ; (a) Loads EIP with the higher-half virtual address (0xC01xxxxx)\n    ; (b) Flushes the pipeline (same reasoning as the CR0.PE far jump)\n    ;\n    ; paging_high_entry is linked at 0xC01xxxxx by the updated linker script.\n    ; The 'jmp' uses an absolute virtual address \u2014 valid because pt_high maps it.\n    jmp  paging_high_entry\n    ; \u2500\u2500 EXECUTION DOES NOT RETURN HERE \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n```\n**Phase C \u2014 Higher-half C continuation (`paging.c`):**\n```c\n// Called by the assembly 'jmp paging_high_entry' \u2014 never called by C\n// This function runs at virtual address 0xC01xxxxx.\n// At this point: identity map still active (boot_pd[0] != 0).\nvoid paging_high_entry(void) {\n    // \u2500\u2500 Step 8: Remove the identity map \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    // boot_pd[0] maps virtual 0x00000000 \u2192 physical pt_low.\n    // After removal, accessing any address in [0, 0x3FFFFF] triggers #PF.\n    // This makes NULL pointer dereferences catchable.\n    boot_pd[0] = 0;\n    // \u2500\u2500 Step 9: Full TLB flush (CR3 reload) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    // Must flush after clearing boot_pd[0] or the old mapping stays in TLB.\n    // Use full flush because we removed an entire 4MB region.\n    tlb_flush_all();\n    // \u2500\u2500 Step 10: Update VGA pointer to use higher-half virtual address \u2500\u2500\u2500\n    // The VGA buffer was at physical 0xB8000.\n    // With pt_high mapping 0xC0000000\u20130xC03FFFFF \u2192 0x00000000\u20130x003FFFFF:\n    // Virtual address = 0xC0000000 + 0xB8000 = 0xC00B8000\n    // Update the VGA driver's internal buffer pointer (driver must support this).\n    // Implementation: vga_set_buffer((volatile uint16_t*)0xC00B8000);\n    // \u2500\u2500 Step 11: Return to kernel_main (now at higher-half address) \u2500\u2500\u2500\u2500\u2500\n    // The kernel stack (kernel_stack in .bss) is mapped at its virtual address.\n    // The call stack going back to kernel_main is valid because both\n    // kernel_entry.asm and kernel_main.c are linked at 0xC01xxxxx.\n    // paging_high_entry is called via 'jmp', so there is no return address here.\n    // We must call kernel_main_resume() or restructure the call chain.\n    // See \u00a77 (Implementation Sequence) for the recommended call structure.\n    kernel_main_paging_done();  // Tail-call into the next phase of kernel_main\n}\n```\n**Linker script update (VMA/LMA split):**\n```ld\n/* kernel.ld \u2014 Updated for higher-half kernel */\nENTRY(kernel_entry)\nKERNEL_VIRT_BASE = 0xC0000000;\nKERNEL_PHYS_BASE = 0x00100000;\nSECTIONS {\n    . = KERNEL_VIRT_BASE + KERNEL_PHYS_BASE;   /* VMA = 0xC0100000 */\n    .text ALIGN(4096) : AT(ADDR(.text) - KERNEL_VIRT_BASE) {\n        *(.multiboot)\n        *(.text)\n        *(.text.*)\n    }\n    .rodata ALIGN(4096) : AT(ADDR(.rodata) - KERNEL_VIRT_BASE) {\n        *(.rodata)\n        *(.rodata.*)\n    }\n    .data ALIGN(4096) : AT(ADDR(.data) - KERNEL_VIRT_BASE) {\n        *(.data)\n        *(.data.*)\n    }\n    .bss ALIGN(4096) : AT(ADDR(.bss) - KERNEL_VIRT_BASE) {\n        __kernel_start = .;       /* Used by PMM to reserve kernel frames */\n        __bss_start    = .;\n        *(.bss)\n        *(.bss.*)\n        *(COMMON)\n        __bss_end      = .;\n    }\n    __kernel_end      = .;        /* Used by PMM and heap */\n    __kernel_phys_end = __kernel_end - KERNEL_VIRT_BASE;\n}\n```\n**Critical linker constraint:** `kernel_entry.asm` must work at both physical and virtual addresses during the boot trampoline. Its first instructions run at physical `0x00100000` (where the bootloader loaded it), but the linker has resolved all labels to `0xC0100000`. The `kernel_entry` bootstrap code must therefore use only position-independent instructions (no absolute address loads) until `paging_high_entry` is reached. In practice, `kernel_entry.asm` uses `__bss_start` and `__bss_end` as absolute labels \u2014 these will have values starting at `0xC01xxxxx`. Before paging, these values are wrong as physical addresses. **Solution:** perform BSS zeroing and `kernel_main` call only from `paging_high_entry`, after paging is on, so that virtual addresses are valid. Restructure `kernel_entry.asm` to be minimal: set up a temporary physical stack, call `paging_init_physical` (a C function that uses only addresses below `0x400000` and works before paging), then the assembly trampoline takes over.\n---\n### 5.5 `kmalloc` \u2014 First-Fit with Split\n{{DIAGRAM:tdd-diag-20}}\n```\nPROCEDURE kmalloc(size):\n  1. IF size == 0: size = HEAP_ALIGN\n  2. size = ALIGN_UP(size, HEAP_ALIGN)   // Round up to 8-byte boundary\n  3. block = heap_head\n  4. WHILE block != NULL:\n       a. IF block->magic != HEAP_MAGIC: halt with corruption message\n       b. IF NOT block->used AND block->size >= size:\n            GOTO found\n       c. block = block->next\n  5. // No suitable block: extend heap\n     block = heap_extend(size)\n     // heap_extend commits new page(s) and creates a free block covering them\n     // Then fall through to 'found' (the new block is always large enough)\n  found:\n  6. // Optionally split: if remainder is large enough for another allocation\n     remainder_size = block->size - size - sizeof(heap_block_t)\n     IF remainder_size >= HEAP_ALIGN:\n       // Create a new free block in the remainder\n       new_block = (heap_block_t*)((uint8_t*)(block+1) + size)\n       new_block->magic = HEAP_MAGIC\n       new_block->size  = remainder_size\n       new_block->used  = 0\n       new_block->next  = block->next\n       new_block->prev  = block\n       IF block->next != NULL: block->next->prev = new_block\n       block->next = new_block\n       block->size = size\n  7. block->used = 1\n  8. RETURN (void*)(block + 1)   // Pointer past the header\n```\n**`heap_extend(min_size)` \u2014 commit new pages:**\n```c\nstatic heap_block_t *heap_extend(uint32_t min_size) {\n    uint32_t needed = min_size + sizeof(heap_block_t);\n    uint32_t pages  = (needed + PAGE_SIZE - 1) / PAGE_SIZE;\n    if (heap_brk + pages * PAGE_SIZE > HEAP_END) {\n        kprintf(\"[HEAP] Virtual heap exhausted (brk=0x%x)\\n\", heap_brk);\n        for (;;) { __asm__ volatile (\"cli; hlt\"); }\n    }\n    uint32_t new_block_virt = heap_brk;\n    for (uint32_t i = 0; i < pages; i++) {\n        uint32_t phys = pmm_alloc_frame();\n        paging_map((page_directory_t*)PHYS_TO_VIRT(\n                       PTE_GET_FRAME(/* read CR3 */ get_cr3())),\n                   heap_brk, phys, PTE_PRESENT | PTE_WRITABLE);\n        heap_brk += PAGE_SIZE;\n    }\n    heap_block_t *block = (heap_block_t*)new_block_virt;\n    block->magic = HEAP_MAGIC;\n    block->size  = pages * PAGE_SIZE - sizeof(heap_block_t);\n    block->used  = 0;\n    block->next  = NULL;\n    block->prev  = NULL;\n    // Append to end of block list\n    if (heap_head == NULL) {\n        heap_head = block;\n    } else {\n        heap_block_t *last = heap_head;\n        while (last->next != NULL) last = last->next;\n        last->next = block;\n        block->prev = last;\n    }\n    return block;\n}\n```\n**`get_cr3()` helper:**\n```c\nstatic inline uint32_t get_cr3(void) {\n    uint32_t val;\n    __asm__ volatile (\"mov %0, cr3\" : \"=r\"(val));\n    return val;\n}\n```\n---\n### 5.6 `kfree` \u2014 Coalescing Free\n```\nPROCEDURE kfree(ptr):\n  1. IF ptr == NULL: RETURN  // No-op (matches C standard)\n  2. block = (heap_block_t*)ptr - 1\n  3. IF block->magic != HEAP_MAGIC:\n       kprintf(\"[HEAP] CORRUPTION: bad magic at ptr=0x%x\\n\", ptr); halt\n  4. IF block->used == 0:\n       kprintf(\"[HEAP] DOUBLE FREE: ptr=0x%x\\n\", ptr); halt\n  5. block->used = 0\n  // Coalesce with NEXT block\n  6. IF block->next != NULL:\n       next = block->next\n       IF next->magic != HEAP_MAGIC:\n         kprintf(\"[HEAP] CORRUPTION: neighbor bad magic at 0x%x\\n\", next); halt\n       IF next->used == 0:\n         // Merge block and next into block\n         block->size += sizeof(heap_block_t) + next->size\n         block->next  = next->next\n         IF next->next != NULL: next->next->prev = block\n         next->magic  = 0  // Invalidate merged block's header\n  // Coalesce with PREVIOUS block\n  7. IF block->prev != NULL:\n       prev = block->prev\n       IF prev->magic != HEAP_MAGIC:\n         kprintf(\"[HEAP] CORRUPTION: neighbor bad magic at 0x%x\\n\", prev); halt\n       IF prev->used == 0:\n         prev->size += sizeof(heap_block_t) + block->size\n         prev->next  = block->next\n         IF block->next != NULL: block->next->prev = prev\n         block->magic = 0  // Invalidate absorbed block's header\n```\n**Coalescing order matters:** Always coalesce forward (with `next`) before backward (with `prev`). This ensures that after merging `block` and `next`, the backward coalesce correctly accounts for the full merged size.\n---\n### 5.7 Page Fault Handler Update\n```c\n// In interrupt.c, case vec==14 (update from M2 stub):\nvoid page_fault_handler_extended(interrupt_frame_t *frame) {\n    uint32_t fault_addr;\n    __asm__ volatile (\"mov %0, cr2\" : \"=r\"(fault_addr));\n    int p     = (frame->err_code >> 0) & 1; // 0=not present, 1=protection violation\n    int write = (frame->err_code >> 1) & 1; // 0=read, 1=write\n    int user  = (frame->err_code >> 2) & 1; // 0=kernel, 1=user-mode access\n    int rsvd  = (frame->err_code >> 3) & 1; // 1=reserved bit set in PTE (CPU bug?)\n    int ifetch= (frame->err_code >> 4) & 1; // 1=instruction fetch\n    kprintf(\"\\n[#PF] Page Fault at virtual address 0x%p\\n\", fault_addr);\n    kprintf(\"  EIP=0x%p  CS=0x%x  EFLAGS=0x%x\\n\",\n            frame->eip, frame->cs, frame->eflags);\n    kprintf(\"  Access: %s%s from %s mode\\n\",\n            write ? \"WRITE\" : \"READ\",\n            ifetch ? \" (IFETCH)\" : \"\",\n            user ? \"USER\" : \"KERNEL\");\n    kprintf(\"  Cause: %s%s\\n\",\n            p ? \"Protection violation\" : \"Page not present\",\n            rsvd ? \" [RESERVED BIT SET - CPU BUG]\" : \"\");\n    if (!user) {\n        // Kernel page fault is always a kernel bug in M3 \u2014 no demand paging yet\n        kprintf(\"  [KERNEL FAULT] \u2014 system halted\\n\");\n        for (;;) __asm__ volatile (\"cli; hlt\");\n    } else {\n        // User page fault placeholder \u2014 M4 will implement demand paging here\n        kprintf(\"  [USER FAULT] \u2014 no demand pager in M3, halting\\n\");\n        for (;;) __asm__ volatile (\"cli; hlt\");\n    }\n}\n```\n---\n## 6. Error Handling Matrix\n| Error | Detected By | Recovery | User-Visible? |\n|-------|-------------|----------|---------------|\n| Multiboot flags missing `MBOOT_FLAG_MMAP` | `mmap_parse`: `!(mbi->flags & MBOOT_FLAG_MMAP)` | `kprintf` error + `cli; hlt` | kprintf message on VGA/serial |\n| No usable E820 region found | `mmap_parse`: `phys_region_count == 0` after parse | `kprintf` error + `cli; hlt` | kprintf message |\n| PMM OOM \u2014 no free frames | `pmm_alloc_frame`: scan completed without free bit | `kprintf(\"[PMM] OUT OF MEMORY\")` + halt | kprintf message |\n| PMM double-free | `pmm_free_frame`: frame bit already 0 | `kprintf(\"[PMM] DOUBLE FREE: phys=0x%x\")` + halt | kprintf message |\n| PMM misaligned free address | `pmm_free_frame`: `phys_addr & 0xFFF != 0` | `kprintf` error + halt | kprintf message |\n| PMM out-of-range free address | `pmm_free_frame`: frame >= total_frames | `kprintf` error + halt | kprintf message |\n| Triple-fault: CR0.PG=1 without identity map | Hardware: next fetch after `mov cr0,eax` is at 0x001xxxxx, no PTE_PRESENT \u2192 #PF \u2192 no IDT mapped yet \u2192 #DF \u2192 triple-fault | Machine reset | QEMU `-d int` shows `v=0e` then `v=08` then `CPU Reset` |\n| Triple-fault: missing `boot_pd[768]` before jump | Hardware: `jmp paging_high_entry` (at 0xC01xxxxx) with no PDE 768 \u2192 #PF \u2192 triple-fault | Machine reset | QEMU `-d int` shows `v=0e` at fault addr 0xC01xxxxx |\n| TLB stale translation | Hardware: silent wrong physical frame used | Non-deterministic memory corruption, eventual wrong data or fault | May be invisible for many instructions; eventually manifests as data corruption or spurious #PF |\n| Identity map not removed after higher-half jump | Not an immediate error; NULL pointer dereference silently reads physical 0 instead of faulting | Deferred corruption; NULL pointer bugs become invisible | No immediate symptom; debugging becomes harder |\n| `boot_pd` not 4KB-aligned | Hardware: CR3 interprets low bits as flags, translates from wrong base | Immediate #PF on first fetch after CR3 load | Triple-fault |\n| Heap HEAP_MAGIC corrupted | `kmalloc`/`kfree`: `block->magic != HEAP_MAGIC` on traversal | `kprintf(\"[HEAP] CORRUPTION at 0x%x\")` + halt | kprintf message |\n| Heap double-free | `kfree`: `block->used == 0` | `kprintf(\"[HEAP] DOUBLE FREE: ptr=0x%x\")` + halt | kprintf message |\n| Heap virtual address exhausted | `heap_extend`: `heap_brk + pages*PAGE_SIZE > HEAP_END` | `kprintf(\"[HEAP] Virtual heap exhausted\")` + halt | kprintf message |\n| Kernel page fault (NULL deref, wild ptr) | `page_fault_handler_extended`: `!user` | `kprintf` fault details + halt | Detailed fault message with CR2, EIP, error code bits |\n| Page directory not accessible from higher-half | `paging_map`: `pd` virtual ptr not in kernel-mapped range | #PF in `paging_map` itself \u2192 caught by page fault handler | #PF fault message |\n| `paging_map` called on already-mapped virtual addr | `paging_map`: `(*pt)[pt_idx] & PTE_PRESENT` already set | `kprintf` warning, remap proceeds (not a halt) | kprintf warning |\n---\n## 7. Implementation Sequence with Checkpoints\n### Phase 1 \u2014 E820 Memory Map Parser (3\u20135 hours)\n1. Add `multiboot_info_t` and `multiboot_mmap_entry_t` to `mmap.h` with exact byte-offset fields. Add `phys_region_t` and extern declarations.\n2. Write `mmap.c`: implement `mmap_parse` per \u00a75.1. Log each region with type string.\n3. In `kernel_entry.asm`: save EBX (Multiboot info pointer) before zeroing registers. Pass it to `kernel_main` as a parameter (push EBX before `call kernel_main`; update `kernel_main` signature to `void kernel_main(multiboot_info_t *mbi)`).\n4. Call `mmap_parse(mbi)` as the first statement in `kernel_main`.\n**Checkpoint 1:** `make run -serial stdio` shows the physical memory map printed by `mmap_parse`. A 128 MB QEMU machine (`-m 128`) should print at minimum: usable region starting at 0x00100000 of approximately 127 MB, and one or more reserved regions. Verify entry count > 0 and at least one `MMAP_TYPE_USABLE` entry.\n---\n### Phase 2 \u2014 Bitmap PMM (4\u20136 hours)\n1. Write `pmm.h` and `pmm.c`. Implement `pmm_init`, `pmm_alloc_frame`, `pmm_free_frame`, `pmm_free_frames`, `pmm_mark_used` (static helper).\n2. Call `pmm_init(mbi)` in `kernel_main` after `mmap_parse`.\n3. Add compile-time assert: `sizeof(frame_bitmap) == MAX_PHYS_FRAMES / 8` (128 KB for 4 GB).\n4. Test: After `pmm_init`, call `pmm_alloc_frame()` 4 times; verify all 4 addresses are distinct, nonzero, 4KB-aligned, and in usable memory range. Call `pmm_free_frame` on one; verify `free_frames` increases. Attempt `pmm_free_frame` on same address again; verify halt.\n**Checkpoint 2:** Serial output shows `[PMM] N MB physical; M frames free` where N matches QEMU `-m` value and M is approximately N*256 minus kernel size. Allocating and freeing frames succeeds. Double-free halts with the expected message visible on VGA and serial.\n---\n### Phase 3 \u2014 Linker Script Update (2\u20133 hours)\n1. Update `kernel.ld` with `KERNEL_VIRT_BASE = 0xC0000000`, `KERNEL_PHYS_BASE = 0x00100000`, and `AT()` directives on all sections per \u00a75.4.\n2. Verify: `readelf -S kernel.elf` \u2014 `.text` VMA = `0xC0100000`, LMA = `0x00100000`. `nm kernel.elf | grep __kernel` \u2014 `__kernel_start` and `__kernel_end` values begin with `0xC01`.\n3. Verify: `objcopy -O binary kernel.elf kernel.bin && wc -c kernel.bin` \u2014 binary size reasonable (not 3 GB). The `AT()` directive ensures LMA = physical; `objcopy` strips ELF and produces flat binary at LMA values.\n4. Update `kernel_entry.asm` to handle the VMA/LMA split: BSS symbols (`__bss_start`, `__bss_end`) now have values like `0xC01xxxxx`. The `rep stosb` must run before paging is on \u2014 but those virtual addresses are invalid before paging. **Solution:** do NOT zero BSS in `kernel_entry.asm` before paging. Instead, zero BSS in `paging_high_entry` after paging is enabled and the higher-half map makes `0xC01xxxxx` valid. `kernel_entry.asm` only sets a temporary physical stack and calls `paging_init`.\n**Checkpoint 3:** `objdump -d kernel.elf | head -5` shows `kernel_entry` at VMA `0xC0100000`. `objdump -d kernel.elf -j .text | grep \"c01\"` \u2014 confirms all code addresses start with `0xc01`.\n---\n### Phase 4 \u2014 Static Page Tables + CR0.PG + Higher-Half Jump (6\u201310 hours)\n{{DIAGRAM:tdd-diag-21}}\n1. Write `paging.h` with all constants, macros, type aliases, and extern declarations.\n2. Write `paging.c` with `boot_pd`, `pt_low`, `pt_high` static arrays and `paging_init`.\n3. Write `paging_boot.asm` with `paging_enable_and_jump` and the `jmp paging_high_entry` instruction.\n4. Write `paging_high_entry` in `paging.c` (C function at virtual address). This function: zeros BSS (now valid since higher-half map is active), calls `kprintf` test, calls `kernel_main_paging_done()`.\n5. Restructure `kernel_main.c`: split into `kernel_main(mbi)` (pre-paging: mmap_parse, pmm_init, paging_init \u2014 which never returns) and `kernel_main_paging_done()` (post-paging: heap_init, IDT re-register, sti, tests).\n**Incremental testing approach to avoid silent triple-faults:**\nBefore the full higher-half jump, verify paging works with identity map only:\n- Temporarily skip the `jmp paging_high_entry` in `paging_boot.asm` and instead `ret` (stays at physical addresses).\n- `kprintf(\"paging on, still at physical addr\\n\")` \u2014 this uses physical `0xB8000` for VGA, which is identity-mapped in `pt_low`. If it prints, identity map works.\n- Then add the `jmp paging_high_entry` \u2014 this moves to virtual addresses.\n**Checkpoint 4A (identity map only):** System prints \"paging on\" message at physical VGA address. QEMU `info mem` shows `0x00000000\u20130x003FFFFF` mapped with `rwx`.\n**Checkpoint 4B (full higher-half):** System prints message from `paging_high_entry`. QEMU `info mem` shows `0xC0000000\u20130xC03FFFFF` mapped. QEMU `info pg` shows PD[0] and PD[768] as present.\n---\n### Phase 5 \u2014 Identity Map Removal + TLB Utilities (2\u20133 hours)\n1. Implement `tlb_flush_page` and `tlb_flush_all` in `paging.c`.\n2. In `paging_high_entry`: after `kprintf` confirming higher-half is working, set `boot_pd[0] = 0` and call `tlb_flush_all()`.\n3. Update VGA driver to use virtual `0xC00B8000` instead of physical `0xB8000`. Add `vga_set_buffer` or update the compile-time constant.\n4. Test NULL deref catches: temporarily dereference NULL (`*(volatile int*)0 = 1`). Should trigger #PF with CR2=0, P=0, W=1, U=0 and halt with diagnostic. Remove after verification.\n**Checkpoint 5:** After `boot_pd[0] = 0` and TLB flush, QEMU `info mem` shows `0x00000000` no longer mapped. VGA output still works (using `0xC00B8000`). NULL dereference produces the page fault handler's diagnostic message.\n---\n### Phase 6 \u2014 Dynamic `paging_map`/`paging_unmap` (3\u20135 hours)\n1. Implement `paging_map`, `paging_unmap`, `get_cr3` (static helper) in `paging.c`.\n2. Test: map a new virtual address (`0xD0000000`) to a freshly allocated physical frame. Write a pattern to the mapped virtual address. Read back and verify. Unmap. Verify that accessing it generates a #PF. Re-map with a different frame. Verify new mapping works.\n**Checkpoint 6:** `paging_map(boot_pd_virt, 0xD0000000, pmm_alloc_frame(), PTE_PRESENT|PTE_WRITABLE)` succeeds. `*(volatile uint32_t*)0xD0000000 = 0x12345678` followed by read-back returns `0x12345678`. `paging_unmap(boot_pd_virt, 0xD0000000)` followed by access generates #PF at CR2=0xD0000000.\n---\n### Phase 7 \u2014 Page Fault Handler Enhancement (2\u20133 hours)\n1. Update `interrupt.c` case `vec==14` to call the full `page_fault_handler_extended` per \u00a75.7.\n2. Test all five error code bit combinations in QEMU with deliberate faults: not-present read, not-present write, protection violation (would require M4 user pages \u2014 defer protection violation test).\n**Checkpoint 7:** Page fault diagnostic prints: virtual address (CR2), EIP, access type (READ/WRITE), privilege (KERNEL/USER), cause (not present / protection violation).\n---\n### Phase 8 \u2014 `kmalloc`/`kfree` Heap (4\u20136 hours)\n{{DIAGRAM:tdd-diag-22}}\n1. Write `heap.h` and `heap.c`. Implement `heap_init`, `kmalloc`, `kfree`, `heap_extend` (static).\n2. Call `heap_init()` in `kernel_main_paging_done()` before `sti`.\n3. The `heap_extend` function uses `paging_map` \u2014 verify `get_cr3()` returns the boot_pd physical address.\n**Checkpoint 8A \u2014 Basic allocation:** `void *a = kmalloc(64); void *b = kmalloc(128);` \u2014 both non-NULL, distinct, \u2265 8-byte aligned, at addresses \u2265 `HEAP_START`. `memset(a, 0xAA, 64); memset(b, 0xBB, 128)` \u2014 no fault. Verify VGA still works after heap writes.\n**Checkpoint 8B \u2014 Free and reuse:** `kfree(a); void *c = kmalloc(32);` \u2014 `c` should be at or near `a` (first-fit reuse). Verify coalescing: `kfree(c); kfree(b)` \u2014 heap should coalesce adjacent free blocks (verify via internal `heap_head->size` inspection with GDB).\n**Checkpoint 8C \u2014 Corruption detection:** Deliberately write past end of an allocation: `char *p = kmalloc(8); p[sizeof(heap_block_t) + 8] = 0xFF;` \u2014 the next `kmalloc` call that traverses the corrupted block should detect `magic != HEAP_MAGIC` and halt. Remove after verification.\n---\n### Phase 9 \u2014 Integration Test (2\u20133 hours)\n{{DIAGRAM:tdd-diag-23}}\nFinal integration test sequence in `kernel_main_paging_done()`:\n```c\nkprintf(\"=== M3 Integration Tests ===\\n\");\n// 1. PMM stats\nkprintf(\"PMM: %u frames free (%u MB)\\n\",\n        pmm_free_frames(), pmm_free_frames() * 4 / 1024);\n// 2. kmalloc stress\n#define N 16\nvoid *ptrs[N];\nfor (int i = 0; i < N; i++) {\n    ptrs[i] = kmalloc(64 * (i + 1));\n    __builtin_memset(ptrs[i], (uint8_t)i, 64 * (i + 1));\n}\nkprintf(\"kmalloc x%d: OK\\n\", N);\n// 3. Free alternating and reallocate\nfor (int i = 0; i < N; i += 2) kfree(ptrs[i]);\nfor (int i = 0; i < N; i += 2) {\n    ptrs[i] = kmalloc(32);\n    __builtin_memset(ptrs[i], 0xCC, 32);\n}\nkprintf(\"kfree+realloc: OK\\n\");\n// 4. Free all\nfor (int i = 0; i < N; i++) kfree(ptrs[i]);\nkprintf(\"kfree all: OK\\n\");\n// 5. PMM stats after heap test (some frames still committed to heap)\nkprintf(\"PMM after heap: %u frames free\\n\", pmm_free_frames());\n// 6. QEMU info pg verification (manual)\nkprintf(\"Run 'info pg' in QEMU monitor to verify address space\\n\");\nkprintf(\"Expected: 0xC0000000-0xC03FFFFF mapped, 0x00000000 absent\\n\");\nkprintf(\"=== M3 PASS ===\\n\");\n```\n**Checkpoint 9 (QEMU monitor verification):**\n```\n(QEMU) info mem\n  00000000c0000000-00000000c0400000 0000000000400000 -rw\n(QEMU) info pg\n  PDE[768]: physaddr=<pt_high_phys> present rw\n  PDE[0]: not present\n(QEMU) x/4x 0xc00b8000\n  (VGA buffer contents visible)\n```\n---\n## 8. Test Specification\n### 8.1 Multiboot Parser Tests\n| Test | Setup | Expected |\n|------|-------|----------|\n| Valid multiboot with mmap | QEMU 128 MB: default GRUB config | `phys_region_count >= 2`; at least one usable region covers `0x100000`\u2013`0x7XXXXXX` |\n| Flag check failure | Manually clear bit 6 of `mbi->flags` (debug) | `kprintf` error + halt (observable on VGA/serial) |\n| Entry pointer advance | Verify by printing all entries | Each entry's base + length = next entry's base (for contiguous maps) |\n| 64-bit base > 4GB | Mock entry with `base_addr = 0x100000000` | Entry skipped; `phys_region_count` not incremented |\n| Truncated length | Mock entry where `base + len` overflows 32-bit | `len` clamped; no integer overflow in parser |\n### 8.2 PMM Tests\n| Test | Setup | Expected |\n|------|-------|----------|\n| `pmm_alloc_frame` returns nonzero | After `pmm_init` | Return value \u2265 `PAGE_SIZE`, multiple of `PAGE_SIZE` |\n| `pmm_alloc_frame` returns distinct values | Call 10 times | All 10 values distinct |\n| Allocated frame not in kernel region | After `pmm_init` | No returned frame overlaps `[__kernel_phys_start, __kernel_phys_end)` |\n| `pmm_free_frame` \u2192 `pmm_alloc_frame` reuses frame | Free frame F; allocate again | Next allocation returns F (first-fit) |\n| Double-free halts | Free same address twice | Second call to `kfree` halts with `[PMM] DOUBLE FREE` message |\n| `free_frames` accuracy | After N allocs and M frees | `pmm_free_frames() == initial - N + M` |\n| Frame 0 never allocated | After `pmm_init` | `frame_bitmap[0] & 1 == 1` (frame 0 marked used) |\n| Kernel frames never allocated | Check all kernel physical frames | `frame_bitmap[f/32] & (1<<(f%32)) == 1` for all kernel frames |\n### 8.3 Paging Tests\n| Test | Assertion | Expected |\n|------|-----------|----------|\n| CR0.PG=1 after paging_init | `mov eax, cr0; test eax, 0x80000000` | PG bit set |\n| CR3 holds boot_pd physical | `mov eax, cr3` | `eax == VIRT_TO_PHYS(boot_pd)` |\n| Higher-half virtual mapped | Access `0xC0100000` after init | No fault; contains kernel code |\n| Identity map removed | `*(volatile int*)0x1000` after init | #PF with CR2=0x1000, P=0 |\n| NULL deref faults | `*(volatile int*)0` after init | #PF with CR2=0x0 |\n| VGA accessible at `0xC00B8000` | Write `'T'` to `[0xC00B8000]` | 'T' appears on VGA screen |\n| `paging_map` new frame | Map 0xD0000000, write/read | Write returns same read value |\n| `paging_unmap` removes map | Unmap 0xD0000000, read | #PF with CR2=0xD0000000 |\n| TLB flush after unmap | `invlpg` called (verified by `tlb_flush_page`) | Stale entry not used after unmap |\n| `boot_pd` 4KB-aligned | `(uint32_t)boot_pd & 0xFFF == 0` | True (guaranteed by `__attribute__((aligned(4096)))`) |\n### 8.4 Page Fault Handler Tests\n| Test | Trigger | Expected Output |\n|------|---------|-----------------|\n| Not-present read | `*(volatile int*)0x12345000` | CR2=0x12345000, P=0, READ, KERNEL |\n| Not-present write | `*(volatile int*)0x12345000 = 1` | CR2=0x12345000, P=0, WRITE, KERNEL |\n| NULL pointer | `*(volatile int*)0` | CR2=0x00000000, P=0, KERNEL |\n| All output fields | Any #PF | EIP, CS, EFLAGS all printed |\n### 8.5 `kmalloc`/`kfree` Tests\n| Test | Input | Expected |\n|------|-------|----------|\n| Basic allocation | `kmalloc(8)` | Non-NULL, \u2265 HEAP_START, 8-byte aligned |\n| Alignment | `kmalloc(1)`, `kmalloc(3)`, `kmalloc(7)` | All return 8-byte aligned pointers |\n| Write coverage | `kmalloc(4096)`, `memset(p, 0x55, 4096)` | No fault; readback matches |\n| Free-list reuse | `kmalloc(64)`, `kfree`, `kmalloc(32)` | Second alloc at or near first alloc address |\n| Split | `kmalloc(64)`, `kfree`, `kmalloc(8)`, `kmalloc(8)` | Both small allocs within original 64-byte region |\n| Forward coalesce | Alloc A, B adjacent; free A; free B; alloc A+B size | Single allocation fits without extending heap |\n| Backward coalesce | Alloc A, B, C; free C; free B; alloc B+C | Fits without extending heap |\n| HEAP_MAGIC check | `kmalloc(8)`, write 0 at `ptr[-1]` (corrupts magic), `kfree` | Halt with `[HEAP] CORRUPTION` message |\n| Double-free | `kmalloc(8)`, `kfree(p)`, `kfree(p)` | Halt with `[HEAP] DOUBLE FREE` message |\n| NULL kfree | `kfree(NULL)` | Returns without fault |\n| Stress: 256 allocs | Loop `kmalloc(64)` \u00d7 256 | All distinct addresses, no faults, all writable |\n---\n## 9. Performance Targets\n| Operation | Target | Measurement Method |\n|-----------|--------|--------------------|\n| `pmm_alloc_frame` (128 MB, 50% full) | < 1 \u00b5s | 16,384 words \u00d7 skip check; ~500 iterations avg at 50% full; ~500 cycles at 1 GHz |\n| `pmm_alloc_frame` (worst case, 99% full) | < 10 \u00b5s | 32,768 words \u00d7 1 compare each \u2248 32K cycles \u2248 10 \u00b5s at 3 GHz |\n| `pmm_free_frame` | < 100 ns | 3 instructions: divide, array read, bit clear; < 10 cycles |\n| `paging_map` (existing PT) | < 500 ns | Index compute + 2 array writes + 1 `invlpg` \u2248 10 cycles + TLB flush latency |\n| `paging_map` (new PT allocated) | < 5 \u00b5s | `pmm_alloc_frame` + zero 4KB + map PDE + map PTE + `invlpg` |\n| `tlb_flush_page` (`invlpg`) | < 10 ns | Single instruction; measured as ~20\u201350 CPU cycles on real hardware |\n| `tlb_flush_all` (CR3 reload) | < 100 ns | Single `mov cr3, eax`; evicts up to 1536 entries on typical CPUs |\n| `kmalloc` first-fit (10 live allocs) | < 500 ns | 10 linked-list traversals + pointer arithmetic |\n| `kmalloc` first-fit (1000 live allocs) | < 5 \u00b5s | 1000 cache-miss-prone pointer traversals (worst case) |\n| `kfree` with coalescing | < 500 ns | 2\u20134 pointer dereferences for neighbor check + coalesce |\n| `heap_extend` (1 new page) | < 5 \u00b5s | `pmm_alloc_frame` + `paging_map` + zero page write |\n| Page fault handler dispatch | < 500 ns | Same ISR path as M2 generic interrupt; CR2 read \u2248 1 cycle |\n| `mmap_parse` (20 E820 entries) | < 10 \u00b5s | 20 iterations \u00d7 pointer arithmetic + `kprintf` |\n**Memory consumption targets:**\n| Resource | Size | Notes |\n|----------|------|-------|\n| `frame_bitmap` | 128 KB (max) | Proportional to physical RAM: 4KB/frame \u00d7 1-bit/frame = 1 bit per 4 KB = 32 KB per 1 GB |\n| `boot_pd` | 4 KB | One page directory |\n| `pt_low` | 4 KB | Identity map PT |\n| `pt_high` | 4 KB | Higher-half kernel PT |\n| `phys_regions` | 24 \u00d7 64 = 1,536 B | Fixed-size array |\n| Heap overhead per alloc | 20 B (`heap_block_t`) | 31% overhead for 64-byte allocs; 2% for 4096-byte allocs |\n---\n## 10. Concurrency Specification\n**Model:** Single CPU; EFLAGS.IF=0 during all memory management initialization. `sti` is called only after `heap_init()` completes. After `sti`, the timer interrupt (IRQ0) fires at 100 Hz and calls `timer_handler` \u2192 `scheduler_tick` (M4). In M3, `scheduler_tick` is a no-op stub.\n**PMM re-entrancy:** The timer interrupt handler must NOT call `pmm_alloc_frame`. There are no locks. If a PMM allocation were interrupted by another PMM allocation, `free_frames` would be double-decremented and the frame just allocated might be allocated again. Enforce this by design: no interrupt handler in M3 calls `pmm_alloc_frame`. The page fault handler halts rather than demand-mapping (no allocation from fault handler).\n**TLB consistency:** Single CPU; no inter-processor TLB shootdown required. Every `paging_map` and `paging_unmap` calls `tlb_flush_page` before returning. The `\"memory\"` clobber in all inline assembly ensures the compiler does not reorder memory writes across the CR3/CR0/invlpg instructions.\n**Volatile usage:**\n- `frame_bitmap`: not `volatile` \u2014 modified only in non-IRQ context (M3). Safe after `sti` as long as IRQ handlers never touch it.\n- `heap_brk`, `heap_head`: not `volatile` \u2014 same rationale.\n- VGA buffer pointer: `volatile uint16_t *` \u2014 hardware MMIO writes must not be optimized away.\n- `tick_counter`: `volatile uint64_t` \u2014 modified in IRQ, read outside (from M2).\n**Lock ordering:** Not applicable (no locks in M3; single-threaded init).\n**Illegal operations:**\n- Calling `kmalloc` from within an interrupt handler (M3): would work on single-core but is architecturally incorrect preparation for M4. Document this restriction; enforce in M4 via `current_process` check.\n- Calling `pmm_alloc_frame` from the page fault handler: forbidden. The page fault handler in M3 always halts.\n---\n<!-- END_TDD_MOD -->\n\n\n<!-- TDD_MOD_ID: build-os-m4 -->\n# Technical Design Specification: Processes and Preemptive Scheduling (`build-os-m4`)\n---\n## 1. Module Charter\nThis module implements the full process abstraction on top of the M1\u2013M3 kernel foundation: process control blocks (PCBs) with complete CPU context capture, an assembly-level context switch routine that atomically swaps kernel stacks, a TSS registered in the GDT with per-switch ESP0 updates, a circular round-robin scheduler driven by the PIT IRQ0 handler, per-process page directories with user-space isolation and shared kernel PDEs, an `iretd`-based sequence for entering ring 3, and an INT 0x80 system call interface implementing `sys_write` (fd=1 \u2192 VGA+serial) and `sys_exit`. It delivers demonstrated preemptive multitasking across at least three concurrent kernel processes and at least one ring-3 user process whose accesses to kernel virtual addresses produce page faults with the U bit set.\nThis module does **not** implement `fork`, `exec`, `waitpid`, signals, blocking I/O primitives, scheduling priorities, process groups, copy-on-write semantics, user-space dynamic linking, `mmap` from user space, filesystem access, or SMP. The `keyboard_getchar` spin-wait from M2 remains the only blocking primitive available to kernel code.\n**Upstream dependency:** M3 must deliver: GDT (5 entries, selectors 0x00/0x08/0x10/0x18/0x20), IDT (256 gates, vectors 0\u201347 installed, sti called after `heap_init`), PIC remapped (IRQ0\u2192vector 32), PIT at 100 Hz, PMM operational, paging active with kernel at `0xC0100000`, `kmalloc`/`kfree` functional, `kprintf` operational on VGA+serial, `paging_map`/`paging_unmap` callable, `create_user_page_directory` stub or its equivalent logic available.\n**Downstream dependency:** None within this project scope. This is the terminal milestone. All four acceptance criteria groups are self-contained.\n**Invariants that must hold throughout:**\n1. `kernel_tss.esp0` always equals `current_process->kernel_stack_top` at the moment any `iretd` to ring 3 executes or any interrupt fires while ring 3 is active.\n2. `current_process` is never NULL after the bootstrap jump; always points to the RUNNING process.\n3. `current_process->state == PROCESS_RUNNING` for exactly one process at any instant.\n4. Every `context_switch_asm` call saves exactly six values (EBX, ESI, EDI, EBP, EFLAGS, EIP via `ret` address) to the old process's kernel stack and restores exactly six from the new process's kernel stack.\n5. CR3 always holds the physical address of `current_process->page_directory` after every context switch completes.\n6. Every `sys_exit` call leaves `process_list_head` and all `process->next` pointers in a valid circular list with no dangling references.\n---\n## 2. File Structure\nCreate files in this exact order:\n```\nbuild-os/\n\u251c\u2500\u2500 kernel/\n\u2502   \u251c\u2500\u2500 37  tss.h                # tss_t struct, kernel_tss extern, tss_init, tss_set_kernel_stack\n\u2502   \u251c\u2500\u2500 38  tss.c                # kernel_tss, tss_init (ICW into GDT + ltr), tss_set_kernel_stack\n\u2502   \u251c\u2500\u2500 39  process.h            # process_state_t, cpu_context_t, process_t, MAX_PROCESSES,\n\u2502   \u2502                            #   KERNEL_STACK_SIZE, current_process extern, process_list_head extern\n\u2502   \u251c\u2500\u2500 40  process.c            # process_create, process_destroy (M4: PCB + kernel stack alloc,\n\u2502   \u2502                            #   fabricated initial frame), next_pid global\n\u2502   \u251c\u2500\u2500 41  context_switch.asm   # context_switch_asm(cpu_context_t *old, cpu_context_t *new)\n\u2502   \u251c\u2500\u2500 42  scheduler.h          # scheduler_init, scheduler_add_process, scheduler_tick,\n\u2502   \u2502                            #   scheduler_remove_current prototypes\n\u2502   \u251c\u2500\u2500 43  scheduler.c          # circular list management, round-robin scheduler_tick,\n\u2502   \u2502                            #   context_switch C wrapper, scheduler_remove_current\n\u2502   \u251c\u2500\u2500 44  usermode.h           # create_user_page_directory, enter_user_mode prototypes\n\u2502   \u251c\u2500\u2500 45  usermode.c           # create_user_page_directory (copy kernel PDEs 768-1023),\n\u2502   \u2502                            #   user stack allocation, enter_user_mode (iretd sequence)\n\u2502   \u251c\u2500\u2500 46  syscall.h            # syscall_handler_t typedef, SYS_* constants, syscall_dispatch\n\u2502   \u251c\u2500\u2500 47  syscall.c            # syscall_table[], sys_write, sys_exit, syscall_dispatch\n\u2502   \u251c\u2500\u2500 48  interrupt.c          # UPDATED: route int_no==0x80 to syscall_dispatch\n\u2502   \u251c\u2500\u2500 49  idt.c                # UPDATED: idt_init installs vector 0x80 with flags=0xEF (DPL=3, trap)\n\u2502   \u251c\u2500\u2500 50  gdt.c                # UPDATED: gdt_set_tss_entry added; GDT expands to 6 entries\n\u2502   \u2514\u2500\u2500 51  kernel_main.c        # UPDATED: tss_init, process_create x4, scheduler_add x4,\n\u2502                                #   bootstrap jump into first process\n\u2514\u2500\u2500 Makefile                     # UPDATED: add tss.o process.o context_switch.o scheduler.o\n                                 #           usermode.o syscall.o\n```\n---\n## 3. Complete Data Model\n### 3.1 `cpu_context_t` \u2014 Saved Register State\nThis struct exists solely to hold the ESP value that captures the full register snapshot on the process's kernel stack. The fields are named to match what is on the stack at the time `context.esp` is saved, but **only `esp` is stored in the struct at runtime**. The remaining fields document what is present on the stack at `context.esp`.\n```c\n// process.h\ntypedef struct {\n    uint32_t esp;    // Offset 0: saved kernel ESP \u2014 the only field written at runtime.\n                     // At (esp+0): EFLAGS (pushed by pushfd)\n                     // At (esp+4): EBP\n                     // At (esp+8): EDI\n                     // At (esp+12): ESI\n                     // At (esp+16): EBX\n                     // At (esp+20): return EIP (pushed by 'call context_switch_asm')\n} cpu_context_t;\n// sizeof(cpu_context_t) == 4 bytes\ntypedef char cpu_context_size_check[(sizeof(cpu_context_t) == 4) ? 1 : -1];\n```\n**Why only ESP is stored:** The complete register state lives on the process's own kernel stack, arranged by the `pushfd` + 4\u00d7 `push` sequence in `context_switch_asm`. Storing only ESP is equivalent to storing a pointer to the full register frame. This matches Linux's `thread_struct.sp` design.\n**Stack layout at `context.esp` after save (low address \u2192 high address):**\n| Offset from `context.esp` | Content | How it got there |\n|--------------------------|---------|-----------------|\n| +0 | EFLAGS | `pushfd` in `context_switch_asm` |\n| +4 | EBP | `push ebp` |\n| +8 | EDI | `push edi` |\n| +12 | ESI | `push esi` |\n| +16 | EBX | `push ebx` |\n| +20 | Return EIP | pushed by `call context_switch_asm` from C |\nTotal saved frame: 6 \u00d7 4 = **24 bytes** below the stack pointer at the time of the `call` instruction.\n---\n### 3.2 `process_state_t` \u2014 Process Lifecycle States\n```c\n// process.h\ntypedef enum {\n    PROCESS_READY   = 0,   // In the run queue; eligible for scheduling\n    PROCESS_RUNNING = 1,   // Currently executing on the CPU; only one at a time\n    PROCESS_BLOCKED = 2,   // Waiting for an event; not in round-robin run queue (M4: unused)\n    PROCESS_DEAD    = 3,   // sys_exit called; slot being recycled by scheduler\n} process_state_t;\n```\n{{DIAGRAM:tdd-diag-24}}\n**Legal state transitions:**\n- READY \u2192 RUNNING: scheduler selects this process\n- RUNNING \u2192 READY: scheduler preempts (timer interrupt)\n- RUNNING \u2192 DEAD: `sys_exit` called\n- DEAD \u2192 (removed): `scheduler_remove_current` unlinks from list\n- BLOCKED: reserved for M5+; no transitions in M4\n**Illegal transitions (must never occur):**\n- Any \u2192 RUNNING when another process is RUNNING\n- DEAD \u2192 READY (dead processes are never rescheduled)\n- RUNNING \u2192 RUNNING (same process \"scheduled\" twice)\n---\n### 3.3 `process_t` \u2014 Process Control Block\n{{DIAGRAM:tdd-diag-25}}\n```c\n// process.h\n#define KERNEL_STACK_SIZE  8192u   // 8 KB per process kernel stack (from kmalloc)\n#define MAX_PROCESSES      64u     // Maximum simultaneous processes\ntypedef struct process {\n    // \u2500\u2500 Identity \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    uint32_t         pid;              // Offset 0:  Unique PID; monotonically assigned\n    char             name[32];         // Offset 4:  Human-readable name (null-terminated)\n    // \u2500\u2500 Scheduler State \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    process_state_t  state;            // Offset 36: READY/RUNNING/BLOCKED/DEAD\n    // \u2500\u2500 Saved CPU State \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    cpu_context_t    context;          // Offset 40: context.esp = saved kernel stack pointer\n    // \u2500\u2500 Memory Management \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    uint32_t        *page_directory;   // Offset 44: PHYSICAL address of page directory\n                                       //            (loaded into CR3 on switch)\n    // \u2500\u2500 Kernel Stack \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    uint8_t         *kernel_stack;     // Offset 48: Virtual pointer to bottom of 8 KB allocation\n    uint32_t         kernel_stack_top; // Offset 52: Virtual addr of top (empty stack high-water mark)\n                                       //            Written to TSS.ESP0 on every context switch\n    // \u2500\u2500 Accounting \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    uint32_t         total_ticks;      // Offset 56: Total timer ticks this process has consumed\n    // \u2500\u2500 Run Queue Linkage \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    struct process  *next;             // Offset 60: Next in circular singly-linked ready list\n                                       //            Points to self when sole process\n} process_t;\n// sizeof(process_t) == 64 bytes (verify at compile time)\ntypedef char process_t_size_check[(sizeof(process_t) == 64) ? 1 : -1];\n```\n**Byte-offset table:**\n| Offset | Size (bytes) | Field | Notes |\n|--------|-------------|-------|-------|\n| 0 | 4 | `pid` | Starts at 1; 0 is reserved/invalid |\n| 4 | 32 | `name[32]` | Always null-terminated; truncated silently |\n| 36 | 4 | `state` | `process_state_t` enum |\n| 40 | 4 | `context.esp` | The kernel stack save pointer |\n| 44 | 4 | `page_directory` | Physical address for CR3 |\n| 48 | 4 | `kernel_stack` | Virtual base of 8 KB allocation |\n| 52 | 4 | `kernel_stack_top` | `kernel_stack + KERNEL_STACK_SIZE`; TSS ESP0 value |\n| 56 | 4 | `total_ticks` | Accounting only |\n| 60 | 4 | `next` | Circular list pointer |\n**Why `page_directory` stores a physical address:** CR3 is a hardware register. The MMU uses it before any TLB entry exists for the new address space. Writing a virtual address into CR3 causes an immediate fault on the next instruction fetch.\n**Why `kernel_stack_top` is separate from `kernel_stack + KERNEL_STACK_SIZE`:** While `kernel_stack_top` is computed as `kernel_stack + KERNEL_STACK_SIZE` at creation, the TSS always stores the original high-water mark \u2014 the value where the stack begins when empty. If we stored `current_esp` in the TSS instead, an interrupt arriving while kernel code was mid-execution would overwrite kernel state already on the stack.\n---\n### 3.4 `tss_t` \u2014 Task State Segment\n{{DIAGRAM:tdd-diag-26}}\nThe x86 32-bit TSS is a hardware-defined structure at a fixed, architecturally mandated layout. Only `esp0` and `ss0` are used by software task switching; all other fields are zeroed.\n```c\n// tss.h\ntypedef struct {\n    uint32_t prev_tss;    // Offset 0:   Hardware task link (unused = 0)\n    uint32_t esp0;        // Offset 4:   *** KEY FIELD: kernel stack ptr for ring 0 ***\n    uint32_t ss0;         // Offset 8:   Kernel stack segment selector (0x10)\n    uint32_t esp1;        // Offset 12:  Ring 1 stack (unused = 0)\n    uint32_t ss1;         // Offset 16:  Ring 1 segment (unused = 0)\n    uint32_t esp2;        // Offset 20:  Ring 2 stack (unused = 0)\n    uint32_t ss2;         // Offset 24:  Ring 2 segment (unused = 0)\n    uint32_t cr3_field;   // Offset 28:  Hardware task CR3 (unused = 0; we manage CR3 ourselves)\n    uint32_t eip_field;   // Offset 32:  Hardware task EIP (unused = 0)\n    uint32_t eflags_field;// Offset 36:  Hardware task EFLAGS (unused = 0)\n    uint32_t eax_field;   // Offset 40:  (unused = 0)\n    uint32_t ecx_field;   // Offset 44:  (unused = 0)\n    uint32_t edx_field;   // Offset 48:  (unused = 0)\n    uint32_t ebx_field;   // Offset 52:  (unused = 0)\n    uint32_t esp_field;   // Offset 56:  (unused = 0)\n    uint32_t ebp_field;   // Offset 60:  (unused = 0)\n    uint32_t esi_field;   // Offset 64:  (unused = 0)\n    uint32_t edi_field;   // Offset 68:  (unused = 0)\n    uint16_t es_field;    // Offset 72:  (unused = 0)\n    uint16_t _pad0;\n    uint16_t cs_field;    // Offset 76:  (unused = 0)\n    uint16_t _pad1;\n    uint16_t ss_field;    // Offset 80:  (unused = 0)\n    uint16_t _pad2;\n    uint16_t ds_field;    // Offset 84:  (unused = 0)\n    uint16_t _pad3;\n    uint16_t fs_field;    // Offset 88:  (unused = 0)\n    uint16_t _pad4;\n    uint16_t gs_field;    // Offset 92:  (unused = 0)\n    uint16_t _pad5;\n    uint16_t ldt;         // Offset 96:  LDT selector (unused = 0)\n    uint16_t _pad6;\n    uint16_t trap;        // Offset 100: Debug trap on task switch (unused = 0)\n    uint16_t iomap_base;  // Offset 102: I/O permission bitmap base\n                          //             Set to sizeof(tss_t) \u2192 no user I/O permissions\n} __attribute__((packed)) tss_t;\ntypedef char tss_size_check[(sizeof(tss_t) == 104) ? 1 : -1];\nextern tss_t kernel_tss;\n```\n**GDT entry for the TSS (GDT index 5, selector 0x28):**\nThe TSS descriptor is a system descriptor (S=0) of type `0x9` (32-bit TSS, available):\n| Field | Value | Notes |\n|-------|-------|-------|\n| Base | `(uint32_t)&kernel_tss` | Virtual address of `kernel_tss` in kernel data |\n| Limit | `sizeof(tss_t) - 1 = 103` | Byte granularity (G=0); no I/O bitmap beyond struct |\n| Access byte | `0x89` | P=1, DPL=0, S=0, Type=1001 (32-bit TSS available) |\n| Flags nibble | `0x00` | G=0 (byte granularity), D=0, L=0, AVL=0 |\n**Complete 6-entry GDT after this module:**\n| Index | Selector | Purpose | Access | flags_limit |\n|-------|----------|---------|--------|-------------|\n| 0 | `0x00` | Null | `0x00` | `0x00` |\n| 1 | `0x08` | Kernel code (ring 0) | `0x9A` | `0xCF` |\n| 2 | `0x10` | Kernel data (ring 0) | `0x92` | `0xCF` |\n| 3 | `0x18` | User code (ring 3), RPL=3 \u2192 `0x1B` | `0xFA` | `0xCF` |\n| 4 | `0x20` | User data (ring 3), RPL=3 \u2192 `0x23` | `0xF2` | `0xCF` |\n| 5 | `0x28` | TSS descriptor | `0x89` | `0x00` |\n---\n### 3.5 Fabricated Initial Kernel Stack Frame\nWhen `process_create` constructs a new process, it must build a stack frame on the process's kernel stack that is **indistinguishable from what `context_switch_asm` would have left** if the process had been suspended mid-execution. This allows `context_switch_asm`'s restore path to resume a brand-new process identically to an existing one.\n**Layout (stack grows downward; values pushed from `kernel_stack_top` downward):**\n```\nkernel_stack_top  \u2190 initial value of ESP before any pushes\nkernel_stack_top - 4   = EFLAGS    = 0x00000202  (IF=1, reserved bit 1 set)\nkernel_stack_top - 8   = EBP       = 0x00000000  (bottom of call stack for backtraces)\nkernel_stack_top - 12  = EDI       = 0x00000000\nkernel_stack_top - 16  = ESI       = 0x00000000\nkernel_stack_top - 20  = EBX       = 0x00000000\nkernel_stack_top - 24  = entry_fn  = (uint32_t)entry  \u2190 'ret' pops this as EIP\n```\nAfter fabrication: `context.esp = kernel_stack_top - 24`.\n**The IF=1 requirement (EFLAGS = 0x00000202):**\n- Bit 9 (IF) = 1: interrupts enabled. If this is 0, the process runs with interrupts permanently disabled, the timer never fires, and the scheduler never preempts. The system freezes on the first scheduled process.\n- Bit 1: always 1 in EFLAGS (reserved, must be set).\n- All other bits: 0 (no carry, no overflow, no direction flag, no IOPL).\n---\n### 3.6 Syscall Dispatch Table\n```c\n// syscall.h\n#define SYS_EXIT    1   // sys_exit(uint32_t code)\n#define SYS_WRITE   4   // sys_write(uint32_t fd, uint32_t buf, uint32_t len)\n#define SYSCALL_MAX 5   // Table size; indices 0,2,3 are NULL\ntypedef int32_t (*syscall_handler_t)(uint32_t arg1, uint32_t arg2, uint32_t arg3);\n// syscall.c\nstatic syscall_handler_t syscall_table[SYSCALL_MAX] = {\n    NULL,       // 0: unused\n    sys_exit,   // 1: exit\n    NULL,       // 2: fork (unimplemented)\n    NULL,       // 3: read (unimplemented)\n    sys_write,  // 4: write\n};\n```\n**IDT entry for INT 0x80:**\n| Field | Value | Reason |\n|-------|-------|--------|\n| Vector | `0x80` (128) | Unix convention; safely above IRQ range (32\u201347) |\n| Handler | `isr_128` (ISR_NOERR stub from M2) | Reuses existing stub infrastructure |\n| Selector | `0x08` | Kernel code segment |\n| Flags | `0xEF` | P=1, DPL=3 (user-invocable!), type=1111 (32-bit **trap** gate) |\n**Trap gate vs interrupt gate for syscalls:** Trap gate (type `0xF`) does NOT clear EFLAGS.IF on entry. The kernel remains interruptible during syscall processing. This is correct: a `sys_write` taking 5 \u00b5s should not block timer interrupts for the entire duration.\n**Calling convention (user-space \u2192 kernel):**\n```\nEAX = syscall number (1 or 4)\nEBX = arg1\nECX = arg2\nEDX = arg3\nReturn value: EAX on exit from INT 0x80\n```\n---\n## 4. Interface Contracts\n### 4.1 TSS\n```c\n// tss.h / tss.c\nvoid tss_init(void);\n```\n- **Preconditions:** GDT has been extended to 6 entries (index 5 available); EFLAGS.IF=0; `kernel_tss` is in a writable kernel data section (not BSS, or BSS is zeroed).\n- **Postconditions:** `kernel_tss` zeroed; `kernel_tss.ss0 = 0x10`; `kernel_tss.iomap_base = sizeof(tss_t)` (104); GDT entry 5 populated with TSS descriptor (base = physical addr of `kernel_tss`, limit = 103, access = 0x89, flags = 0x00); `ltr 0x28` executed; `kernel_tss.esp0` is 0 (will be set on first `tss_set_kernel_stack` call before any ring-3 interrupt).\n- **Side effects:** Writes GDT[5] via `gdt_set_tss_entry(5, ...)`. Executes `ltr` instruction (privileged; must be ring 0). Writes to `kernel_tss`.\n- **Errors:** No runtime errors. If GDT is not large enough, the `ltr` instruction raises #GP \u2014 this is a programming error caught at development time.\n```c\nvoid tss_set_kernel_stack(uint32_t esp0_value);\n```\n- **Preconditions:** `tss_init` has been called.\n- **Postconditions:** `kernel_tss.esp0 = esp0_value`.\n- **Thread safety:** Must be called with interrupts disabled (inside `context_switch` which runs from IRQ handler). Single write to a `uint32_t` at a known offset is atomic on x86.\n- **Called by:** `context_switch` C wrapper on every process switch. Must be called BEFORE `context_switch_asm` swaps stacks, so the TSS update is visible to the hardware before any interrupt that might fire in the new process's ring-3 code.\n- **Errors:** None. Invalid `esp0_value` (e.g., 0) causes the next ring-3 interrupt to push its frame to address 0 \u2014 immediate #PF \u2192 triple fault. Validate at call site.\n```c\n// gdt.c addition\nvoid gdt_set_tss_entry(int idx, uint32_t base, uint32_t limit);\n```\n- **Preconditions:** `idx` is a valid GDT index (5 for TSS); `base` is the linear address of the TSS struct; `limit = sizeof(tss_t) - 1 = 103`.\n- **Postconditions:** GDT[idx] populated with a 32-bit available TSS descriptor: `access = 0x89`, `flags_limit = 0x00 | ((limit >> 16) & 0x0F)` = `0x00` (limit < 0x10000 so upper nibble = 0), all base fields split correctly.\n- **Errors:** None at runtime. Incorrect base causes `ltr` to succeed but CPU to use wrong memory \u2014 silent TSS corruption.\n---\n### 4.2 Process Management\n```c\n// process.h / process.c\nprocess_t *process_create(const char *name,\n                           void (*entry)(void),\n                           uint32_t *page_dir_phys,\n                           int is_user);\n```\n- **Parameters:**\n  - `name`: null-terminated string; copied into `proc->name` (truncated at 31 chars).\n  - `entry`: Function pointer. For kernel processes: virtual address callable directly. For user processes: virtual address within the **user** address space (e.g., `0x00400000`), not a kernel function pointer.\n  - `page_dir_phys`: Physical address of the process's page directory. For kernel processes: `VIRT_TO_PHYS((uint32_t)&boot_pd)`. For user processes: returned by `create_user_page_directory()`.\n  - `is_user`: 0 = kernel process (entry executed at ring 0, kernel stack only). 1 = user process (entry is a ring-3 virtual address; requires `enter_user_mode` wrapper as the actual fabricated EIP).\n- **Returns:** Pointer to allocated `process_t` on the kernel heap. Never returns NULL (OOM halts).\n- **Postconditions:** `proc->pid` unique; `proc->state = PROCESS_READY`; `proc->kernel_stack` is an 8 KB allocation from `kmalloc`; `proc->kernel_stack_top = (uint32_t)(proc->kernel_stack) + KERNEL_STACK_SIZE`; `proc->context.esp` points to the fabricated initial stack frame; `proc->page_directory = page_dir_phys`; `proc->next = NULL` (set by `scheduler_add_process`).\n- **For `is_user=1`:** The fabricated EIP must not be `entry` directly \u2014 instead, it must be the address of a kernel-mode trampoline `process_user_entry_trampoline` that calls `enter_user_mode(entry, user_esp)`. The user stack address (`user_esp`) is allocated inside `process_create` by calling `pmm_alloc_frame()`, mapping it into `page_dir_phys` at `USER_STACK_VIRT`, and computing `user_esp = USER_STACK_VIRT + PAGE_SIZE - 4`.\n- **Errors:**\n  - `kmalloc` for PCB fails: OOM halt (kmalloc never returns NULL \u2014 it halts).\n  - `kmalloc` for kernel stack fails: same.\n  - `pmm_alloc_frame` for user stack fails (is_user=1): same.\n```c\n#define USER_STACK_VIRT   0xBFFFF000u  // Top of user virtual address space, one page\n#define USER_CODE_VIRT    0x00400000u  // Standard ELF load address for user code\n```\n```c\nextern process_t *current_process;      // The currently RUNNING process\nextern process_t *process_list_head;    // Head of circular ready queue\n```\n---\n### 4.3 Context Switch\n```c\n// context_switch.asm (assembly only \u2014 no C declaration; called via C wrapper)\n// Signature: void context_switch_asm(cpu_context_t *old_ctx, cpu_context_t *new_ctx)\n// Calling convention: cdecl\n//   [ESP+4] = old_ctx (pointer to old process's cpu_context_t)\n//   [ESP+8] = new_ctx (pointer to new process's cpu_context_t)\n```\n- **Preconditions:** Both pointers are valid virtual addresses in kernel space. Called with interrupts disabled (we are inside IRQ0 interrupt gate handler). `new_ctx->esp` has been previously set (either by a prior `context_switch_asm` call or by `process_create`'s fabricated frame).\n- **Postconditions:** Old process's EBX, ESI, EDI, EBP, EFLAGS, and return EIP are saved to old's kernel stack; `old_ctx->esp` updated. New process's `new_ctx->esp` loaded into ESP; new process's EBX, ESI, EDI, EBP, EFLAGS restored from new's stack. `ret` pops new's EIP and resumes new process.\n- **Critical: identity-change mid-function.** After `mov esp, [eax+0]` (loading new ESP), the executing code is on new's stack. The subsequent `pop` instructions restore new's registers. The `ret` jumps to new's saved EIP. Old process is suspended. New process continues.\n- **Does not modify:** EAX, ECX, EDX (caller-saved per cdecl; caller is responsible).\n- **Does not save:** Segment registers (DS, ES, FS, GS, SS are always `0x10` for kernel processes; `isr_common_stub` already handles segment save/restore for ring-3 entry).\n```c\n// scheduler.c\nvoid context_switch(process_t *old, process_t *new);\n```\n- **Preconditions:** `old != NULL`; `new != NULL`; `old != new`; interrupts disabled (IRQ gate).\n- **Sequence (order is mandatory \u2014 see \u00a75.3):**\n  1. `tss_set_kernel_stack(new->kernel_stack_top)` \u2014 TSS update FIRST.\n  2. CR3 reload if `old->page_directory != new->page_directory`.\n  3. `current_process = new` \u2014 update global BEFORE stack swap.\n  4. `context_switch_asm(&old->context, &new->context)`.\n- **After return:** We are executing as `old` again (the next time `old` is scheduled). `current_process` correctly reflects whoever is running.\n- **Errors:** No error returns. Incorrect order of operations causes: wrong TSS \u2192 triple fault; wrong CR3 \u2192 memory corruption; wrong `current_process` \u2192 stale process info in syscall handlers.\n---\n### 4.4 Scheduler\n```c\nvoid scheduler_init(void);\n```\n- **Postconditions:** `current_process = NULL`; `process_list_head = NULL`.\n- **Called:** Once from `kernel_main`, before any `process_create`.\n```c\nvoid scheduler_add_process(process_t *proc);\n```\n- **Preconditions:** `proc != NULL`; `proc->state == PROCESS_READY`; `proc->next == NULL`.\n- **Postconditions:** `proc` inserted into the circular list. If `process_list_head == NULL`: `process_list_head = proc; proc->next = proc`. Otherwise: find the tail (node where `tail->next == process_list_head`), set `tail->next = proc; proc->next = process_list_head`.\n- **Errors:** Inserting the same process twice produces a cycle of length 1 within the list \u2014 detected by checking `proc->next != NULL` before insert. If `proc->next != NULL`: `kprintf` error + halt.\n```c\nvoid scheduler_tick(interrupt_frame_t *frame);\n```\n- **Preconditions:** Called from `timer_handler` (IRQ0); interrupts disabled; `current_process != NULL`; `current_process->state == PROCESS_RUNNING`.\n- **Behavior:**\n  1. `current_process->total_ticks++`.\n  2. Find `next = current_process->next`.\n  3. Walk `next` until `next->state == PROCESS_READY || next->state == PROCESS_RUNNING` (skips DEAD entries). Abort after `MAX_PROCESSES` steps to prevent infinite loop on all-dead list.\n  4. If `next == current_process`: no other runnable process; return immediately without switch.\n  5. `old = current_process`. `old->state = PROCESS_READY`. `next->state = PROCESS_RUNNING`.\n  6. Call `context_switch(old, next)`.\n- **After context_switch returns:** We are the old process again, rescheduled. Continue return path through `irq_dispatch` \u2192 `isr_common_stub` \u2192 `iretd`.\n- **Errors:** If all processes are DEAD: `kprintf(\"[SCHED] All processes dead\\n\"); cli; hlt`.\n```c\nvoid scheduler_remove_current(void);\n```\n- **Preconditions:** `current_process->state == PROCESS_DEAD`. Called from `sys_exit` AFTER marking state DEAD.\n- **Behavior:** Find the predecessor `prev` (node where `prev->next == current_process`). If `current_process == current_process->next` (sole process): all dead, halt. Otherwise: `prev->next = current_process->next`. If `process_list_head == current_process`: `process_list_head = current_process->next`. Set `next = current_process->next`. Load `next->state = PROCESS_RUNNING`. Perform a one-way context switch: update TSS, update CR3, set `current_process = next`, then perform the bootstrap jump (same as the initial bootstrap: load `next->context.esp`, pop all saved registers, `ret`).\n- **Critical:** After `scheduler_remove_current`, execution does NOT return to the caller (the current process is dead and its stack is abandoned). This function is `__attribute__((noreturn))`.\n---\n### 4.5 User-Mode Setup\n```c\n// usermode.h / usermode.c\nuint32_t *create_user_page_directory(void);\n```\n- **Returns:** Physical address of the new page directory (suitable for CR3 and `process->page_directory`).\n- **Algorithm:**\n  1. `pd_phys = pmm_alloc_frame()`.\n  2. `pd_virt = (page_directory_t *)PHYS_TO_VIRT(pd_phys)`.\n  3. Zero all 1024 PDEs: `memset(pd_virt, 0, 4096)`.\n  4. Copy kernel PDEs (indices 768\u20131023) from `boot_pd` into `pd_virt`: `pd_virt[i] = boot_pd[i]` for i in [768, 1023]. This shares the kernel page tables (not copies \u2014 the PDE points to the same physical page tables), so kernel mapping changes are reflected in all processes automatically.\n  5. Return `pd_phys`.\n- **Postconditions:** New directory has no user-space mappings (PDEs 0\u2013767 all zero); kernel is fully accessible (PDEs 768\u20131023 copied); virtual address `0x00000000` is unmapped (#PF on NULL deref); kernel code at `0xC0100000` is accessible.\n- **Errors:** `pmm_alloc_frame` OOM \u2192 halt (never returns NULL).\n```c\nvoid enter_user_mode(uint32_t user_eip, uint32_t user_esp) __attribute__((noreturn));\n```\n- **Preconditions:** CR3 holds the user process's page directory (containing both the user code mapping and the kernel mapping). `user_eip` is a virtual address within the user address space (PDEs 0\u2013767). `user_esp` is a virtual address within the user stack. TSS ESP0 is already set correctly for this process. Interrupts may be enabled or disabled \u2014 we force them via EFLAGS.\n- **Sequence (see \u00a75.6 for inline assembly):**\n  1. `cli` \u2014 ensure atomicity while building the frame.\n  2. Load segment registers: `DS = ES = FS = GS = 0x23` (user data selector with RPL=3).\n  3. Push in order (each push decrements ESP): `0x23` (SS), `user_esp`, EFLAGS with IF=1, `0x1B` (CS), `user_eip`.\n  4. `iretd` \u2014 atomically restores EIP, CS (\u2192 ring 3), EFLAGS (\u2192 IF=1), ESP, SS.\n- **Does not return.** After `iretd`, the process runs at ring 3.\n- **Error \u2014 wrong CS selector:** Using `0x18` instead of `0x1B` gives RPL=0 in a ring-3 context. The CPU detects CPL=0 from `0x18` after `iretd` but has already switched to a ring-3 stack \u2014 this is a #GP. Always use `0x1B` (GDT index 3 | RPL=3) and `0x23` (GDT index 4 | RPL=3).\n---\n### 4.6 System Calls\n```c\n// syscall.h\nvoid syscall_dispatch(interrupt_frame_t *frame);\n```\n- **Preconditions:** `frame->int_no == 0x80`. `frame->eax` = syscall number. `frame->ebx/ecx/edx` = args 1\u20133. The interrupt stack frame contains valid user-mode saved state (EIP, CS, EFLAGS, ESP, SS pushed by CPU on privilege change).\n- **Behavior:**\n  1. `uint32_t n = frame->eax`.\n  2. If `n >= SYSCALL_MAX || syscall_table[n] == NULL`: `frame->eax = (uint32_t)(-1); return` (ENOSYS).\n  3. `int32_t result = syscall_table[n](frame->ebx, frame->ecx, frame->edx)`.\n  4. `frame->eax = (uint32_t)result` \u2014 write return value into the saved EAX; `iretd` restores it to user-space EAX.\n- **Errors:** Unknown syscall \u2192 returns -1 with `kprintf` warning. Handler returning negative values \u2192 returned to user unchanged.\n```c\nstatic int32_t sys_write(uint32_t fd, uint32_t buf_virt, uint32_t len);\n```\n- **Preconditions:** Called from `syscall_dispatch`; CR3 holds user's page directory.\n- **Parameters:** `fd` = file descriptor (only 1 = stdout supported). `buf_virt` = user virtual address of buffer. `len` = byte count.\n- **Validation:**\n  - If `fd != 1`: return `-1` (EBADF).\n  - If `buf_virt >= 0xC0000000u`: return `-1` (EFAULT \u2014 user passing kernel pointer).\n  - If `buf_virt + len > 0xC0000000u` (overflow): return `-1` (EFAULT).\n  - If `len > 4096`: clamp to 4096 (prevent unbounded kernel time in a single syscall).\n- **Behavior:** Read bytes from `(const char *)buf_virt` \u2014 valid because: user pages are mapped `PTE_USER`, kernel code is CPL=0 so it can access user pages regardless of U/S bit; the user page directory is currently in CR3. Write each byte to both `vga_putchar` and `serial_putchar`. Return `(int32_t)len` (or clamped count) on success.\n- **Errors:** If `buf_virt` is a user virtual address that is not mapped (user page not present): accessing it causes a kernel #PF with U=0 (kernel code accessing user page). In M4 this halts. To avoid this, add a page presence check before the loop: for each page containing the buffer, verify the PDE and PTE in the user's page directory are present. If not: return `-1` (EFAULT).\n```c\nstatic int32_t sys_exit(uint32_t exit_code, uint32_t unused1, uint32_t unused2);\n```\n- **Behavior:**\n  1. `kprintf(\"[PID %u] exited with code %u\\n\", current_process->pid, exit_code)`.\n  2. `current_process->state = PROCESS_DEAD`.\n  3. Call `scheduler_remove_current()` \u2014 does not return.\n- **Does not return.** `scheduler_remove_current` performs a one-way switch to the next process.\n- **Errors:** If `scheduler_remove_current` determines no other process exists: halt.\n---\n## 5. Algorithm Specification\n### 5.1 TSS GDT Descriptor Construction\n```\nPROCEDURE gdt_set_tss_entry(idx, base, limit):\n  // TSS descriptor uses same byte-split format as code/data, but:\n  // access = 0x89 (P=1, DPL=0, S=0 [system], Type=1001 [32-bit TSS available])\n  // flags nibble = 0x0 (G=0: byte granularity; D=0; L=0; AVL=0)\n  gdt[idx].limit_low   = limit & 0xFFFF         // = 0x0067 (103 in hex)\n  gdt[idx].base_low    = base  & 0xFFFF\n  gdt[idx].base_mid    = (base >> 16) & 0xFF\n  gdt[idx].access      = 0x89\n  gdt[idx].flags_limit = 0x00 | ((limit >> 16) & 0x0F)   // = 0x00 (limit < 0x10000)\n  gdt[idx].base_high   = (base >> 24) & 0xFF\n  // Note: limit=103 means 0x67; bits 19:16 = 0, so flags_limit = 0x00\n```\nAfter `gdt_set_tss_entry(5, (uint32_t)&kernel_tss, 103)`, execute:\n```c\n__asm__ volatile (\"ltr %0\" : : \"r\"((uint16_t)0x28));\n// 0x28 = (5 << 3) | 0 = GDT index 5, TI=0 (GDT), RPL=0\n```\n---\n### 5.2 `process_create` \u2014 Detailed Steps\n```\nPROCEDURE process_create(name, entry, page_dir_phys, is_user):\n  1. proc = kmalloc(sizeof(process_t))\n     memset(proc, 0, sizeof(process_t))\n  2. proc->pid   = atomic_next_pid()       // static uint32_t next_pid = 1; return next_pid++\n     proc->state = PROCESS_READY\n     strncpy(proc->name, name, 31)         // Always null-terminate\n     proc->name[31] = '\\0'\n  3. proc->kernel_stack     = kmalloc(KERNEL_STACK_SIZE)\n     memset(proc->kernel_stack, 0, KERNEL_STACK_SIZE)\n     proc->kernel_stack_top = (uint32_t)(proc->kernel_stack) + KERNEL_STACK_SIZE\n  4. proc->page_directory = page_dir_phys\n  5. // Build fabricated stack frame\n     uint32_t *stack = (uint32_t *)proc->kernel_stack_top\n     IF is_user:\n       // For user process: the fabricated EIP is a kernel trampoline\n       // that calls enter_user_mode(entry, user_esp)\n       user_stack_phys = pmm_alloc_frame()\n       paging_map((page_directory_t*)PHYS_TO_VIRT(page_dir_phys),\n                  USER_STACK_VIRT, user_stack_phys,\n                  PTE_PRESENT | PTE_WRITABLE | PTE_USER)\n       user_esp = USER_STACK_VIRT + PAGE_SIZE - 4\n       // Also map user code into user page directory\n       // (caller's responsibility to have mapped code pages before calling process_create)\n       // Store entry and user_esp in process-specific locations:\n       // Two words below the trampoline frame, for the trampoline to read\n       *--stack = (uint32_t)entry           // pushed last = lowest addr\n       *--stack = user_esp                  // pushed before entry\n       // Now the actual fabricated frame (trampoline will use these):\n       *--stack = 0x00000202                // EFLAGS: IF=1\n       *--stack = 0                         // EBP\n       *--stack = 0                         // EDI\n       *--stack = 0                         // ESI\n       *--stack = 0                         // EBX\n       *--stack = (uint32_t)process_user_entry_trampoline  // EIP\n     ELSE:\n       // Kernel process: EIP = entry directly\n       *--stack = 0x00000202                // EFLAGS: IF=1\n       *--stack = 0                         // EBP\n       *--stack = 0                         // EDI\n       *--stack = 0                         // ESI\n       *--stack = 0                         // EBX\n       *--stack = (uint32_t)entry           // EIP: where to resume\n  6. proc->context.esp = (uint32_t)stack   // points to EFLAGS on stack\n  7. proc->next = NULL  // Set by scheduler_add_process\n  8. RETURN proc\n```\n**`process_user_entry_trampoline` (kernel function):**\n```c\n// process.c\n// Called when a user process is first scheduled (in kernel mode on its kernel stack)\n// The fabricated frame's EIP points here.\n// BELOW the frame (at higher addresses, pushed before the frame) are:\n//   [kernel_stack_top - 4]  = original entry (user EIP)\n//   [kernel_stack_top - 8]  = user_esp\nstatic void process_user_entry_trampoline(void) {\n    // Recover the entry and user_esp stored above the frame during process_create.\n    // After context_switch_asm's 'ret', ESP points to the EFLAGS we pushed.\n    // Above that (higher addresses) are the pre-frame arguments.\n    // After 'ret' pops EIP and we're here, the stack pointer is:\n    //   ESP = (fabricated_frame_base + 24) = kernel_stack_top - 24 + 24 = kernel_stack_top\n    // But actually after 'ret' ESP advances by 4 (past the return address).\n    // So ESP = fabricated_frame_base + 24 = where EBX was pushed, +24 = past all 5 saves.\n    // Wait: context_switch_asm pushes: EFLAGS, EBP, EDI, ESI, EBX, then call saves EIP.\n    // 'ret' pops EIP (+4 to ESP). Then context_switch_asm returns to its C caller.\n    // But for the first scheduling, 'ret' goes to 'entry' (our trampoline).\n    // After 'ret' into trampoline: ESP = fabricated_frame_esp + 24.\n    // For kernel process: this is kernel_stack_top. For user process with extra words:\n    // kernel_stack_top - 8 (user_esp) and kernel_stack_top - 4 (entry) were pushed\n    // BEFORE the frame. After 'ret' pops EIP, ESP = fabricated_frame_esp + 24.\n    // fabricated_frame_esp = kernel_stack_top - (2+5)*4 = kernel_stack_top - 28\n    // After ret: ESP = kernel_stack_top - 28 + 24 = kernel_stack_top - 4\n    // [ESP+0] = entry (user EIP), [ESP-4] = user_esp \u2014 but growing downward means:\n    // [ESP]   points to the last pushed word before the frame = user_esp\n    // [ESP+4] = entry\n    // Actually re-examine: we push user_esp first, then entry \u2014 so entry is at lower addr.\n    // Let me re-derive: push order (high to low): user_esp, entry, then 5-word frame\n    // Stack (high to low): [kernel_stack_top-4]=user_esp, [kernel_stack_top-8]=entry\n    // Frame bottom: [kernel_stack_top-28]=EFLAGS, ..., [kernel_stack_top-12]=EBX,\n    //               [kernel_stack_top-8]=entry (trampoline EIP \u2014 this is the return addr)\n    // Wait this collides. Correct push order in process_create:\n    // stack = kernel_stack_top\n    // *--stack = entry         \u2192 stack now at kernel_stack_top - 4; [kst-4] = entry\n    // *--stack = user_esp      \u2192 [kst-8] = user_esp\n    // *--stack = 0x202         \u2192 [kst-12] = EFLAGS\n    // *--stack = 0             \u2192 [kst-16] = EBP\n    // *--stack = 0             \u2192 [kst-20] = EDI\n    // *--stack = 0             \u2192 [kst-24] = ESI\n    // *--stack = 0             \u2192 [kst-28] = EBX\n    // *--stack = trampoline    \u2192 [kst-32] = trampoline EIP (the return address)\n    // context.esp = kst - 32\n    // After context_switch_asm restores: pops EFLAGS(kst-12),EBP,EDI,ESI,EBX; ret pops trampoline(kst-32)? NO.\n    // context_switch_asm restore: mov esp, [new_ctx->esp] = kst-32\n    //   popfd       \u2192 ESP = kst-28, popped [kst-32] = ??? \n    // PROBLEM: the order must match exactly what context_switch_asm pushes.\n    // context_switch_asm push order: push ebx, push esi, push edi, push ebp, pushfd\n    // So stack from context.esp upward: [esp+0]=EFLAGS, [esp+4]=EBP, [esp+8]=EDI, [esp+12]=ESI, [esp+16]=EBX, [esp+20]=return_EIP\n    // Fabricated frame must match this layout EXACTLY.\n    // stack = kernel_stack_top\n    // The 'return EIP' is at [context.esp + 20] \u2014 the thing 'ret' will pop.\n    // So we need EIP to be 20 bytes ABOVE context.esp.\n    // In push terms (stack grows down): push EIP first (highest address), then EBX, ESI, EDI, EBP, EFLAGS last (lowest).\n    // *--stack = trampoline    \u2192 [kst-4]  = EIP (ret pops this)\n    // *--stack = 0             \u2192 [kst-8]  = EBX\n    // *--stack = 0             \u2192 [kst-12] = ESI\n    // *--stack = 0             \u2192 [kst-16] = EDI\n    // *--stack = 0             \u2192 [kst-20] = EBP\n    // *--stack = 0x202         \u2192 [kst-24] = EFLAGS\n    // context.esp = kst - 24\n    // After restore: popfd\u2192ESP=kst-20; pop ebp\u2192kst-16; pop edi\u2192kst-12; pop esi\u2192kst-8; pop ebx\u2192kst-4; ret\u2192pops [kst-4]=trampoline; ESP=kst\n    // Now for user process, we need entry and user_esp accessible. Store them ABOVE the frame (before pushing the frame):\n    // BEFORE the frame pushes above: push entry and user_esp at kst-4 and kst-8... conflict.\n    // Solution: store entry and user_esp in the process_t struct itself, not on the stack.\n    // Use dedicated fields: proc->user_entry_fn and proc->user_initial_esp\n    uint32_t user_eip  = current_process->user_entry_fn;\n    uint32_t user_esp_val = current_process->user_initial_esp;\n    enter_user_mode(user_eip, user_esp_val);\n    __builtin_unreachable();\n}\n```\n**Process_t revised to include user-mode launch info (add two fields):**\nAdd to `process_t` at offset 64:\n```c\n    uint32_t         user_entry_fn;    // Offset 64: user-mode EIP for trampoline (is_user only)\n    uint32_t         user_initial_esp; // Offset 68: user-mode ESP for trampoline (is_user only)\n```\nRevise `sizeof(process_t)` to 72; update compile-time check accordingly. Set these fields in `process_create` when `is_user=1`.\n---\n### 5.3 `context_switch_asm` \u2014 Full Assembly\n{{DIAGRAM:tdd-diag-27}}\n```nasm\n; context_switch.asm\n[BITS 32]\n[GLOBAL context_switch_asm]\n; void context_switch_asm(cpu_context_t *old_ctx, cpu_context_t *new_ctx)\n; Arguments (cdecl, on stack at entry):\n;   [ESP+ 4] = old_ctx  (pointer to old process's cpu_context_t)\n;   [ESP+ 8] = new_ctx  (pointer to new process's cpu_context_t)\n;\n; cpu_context_t contains only one field: esp at offset 0.\n; The full register state lives on the respective kernel stacks.\n;\n; Stack state at entry to context_switch_asm:\n;   [ESP+0] = return EIP (pushed by 'call context_switch_asm' in C wrapper)\n;   [ESP+4] = old_ctx\n;   [ESP+8] = new_ctx\ncontext_switch_asm:\n    ; \u2500\u2500 SAVE OLD PROCESS STATE \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    ; Push callee-saved registers per cdecl ABI.\n    ; We save them in the EXACT ORDER that our restore path pops them.\n    ; Push order: EBX first (lowest on stack last), EFLAGS last (lowest address).\n    ; This means restore order (pop): EFLAGS, EBP, EDI, ESI, EBX.\n    push ebx\n    push esi\n    push edi\n    push ebp\n    pushfd                          ; Save EFLAGS (including IF)\n    ;\n    ; Stack layout now (relative to current ESP, post-pushfd):\n    ;   [ESP+0]  = EFLAGS\n    ;   [ESP+4]  = EBP\n    ;   [ESP+8]  = EDI\n    ;   [ESP+12] = ESI\n    ;   [ESP+16] = EBX\n    ;   [ESP+20] = return EIP  (pushed by 'call' before we entered)\n    ;   [ESP+24] = old_ctx     (first arg)\n    ;   [ESP+28] = new_ctx     (second arg)\n    ;\n    ; Save ESP to old_ctx->esp  (old_ctx->esp is at offset 0 of cpu_context_t)\n    mov eax, [esp + 24]             ; EAX = old_ctx\n    mov [eax + 0], esp              ; old_ctx->esp = current ESP\n    ;\n    ; \u2500\u2500 LOAD NEW PROCESS STATE \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    mov eax, [esp + 28]             ; EAX = new_ctx\n    ;\n    ; <<< IDENTITY SWAP \u2014 point of no return for old process >>>\n    mov esp, [eax + 0]              ; ESP = new_ctx->esp (switch to new process's stack)\n    ;\n    ; We are now on the NEW process's kernel stack.\n    ; Its stack was either built by a prior context_switch_asm save,\n    ; or fabricated by process_create.\n    ;\n    ; \u2500\u2500 RESTORE NEW PROCESS STATE \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    popfd                           ; Restore EFLAGS (may re-enable interrupts if IF=1)\n    pop ebp\n    pop edi\n    pop esi\n    pop ebx\n    ;\n    ; 'ret' pops the return EIP from the new process's stack.\n    ; For a previously-suspended process: returns to context_switch C wrapper.\n    ; For a first-time process: returns to the fabricated 'entry' function.\n    ret\n```\n**Stack pointer arithmetic verification (first scheduling of a new kernel process):**\nAt `process_create` time with `kernel_stack_top = kst`:\n```\nPush order \u2192 stack contents (kst = 0xC0410000 for example):\n  *--stack = entry    \u2192 [kst-4]  = entry_fn (EIP; 'ret' pops this)\n  *--stack = 0        \u2192 [kst-8]  = EBX\n  *--stack = 0        \u2192 [kst-12] = ESI\n  *--stack = 0        \u2192 [kst-16] = EDI\n  *--stack = 0        \u2192 [kst-20] = EBP\n  *--stack = 0x202    \u2192 [kst-24] = EFLAGS\ncontext.esp = kst - 24\n```\n`context_switch_asm` restore path from `context.esp = kst-24`:\n```\nmov esp, kst-24        \u2192 ESP = kst-24\npopfd                  \u2192 pops [kst-24]=0x202 into EFLAGS; ESP = kst-20\npop ebp                \u2192 pops [kst-20]=0;    ESP = kst-16\npop edi                \u2192 pops [kst-16]=0;    ESP = kst-12\npop esi                \u2192 pops [kst-12]=0;    ESP = kst-8\npop ebx                \u2192 pops [kst-8]=0;     ESP = kst-4\nret                    \u2192 pops [kst-4]=entry_fn into EIP; ESP = kst\n```\nProcess begins executing `entry_fn` with:\n- ESP = `kernel_stack_top` (clean kernel stack for this process)\n- EFLAGS = 0x202 (IF=1, interrupts enabled)\n- EBX=ESI=EDI=EBP=0\n---\n### 5.4 Round-Robin Scheduler\n{{DIAGRAM:tdd-diag-28}}\n```\nPROCEDURE scheduler_tick(frame):\n  // Runs inside IRQ0 handler. Interrupts disabled.\n  1. IF current_process == NULL: RETURN\n  2. current_process->total_ticks++\n  3. next = current_process->next\n     iterations = 0\n  4. WHILE next->state != PROCESS_READY AND next->state != PROCESS_RUNNING:\n       next = next->next\n       iterations++\n       IF iterations > MAX_PROCESSES:\n         kprintf(\"[SCHED] No runnable process \u2014 halting\\n\")\n         cli; hlt\n       IF next == current_process: RETURN  // Only one runnable process\n  5. IF next == current_process: RETURN    // Still the only one\n  6. old = current_process\n     old->state = PROCESS_READY\n     next->state = PROCESS_RUNNING\n  7. context_switch(old, next)\n  // When context_switch returns here, we are 'old' again, rescheduled.\n  8. RETURN\n```\n**`context_switch` C wrapper:**\n```c\nvoid context_switch(process_t *old, process_t *new) {\n    // Step 1: TSS update FIRST (before stack swap)\n    tss_set_kernel_stack(new->kernel_stack_top);\n    // Step 2: Address space switch if needed\n    if (old->page_directory != new->page_directory) {\n        __asm__ volatile (\"mov cr3, %0\" : : \"r\"(new->page_directory) : \"memory\");\n        // Note: this is the physical address; correct per CR3 hardware requirement\n    }\n    // Step 3: Update global before stack swap\n    current_process = new;\n    // Step 4: Perform register swap (old process suspended here until rescheduled)\n    context_switch_asm(&old->context, &new->context);\n    // Returns here when old is rescheduled; current_process may be old or new\n    // (actually context_switch_asm's caller sees the return \u2014 we're old again)\n}\n```\n---\n### 5.5 Bootstrap into First Process\nThe bootstrap jump from `kernel_main` into the first process is a one-way operation. `kernel_main`'s stack is abandoned permanently after this point.\n```c\n// kernel_main.c, at end of kernel_main_paging_done() or equivalent\nvoid start_multitasking(process_t *first) {\n    // Must set current_process before any interrupt fires\n    current_process = first;\n    first->state = PROCESS_RUNNING;\n    // Set TSS ESP0 for the first process BEFORE enabling ring-3 or any interrupt\n    tss_set_kernel_stack(first->kernel_stack_top);\n    // Perform a one-way \"restore\" \u2014 identical to context_switch_asm's restore path\n    // but without a prior save (we discard kernel_main's stack).\n    __asm__ volatile (\n        \"mov esp, %0\\n\\t\"   // Switch to first process's kernel stack\n        \"popfd\\n\\t\"         // Restore EFLAGS (IF=1 \u2192 enables interrupts)\n        \"pop ebp\\n\\t\"\n        \"pop edi\\n\\t\"\n        \"pop esi\\n\\t\"\n        \"pop ebx\\n\\t\"\n        \"ret\\n\\t\"           // Jump to first->entry (fabricated EIP)\n        :\n        : \"r\"(first->context.esp)\n        : \"memory\"\n    );\n    __builtin_unreachable();\n}\n```\n**Why this is safe without `sti` first:** The `popfd` restores EFLAGS from the fabricated frame (0x00000202, IF=1). This atomically enables interrupts as part of the `popfd` instruction. The next timer tick after `popfd` will cause a context switch. No explicit `sti` is needed.\n**Why not call `context_switch_asm` instead:** `context_switch_asm` requires an `old_ctx` to save to. There is no valid \"old process\" during bootstrap. Using the bootstrap inline assembly avoids needing a dummy process_t.\n---\n### 5.6 `enter_user_mode` \u2014 Ring-3 Entry via `iretd`\n{{DIAGRAM:tdd-diag-29}}\n```c\nvoid enter_user_mode(uint32_t user_eip, uint32_t user_esp) {\n    // Reload data segment registers with user data selector BEFORE building iret frame.\n    // After iretd, CS=0x1B (ring 3). DS/ES/FS/GS must already be ring-3 selectors\n    // or the first user instruction's data access causes a #GP.\n    // 0x23 = GDT index 4 | RPL=3 = user data with explicit RPL=3\n    __asm__ volatile (\n        // Load segment registers\n        \"mov ax, 0x23\\n\\t\"\n        \"mov ds, ax\\n\\t\"\n        \"mov es, ax\\n\\t\"\n        \"mov fs, ax\\n\\t\"\n        \"mov gs, ax\\n\\t\"\n        // Build iretd frame on current (kernel) stack.\n        // iretd on privilege change pops: EIP, CS, EFLAGS, ESP, SS (in this order from top).\n        // So we push in REVERSE: SS first, then ESP, EFLAGS, CS, EIP last.\n        // After iretd pops EIP, it sees CS has RPL=3 > CPL=0 \u2192 privilege change \u2192\n        // also pops ESP and SS \u2192 switches stack to user stack.\n        \"push 0x23\\n\\t\"         // SS  (user stack segment = user data selector)\n        \"push %1\\n\\t\"           // ESP (user stack pointer)\n        \"pushfd\\n\\t\"            // EFLAGS (current value)\n        \"pop eax\\n\\t\"           // Get EFLAGS into EAX\n        \"or eax, 0x200\\n\\t\"     // Set IF (bit 9) \u2014 user process starts with interrupts enabled\n        \"and eax, ~0x3000\\n\\t\"  // Clear IOPL bits (bits 13:12 = 0 \u2192 no I/O from ring 3)\n        \"push eax\\n\\t\"          // Push modified EFLAGS\n        \"push 0x1B\\n\\t\"         // CS  (user code segment = GDT[3] | RPL=3 = 0x18|3 = 0x1B)\n        \"push %0\\n\\t\"           // EIP (user entry point)\n        \"iretd\\n\\t\"             // Atomically: pop EIP,CS,EFLAGS,ESP,SS; switch to ring 3\n        :\n        : \"r\"(user_eip), \"r\"(user_esp)\n        : \"eax\", \"memory\"\n    );\n    __builtin_unreachable();\n}\n```\n**Selector arithmetic verification:**\n- `0x1B` = `0001 1011` binary = index 3 (bits 15:3 = 3), TI=0 (GDT), RPL=3 (bits 1:0 = 11). GDT[3] = user code (access=0xFA, DPL=3). \u2713\n- `0x23` = `0010 0011` binary = index 4, TI=0, RPL=3. GDT[4] = user data (access=0xF2, DPL=3). \u2713\n- CPL after `iretd` = low 2 bits of CS = `0x1B & 3 = 3` = ring 3. \u2713\n---\n### 5.7 `sys_exit` \u2014 Process Removal and One-Way Switch\n{{DIAGRAM:tdd-diag-30}}\n```\nPROCEDURE scheduler_remove_current():\n  // current_process->state is already PROCESS_DEAD (set by sys_exit)\n  1. dead = current_process\n  2. // Find predecessor in circular list\n     prev = dead\n     WHILE prev->next != dead:\n       prev = prev->next\n       // Cycle detection: if we return to dead after MAX_PROCESSES steps,\n       // the list is corrupt (halt)\n  3. IF prev == dead:\n       // dead is the only process in the list\n       kprintf(\"[SCHED] Last process exited \u2014 halting\\n\")\n       cli; hlt\n  4. // Unlink dead from the list\n     prev->next = dead->next\n     IF process_list_head == dead:\n       process_list_head = dead->next\n  5. // Select next to run\n     next = dead->next  // already unlinked\n     WHILE next->state != PROCESS_READY:\n       next = next->next\n       IF next == dead: kprintf + halt  // All dead\n  6. // One-way switch to next (no context save for dead process)\n     next->state = PROCESS_RUNNING\n     tss_set_kernel_stack(next->kernel_stack_top)\n     current_process = next\n     IF dead->page_directory != next->page_directory:\n       CR3 = next->page_directory\n     // Load next's context and jump \u2014 no return\n     uint32_t new_esp = next->context.esp\n     __asm__ volatile (\n       \"mov esp, %0\\n\\t\"\n       \"popfd\\n\\t\"\n       \"pop ebp\\n\\t\"\n       \"pop edi\\n\\t\"\n       \"pop esi\\n\\t\"\n       \"pop ebx\\n\\t\"\n       \"ret\\n\\t\"\n       : : \"r\"(new_esp) : \"memory\"\n     )\n     __builtin_unreachable()\n```\n---\n### 5.8 Three-Process VGA Demonstration\nThree concurrent kernel processes each write to a distinct screen region using the VGA buffer at virtual `0xC00B8000`:\n```c\n// Demo process bodies (in process.c or kernel_main.c)\nstatic void proc_a_body(void) {\n    volatile uint16_t *vga = (volatile uint16_t *)0xC00B8000u;\n    uint8_t row = 0;\n    while (1) {\n        for (uint8_t col = 0; col < 26; col++) {\n            vga[row * 80 + col] = (uint16_t)(0x0A00 | 'A'); // Green on black\n        }\n        for (volatile uint32_t i = 0; i < 50000; i++);\n        row = (row + 1) % 25;\n    }\n}\nstatic void proc_b_body(void) {\n    volatile uint16_t *vga = (volatile uint16_t *)0xC00B8000u;\n    uint8_t row = 0;\n    while (1) {\n        for (uint8_t col = 27; col < 53; col++) {\n            vga[row * 80 + col] = (uint16_t)(0x0C00 | 'B'); // Red on black\n        }\n        for (volatile uint32_t i = 0; i < 50000; i++);\n        row = (row + 1) % 25;\n    }\n}\nstatic void proc_c_body(void) {\n    volatile uint16_t *vga = (volatile uint16_t *)0xC00B8000u;\n    uint8_t row = 0;\n    while (1) {\n        for (uint8_t col = 54; col < 80; col++) {\n            vga[row * 80 + col] = (uint16_t)(0x0B00 | 'C'); // Cyan on black\n        }\n        for (volatile uint32_t i = 0; i < 50000; i++);\n        row = (row + 1) % 25;\n    }\n}\n```\nAll three processes share `boot_pd_phys` as their page directory \u2014 they are kernel processes with identical address spaces.\n---\n### 5.9 Ring-3 User Process Code Template\n```c\n// user_process.c \u2014 compiled freestanding, linked at USER_CODE_VIRT = 0x00400000\n// Must NOT link against any kernel symbols. All communication via INT 0x80.\nstatic void user_sys_write(const char *s, uint32_t len) {\n    __asm__ volatile (\n        \"int 0x80\"\n        : : \"a\"(4), \"b\"(1), \"c\"(s), \"d\"(len)\n        : \"memory\"\n    );\n}\nstatic void user_sys_exit(uint32_t code) {\n    __asm__ volatile (\n        \"int 0x80\"\n        : : \"a\"(1), \"b\"(code)\n    );\n    while (1) __asm__ volatile (\"hlt\");\n}\nvoid user_main(void) {\n    user_sys_write(\"Hello from ring 3!\\n\", 19);\n    // Isolation test: attempt kernel memory read (should #PF with U=1)\n    // volatile uint32_t x = *(volatile uint32_t *)0xC0100000u;  // INTENTIONALLY FORBIDDEN\n    user_sys_exit(0);\n}\n```\n**Linking the user process:** The user process must be compiled and linked separately with its own linker script placing `.text` at `0x00400000`, then mapped into the user page directory via `paging_map` with `PTE_PRESENT | PTE_USER` (no `PTE_WRITABLE` for code pages). The binary must be embedded in the kernel image (e.g., as a `INCBIN` in NASM, or as a char array in a `.c` file generated by `xxd -i`).\n---\n## 6. Error Handling Matrix\n| Error | Detected By | Recovery | User-Visible? |\n|-------|-------------|----------|---------------|\n| EFLAGS.IF=0 in fabricated initial frame | `process_create`: wrong EFLAGS constant | Timer never fires; system freezes on first process | System freeze; no output after bootstrap |\n| TSS ESP0 not updated before context switch | `context_switch`: missing `tss_set_kernel_stack` | Next ring-3 interrupt pushes frame to old process's stack \u2192 corruption | Random triple faults after first ring-3 interrupt |\n| TSS ESP0 updated AFTER stack swap (wrong order) | `context_switch`: wrong call order | Race: interrupt arrives between swap and TSS update \u2192 old ESP0 used | Same as above; intermittent |\n| CR3 not updated on address space change | `context_switch`: missing CR3 write | Processes access each other's user-space memory | Memory corruption; wrong data; potential #PF |\n| `current_process` set after stack swap | `context_switch`: wrong order | Syscall handler sees old process info momentarily | Wrong PID in kprintf; incorrect sys_exit behavior |\n| Wrong register count saved/restored | `context_switch_asm`: push/pop count mismatch | Stack misaligned on resume; wrong EIP; crash | Triple fault or jump to garbage address |\n| `iretd` with CS=0x18 (RPL=0) instead of 0x1B | `enter_user_mode`: wrong selector | CPU detects CS.RPL=0 but stack selector has RPL=3 \u2192 #GP | #GP exception printed by M2 handler; system halts |\n| `iretd` with SS=0x10 (kernel data) instead of 0x23 | `enter_user_mode`: wrong SS | CPU attempts ring-0\u2192ring-3 transition with ring-0 SS \u2192 #GP | #GP; system halts |\n| DS/ES/FS/GS not loaded with 0x23 before `iretd` | `enter_user_mode`: missing segment reload | User process's first data access uses kernel selector \u2192 #GP | #GP immediately after user code begins |\n| User buffer in sys_write is kernel address | `sys_write`: missing range check | Kernel reads from `buf_virt >= 0xC0000000` \u2014 potentially leaks kernel data | Silent data leak; no visible error |\n| sys_write buf_virt not mapped in user PD | `sys_write`: accessing unmapped user page | Kernel #PF with U=0 (kernel access to unmapped address) \u2192 halt | Page fault message + halt |\n| sys_exit called; next process is dead | `scheduler_remove_current`: all-dead check | `kprintf(\"[SCHED] All processes dead\")` + `cli; hlt` | Visible kprintf message; clean halt |\n| Circular list broken after sys_exit | `scheduler_remove_current`: prev->next update | Dangling pointer \u2192 crash on next `scheduler_tick` | Triple fault on next timer interrupt |\n| `process_list_head` not updated after removing head | `scheduler_remove_current`: missing head update | `process_list_head` points to dead process \u2192 accessed next tick \u2192 DEAD state skipped | Skip works by design (DEAD skipped in tick); but freed memory access is undefined |\n| `process_create` called for user process without mapping code pages | `enter_user_mode`: first user instruction fetch | #PF at user_eip with P=0 \u2192 halt | Page fault + halt; check that code pages are mapped |\n| Bootstrap jump with IF=0 in fabricated frame | Already caught above; EFLAGS = 0x00000202 | Timer never fires; same as EFLAGS.IF=0 | System freeze |\n| `scheduler_remove_current` returns (not `noreturn`) | Code reaches past inline asm | Stack invalid; undefined behavior | Random crash |\n| Kernel-mode process accesses VGA via physical 0xB8000 (not 0xC00B8000) | Runtime: paging is on | #PF with CR2=0xB8000 (not mapped after identity map removal) | Page fault message; use 0xC00B8000 |\n| User process accesses kernel virtual address | Hardware: PTE_USER=0 on kernel pages | #PF with error code bit 2 (U=1), bit 0 (P=1) | Page fault message showing U=1 protection violation |\n---\n## 7. Implementation Sequence with Checkpoints\n### Phase 1 \u2014 TSS Setup (3\u20135 hours)\n1. Write `tss.h` with `tss_t` (all 104 bytes, `__attribute__((packed))`), `kernel_tss` extern, `tss_init`, `tss_set_kernel_stack` prototypes.\n2. Write `tss.c`: define `tss_t kernel_tss` (not in BSS \u2014 explicit zero init in `tss_init`). Implement `tss_init`: `memset(&kernel_tss, 0, sizeof(tss_t)); kernel_tss.ss0 = 0x10; kernel_tss.iomap_base = sizeof(tss_t); gdt_set_tss_entry(5, (uint32_t)&kernel_tss, sizeof(tss_t)-1); __asm__ volatile (\"ltr %0\" : : \"r\"((uint16_t)0x28));`. Implement `tss_set_kernel_stack`: single assignment `kernel_tss.esp0 = esp0_value`.\n3. Update `gdt.c`: add `gdt_set_tss_entry` (access=0x89, flags=0x00, byte granularity). Expand GDT array to 6 entries; update `gdt_init` to call `gdt_set_tss_entry(5, ...)` with zeroed base (will be set by `tss_init` later, or set here if `tss_init` is called from `gdt_init`). Recommended: `gdt_init` sets up 5 code/data entries; `tss_init` sets entry 6.\n4. Call `tss_init()` from `kernel_main` after `gdt_init()`.\n**Checkpoint 1:** GDB: `x/13wx &kernel_tss` \u2192 first word (prev_tss) = 0, second word (esp0) = 0 (before any process), third word (ss0) = 0x10. `info registers` after `tss_init`: TR = 0x28. `x/8bx &gdt+40` (GDT entry 5, offset 40 bytes) \u2192 access byte at offset +5 = 0x89. QEMU `-d int` shows no exceptions during `tss_init`. System continues running (does not triple-fault).\n---\n### Phase 2 \u2014 Process PCB and `process_create` (4\u20137 hours)\n1. Write `process.h` with all types: `process_state_t`, `cpu_context_t` (one field: `esp`), `process_t` (72-byte struct with the two `user_entry_fn`/`user_initial_esp` fields), `KERNEL_STACK_SIZE = 8192`, `MAX_PROCESSES = 64`, externs for `current_process` and `process_list_head`.\n2. Write `process.c`: `static uint32_t next_pid = 1`; `process_t *current_process = NULL`; `process_t *process_list_head = NULL`; implement `process_create`.\n3. Add `process_user_entry_trampoline` (static function in `process.c`).\n4. Add compile-time check: `typedef char proc_size_check[(sizeof(process_t) == 72) ? 1 : -1];`.\n**Checkpoint 2:** From `kernel_main`, create one kernel process: `process_t *p = process_create(\"test\", test_fn, boot_pd_phys, 0)`. GDB: `print *p` \u2192 `pid=1`, `state=PROCESS_READY`, `kernel_stack != NULL`, `kernel_stack_top == (uint32_t)p->kernel_stack + 8192`. `x/6wx p->context.esp` \u2192 `[0]=0x202, [4]=0, [8]=0, [12]=0, [16]=0, [20]=test_fn_addr`. Verify `test_fn_addr` matches `(uint32_t)test_fn`.\n---\n### Phase 3 \u2014 `context_switch_asm` (6\u201310 hours)\n{{DIAGRAM:tdd-diag-31}}\n1. Write `context_switch.asm` with the exact 11-instruction body from \u00a75.3. Assemble with `-f elf32`.\n2. Write `scheduler.h` / `scheduler.c` stubs: `scheduler_init` (sets globals NULL), `scheduler_add_process` (circular list insert), `context_switch` C wrapper (\u00a75.4 sequence).\n3. **Verify stack offsets before testing on real execution.** Use GDB to single-step through `context_switch_asm`: set breakpoint at `pushfd`, examine `[ESP+24]` == old_ctx, `[ESP+28]` == new_ctx. After `mov esp, [eax+0]`: verify `$esp` changed to new process's fabricated frame. After all pops: verify EBP=0, EDI=0, ESI=0, EBX=0. After `ret`: verify EIP jumped to the fabricated entry function.\n**Checkpoint 3A \u2014 Manual two-process switch:** Create two processes A and B. Set `current_process = A; A->state = PROCESS_RUNNING`. Manually call `context_switch(A, B)` from `kernel_main`. Verify: B begins executing, prints \"Process B running\", and since B has no way to switch back (scheduler not connected to timer yet), runs until its infinite loop. No crash, no corruption.\n**Checkpoint 3B \u2014 Round-trip switch:** Modify process A's body to call `context_switch` back to A from B (requires passing B back via global). Verify both processes execute their bodies in alternation. Confirm `current_process` is updated correctly before each switch.\n---\n### Phase 4 \u2014 Round-Robin Scheduler + Timer Integration (3\u20135 hours)\n1. Implement `scheduler_tick` in `scheduler.c` per \u00a75.4.\n2. Update `pit.c` / `timer_handler`: add `scheduler_tick(frame)` call (before `pic_send_eoi`? No \u2014 after timer handler body but before EOI is sent by `irq_dispatch`). Actually `irq_dispatch` sends EOI after `timer_handler` returns; `scheduler_tick` should be called from within `timer_handler`. Correct sequence: `tick_counter++; scheduler_tick(frame); return;` then EOI via `irq_dispatch`.\n3. Implement `scheduler_add_process` with circular list insert and the duplicate-insert check (`proc->next != NULL` \u2192 halt).\n**Checkpoint 4:** Create idle process (`while(1) __asm__ volatile(\"hlt\")`), add to scheduler. Create process A (prints something every N ticks), add to scheduler. `start_multitasking(idle_proc)`. QEMU: see process A's output appearing at regular intervals (~10 per second). QEMU `-d int` shows vector 32 entries every 10ms. No triple faults. The system runs indefinitely.\n---\n### Phase 5 \u2014 Bootstrap + Three-Process VGA Demo (3\u20135 hours)\n{{DIAGRAM:tdd-diag-32}}\n1. Write `start_multitasking` in `kernel_main.c` (the inline assembly bootstrap).\n2. Create four processes: idle, proc_a_body, proc_b_body, proc_c_body. Add all four to scheduler. Call `start_multitasking(proc_a)` (or idle \u2014 either works).\n3. VGA must be accessed via `0xC00B8000`. Verify this is correctly mapped in `pt_high` (physical `0xB8000` maps to virtual `0xC00B8000` via PD[768]/pt_high[0xB8]).\n**Checkpoint 5:** QEMU screen shows three columns simultaneously filling with 'A' (green), 'B' (red), 'C' (cyan). All three columns progress visually in parallel \u2014 no one process monopolizes the screen. Serial output shows kernel boot messages from before `start_multitasking`. QEMU `-d int` shows timer interrupt at steady 100 Hz.\n---\n### Phase 6 \u2014 User Page Directory + User Stack (4\u20136 hours)\n1. Write `usermode.h` / `usermode.c`. Implement `create_user_page_directory`: allocate frame, zero it, copy PDEs 768\u20131023 from `boot_pd` (accessible via `PHYS_TO_VIRT`).\n2. In `process_create` for `is_user=1`: allocate user stack frame, map it at `USER_STACK_VIRT` with `PTE_PRESENT|PTE_WRITABLE|PTE_USER`, set `proc->user_initial_esp = USER_STACK_VIRT + PAGE_SIZE - 4`, set `proc->user_entry_fn = (uint32_t)entry`.\n3. Map user code pages into the user page directory. The user binary must be embedded in the kernel image. Use `objcopy --add-section .user_bin=user.bin kernel.elf` or equivalent. Map the embedded binary pages at `USER_CODE_VIRT` with `PTE_PRESENT|PTE_USER` (no write \u2014 code is read-only).\n**Checkpoint 6:** GDB: After `create_user_page_directory()`, examine the returned physical address + `KERNEL_VIRT_BASE` as a `page_directory_t`. Verify PDEs 768\u20131023 are non-zero (match `boot_pd`). Verify PDEs 0\u2013767 are zero. `paging_map` of user stack at `USER_STACK_VIRT`: examine `pd_virt[VADDR_PD_INDEX(USER_STACK_VIRT)]` \u2014 should be present. PTE at `pt[VADDR_PT_INDEX(USER_STACK_VIRT)]` \u2014 should have `PTE_USER` set (bit 2).\n---\n### Phase 7 \u2014 `enter_user_mode` + `iretd` Sequence (4\u20136 hours)\n1. Implement `enter_user_mode` in `usermode.c` per \u00a75.6.\n2. Implement `process_user_entry_trampoline` in `process.c`.\n3. Create a user process in `kernel_main`: `uint32_t *upd = create_user_page_directory(); /* map code pages */ process_t *up = process_create(\"user_proc\", (void(*)(void))USER_CODE_VIRT, upd, 1);`. Add to scheduler.\n**Checkpoint 7A \u2014 Segment registers:** Break in GDB inside `enter_user_mode` after segment register loads: `info registers` \u2192 DS=0x23, ES=0x23, FS=0x23, GS=0x23. Verify `iretd` stack has exactly five words: SS=0x23, ESP=user_esp, EFLAGS with IF=1, CS=0x1B, EIP=USER_CODE_VIRT.\n**Checkpoint 7B \u2014 Ring-3 execution:** After `iretd`, GDB `stepi` \u2014 verify `$cs & 3 == 3` (ring 3). Single-step through user code. Serial shows \"Hello from ring 3!\\n\" \u2014 confirming sys_write works (Phase 8 must be done first). If not yet: just verify execution reaches `user_main` without immediately faulting.\n---\n### Phase 8 \u2014 INT 0x80 Syscall Gate + sys_write + sys_exit (5\u20138 hours)\n1. Update `idt.c` / `idt_init`: add `idt_set_gate(0x80, (uint32_t)isr_128, 0x08, 0xEF)`. Verify `isr_128` is defined in `isr_stubs.asm` (ISR_NOERR 128 should already be in the `%rep` section from M2; if `%rep` started at 48 and covers 208 entries: 48+208-1=255, so 128 is covered \u2713).\n2. Update `interrupt.c` / `interrupt_dispatch`: add `else if (frame->int_no == 0x80) { syscall_dispatch(frame); }` (no EOI \u2014 software interrupt, not hardware).\n3. Write `syscall.h` / `syscall.c`: define `SYS_EXIT=1`, `SYS_WRITE=4`, `SYSCALL_MAX=5`, dispatch table, `sys_write`, `sys_exit`.\n4. Implement `sys_write` with full user-pointer validation (range check + optional per-page presence check).\n5. Implement `sys_exit` calling `scheduler_remove_current`.\n6. Implement `scheduler_remove_current` as `__attribute__((noreturn))`.\n**Checkpoint 8A \u2014 IDT gate:** GDB: `x/8bx &idt[0x80]`. Expected (assuming isr_128 at addr 0xC010ABCD): `CD AB 08 00 00 EF 10 C0` (offset_low=0xABCD, selector=0x08, reserved=0x00, flags=0xEF, offset_high=0xC010). Verify DPL=3 (flags=0xEF = 1110_1111; bits 6:5 = 11 = DPL=3 \u2713).\n**Checkpoint 8B \u2014 User sys_write:** Run user process. Serial/VGA shows \"Hello from ring 3!\\n\". Verify `frame->eax` has the byte count on return.\n**Checkpoint 8C \u2014 sys_exit:** User process calls `user_sys_exit(0)`. Serial shows \"[PID N] exited with code 0\". Process is unlinked. Remaining processes (idle, A, B, C) continue running. No crash.\n---\n### Phase 9 \u2014 Ring-3 Isolation Test + Debugging (3\u20135 hours)\n{{DIAGRAM:tdd-diag-33}}\n1. In the user process, after `sys_write`, add a deliberate kernel memory access: `volatile uint32_t x = *(volatile uint32_t *)0xC0100000u;`.\n2. The page fault handler (M3) must detect `user=1` and print the appropriate message instead of halting silently.\n3. Update `page_fault_handler_extended` to handle `user=1, p=1` (protection violation from user) distinctly: print diagnostic, then \"kill\" the user process via `sys_exit(139)` (SIGSEGV equivalent) instead of halting the entire system.\n**Checkpoint 9 \u2014 Isolation verified:** User process accesses `0xC0100000`. Page fault handler prints:\n```\n[#PF] Page Fault at virtual address 0xC0100000\n  Access: READ from user mode\n  Cause: Protection violation (page present, wrong permissions)\n  \u2192 Killing user process (pid N)\n```\nThen `sys_exit(139)` is called. The three kernel demo processes continue running uninterrupted. QEMU screen still shows A, B, C columns filling. **This is the definitive proof of ring-3 isolation.**\n---\n## 8. Test Specification\n### 8.1 TSS Tests\n| Test | Setup | Expected |\n|------|-------|----------|\n| `sizeof(tss_t) == 104` | Compile-time | Build succeeds (size check passes) |\n| `kernel_tss.ss0 == 0x10` after `tss_init` | GDB inspect | `x/1wx ((uint8_t*)&kernel_tss+8)` = `0x00000010` |\n| `kernel_tss.iomap_base == 104` after `tss_init` | GDB inspect | `x/1hx ((uint8_t*)&kernel_tss+102)` = `0x0068` |\n| TR register loaded | `info registers` in GDB | `tr` = `0x28` |\n| GDT[5] access byte = 0x89 | `x/8bx &gdt[5]` | byte at offset 5 = `0x89` |\n| GDT[5] flags byte = 0x00 | `x/8bx &gdt[5]` | byte at offset 6 = `0x00` (byte granularity) |\n| `tss_set_kernel_stack(0xDEAD0000)` | After call | `kernel_tss.esp0 == 0xDEAD0000` |\n| No exception from `ltr` | QEMU `-d int` | Zero exception entries during `tss_init` |\n### 8.2 `process_create` Tests\n| Test | Input | Expected |\n|------|-------|----------|\n| PID assignment | Create 3 processes | PIDs = 1, 2, 3 (monotonically increasing) |\n| Kernel stack allocation | Inspect `proc->kernel_stack` | Non-NULL, aligned to \u2265 8 bytes, size = 8192 |\n| `kernel_stack_top` | `proc->kernel_stack_top` | `== (uint32_t)proc->kernel_stack + 8192` |\n| Fabricated EFLAGS | `x/1wx proc->context.esp` | `== 0x00000202` (IF=1, bit 1 set) |\n| Fabricated EIP | `x/1wx (proc->context.esp + 20)` | `== (uint32_t)entry_fn` |\n| All other regs = 0 | `x/4wx (proc->context.esp + 4)` | All four words = 0 (EBP, EDI, ESI, EBX) |\n| `state == PROCESS_READY` | Inspect | `proc->state == 0` |\n| `next == NULL` before add | Inspect | `proc->next == NULL` |\n| `page_directory` set | Inspect | `proc->page_directory == boot_pd_phys` |\n| User process: `user_entry_fn` | `is_user=1`, entry=0x400000 | `proc->user_entry_fn == 0x400000` |\n| User process: stack mapped | Check PTE at USER_STACK_VIRT | `PTE_PRESENT|PTE_WRITABLE|PTE_USER` all set |\n### 8.3 `context_switch_asm` Tests\n| Test | Method | Expected |\n|------|--------|----------|\n| Save: ESP stored in old_ctx | GDB breakpoint after `mov [eax+0], esp` | `old_ctx->esp == $esp` (at that moment) |\n| Load: ESP from new_ctx loaded | GDB after `mov esp, [eax+0]` | `$esp == new_ctx->esp` |\n| EFLAGS restored | Inspect EFLAGS after `popfd` | Matches value stored in fabricated frame (0x202) |\n| EBP=0 after restore | First scheduling of new process | `$ebp == 0` |\n| Return to entry_fn | Single-step `ret` | EIP = `entry_fn` address |\n| Round-trip: switch A\u2192B\u2192A | Manual test | A's ESP/EFLAGS restored exactly after returning to A |\n| Stack aligned after ret | Inspect new ESP after ret in entry_fn | `$esp % 4 == 0` (4-byte aligned) |\n### 8.4 Scheduler Tests\n| Test | Setup | Expected |\n|------|-------|----------|\n| `scheduler_add_process` single | Add P, check circular | `P->next == P` |\n| `scheduler_add_process` three | Add A,B,C; check list | `A->next==B, B->next==C, C->next==A` |\n| Duplicate add detection | Add same `process_t` twice | Second call halts with error message |\n| `scheduler_tick` skips DEAD | Kill B (state=DEAD), tick from A | Next is C (B skipped) |\n| `scheduler_tick` no switch if sole runnable | Only A in queue (B,C dead) | A continues; no context_switch called |\n| Preemption at 100 Hz | Three processes, QEMU 1-second run | Each process gets ~33 ticks (`total_ticks` \u2248 33 each) |\n### 8.5 User-Mode and Isolation Tests\n| Test | Setup | Expected |\n|------|-------|----------|\n| CS=0x1B after iretd | GDB `stepi` past `iretd`, `info reg cs` | `cs=0x1B` |\n| DS=0x23 in user mode | GDB inspect DS after entering ring 3 | `ds=0x23` |\n| CPL=3 after iretd | `$cs & 3` | `== 3` |\n| Kernel access from user \u2192 #PF U=1 | User reads 0xC0100000 | Page fault: `err_code & 4 == 4` (U bit), `err_code & 1 == 1` (P bit present) |\n| NULL deref from user \u2192 #PF | User reads address 0 | Page fault: CR2=0, P=0 |\n| `create_user_page_directory` copies kernel PDEs | Check PD[768] in new PD | Non-zero, matches boot_pd[768] |\n| User PDEs 0\u2013767 are zero | Check new PD[0..767] | All zero |\n### 8.6 Syscall Tests\n| Test | Trigger | Expected |\n|------|---------|----------|\n| INT 0x80 with EAX=4 (sys_write) | User code | Handler receives correct buf_virt and len in ebx/ecx/edx |\n| Return value in EAX | sys_write 5 bytes | User EAX = 5 after INT 0x80 returns |\n| Unknown syscall (EAX=99) | User code | Returns -1; kprintf warning; does not crash |\n| sys_write fd=2 | EBX=2 | Returns -1 (EBADF) |\n| sys_write kernel addr | ECX=0xC0100000 | Returns -1 (EFAULT) |\n| sys_write NULL | ECX=0 | Returns -1 (EFAULT; 0 < 0xC0000000 but NULL deref risk \u2014 check explicitly) |\n| sys_exit(0) | User calls SYS_EXIT | Process removed; other processes continue; kprintf shows exit message |\n| sys_exit removes from list | Check process list after | Dead process not in circular list; no dangling pointer |\n| VGA output from sys_write | `sys_write(\"AB\", 2)` | 'A' and 'B' appear on VGA; same on serial |\n| sys_write long string (5000 bytes) | `sys_write(buf, 5000)` | Clamped to 4096; 4096 bytes written; returns 4096 |\n---\n## 9. Performance Targets\n{{DIAGRAM:tdd-diag-34}}\n| Operation | Target | How to Measure |\n|-----------|--------|----------------|\n| Kernel-to-kernel context switch | < 500 ns | 5 pushes (5 cycles) + mov ESP (1 cycle) + 5 pops (5 cycles) + ret (1 cycle) + CR3 skip (same PD) + TSS write (1 cycle) \u2248 20 cycles \u2248 7 ns at 3 GHz; total with cache misses < 100 ns; measure with `rdtsc` around `context_switch` call |\n| User-to-user context switch (different PDs) | < 2 \u00b5s | Adds CR3 reload = full TLB flush; ~200\u2013500 TLB entries flushed; ~1\u20135 \u00b5s on real hardware; in QEMU cheaper |\n| `sys_write` overhead (excluding I/O) | < 1 \u00b5s | INT 0x80 entry (~100 ns) + dispatch (~50 ns) + loop per-char to VGA/serial (< 10 ns each) |\n| `sys_write` throughput for 100-byte string | < 20 \u00b5s | 100 chars \u00d7 (VGA write 1 cycle + serial poll ~8.7 \u00b5s max, but QEMU serial is fast) \u2248 5 \u00b5s practical |\n| `sys_exit` + reschedule | < 5 \u00b5s | List walk (O(n) with n\u226464) + one-way switch (~500 ns) |\n| `process_create` (kernel process) | < 10 \u00b5s | `kmalloc` \u00d7 2 (~2 \u00b5s each) + stack setup (~100 ns) = ~5 \u00b5s |\n| `process_create` (user process) | < 15 \u00b5s | Above + `pmm_alloc_frame` + `paging_map` (~2 \u00b5s) |\n| Scheduler tick overhead at 100 Hz | < 100 \u00b5s/second total | 100 ticks/sec \u00d7 ~1 \u00b5s per switch = 100 \u00b5s = 0.01% of CPU |\n| TSS ESP0 update | < 10 ns | Single 32-bit store to known offset; L1 cache hit |\n| `create_user_page_directory` | < 10 \u00b5s | `pmm_alloc_frame` + `memset` 4 KB (~1 \u00b5s at memory bandwidth) + 256-entry PDE copy |\n| Ring-3 entry via `iretd` | < 500 ns | 5 pops by hardware + privilege check + stack switch \u2248 10\u201320 cycles |\n| INT 0x80 round-trip (entry + return, no I/O) | < 500 ns | Two privilege transitions \u00d7 ~100\u2013200 ns each |\n**Measurement method for context switch latency:**\n```c\n// kernel process timing harness\nstatic void timing_process(void) {\n    uint64_t before, after;\n    __asm__ volatile (\"rdtsc\" : \"=A\"(before));\n    // Force a context switch by waiting for next tick\n    uint64_t start = tick_counter;\n    while (tick_counter == start);  // Wait for next tick\n    __asm__ volatile (\"rdtsc\" : \"=A\"(after));\n    uint64_t ticks_elapsed = after - before;\n    // Subtract ~10ms (one tick interval) worth of cycles to get pure switch cost\n    // Pure switch \u2248 total - (10_000_000 ns / (1/CPU_GHz)) cycles\n    kprintf(\"Context switch ~%u cycles\\n\", (uint32_t)(ticks_elapsed % 1000000));\n}\n```\n---\n## 10. Concurrency Specification\n**Model:** Single CPU, preemptive. All concurrent behavior is driven by the PIT IRQ0 at 100 Hz. Timer fires with EFLAGS.IF set; the interrupt gate clears IF on entry to the handler; no concurrent interrupt handlers.\n**Critical section: `scheduler_tick` / `context_switch`:** Runs entirely inside IRQ0 handler with IF=0. This is the only code that modifies `current_process`, `process->state`, CR3, and `kernel_tss.esp0`. No additional protection needed on single-core.\n**`current_process` global:** Written only in `context_switch` (before `context_switch_asm`) and `scheduler_remove_current`. Read by `syscall_dispatch`, `sys_write`, `sys_exit`, and indirectly by the scheduler. All reads occur either inside the IRQ handler (IF=0, no re-entrancy) or in kernel mode between interrupts. No tearing possible with 32-bit aligned access on x86.\n**`tick_counter` (from M2):** `volatile uint64_t`, modified in timer handler, read outside. 64-bit tearing handled by M2's `cli/sti` guard in `pit_get_ticks`. Do not call `pit_get_ticks` from within an IRQ handler (would deadlock on `sti`).\n**`process_list_head` / `proc->next` modification:** Only modified in `scheduler_add_process` (called before `sti`) and `scheduler_remove_current` (called from `sys_exit` which is called from `syscall_dispatch` which runs inside a trap gate \u2014 IF NOT cleared by trap gate, so interrupt can arrive during syscall!). **This is a real concurrency hazard.** `sys_exit` \u2192 `scheduler_remove_current` modifies the process list while a timer interrupt could also be walking the list. Fix: `cli` at the start of `scheduler_remove_current`, before any list modification. `sti` is not needed (the one-way switch via inline asm restores IF from the fabricated frame).\n**Ring-3 processes and kernel state:** Ring-3 user code cannot modify any kernel data structure (no write access to kernel pages). The only way user code touches kernel state is via `int 0x80`, which goes through the trap gate, `isr_common_stub`, and `syscall_dispatch`. This is the defined, safe path.\n**`tss_set_kernel_stack` concurrency:** Called from `context_switch` with IF=0. The write to `kernel_tss.esp0` is a single 32-bit store \u2014 atomic on x86. No protection needed beyond IF=0 (which is guaranteed by the IRQ gate).\n**Lock ordering:** Not applicable (no mutexes; all critical sections protected by IF=0 via interrupt gate entry or explicit `cli`).\n**Illegal concurrent operations:**\n- Calling `kmalloc` from within a timer interrupt handler: unsafe in M4 (no re-entrancy protection). The timer handler must not call `kmalloc`. `scheduler_tick` does not allocate memory.\n- Calling `scheduler_tick` with `current_process == NULL`: guard at top of function.\n- Enabling interrupts (`sti`) while holding a pointer to `process_list_head` for list traversal: race condition with timer interrupt modifying the list.\n---\n<!-- END_TDD_MOD -->\n",
  "tdd_current_mod_index": 4,
  "tdd_diagrams_to_generate": [
    {
      "id": "tdd-diag-3",
      "title": "GDT Entry Byte-Level Bit Field",
      "description": "64-bit segment descriptor laid out as 8 labeled bytes at offsets 0-7. Bytes 0-1: limit[15:0]. Bytes 2-3: base[15:0]. Byte 4: base[23:16]. Byte 5 (access): P(7), DPL(6:5), S(4), E(3), DC(2), RW(1), A(0) \u2014 each bit annotated with its name and value for all five GDT entries. Byte 6 (flags+limit): G(7), DB(6), L(5), AVL(4), limit[19:16](3:0). Byte 7: base[31:24]. Shows concrete hex values for null(0x00/0x00), kernel code(0x9A/0xCF), kernel data(0x92/0xCF), user code(0xFA/0xCF), user data(0xF2/0xCF).",
      "type": "memory_layout",
      "anchor_target": "build-os-m1"
    },
    {
      "id": "tdd-diag-4",
      "title": "Segment Selector to GDT Descriptor Resolution",
      "description": "Shows a 16-bit selector value (e.g., 0x08) decomposed into index(15:3)=1, TI(2)=0, RPL(1:0)=0. Arrow to GDTR register (base, limit). Index\u00d78 offset into GDT array. Arrow to selected 8-byte descriptor. Descriptor fields decoded to base=0, limit=4GB, DPL=0. Final linear address = base(0) + logical offset. Parallel path for user selector 0x1B showing RPL=3 and DPL=3 check. Marks the CPL/DPL comparison that hardware performs on every memory access.",
      "type": "data_flow",
      "anchor_target": "build-os-m1"
    },
    {
      "id": "tdd-diag-5",
      "title": "Real Mode to Protected Mode \u2014 CPU State Machine",
      "description": "State machine with four states: REAL_MODE (16-bit, IVT active, 1MB limit), TRANSITION_UNSAFE (CR0.PE=1 but CS still real-mode \u2014 exists for one instruction), PROTECTED_MODE_PARTIAL (after far jump, CS=0x08, but DS/ES/FS/GS/SS still old), PROTECTED_MODE_FULL (all segment registers loaded, 32-bit stack set). Transitions labeled with exact instructions. ILLEGAL transition shown: enabling interrupts while in TRANSITION_UNSAFE. Shows that missing far jump leaves CPU in TRANSITION_UNSAFE indefinitely, causing GPF.",
      "type": "state_machine",
      "anchor_target": "build-os-m1"
    },
    {
      "id": "tdd-diag-6",
      "title": "Linker Script Section Layout \u2014 VMA vs LMA",
      "description": "Two parallel columns: VMA (virtual, what code sees) and LMA (physical, where binary is stored). For Milestone 1 they are identical at 0x100000. .text starts at 0x100000, 4KB-aligned. .rodata follows page-aligned. .data follows. .bss: shows __bss_start and __bss_end symbols, marks that LMA image contains no bytes for BSS (saves disk space) but VMA region must be zeroed by kernel_entry. __kernel_end symbol at top. Annotated with linker script syntax for each section. Notes where higher-half kernel (M3) will diverge VMA from LMA.",
      "type": "memory_layout",
      "anchor_target": "build-os-m1"
    },
    {
      "id": "tdd-diag-7",
      "title": "VGA Text Mode Buffer Layout",
      "description": "80\u00d725 grid mapped at physical 0xB8000. Each cell is 2 bytes: byte 0 = ASCII code, byte 1 = attribute (bits 7:4=background, 3:0=foreground). Memory layout shows cell at (row, col) = offset (row*80+col)*2. Color attribute byte decomposed with all 16 color values listed. Shows volatile uint16_t* pointer arithmetic for row/col indexing. Notes that writes must be volatile (compiler optimization hazard for MMIO). Shows scroll operation as memmove of rows 1-24 to 0-23.",
      "type": "memory_layout",
      "anchor_target": "build-os-m1"
    },
    {
      "id": "tdd-diag-8",
      "title": "Kernel Entry Stack Frame Setup",
      "description": "Step-by-step stack diagram for kernel_entry assembly stub. Before BSS zero: ESP = kernel_stack_top (uninitialized region below). After BSS zero (rep stosb from __bss_start to __bss_end). Stack after 'mov esp, kernel_stack_top': empty 16KB stack. Stack after 'xor ebp, ebp': EBP=0 marks call chain bottom. Stack after 'call kernel_main': return address pushed, EIP=kernel_main. Shows .bss section containing kernel_stack (16384 bytes) and kernel_stack_top label at high address. Labels each byte region.",
      "type": "algorithm_steps",
      "anchor_target": "build-os-m1"
    },
    {
      "id": "tdd-diag-9",
      "title": "IDT Gate Descriptor Byte-Level Layout",
      "description": "8-byte IDT entry laid out at byte offsets 0-7. Bytes 0-1: handler offset[15:0]. Bytes 2-3: segment selector (0x08 = kernel code). Byte 4: reserved = 0. Byte 5 (flags): P(7), DPL(6:5), 0(4), type(3:0). Shows type values: 1110=32-bit interrupt gate (0x8E), 1111=32-bit trap gate (0x8F). Byte 6-7: handler offset[31:16]. Concrete hex values for a kernel exception gate (0x8E, DPL=0) vs syscall trap gate (0xEF, DPL=3). Shows idt_set_gate() field assignments with bit masks.",
      "type": "memory_layout",
      "anchor_target": "build-os-m2"
    },
    {
      "id": "tdd-diag-10",
      "title": "Interrupt Stack Frame \u2014 With vs Without Error Code",
      "description": "Two side-by-side stack diagrams after CPU interrupt delivery and pusha. Left (no error code, e.g., IRQ0): [ESP+48]=EFLAGS, [ESP+44]=CS, [ESP+40]=EIP, [ESP+36..0]=pusha regs + int_no + fake_err_code(0). Right (with error code, e.g., #GP=13): same layout but err_code is CPU-pushed value, not zero. Middle panel shows the interrupt_frame struct with byte offsets for each field matching the stack layout. Red annotation on the 'add esp, 8' instruction in isr_common_stub that cleans int_no and err_code before iret.",
      "type": "memory_layout",
      "anchor_target": "build-os-m2"
    },
    {
      "id": "tdd-diag-11",
      "title": "8259 PIC Cascade Architecture and Vector Remapping",
      "description": "Hardware block diagram: Master PIC (ports 0x20/0x21) receiving IRQ0-IRQ7. Slave PIC (ports 0xA0/0xA1) receiving IRQ8-IRQ15, connected to Master via IRQ2 cascade. Before remapping: IRQ0\u2192vector8(#DF), IRQ1\u2192vector9(#NP), ... IRQ7\u2192vector15. After remapping: IRQ0\u2192vector32, IRQ1\u2192vector33, ..., IRQ7\u2192vector39, IRQ8\u2192vector40, ..., IRQ15\u2192vector47. ICW1-ICW4 byte sequence with port addresses and timing (io_wait between writes). EOI rules: master-only for IRQ0-7, both slave+master for IRQ8-15.",
      "type": "architecture",
      "anchor_target": "build-os-m2"
    },
    {
      "id": "tdd-diag-12",
      "title": "ISR Stub Assembly \u2014 Stack State Before/After Each Instruction",
      "description": "Step-by-step stack diagram tracing isr_common_stub execution. Initial state: CPU pushed SS/ESP/EFLAGS/CS/EIP (privilege change case) or EFLAGS/CS/EIP (same privilege). ISR_NOERR stub pushed fake_err=0 and int_no. After pusha: 8 GP registers on stack. After push ds/es/fs/gs: 4 segment registers. After 'push esp': frame pointer argument. Highlights the critical 'mov ax, 0x10; mov ds,ax' reload \u2014 without this, kernel data access uses user-mode segment and faults. iret unwinding shown in reverse.",
      "type": "algorithm_steps",
      "anchor_target": "build-os-m2"
    },
    {
      "id": "tdd-diag-13",
      "title": "Exception Cascade: Fault \u2192 Double Fault \u2192 Triple Fault",
      "description": "State machine with four states: NORMAL_EXECUTION, HANDLING_EXCEPTION (first fault, IDT[n] invoked), DOUBLE_FAULT (second fault during handler \u2014 IDT[8] invoked, always error_code=0), TRIPLE_FAULT (fault during #DF handler \u2014 CPU resets, no recovery). Transitions labeled with triggering conditions. ILLEGAL path: raising an exception while HANDLING_EXCEPTION with a corrupt stack bypasses DOUBLE_FAULT and goes directly to TRIPLE_FAULT. Shows that #DF handler needs a dedicated stack (Task Gate) for robustness against stack corruption faults.",
      "type": "state_machine",
      "anchor_target": "build-os-m2"
    },
    {
      "id": "tdd-diag-14",
      "title": "PS/2 Keyboard Scancode-to-ASCII Pipeline",
      "description": "Data flow from physical key press to ring buffer entry. Stage 1: Key closes circuit \u2192 PS/2 serial protocol at 10 kHz \u2192 8042 KBC buffers byte. Stage 2: 8042 asserts IRQ1 \u2192 PIC delivers vector 33 \u2192 keyboard_handler called. Stage 3: inb(0x60) reads scancode byte. Stage 4: bit 7 check \u2014 if set, break code: update shift/ctrl/alt state, return. Stage 5: make code \u2192 check modifier state \u2192 index into scancode_to_ascii or scancode_to_ascii_shift table. Stage 6: non-zero result \u2192 ring_push(). Stage 7: keyboard_getchar() \u2014 ring_empty spin \u2192 ring_pop(). Shows circular buffer head/tail movement.",
      "type": "data_flow",
      "anchor_target": "build-os-m2"
    },
    {
      "id": "tdd-diag-15",
      "title": "Circular Ring Buffer Memory Layout and Head/Tail Invariants",
      "description": "256-byte circular array with head (write index) and tail (read index) as uint8_t (natural modulo 256 arithmetic). Four annotated states: EMPTY (head==tail), PARTIAL (tail < head, normal case), WRAPPED (head < tail, wrap case), FULL ((head+1)%SIZE==tail \u2014 one slot always wasted). Shows ring_push advancing head; ring_pop advancing tail. Diagrams the race-condition-free property on single-core: IRQ handler (producer) can only interrupt consumer code between ring_empty check and ring_pop, but tail is only modified by consumer \u2014 invariants preserved. Notes failure mode if SIZE is not power of 2.",
      "type": "memory_layout",
      "anchor_target": "build-os-m2"
    },
    {
      "id": "tdd-diag-16",
      "title": "Bitmap Physical Frame Allocator \u2014 Memory Layout and Word-Skip Algorithm",
      "description": "frame_bitmap[] array at a known BSS address. Each bit represents one 4 KB frame: bit=0 free, bit=1 used. Shows total_frames=32768 for 128 MB RAM, bitmap size=4096 bytes=1 page. alloc algorithm: outer loop over uint32_t words \u2014 if word==0xFFFFFFFF skip (all used); else inner loop finds first zero bit using __builtin_ctz(~word); returns frame_index * PAGE_SIZE. free algorithm: compute frame=addr/4096; check frame_test() for double-free; frame_clear(). Shows init sequence: memset(0xFF) then frame_clear() for usable E820 regions then re-frame_set() for kernel frames [kstart..kend] and frame 0.",
      "type": "algorithm_steps",
      "anchor_target": "build-os-m3"
    },
    {
      "id": "tdd-diag-17",
      "title": "x86 Two-Level Page Table Walk \u2014 Virtual Address Decomposition",
      "description": "32-bit virtual address split: bits 31-22 (10-bit PD index), bits 21-12 (10-bit PT index), bits 11-0 (12-bit page offset). Step 1: CR3 \u2192 physical address of Page Directory (4KB-aligned, 1024 entries \u00d7 4 bytes). Step 2: PD[pd_index] \u2192 PDE with physical address of Page Table (bits 31-12) + flags (bits 11-0). Step 3: PT[pt_index] \u2192 PTE with physical frame address (bits 31-12) + flags. Step 4: physical_addr = PTE.frame | virtual.offset. TLB cache shown as a bypass path that short-circuits steps 1-3 on hit. TLB miss path shown walking all three steps.",
      "type": "data_flow",
      "anchor_target": "build-os-m3"
    },
    {
      "id": "tdd-diag-18",
      "title": "PDE and PTE Bit-Field Layout",
      "description": "Two 32-bit registers shown with all bit fields labeled. PDE (bits 31-12=page_table_phys_addr, 11-9=avail, 8=global, 7=page_size(0=4KB), 6=reserved, 5=accessed, 4=cache_disable, 3=write_through, 2=user/supervisor, 1=writable, 0=present). PTE (bits 31-12=frame_phys_addr, 11-9=avail, 8=global, 7=reserved, 6=dirty, 5=accessed, 4=cache_disable, 3=write_through, 2=user/supervisor, 1=writable, 0=present). Concrete values shown for: kernel identity-map PTE (0x00003 = present+writable, no user), user page PTE (0x00007 = present+writable+user), MMIO page PTE (0x01B = present+writable+cache_disable+write_through).",
      "type": "memory_layout",
      "anchor_target": "build-os-m3"
    },
    {
      "id": "tdd-diag-19",
      "title": "Virtual Address Space Layout \u2014 Identity + Higher-Half Mapping",
      "description": "Full 32-bit virtual address space (0x00000000 to 0xFFFFFFFF) divided into labeled regions: 0x00000000-0x003FFFFF (identity map, 4 MB \u2014 VGA, BIOS, stack); 0x00400000-0xBFFFFFFF (future user space, 3 GB); 0xC0000000-0xC03FFFFF (higher-half kernel, 4 MB \u2014 kernel code/data); 0xC0400000-0xCFFFFFFF (kernel heap, 252 MB); 0xD0000000-0xFFBFFFFF (reserved); 0xFFC00000-0xFFFFFFFF (recursive PD mapping, optional). Arrow showing physical 0x00000000-0x003FFFFF maps to both VA 0x00000000 (identity) and VA 0xC0000000 (kernel). Red cross over identity map after removal.",
      "type": "memory_layout",
      "anchor_target": "build-os-m3"
    },
    {
      "id": "tdd-diag-20",
      "title": "Paging Enable Moment \u2014 Instruction-Level Transition",
      "description": "Five sequential CPU states with register values and address space interpretation. State 1: paging off, EIP=0x001xxxxx (physical=virtual). State 2: CR3 loaded with boot_pd_phys; paging still off \u2014 CR3 write is safe. State 3: CR0.PG=1 set \u2014 paging NOW active; EIP still at physical 0x001xxxxx but now interpreted as virtual 0x001xxxxx (identity-mapped by boot_pd[0] \u2014 execution continues). State 4: 'lea eax, [kernel_main_high]' loads 0xC01xxxxx. State 5: 'jmp eax' \u2014 EIP=0xC01xxxxx, fetched via PDE[768]\u2192pt_high. State 6: 'mov [boot_pd+0], 0' + CR3 reload \u2014 identity map gone; NULL deref now causes #PF. Red vertical line at the CR0.PG instruction marks the paging-active boundary.",
      "type": "algorithm_steps",
      "anchor_target": "build-os-m3"
    },
    {
      "id": "tdd-diag-21",
      "title": "TLB Flush Decision Tree \u2014 invlpg vs Full CR3 Reload",
      "description": "Decision tree starting at 'Page table entry modified'. Branch: single page changed? \u2192 Yes \u2192 use invlpg(virt_addr) \u2014 evicts one entry, O(1), ~10 ns. Branch: multiple pages in same PT changed? \u2192 loop invlpg per page. Branch: switching address spaces (new CR3)? \u2192 full CR3 reload \u2014 flushes all non-global entries. Branch: kernel mapping changed (shared across all PDs)? \u2192 full CR3 reload in current process + IPI to other CPUs (SMP, future). Shows which scenarios require action and which are safe to skip (mapping a previously-unmapped page: no stale entry exists, no flush needed). Annotated with cost in cycles for each path.",
      "type": "algorithm_steps",
      "anchor_target": "build-os-m3"
    },
    {
      "id": "tdd-diag-22",
      "title": "Page Fault Error Code \u2014 CR2 and Error Code Bit Decode",
      "description": "interrupt_frame shown with err_code field. Error code bit decomposition: bit 0 (P): 0=page not present, 1=protection violation. Bit 1 (W): 0=read access, 1=write access. Bit 2 (U): 0=kernel mode, 1=user mode. Bit 3 (RSVD): reserved bit set in PTE. Bit 4 (I/D): instruction fetch. CR2 register = faulting virtual address (must be read inside handler before any other memory op that might overwrite it). Truth table showing 8 common combinations with diagnosis: (0,0,0)=kernel null deref, (0,0,1)=user null deref/demand page, (1,1,1)=user write to read-only=COW trigger, (1,0,0)=kernel protection violation=kernel bug.",
      "type": "data_flow",
      "anchor_target": "build-os-m3"
    },
    {
      "id": "tdd-diag-23",
      "title": "Kernel Heap Block Layout and Free-List Coalescing",
      "description": "Linear virtual address range 0xC0400000-0xCFFF0000 shown as a sequence of heap_block_t headers interleaved with data regions. heap_block_t struct at byte offsets: 0=size(4B), 4=magic(4B, 0xDEADBEEF), 8=used(1B), 9-11=padding, 12=next*(4B), 16=prev*(4B). Total header=20 bytes. Three scenarios shown as before/after diagrams: (1) Split: large free block \u2192 allocated block + smaller free block. (2) Coalesce-forward: free block adjacent to next free block \u2192 merged block. (3) Coalesce-backward: freed block with previous free block \u2192 merged. Shows heap_brk advance when no free block satisfies request: pmm_alloc_frame() + paging_map() called to commit new page, heap_extend() creates new free block.",
      "type": "memory_layout",
      "anchor_target": "build-os-m3"
    },
    {
      "id": "tdd-diag-24",
      "title": "Process Control Block (process_t) \u2014 Byte-Level Field Map",
      "description": "process_t struct with byte offset for every field. Offset 0: pid (4B). Offset 4: name[32] (32B). Offset 36: state (4B enum). Offset 40: cpu_context_t context (28B): sub-offsets edi=0, esi=4, ebx=8, ebp=12, esp=16, eip=20, eflags=24. Offset 68: page_directory* (4B, physical address). Offset 72: kernel_stack* (4B). Offset 76: kernel_stack_top (4B \u2014 ESP0 value for TSS). Offset 80: user_esp (4B). Offset 84: ticks_remaining (4B). Offset 88: total_ticks (4B). Offset 92: next* (4B). Total struct size annotated. Notes which fields are valid in each process state (READY/RUNNING/BLOCKED/DEAD).",
      "type": "memory_layout",
      "anchor_target": "build-os-m4"
    },
    {
      "id": "tdd-diag-25",
      "title": "Task State Segment (tss_t) \u2014 Critical Fields and GDT Descriptor",
      "description": "tss_t struct with all 26 fields and byte offsets 0-103. Highlights ESP0 (offset 4) and SS0 (offset 8) in red as the only operationally significant fields. All other fields shown as 0/unused. GDT entry 5 shown as a system descriptor (S=0, type=0x9=32-bit TSS available) with base=&kernel_tss and limit=sizeof(tss_t)-1. Contrast with code/data descriptors (S=1). Shows ltr instruction loading selector 0x28 into the TR (Task Register). Sequence diagram: timer interrupt fires while ring-3 process runs \u2192 CPU reads tss.esp0 \u2192 switches stack \u2192 pushes SS/ESP/EFLAGS/CS/EIP at that address.",
      "type": "memory_layout",
      "anchor_target": "build-os-m4"
    },
    {
      "id": "tdd-diag-26",
      "title": "context_switch_asm \u2014 Stack State Trace at Each Instruction",
      "description": "Two parallel stack columns (OLD process stack on left, NEW process stack on right). Traces every push/pop/mov in context_switch_asm with ESP values. Left column: initial ESP (kernel stack in timer ISR context). After push ebx: ESP-4. After push esi: ESP-8. After push edi: ESP-12. After push ebp: ESP-16. After pushfd: ESP-20 = saved EFLAGS. 'mov [old_ctx+16], esp': stores this ESP into cpu_context_t.esp. 'mov esp, [new_ctx+16]': ESP jumps to new process's stack (right column). Right column now active: shows NEW's stack with its previously saved EFLAGS/EBP/EDI/ESI/EBX/EIP. popfd: restores new EFLAGS (including IF=1). pop ebp/edi/esi/ebx. ret: pops new EIP. Red vertical line at the ESP swap instruction marks identity change.",
      "type": "algorithm_steps",
      "anchor_target": "build-os-m4"
    },
    {
      "id": "tdd-diag-27",
      "title": "Fabricated Initial Kernel Stack Frame for First Process Schedule",
      "description": "process_create() builds a fake 'return from context_switch_asm' frame on the new process's kernel_stack buffer (8 KB, from kmalloc). Shows kernel_stack + KERNEL_STACK_SIZE = kernel_stack_top. Stack built downward from kernel_stack_top: [top-4]=0x00000202 (EFLAGS: IF=1, reserved bit 1 set); [top-8]=0 (EBP); [top-12]=0 (EDI); [top-16]=0 (ESI); [top-20]=0 (EBX); [top-24]=entry_point (EIP \u2014 the process function). context.esp = kernel_stack_top - 24. When context_switch_asm restores this process: popfd loads 0x202 (enables interrupts), pops zero regs, ret jumps to entry_point. Comparison: real saved frame vs fabricated frame \u2014 structurally identical.",
      "type": "algorithm_steps",
      "anchor_target": "build-os-m4"
    },
    {
      "id": "tdd-diag-28",
      "title": "Process State Machine \u2014 All States and Legal Transitions",
      "description": "State machine with four nodes: READY (in run queue, waiting for CPU), RUNNING (executing on CPU), BLOCKED (waiting for event \u2014 keyboard, sleep), DEAD (exited, slot recyclable). Legal transitions with labels: READY\u2192RUNNING (scheduler_tick selects this process), RUNNING\u2192READY (timer preempts \u2014 scheduler_tick context switch), RUNNING\u2192BLOCKED (process calls blocking operation, e.g., keyboard_getchar spin), BLOCKED\u2192READY (event arrives \u2014 keyboard char available), RUNNING\u2192DEAD (sys_exit called). ILLEGAL transitions shown with red X: BLOCKED\u2192RUNNING (must pass through READY), DEAD\u2192any (no resurrection). Notes that only one process can be in RUNNING state at any time on single-core.",
      "type": "state_machine",
      "anchor_target": "build-os-m4"
    },
    {
      "id": "tdd-diag-29",
      "title": "Round-Robin Scheduler \u2014 Circular List and Timer-Driven Preemption",
      "description": "Circular linked list of process_t nodes (process_a\u2192process_b\u2192process_c\u2192idle\u2192process_a). current_process pointer shown advancing on each tick. Timer IRQ0 fires \u2192 scheduler_tick() \u2192 advance current_process->next (skip BLOCKED/DEAD) \u2192 context_switch(old, next). Shows tick_counter and total_ticks per process increasing. Sequence diagram for a preemption event: (1) process_a running, (2) timer fires, (3) ISR saves process_a's kernel regs, (4) scheduler selects process_b, (5) TSS.ESP0 = process_b.kernel_stack_top, (6) CR3 = process_b.page_directory, (7) context_switch_asm swaps ESP, (8) isr_common_stub iretd restores process_b's user regs, (9) process_b runs.",
      "type": "sequence",
      "anchor_target": "build-os-m4"
    },
    {
      "id": "tdd-diag-30",
      "title": "Per-Process Page Directory \u2014 Kernel Shared / User Isolated",
      "description": "Two page directory arrays side by side (kernel_pd and user_proc_pd). Each has 1024 entries. PDE indices 0-767 (virtual 0x00000000-0xBFFFFFFF): kernel_pd has only kernel mapping; user_proc_pd has user-specific mappings (PTE_USER set). PDE indices 768-1023 (virtual 0xC0000000-0xFFFFFFFF): both PDs contain IDENTICAL entries pointing to the same physical page tables (shared kernel pages, PTE_USER NOT set). Shows that modifying a kernel page table entry is immediately visible to all processes because they share the same physical PT. User pages: different physical frames, different virtual addresses, PTE_USER=1 allows ring-3 access. Kernel pages: PTE_USER=0, ring-3 access \u2192 #PF with U=1.",
      "type": "architecture",
      "anchor_target": "build-os-m4"
    },
    {
      "id": "tdd-diag-31",
      "title": "Ring 3 Entry via iretd \u2014 Stack Layout and CPU State Transitions",
      "description": "enter_user_mode() function execution trace. Before iretd, kernel stack contains (from top/low address): [ESP+0]=user_EIP, [ESP+4]=user_CS(0x1B), [ESP+8]=user_EFLAGS(IF=1), [ESP+12]=user_ESP, [ESP+16]=user_SS(0x23). Segment registers DS/ES/FS/GS loaded with 0x23 (user data) before iretd. iretd execution: CPU pops EIP=user_EIP, CS=0x1B (CPL becomes 3), EFLAGS (IF=1), ESP=user_ESP, SS=0x23. CPU state after: ring-3, user stack active, all data segs=0x23, kernel stack abandoned. Selector values decoded: 0x1B=(3<<3)|3=index3,RPL3,TI0; 0x23=(4<<3)|3=index4,RPL3,TI0. Shows the ILLEGAL alternatives that cause #GP.",
      "type": "algorithm_steps",
      "anchor_target": "build-os-m4"
    },
    {
      "id": "tdd-diag-32",
      "title": "INT 0x80 Syscall \u2014 Full Round-Trip from User to Kernel and Back",
      "description": "Sequence diagram spanning user_process \u2192 CPU \u2192 isr_128 \u2192 interrupt_dispatch \u2192 syscall_dispatch \u2192 sys_write \u2192 VGA/serial \u2192 return. User code: 'mov eax,4; mov ebx,1; mov ecx,buf; mov edx,len; int 0x80'. CPU: reads IDT[128] (DPL=3 trap gate, so user can invoke; IF not cleared because trap gate). Pushes EFLAGS/CS/EIP onto kernel stack (privilege change: also pushes user SS+ESP). Loads kernel CS=0x08, EIP=isr_128. isr_128: push 0 (fake err), push 128, jmp isr_common_stub. isr_common_stub: pusha, push segs, reload DS=0x10, push ESP, call interrupt_dispatch. interrupt_dispatch: int_no==0x80 \u2192 syscall_dispatch(frame). syscall_dispatch: EAX=4=sys_write, call sys_write(EBX,ECX,EDX). sys_write: validate ECX<0xC0000000, write chars. Return: frame->eax = written_count. isr_common_stub: pop segs, popa, add esp 8, iretd. User code: EAX = return value.",
      "type": "sequence",
      "anchor_target": "build-os-m4"
    },
    {
      "id": "tdd-diag-33",
      "title": "Interrupt Enable/Disable Windows During Context Switch",
      "description": "Timeline showing IF (interrupt flag) value across the context switch critical path. Zone 1: Timer ISR entry \u2014 IF=0 (interrupt gate cleared it). Zone 2: scheduler_tick() \u2014 IF=0 (safe to call context_switch). Zone 3: context_switch C wrapper \u2014 IF=0; CR3 written; TSS.ESP0 written; current_process updated. Zone 4: context_switch_asm \u2014 IF=0 throughout register save and ESP swap. Zone 5: popfd in restore phase \u2014 IF restored from new process's EFLAGS (0x202, IF=1). Zone 6: ret to new process's ISR path \u2014 IF=1 from this point. Zone 7: iretd to user mode \u2014 IF=1. Annotates the window (zones 3-4) where CR3, TSS, and ESP changes must be atomic with respect to interrupts \u2014 violation causes TSS.ESP0 pointing to wrong stack on next interrupt.",
      "type": "algorithm_steps",
      "anchor_target": "build-os-m4"
    },
    {
      "id": "tdd-diag-34",
      "title": "TSS ESP0 Update Requirement \u2014 Correct vs Incorrect Sequence",
      "description": "Two side-by-side sequence diagrams. CORRECT: context_switch() updates TSS.ESP0 = new_proc.kernel_stack_top BEFORE calling context_switch_asm. Timer fires while new process runs \u2192 CPU reads TSS.ESP0 \u2192 kernel stack for new process \u2713. INCORRECT: TSS.ESP0 not updated. Timer fires while new process runs \u2192 CPU reads stale TSS.ESP0 (old process's kernel stack) \u2192 pushes EFLAGS/CS/EIP onto old process's kernel stack \u2192 when old process is rescheduled and its timer ISR completes, the extra frame corrupts its return address \u2192 delayed crash in unrelated code. Diagram makes the time-distance between cause (missed update) and effect (crash) visually explicit.",
      "type": "sequence",
      "anchor_target": "build-os-m4"
    }
  ],
  "external_reading": "",
  "running_criteria": [
    {
      "milestone_id": "build-os-m1",
      "criteria": [
        "Bootloader stage 1 fits within 510 bytes (512 bytes minus 2-byte boot signature) and ends with the little-endian boot signature 0x55AA at bytes 510-511 of sector 0",
        "Stage 1 bootloader uses BIOS INT 13h (function 0x02 or 0x42 for LBA) to load the stage 2 loader or kernel binary from disk into a valid memory region",
        "Kernel binary is loaded to physical address 0x100000 (1MB mark) before protected mode transition completes; stage 2 may load to a staging address and copy above 1MB after A20 is enabled",
        "A20 line is explicitly enabled using at least one method (BIOS INT 15h/2401, fast A20 via port 0x92 bit 1, or 8042 keyboard controller); A20 enable is verified before loading above 1MB",
        "GDT contains exactly 5 entries: index 0 (null descriptor, all-zero 8 bytes), index 1 (kernel code, selector 0x08, base=0, limit=4GB, access=0x9A, flags=0xCF), index 2 (kernel data, selector 0x10, base=0, limit=4GB, access=0x92, flags=0xCF), index 3 (user code, selector 0x18/0x1B, base=0, limit=4GB, access=0xFA, DPL=3), index 4 (user data, selector 0x20/0x23, base=0, limit=4GB, access=0xF2, DPL=3)",
        "GDTR is loaded with the lgdt instruction (pointing to a struct containing the 16-bit GDT size limit and 32-bit GDT linear base address) before CR0.PE is set",
        "Interrupts are disabled (cli) before loading the GDT and before setting CR0.PE; they remain disabled until the IDT is configured in Milestone 2",
        "Protected mode is entered by reading CR0, ORing bit 0 (PE) to 1, and writing back to CR0",
        "A far jump (jmp 0x08:label) is executed as the instruction immediately following the CR0.PE write; this atomically loads CS with the kernel code segment selector (0x08) and flushes the CPU instruction prefetch queue",
        "After the far jump, all data segment registers (DS, ES, FS, GS, SS) are loaded with the kernel data selector (0x10) using explicit mov reg, ax instructions",
        "32-bit stack pointer (ESP) is initialized to a valid, writable memory region (e.g., 0x9FC00 or a BSS-allocated stack buffer) before any C function is called",
        "Kernel entry assembly function zeroes the BSS section by iterating from the __bss_start symbol to the __bss_end symbol (both exported by the linker script) using rep stosb or equivalent",
        "Direction flag is cleared (cld) and EBP is set to 0 before calling the C entry point (kernel_main or equivalent)",
        "VGA text mode driver writes 16-bit entries (character byte + color attribute byte) to the volatile uint16_t array at physical address 0xB8000; implements putchar, newline handling, and screen scrolling",
        "VGA driver uses the volatile qualifier on the framebuffer pointer to prevent compiler optimization of writes; color attribute format is correct (bits 7:4 background, bits 3:0 foreground)",
        "Serial port COM1 (base I/O port 0x3F8) is initialized with: DLAB set (port+3 = 0x80), divisor = 1 for 115200 baud (port+0 = 0x01, port+1 = 0x00), 8N1 format (port+3 = 0x03), FIFO enabled (port+2 = 0xC7)",
        "Serial output polls the transmitter holding register empty bit (bit 5 of port+5) before each byte write",
        "kprintf function supports format specifiers %c (character), %s (null-terminated string), %d (signed decimal integer), %x (unsigned hex without prefix), and %p (hex with 0x prefix); output goes to both VGA and serial simultaneously",
        "Linker script defines ENTRY() pointing to the kernel entry assembly symbol; places .text section at 0x100000 with subsequent .rodata, .data, and .bss sections each 4KB-aligned; exports __bss_start, __bss_end, and __kernel_end symbols",
        "Build system uses an i686-elf cross-compiler (not the host gcc) with -ffreestanding -fno-stack-protector -fno-builtin -nostdlib flags; kernel is linked with the custom linker script",
        "Build system produces a raw disk image with stage 1 bootloader at byte offset 0 (sector 0), stage 2 loader starting at sector 2, and kernel binary at a sector offset consistent with the bootloader's INT 13h read parameters",
        "Kernel boots successfully in QEMU with -no-reboot flag (indicating no triple-fault), displays a welcome message on the VGA console, and outputs the same message to the serial port (visible via -serial stdio or -serial file:log.txt)",
        "QEMU invocation includes -d int,cpu_reset to verify no unexpected interrupts or resets occur during boot"
      ]
    },
    {
      "milestone_id": "build-os-m2",
      "criteria": [
        "IDT contains exactly 256 entries (each 8 bytes, total 2048 bytes); entries 0-31 use interrupt gate type (flags=0x8E, selector=0x08); the IDTR is loaded with lidt pointing to the correct base and limit",
        "A unified ISR stub system generates assembly stubs for all 256 vectors using macros; stubs for exceptions 8, 10-14 do not push a fake error code (CPU already pushed one); all other stubs push a dummy error code of 0 to maintain a uniform stack frame layout",
        "The common ISR stub executes pusha then pushes DS, ES, FS, GS before calling the C dispatch function; on exit it pops GS, FS, ES, DS then popa, then removes 8 bytes (int_no + err_code) with add esp 8, then executes iret",
        "The C interrupt_dispatch function receives a pointer to the saved interrupt frame (containing the 8 GP registers from pusha, 4 segment registers, int_no, err_code, and CPU-pushed EIP/CS/EFLAGS) and routes based on int_no",
        "CPU exception handlers 0-31 print: the exception name, vector number, EIP from the frame, CS, EFLAGS, EAX/EBX/ECX/EDX values, and the error code; execution halts after printing",
        "The page fault handler (vector 14) additionally reads CR2 via inline assembly and prints the faulting virtual address and the P/W/U bits of the error code",
        "The double fault handler (vector 8) prints a DOUBLE FAULT message including the error code (always 0) and the EIP field from the interrupt frame, then halts with cli+hlt in an infinite loop",
        "Both 8259 PICs are reinitialized with the four-step ICW1-ICW4 sequence before interrupts are enabled; master PIC is configured with offset 0x20 (IRQ0 maps to vector 32) and slave PIC with offset 0x28 (IRQ8 maps to vector 40)",
        "After PIC remapping, the master PIC data port (0x21) and slave PIC data port (0xA1) have appropriate IRQ masks set; at minimum, all IRQs except IRQ0 (timer) and IRQ1 (keyboard) are masked",
        "EOI (value 0x20) is written to master PIC command port (0x20) after every IRQ0-IRQ7 handler; for IRQ8-IRQ15, EOI is written to both slave command port (0xA0) and master command port (0x20)",
        "PIT channel 0 is programmed in mode 3 (square wave) by writing 0x36 to port 0x43, then writing the divisor low byte then high byte to port 0x40; divisor = 1193182 / frequency, yielding 100Hz with divisor 11931-11932",
        "A volatile uint64_t tick_counter is incremented on every timer IRQ (vector 32) handler invocation; the counter is accessible via a pit_get_ticks() function",
        "The keyboard IRQ handler (vector 33) reads one byte from port 0x60; if bit 7 is set (break/release code), it updates modifier state only; if bit 7 is clear (make code), it looks up the ASCII value using a 128-entry scancode table and pushes non-zero results to the keyboard ring buffer",
        "Left Shift (scancode 0x2A), Right Shift (scancode 0x36), and their release codes (0xAA, 0xB6) are tracked; when shift is active, a second 128-entry shifted scancode table is used for ASCII lookup",
        "The keyboard circular ring buffer has at least 256 bytes capacity; head and tail indices wrap modulo buffer size; ring_push silently drops characters when full; ring_pop returns 0 when empty",
        "sti is executed only after all of the following are complete: IDT loaded (lidt called), PIC remapped (both ICW sequences complete), and PIT initialized; the order in kernel_main enforces this invariant",
        "After enabling interrupts, a busy-wait loop confirms the tick_counter advances by the expected amount (e.g., 100 ticks in approximately 1 second) demonstrating the timer is operational"
      ]
    },
    {
      "milestone_id": "build-os-m3",
      "criteria": [
        "Physical memory map is parsed from the Multiboot information structure (mbi->flags bit 6 checked for validity) before any memory allocation occurs; each E820 region is classified as usable (type 1), reserved (type 2), ACPI reclaimable (type 3), ACPI NVS (type 4), or bad memory (type 5) and printed to the debug console",
        "Bitmap-based physical frame allocator initializes with ALL frames marked used, then selectively frees only regions classified as type-1 usable in the E820 map; frames occupied by the kernel binary (from __kernel_start to __kernel_end), frame 0 (NULL page protection), and any reserved MMIO regions are permanently marked used after freeing",
        "pmm_alloc_frame() scans the bitmap word-by-word (32 bits at a time), returning the physical address of the first free 4KB-aligned frame and marking it used; pmm_free_frame() detects and halts on double-free by checking frame_test() before clearing the bit",
        "Static boot page directory (4KB-aligned) installs at minimum two PDEs: PDE index 0 mapping virtual 0x00000000-0x003FFFFF to physical 0x00000000-0x003FFFFF (identity map), and PDE index 768 (0xC0000000 >> 22) mapping virtual 0xC0000000-0xC03FFFFF to physical 0x00000000-0x003FFFFF (higher-half kernel)",
        "Paging is enabled in the correct sequence: CR3 is loaded with the PHYSICAL address of the page directory (verified by VIRT_TO_PHYS conversion), then CR0 bit 31 (PG) is set; inline assembly includes a 'memory' clobber to prevent compiler reordering of page table writes across the CR0 write",
        "After enabling paging and jumping to the higher-half virtual address (0xC0100000+), the identity map PDE (boot_pd[0]) is cleared and the TLB is flushed by writing CR3 back to itself; subsequent NULL pointer dereferences trigger page fault #14 rather than silently accessing physical address 0",
        "The linker script links the kernel at virtual base 0xC0100000 (VMA) with AT() directives specifying physical LMA = VMA - 0xC0000000; the linker exports __kernel_start, __kernel_end, __bss_start, __bss_end symbols usable from C for BSS zeroing and PMM initialization",
        "paging_map(pd, virt, phys, flags) correctly computes PDE index as virt >> 22 and PTE index as (virt >> 12) & 0x3FF; allocates a new zeroed page table via pmm_alloc_frame() if the PDE is not present; installs the PTE with the correct physical frame address (PTE_FRAME mask applied) and specified flags; calls tlb_flush_page(virt) via the INVLPG instruction before returning",
        "paging_unmap(pd, virt) clears the PTE to 0 and calls tlb_flush_page(virt) before returning; failing to flush is caught in testing by verifying that a remapped page reflects new content rather than stale cache data",
        "Page fault handler (exception 14, vector 14) reads CR2 via inline assembly ('mov %0, cr2') to obtain the faulting virtual address; decodes error code bits: bit 0 (P=present), bit 1 (W=write), bit 2 (U=user mode), bit 4 (I=instruction fetch); prints fault address, access type, and EIP from the interrupt frame to both VGA and serial; halts with 'cli; hlt' on kernel-mode faults",
        "Kernel heap (kmalloc/kfree) reserves virtual range 0xC0400000-0xCFFF0000 for the heap arena; extends the heap by calling pmm_alloc_frame() + paging_map() in PAGE_SIZE increments when no suitable free block exists; each allocation header contains a magic value (e.g., 0xDEADBEEF) validated on every kmalloc and kfree to detect corruption and double-free",
        "kmalloc() implements first-fit block search with block splitting when remaining fragment is larger than sizeof(heap_block_t) + 8 bytes; kfree() coalesces adjacent free blocks (both forward with next block and backward with prev block) to prevent fragmentation; all returned pointers are 8-byte aligned",
        "VGA text buffer at virtual 0xB8000 and serial port registers at I/O port 0x3F8 remain accessible after paging is enabled; the identity map covers physical 0x00000000-0x003FFFFF which includes the VGA buffer at 0xB8000; the kernel can write to VGA immediately after enabling paging without a page fault",
        "A post-initialization test sequence calls kmalloc() for at least two allocations of different sizes, writes a pattern to the allocated memory with memset (verified not to cause page faults), frees one allocation and reallocates a smaller size from it (verifying block reuse), and prints the PMM free frame count; all tests pass without faults in QEMU"
      ]
    },
    {
      "milestone_id": "build-os-m4",
      "criteria": [
        "Process Control Block (PCB) struct stores exactly: uint32_t pid, char name[32], process_state_t state (enum: READY/RUNNING/BLOCKED/DEAD), cpu_context_t context (containing edi, esi, ebx, ebp, esp, eip, eflags fields), uint32_t *page_directory (physical address), uint8_t *kernel_stack, uint32_t kernel_stack_top, and scheduler linkage (next pointer for circular linked list)",
        "cpu_context_t layout matches the exact push/pop order in context_switch_asm: EFLAGS at stack top (pushed last by pushfd), then EBP, EDI, ESI, EBX, then EIP (return address from call instruction at bottom), with ESP saved explicitly into context.esp field via mov instruction",
        "context_switch_asm is implemented in x86 assembly (not C) and correctly saves EFLAGS via pushfd, saves EBX/ESI/EDI/EBP, saves old ESP into old_ctx->esp (offset 16), loads new ESP from new_ctx->esp, restores new process's EBP/EDI/ESI/EBX/EFLAGS via popfd, and returns to new process's saved EIP via ret",
        "The ESP swap in context_switch_asm is the identity boundary: pushes before the swap go onto the old process's kernel stack, pops after the swap come from the new process's kernel stack \u2014 demonstrated by being able to trace a context switch in GDB and observe ESP change to a different memory region at that exact instruction",
        "TSS structure (tss_t) is correctly defined as a packed struct with prev_tss at offset 0, esp0 at offset 4, ss0 at offset 8 (set to 0x10 = kernel data selector), and iomap_base at offset 102; TSS is registered as GDT entry 5 with a system descriptor (access byte 0x89) and loaded into the Task Register via the ltr instruction with selector 0x28",
        "tss_set_kernel_stack() updates kernel_tss.esp0 on every context switch before context_switch_asm is called, so that any interrupt arriving while the new process runs uses the new process's kernel stack top \u2014 verified by causing a timer interrupt during a user process and confirming the interrupt handler runs on the correct kernel stack",
        "Fabricated initial kernel stack for new processes contains (top to bottom): EFLAGS = 0x00000202 (IF=1, reserved bit 1 set), EBP = 0, EDI = 0, ESI = 0, EBX = 0, entry function address (as EIP); context.esp points to this fabricated frame so context_switch_asm can pop it on first scheduling",
        "Round-robin scheduler maintains a circular singly-linked list of READY processes; scheduler_tick() is called from the timer IRQ handler, advances current_process to the next READY process in the list, transitions old state to READY and new state to RUNNING, and calls context_switch() \u2014 all with interrupts disabled (inside interrupt gate handler)",
        "At least 3 kernel-mode processes run concurrently, each writing distinct characters to non-overlapping VGA columns, with visible interleaved output demonstrating that no single process monopolizes the CPU across multiple screen rows",
        "Per-process page directories for user-mode processes copy kernel PDEs (indices 768-1023, covering 0xC0000000+) from the boot page directory so kernel mappings are always accessible, while user PDEs (indices 0-767) are unique per process; user pages mapped with PTE_PRESENT | PTE_WRITABLE | PTE_USER",
        "enter_user_mode() uses iretd with stack frame containing (top to bottom): SS=0x23 (user data, RPL=3), user_esp, EFLAGS with IF=1 (bit 9 set), CS=0x1B (user code, RPL=3), user_eip; all data segment registers (DS/ES/FS/GS) loaded with 0x23 before iretd executes",
        "User-mode process accessing a kernel virtual address (>= 0xC0000000, mapped without PTE_USER) triggers page fault #14 with error code bit 2 (U bit) = 1 and bit 0 (P bit) = 1, confirming hardware-enforced supervisor-only protection; page fault handler prints the faulting CR2 address and error code before halting the offending process",
        "System call gate at IDT vector 0x80 uses flags 0xEF (P=1, DPL=3, trap gate type=1111) so user-mode code can invoke int 0x80 without a general protection fault, and interrupts remain enabled during syscall handling (trap gate does not clear IF)",
        "Syscall dispatch reads syscall number from interrupt_frame->eax, argument 1 from frame->ebx, argument 2 from frame->ecx, argument 3 from frame->edx; return value is written back to frame->eax before iret restores user registers",
        "sys_write (syscall 4) validates that the user buffer pointer is below 0xC0000000 before dereferencing, returns -1 on invalid pointer, and successfully outputs the buffer contents to both VGA and serial for fd=1 (stdout)",
        "sys_exit (syscall 1) marks the current process as PROCESS_DEAD, removes it from the circular ready queue, updates process_list_head if needed, and immediately context-switches to the next READY process without saving the dead process's context",
        "TSS ESP0 field is verified to be non-zero and pointing to a valid kernel stack address after every context switch \u2014 confirmed by inspecting kernel_tss.esp0 in GDB after each scheduling event",
        "An idle process exists in the ready queue that executes 'hlt' in a loop; the scheduler switches to it when no other process is READY, preventing the scheduler from having no runnable process when all others are BLOCKED or DEAD"
      ]
    },
    {
      "module_id": "build-os-m1",
      "criteria": [
        "Bootloader code fits within MBR constraints: stage1.bin is exactly 512 bytes with boot signature 0x55 at byte 510 and 0xAA at byte 511",
        "Stage2 loader fits within 4096 bytes (8 sectors); stage2.bin produced by 'make' is verified \u2264 4096 bytes",
        "Bootloader reads kernel binary from disk using BIOS INT 13h extended read (function 0x42) with a Disk Address Packet and loads it to physical address 0x10000, then copies it to 0x100000 after entering protected mode",
        "A20 line is enabled using at least one method (BIOS INT 15h/2401, fast A20 via port 0x92, or keyboard controller); A20 is verified by writing to 0x10500 and confirming 0x0500 is not modified",
        "GDT is configured with exactly 5 entries: null descriptor at index 0; kernel code (ring 0, 0x9A access, 0xCF flags, selector 0x08); kernel data (ring 0, 0x92 access, 0xCF flags, selector 0x10); user code (ring 3, 0xFA access, 0xCF flags, selector 0x18); user data (ring 3, 0xF2 access, 0xCF flags, selector 0x20)",
        "GDTR is loaded with lgdt instruction with correct limit (39) and base address pointing to the 5-entry GDT before CR0.PE is set",
        "Protected mode is entered by setting CR0.PE bit (bit 0) to 1 with interrupts disabled (cli before lgdt and before cr0 write)",
        "Far jump (jmp 0x08:label) is executed immediately after CR0.PE is set to load CS with selector 0x08 and flush the instruction prefetch queue",
        "All data segment registers DS, ES, FS, GS, SS are loaded with kernel data selector 0x10 immediately after the far jump lands in 32-bit protected mode",
        "32-bit stack pointer (ESP) is initialized to 0x9FC00 (below EBDA) in stage2 and then to kernel_stack_top (16 KB BSS-allocated stack above kernel) in kernel_entry before calling kernel_main",
        "kernel_entry.asm executes cld before rep stosb and before calling kernel_main; direction flag DF=0 is established before any C code runs",
        "Kernel entry point in assembly zeroes the BSS section from __bss_start to __bss_end using rep stosb before calling kernel_main",
        "C entry point function kernel_main is called with EBP=0 (for stack unwinding), a valid ESP, DF=0, and EFLAGS.IF=0",
        "VGA text mode driver writes characters with color attributes to the memory-mapped buffer at 0xB8000; VGA_BUFFER declared as volatile uint16_t*; vga_scroll() implemented for row 25 overflow",
        "Serial port COM1 (0x3F8) is initialized with 115200 baud (divisor=1), 8N1 configuration in the exact sequence: disable IRQs, set DLAB, write divisor, clear DLAB with 0x03, configure FIFO 0xC7, set modem control 0x0B",
        "kprintf supports format specifiers %c, %s, %d (with INT_MIN edge case), %x (8 zero-padded hex digits, lowercase), %p (0x prefix + 8 hex digits), and %% (literal percent); output goes to both VGA and serial",
        "Linker script kernel.ld places .text section at exactly 0x100000 with 4096-byte section alignment; __bss_start and __bss_end symbols exported; __kernel_end symbol exported",
        "Compile-time assertions verify sizeof(gdt_entry_t)==8 and sizeof(gdtr_t)==6",
        "gdt_init() is called from kernel_main to reinitialize GDT in kernel memory and reload all segment registers; gdt_flush() reloads DS, ES, FS, GS, SS with 0x10",
        "Kernel boots successfully in QEMU and displays a welcome message on both VGA console (verified via QEMU video output) and serial output (verified via -serial stdio or serial.log)",
        "Build system produces a valid bootable disk image os.img with stage1 in sector 0, stage2 starting at sector 2, and kernel starting at sector 10; 'make run' boots to kernel_main without manual steps",
        "QEMU -d int output shows zero exceptions from boot through kernel_main execution (no triple faults or protection violations during normal boot)",
        "GDB can attach via 'make debug' (QEMU -s -S), break at kernel_main, and inspect CS=0x8 DS=0x10 SS=0x10 in 'info registers'"
      ]
    },
    {
      "module_id": "build-os-m2",
      "criteria": [
        "IDT is allocated as a 256-entry array of 8-byte idt_entry_t structures; total size exactly 2048 bytes; IDTR loaded with limit=2047 and base pointing to idt[0] before sti is called",
        "idt_set_gate correctly encodes handler address across offset_low (bits 15:0) and offset_high (bits 31:16); selector field always 0x08; reserved field always 0; flags field 0x8E for interrupt gates",
        "ISR_NOERR macro pushes a fake dword 0 error code then the interrupt number; ISR_ERR macro pushes only the interrupt number (CPU already pushed error code); both jump to isr_common_stub",
        "Exceptions 8, 10, 11, 12, 13, 14, 17 use ISR_ERR; all other vectors 0-255 use ISR_NOERR",
        "isr_common_stub executes pusha, pushes ds/es/fs/gs, reloads kernel data segments (0x10), pushes esp as interrupt_frame_t pointer, calls interrupt_dispatch, then reverses: pops gs/fs/es/ds, popa, add esp 8, iretd",
        "interrupt_frame_t struct field offsets match actual stack layout: gs at offset 0, fs at 4, es at 8, ds at 12, edi at 16, esi at 20, ebp at 24, esp_dummy at 28, ebx at 32, edx at 36, ecx at 40, eax at 44, int_no at 48, err_code at 52, eip at 56, cs at 60, eflags at 64",
        "PIC 8259 is remapped using the full ICW1-ICW4 sequence: master offset 0x20 (IRQ0=vector 32), slave offset 0x28 (IRQ8=vector 40); pic_remap called with interrupts disabled before sti",
        "After pic_remap, master IMR (port 0x21) has bits 0 and 1 clear (IRQ0 timer and IRQ1 keyboard unmasked); slave IMR (port 0xA1) is 0xFF (all masked)",
        "pic_send_eoi sends 0x20 to master port 0x20 for all IRQs; additionally sends 0x20 to slave port 0xA0 first for IRQs 8-15; called at end of every IRQ handler before iretd",
        "Spurious IRQ7 detection: reads master PIC ISR via OCW3 (outb 0x20, 0x0B); if bit 7 not set, returns without sending EOI and without processing the IRQ",
        "Spurious IRQ15 detection: reads slave PIC ISR; if bit 15 not set, sends EOI only to master (not slave) and returns without processing",
        "PIT channel 0 programmed with command byte 0x36 (channel 0, lo/hi byte access, mode 3 square wave, binary); divisor written low byte then high byte to port 0x40; divisor = 1193182 / 100 = 11931 or 11932 for 100 Hz",
        "tick_counter declared as volatile uint64_t; incremented by exactly 1 in timer_handler; 100 increments occur in approximately 1 second wall time in QEMU",
        "CPU exceptions 0-31 invoke kprintf with: exception name string, int_no, EIP from frame, CS from frame, EFLAGS from frame, error code from frame",
        "Page fault handler (vector 14) reads CR2 via inline asm 'mov %0, cr2' and prints the faulting address plus decoded error code bits (P, W, U, RSVD, ID)",
        "Double fault handler (vector 8) prints diagnostic then enters infinite cli+hlt loop; does not attempt to return",
        "keyboard_handler reads port 0x60 unconditionally on every IRQ1; break codes (bit 7 set) update modifier state and return without pushing to ring buffer; make codes are translated via scancode table and pushed to ring buffer if ASCII != 0",
        "Scancode table covers Set 1 make codes 0x00-0x7F; shift table provides uppercase/symbol variants; CapsLock toggles on make code 0x3A; Shift XOR CapsLock determines uppercase selection",
        "Ring buffer uses uint8_t head and tail in a 256-byte array; full condition is (uint8_t)(head+1)==tail; empty condition is head==tail; overflow silently drops the new character",
        "keyboard_getchar blocks by executing hlt in a loop while ring is empty; returns when keyboard IRQ populates the buffer; requires EFLAGS.IF=1 at call site",
        "sti is executed after and only after: idt_init completes, pic_remap completes, pit_init completes; no sti call appears before all three",
        "System does not triple-fault when sti is called and the first timer interrupt fires; QEMU -d int shows vector 32 (0x20) not vector 8 (0x08) for timer interrupts"
      ]
    },
    {
      "module_id": "build-os-m3",
      "criteria": [
        "Physical memory map obtained from multiboot info or E820, with regions classified as usable/reserved/ACPI",
        "Physical frame allocator (bitmap or free-list) allocates and frees 4KB frames with double-free prevention",
        "Page directory and page tables configured for identity-mapping (kernel + VGA + MMIO) and higher-half kernel mapping (0xC0000000+)",
        "Paging enabled by loading CR3 with page directory physical address and setting CR0.PG bit",
        "TLB flushed with invlpg or CR3 reload after modifying page table entries",
        "Page fault handler reads CR2 for faulting address and prints diagnostic (address, error code bits for present/write/user)",
        "Kernel heap allocator (kmalloc/kfree) provides dynamic allocation from dedicated virtual range using page allocator for backing frames",
        "Identity map maintained for low memory so VGA (0xB8000) and MMIO regions remain accessible at physical addresses"
      ]
    },
    {
      "module_id": "build-os-m4",
      "criteria": [
        "TSS (Task State Segment) registered as GDT entry 5 with selector 0x28, access byte 0x89, byte granularity (flags=0x00); TR register loaded via 'ltr 0x28' instruction after tss_init",
        "kernel_tss.ss0 == 0x10 (kernel data segment) and kernel_tss.iomap_base == sizeof(tss_t) == 104 after tss_init",
        "tss_set_kernel_stack(new->kernel_stack_top) is called BEFORE context_switch_asm in the context_switch C wrapper, ensuring TSS.ESP0 is correct before any ring-3 interrupt fires",
        "process_t PCB has exactly the required fields: pid, name[32], state, cpu_context_t (esp only), page_directory (physical address), kernel_stack, kernel_stack_top, total_ticks, next; sizeof(process_t) verified at compile time",
        "Fabricated initial kernel stack frame has EFLAGS=0x00000202 (IF=1, bit 1 set); EBP=EDI=ESI=EBX=0; EIP=entry_fn; context.esp points to EFLAGS word on stack",
        "context_switch_asm saves exactly 5 registers (EBX, ESI, EDI, EBP, EFLAGS via pushfd) plus the implicit call return address (EIP); saves old ESP to old_ctx->esp; loads new ESP from new_ctx->esp; restores new process registers with matching pops",
        "context_switch C wrapper performs operations in this exact order: tss_set_kernel_stack, CR3 update (if page directories differ), current_process = new, then context_switch_asm",
        "CR3 is loaded with the PHYSICAL address of new->page_directory on every context switch where address spaces differ",
        "Round-robin scheduler_tick is called from timer_handler (IRQ0); selects next READY process in circular list; skips DEAD processes; performs no switch if sole runnable process; updates state: old=READY, new=RUNNING before calling context_switch",
        "At least 3 concurrent kernel processes run demonstrably in parallel on VGA (distinct columns filling simultaneously) under preemptive scheduling at 100 Hz",
        "Bootstrap sequence: current_process set before bootstrap jump; tss_set_kernel_stack called before first process runs; bootstrap uses inline assembly with mov esp + popfd + 4 pops + ret pattern; kernel_main stack is permanently abandoned",
        "create_user_page_directory: allocates one physical frame, zeros it, copies PDEs 768-1023 from boot_pd, leaves PDEs 0-767 as zero; returns physical address",
        "User-mode process stack allocated via pmm_alloc_frame and mapped at USER_STACK_VIRT=0xBFFFF000 with PTE_PRESENT|PTE_WRITABLE|PTE_USER flags",
        "enter_user_mode: loads DS/ES/FS/GS=0x23 before iretd; builds iretd frame with SS=0x23, user_esp, EFLAGS|0x200 (IF=1), CS=0x1B, user_eip; executes iretd; never returns",
        "After iretd: CS=0x1B (ring 3 confirmed by $cs & 3 == 3); user process executes at ring 3 with user stack active",
        "INT 0x80 IDT gate installed at vector 128 with flags=0xEF (P=1, DPL=3 for user invocability, type=0xF trap gate); user-mode 'int 0x80' does not cause #GP",
        "syscall_dispatch reads EAX (syscall number), EBX/ECX/EDX (args); writes return value back to frame->eax; INT 0x80 does not send EOI (software interrupt, not hardware IRQ)",
        "sys_write(fd=1, buf_virt, len): validates fd==1 (else -1), buf_virt < 0xC0000000 (else -1), clamps len to 4096; writes each byte to vga_putchar and serial_putchar; returns byte count",
        "sys_exit(code): prints exit message, sets current_process->state=PROCESS_DEAD, calls scheduler_remove_current (noreturn); unlinks process from circular list; switches to next READY process via one-way stack bootstrap",
        "scheduler_remove_current executes with interrupts disabled (cli before list modification); correctly updates process_list_head if removing head; does not return (uses one-way inline asm bootstrap into next process)",
        "Accessing any kernel virtual address (>= 0xC0000000) from user-mode code produces page fault with error code bit 2 (U) set to 1 and bit 0 (P) set to 1 (protection violation, not page-not-present)",
        "All kernel pages mapped without PTE_USER flag (bit 2 clear); user pages mapped with PTE_USER flag; this enforcement is via page table entries, not software checks",
        "EFLAGS.IF=0 during context_switch_asm execution (protected by interrupt gate entry); EFLAGS.IF re-enabled by popfd restoring IF=1 from saved context",
        "process_t->next forms a valid circular singly-linked list at all times: after scheduler_add_process, after sys_exit with scheduler_remove_current; no dangling pointers or list cycles of wrong length"
      ]
    }
  ],
  "explained_concepts": [
    "segment-descriptors-flat-model",
    "linker-script-bare-metal",
    "real-mode-vs-protected-mode",
    "x86-privilege-rings"
  ],
  "system_diagram_d2": null,
  "system_diagram_iteration": 0,
  "system_diagram_done": false,
  "project_structure_md": "",
  "project_charter_md": ""
}