[
  {
    "milestone_id": "build-sqlite-m1",
    "criteria": [
      "Tokenizer correctly identifies all SQL keywords (SELECT, INSERT, CREATE, TABLE, WHERE, FROM, JOIN, VALUES, INTEGER, TEXT, REAL, BLOB, PRIMARY, KEY, NOT, NULL, UNIQUE) case-insensitively.",
      "String literals are captured correctly, including the handling of escaped single quotes (e.g., 'it''s' results in the literal value 'it's').",
      "Numeric literals are distinguished as separate types: Integers (no decimal) and Floats (containing a decimal point).",
      "Multi-character operators (>=, <=, !=, <>) are correctly tokenized as a single token, not two separate ones.",
      "Quoted identifiers using double quotes (e.g., \"Table Name\") are correctly identified as identifiers, preserving spaces and case.",
      "The tokenizer tracks and reports the line and column number for every token produced.",
      "An error is raised with precise position (line/column) when an unrecognized character is encountered.",
      "The tokenizer correctly handles and ignores various forms of whitespace (spaces, tabs, newlines) while maintaining line counts.",
      "A test suite proves that a complex SQL string (containing quotes, numbers, and operators) produces an identical sequence of tokens to the expected output."
    ]
  },
  {
    "milestone_id": "build-sqlite-m2",
    "criteria": [
      "Implement a 'Statement' interface/enum and concrete nodes for SELECT, INSERT, and CREATE TABLE.",
      "Implement an 'Expression' node system capable of representing literals, identifiers (column names), and binary operations.",
      "The SELECT parser must handle the '*' wildcard, named column lists, and optional FROM, WHERE, ORDER BY, and LIMIT clauses.",
      "The INSERT parser must correctly extract the table name and map values into an internal 'ValueList' structure.",
      "The CREATE TABLE parser must correctly identify column names, data types (INTEGER, TEXT, REAL, BLOB), and constraints (PRIMARY KEY, NOT NULL, UNIQUE).",
      "Implement Precedence Climbing in the expression parser to ensure 'NOT' > 'AND' > 'OR' and math operators are correctly nested.",
      "Handle parenthesized expressions by recursively calling the expression parser and stripping the markers from the AST.",
      "Ensure 'NULL' is parsed as a distinct literal type and not an identifier.",
      "The parser must report the exact line and column of any syntax error based on the token's metadata.",
      "Successfully parse at least 15 distinct, valid SQL statements and generate the expected tree structure.",
      "Correcty reject at least 10 invalid SQL statements (e.g., missing commas, keywords in wrong order) without crashing."
    ]
  },
  {
    "milestone_id": "build-sqlite-m3",
    "criteria": [
      "The compiler translates a SELECT AST into a sequence of at least 5 distinct opcodes (e.g., OpenRead, Rewind, Column, ResultRow, Next).",
      "The Virtual Machine implements a fetch-decode-execute loop that processes one opcode per iteration.",
      "The VM maintains a 'Register File' capable of storing multiple data types (Integer, Text, Null) without losing type information.",
      "A WHERE clause with a comparison operator (e.g., age > 21) compiles into a conditional jump opcode (Lt, Le, Gt, or Ge) that skips the ResultRow instruction.",
      "The EXPLAIN command correctly halts execution and outputs a human-readable table of the generated bytecode instructions.",
      "The VM supports a 'Cursor' abstraction that tracks the current B-tree page and row offset independently of the register file.",
      "Register allocation logic correctly handles nested expressions (e.g., a + b * c) without overwriting intermediate results.",
      "The engine can execute a 'SELECT * FROM table' scan of 10,000 mock rows in memory in under 100ms, demonstrating minimal per-row overhead."
    ]
  },
  {
    "milestone_id": "build-sqlite-m4",
    "criteria": [
      "Buffer pool allocates a fixed memory region for a configurable number of frames (default 1000).",
      "Page size is strictly enforced at 4096 bytes (or a configurable constant).",
      "FetchPage returns a cached pointer if the PageID is already in the pool (Hit).",
      "FetchPage reads from the underlying file only when the PageID is not resident (Miss).",
      "LRU eviction policy successfully identifies and replaces the least recently used page.",
      "Pages with PinCount > 0 are strictly protected from eviction, even if they are the LRU candidate.",
      "Dirty pages are automatically written to disk (pwrite) before being reused for a different PageID.",
      "The manager provides a FlushAll() method that forces all dirty pages to disk without evicting them.",
      "The manager tracks 'hits' and 'misses' to calculate a real-time hit rate percentage.",
      "Unpin() must be called to decrement PinCount; failure to do so eventually prevents all evictions.",
      "Page-to-Frame mapping is implemented via an O(1) lookup structure (Hash Map).",
      "LRU updates (moving a page to the front) occur on every page access (FetchPage)."
    ]
  },
  {
    "milestone_id": "build-sqlite-m5",
    "criteria": [
      "Implement Varint encoding/decoding supporting 1-9 bytes for 64-bit integers.",
      "Define a 4096-byte Page Header including Page Type, Cell Count, and Cell Start offset.",
      "Implement the Slotted Page layout with a Cell Pointer Array growing down and Cell Content growing up.",
      "Write a Big-Endian serialization layer for all multi-byte header fields.",
      "Implement Table B-tree Leaf logic: store (RowID, Payload) pairs where Payload is the serialized row.",
      "Implement Table B-tree Internal logic: store (RowID, ChildPageID) as separator keys.",
      "Build a Node Split algorithm that creates a sibling page and promotes the median key to the parent.",
      "Implement a Root Split mechanism that increases the B-tree height by one.",
      "Create a System Catalog (sqlite_master) on Page 1 to store and retrieve root page numbers for tables.",
      "Implement a full B-tree scan (depth-first traversal) that returns all rows in RowID order.",
      "Verify that the total page size remains exactly 4096 bytes after multiple insertions and splits.",
      "Implement row serialization that handles NULL, INTEGER, REAL, and TEXT types into a binary record format."
    ]
  },
  {
    "milestone_id": "build-sqlite-m6",
    "criteria": [
      "The VM successfully executes 'SELECT * FROM table' by using a Cursor to iterate through all leaf pages and slots.",
      "The 'Column' opcode correctly deserializes variable-length records by parsing the Record Header (Serial Types).",
      "A 'SELECT col1, col2' projection correctly returns only the requested columns from the record buffer.",
      "The 'WHERE' clause correctly implements Three-Valued Logic, ensuring that 'NULL = NULL' and 'NULL = 5' both evaluate to 'Unknown' and result in a filtered row.",
      "The 'INSERT' operation handles RowID generation, correctly finding the next ID for INTEGER PRIMARY KEY columns if not provided.",
      "The 'UPDATE' operation correctly handles size increases by performing a Delete + Insert, triggering B-tree node splits if the page capacity is exceeded.",
      "The 'DELETE' operation avoids cursor corruption, specifically handling the case where a row removal affects the position of the current scanning cursor (e.g., via two-pass delete).",
      "The engine enforces 'NOT NULL' constraints during 'INSERT' and 'UPDATE', returning a specific error message and preventing the write if a null is provided for a restricted column.",
      "Attempting to query or modify a table not present in the System Catalog (sqlite_master) returns a clear 'undefined table' error.",
      "DML operations (INSERT/UPDATE/DELETE) correctly update the 'dirty' flag in the Buffer Pool, ensuring persistence on flush."
    ]
  },
  {
    "milestone_id": "build-sqlite-m7",
    "criteria": [
      "CREATE INDEX successfully creates a new B+tree root page and registers it in the system catalog.",
      "Index B+tree cells correctly use the (Value, RowID) tuple format for non-unique indexes.",
      "B+tree implementation includes leaf-level pointers to enable sequential range scanning without parent traversal.",
      "INSERT/UPDATE/DELETE operations in the VM automatically trigger corresponding operations in all associated index trees.",
      "The VM correctly implements the 'Double Lookup' pattern using IdxRowid and SeekRowid opcodes.",
      "UNIQUE index constraints are enforced during the Index B+tree insertion phase, returning a specific error on duplicates.",
      "NULL values are handled in the index sorting logic, typically as the smallest possible value.",
      "Query execution demonstrates O(log N) performance for equality lookups compared to O(N) for table scans.",
      "Index maintenance logic correctly handles the 'Update Paradox' by deleting the old index key and inserting the new one.",
      "The engine correctly identifies and executes 'Covering Index' queries by extracting data directly from the index cursor without a table seek."
    ]
  },
  {
    "milestone_id": "build-sqlite-m8",
    "criteria": [
      "Implement the ANALYZE command that performs a full scan of a table and its indexes to count total rows and distinct values.",
      "Create a system statistics table (e.g., 'sqlite_stat1') to persist table and index metadata across restarts.",
      "Implement a cost-estimation function that calculates a numerical score for a 'Full Table Scan' based on the number of pages in the table.",
      "Implement a cost-estimation function for 'Index Scans' that accounts for B-tree depth and a 'Random I/O penalty' multiplier (e.g., 4.0).",
      "The Planner must correctly choose a Full Table Scan over an Index Scan when the estimated selectivity is high (e.g., > 30% of rows).",
      "Implement 'Equality Selectivity' estimation: 1.0 / Cardinality (distinct values) for a column.",
      "Implement 'Range Selectivity' heuristics: default to 33% for single-sided ranges (>, <) if specific histogram data is unavailable.",
      "Extend the EXPLAIN command to output 'QUERY PLAN' information, showing whether a SCAN or SEARCH (index) was chosen.",
      "The join optimizer must evaluate at least two different join orders for a 2-table join and select the one with the lowest total cost.",
      "A test suite must verify that adding an index to a large table changes the execution plan from SCAN to SEARCH for highly selective queries."
    ]
  },
  {
    "milestone_id": "build-sqlite-m9",
    "criteria": [
      "BEGIN TRANSACTION command correctly transitions the Pager into a 'RECORDING' state.",
      "A .db-journal file is created immediately upon the first write operation of a transaction.",
      "Before any page is modified in the main database file, its original content is written to the journal file.",
      "The Pager executes a physical fsync() on the journal file before attempting to write to the .db file.",
      "The journal file header includes the original database size and a magic number for validation.",
      "COMMIT command triggers a physical fsync() of the .db file followed by the deletion or truncation of the journal.",
      "ROLLBACK command reads the journal file and restores the original pages to the .db file, then clears the journal.",
      "Startup recovery logic detects a non-empty journal and successfully restores the database to a consistent state (Atomic Recovery).",
      "Recovery logic correctly handles 'Torn Journal' scenarios by validating page checksums before applying them.",
      "The engine implements at least three levels of locking (SHARED, RESERVED, EXCLUSIVE) to prevent data corruption between concurrent processes.",
      "The database file is truncated to its original size during rollback if the failed transaction attempted to grow the file.",
      "Writes are invisible to other connections (Read Isolation) until the journal is deleted/truncated."
    ]
  },
  {
    "milestone_id": "build-sqlite-m10",
    "criteria": [
      "The engine creates a separate WAL file and appends modified pages to it during WRITE transactions, leaving the main .db file untouched until checkpointing.",
      "WAL frames are implemented with a binary header containing the PageID and a cumulative checksum for the entire log chain.",
      "A WAL-Index lookup mechanism is implemented that returns the frame index for the most recent committed version of a PageID.",
      "The Pager correctly implements the 'WAL-first' read policy: checking the WAL Index before falling back to the main database file.",
      "Snapshot Isolation is enforced by readers capturing the current WAL Commit Mark at the start of a transaction and ignoring any subsequent appends.",
      "The engine supports multiple concurrent readers and a single concurrent writer without deadlocking or blocking reads.",
      "A manual and automatic 'wal_checkpoint' mechanism is implemented that copies WAL frames back to the main file in PageID order.",
      "Checkpointing logic respects the 'Read Mark' barrier, never overwriting pages in the main file that are currently in use by active readers.",
      "Corruption detection is implemented via checksum verification on both individual WAL frames and the cumulative log integrity.",
      "PRAGMA journal_mode=WAL correctly toggles the engine behavior and initializes the WAL-Index upon the first write."
    ]
  },
  {
    "milestone_id": "build-sqlite-m11",
    "criteria": [
      "VDBE supports managing at least 16 independent cursors simultaneously for multi-table queries.",
      "COUNT(*) correctly counts all rows in the scan, including rows where all columns are NULL.",
      "COUNT(column) correctly ignores NULL values and only increments the accumulator for non-NULL entries.",
      "SUM and AVG handle the transition from NULL to Numeric correctly: a SUM over zero rows or only NULLs returns NULL, not 0.",
      "AVG aggregate function always returns a floating-point (REAL) result, even when calculating the average of INTEGER columns.",
      "MIN and MAX aggregates work across all supported data types (INTEGER, TEXT, REAL) using the engine's comparison logic.",
      "INNER JOIN implementation uses the Nested Loop Join (NLJ) algorithm, correctly resetting the inner cursor for every outer row.",
      "Join predicates (ON clause) are evaluated correctly within the inner loop, filtering out non-matching row combinations.",
      "GROUP BY logic correctly partitions aggregation state; if using sort-based grouping, it detects 'breaks' in the sorted column values.",
      "HAVING clause is executed as a post-aggregation filter, correctly accessing values in accumulator registers.",
      "Multiple aggregate functions (e.g., SELECT COUNT(*), SUM(a), AVG(b)) can be computed in a single pass over the data.",
      "Queries on an empty table return 0 for COUNT and NULL for SUM/AVG/MIN/MAX, following SQL standard behavior.",
      "WHERE clauses in a JOIN query are applied as early as possible (predicate pushdown) or correctly within the nested loop to minimize row processing."
    ]
  },
  {
    "module_id": "build-sqlite-m1",
    "criteria": [
      "Tokenizer recognizes SQL keywords case-insensitively",
      "String literals correctly handle escaped single quotes ('') and preserve internal content",
      "Numeric literals distinguish between integers (42) and floats (3.14)",
      "The tokenizer returns a list or stream of objects containing type, value, line, and column",
      "Lexical errors provide position information (line/column)"
    ]
  },
  {
    "module_id": "build-sqlite-m2",
    "criteria": [
      "Expression parser correctly handles operator precedence: NOT > comparison > AND > OR",
      "SELECT parser produces AST with column list including * wildcard support",
      "SELECT parser produces optional WHERE clause as Expression node",
      "CREATE TABLE parser extracts column definitions with names and data types (INTEGER, TEXT, REAL, BLOB)",
      "Parser provides error position (line and column) for syntax errors",
      "NULL keyword is parsed as LiteralExpression not IdentifierExpression"
    ]
  },
  {
    "module_id": "build-sqlite-m3",
    "criteria": [
      "Bytecode includes OpenRead, Rewind, Column, ResultRow, Next, Halt",
      "VM implements register-based storage for intermediate values",
      "Compiler handles backpatching for jump targets in loops",
      "WHERE clause translates to conditional jump opcodes",
      "EXPLAIN command displays human-readable opcode sequence",
      "VM executes fetch-decode-execute loop with < 10ns overhead per instruction"
    ]
  },
  {
    "module_id": "build-sqlite-m4",
    "criteria": [
      "Buffer pool must implement LRU eviction",
      "Dirty pages must be flushed to disk before eviction",
      "Pinned pages (pin_count > 0) must never be evicted",
      "Page access (fetch/unpin) must be O(1) in memory",
      "Disk I/O must use 4096-byte page boundaries"
    ]
  },
  {
    "module_id": "build-sqlite-m5",
    "criteria": [
      "Implement 1-9 byte Varint encoding/decoding supporting full 64-bit range.",
      "Design 4096-byte Slotted Page header with page type, cell count, and content start offsets.",
      "Implement Big-Endian serialization for all on-disk multi-byte integers.",
      "Develop a B-tree node split algorithm that promotes the median key to a parent node.",
      "Implement binary search within the cell pointer array for O(log N) row lookups per page.",
      "Ensure Table B-tree internal nodes store only separators and leaf nodes store full payloads.",
      "Maintain a 'content_start' pointer that tracks the bottom-up growth of the cell heap.",
      "Implement a 'freeblock' linked list within pages to reclaim space from deleted cells."
    ]
  },
  {
    "module_id": "build-sqlite-m6",
    "criteria": [
      "Cursor recognizes EOF across multiple B-tree pages",
      "RecordDeserializer correctly skips variable-length strings to reach subsequent columns",
      "OP_Column returns VAL_NULL for missing columns in a record",
      "Insert operation triggers RESERVED lock upgrade in Pager",
      "Two-pass delete prevents cursor invalidation errors"
    ]
  },
  {
    "module_id": "build-sqlite-m7",
    "criteria": [
      "Implement B+tree variant with horizontal leaf linking via next_leaf pointer.",
      "Index cells must contain the RowID as a tie-breaker to ensure key uniqueness.",
      "Implement synchronous index maintenance hooks for INSERT, UPDATE, and DELETE.",
      "UNIQUE constraint enforcement via O(log N) pre-insertion search.",
      "New VDBE opcodes: IdxGE (Greater-Equal Seek) and IdxRowid (RowID Extraction).",
      "Index comparison logic must handle NULLs and SQL Type Affinity correctly."
    ]
  },
  {
    "module_id": "build-sqlite-m8",
    "criteria": [
      "Implement ANALYZE command collecting table row count and index cardinality",
      "Design cost model weighing Random I/O vs Sequential I/O",
      "Implement selectivity estimation for equality and range predicates",
      "Integrate planner with Bytecode Compiler to select Index Scan vs Table Scan",
      "Support basic join order optimization based on table size",
      "Ensure EXPLAIN output reflects the chosen access path"
    ]
  },
  {
    "module_id": "build-sqlite-m9",
    "criteria": [
      "Journal file is created before any database modification",
      "fsync is called on the journal before the database is touched",
      "Hot journal is detected and processed on startup",
      "The database lock state transitions correctly through SHARED, RESERVED, PENDING, EXCLUSIVE",
      "The database file is truncated to its original size during rollback if pages were appended"
    ]
  },
  {
    "module_id": "build-sqlite-m10",
    "criteria": [
      "Recognizes WAL keywords and PRAGMA journal_mode=WAL",
      "Implements WALHeader and WALFrame binary serialization with cumulative checksums",
      "Manages a memory-mapped WAL Index for O(1) page searches",
      "Implements Snapshot Isolation via Read Marks in shared memory",
      "Executes Passive Checkpointing without blocking concurrent readers",
      "Detects and recovers from torn WAL writes using checksum validation"
    ]
  },
  {
    "module_id": "build-sqlite-m11",
    "criteria": [
      "Implement Aggregate Accumulator Logic for SUM, COUNT, MIN, MAX, AVG",
      "Implement Nested Loop Join (NLJ) as the primary relational join mechanism",
      "Design a Hash-based GROUP BY manager for streaming aggregation",
      "Ensure NULL values are handled per SQL standard in aggregates (ignored) and JOINS (Three-Valued Logic)",
      "Support multi-cursor synchronization within the VDBE fetch-decode-execute loop"
    ]
  }
]