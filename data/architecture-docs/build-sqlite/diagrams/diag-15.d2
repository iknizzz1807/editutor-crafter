vars: {
  d2-config: {
    layout-engine: elk
    theme-id: 200
  }
}

classes: {
  state: {
    shape: circle
    width: 80
    height: 80
    style: {
      fill: "#e0e0e0"
      stroke: "#333"
      stroke-width: 2
      font-size: 14
      shadow: true
    }
  }
  memory_cell: {
    shape: square
    width: 40
    height: 40
    style: {
      fill: "#f8f9fa"
      stroke: "#dee2e6"
      font-size: 18
      font: mono
    }
  }
  token_struct: {
    shape: class
    style: {
      stroke-width: 2
      fill: "#e8f4f8"
      border-radius: 5
    }
  }
  code_block: {
    shape: rectangle
    style: {
      font: mono
      fill: "#2d2d2d"
      font-color: "#f8f8f2"
      stroke-width: 0
      border-radius: 4
    }
  }
}

title: |md
  # SQL Lexer: The Tokenizer State Machine
  *Transforming raw bytes into meaningful tokens via FSM*
| {
  near: top-center
  link: "#anchor-lexer"
}

# -------------------------------------------------------------------------
# LAYER 1: RAW INPUT & CURSOR
# -------------------------------------------------------------------------
Input_Buffer: "Input Source (Heap)" {
  link: "#anchor-lexer"
  style: {
    fill: "#ffffff"
    stroke: "#333"
    stroke-dash: 3
  }
  
  # Representing: SELECT * FROM "db"
  c0: S {class: memory_cell; style.fill: "#dbeafe"}
  c1: E {class: memory_cell; style.fill: "#dbeafe"}
  c2: L {class: memory_cell; style.fill: "#dbeafe"}
  c3: E {class: memory_cell; style.fill: "#dbeafe"}
  c4: C {class: memory_cell; style.fill: "#dbeafe"}
  c5: T {class: memory_cell; style.fill: "#dbeafe"}
  c6: " " {class: memory_cell}
  c7: "*" {class: memory_cell}
  c8: " " {class: memory_cell}
  c9: F {class: memory_cell}
  c10: R {class: memory_cell}
  
  c0 -> c1 -> c2 -> c3 -> c4 -> c5 -> c6 -> c7 -> c8 -> c9 -> c10: {
    style: {
      stroke: transparent
    }
  }
}

Lexer_Struct: "struct Lexer" {
  link: "#anchor-lexer"
  shape: class
  
  source: "char* (0x4000)"
  cursor: "int (6)"
  length: "int (512)"
  
  # Visual pointer to current char
  cursor_ptr: "Current Char" {
    shape: step
    style.fill: "#ff7675"
  }
}

Lexer_Struct.cursor_ptr -> Input_Buffer.c6: "reads ' ' (space)" {
  style: {
    stroke: "#ff7675"
    stroke-width: 2
    animated: true
  }
}

# -------------------------------------------------------------------------
# LAYER 2: THE DISPATCHER (JUMP TABLE)
# -------------------------------------------------------------------------
Dispatcher: "Jump Table / Switch" {
  link: "#anchor-lexer"
  shape: diamond
  label: "char c = source[cursor]"
  style: {
    fill: "#ffeaa7"
    stroke: "#fdcb6e"
    stroke-width: 3
  }
}

Input_Buffer -> Dispatcher: "fetch char"

# -------------------------------------------------------------------------
# LAYER 3: STATE HANDLERS
# -------------------------------------------------------------------------
Handlers: {
  link: "#anchor-lexer"
  style.fill: transparent
  style.stroke-width: 0

  State_Whitespace: "SKIP_WS" {
    class: state
    style.fill: "#dfe6e9"
    tooltip: "cursor++ until non-space"
  }

  State_Identifier: "READ_ID" {
    class: state
    style.fill: "#a29bfe"
    label: "ID / KW"
  }

  State_String: "READ_STR" {
    class: state
    style.fill: "#81ecec"
  }

  State_Number: "READ_NUM" {
    class: state
    style.fill: "#fab1a0"
  }

  State_Symbol: "READ_SYM" {
    class: state
    style.fill: "#fd79a8"
  }
}

# Dispatch Logic
Dispatcher -> Handlers.State_Whitespace: "' ', '\\t', '\\n'"
Dispatcher -> Handlers.State_Identifier: "[a-z], [A-Z], _"
Dispatcher -> Handlers.State_String: "' (single quote)"
Dispatcher -> Handlers.State_Number: "[0-9]"
Dispatcher -> Handlers.State_Symbol: "*, =, ;, ("

# Transitions (Loops)
Handlers.State_Whitespace -> Dispatcher: "next char"
Handlers.State_Identifier -> Handlers.State_Identifier: "while is_alnum(c)"
Handlers.State_String -> Handlers.State_String: "until closing quote"
Handlers.State_Number -> Handlers.State_Number: "while is_digit(c)"

# -------------------------------------------------------------------------
# LAYER 4: TOKEN EMISSION
# -------------------------------------------------------------------------
Token_Stream: "Token Output Stream" {
  link: "#anchor-lexer"
  style: {
    fill: "#f0f0f0"
    stroke: "#333"
    stroke-width: 1
  }
  
  T1: {
    class: token_struct
    type: "TOKEN_KEYWORD (SELECT)"
    start: "ptr to c0"
    length: "6"
  }
  
  T2: {
    class: token_struct
    type: "TOKEN_SYMBOL (*)"
    start: "ptr to c7"
    length: "1"
    style.opacity: 0.5
  }
  
  T1 -> T2: "next"
}

# -------------------------------------------------------------------------
# CONNECTIONS & LOGIC
# -------------------------------------------------------------------------
Handlers.State_Identifier -> Token_Stream.T1: "1. check_keyword()\n2. emit token" {
  style: {
    stroke: "#a29bfe"
    stroke-width: 2
  }
}

Handlers.State_Symbol -> Token_Stream.T2: "emit symbol"

# Code annotation for the Keyword Check
Code_Check: |c
  // Keyword Check Logic
  if (len == 6 && 
      strncmp(start, "SELECT", 6) == 0) {
      return TOKEN_KEYWORD;
  }
  return TOKEN_IDENTIFIER;
| {
  class: code_block
}

# Connect Code_Check to the relevant state for context, avoiding 'near' with object
Handlers.State_Identifier -- Code_Check: "implements" {
  style: {
    stroke-dash: 3
    opacity: 0.5
  }
}

# Explanation of Zero-Copy
Zero_Copy_Note: |md
  **Zero-Copy Architecture**
  Tokens do not copy string data.
  They point back to the original source.
| {
  shape: rectangle
  style.fill: "#fff3cd"
}

Token_Stream -- Zero_Copy_Note {
  style: {
    stroke: transparent
  }
}

Token_Stream.T1 -> Input_Buffer.c0: "points to" {
  style: {
    stroke: "#fab1a0"
    stroke-dash: 3
  }
}

# -------------------------------------------------------------------------
# SYSTEM INTEGRATION
# -------------------------------------------------------------------------
Parser: "The Parser (Consumer)" {
  link: "#ms-parser"
  shape: package
  style.fill: "#55efc4"
}

Token_Stream -> Parser: "consumed by"