{
  "title": "Cache-Optimized Data Structures: Design Document",
  "overview": "This project builds a suite of data structures optimized for modern CPU cache hierarchies. It tackles the key architectural challenge of mitigating the immense performance penalty of cache misses by designing memory layouts and access patterns that maximize spatial and temporal locality, leading to significant speedups for memory-bound workloads.",
  "sections": [
    {
      "id": "context",
      "title": "1. Context and Problem Statement",
      "summary": "Explains the 'memory wall' problem, introduces CPU cache hierarchy, and contrasts naive versus cache-aware data structures.",
      "subsections": [
        {
          "id": "analogy-library",
          "title": "The Library Analogy for CPU Cache",
          "summary": "Uses a library/bookshelf analogy to make cache hierarchy, latency, and cache lines intuitive."
        },
        {
          "id": "problem-statement",
          "title": "The Memory Wall Problem",
          "summary": "Defines the core problem: main memory access is 100-300x slower than L1 cache, making memory layout critical for performance."
        },
        {
          "id": "existing-approaches",
          "title": "Existing Approaches Comparison",
          "summary": "Compares classic pointer-heavy data structures (linked lists, BSTs) with cache-conscious alternatives (arrays, B-Trees) in a table."
        }
      ]
    },
    {
      "id": "goals",
      "title": "2. Goals and Non-Goals",
      "summary": "Defines the functional and performance objectives for the project, as well as explicit out-of-scope items.",
      "subsections": [
        {
          "id": "goals-list",
          "title": "Goals",
          "summary": "List of what the system must achieve, including performance benchmarks, educational clarity, and milestone completion."
        },
        {
          "id": "non-goals",
          "title": "Non-Goals",
          "summary": "List of what the system will not do, such as being production-ready, thread-safe, or supporting dynamic schemas."
        }
      ]
    },
    {
      "id": "architecture",
      "title": "3. High-Level Architecture",
      "summary": "Provides a component overview of the benchmarking suite and data structure implementations, showing how they connect.",
      "subsections": [
        {
          "id": "component-overview",
          "title": "System Component Overview",
          "summary": "Describes the three main layers: Benchmarking Infrastructure, Core Data Structures, and Analysis/Visualization tools."
        },
        {
          "id": "file-structure",
          "title": "Recommended File/Module Structure",
          "summary": "Suggests a directory and file layout for organizing the C codebase across milestones."
        }
      ]
    },
    {
      "id": "data-model",
      "title": "4. Data Model",
      "summary": "Describes the key data types and structures used across all milestones, from benchmark results to particle systems and hash table entries.",
      "subsections": [
        {
          "id": "benchmark-types",
          "title": "Benchmark and Measurement Types",
          "summary": "Tables defining structures for cache latency measurements, performance counter results, and timing statistics."
        },
        {
          "id": "data-struct-types",
          "title": "Data Structure Core Types",
          "summary": "Tables defining the Particle (AoS/SoA), HashTableEntry, and vEB Tree Node structures."
        }
      ]
    },
    {
      "id": "component-benchmarking",
      "title": "5. Component Design: Benchmarking Infrastructure (Milestone 1)",
      "summary": "Details the design of tools to measure cache characteristics and profile data structure performance.",
      "subsections": [
        {
          "id": "benchmark-mental-model",
          "title": "Mental Model: The Cache Detective",
          "summary": "Analogy of a detective measuring room access times to deduce room (cache) sizes and layout."
        },
        {
          "id": "cache-size-detector",
          "title": "Cache Size Detector",
          "summary": "Design and algorithm for measuring access latency to detect L1, L2, L3 cache sizes."
        },
        {
          "id": "performance-counter-reader",
          "title": "Performance Counter Reader",
          "summary": "Design for interfacing with hardware performance monitoring units (PMUs) to count cache misses."
        },
        {
          "id": "benchmark-harness",
          "title": "Benchmark Harness",
          "summary": "Design of a reusable framework for timing different access patterns and data structures."
        },
        {
          "id": "adr-benchmark-method",
          "title": "ADR: Benchmark Measurement Method",
          "summary": "Decision record for using hardware performance counters over manual timing for miss ratios."
        },
        {
          "id": "pitfalls-benchmarking",
          "title": "Common Pitfalls in Benchmarking",
          "summary": "Covers compiler optimization, warmup effects, system noise, and alignment issues."
        },
        {
          "id": "impl-benchmarking",
          "title": "Implementation Guidance",
          "summary": "Starter code for reading performance counters (Linux `perf_event_open`), skeleton for cache detector, and milestone 1 checkpoint."
        }
      ]
    },
    {
      "id": "component-aos-soa",
      "title": "6. Component Design: AoS vs SoA Layouts (Milestone 2)",
      "summary": "Designs and compares Array of Structs and Struct of Arrays memory layouts using a particle system case study.",
      "subsections": [
        {
          "id": "aos-soa-mental-model",
          "title": "Mental Model: Packing for a Trip",
          "summary": "Analogy of packing clothes in a suitcase (AoS) vs packing by item type in separate bags (SoA)."
        },
        {
          "id": "aos-implementation",
          "title": "AoS Implementation Design",
          "summary": "Design for a contiguous array of Particle structs, detailing memory layout and access patterns."
        },
        {
          "id": "soa-implementation",
          "title": "SoA Implementation Design",
          "summary": "Design for separate, aligned arrays for each particle field (x[], y[], vx[], etc.)."
        },
        {
          "id": "adr-layout-choice",
          "title": "ADR: Choosing Layout Based on Access Pattern",
          "summary": "Decision record for selecting AoS for random access to all fields vs SoA for sequential, field-wise operations."
        },
        {
          "id": "pitfalls-aos-soa",
          "title": "Common Pitfalls in AoS/SoA",
          "summary": "Covers lack of alignment, ignoring remainder in SIMD loops, and premature optimization."
        },
        {
          "id": "impl-aos-soa",
          "title": "Implementation Guidance",
          "summary": "Starter code for aligned memory allocation, skeleton for SoA update function with SIMD hints, and milestone 2 checkpoint."
        }
      ]
    },
    {
      "id": "component-hashtable",
      "title": "7. Component Design: Cache-Friendly Hash Table (Milestone 3)",
      "summary": "Designs an open-addressing hash table with linear probing and Robin Hood hashing for cache locality.",
      "subsections": [
        {
          "id": "hashtable-mental-model",
          "title": "Mental Model: Finding a Parking Spot",
          "summary": "Analogy of linear probing for an open parking spot in a contiguous lot, and Robin Hood as taking from the rich (long probes) to give to the poor."
        },
        {
          "id": "open-addressing-layout",
          "title": "Open Addressing and Memory Layout",
          "summary": "Design for storing keys and values in separate, cache-line-aligned arrays to optimize probe sequences."
        },
        {
          "id": "robin-hood-hashing",
          "title": "Robin Hood Hashing Algorithm",
          "summary": "Algorithm steps for insertion and lookup with probe distance swapping to reduce variance."
        },
        {
          "id": "software-prefetching",
          "title": "Software Prefetching Strategy",
          "summary": "Design for prefetching potential next cache lines during probe sequence."
        },
        {
          "id": "adr-probing-strategy",
          "title": "ADR: Linear Probing vs Quadratic Probing",
          "summary": "Decision record for choosing linear probing for superior cache locality despite clustering."
        },
        {
          "id": "pitfalls-hashtable",
          "title": "Common Pitfalls in Cache-Friendly Hash Tables",
          "summary": "Covers high load factor, poor hash function, tombstone accumulation, and resize overhead."
        },
        {
          "id": "impl-hashtable",
          "title": "Implementation Guidance",
          "summary": "Starter code for hash functions (FNV-1a), skeleton for Robin Hood insertion, and milestone 3 checkpoint."
        }
      ]
    },
    {
      "id": "component-veb-tree",
      "title": "8. Component Design: Cache-Oblivious B-Tree (Milestone 4)",
      "summary": "Designs a static search tree using the van Emde Boas (vEB) memory layout to achieve cache efficiency without tuning.",
      "subsections": [
        {
          "id": "veb-mental-model",
          "title": "Mental Model: Recursive Book Organization",
          "summary": "Analogy of organizing a book collection recursively by splitting shelves into smaller, contiguous sub-shelves."
        },
        {
          "id": "veb-layout-algorithm",
          "title": "Van Emde Boas Layout Algorithm",
          "summary": "Algorithm steps for recursively reordering a sorted array into the vEB pattern for a given tree height."
        },
        {
          "id": "veb-search-algorithm",
          "title": "Search in vEB Layout",
          "summary": "Algorithm steps for performing binary search on the vEB-ordered array, calculating child node indices."
        },
        {
          "id": "adr-static-vs-dynamic",
          "title": "ADR: Static vEB Layout vs Dynamic Pointer-Based Tree",
          "summary": "Decision record for implementing a static, array-based vEB tree over a dynamic node-based one for simplicity and layout control."
        },
        {
          "id": "pitfalls-veb-tree",
          "title": "Common Pitfalls in vEB Trees",
          "summary": "Covers incorrect index calculation for non-power-of-2 sizes, overhead for small trees, and confusion over recursion base case."
        },
        {
          "id": "impl-veb-tree",
          "title": "Implementation Guidance",
          "summary": "Helper code for calculating subtree sizes, skeleton for vEB search function, and milestone 4 checkpoint."
        }
      ]
    },
    {
      "id": "component-matrix-blocking",
      "title": "9. Component Design: Blocked Matrix Operations (Milestone 5)",
      "summary": "Designs cache-blocked (tiled) algorithms for matrix multiplication and transpose to exploit temporal locality.",
      "subsections": [
        {
          "id": "blocking-mental-model",
          "title": "Mental Model: Tiled Kitchen Workflow",
          "summary": "Analogy of cooking multiple dishes by working on one tile (cutting board) at a time, reusing ingredients from nearby."
        },
        {
          "id": "blocked-mult-algorithm",
          "title": "Blocked Matrix Multiplication Algorithm",
          "summary": "Algorithm steps for triple-nested loops over blocks, with sub-matrix multiplication in the innermost kernel."
        },
        {
          "id": "block-size-autotuner",
          "title": "Block Size Auto-Tuner Design",
          "summary": "Design for an empirical tuner that tests a range of block sizes and selects the one with minimal runtime."
        },
        {
          "id": "adr-auto-tune-vs-fixed",
          "title": "ADR: Empirical Auto-Tuning vs Fixed Block Size",
          "summary": "Decision record for implementing a simple auto-tuner to adapt to different hardware cache sizes."
        },
        {
          "id": "pitfalls-matrix-blocking",
          "title": "Common Pitfalls in Matrix Blocking",
          "summary": "Covers block size too large for cache, not handling matrix dimensions not multiples of block size, and pointer chasing in naive transpose."
        },
        {
          "id": "impl-matrix-blocking",
          "title": "Implementation Guidance",
          "summary": "Starter code for matrix allocation/initialization, skeleton for blocked multiplication, and milestone 5 checkpoint."
        }
      ]
    },
    {
      "id": "interactions",
      "title": "10. Interactions and Data Flow",
      "summary": "Describes how the components work together, focusing on the benchmarking flow and data structure usage patterns.",
      "subsections": [
        {
          "id": "benchmark-flow",
          "title": "Benchmark Execution Flow",
          "summary": "Sequence of operations from cache detection, to running a specific data structure benchmark, to collecting and reporting results."
        },
        {
          "id": "data-structure-usage",
          "title": "Data Structure Usage Patterns",
          "summary": "Typical sequences of operations for each data structure (e.g., build, query, update) and their cache implications."
        }
      ]
    },
    {
      "id": "error-handling",
      "title": "11. Error Handling and Edge Cases",
      "summary": "Covers failure modes like out-of-memory, invalid inputs, and edge cases specific to each data structure and benchmark.",
      "subsections": [
        {
          "id": "failure-modes",
          "title": "Common Failure Modes and Recovery",
          "summary": "Table of potential errors (allocation failure, invalid size, hash table full) and suggested handling strategies (return codes, graceful exit)."
        },
        {
          "id": "edge-cases",
          "title": "Data Structure Specific Edge Cases",
          "summary": "Covers empty structures, single-element operations, power-of-two boundaries for vEB tree, and load factor extremes for hash tables."
        }
      ]
    },
    {
      "id": "testing",
      "title": "12. Testing Strategy",
      "summary": "Outlines approaches to verify correctness and performance, including property-based tests and milestone verification checkpoints.",
      "subsections": [
        {
          "id": "correctness-testing",
          "title": "Correctness Testing",
          "summary": "Strategies for unit tests, comparison against reference implementations (e.g., standard library sorts/maps), and property-based testing (e.g., insert/find all)."
        },
        {
          "id": "performance-validation",
          "title": "Performance Validation",
          "summary": "How to verify the performance claims, such as checking speedup factors and cache miss reductions."
        },
        {
          "id": "milestone-checkpoints",
          "title": "Milestone Checkpoints",
          "summary": "For each milestone (1-5), lists expected observable outcomes and commands to run for verification."
        }
      ]
    },
    {
      "id": "debugging",
      "title": "13. Debugging Guide",
      "summary": "Provides a symptom-cause-fix table for common bugs, and recommends tools and techniques for inspecting cache behavior.",
      "subsections": [
        {
          "id": "common-bugs-table",
          "title": "Symptom \u2192 Cause \u2192 Fix Table",
          "summary": "Table addressing issues like segmentation faults (out-of-bounds access), incorrect results (off-by-one in layout), and performance worse than expected (cache line false sharing)."
        },
        {
          "id": "debugging-tools",
          "title": "Tools and Techniques",
          "summary": "Recommendations for using `perf`, `valgrind/cachegrind`, debuggers, and simple print/logging to trace execution and memory access."
        }
      ]
    },
    {
      "id": "future-extensions",
      "title": "14. Future Extensions",
      "summary": "Suggests potential advanced features and research directions to explore after completing the core milestones.",
      "subsections": [
        {
          "id": "extensions-list",
          "title": "Possible Extensions",
          "summary": "Ideas such as concurrent cache-friendly structures, adaptive layouts, GPU cache considerations, and more advanced cache-oblivious algorithms (sorting)."
        }
      ]
    },
    {
      "id": "glossary",
      "title": "15. Glossary",
      "summary": "Definitions of key technical terms, acronyms, and domain-specific vocabulary used throughout the document.",
      "subsections": [
        {
          "id": "terms-table",
          "title": "Glossary Terms",
          "summary": "Table of terms like Cache Line, Temporal Locality, AoS/SoA, Open Addressing, vEB Layout, Loop Tiling, etc., with definitions and reference sections."
        }
      ]
    }
  ],
  "diagrams": [
    {
      "id": "sys-comp",
      "title": "System Component Diagram",
      "description": "Shows the three main layers: Benchmarking Infrastructure (Cache Detector, Perf Counter Reader, Harness), Core Data Structures (AoS/SoA, Hash Table, vEB Tree, Blocked Matrix), and Analysis Tools (Reporter, Visualizer). Arrows show data flow from benchmarks to analysis.",
      "type": "component",
      "relevant_sections": [
        "architecture"
      ]
    },
    {
      "id": "data-model-rel",
      "title": "Data Model Relationships",
      "description": "Class diagram showing relationships between key data structures: BenchmarkResult contains many RunMetrics; ParticleSystem has either an AoS array or multiple SoA arrays; HashTable contains arrays of keys and values; vEBTree is stored as a single array.",
      "type": "class",
      "relevant_sections": [
        "data-model"
      ]
    },
    {
      "id": "seq-benchmark",
      "title": "Benchmark Execution Sequence",
      "description": "Sequence diagram showing Actor: User, Benchmark Harness, Cache Detector, Data Structure under test, and Performance Counter Reader. Steps: Harness calls Detector, initializes DS, starts counters, runs operations, stops counters, collects results.",
      "type": "sequence",
      "relevant_sections": [
        "interactions",
        "component-benchmarking"
      ]
    },
    {
      "id": "flow-veb-search",
      "title": "vEB Tree Search Flowchart",
      "description": "Flowchart for searching in a vEB layout. Start at root index. Check if at leaf. If not, calculate size of left subtree, compare key to split value, recursively search in the appropriate child subtree (calculating its new root index in the array).",
      "type": "flowchart",
      "relevant_sections": [
        "component-veb-tree"
      ]
    },
    {
      "id": "state-hash-probe",
      "title": "Hash Table Probe State Machine",
      "description": "State machine for a single hash table slot during a probe sequence. States: EMPTY, OCCUPIED, TOMBSTONE. Transitions on events: Insert (EMPTY/TOMBSTONE->OCCUPIED), Delete (OCCUPIED->TOMBSTONE), Lookup (check key match in OCCUPIED).",
      "type": "state-machine",
      "relevant_sections": [
        "component-hashtable"
      ]
    },
    {
      "id": "mem-layout-aos-soa",
      "title": "AoS vs SoA Memory Layout",
      "description": "Visual comparison of memory addresses. AoS shows sequential blocks each containing [x,y,z,vx,vy,vz]. SoA shows six long contiguous arrays: all x values, then all y values, etc. Highlight cache lines spanning across elements.",
      "type": "component",
      "relevant_sections": [
        "component-aos-soa"
      ]
    },
    {
      "id": "flow-blocked-mult",
      "title": "Blocked Matrix Multiplication Loop Flow",
      "description": "Flowchart of the triple-blocked loop: For i_block in rows, for j_block in columns, for k_block in depth. Inside the innermost block, perform a small naive multiplication on submatrices A_block and B_block to update C_block.",
      "type": "flowchart",
      "relevant_sections": [
        "component-matrix-blocking"
      ]
    }
  ]
}