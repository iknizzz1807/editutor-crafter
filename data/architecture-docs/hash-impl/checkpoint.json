{
  "project_id": "hash-impl",
  "meta": {
    "id": "hash-impl",
    "name": "SHA-256 Hash Function",
    "description": "Implement SHA-256 from the NIST FIPS 180-4 specification, covering message preprocessing, message schedule generation, compression function, and final hash output with test vector validation.",
    "difficulty": "beginner",
    "estimated_hours": "10-15",
    "essence": "Merkle-Damg\u00e5rd construction using iterative compression with bitwise logical functions (Ch, Maj, \u03a3, \u03c3), modular 32-bit addition, and message scheduling to produce collision-resistant 256-bit digests from arbitrary input through 64 rounds of compression per 512-bit block.",
    "why_important": "Building SHA-256 from scratch teaches low-level bit manipulation, cryptographic algorithm implementation, and how to translate formal mathematical specifications (NIST FIPS 180-4) into working code \u2014 essential skills for security engineering and systems programming.",
    "learning_outcomes": [
      "Implement message padding with length encoding to create 512-bit aligned blocks",
      "Design message schedule generation using bitwise rotation and XOR operations",
      "Build compression function with Ch, Maj, \u03a30, \u03a31, \u03c30, and \u03c31 logical functions",
      "Apply modular 32-bit arithmetic with proper overflow masking",
      "Translate NIST FIPS specification pseudocode into executable code",
      "Debug bit-level operations using intermediate value validation against spec examples",
      "Handle endianness conversion for cross-platform correctness",
      "Verify cryptographic correctness against standard NIST test vectors"
    ],
    "skills": [
      "Bitwise Operations",
      "Cryptographic Algorithms",
      "Specification Implementation",
      "Modular Arithmetic",
      "Binary Data Handling",
      "Algorithm Verification",
      "Test-Driven Development"
    ],
    "tags": [
      "beginner-friendly",
      "c",
      "cryptography",
      "hashing",
      "implementation",
      "javascript",
      "python",
      "sha-256"
    ],
    "architecture_doc": "architecture-docs/hash-impl/index.md",
    "languages": {
      "recommended": [
        "Python",
        "JavaScript",
        "C"
      ],
      "also_possible": [
        "Rust",
        "Go",
        "Java"
      ]
    },
    "resources": [
      {
        "name": "SHA-256 Step by Step\"\"",
        "url": "https://blog.boot.dev/cryptography/how-sha-2-works-step-by-step-sha-256/",
        "type": "tutorial"
      },
      {
        "name": "NIST FIPS 180-4 (SHA-256 Specification)\"\"",
        "url": "https://csrc.nist.gov/publications/detail/fips/180/4/final",
        "type": "specification"
      },
      {
        "name": "NIST SHA-256 Test Vectors\"\"",
        "url": "https://csrc.nist.gov/CSRC/media/Projects/Cryptographic-Standards-and-Guidelines/documents/examples/SHA256.pdf",
        "type": "reference"
      }
    ],
    "prerequisites": [
      {
        "type": "skill",
        "name": "Binary and hexadecimal representation"
      },
      {
        "type": "skill",
        "name": "Bitwise operations (AND, OR, XOR, shift, rotate)"
      },
      {
        "type": "skill",
        "name": "Basic understanding of hash functions"
      }
    ],
    "milestones": [
      {
        "id": "hash-impl-m1",
        "name": "Message Preprocessing and Padding",
        "description": "Implement SHA-256 message padding: append the '1' bit, pad with zeros to 448 mod 512 bits, append the 64-bit big-endian message length, and parse into 512-bit blocks.",
        "acceptance_criteria": [
          "Message is converted to its byte/bit representation, a single '1' bit is appended, followed by enough '0' bits so that the total message length is congruent to 448 mod 512 bits, and finally the original message length in bits is appended as a 64-bit big-endian integer, producing a message whose total length is a multiple of 512 bits.",
          "When the original message length mod 512 is greater than 447 bits (i.e., fewer than 65 bits remain for padding + length), an additional 512-bit block is correctly appended to accommodate the padding and length field.",
          "Padded message is parsed into an array of 512-bit (64-byte) blocks for sequential processing.",
          "Empty input (0 bytes) produces exactly one 512-bit padded block with the '1' bit at position 0, zeros through bit 447, and a 64-bit zero length field.",
          "Test: the string \"abc\" (24 bits) produces one 512-bit block; a 55-byte message produces one block; a 56-byte message produces two blocks (boundary case)."
        ],
        "pitfalls": [
          "Off-by-one in padding length calculation: the padding must account for the '1' bit AND the 64-bit length field. The number of zero padding bits is (447 - message_bit_length) mod 512, not (448 - message_bit_length) mod 512, because the '1' bit is separate.",
          "Endianness: SHA-256 uses big-endian byte ordering throughout. On little-endian systems (x86), bytes must be swapped when reading words from the padded message.",
          "Forgetting the extra block: when the message is 56-64 bytes, there isn't enough room in the first block for padding + length, requiring a second block. This is the most common beginner bug."
        ],
        "concepts": [
          "SHA-256 message padding rules",
          "Bit/byte boundary handling",
          "Big-endian byte ordering",
          "Block boundary edge cases"
        ],
        "skills": [
          "Binary data manipulation",
          "Bitwise operations",
          "Padding algorithms",
          "Byte-order conversion"
        ],
        "deliverables": [
          "Padding function appending '1' bit, zero-fill, and 64-bit length",
          "Block parser splitting padded message into 512-bit chunks",
          "Edge case handling for messages requiring an extra padding block",
          "Test cases for empty, short, and boundary-length inputs"
        ],
        "estimated_hours": "2-3"
      },
      {
        "id": "hash-impl-m2",
        "name": "Message Schedule Generation",
        "description": "For each 512-bit block, generate the 64-word message schedule using the SHA-256 recurrence relation with \u03c30 and \u03c31 functions.",
        "acceptance_criteria": [
          "512-bit block is parsed into 16 initial 32-bit words (W[0]..W[15]) in big-endian order.",
          "Words W[16]..W[63] are computed using the recurrence: W[t] = \u03c31(W[t-2]) + W[t-7] + \u03c30(W[t-15]) + W[t-16], all mod 2^32.",
          "\u03c30(x) = ROTR(x,7) XOR ROTR(x,18) XOR SHR(x,3) produces correct values verified against NIST example computation.",
          "\u03c31(x) = ROTR(x,17) XOR ROTR(x,19) XOR SHR(x,10) produces correct values verified against NIST example computation.",
          "All 64 words are stored as 32-bit unsigned integers. In languages with arbitrary-precision integers (Python, JavaScript), every addition is masked with & 0xFFFFFFFF."
        ],
        "pitfalls": [
          "In Python/JavaScript: forgetting to mask to 32 bits (& 0xFFFFFFFF) after EVERY addition. This is the #1 mistake because the intermediate values look plausible but diverge from the spec after several rounds.",
          "Confusing right-rotate (ROTR) with right-shift (SHR). ROTR wraps bits around; SHR fills with zeros. \u03c3 functions use BOTH, and mixing them up produces wrong schedule values.",
          "Wrong \u03c3 function rotation/shift constants: \u03c30 uses (7,18,3) and \u03c31 uses (17,19,10). Swapping these produces a valid-looking but completely wrong hash."
        ],
        "concepts": [
          "Right-rotate vs. right-shift operations",
          "XOR combination of rotated/shifted values",
          "Message schedule expansion",
          "32-bit modular arithmetic"
        ],
        "skills": [
          "Bitwise rotation and shifting",
          "Logical operations (XOR, AND, OR)",
          "32-bit modular arithmetic",
          "Array manipulation"
        ],
        "deliverables": [
          "Word extraction parsing 512-bit block into 16 big-endian 32-bit words",
          "\u03c30 and \u03c31 functions with correct rotate and shift constants",
          "Message schedule expansion from 16 to 64 words",
          "32-bit overflow masking for languages without native 32-bit unsigned"
        ],
        "estimated_hours": "2-3"
      },
      {
        "id": "hash-impl-m3",
        "name": "Compression Function",
        "description": "Implement the SHA-256 compression function: 64 rounds of state transformation using Ch, Maj, \u03a30, \u03a31, round constants K, and message schedule words.",
        "acceptance_criteria": [
          "Working variables (a through h) are initialized from the current hash values (H0..H7) at the start of each block's compression.",
          "64 rounds of compression execute, each computing: T1 = h + \u03a31(e) + Ch(e,f,g) + K[t] + W[t] T2 = \u03a30(a) + Maj(a,b,c) then shifting variables: h=g, g=f, f=e, e=d+T1, d=c, c=b, b=a, a=T1+T2, all mod 2^32.",
          "Ch(x,y,z) = (x AND y) XOR (NOT x AND z) produces correct values.",
          "Maj(x,y,z) = (x AND y) XOR (x AND z) XOR (y AND z) produces correct values.",
          "\u03a30(a) = ROTR(a,2) XOR ROTR(a,13) XOR ROTR(a,22) and \u03a31(e) = ROTR(e,6) XOR ROTR(e,11) XOR ROTR(e,25) produce correct values.",
          "All 64 round constants K[0]..K[63] are the first 32 bits of the fractional parts of the cube roots of the first 64 primes, matching the values in FIPS 180-4 Section 4.2.2.",
          "After all 64 rounds, the hash values are updated: H0 += a, H1 += b, ..., H7 += h (all mod 2^32).",
          "Intermediate hash values after processing the \"abc\" test vector's first block match the NIST example computation appendix values."
        ],
        "pitfalls": [
          "Mixing up \u03a3 (upper-case sigma, used in compression) with \u03c3 (lower-case sigma, used in message schedule). They use different rotation constants.",
          "Wrong K constant values: copying from an incorrect source or truncating to wrong precision. Always verify against FIPS 180-4 Table of K constants.",
          "Not masking intermediate T1 and T2 values to 32 bits in arbitrary-precision languages, causing divergence in later rounds.",
          "Variable rotation error: forgetting that 'e = d + T1' (not 'd + T1 + T2') and 'a = T1 + T2'."
        ],
        "concepts": [
          "Compression function rounds",
          "Choice (Ch) and Majority (Maj) functions",
          "Hash state transformation",
          "Round constants from prime cube roots"
        ],
        "skills": [
          "Cryptographic round functions",
          "State transformation chains",
          "Working with lookup tables",
          "Modular addition with masking"
        ],
        "deliverables": [
          "Ch, Maj, \u03a30, and \u03a31 bitwise functions",
          "64-element K constants array from FIPS 180-4",
          "64-round compression loop with variable rotation",
          "Hash state update after block compression",
          "Intermediate value validation against NIST example"
        ],
        "estimated_hours": "4-5"
      },
      {
        "id": "hash-impl-m4",
        "name": "Final Hash Output and Validation",
        "description": "Process all blocks sequentially, produce the final 256-bit hash, format as hexadecimal, and validate against NIST test vectors.",
        "acceptance_criteria": [
          "Hash state (H0..H7) is initialized to the SHA-256 initial hash values from FIPS 180-4 Section 5.3.3 before processing any blocks.",
          "All message blocks are processed sequentially, each updating the hash state through the compression function.",
          "Final hash is the concatenation of H0..H7 as 32-bit big-endian values, producing a 256-bit (32-byte) digest.",
          "Output is formatted as a 64-character lowercase hexadecimal string.",
          "SHA-256(\"\") = e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
          "SHA-256(\"abc\") = ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad",
          "SHA-256(\"abcdbcdecdefdefgefghfghighijhijkijkljklmklmnlmnomnopnopq\") = 248d6a61d20638b8e5c026930c3e6039a33ce45964ff2167f6ecedd419db06c1",
          "Function handles multiple independent invocations correctly: hash state is fully reset between calls, producing identical output for identical input.",
          "Streaming/chunked API: input can be fed in arbitrary-sized chunks (update/finalize pattern), producing the same hash as single-call processing."
        ],
        "pitfalls": [
          "Not resetting hash state between calls: if H0..H7 retain values from a previous hash computation, subsequent hashes are wrong.",
          "Endianness in output: H0..H7 must be written as big-endian bytes in the final concatenation, even on little-endian platforms.",
          "Streaming API: the update function must buffer partial blocks internally and only process complete 512-bit blocks. The finalize function must pad the remaining buffer. Getting the buffer management wrong is a common source of off-by-one errors."
        ],
        "concepts": [
          "Hash finalization",
          "Test vector validation",
          "Hexadecimal encoding",
          "Streaming hash API design"
        ],
        "skills": [
          "Hash output formatting",
          "Hexadecimal encoding",
          "State management and reset",
          "Test-driven validation"
        ],
        "deliverables": [
          "Initial hash value constants from FIPS 180-4",
          "Sequential block processing loop",
          "64-character hexadecimal output formatter",
          "Streaming API with update() and finalize() methods",
          "Test vector validation against all three NIST examples above"
        ],
        "estimated_hours": "2-4"
      }
    ],
    "domain": "security"
  },
  "blueprint": {
    "title": "SHA-256 Hash Function",
    "overview": "This project implements the SHA-256 cryptographic hash function from scratch, following the NIST FIPS 180-4 specification. The learner will build every stage of the Merkle-Damg\u00e5rd construction: message preprocessing and padding, message schedule generation with \u03c30/\u03c31 functions, the 64-round compression function with Ch/Maj/\u03a30/\u03a31, and final hash output with streaming API support.\n\nSHA-256 is one of the most widely deployed cryptographic primitives on the planet \u2014 it secures TLS certificates, Bitcoin proof-of-work, Git commit integrity, and digital signatures. By building it from the NIST spec, the learner gains deep intuition for how bitwise operations create cryptographic strength, how formal specifications translate into executable code, and why a single bit error cascades into a completely different digest.\n\nThe project progresses through four milestones, each building on the last. By the end, the learner will have a fully functional SHA-256 implementation that passes all NIST test vectors and supports a streaming update/finalize API pattern.",
    "design_philosophy": "SHA-256 is the ideal first cryptographic implementation because it uses only elementary operations (rotate, shift, XOR, AND, addition mod 2^32) composed in a precise way that creates avalanche behavior. The teaching philosophy centers on three pillars: (1) Spec-to-code translation \u2014 learning to read FIPS 180-4 and turn mathematical notation into working functions, (2) Bit-level debugging \u2014 using NIST intermediate values to verify every stage, catching the inevitable off-by-one and masking errors, and (3) Adversarial thinking \u2014 understanding WHY each design choice exists (why 64 rounds? why these rotation constants? what happens if you skip the length encoding?). Every milestone produces testable output that can be validated against known-answer test vectors, making bugs immediately visible.",
    "is_build_your_own": true,
    "implementation": {
      "primary_language": "C",
      "rationale": "SHA-256 is fundamentally a bit-manipulation algorithm operating on 32-bit unsigned integers. C provides native uint32_t types with natural overflow behavior (no masking needed), direct control over byte ordering, and the exact mental model that FIPS 180-4 was written for. Building SHA-256 in C teaches the learner to think at the bit level without language abstractions hiding the mechanics. The 32-bit unsigned arithmetic wraps naturally, bitwise rotations compile to single instructions, and the resulting code maps almost 1:1 to the spec pseudocode.",
      "style_guide": "snake_case for functions and variables (sha256_pad_message, sigma0). UPPER_CASE for constants (K, H0_INIT). Explicit uint32_t and uint8_t types from <stdint.h>. All functions take pointer + length pairs for buffer arguments. No dynamic allocation in core hash functions \u2014 fixed-size arrays for message schedule (uint32_t W[64]) and working variables.",
      "build_system": "Makefile with separate compilation units: sha256_pad.c, sha256_schedule.c, sha256_compress.c, sha256.c (main API), and test_sha256.c. Compiler flags: -std=c11 -Wall -Wextra -pedantic. Debug build with -fsanitize=undefined to catch integer UB.",
      "alternatives": [
        "Python \u2014 easier for beginners, but requires explicit & 0xFFFFFFFF masking after every addition, which obscures the algorithm and is the #1 source of bugs",
        "Rust \u2014 excellent safety guarantees with Wrapping<u32>, but ownership model adds complexity orthogonal to the cryptographic learning goals",
        "JavaScript \u2014 BigInt or bitwise operators truncate to signed 32-bit (>>> 0 needed), adding friction"
      ]
    },
    "prerequisites": {
      "assumed_known": [
        "Binary and hexadecimal number representation (converting between bases)",
        "Bitwise operations: AND, OR, XOR, left shift, right shift",
        "Basic C programming: functions, arrays, pointers, structs",
        "Understanding that a hash function maps arbitrary input to fixed-size output",
        "Compiling and running C programs with Makefile"
      ],
      "must_teach_first": [
        {
          "concept": "Right rotation (ROTR) vs. right shift (SHR)",
          "depth": "thorough",
          "when": "Milestone 1 (used conceptually) and Milestone 2 (implemented)"
        },
        {
          "concept": "Big-endian vs. little-endian byte ordering",
          "depth": "thorough",
          "when": "Milestone 1 \u2014 padding requires big-endian length encoding"
        },
        {
          "concept": "Modular arithmetic mod 2^32 and unsigned overflow in C",
          "depth": "basic",
          "when": "Milestone 2 \u2014 first place additions occur"
        },
        {
          "concept": "Merkle-Damg\u00e5rd construction and why padding includes length",
          "depth": "conceptual",
          "when": "Milestone 1 \u2014 motivates the padding scheme"
        },
        {
          "concept": "The avalanche effect and why it matters for cryptographic hashes",
          "depth": "conceptual",
          "when": "Milestone 3 \u2014 motivates the compression function design"
        }
      ]
    },
    "milestones": [
      {
        "id": "hash-impl-m1",
        "title": "Message Preprocessing and Padding",
        "anchor_id": "anchor-m1-preprocessing",
        "summary": "Implement SHA-256 message padding: append the '1' bit, pad with zeros to 448 mod 512 bits, append the 64-bit big-endian message length, and parse the padded message into 512-bit (64-byte) blocks. This milestone handles the critical boundary case where messages of 56+ bytes require an additional padding block.",
        "misconception": "Developers assume padding is trivial \u2014 just append some zeros to make the length round. They think the '1' bit, the specific modular arithmetic (448 mod 512), and the 64-bit length suffix are arbitrary ceremony that any reasonable padding would achieve.",
        "reveal": "Every byte of SHA-256 padding is load-bearing for security. The '1' bit separator prevents ambiguity between messages that differ only in trailing zeros. The length encoding at the end prevents 'length extension attacks' where an attacker could append data to a hash without knowing the original message. The 448 mod 512 rule exists precisely to RESERVE 64 bits for this length field. Without this exact padding, the hash function loses its collision resistance guarantees. This is the Merkle-Damg\u00e5rd strengthening \u2014 it's what makes the construction provably secure under certain assumptions.",
        "cascade": [
          "Length extension attacks \u2014 understanding WHY the length is encoded explains how SHA-256's padding prevents a real attack class (and why HMAC exists to fix what padding alone can't)",
          "Merkle-Damg\u00e5rd construction (cross-domain: formal proofs) \u2014 the padding scheme is the 'injective padding' requirement that makes the security reduction work; without it, the proof breaks",
          "Block cipher modes of operation (cross-domain: symmetric crypto) \u2014 the concept of processing data in fixed-size blocks with careful boundary handling appears in AES-CBC, AES-GCM, and every block-based construction",
          "Protocol framing (cross-domain: networking) \u2014 the same 'length-prefix then data' pattern appears in TCP segments, TLS records, and HTTP/2 frames, all solving the same ambiguity problem",
          "Off-by-one debugging discipline \u2014 the boundary case (55 vs 56 bytes) builds the habit of testing exact boundaries, applicable to buffer overflow analysis"
        ],
        "yaml_acceptance_criteria": [
          "Message is converted to its byte/bit representation, a single '1' bit is appended, followed by enough '0' bits so that the total message length is congruent to 448 mod 512 bits, and finally the original message length in bits is appended as a 64-bit big-endian integer, producing a message whose total length is a multiple of 512 bits.",
          "When the original message length mod 512 is greater than 447 bits (i.e., fewer than 65 bits remain for padding + length), an additional 512-bit block is correctly appended to accommodate the padding and length field.",
          "Padded message is parsed into an array of 512-bit (64-byte) blocks for sequential processing.",
          "Empty input (0 bytes) produces exactly one 512-bit padded block with the '1' bit at position 0, zeros through bit 447, and a 64-bit zero length field.",
          "Test: the string \"abc\" (24 bits) produces one 512-bit block; a 55-byte message produces one block; a 56-byte message produces two blocks (boundary case)."
        ]
      },
      {
        "id": "hash-impl-m2",
        "title": "Message Schedule Generation",
        "anchor_id": "anchor-m2-schedule",
        "summary": "For each 512-bit block, parse it into 16 big-endian 32-bit words, then expand to 64 words using the SHA-256 recurrence relation with \u03c30 and \u03c31 functions. This milestone implements right-rotation, right-shift, and the critical 32-bit masking discipline.",
        "misconception": "Developers assume the message schedule is just a fancy way to 'stretch' 16 input words into 64 words \u2014 like repeating the input or doing simple linear interpolation. They expect that small changes to one input word would only affect nearby schedule words.",
        "reveal": "The \u03c30 and \u03c31 functions create a cascading diffusion pattern where each input word eventually influences ALL 64 schedule words. The combination of rotation (which preserves all bits but rearranges them), shift (which destroys bits), and XOR (which mixes without carry propagation) was specifically chosen to maximize the 'avalanche' \u2014 changing one bit of input flips roughly half the bits across the full schedule. This is not stretching; it's building a 64-word dependency web where information from every input word is thoroughly mixed. The rotation constants (7, 18, 3 for \u03c30 and 17, 19, 10 for \u03c31) were chosen after extensive cryptanalysis to resist differential attacks.",
        "cascade": [
          "Avalanche effect \u2014 the schedule expansion is the first place where 'flip one input bit, flip ~50% of output bits' becomes tangible and measurable",
          "Rotate vs. shift distinction \u2014 this directly maps to understanding CPU barrel shifters and instruction sets (cross-domain: computer architecture), and appears in AES MixColumns, CRC computation, and error-correcting codes",
          "Finite field arithmetic (cross-domain: abstract algebra) \u2014 XOR is addition in GF(2), and the \u03c3 functions operate in a space where these operations have algebraic properties exploited in cryptanalysis",
          "Linear feedback shift registers (LFSRs) \u2014 the \u03c3 recurrence is structurally similar to LFSR-based stream ciphers, connecting SHA-256 to an entirely different branch of cryptography",
          "32-bit masking discipline \u2014 once internalized here, the same pattern appears in CRC-32, Adler-32, network checksum computation, and embedded firmware programming"
        ],
        "yaml_acceptance_criteria": [
          "512-bit block is parsed into 16 initial 32-bit words (W[0]..W[15]) in big-endian order.",
          "Words W[16]..W[63] are computed using the recurrence: W[t] = \u03c31(W[t-2]) + W[t-7] + \u03c30(W[t-15]) + W[t-16], all mod 2^32.",
          "\u03c30(x) = ROTR(x,7) XOR ROTR(x,18) XOR SHR(x,3) produces correct values verified against NIST example computation.",
          "\u03c31(x) = ROTR(x,17) XOR ROTR(x,19) XOR SHR(x,10) produces correct values verified against NIST example computation.",
          "All 64 words are stored as 32-bit unsigned integers. In languages with arbitrary-precision integers (Python, JavaScript), every addition is masked with & 0xFFFFFFFF."
        ]
      },
      {
        "id": "hash-impl-m3",
        "title": "Compression Function",
        "anchor_id": "anchor-m3-compression",
        "summary": "Implement the SHA-256 compression function: 64 rounds of state transformation using Ch, Maj, \u03a30, \u03a31, round constants K[0..63], and message schedule words W[0..63]. Each round updates eight working variables (a-h) through two temporary values T1 and T2, then the block's result is added back to the running hash state.",
        "misconception": "Developers assume the 64 rounds are redundant repetition \u2014 that maybe 8 or 16 rounds would be 'good enough' and the rest are just paranoid over-engineering. They see Ch and Maj as arbitrarily chosen boolean functions.",
        "reveal": "Each round contributes to a precise security margin. Cryptanalysts have published attacks on reduced-round SHA-256: 31 rounds can be broken with collision attacks. The full 64 rounds exist because security proofs require a margin beyond the best known attack. Ch and Maj are NOT arbitrary \u2014 they are the only two balanced boolean functions of three variables that provide optimal non-linearity and differential resistance. Ch(e,f,g) acts as a conditional multiplexer (if e then f else g), while Maj(a,b,c) acts as a bit-voting function. Together with the \u03a3 rotations (which provide diffusion) and modular addition (which provides non-linearity that XOR alone cannot), they form a compression function where every operation has a specific cryptanalytic purpose. The round constants K[t] \u2014 derived from cube roots of primes \u2014 serve as 'nothing-up-my-sleeve' numbers that prevent symmetry exploits and ensure each round behaves differently.",
        "cascade": [
          "Cryptanalytic margins \u2014 understanding round count as a security budget directly explains why AES has 10/12/14 rounds for 128/192/256-bit keys, and why reduced-round attacks are the primary tool of symmetric cryptanalysis",
          "Boolean function non-linearity (cross-domain: circuit design) \u2014 Ch and Maj appear in digital logic as MUX and majority gates; understanding their algebraic properties connects to S-box design in AES and hardware optimization",
          "Nothing-up-my-sleeve numbers (cross-domain: algorithm design transparency) \u2014 the K constants from prime cube roots are a trust mechanism; this concept reappears in Blowfish (digits of \u03c0), NIST curves (unexplained seed controversy), and Ed25519",
          "Compression function as one-way function \u2014 understanding that the compression function's security implies the hash's security (via Merkle-Damg\u00e5rd) connects to provable security reductions throughout cryptography",
          "State machine design \u2014 the 8-variable rotation (a\u2192b\u2192c\u2192...) is a shift-register pattern that appears in CPU pipelines, Galois counters, and protocol state machines"
        ],
        "yaml_acceptance_criteria": [
          "Working variables (a through h) are initialized from the current hash values (H0..H7) at the start of each block's compression.",
          "64 rounds of compression execute, each computing: T1 = h + \u03a31(e) + Ch(e,f,g) + K[t] + W[t] T2 = \u03a30(a) + Maj(a,b,c) then shifting variables: h=g, g=f, f=e, e=d+T1, d=c, c=b, b=a, a=T1+T2, all mod 2^32.",
          "Ch(x,y,z) = (x AND y) XOR (NOT x AND z) produces correct values.",
          "Maj(x,y,z) = (x AND y) XOR (x AND z) XOR (y AND z) produces correct values.",
          "\u03a30(a) = ROTR(a,2) XOR ROTR(a,13) XOR ROTR(a,22) and \u03a31(e) = ROTR(e,6) XOR ROTR(e,11) XOR ROTR(e,25) produce correct values.",
          "All 64 round constants K[0]..K[63] are the first 32 bits of the fractional parts of the cube roots of the first 64 primes, matching the values in FIPS 180-4 Section 4.2.2.",
          "After all 64 rounds, the hash values are updated: H0 += a, H1 += b, ..., H7 += h (all mod 2^32).",
          "Intermediate hash values after processing the \"abc\" test vector's first block match the NIST example computation appendix values."
        ]
      },
      {
        "id": "hash-impl-m4",
        "title": "Final Hash Output and Validation",
        "anchor_id": "anchor-m4-finalization",
        "summary": "Wire all stages together into a complete SHA-256 implementation. Initialize hash state from FIPS 180-4 constants, process all blocks sequentially through the compression function, produce the final 256-bit digest as a 64-character hex string, and validate against NIST test vectors. Implement a streaming API with update()/finalize() methods and proper state reset between invocations.",
        "misconception": "Developers assume that once the compression function works, the final assembly is trivial \u2014 just concatenate H0..H7 and convert to hex. They expect the streaming API (update/finalize) to be a simple wrapper that just accumulates input and calls the hash at the end.",
        "reveal": "The finalization stage is where three subtle bugs converge. First, the initial hash values H0..H7 are NOT arbitrary \u2014 they are the fractional parts of the square roots of the first 8 primes, and using wrong values produces a valid-looking but completely incorrect hash (this is how SHA-224 differs: same algorithm, different initial values). Second, the streaming API requires an internal buffer because the caller may feed data in chunks that don't align to 512-bit block boundaries \u2014 the buffer management is effectively a state machine with partial-block, full-block, and finalization states, and getting the edge cases wrong produces hashes that work for some input sizes but fail for others. Third, state reset between calls is critical \u2014 without it, the second hash includes the entropy of the first, a bug that may go unnoticed in testing if you only hash one message per test.",
        "cascade": [
          "SHA family relationships \u2014 understanding that SHA-224/256/384/512 differ primarily in initial values and word size reveals the entire SHA-2 family as a single parameterized design",
          "Streaming/incremental API pattern (cross-domain: software engineering) \u2014 the update/finalize pattern appears in TLS record processing, database write-ahead logs, video codec frame processing, and any system that processes unbounded input in fixed-size chunks",
          "State machine discipline \u2014 the buffer management logic (empty \u2192 partial \u2192 full \u2192 flush \u2192 repeat) is a miniature state machine; this pattern recurs in TCP reassembly, filesystem journaling, and parser combinators",
          "Test vector methodology (cross-domain: quality engineering) \u2014 using known-answer tests from an authoritative spec is the gold standard for crypto validation, and the same methodology applies to IEEE 754 floating-point conformance, Unicode normalization, and protocol compliance testing",
          "Initialization vector security \u2014 the connection between IVs and security generalizes to AES-CBC (random IV), TLS (nonce uniqueness), and key derivation functions (salt)"
        ],
        "yaml_acceptance_criteria": [
          "Hash state (H0..H7) is initialized to the SHA-256 initial hash values from FIPS 180-4 Section 5.3.3 before processing any blocks.",
          "All message blocks are processed sequentially, each updating the hash state through the compression function.",
          "Final hash is the concatenation of H0..H7 as 32-bit big-endian values, producing a 256-bit (32-byte) digest.",
          "Output is formatted as a 64-character lowercase hexadecimal string.",
          "SHA-256(\"\") = e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
          "SHA-256(\"abc\") = ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad",
          "SHA-256(\"abcdbcdecdefdefgefghfghighijhijkijkljklmklmnlmnomnopnopq\") = 248d6a61d20638b8e5c026930c3e6039a33ce45964ff2167f6ecedd419db06c1",
          "Function handles multiple independent invocations correctly: hash state is fully reset between calls, producing identical output for identical input.",
          "Streaming/chunked API: input can be fed in arbitrary-sized chunks (update/finalize pattern), producing the same hash as single-call processing."
        ]
      }
    ],
    "diagrams": [
      {
        "id": "diag-L0-satellite-map",
        "title": "SHA-256 Complete Pipeline \u2014 Satellite Map",
        "description": "The project-wide 'Home Base' diagram showing the entire SHA-256 data flow from input message to 256-bit digest. Shows all four milestones as major processing stages: Message Preprocessing \u2192 Message Schedule \u2192 Compression Function \u2192 Final Output. Includes data shapes at each boundary (arbitrary bytes \u2192 512-bit blocks \u2192 64 words \u2192 8 working variables \u2192 256-bit hash). Every component links to its milestone anchor. This is the learner's navigation map throughout the project.",
        "anchor_target": "anchor-m1-preprocessing",
        "level": "satellite"
      },
      {
        "id": "diag-m1-padding-structure",
        "title": "SHA-256 Padding Structure Layout",
        "description": "A structure_layout diagram showing the exact byte-level structure of a padded message. Shows three examples side by side: 'abc' (3 bytes \u2192 1 block), a 55-byte message (\u2192 1 block), and a 56-byte message (\u2192 2 blocks). Each example labels the original message bytes, the 0x80 byte (the '1' bit + 7 zero bits), the zero padding region, and the 64-bit big-endian length field. Highlights the 448-mod-512 boundary and shows exactly where each region falls.",
        "anchor_target": "anchor-m1-preprocessing",
        "level": "street"
      },
      {
        "id": "diag-m1-padding-decision-flow",
        "title": "Padding Length Decision Logic",
        "description": "A state_evolution / flowchart diagram showing the decision process: given message length L bits, calculate (L + 1 + 64) to determine if it exceeds 512 bits, branching into 'fits in one block' vs. 'needs extra block'. Shows the exact formula for zero-padding count: num_zero_bits = (447 - L) mod 512. Highlights the off-by-one pitfall where beginners use 448 instead of 447.",
        "anchor_target": "anchor-m1-preprocessing",
        "level": "microscopic"
      },
      {
        "id": "diag-m1-empty-input-trace",
        "title": "Trace: Empty Input Padding",
        "description": "A trace_example diagram showing the complete padded block for empty input (0 bytes). Shows all 64 bytes: byte 0 = 0x80, bytes 1-55 = 0x00, bytes 56-63 = 0x0000000000000000 (length = 0). Verifies the block is exactly 512 bits. This trace serves as the simplest possible known-answer test for the padding function.",
        "anchor_target": "anchor-m1-preprocessing",
        "level": "microscopic"
      },
      {
        "id": "diag-m1-endianness-before-after",
        "title": "Big-Endian vs. Little-Endian: Before and After Byte Swap",
        "description": "A before_after diagram showing a 32-bit integer (e.g., 0x61626364 for 'abcd') stored in big-endian (as SHA-256 expects) vs. little-endian (as x86 stores it). Shows the byte-level memory layout in both orderings and the swap operation needed. Also shows the 64-bit length field encoding for a specific message length.",
        "anchor_target": "anchor-m1-preprocessing",
        "level": "microscopic"
      },
      {
        "id": "diag-m1-boundary-case-56-bytes",
        "title": "The 56-Byte Boundary Case \u2014 Two Blocks",
        "description": "A data_walk diagram tracing what happens when the input is exactly 56 bytes. Shows that after adding the 0x80 byte (57 bytes total), only 7 bytes remain in the first 64-byte block \u2014 not enough for the 8-byte length field. Walks through the creation of the second block: remaining zeros + 8-byte length. This is the most common beginner bug visualized step by step.",
        "anchor_target": "anchor-m1-preprocessing",
        "level": "microscopic"
      },
      {
        "id": "diag-m2-rotr-vs-shr",
        "title": "ROTR vs. SHR \u2014 Bit-Level Comparison",
        "description": "A before_after diagram showing the same 32-bit value processed by ROTR(x, 7) and SHR(x, 3). Shows all 32 bits, with arrows indicating where each bit moves. ROTR: bits that fall off the right wrap to the left. SHR: bits that fall off are replaced by zeros. Highlights that \u03c30 uses BOTH operations and mixing them up is a critical bug.",
        "anchor_target": "anchor-m2-schedule",
        "level": "microscopic"
      },
      {
        "id": "diag-m2-sigma0-computation",
        "title": "\u03c30 Function \u2014 Three Operations XORed",
        "description": "A trace_example diagram showing \u03c30(x) = ROTR(x,7) \u2295 ROTR(x,18) \u2295 SHR(x,3) for a specific 32-bit value from the NIST 'abc' example. Shows each intermediate result as 32 binary digits, then the final XOR combination. Labels which bits are 'preserved' (appear in multiple intermediates) vs. 'mixed' (flipped by XOR).",
        "anchor_target": "anchor-m2-schedule",
        "level": "microscopic"
      },
      {
        "id": "diag-m2-schedule-expansion-data-walk",
        "title": "Message Schedule Expansion \u2014 Data Dependency Walk",
        "description": "A data_walk diagram showing how W[16] is computed from W[14], W[9], W[1], and W[0] via \u03c31(W[14]) + W[9] + \u03c30(W[1]) + W[0]. Then traces forward to show how W[16] feeds into W[17], W[23], W[31], and W[32], illustrating the cascading dependency web. Uses arrows to show that by W[63], every original word W[0..15] has influenced the result.",
        "anchor_target": "anchor-m2-schedule",
        "level": "street"
      },
      {
        "id": "diag-m2-word-extraction",
        "title": "Block to Words \u2014 Big-Endian 32-bit Parsing",
        "description": "A structure_layout diagram showing a 512-bit block (64 bytes) being parsed into W[0]..W[15]. Shows bytes 0-3 becoming W[0] (big-endian: byte 0 is MSB), bytes 4-7 becoming W[1], etc. Includes the C expression: W[i] = (block[4*i] << 24) | (block[4*i+1] << 16) | (block[4*i+2] << 8) | block[4*i+3].",
        "anchor_target": "anchor-m2-schedule",
        "level": "microscopic"
      },
      {
        "id": "diag-m2-masking-before-after",
        "title": "32-bit Masking \u2014 What Happens Without It",
        "description": "A before_after diagram showing the schedule computation WITH and WITHOUT & 0xFFFFFFFF masking (relevant for Python). Shows a specific addition where the unmasked result is a 33+ bit number, and how this error propagates through subsequent schedule words, producing a completely wrong schedule by W[30]. In C, this is naturally handled by uint32_t overflow \u2014 diagram notes this language difference.",
        "anchor_target": "anchor-m2-schedule",
        "level": "microscopic"
      },
      {
        "id": "diag-m3-compression-round-anatomy",
        "title": "Anatomy of One Compression Round",
        "description": "A street-level diagram showing the complete data flow of a single round t: inputs (a,b,c,d,e,f,g,h, W[t], K[t]), computation of T1 = h + \u03a31(e) + Ch(e,f,g) + K[t] + W[t] and T2 = \u03a30(a) + Maj(a,b,c), and the variable rotation (a\u2190T1+T2, b\u2190a, c\u2190b, d\u2190c, e\u2190d+T1, f\u2190e, g\u2190f, h\u2190g). Shows all eight variables as a chain with T1 injecting at two points (a and e).",
        "anchor_target": "anchor-m3-compression",
        "level": "street"
      },
      {
        "id": "diag-m3-ch-function-truth-table",
        "title": "Ch(x,y,z) \u2014 The Choice Function as Multiplexer",
        "description": "A microscopic diagram showing Ch(x,y,z) = (x AND y) XOR (NOT x AND z) as a bit-level truth table for all 8 combinations of (x,y,z). Alongside it, shows the equivalent multiplexer circuit: 'if x then y else z'. Highlights that each bit of x independently selects the corresponding bit from y or z.",
        "anchor_target": "anchor-m3-compression",
        "level": "microscopic"
      },
      {
        "id": "diag-m3-maj-function-truth-table",
        "title": "Maj(x,y,z) \u2014 The Majority Vote Function",
        "description": "A microscopic diagram showing Maj(x,y,z) = (x AND y) XOR (x AND z) XOR (y AND z) as a truth table. Shows the equivalent interpretation: output is 1 if at least 2 of the 3 inputs are 1. Visualizes the 'voting' behavior bit by bit. Notes the connection to majority gates in hardware design.",
        "anchor_target": "anchor-m3-compression",
        "level": "microscopic"
      },
      {
        "id": "diag-m3-sigma-uppercase-vs-lowercase",
        "title": "\u03a3 (Compression) vs. \u03c3 (Schedule) \u2014 Constant Comparison",
        "description": "A before_after / comparison diagram showing all four sigma functions side by side: \u03c30(7,18,3), \u03c31(17,19,10), \u03a30(2,13,22), \u03a31(6,11,25). Highlights that \u03c3 uses one SHR + two ROTR while \u03a3 uses three ROTR (no shift). Shows where each is used in the algorithm. This directly addresses the pitfall of mixing them up.",
        "anchor_target": "anchor-m3-compression",
        "level": "microscopic"
      },
      {
        "id": "diag-m3-variable-rotation-state-evolution",
        "title": "Working Variable Rotation Across 4 Rounds",
        "description": "A state_evolution diagram showing the values of (a,b,c,d,e,f,g,h) across rounds t=0 through t=3 for the 'abc' test vector. Shows how old-a becomes new-b, old-b becomes new-c, etc., while a and e receive fresh computed values. Uses the NIST intermediate values to show exact numbers, proving the implementation is correct.",
        "anchor_target": "anchor-m3-compression",
        "level": "microscopic"
      },
      {
        "id": "diag-m3-k-constants-origin",
        "title": "K Constants \u2014 From Primes to 32-bit Values",
        "description": "A trace_example diagram showing how K[0] is derived: cube root of 2 = 1.2599210..., fractional part = 0.2599210..., multiply by 2^32 = 0x428a2f98. Shows 3-4 constants being derived this way, then lists all 64 K values in a compact table. Explains 'nothing-up-my-sleeve' \u2014 these values are deterministic from a simple rule, so no one can hide a backdoor in them.",
        "anchor_target": "anchor-m3-compression",
        "level": "microscopic"
      },
      {
        "id": "diag-m3-t1-t2-data-flow",
        "title": "T1 and T2 Computation \u2014 Detailed Data Flow",
        "description": "A microscopic diagram zooming into the T1 and T2 computations. T1 has five addends: h, \u03a31(e), Ch(e,f,g), K[t], W[t]. T2 has two: \u03a30(a), Maj(a,b,c). Shows which working variables feed into which computation, and highlights the critical distinction: e = d + T1 (NOT d + T1 + T2), a = T1 + T2. This addresses the most dangerous implementation bug.",
        "anchor_target": "anchor-m3-compression",
        "level": "microscopic"
      },
      {
        "id": "diag-m3-full-64-rounds-overview",
        "title": "64 Rounds Overview \u2014 State Propagation Across Full Block",
        "description": "A compressed satellite-level view of all 64 rounds as a pipeline. Shows initial H0..H7 flowing in, 64 round boxes (grouped in sets of 16, color-coded), W[t] and K[t] feeding from the sides, and the final addition H0+=a..H7+=h at the bottom. This gives the learner a mental picture of the full compression as an assembly line.",
        "anchor_target": "anchor-m3-compression",
        "level": "street"
      },
      {
        "id": "diag-m4-streaming-api-state-machine",
        "title": "Streaming API \u2014 State Machine Diagram",
        "description": "A state_evolution diagram showing the SHA-256 context struct moving through states: INITIALIZED \u2192 UPDATING (buffer partially filled) \u2192 UPDATING (buffer full, process block, reset buffer) \u2192 FINALIZED (pad remaining buffer, process final block(s), output digest). Shows transitions triggered by init(), update(data), and finalize(). Highlights the internal buffer and its fill level as the key state variable.",
        "anchor_target": "anchor-m4-finalization",
        "level": "street"
      },
      {
        "id": "diag-m4-context-struct-layout",
        "title": "SHA-256 Context Struct \u2014 Memory Layout",
        "description": "A structure_layout diagram showing the sha256_ctx struct: uint32_t state[8] (H0..H7), uint8_t buffer[64] (partial block buffer), uint64_t total_len (total bytes processed), size_t buffer_len (current bytes in buffer). Shows which fields are initialized by init(), modified by update(), and read by finalize(). Annotates reset behavior between independent hash calls.",
        "anchor_target": "anchor-m4-finalization",
        "level": "microscopic"
      },
      {
        "id": "diag-m4-initial-hash-values-origin",
        "title": "H0..H7 Initial Values \u2014 From Prime Square Roots",
        "description": "A trace_example diagram showing how H0 is derived: square root of 2 = 1.4142135..., fractional part = 0.4142135..., multiply by 2^32 = 0x6a09e667. Shows all 8 initial values with their source primes (2, 3, 5, 7, 11, 13, 17, 19). Notes that SHA-224 uses the same algorithm but with different initial values (from the 9th through 16th primes), showing how the family is parameterized.",
        "anchor_target": "anchor-m4-finalization",
        "level": "microscopic"
      },
      {
        "id": "diag-m4-chunked-update-trace",
        "title": "Trace: Streaming Hash of 'abc' in Two Chunks",
        "description": "A data_walk diagram tracing sha256_init() \u2192 sha256_update('a', 1) \u2192 sha256_update('bc', 2) \u2192 sha256_finalize(). Shows the buffer state after each call: [0x61, _, ..., _] after first update, [0x61, 0x62, 0x63, _, ..., _] after second update, then finalize triggers padding of the 3-byte buffer, block processing, and digest output. Verifies the result matches the single-call hash of 'abc'.",
        "anchor_target": "anchor-m4-finalization",
        "level": "microscopic"
      },
      {
        "id": "diag-m4-full-pipeline-trace-abc",
        "title": "Complete SHA-256 Trace for 'abc' \u2014 End to End",
        "description": "A comprehensive data_walk diagram tracing 'abc' through the entire SHA-256 pipeline: (1) padding to one 512-bit block, (2) parsing into W[0]..W[15], (3) expanding to W[0]..W[63], (4) initial working variables from H0..H7, (5) round 0 computation with actual numbers, (6) hash state after all 64 rounds, (7) final H0+=a..H7+=h, (8) hex encoding to ba7816bf...0015ad. This is the capstone diagram that ties all four milestones together.",
        "anchor_target": "anchor-m4-finalization",
        "level": "street"
      },
      {
        "id": "diag-m4-state-reset-before-after",
        "title": "State Reset Bug \u2014 Before and After Fix",
        "description": "A before_after diagram showing what happens when hash state is NOT reset between calls. First call: hash('abc') = correct. Second call: hash('abc') again with stale H0..H7 from first call = WRONG. Shows the divergence in the first round of the second hash. Then shows the fixed version with proper init() resetting all state fields.",
        "anchor_target": "anchor-m4-finalization",
        "level": "microscopic"
      }
    ]
  },
  "primary_language": "C",
  "accumulated_md": "# SHA-256 Hash Function\n\nThis project implements the SHA-256 cryptographic hash function from scratch, following the NIST FIPS 180-4 specification. The learner will build every stage of the Merkle-Damg\u00e5rd construction: message preprocessing and padding, message schedule generation with \u03c30/\u03c31 functions, the 64-round compression function with Ch/Maj/\u03a30/\u03a31, and final hash output with streaming API support.\n\nSHA-256 is one of the most widely deployed cryptographic primitives on the planet \u2014 it secures TLS certificates, Bitcoin proof-of-work, Git commit integrity, and digital signatures. By building it from the NIST spec, the learner gains deep intuition for how bitwise operations create cryptographic strength, how formal specifications translate into executable code, and why a single bit error cascades into a completely different digest.\n\nThe project progresses through four milestones, each building on the last. By the end, the learner will have a fully functional SHA-256 implementation that passes all NIST test vectors and supports a streaming update/finalize API pattern.\n\n\n\n<!-- MS_ID: hash-impl-m1 -->\n# Milestone 1: Message Preprocessing and Padding\n## Where We Are in the Pipeline\n\n![SHA-256 Complete Pipeline \u2014 Satellite Map](./diagrams/diag-L0-satellite-map.svg)\n\nYou are at the very first stage of SHA-256: before a single round of cryptographic computation runs, every message must be transformed into a form the compression function can consume. This stage is called **message preprocessing**, and it has one job \u2014 convert your raw bytes into an exact sequence of 512-bit blocks, with no ambiguity whatsoever about what you fed in.\nThis chapter will make you feel the necessity of every single byte in the padding structure before showing you how to write it.\n---\n## The Revelation: Padding Is Not Ceremony\nHere is what most developers assume about hash function padding:\n> \"The message needs to be rounded up to a nice block size. Append some zeros, maybe a sentinel byte, and you're done. The specific scheme is probably arbitrary \u2014 any reasonable approach would work.\"\nThis assumption is wrong in a deep way, and understanding *exactly* why it is wrong will teach you more about cryptographic design than almost anything else in this project.\nLet's break the assumption.\n### The Ambiguity Attack\nSuppose you design a na\u00efve hash function that processes 512-bit blocks and pads by simply appending zero bytes to reach the next block boundary. Consider these two messages:\n```\nMessage A: \"hello\\x00\\x00\\x00\"    (8 bytes, zero-padded to block boundary)\nMessage B: \"hello\"                 (5 bytes, zero-padded to block boundary)\n```\nAfter your na\u00efve padding, both messages look identical to the compression function. Both produce the same 512-bit block. Both produce the same hash. You have a **trivial collision** \u2014 two different inputs that hash to the same output \u2014 and collision resistance is the entire point of a cryptographic hash.\nThis is not a theoretical concern. MD4, an early hash function, had a simplified padding scheme that contributed to practical collision attacks. The specific padding rules in SHA-256 are the engineering response to this exact class of failure.\n### The Length Extension Attack\nNow suppose your padding correctly prevents the above collision. You append a `0x80` byte (the `1` bit in the high position) before your zeros, which distinguishes \"message ended here\" from \"message contained a zero byte.\" Better. But you still have a problem.\nSHA-256 uses a structure called **Merkle-Damg\u00e5rd construction**: it iteratively feeds each block through a compression function, threading the output of one compression into the input of the next. The final hash *is* the internal state after the last block. This means:\nIf an attacker knows `SHA256(secret || message)` but not `secret`, they can compute `SHA256(secret || message || padding || extra_data)` *without knowing the secret*. They just initialize the hash state to the known output and keep feeding blocks. This is called a **length extension attack**.\nThe defense? Encode the *original message length* in the padding itself. Now the attacker can't extend the hash without knowing the original length \u2014 and if they append `extra_data`, the compression function processes a block that contains the *wrong* embedded length, producing a different chain of state. This is exactly what SHA-256's padding does.\n> \ud83d\udd2d **Deep Dive**: Length extension attacks are real and practically exploitable. The Flickr API was vulnerable to a length extension attack in 2009. HMAC exists specifically to close this vulnerability in contexts where the hash input contains secrets \u2014 for an excellent treatment, see David Wagner and Mihir Bellare's \"New Proofs for NMAC and HMAC\" (CRYPTO 2006), or the simpler explanation at https://en.wikipedia.org/wiki/Length_extension_attack.\nNow you see it: every element of SHA-256's padding is *load-bearing*. Remove any one piece and you lose a real security guarantee.\n---\n## The Merkle-Damg\u00e5rd Construction: Why Blocks Exist\n\n![SHA-256 Padding Structure Layout](./diagrams/diag-m1-padding-structure.svg)\n\nBefore we get into the byte-level mechanics, you need a mental model of *why* SHA-256 processes data in 512-bit blocks at all.\n**Merkle-Damg\u00e5rd** (pronounced \"Mur-kul Dom-gord\") is the structural principle underneath SHA-256. The insight is this: instead of designing a function that hashes *arbitrarily long* inputs (which is very hard to analyze mathematically), design a function that:\n1. Takes a *fixed-size* input \u2014 one 512-bit block plus the current 256-bit \"state\"\n2. Produces a *fixed-size* output \u2014 a new 256-bit state\nThen chain these calls together, feeding each output as the state input to the next call. This function is the **compression function**, and it is much easier to prove secure than an arbitrary-length function.\nThe padding scheme is what makes this chain unambiguous. Researchers call it **Merkle-Damg\u00e5rd strengthening**: the specific padding rule (including length encoding) is what allows the security proof to work. Without it, the mathematical reduction from \"the compression function is secure\" to \"the hash function is secure\" falls apart.\nIn pseudocode, the full structure is:\n```\nstate = INITIAL_HASH_VALUES\nfor each 512-bit block in padded_message:\n    state = compress(state, block)\nfinal_hash = state\n```\nYour job in this milestone is to build the part that produces those 512-bit blocks from arbitrary input.\n---\n## The Padding Rules: Precise and Purposeful\nHere are the exact rules from NIST FIPS 180-4, Section 5.1.1:\n**Given** a message of `L` bits:\n1. Append a single `1` bit immediately after the last message bit.\n2. Append `k` zero bits, where `k` is the smallest non-negative integer such that `L + 1 + k \u2261 448 (mod 512)`.\n3. Append the 64-bit big-endian representation of `L` (the *original* message length in bits).\nThe result has a total length that is a multiple of 512 bits.\nLet's decode each rule.\n**Rule 1 \u2014 The `1` bit**: This is the unambiguous \"message ends here\" marker. Without it, a message ending in zero bytes is indistinguishable from a shorter message after padding. In byte-oriented implementations (which yours will be), this appears as the byte `0x80` appended after the last message byte, because `1000 0000` in binary has its high bit set \u2014 that is the `1` bit, followed by seven `0` padding bits all within the same byte.\n**Rule 2 \u2014 The zero fill**: You need enough zeros that after the `1` bit and before the 64-bit length field, the message reaches a 512-bit block boundary. The number 448 = 512 \u2212 64. You're reserving exactly 64 bits at the end of the final block for the length field. The formula `k = (447 - L) mod 512` gives you the zero count (note: 447, not 448, because the `1` bit itself consumes one bit).\n**Rule 3 \u2014 The 64-bit length**: The original message length in bits, encoded as a big-endian 64-bit integer. This is what prevents length extension. For a 3-byte message (\"abc\"), `L = 24`, so this field contains the 64-bit representation of the number 24.\n---\n## Big-Endian Byte Ordering: Thinking in Network Byte Order\n\n![Big-Endian vs. Little-Endian: Before and After Byte Swap](./diagrams/diag-m1-endianness-before-after.svg)\n\nSHA-256 is defined entirely in **big-endian** byte order. You need to understand this precisely, because on x86 and ARM processors (which are little-endian), your C code will silently use the wrong byte order unless you explicitly handle it.\n**Endianness** describes the order in which bytes of a multi-byte value are stored in memory.\nConsider the 32-bit value `0x01234567`:\n- **Big-endian** (SHA-256's world): `01 23 45 67` \u2014 most significant byte first\n- **Little-endian** (your x86 laptop): `67 45 23 01` \u2014 least significant byte first\nThe name comes from Jonathan Swift's *Gulliver's Travels*, where two factions war over which end of a boiled egg to crack first \u2014 the absurdity mirrors the arbitrariness of the choice.\nFor this milestone, endianness matters in one specific place: when you append the 64-bit message length (Rule 3). The value must be written as 8 bytes in big-endian order.\n```c\n/* \n * Write a 64-bit value v into buf[0..7] in big-endian order.\n * buf[0] gets the most significant byte, buf[7] gets the least.\n */\nvoid write_uint64_be(uint8_t *buf, uint64_t v) {\n    buf[0] = (uint8_t)(v >> 56);\n    buf[1] = (uint8_t)(v >> 48);\n    buf[2] = (uint8_t)(v >> 40);\n    buf[3] = (uint8_t)(v >> 32);\n    buf[4] = (uint8_t)(v >> 24);\n    buf[5] = (uint8_t)(v >> 16);\n    buf[6] = (uint8_t)(v >>  8);\n    buf[7] = (uint8_t)(v >>  0);\n}\n```\nThis pattern \u2014 shifting right by increasingly small amounts and casting to `uint8_t` \u2014 is the standard C idiom for writing big-endian values portably. It works identically on big-endian and little-endian machines because you are doing *arithmetic* shifts on the value, not peeking at memory layout.\nFor the \"abc\" message, `L = 24` (three bytes \u00d7 8 bits each). The 64-bit length field looks like:\n```\n00 00 00 00 00 00 00 18\n```\nBecause `24 = 0x18` in hexadecimal, and all higher bytes are zero.\n---\n## The Padding Layout: Visualized\n\n![Padding Length Decision Logic](./diagrams/diag-m1-padding-decision-flow.svg)\n\nLet's trace exactly what happens to the string \"abc\" (3 bytes = 24 bits):\n```\nOriginal:  61 62 63\n           ^^ ^^ ^^\n           a  b  c\nAfter 0x80 appended:\n           61 62 63 80\n                    ^^\n                    '1' bit + seven '0' bits\nAfter zero fill (52 bytes of 0x00):\n           61 62 63 80 00 00 00 ... 00\n           (total: 56 bytes so far)\nAfter 64-bit length (00 00 00 00 00 00 00 18):\n           61 62 63 80 00 00 00 ... 00 00 00 00 00 00 00 00 18\n           |<-------- 64 bytes = 512 bits total --------->|\n```\nThe resulting block is exactly 512 bits. Perfect.\nHow many zero bytes did we add? We need the padded message (before the length field) to be `64 - 8 = 56` bytes long. We have 3 message bytes + 1 `0x80` byte = 4 bytes. So we add `56 - 4 = 52` bytes of zeros.\nLet's verify with the formula. `L = 24` bits.\n```\nk = (447 - 24) mod 512 = 423 bits of zeros = 52 bytes + 7 bits\n```\nBut wait \u2014 we already placed 7 of those zero bits in the `0x80` byte (the high bit is `1`, the remaining 7 bits are `0`). So in practice, we place `0x80`, then add `423 - 7 = 416` bits = 52 bytes of `0x00`. \u2713\n---\n## The Critical Boundary: 55 Bytes vs. 56 Bytes\n\n![The 56-Byte Boundary Case \u2014 Two Blocks](./diagrams/diag-m1-boundary-case-56-bytes.svg)\n\nThis is the most common source of bugs in SHA-256 implementations. Pay close attention.\nA 512-bit block is 64 bytes. The last 8 bytes are reserved for the 64-bit length field. The byte before that must contain the `0x80` marker. This means there must be at least `8 + 1 = 9` bytes available after the last message byte *within the current block*.\nTherefore:\n- If your message is **55 bytes or shorter**: you can fit `0x80`, zero padding, and the 8-byte length field into a single 64-byte block. \u2713\n- If your message is **56 bytes or longer**: the `0x80` byte is placed in position 56 (zero-indexed), leaving room for 7 bytes before the block ends \u2014 not enough for the 8-byte length field. You must spill into a **second block**.\nThe 56-byte boundary case looks like this:\n```\nBlock 1 (64 bytes):\n  [56 bytes of message][0x80][7 bytes of 0x00]\nBlock 2 (64 bytes):\n  [56 bytes of 0x00][8-byte big-endian length]\n```\nThe second block is almost entirely zeros, with the length field at the very end. This feels wasteful, but it is *required* by the specification. Any implementation that tries to \"fit\" the length into block 1 by truncating the zero padding is wrong.\n**The formula for number of padding blocks:**\n```c\n/*\n * Given message length in bytes, compute the total padded length in bytes.\n * Result is always a multiple of 64 (512 bits).\n */\nsize_t sha256_padded_length(size_t msg_len) {\n    /*\n     * After the message, we need:\n     *   1 byte  for the 0x80 marker\n     *   8 bytes for the 64-bit length field\n     *   = 9 bytes minimum\n     *\n     * Then round up to next 64-byte boundary.\n     */\n    return ((msg_len + 9 + 63) / 64) * 64;\n}\n```\nLet's verify:\n- `msg_len = 3` (\"abc\"): `(3 + 9 + 63) / 64 = 75 / 64 = 1` block \u2192 `1 \u00d7 64 = 64` bytes \u2713\n- `msg_len = 55`: `(55 + 9 + 63) / 64 = 127 / 64 = 1` block \u2192 `64` bytes \u2713\n- `msg_len = 56`: `(56 + 9 + 63) / 64 = 128 / 64 = 2` blocks \u2192 `128` bytes \u2713\n- `msg_len = 0` (empty): `(0 + 9 + 63) / 64 = 72 / 64 = 1` block \u2192 `64` bytes \u2713\nThe integer division truncates, and the `+ 63` ensures we round *up* to the next boundary. This is a standard C idiom for ceiling division.\n---\n## Tracing the Empty Input\n\n![Trace: Empty Input Padding](./diagrams/diag-m1-empty-input-trace.svg)\n\nThe empty message is a powerful test case because it exercises every part of padding in isolation \u2014 there is no message content to distract you.\n```\nSHA-256(\"\") = e3b0c44298fc1c149afbf4c8996fb924\n              27ae41e4649b934ca495991b7852b855\n```\nThe padded block for the empty message looks like:\n```\nByte 0:    0x80   \u2190 the '1' bit (message length L = 0 bits)\nBytes 1-55: 0x00  \u2190 zero fill\nBytes 56-63: 0x00 00 00 00 00 00 00 00  \u2190 64-bit length of 0 bits\n```\nThe total block is 64 bytes, all zeros except the very first byte which is `0x80`. If your implementation produces this block and passes it to the compression function with the correct initial hash state, you'll get the SHA-256 hash of the empty string. This is a critical test because you can verify the block independently of the compression function.\n---\n## Implementing the Padding Function\nNow let's build it. Here is the complete implementation plan, followed by the code.\n### Data Structures\n```c\n#include <stdint.h>\n#include <stddef.h>\n#include <string.h>\n#define SHA256_BLOCK_SIZE  64   /* 512 bits */\n#define SHA256_DIGEST_SIZE 32   /* 256 bits */\n```\n`uint8_t` is the C standard library's unsigned 8-bit integer type \u2014 exactly one byte. `uint64_t` is unsigned 64-bit. Using these types instead of `int` or `unsigned long` makes the code portable across platforms where `int` might be 16 or 64 bits. Include `<stdint.h>` to get them.\n### The Padding Function\n```c\n/*\n * sha256_pad: pad a message according to FIPS 180-4 Section 5.1.1\n *\n * Parameters:\n *   out     - output buffer; caller must allocate sha256_padded_length(msg_len) bytes\n *   msg     - input message bytes\n *   msg_len - number of bytes in msg\n *\n * Returns:\n *   total number of bytes written to out (always a multiple of 64)\n */\nsize_t sha256_pad(uint8_t *out, const uint8_t *msg, size_t msg_len) {\n    /* Step 1: copy the original message */\n    memcpy(out, msg, msg_len);\n    /* Step 2: append the 0x80 byte (the '1' bit marker) */\n    out[msg_len] = 0x80;\n    /* Step 3: compute total padded length */\n    size_t total = ((msg_len + 9 + 63) / 64) * 64;\n    /* Step 4: zero out everything between 0x80 and the length field */\n    size_t zero_start = msg_len + 1;\n    size_t zero_end   = total - 8;\n    memset(out + zero_start, 0, zero_end - zero_start);\n    /* Step 5: write the 64-bit message length in bits, big-endian */\n    uint64_t bit_length = (uint64_t)msg_len * 8;\n    write_uint64_be(out + total - 8, bit_length);\n    return total;\n}\n```\nWalk through each step:\n**Step 1** (`memcpy`): Copy the raw message bytes verbatim. SHA-256 operates on the message as-is \u2014 no encoding, no transformation.\n**Step 2** (`out[msg_len] = 0x80`): The byte immediately after the message becomes `0x80`, which in binary is `1000 0000`. The high bit is the required `1` bit from the spec. The remaining 7 bits of this byte are already the first 7 zero bits of the zero-fill.\n**Step 3** (ceiling division formula): Compute how large the padded output needs to be. We've seen this formula already.\n**Step 4** (`memset`): Clear the region between the `0x80` byte and the 8 bytes reserved for the length. The `zero_end - zero_start` expression computes how many bytes to zero.\n**Step 5** (`write_uint64_be`): Write the original message length *in bits* (not bytes!) as a big-endian 64-bit integer into the last 8 bytes of the padded buffer.\n> \u26a0\ufe0f **Critical pitfall**: The length field stores *bit count*, not byte count. For a 3-byte message, write `24` (= 3 \u00d7 8), not `3`. This is specified in FIPS 180-4 and is the value you must use \u2014 `(uint64_t)msg_len * 8`.\n### Block Parsing\nOnce you have the padded byte array, you need to split it into 64-byte (512-bit) blocks for sequential processing. For now, the parser is straightforward \u2014 just a pointer into your padded buffer:\n```c\n/*\n * sha256_get_block: return a pointer to the i-th 512-bit (64-byte) block\n *                   within a padded message buffer.\n *\n * Parameters:\n *   padded_msg - the fully padded message buffer\n *   block_idx  - zero-based block index\n *\n * Returns:\n *   pointer to the first byte of the requested block\n */\nconst uint8_t *sha256_get_block(const uint8_t *padded_msg, size_t block_idx) {\n    return padded_msg + (block_idx * SHA256_BLOCK_SIZE);\n}\n/*\n * sha256_num_blocks: compute the number of 512-bit blocks in a padded message.\n */\nsize_t sha256_num_blocks(size_t padded_len) {\n    return padded_len / SHA256_BLOCK_SIZE;\n}\n```\nIn Milestone 2, when you implement the message schedule, you'll call `sha256_get_block(padded, i)` and then parse each 64-byte block into sixteen 32-bit words. For now, the block parser is simply an offset calculation.\n---\n## Testing Your Implementation\nTest-driven development is essential for cryptographic code. Unlike application logic, there is no \"close enough\" \u2014 a single wrong bit produces a completely different hash. Test each layer before proceeding.\n### Test 1: Empty Input\n```c\n#include <stdio.h>\n#include <assert.h>\n#include <string.h>\nvoid test_empty_input(void) {\n    uint8_t out[64];\n    size_t len = sha256_pad(out, NULL, 0);\n    /* padded length must be exactly one block */\n    assert(len == 64);\n    /* first byte must be 0x80 */\n    assert(out[0] == 0x80);\n    /* bytes 1 through 55 must be 0x00 */\n    for (int i = 1; i <= 55; i++) {\n        assert(out[i] == 0x00);\n    }\n    /* bytes 56 through 63 must encode 0 in big-endian */\n    for (int i = 56; i <= 63; i++) {\n        assert(out[i] == 0x00);\n    }\n    printf(\"PASS: empty input \u2192 one 512-bit block, 0x80 at byte 0, zero length\\n\");\n}\n```\n> \u26a0\ufe0f Note: Passing `NULL` as the message pointer when `msg_len = 0` requires that your `sha256_pad` implementation skips the `memcpy` when `msg_len == 0`. Add a guard: `if (msg_len > 0) memcpy(out, msg, msg_len);`\n### Test 2: \"abc\" \u2014 3-byte message\n```c\nvoid test_abc_padding(void) {\n    const uint8_t msg[] = { 0x61, 0x62, 0x63 };  /* \"abc\" */\n    uint8_t out[64];\n    size_t len = sha256_pad(out, msg, 3);\n    assert(len == 64);  /* exactly one block */\n    /* first three bytes: the message */\n    assert(out[0] == 0x61);  /* 'a' */\n    assert(out[1] == 0x62);  /* 'b' */\n    assert(out[2] == 0x63);  /* 'c' */\n    /* byte 3: 0x80 */\n    assert(out[3] == 0x80);\n    /* bytes 4-55: zeros */\n    for (int i = 4; i <= 55; i++) {\n        assert(out[i] == 0x00);\n    }\n    /* bytes 56-63: 24 in big-endian (3 bytes * 8 bits = 24 bits) */\n    assert(out[56] == 0x00);\n    assert(out[57] == 0x00);\n    assert(out[58] == 0x00);\n    assert(out[59] == 0x00);\n    assert(out[60] == 0x00);\n    assert(out[61] == 0x00);\n    assert(out[62] == 0x00);\n    assert(out[63] == 0x18);  /* 24 = 0x18 */\n    printf(\"PASS: 'abc' (3 bytes) \u2192 one 512-bit block\\n\");\n}\n```\n### Test 3: The 56-byte boundary case\nThis is the test that will break na\u00efve implementations. A 56-byte message must produce **two** blocks.\n```c\nvoid test_56_byte_boundary(void) {\n    /* 56 bytes: this forces the two-block case */\n    uint8_t msg[56];\n    memset(msg, 0x41, 56);  /* fill with 'A' */\n    uint8_t out[128];       /* two blocks: 128 bytes */\n    size_t len = sha256_pad(out, msg, 56);\n    assert(len == 128);  /* MUST be two blocks */\n    /* bytes 0-55: the message */\n    for (int i = 0; i < 56; i++) {\n        assert(out[i] == 0x41);\n    }\n    /* byte 56: 0x80 */\n    assert(out[56] == 0x80);\n    /* bytes 57-119: zeros (fills rest of block 1 + most of block 2) */\n    for (int i = 57; i <= 119; i++) {\n        assert(out[i] == 0x00);\n    }\n    /* bytes 120-127: 448 (= 56 * 8) in big-endian */\n    /* 448 = 0x00000000000001C0 */\n    assert(out[120] == 0x00);\n    assert(out[121] == 0x00);\n    assert(out[122] == 0x00);\n    assert(out[123] == 0x00);\n    assert(out[124] == 0x00);\n    assert(out[125] == 0x00);\n    assert(out[126] == 0x01);\n    assert(out[127] == 0xC0);  /* 448 = 0x1C0, split as 0x01, 0xC0 */\n    printf(\"PASS: 56-byte message \u2192 two 512-bit blocks\\n\");\n}\n```\n### Test 4: 55-byte message (one block, last safe case)\n```c\nvoid test_55_byte_boundary(void) {\n    uint8_t msg[55];\n    memset(msg, 0x41, 55);\n    uint8_t out[64];\n    size_t len = sha256_pad(out, msg, 55);\n    assert(len == 64);  /* one block: 55 is still safe */\n    /* byte 55: 0x80 (immediately after last message byte) */\n    assert(out[55] == 0x80);\n    /* bytes 56-63: 440 in big-endian (55 * 8 = 440 = 0x1B8) */\n    assert(out[56] == 0x00);\n    assert(out[57] == 0x00);\n    assert(out[58] == 0x00);\n    assert(out[59] == 0x00);\n    assert(out[60] == 0x00);\n    assert(out[61] == 0x00);\n    assert(out[62] == 0x01);\n    assert(out[63] == 0xB8);  /* 440 = 0x01B8 */\n    printf(\"PASS: 55-byte message \u2192 one 512-bit block\\n\");\n}\n```\n### Running All Tests\n```c\nint main(void) {\n    test_empty_input();\n    test_abc_padding();\n    test_55_byte_boundary();\n    test_56_byte_boundary();\n    printf(\"\\nAll padding tests passed.\\n\");\n    return 0;\n}\n```\nCompile and run:\n```bash\ngcc -Wall -Wextra -o test_padding test_padding.c sha256_pad.c\n./test_padding\n```\nIf every assert passes, your padding function is correct. If any assert fires, you have a concrete byte-level debugging target \u2014 check the exact offset that failed.\n---\n## Putting It Together: The Complete Module\nHere is a clean header file that defines the padding interface you'll use in later milestones:\n```c\n/* sha256_pad.h */\n#ifndef SHA256_PAD_H\n#define SHA256_PAD_H\n#include <stdint.h>\n#include <stddef.h>\n#define SHA256_BLOCK_SIZE  64   /* bytes per 512-bit block */\n#define SHA256_DIGEST_SIZE 32   /* bytes in final hash */\n/*\n * Compute the total padded length for a message of msg_len bytes.\n * Always a multiple of SHA256_BLOCK_SIZE.\n */\nsize_t sha256_padded_length(size_t msg_len);\n/*\n * Write the padded message into out[].\n * out must have at least sha256_padded_length(msg_len) bytes.\n * Returns the number of bytes written.\n */\nsize_t sha256_pad(uint8_t *out, const uint8_t *msg, size_t msg_len);\n/*\n * Return a pointer to the i-th 512-bit block in a padded message.\n */\nconst uint8_t *sha256_get_block(const uint8_t *padded_msg, size_t block_idx);\n/*\n * Compute the number of 512-bit blocks in a padded message.\n */\nsize_t sha256_num_blocks(size_t padded_len);\n#endif /* SHA256_PAD_H */\n```\n---\n## Common Pitfalls and Debugging Checklist\nHere are the exact mistakes that break padding implementations, ranked by how often they appear:\n**Pitfall 1: Forgetting the extra block at 56 bytes**\nYour `sha256_padded_length` returns 64 bytes for a 56-byte message. Check: `(56 + 9 + 63) / 64` should equal `2`. If your formula gives `1`, you have an off-by-one.\n**Pitfall 2: Length field in bytes instead of bits**\nYou write `msg_len` instead of `msg_len * 8`. For \"abc\", the length field should be `24`, not `3`. Always multiply by 8.\n**Pitfall 3: Wrong endianness in the length field**\nYou write the length as little-endian (least significant byte first). On x86, `*(uint64_t*)(out + 56) = bit_length` will store it little-endian. Use the `write_uint64_be` function shown above \u2014 never cast a buffer pointer to a wider integer type for this purpose.\n**Pitfall 4: Off-by-one in the `0x80` byte position**\nYou write `out[msg_len - 1] = 0x80` instead of `out[msg_len] = 0x80`. The marker goes *after* the last message byte, at index `msg_len`.\n**Pitfall 5: Buffer too small**\nYou allocate `64` bytes for the output and pass in a 56-byte message. The padded output needs `128` bytes. Always call `sha256_padded_length(msg_len)` to determine the required allocation.\n**Debugging technique**: When your hash output is wrong, print the padded block in hexadecimal and compare byte-by-byte with the expected values from the test cases above. The padding stage can be fully verified independently of the compression function.\n---\n## Knowledge Cascade: What You've Actually Learned\nYou just built message padding for SHA-256. But the concepts you used appear everywhere in cryptography and systems programming.\n### 1. Length Extension \u2192 Why HMAC Exists\nThe 64-bit length field you just implemented is a direct defense against length extension attacks. But here's the twist: SHA-256 alone *still* isn't safe when used as `SHA256(secret || message)`. The attacker knows the padded length of the original message, so they can still extend it by starting from the known hash output and feeding new blocks. This is why HMAC computes `SHA256(key XOR opad || SHA256(key XOR ipad || message))` \u2014 the double nesting prevents any state from being a valid starting point for extension. Your padding makes SHA-256 collision-resistant; HMAC is what makes it safe for message authentication.\n### 2. Padding in Block Cipher Modes (AES-CBC)\nAES processes data in 128-bit blocks, and AES-CBC (Cipher Block Chaining) faces the exact same boundary problem you just solved: what do you do when the plaintext doesn't divide evenly into 128-bit blocks? The answer is PKCS#7 padding \u2014 append `n` bytes each with value `n`, where `n` is the number of bytes needed to reach the next block boundary. Different scheme, same fundamental problem: block-oriented algorithms need unambiguous padding. When you debug AES-CBC padding oracle attacks (a real class of vulnerabilities), you'll recognize this problem instantly.\n### 3. Protocol Framing (TLS Records, TCP, HTTP/2)\nThe pattern of \"length field + data\" appears in nearly every binary protocol. TLS records start with a 3-byte length. TCP segments carry a 16-bit length. HTTP/2 frames begin with a 24-bit length. All of these solve the same problem you just solved: how does the receiver know where one message ends and the next begins? In SHA-256, the length encodes the *original* message length to prevent ambiguity during hashing. In network protocols, the length encodes the *payload size* so the receiver knows how many bytes to read. The design tension \u2014 \"where does this message end?\" \u2014 is universal.\n### 4. Merkle-Damg\u00e5rd and Its Successors\nSHA-256 uses Merkle-Damg\u00e5rd construction, and you've just implemented the padding that makes it secure. But MD has a known structural weakness: length extension. This is why SHA-3 uses a completely different structure called a **sponge construction** (Keccak), which absorbs input bits into an internal state and squeezes output from it. The sponge design eliminates length extension attacks by construction, without needing the specific padding trick you implemented. Knowing MD's padding intimately makes SHA-3's design choices immediately legible.\n### 5. Off-by-One Discipline\nThe 55/56 byte boundary is your first encounter with the kind of exact boundary that causes buffer overflows and security vulnerabilities. The habit you build here \u2014 testing exact boundaries, not just \"small\" and \"large\" inputs \u2014 is directly applicable to buffer overflow analysis. When reviewing security-critical C code, experienced engineers always test `n - 1`, `n`, and `n + 1` at every boundary. You just learned why.\n---\n## Summary: What You Built and Why It Matters\nIn this milestone you built three things:\n1. **A padding function** that converts arbitrary byte sequences into padded, length-encoded, 512-bit-aligned buffers \u2014 following FIPS 180-4 exactly.\n2. **A block parser** that returns a pointer to any 512-bit block within the padded buffer.\n3. **A test suite** that validates the boundary cases that break na\u00efve implementations.\nEvery byte you placed is there for a reason: the `0x80` marker prevents ambiguity between messages differing in trailing zeros, the zero fill reaches the block boundary, and the 64-bit length field prevents length extension attacks and is the cornerstone of Merkle-Damg\u00e5rd strengthening.\nIn Milestone 2, you will take each 64-byte block and parse it into sixteen 32-bit words \u2014 then expand those sixteen words into sixty-four words using the \u03c30 and \u03c31 functions. The blocks you are producing here are the direct input to that expansion. If your padding is correct, the message schedule will be correct. If your padding is off by one byte, every subsequent computation will be wrong, and the final hash will be completely different from the expected value.\nRun your tests. Verify the boundary cases. Then move on.\n---\n<!-- END_MS -->\n\n\n<!-- MS_ID: hash-impl-m2 -->\n<!-- MS_ID: hash-impl-m2 -->\n# Milestone 2: Message Schedule Generation\n## Where We Are in the Pipeline\n\n![SHA-256 Complete Pipeline \u2014 Satellite Map](./diagrams/diag-L0-satellite-map.svg)\n\nYou just built a padding function that transforms any message into a sequence of clean, 512-bit blocks. Now the question is: what does the compression function actually *do* with those blocks?\nThe answer surprises most people. The compression function does not consume raw block bytes directly. It consumes a carefully constructed **64-word message schedule** derived from those bytes. Your 512-bit block is 64 bytes = 16 four-byte words. But the compression function needs 64 words \u2014 one per round. Your job in this milestone is to generate the extra 48 words.\nThis sounds like a bookkeeping detail. It is not. The message schedule is where SHA-256's most important structural property is established: the **avalanche effect**. Before you write a line of code, you need to understand what the schedule is actually building and why it must be built this way.\n---\n## The Misconception Worth Shattering\nHere is what experienced programmers assume when they first read the SHA-256 spec:\n> \"The schedule is just padding for the compression function. You have 16 words of input, you need 64 words, so you 'stretch' the data somehow \u2014 maybe by repeating it, or computing some weighted average of adjacent words. It's a bookkeeping step.\"\nThis model predicts something: changing W[0] (the first input word) should mostly affect W[16] and W[17] \u2014 the first few expanded words \u2014 and the effect should decay as you move further into the schedule.\nLet's test that prediction. Take the \"abc\" message block. Flip a single bit in W[0] \u2014 say, the low bit \u2014 changing it from `0x61626380` to `0x61626381`. What happens to the 64-word schedule?\nThe honest answer: **every single word from W[16] onward will be different**. Not \"mostly the same with a few bit flips.\" Completely, thoroughly scrambled. By W[63], roughly half of all bits will have flipped. The perturbation has spread to every corner of the schedule.\nThis is not stretching. This is **diffusion** \u2014 the cryptographic property that ensures changes in the input spread throughout the output. The message schedule is not bookkeeping; it is the first layer of SHA-256's cryptographic strength, and the \u03c3 functions are engineered to maximize it.\n---\n## What You're Actually Building: A Dependency Web\n\n![Message Schedule Expansion \u2014 Data Dependency Walk](./diagrams/diag-m2-schedule-expansion-data-walk.svg)\n\nThe recurrence relation that defines the message schedule is:\n```\nW[t] = \u03c31(W[t-2]) + W[t-7] + \u03c30(W[t-15]) + W[t-16]    (mod 2\u00b3\u00b2)\n```\nfor `t = 16, 17, ..., 63`.\nRead this carefully. Each new word W[t] depends on **four** previously computed words. Not two, not three \u2014 four, spread at carefully chosen distances (2, 7, 15, 16). This is not an accident. The distances were selected through extensive cryptanalysis to break up the regular patterns that an attacker might exploit.\nThink of it as a **dependency web**: W[16] depends on W[14], W[9], W[1], and W[0]. W[17] depends on W[15], W[10], W[2], and W[1]. W[18] depends on W[16], W[11], W[3], and W[2] \u2014 but W[16] itself depends on W[0] and W[1], so W[18] transitively depends on those too. By the time you reach W[63], it has a transitive dependency on every one of the original 16 words.\nNow add the \u03c3 functions. Each \u03c3 function takes its input word, applies three different bitwise operations (two rotations and one shift), and XORs the results together. This mixing means that even if the dependency graph connected words in a simple chain, the values would still be thoroughly scrambled. The combination of a spread-out dependency graph *and* aggressive bit mixing at each step is what creates the avalanche.\nThe \u03c3 functions are where most of this milestone's implementation lives. Let's understand them precisely.\n---\n## Right Rotation vs. Right Shift: The Critical Distinction\n{{DIAGRAM:diag-m2-rotr-vs-shr}}\nBefore you can implement \u03c30 and \u03c31, you need to internalize the difference between two operations that look similar and behave very differently. This distinction matters enough to give it its own section.\n**Right shift (SHR)** shifts all bits toward the least-significant position. Bits that fall off the right end are destroyed. The vacated positions on the left are filled with zeros.\n```\nSHR(0b10110100, 2) = 0b00101101\n                       ^^\n                       two new zeros on the left\n                       the rightmost two bits vanished\n```\n**Right rotation (ROTR)** shifts all bits toward the least-significant position, but bits that fall off the right end wrap around and appear on the left. No bits are destroyed.\n```\nROTR(0b10110100, 2) = 0b00101101\n                              ^^\nWait \u2014 let's be more careful with 8 bits:\nOriginal:   1  0  1  1  0  1  0  0\nPositions:  7  6  5  4  3  2  1  0\nROTR 2 means each bit moves to position (current - 2) mod 8.\nBit at position 1 \u2192 position 7 (wraps around)\nBit at position 0 \u2192 position 6 (wraps around)\nResult:     0  0  1  0  1  1  0  1\n                        ^^  ^^\n                        bits from positions 1 and 0\n                        are now at positions 7 and 6\n```\nIn C, with 32-bit unsigned integers, these operations look like:\n```c\n#include <stdint.h>\n/* Right shift: bits fall off the right, zeros fill on the left */\nuint32_t shr(uint32_t x, int n) {\n    return x >> n;\n}\n/* Right rotation: bits wrap from right to left */\nuint32_t rotr(uint32_t x, int n) {\n    return (x >> n) | (x << (32 - n));\n}\n```\nThe `rotr` implementation combines two shifts with a bitwise OR:\n- `x >> n` shifts right by n, dropping n bits off the right edge\n- `x << (32 - n)` shifts left by `(32 - n)`, which moves those same dropped bits to the top\nBecause `x` is `uint32_t` (an unsigned 32-bit type), the left shift `x << (32 - n)` naturally wraps at 32 bits. The two halves fit together perfectly, reconstructing all 32 bits with no information loss.\n> \u26a0\ufe0f **One edge case**: if `n == 0`, then `32 - n == 32`, and shifting a 32-bit integer by 32 is undefined behavior in C. In practice, SHA-256 never calls ROTR with n=0 (the constants are 2, 6, 7, 11, 13, 17, 18, 19, 22, 25), but it's good practice to be aware of this.\n**Why does SHA-256 use both?** The \u03c3 functions use ROTR twice and SHR once. The two rotations are *reversible* \u2014 given ROTR(x, 7), you can recover x by doing ROTR(x, 32-7). The shift is *irreversible* \u2014 SHR destroys information. This combination matters cryptographically: the irreversibility introduced by SHR means you can't simply invert the \u03c3 function. An attacker cannot work backwards from known schedule words to recover the original input words. The intentional information destruction is a security feature, not a bug.\n> \ud83d\udd2d **Deep Dive**: ROTR appears everywhere in hardware-efficient cryptography. AES MixColumns, CRC computation, and many error-correcting codes use rotation because it is a single instruction on modern CPUs (`ROR` on x86, `ROR` on ARM). The Intel Architecture Reference Manual, Volume 2, Section \"ROR \u2014 Rotate Right\" describes the instruction. Understanding ROTR as a primitive makes the instruction-level implementation of these algorithms immediately readable.\n---\n## The \u03c3 Functions: Precise Specification\n{{DIAGRAM:diag-m2-sigma0-computation}}\nFIPS 180-4, Section 4.1.2 defines the lowercase sigma functions as:\n```\n\u03c30(x) = ROTR(x, 7) XOR ROTR(x, 18) XOR SHR(x, 3)\n\u03c31(x) = ROTR(x, 17) XOR ROTR(x, 19) XOR SHR(x, 10)\n```\n(Note: in the spec, these are written with a lowercase \u03c3. In the compression function, there are uppercase \u03a3 functions with completely different constants. You'll build those in Milestone 3. Keep them separate in your mind \u2014 they are not interchangeable.)\nLet's implement both:\n```c\n/*\n * sigma0: used in message schedule expansion\n * \u03c30(x) = ROTR(x,7) XOR ROTR(x,18) XOR SHR(x,3)\n */\nstatic uint32_t sigma0(uint32_t x) {\n    return rotr(x, 7) ^ rotr(x, 18) ^ (x >> 3);\n}\n/*\n * sigma1: used in message schedule expansion\n * \u03c31(x) = ROTR(x,17) XOR ROTR(x,19) XOR SHR(x,10)\n */\nstatic uint32_t sigma1(uint32_t x) {\n    return rotr(x, 17) ^ rotr(x, 19) ^ (x >> 10);\n}\n```\nThe `static` keyword means these functions are local to their translation unit (the `.c` file). This is good C practice \u2014 these are internal helper functions, not part of the public API.\n**Verify your \u03c3 functions against known values before writing anything else.** The NIST SHA-256 example document (linked in your resources) provides intermediate schedule values for the \"abc\" message. Here is the first few:\nFor the \"abc\" message, after parsing the padded block, `W[1] = 0x62636380`. Let's compute `\u03c30(W[1])`:\n```\nx = 0x62636380\nROTR(x, 7):\n  x in binary:  0110 0010 0110 0011 0110 0011 1000 0000\n  Rotate right 7:\n  Low 7 bits of x: 000 0000 \u2192 move to top\n  Result:        0000 000 | 0110 0010 0110 0011 0110 0011 1\n  = 0x00C4C6C7... let's compute precisely:\n  x = 0x62636380\n  x >> 7  = 0x00C4C6C7\n  x << 25 = 0x00000000  (the low 7 bits of 0x62636380 are all 0)\n  ROTR(x,7) = 0x00C4C6C7\nROTR(x, 18):\n  x >> 18 = 0x00001898\n  x << 14 = 0x8E000000\n  ROTR(x,18) = 0x8E001898\nSHR(x, 3):\n  x >> 3  = 0x0C4C6C70\n\u03c30(x) = 0x00C4C6C7 XOR 0x8E001898 XOR 0x0C4C6C70\n       = 0x00C4C6C7\n         XOR 0x8E001898\n         ----------\n         = 0x8EC4DED F\n         XOR 0x0C4C6C70\n         ----------\n       = let's compute column by column...\n```\nRather than tracing the full arithmetic here, the point is: **write a small test program that prints `sigma0(0x62636380)` and compare it against the NIST example document.** This is exactly the debugging methodology that makes cryptographic implementation tractable \u2014 test each primitive in isolation against the spec before assembling them.\n---\n## Big-Endian Word Extraction\n\n![Block to Words \u2014 Big-Endian 32-bit Parsing](./diagrams/diag-m2-word-extraction.svg)\n\nYour `sha256_get_block()` function from Milestone 1 returns a pointer to 64 bytes. The message schedule needs those 64 bytes interpreted as 16 four-byte unsigned integers, in big-endian order.\n**Big-endian** means the most significant byte comes first in memory. The 32-bit word `0x61626380` (which is what \"abc\\x80\" looks like when read as four bytes) is stored as:\n```\nMemory address:   +0    +1    +2    +3\nByte content:    0x61  0x62  0x63  0x80\n                  ^                  ^\n                  most significant   least significant\n```\nOn a little-endian machine (x86), if you simply cast the byte pointer to `uint32_t*` and read it, you'd get `0x80636261` \u2014 the bytes in reverse order. This produces wrong schedule words, and consequently the completely wrong hash. This is a silent bug: the code compiles, runs, and produces output, just not the SHA-256 output.\nThe correct approach is to read four bytes explicitly and shift-assemble the word:\n```c\n/*\n * Read 4 bytes from buf starting at byte offset i,\n * interpreting them as a big-endian 32-bit unsigned integer.\n */\nstatic uint32_t read_uint32_be(const uint8_t *buf, size_t i) {\n    return ((uint32_t)buf[i    ] << 24)\n         | ((uint32_t)buf[i + 1] << 16)\n         | ((uint32_t)buf[i + 2] <<  8)\n         | ((uint32_t)buf[i + 3] <<  0);\n}\n```\nWalk through this for `buf = {0x61, 0x62, 0x63, 0x80}` at `i = 0`:\n```\nbuf[0] = 0x61 \u2192 0x61 << 24 = 0x61000000\nbuf[1] = 0x62 \u2192 0x62 << 16 = 0x00620000\nbuf[2] = 0x63 \u2192 0x63 <<  8 = 0x00006300\nbuf[3] = 0x80 \u2192 0x80 <<  0 = 0x00000080\nOR them together:          = 0x61626380\n```\nThat's the correct big-endian interpretation. The cast `(uint32_t)buf[i]` is important: `buf[i]` is a `uint8_t` (8 bits). If you write `buf[i] << 24` without the cast, the shift may operate on a signed integer and produce implementation-defined behavior (potentially wrong results on some platforms). Always cast to the destination type before shifting.\nNow parse all 16 initial words from a block:\n```c\n/*\n * sha256_parse_block: extract 16 big-endian 32-bit words from a 64-byte block.\n *\n * Parameters:\n *   block - pointer to 64 bytes (one 512-bit block from the padded message)\n *   W     - output array of at least 16 uint32_t values\n */\nstatic void sha256_parse_block(const uint8_t *block, uint32_t *W) {\n    for (int i = 0; i < 16; i++) {\n        W[i] = read_uint32_be(block, i * 4);\n    }\n}\n```\nEach word starts at byte offset `i * 4`, since each word is 4 bytes wide.\n---\n## Modular Arithmetic and 32-bit Masking\n\n![32-bit Masking \u2014 What Happens Without It](./diagrams/diag-m2-masking-before-after.svg)\n\nThe recurrence relation adds four 32-bit words together:\n```\nW[t] = \u03c31(W[t-2]) + W[t-7] + \u03c30(W[t-15]) + W[t-16]\n```\nEach term is a 32-bit unsigned integer. The sum of four 32-bit unsigned integers can be as large as `4 \u00d7 (2\u00b3\u00b2 - 1) \u2248 1.7 \u00d7 10\u00b9\u2070`, which does not fit in 32 bits. The SHA-256 specification says this addition is **mod 2\u00b3\u00b2**: any overflow past 32 bits is simply discarded.\n**In C, with `uint32_t`, this happens automatically.** Unsigned integer arithmetic in C is defined to wrap around at the type's maximum value. If `a` and `b` are both `uint32_t`, then `a + b` is also `uint32_t`, and any carry beyond bit 31 silently disappears. No masking required.\n```c\nuint32_t a = 0xFFFFFFFF;  /* 2^32 - 1 */\nuint32_t b = 0x00000002;  /* 2 */\nuint32_t c = a + b;       /* = 0x00000001, the carry beyond bit 31 is lost */\n/* c == 1 */\n```\nThis is not an accident or a compiler quirk \u2014 it is guaranteed by the C standard (C11 \u00a76.2.5/9): \"A computation involving unsigned operands can never overflow, because a result that cannot be represented by the resulting unsigned integer type is reduced modulo the number that is one greater than the largest value that can be represented by the resulting type.\"\nSo `uint32_t` arithmetic is exactly what the spec means by \"mod 2\u00b3\u00b2.\" You get it for free in C. This is one of the main reasons C is the ideal language for implementing SHA-256: the type system is a direct expression of the spec.\n> \ud83d\udd2d **Deep Dive**: In Python, integers have arbitrary precision \u2014 `0xFFFFFFFF + 2` gives `0x100000001`, a 33-bit value. This is why Python SHA-256 implementations must explicitly mask every addition: `(a + b) & 0xFFFFFFFF`. The masking discipline you'd need there is implicitly handled by `uint32_t` in C. If you ever port this implementation to Python or JavaScript, every single addition in the schedule and compression function needs that mask. Forgetting even one produces a subtly wrong intermediate value that diverges from the spec a few rounds later, producing a completely wrong final hash.\n---\n## The Complete Schedule Generation Function\nNow you have all the pieces. Here is the full message schedule generation:\n```c\n/*\n * sha256_schedule: generate the 64-word message schedule from a 512-bit block.\n *\n * Parameters:\n *   block - pointer to 64 bytes (one 512-bit block)\n *   W     - output array of exactly 64 uint32_t values\n *\n * After this call, W[0..63] contains the message schedule for this block.\n */\nvoid sha256_schedule(const uint8_t *block, uint32_t W[64]) {\n    /* Step 1: parse the block into 16 big-endian 32-bit words */\n    sha256_parse_block(block, W);  /* fills W[0]..W[15] */\n    /* Step 2: extend to 64 words using the recurrence relation */\n    for (int t = 16; t < 64; t++) {\n        W[t] = sigma1(W[t - 2])\n             + W[t - 7]\n             + sigma0(W[t - 15])\n             + W[t - 16];\n        /*\n         * In C, uint32_t addition wraps at 2^32 automatically.\n         * No explicit masking needed here.\n         */\n    }\n}\n```\nSix lines of substantive code for the entire schedule expansion. Every line maps directly to a clause in FIPS 180-4. This is what good specification-to-code translation looks like.\nNote the order of terms in the addition. The spec writes it as \u03c31(W[t-2]) + W[t-7] + \u03c30(W[t-15]) + W[t-16]. Your C code follows the same order. Commutativity of addition means any order produces the same numerical result, but matching the spec order makes comparison and debugging easier.\n---\n## Tracing the \"abc\" Message Schedule\nTo verify your implementation, let's trace the first few steps of the \"abc\" schedule. After padding, the block's first 16 words are:\n```\nW[ 0] = 0x61626380  ('a','b','c', 0x80)\nW[ 1] = 0x00000000\nW[ 2] = 0x00000000\nW[ 3] = 0x00000000\nW[ 4] = 0x00000000\nW[ 5] = 0x00000000\nW[ 6] = 0x00000000\nW[ 7] = 0x00000000\nW[ 8] = 0x00000000\nW[ 9] = 0x00000000\nW[10] = 0x00000000\nW[11] = 0x00000000\nW[12] = 0x00000000\nW[13] = 0x00000000\nW[14] = 0x00000000\nW[15] = 0x00000018  (24 = 0x18, the bit-length of \"abc\")\n```\nThe message block is almost entirely zeros, with the message bytes in W[0] and the bit-length `24` in W[15]. This is a good sanity check for your word extraction: if you see `0x80636261` for W[0] instead of `0x61626380`, your endianness is wrong.\nNow compute W[16]:\n```\nW[16] = \u03c31(W[14]) + W[9] + \u03c30(W[1]) + W[0]\n      = \u03c31(0x00000000) + 0x00000000 + \u03c30(0x00000000) + 0x61626380\n```\nWhat is \u03c30(0) and \u03c31(0)?\n```\n\u03c30(0) = ROTR(0, 7) XOR ROTR(0, 18) XOR SHR(0, 3)\n       = 0 XOR 0 XOR 0\n       = 0\n\u03c31(0) = ROTR(0, 17) XOR ROTR(0, 19) XOR SHR(0, 10)\n       = 0 XOR 0 XOR 0\n       = 0\n```\nSo:\n```\nW[16] = 0 + 0 + 0 + 0x61626380 = 0x61626380\n```\nThe schedule barely changes for the first few words because most input words are zero. But watch what happens when W[15] (the nonzero length word) starts influencing things at W[30]:\n```\nW[30] = \u03c31(W[28]) + W[23] + \u03c30(W[15]) + W[14]\n```\nNow `\u03c30(W[15]) = \u03c30(0x00000018)` involves real bit rotation of a nonzero value, and the result contributes to W[30], W[31], W[32], ..., cascading forward.\nThe NIST SHA-256 example document provides all 64 schedule words for the \"abc\" input. After you implement the schedule function, print all 64 words and compare them line by line against the NIST values. This is your primary correctness check for this milestone.\n---\n## Why These Constants? The Avalanche Argument\nYou might wonder: why 7, 18, and 3 for \u03c30? Why 17, 19, and 10 for \u03c31? Why not 1, 2, 3 or some other arbitrary choices?\nThe rotation and shift constants were selected through cryptanalytic analysis. Here's the intuition:\nFor a 32-bit word, you want the three outputs (ROTR by two amounts, SHR by one amount) to \"cover\" the bit positions as differently as possible \u2014 maximizing the independence of each output. If two rotations use very similar amounts (e.g., ROTR 7 and ROTR 8), the resulting outputs share most of their bits, and XORing them cancels much of the information. You want the rotations spread out enough that each output contributes genuinely new bit information.\nThe shift distances were also chosen so that the \u03c3 functions interact well with the dependency distances (2, 7, 15, 16) in the recurrence. Cryptanalysts attack hash functions using **differential cryptanalysis** \u2014 they track how carefully chosen bit-difference patterns in the input propagate through the function. The specific constants in SHA-256 were chosen to make these differential paths fail to produce collisions efficiently.\nThe short version: these constants are not arbitrary. They emerged from a design process informed by attacks on earlier hash functions (MD4, MD5, SHA-0, SHA-1). For SHA-0 vs. SHA-1: SHA-0 omitted a single rotation in the message schedule, and this omission allowed Wang Xiaoyun to find practical collisions in 2004. SHA-1 added that rotation and collapsed to a safe design (for a while). SHA-256 generalized this lesson into a richer, more aggressively mixing schedule.\n> \ud83d\udd2d **Deep Dive**: The connection between message schedule design and differential cryptanalysis is explored in detail in Stevens, Lenstra, and de Weger's \"Chosen-Prefix Collisions for MD5 and Colliding X.509 Certificates for Different Identities\" (Eurocrypt 2007). For SHA-256 specifically, Nikoli\u0107 and Biryukov's \"Collisions for Step-Reduced SHA-256\" (FSE 2008) shows what happens when you reduce the number of rounds \u2014 and by implication, why 64 rounds with the full schedule is the chosen design point.\n---\n## Implementing and Testing the Complete Module\nHere is the complete module header and implementation:\n```c\n/* sha256_schedule.h */\n#ifndef SHA256_SCHEDULE_H\n#define SHA256_SCHEDULE_H\n#include <stdint.h>\n#include <stddef.h>\n/*\n * Generate the 64-word message schedule from a 512-bit (64-byte) block.\n *\n * Parameters:\n *   block - pointer to exactly 64 bytes (one 512-bit block)\n *   W     - output array of 64 uint32_t values\n *\n * W[0..15] will contain the 16 big-endian 32-bit words parsed from the block.\n * W[16..63] will contain the expanded schedule words.\n */\nvoid sha256_schedule(const uint8_t *block, uint32_t W[64]);\n#endif /* SHA256_SCHEDULE_H */\n```\n```c\n/* sha256_schedule.c */\n#include \"sha256_schedule.h\"\n#include <stdint.h>\n/* ------------------------------------------------------------------ */\n/* Internal helpers                                                     */\n/* ------------------------------------------------------------------ */\nstatic uint32_t rotr(uint32_t x, int n) {\n    return (x >> n) | (x << (32 - n));\n}\nstatic uint32_t sigma0(uint32_t x) {\n    return rotr(x, 7) ^ rotr(x, 18) ^ (x >> 3);\n}\nstatic uint32_t sigma1(uint32_t x) {\n    return rotr(x, 17) ^ rotr(x, 19) ^ (x >> 10);\n}\nstatic uint32_t read_uint32_be(const uint8_t *buf, size_t i) {\n    return ((uint32_t)buf[i    ] << 24)\n         | ((uint32_t)buf[i + 1] << 16)\n         | ((uint32_t)buf[i + 2] <<  8)\n         | ((uint32_t)buf[i + 3] <<  0);\n}\nstatic void sha256_parse_block(const uint8_t *block, uint32_t *W) {\n    for (int i = 0; i < 16; i++) {\n        W[i] = read_uint32_be(block, (size_t)i * 4);\n    }\n}\n/* ------------------------------------------------------------------ */\n/* Public API                                                           */\n/* ------------------------------------------------------------------ */\nvoid sha256_schedule(const uint8_t *block, uint32_t W[64]) {\n    sha256_parse_block(block, W);\n    for (int t = 16; t < 64; t++) {\n        W[t] = sigma1(W[t -  2])\n             + W[t -  7]\n             + sigma0(W[t - 15])\n             + W[t - 16];\n    }\n}\n```\n### Test Suite\n```c\n/* test_schedule.c */\n#include <stdio.h>\n#include <string.h>\n#include <assert.h>\n#include <stdint.h>\n#include \"sha256_pad.h\"\n#include \"sha256_schedule.h\"\n/*\n * Test 1: word extraction \u2014 verify \"abc\" block parses to correct W[0] and W[15]\n */\nvoid test_word_extraction(void) {\n    /* Build the padded \"abc\" block */\n    const uint8_t msg[] = { 0x61, 0x62, 0x63 };\n    uint8_t padded[64];\n    sha256_pad(padded, msg, 3);\n    uint32_t W[64];\n    sha256_schedule(padded, W);\n    /* First word: bytes 0-3 of the padded block = 'a','b','c',0x80 */\n    assert(W[0] == 0x61626380);\n    /* Word at index 15: the 64-bit length field occupies bytes 56-63.\n     * Words 14 and 15 correspond to bytes 56-59 and 60-63.\n     * Bytes 56-59 = 0x00000000, bytes 60-63 = 0x00000018 (24 in big-endian) */\n    assert(W[14] == 0x00000000);\n    assert(W[15] == 0x00000018);\n    printf(\"PASS: word extraction \u2014 W[0]=0x%08X, W[15]=0x%08X\\n\", W[0], W[15]);\n}\n/*\n * Test 2: sigma functions \u2014 verify against known values\n * \u03c30(0x61626380):\n *   ROTR(0x61626380, 7)  = 0x00C4C4C7  (check your computation)\n *   ROTR(0x61626380, 18) = ...\n *   SHR (0x61626380, 3)  = 0x0C2C4C70\n */\nvoid test_sigma_functions(void) {\n    /* \u03c30 and \u03c31 of zero should be zero */\n    /* We test via the schedule: W[1] through W[13] are all 0x00000000,\n     * so W[16] = \u03c31(W[14]) + W[9] + \u03c30(W[1]) + W[0]\n     *          = \u03c31(0)     + 0    + \u03c30(0)     + 0x61626380\n     *          = 0 + 0 + 0 + 0x61626380\n     *          = 0x61626380  */\n    const uint8_t msg[] = { 0x61, 0x62, 0x63 };\n    uint8_t padded[64];\n    sha256_pad(padded, msg, 3);\n    uint32_t W[64];\n    sha256_schedule(padded, W);\n    /* W[16] must equal 0x61626380 given all-zero surrounding words */\n    assert(W[16] == 0x61626380);\n    printf(\"PASS: W[16] = 0x%08X (expected 0x61626380)\\n\", W[16]);\n    /* \n     * Verify W[17]: W[17] = \u03c31(W[15]) + W[10] + \u03c30(W[2]) + W[1]\n     * W[15] = 0x00000018, W[10] = 0, W[2] = 0, W[1] = 0\n     * W[17] = \u03c31(0x00000018) + 0 + 0 + 0\n     *\n     * \u03c31(0x00000018):\n     *   ROTR(0x00000018, 17) = 0x000C0000\n     *   ROTR(0x00000018, 19) = 0x00030000\n     *   SHR (0x00000018, 10) = 0x00000000  (0x18 = 24, shifted right 10 = 0)\n     *   \u03c31(0x00000018) = 0x000C0000 XOR 0x00030000 XOR 0 = 0x000F0000\n     */\n    assert(W[17] == 0x000F0000);\n    printf(\"PASS: W[17] = 0x%08X (expected 0x000F0000)\\n\", W[17]);\n}\n/*\n * Test 3: full schedule against NIST example values\n * These W[] values for the \"abc\" input are from the NIST SHA-256 example document.\n */\nvoid test_full_schedule_abc(void) {\n    const uint8_t msg[] = { 0x61, 0x62, 0x63 };\n    uint8_t padded[64];\n    sha256_pad(padded, msg, 3);\n    uint32_t W[64];\n    sha256_schedule(padded, W);\n    /* NIST known values for \"abc\" message schedule (partial) */\n    /* From NIST SHA-256 Example Computations document */\n    struct { int idx; uint32_t val; } known[] = {\n        {  0, 0x61626380 },\n        { 15, 0x00000018 },\n        { 16, 0x61626380 },\n        { 17, 0x000F0000 },\n        { 18, 0x636B6361 },  /* verify against NIST document */\n        { 19, 0x70746162 },  /* verify against NIST document */\n    };\n    /*\n     * NOTE TO IMPLEMENTER: Replace the values for indices 18 and 19 with\n     * the actual values from the NIST SHA-256 example document\n     * (https://csrc.nist.gov/CSRC/media/Projects/Cryptographic-Standards-\n     *  and-Guidelines/documents/examples/SHA256.pdf).\n     * The exact values depend on the \u03c3 function outputs cascading through\n     * the recurrence.\n     */\n    for (size_t i = 0; i < sizeof(known) / sizeof(known[0]); i++) {\n        if (W[known[i].idx] != known[i].val) {\n            printf(\"FAIL: W[%d] = 0x%08X, expected 0x%08X\\n\",\n                   known[i].idx, W[known[i].idx], known[i].val);\n        }\n    }\n    printf(\"PASS: schedule generation matches known values\\n\");\n}\n/*\n * Print all 64 schedule words for visual comparison with NIST document.\n */\nvoid print_schedule(void) {\n    const uint8_t msg[] = { 0x61, 0x62, 0x63 };\n    uint8_t padded[64];\n    sha256_pad(padded, msg, 3);\n    uint32_t W[64];\n    sha256_schedule(padded, W);\n    printf(\"\\nMessage schedule for 'abc':\\n\");\n    for (int i = 0; i < 64; i++) {\n        printf(\"W[%02d] = 0x%08X\\n\", i, W[i]);\n    }\n}\nint main(void) {\n    test_word_extraction();\n    test_sigma_functions();\n    test_full_schedule_abc();\n    print_schedule();\n    printf(\"\\nAll schedule tests passed.\\n\");\n    return 0;\n}\n```\nCompile and run:\n```bash\ngcc -Wall -Wextra -o test_schedule test_schedule.c sha256_schedule.c sha256_pad.c\n./test_schedule\n```\nThe `print_schedule()` function is your debugging superpower. When the final hash is wrong in Milestone 4, you'll come back here, print the schedule, and compare word-by-word against the NIST document. **Never debug a 64-round compression failure without first verifying the schedule is correct.** The compression function is effectively a black box on top of the schedule \u2014 if the schedule is wrong, every hash will be wrong, and the error is here.\n---\n## Common Pitfalls and How to Catch Them\n**Pitfall 1: Swapping \u03c30 and \u03c31 constants**\nThe most dangerous mistake. \u03c30 uses (7, 18, 3) and \u03c31 uses (17, 19, 10). Getting these backwards produces a schedule that *looks* plausible \u2014 no crashes, no assertion failures unless you check specific values \u2014 but diverges immediately from the NIST reference values. Your first test should always be W[16] and W[17] (where the sigma functions are applied to known values), before testing any larger indices.\n**Pitfall 2: Confusing ROTR with SHR**\nWriting `(x >> n)` for both operations instead of `(x >> n) | (x << (32 - n))` for ROTR. These produce very different results for nonzero inputs. If \u03c30(0x61626380) doesn't match the NIST reference, check whether you used SHR where you meant ROTR.\n**Pitfall 3: Reading the block as little-endian**\nWriting `*((uint32_t*)(block + i*4))` instead of using `read_uint32_be()`. On x86, this reads the bytes in reversed order. Your W[0] will be `0x80636261` instead of `0x61626380`. The hash will be wrong for all non-trivial inputs. This is also undefined behavior in C (violating strict aliasing rules), even if it produces the \"right\" wrong answer on some platforms.\n**Pitfall 4: Wrong recurrence indices**\nWriting `W[t-1]` instead of `W[t-2]` for \u03c31, or `W[t-16]` instead of `W[t-15]` for \u03c30. The indices matter and are asymmetric: \u03c31 looks back 2, the plain addition looks back 7 and 16, \u03c30 looks back 15. One wrong index and the schedule diverges from NIST values starting at W[16] or W[17].\n**Pitfall 5: Using signed integers**\nDeclaring `W` as `int W[64]` instead of `uint32_t W[64]`. In C, right-shifting a negative signed integer produces implementation-defined behavior (on most platforms, arithmetic right shift fills with the sign bit rather than zeros). `SHR(x, 3)` must be a logical shift (filling with zeros), which only works correctly with unsigned types.\n---\n## Knowledge Cascade: What the Schedule Connects To\n### 1. Avalanche Effect \u2014 The First Measurable Cryptographic Property\nThe message schedule is the first place in SHA-256 where you can see the avalanche effect with your own hands. Take your schedule, change W[0] from `0x61626380` to `0x61626381` (flip the lowest bit), and print all 64 words. Count the bits that differ from the original schedule.\nBy W[63], you'll find roughly 50% of the bits have flipped. This is not an approximation \u2014 it's the target of the design. The avalanche effect is what makes it computationally infeasible to find two messages that produce the same hash: even messages differing by one bit produce completely different schedules, which produce completely different compression state sequences, which produce completely different final hashes. You can measure this property directly from your implementation.\n### 2. Linear Feedback Shift Registers (LFSRs) \u2014 A Structural Relative\nThe SHA-256 schedule recurrence `W[t] = \u03c31(W[t-2]) + W[t-7] + \u03c30(W[t-15]) + W[t-16]` has a structural similarity to **Linear Feedback Shift Registers**, a foundational primitive in stream ciphers. An LFSR takes the last N bits of an output sequence, XORs them in a linear combination, and feeds the result back into the register. Stream ciphers like those used in A5/1 (used in GSM phone encryption) and Trivium are built from LFSRs. The SHA-256 schedule uses word-level feedback with nonlinear \u03c3 functions instead of bit-level linear feedback \u2014 the nonlinearity of \u03c3 (due to the SHR, which destroys bits) is what prevents an attacker from analyzing the schedule with linear algebra. If SHA-256 used only ROTR and XOR (without SHR), the schedule would be a linear function and vulnerable to linear cryptanalysis.\n### 3. GF(2) and Finite Field Arithmetic\nThe XOR operations in \u03c30 and \u03c31 are not arbitrary. XOR is **addition in GF(2)** \u2014 the Galois field with two elements, where 1 + 1 = 0 (no carry). Every bit of the XOR output is computed by a degree-1 polynomial over GF(2) of the input bits. This connects SHA-256's bit operations to abstract algebra and the theory of error-correcting codes (Reed-Solomon, BCH codes). Cryptanalysts studying SHA-256's resistance to differential attacks are essentially studying polynomials over GF(2) and GF(2\u00b3\u00b2). Understanding XOR as field addition makes the next step \u2014 formally analyzing the schedule's diffusion properties \u2014 a matter of algebra rather than empiricism.\n> \ud83d\udd2d **Deep Dive**: Finite field arithmetic and its role in cryptography is covered thoroughly in Alfred Menezes, Paul van Oorschot, and Scott Vanstone's *Handbook of Applied Cryptography* (freely available at https://cacr.uwaterloo.ca/hac/), Chapter 2 \"Mathematics Background\" and Chapter 7 \"Block Ciphers.\"\n### 4. CRC-32 and Checksum Computation\nThe `uint32_t` masking discipline you're internalizing here applies directly to CRC-32 (Cyclic Redundancy Check) computation, which you'll find in Ethernet frames, zip files, PNG images, and USB packets. CRC-32 also operates on 32-bit polynomials over GF(2), uses XOR as its core operation, and requires careful treatment of unsigned arithmetic to avoid sign-extension bugs. Once you've debugged a SHA-256 schedule where you forgot `uint32_t`, you'll never make the analogous mistake in CRC-32 or Adler-32 (the checksum used in zlib) implementations.\n### 5. CPU Barrel Shifters and ROTR as a Hardware Primitive\nModern CPUs implement rotation as a single instruction because it is so common in cryptographic and hashing workloads. On x86-64, the instruction is `ROR` (rotate right). On ARM, it's `ROR` as well, and ARM has a dedicated **barrel shifter** in many instructions that can fold a rotation into another operation at no extra clock cost. When you write `rotr(x, 7)` in C, a good compiler (`gcc -O2` or `clang -O2`) will recognize the idiom `(x >> n) | (x << (32 - n))` and emit a single `ROR` instruction. You can verify this with `gcc -O2 -S sha256_schedule.c` and reading the assembly output. Understanding that your C is compiling to single hardware instructions explains why SHA-256 throughput is measured in hundreds of megabytes per second on modern hardware.\n---\n## Summary: What You Built and What It Means\nIn this milestone you built three things:\n1. **A big-endian word extractor** that converts a 64-byte block into 16 correctly ordered 32-bit words \u2014 portable across platforms that use different native byte orders.\n2. **The \u03c30 and \u03c31 functions** implementing ROTR-ROTR-SHR with the precise rotation constants from FIPS 180-4, using only `uint32_t` arithmetic that wraps at 32 bits by definition.\n3. **The 64-word message schedule** generated by the recurrence relation, creating a dependency web where each of the original 16 input words eventually influences all 64 schedule words.\nThe schedule is not padding or bookkeeping. It is the first stage of SHA-256's diffusion \u2014 the property that spreads input bits across the entire computation. Changing one input bit changes roughly half the bits in the full 64-word schedule, which in turn changes the entire compression function output. This is why SHA-256 is collision-resistant: finding two messages that produce the same schedule, and then the same compression output, is computationally equivalent to breaking the entire hash function.\nIn Milestone 3, you'll use these 64 schedule words as inputs to the compression function \u2014 64 rounds of mixing using the Ch, Maj, \u03a30, and \u03a31 functions. The compression function is where the hash state is actually transformed. But its security depends entirely on the schedule you just built. If your schedule is correct, the compression function has the right input for each round. Verify your schedule against the NIST reference values before proceeding.\nPrint your W[0] through W[63] for \"abc\". Compare against the NIST document. Then move on.\n---\n<!-- END_MS -->\n\n\n<!-- MS_ID: hash-impl-m3 -->\n<!-- MS_ID: hash-impl-m3 -->\n# Milestone 3: Compression Function\n## Where We Are in the Pipeline\n\n![SHA-256 Complete Pipeline \u2014 Satellite Map](./diagrams/diag-L0-satellite-map.svg)\n\nYou have built two of SHA-256's three stages. Your padding function converts arbitrary messages into 512-bit-aligned blocks. Your schedule generator expands each 64-byte block into 64 carefully mixed 32-bit words. Now the question is: what actually happens to those words?\nThis is where the hash is made. The **compression function** takes the current 256-bit hash state and one block's 64-word schedule, and produces a new 256-bit hash state. Run it over every block, and at the end you have SHA-256's output. Everything you built before feeds into this function. Everything you'll build in Milestone 4 reads from it.\nThe compression function is also where SHA-256's cryptographic strength is concentrated. Before you write a single line of code, you need to understand something that almost every developer gets wrong when reading the spec for the first time.\n---\n## The Revelation: 64 Rounds Is Not Paranoia\n\n![64 Rounds Overview \u2014 State Propagation Across Full Block](./diagrams/diag-m3-full-64-rounds-overview.svg)\n\nHere is the assumption most developers make when they first see \"64 rounds\":\n> \"The hash function processes data 64 times to be 'extra secure.' Surely 8 or 16 rounds would be good enough \u2014 the rest is conservative over-engineering. The Ch and Maj functions are just some arbitrary boolean operations that add noise.\"\nThis model is wrong in a way that has been measured precisely by cryptanalysts. Let's make the wrongness concrete.\nIn 2012, Biryukov and Khovratovich published a collision attack on **31-round SHA-256** \u2014 a version of the compression function with the first 31 of 64 rounds. They could find two different inputs that produced the same output when processed by 31 rounds. Not quickly, and not practically on today's hardware, but the attack *exists*. The security margin is gone.\nThe full 64-round SHA-256 has no known collision attack. The gap between 31 (broken) and 64 (unbroken) is not wasted computation \u2014 it is a measured **security budget**. Every round you add makes attacks exponentially harder. The 33 extra rounds are what separates \"theoretically breakable by cryptanalysts with a paper\" from \"computationally infeasible to break with all the world's computers.\"\nThe same thinking governs AES: 128-bit key AES uses 10 rounds, 192-bit uses 12, 256-bit uses 14. Each additional round adds margin beyond the best known attacks. The number of rounds in a modern cipher or hash function is the output of cryptanalytic analysis, not arbitrary caution.\nNow for Ch and Maj. They are not arbitrary. They are the result of a precise requirement from Boolean algebra.\nA **balanced boolean function** of three variables is a function where, over all 8 possible inputs (8 combinations of three bits), exactly 4 outputs are 0 and 4 are 1. Balance is necessary for cryptographic security \u2014 an unbalanced function introduces statistical bias that differential cryptanalysis can exploit.\nAmong all balanced boolean functions of three variables, Ch and Maj are the only two that provide **optimal non-linearity** \u2014 meaning they cannot be approximated well by any linear function (a function built only from XOR and constants). Non-linearity is what makes the difference between a cryptographic operation and a checksum. XOR is perfectly linear; any number of XOR operations can be expressed as a single XOR. Ch and Maj introduce algebraic complexity that XOR cannot.\nCh(x, y, z) = (x AND y) XOR (NOT x AND z)\nRead it in plain English: **if x is 1, output y; if x is 0, output z**. It is a bit-level multiplexer \u2014 the same circuit you'd find in a CPU's 2-to-1 MUX gate. For each bit position independently, x selects which of the other two inputs to pass through.\nMaj(x, y, z) = (x AND y) XOR (x AND z) XOR (y AND z)\nRead it: **output 1 if and only if at least two of the three inputs are 1**. It is a majority vote \u2014 the same circuit used in fault-tolerant computing, where three redundant systems vote on the correct result.\nThe pairing of Ch and Maj is deliberate. Ch operates on variables `{e, f, g}` \u2014 the variables that T1 updates. Maj operates on variables `{a, b, c}` \u2014 the variables that T2 updates. They introduce two independent sources of non-linearity into the state update, ensuring that the compression function resists both differential and linear attacks simultaneously.\nThe round constants K[t] are the third piece of this design. They serve as **nothing-up-my-sleeve numbers** \u2014 a transparency mechanism. If the constants were chosen arbitrarily by the designers, an attacker might suspect a backdoor: constants specifically chosen to create a hidden weakness. By deriving K[t] from the cube roots of primes (a fixed, verifiable mathematical process), the designers prove they had no freedom to choose constants that might introduce weaknesses. Anyone can verify: take the 64th prime (311), compute 311^(1/3) \u2248 6.757..., take the fractional part (0.757...), multiply by 2\u00b3\u00b2 (\u2248 3,254,779,648), and the first 32 bits are 0xC19BF174 \u2014 which is K[63]. The math is public and checkable. No backdoor is possible.\n> \ud83d\udd2d **Deep Dive**: The concept of nothing-up-my-sleeve numbers has a fascinating controversy: the NIST P-256 elliptic curve parameters were generated from a seed whose origin was never explained, unlike SHA-256's verifiable derivation. This asymmetry is one reason many cryptographers prefer curves like Curve25519, whose parameters (such as the prime 2\u00b2\u2075\u2075 - 19) are derived from criteria explained upfront. See Daniel J. Bernstein and Tanja Lange's \"SafeCurves\" project (https://safecurves.cr.yp.to) for a systematic comparison of curve parameter transparency.\nNow you see the design as a system: **\u03a3 rotations provide diffusion** (spreading bits across the word), **Ch and Maj provide non-linear confusion** (making the function impossible to approximate linearly), **modular addition provides additional non-linearity** (the carry propagation is deeply nonlinear in GF(2)), and **K constants prevent round symmetry** (ensuring each of 64 rounds behaves differently). Remove any one piece and the security argument collapses.\n---\n## Three Levels of the Compression Function\nThe compression function operates at three distinct levels. Understanding all three prevents the most common implementation bugs.\n**Level 1 \u2014 Protocol Structure**: The compression function takes two inputs (256-bit state, 512-bit block) and produces one output (256-bit updated state). This is the Merkle-Damg\u00e5rd compression step. The security of the entire hash function *reduces* to the security of this single function \u2014 if the compression function is collision-resistant, the full hash is collision-resistant. You are implementing the security primitive that makes the whole system work.\n**Level 2 \u2014 Round Structure**: Inside the compression function, 64 rounds execute sequentially. Each round consumes one schedule word W[t] and one round constant K[t], and transforms an 8-variable state (a, b, c, d, e, f, g, h) into a new 8-variable state. The state transformation is not symmetric \u2014 variables move through the pipeline asymmetrically, with T1 feeding into `e` (the middle of the state) and T2 combining with T1 to produce `a` (the front).\n**Level 3 \u2014 Bit-Level Operations**: Inside each round, the operations \u2014 ROTR, AND, XOR, NOT, modular addition \u2014 produce specific algebraic properties. ROTR is a permutation (reversible, no information loss). AND introduces non-linearity (1 AND 0 \u2260 average of inputs). XOR is linear over GF(2). Modular addition carries non-linearity through carry propagation. The combination creates a function that is both non-linear and non-invertible.\n---\n## The Working Variables: 8 Registers Holding the Hash State\n\n![Working Variable Rotation Across 4 Rounds](./diagrams/diag-m3-variable-rotation-state-evolution.svg)\n\nThe compression function maintains eight 32-bit working variables named `a` through `h`. Before processing any block, these are initialized from the current hash state:\n```c\nuint32_t a = H[0];\nuint32_t b = H[1];\nuint32_t c = H[2];\nuint32_t d = H[3];\nuint32_t e = H[4];\nuint32_t f = H[5];\nuint32_t g = H[6];\nuint32_t h = H[7];\n```\nThink of `a` through `h` as eight CPU registers holding the current compression state. At the start of processing the very first block, `H[0]` through `H[7]` are SHA-256's **initial hash values** \u2014 fixed constants derived from the fractional parts of the square roots of the first eight primes (2, 3, 5, 7, 11, 13, 17, 19). You'll set these up in Milestone 4. For now, treat `H[]` as the 8-element array that carries hash state between blocks.\nAfter 64 rounds of transformation, the variables `a` through `h` hold values that are a complex function of both the original state *and* all 64 schedule words. The **state update** step then feeds these back into the hash state:\n```c\nH[0] += a;\nH[1] += b;\nH[2] += c;\nH[3] += d;\nH[4] += e;\nH[5] += f;\nH[6] += g;\nH[7] += h;\n```\nIn C with `uint32_t`, the `+=` wraps at 2\u00b3\u00b2 automatically. This is the **Davies-Meyer construction**: the compression function's output is the XOR (here, addition mod 2\u00b3\u00b2) of the compression function applied to the current state and the current state itself. This feed-forward of the original state is what makes the compression function one-way \u2014 given the output of one compression step, you cannot determine the input because you'd need to subtract an unknown original state.\n---\n## The Uppercase \u03a3 Functions: Diffusion Within the State\n\n![\u03a3 (Compression) vs. \u03c3 (Schedule) \u2014 Constant Comparison](./diagrams/diag-m3-sigma-uppercase-vs-lowercase.svg)\n\nIn Milestone 2 you implemented \u03c30 and \u03c31 (lowercase sigma) for the message schedule. The compression function uses \u03a30 and \u03a31 (uppercase Sigma) with completely different rotation constants. This is the most common point of confusion, so let's make it explicit before showing the code.\n| Function | Used in | Formula |\n|----------|---------|---------|\n| \u03c30 (lowercase) | Message schedule | ROTR(x,7) \u2295 ROTR(x,18) \u2295 SHR(x,3) |\n| \u03c31 (lowercase) | Message schedule | ROTR(x,17) \u2295 ROTR(x,19) \u2295 SHR(x,10) |\n| \u03a30 (uppercase) | Compression, applied to `a` | ROTR(x,2) \u2295 ROTR(x,13) \u2295 ROTR(x,22) |\n| \u03a31 (uppercase) | Compression, applied to `e` | ROTR(x,6) \u2295 ROTR(x,11) \u2295 ROTR(x,25) |\nNotice that \u03a30 and \u03a31 use only ROTR \u2014 no SHR. This is intentional. In the message schedule, the SHR in \u03c3 functions destroys information to make the schedule non-invertible. In the compression function, the \u03a3 functions are used alongside Ch and Maj which already provide non-linearity. The pure ROTR in \u03a3 functions maximizes diffusion while Ch and Maj supply the algebraic non-linearity.\nThe rotation constants for \u03a3 are also spread further apart than \u03c3: (2, 13, 22) and (6, 11, 25) cover a wider range of the 32-bit word, ensuring that each output bit depends on input bits from across the entire word. The specific values were chosen through the same cryptanalytic analysis process as the schedule constants.\nHere are the implementations in C:\n```c\n#include <stdint.h>\n/* Right rotation \u2014 already implemented in Milestone 2, repeated here for clarity */\nstatic uint32_t rotr(uint32_t x, int n) {\n    return (x >> n) | (x << (32 - n));\n}\n/*\n * Sigma0 (uppercase): used in compression function, applied to variable 'a'\n * \u03a30(x) = ROTR(x,2) XOR ROTR(x,13) XOR ROTR(x,22)\n */\nstatic uint32_t Sigma0(uint32_t x) {\n    return rotr(x, 2) ^ rotr(x, 13) ^ rotr(x, 22);\n}\n/*\n * Sigma1 (uppercase): used in compression function, applied to variable 'e'\n * \u03a31(x) = ROTR(x,6) XOR ROTR(x,11) XOR ROTR(x,25)\n */\nstatic uint32_t Sigma1(uint32_t x) {\n    return rotr(x, 6) ^ rotr(x, 11) ^ rotr(x, 25);\n}\n```\nNaming convention: in your C code, use `Sigma0`/`Sigma1` (capital S) for the compression functions and `sigma0`/`sigma1` (lowercase s) for the schedule functions. This directly mirrors the spec notation and prevents the most common mix-up.\n---\n## Ch and Maj: The Non-Linear Heart\n\n![Ch(x,y,z) \u2014 The Choice Function as Multiplexer](./diagrams/diag-m3-ch-function-truth-table.svg)\n\nBefore implementing Ch and Maj, understand what they do at the bit level \u2014 not just as formulas but as operations with intuitive meaning.\n### Ch \u2014 The Choice Function\n```\nCh(x, y, z) = (x AND y) XOR (NOT x AND z)\n```\nFor each bit position independently:\n- If the corresponding bit of `x` is **1**: the output bit equals the corresponding bit of `y`\n- If the corresponding bit of `x` is **0**: the output bit equals the corresponding bit of `z`\n`x` chooses between `y` and `z`, bit by bit. This is a 2-to-1 multiplexer at the bit level.\nTruth table for a single bit:\n| x | y | z | Ch(x,y,z) |\n|---|---|---|-----------|\n| 0 | 0 | 0 | 0 |\n| 0 | 0 | 1 | 1 |\n| 0 | 1 | 0 | 0 |\n| 0 | 1 | 1 | 1 |\n| 1 | 0 | 0 | 0 |\n| 1 | 0 | 1 | 0 |\n| 1 | 1 | 0 | 1 |\n| 1 | 1 | 1 | 1 |\nCount the 1s in the output column: exactly 4 out of 8 possible inputs. Ch is balanced. The output is 0 as often as 1, over all inputs. If it were unbalanced, an attacker could use the bias to distinguish the compression function's output from random data \u2014 the first step toward finding structure to exploit.\n```c\n/*\n * Ch (Choice): if x then y else z, bit-by-bit\n * Ch(x,y,z) = (x AND y) XOR (NOT x AND z)\n */\nstatic uint32_t Ch(uint32_t x, uint32_t y, uint32_t z) {\n    return (x & y) ^ (~x & z);\n}\n```\nThe `~x` in C produces the bitwise NOT of `x` for a `uint32_t`. Since `x` is unsigned, `~x` flips all 32 bits correctly. If `x` were a signed int, `~x` would still work bitwise but the type semantics would be confusing \u2014 another reason to use `uint32_t` throughout.\nAn equivalent formulation you'll sometimes see is:\n```c\nstatic uint32_t Ch_alt(uint32_t x, uint32_t y, uint32_t z) {\n    return z ^ (x & (y ^ z));\n}\n```\nBoth produce identical outputs. The alternative uses one fewer NOT operation and is sometimes preferred for hardware implementation where NOT costs a gate. For software on a CPU, both compile to essentially the same instructions. Use whichever matches the FIPS 180-4 spec notation you're reading \u2014 it makes debugging against the spec easier.\n{{DIAGRAM:diag-m3-maj-function-truth-table}}\n### Maj \u2014 The Majority Vote Function\n```\nMaj(x, y, z) = (x AND y) XOR (x AND z) XOR (y AND z)\n```\nFor each bit position independently: output 1 if at least two of the three inputs are 1. It is a majority vote.\nTruth table for a single bit:\n| x | y | z | Maj(x,y,z) |\n|---|---|---|------------|\n| 0 | 0 | 0 | 0 |\n| 0 | 0 | 1 | 0 |\n| 0 | 1 | 0 | 0 |\n| 0 | 1 | 1 | 1 |\n| 1 | 0 | 0 | 0 |\n| 1 | 0 | 1 | 1 |\n| 1 | 1 | 0 | 1 |\n| 1 | 1 | 1 | 1 |\nAgain, exactly 4 ones out of 8 inputs. Balanced, and the balance is different from Ch's pattern \u2014 Maj outputs 1 when the count of ones is 2 or 3, Ch outputs 1 according to x's selection. The two functions partition the input space differently, providing independent non-linear mixing.\n```c\n/*\n * Maj (Majority): output 1 if at least 2 of the 3 inputs are 1, bit-by-bit\n * Maj(x,y,z) = (x AND y) XOR (x AND z) XOR (y AND z)\n */\nstatic uint32_t Maj(uint32_t x, uint32_t y, uint32_t z) {\n    return (x & y) ^ (x & z) ^ (y & z);\n}\n```\nAn equivalent (and slightly more efficient) alternative:\n```c\nstatic uint32_t Maj_alt(uint32_t x, uint32_t y, uint32_t z) {\n    return (x & y) | (z & (x | y));\n}\n```\nAgain, both are correct. The spec form with three XORs is most directly verifiable against FIPS 180-4 notation. Use it.\n---\n## The Round Constants K[0..63]\n\n![K Constants \u2014 From Primes to 32-bit Values](./diagrams/diag-m3-k-constants-origin.svg)\n\nEach of the 64 rounds uses a unique 32-bit constant K[t]. These are the first 32 bits of the fractional parts of the cube roots of the first 64 prime numbers.\nFor example: the first prime is 2. The cube root of 2 is 1.2599210... The fractional part is 0.2599210... Multiplied by 2\u00b3\u00b2 and truncated to an integer: 0.2599210... \u00d7 4,294,967,296 \u2248 1,116,352,408 = 0x428A2F98. That is K[0].\nYou do not need to compute these. FIPS 180-4 Section 4.2.2 specifies all 64 values and you should copy them verbatim. Copying them wrong is a real and common mistake \u2014 always verify your K array against the spec or a known-good reference before debugging any further.\nHere is the complete K array as a C array literal:\n```c\n/*\n * SHA-256 round constants.\n * Source: FIPS 180-4, Section 4.2.2.\n * These are the first 32 bits of the fractional parts of the cube roots\n * of the first 64 prime numbers.\n */\nstatic const uint32_t K[64] = {\n    0x428A2F98, 0x71374491, 0xB5C0FBCF, 0xE9B5DBA5,\n    0x3956C25B, 0x59F111F1, 0x923F82A4, 0xAB1C5ED5,\n    0xD807AA98, 0x12835B01, 0x243185BE, 0x550C7DC3,\n    0x72BE5D74, 0x80DEB1FE, 0x9BDC06A7, 0xC19BF174,\n    0xE49B69C1, 0xEFBE4786, 0x0FC19DC6, 0x240CA1CC,\n    0x2DE92C6F, 0x4A7484AA, 0x5CB0A9DC, 0x76F988DA,\n    0x983E5152, 0xA831C66D, 0xB00327C8, 0xBF597FC7,\n    0xC6E00BF3, 0xD5A79147, 0x06CA6351, 0x14292967,\n    0x27B70A85, 0x2E1B2138, 0x4D2C6DFC, 0x53380D13,\n    0x650A7354, 0x766A0ABB, 0x81C2C92E, 0x92722C85,\n    0xA2BFE8A1, 0xA81A664B, 0xC24B8B70, 0xC76C51A3,\n    0xD192E819, 0xD6990624, 0xF40E3585, 0x106AA070,\n    0x19A4C116, 0x1E376C08, 0x2748774C, 0x34B0BCB5,\n    0x391C0CB3, 0x4ED8AA4A, 0x5B9CCA4F, 0x682E6FF3,\n    0x748F82EE, 0x78A5636F, 0x84C87814, 0x8CC70208,\n    0x90BEFFFA, 0xA4506CEB, 0xBEF9A3F7, 0xC67178F2\n};\n```\n> \u26a0\ufe0f **Verification step**: Before proceeding, count the entries: 16 per row \u00d7 4 rows = 64. Check that K[0] = 0x428A2F98 and K[63] = 0xC67178F2 against your copy of FIPS 180-4. If either is wrong, your hash will fail all test vectors, and the bug will be very hard to isolate \u2014 it produces wrong output on every single input with no obvious pattern.\nThe nothing-up-my-sleeve property of these constants means every round behaves differently. Without unique constants, many rounds would be symmetric under certain bit-flip patterns, enabling differential attacks that exploit that symmetry. K[t] breaks the symmetry, ensuring that a bit flip in the input that cancels out in one round cannot also cancel out in the next.\n---\n## Anatomy of One Compression Round\n\n![T1 and T2 Computation \u2014 Detailed Data Flow](./diagrams/diag-m3-t1-t2-data-flow.svg)\n\nEach round computes two temporary values, T1 and T2, then updates the working variables. Here is the round formula from FIPS 180-4, Section 6.2.2:\n```\nT1 = h + \u03a31(e) + Ch(e,f,g) + K[t] + W[t]\nT2 = \u03a30(a) + Maj(a,b,c)\nh = g\ng = f\nf = e\ne = d + T1\nd = c\nc = b\nb = a\na = T1 + T2\n```\nAll additions are mod 2\u00b3\u00b2. In C with `uint32_t`, this is automatic.\nLet's understand each piece of T1 and T2 before seeing the code.\n**T1 = h + \u03a31(e) + Ch(e,f,g) + K[t] + W[t]**\n- `h`: the current \"tail\" variable \u2014 the word that has been shifted through the pipeline the longest without being updated\n- `\u03a31(e)`: diffusion applied to the \"control\" variable `e` (which drives Ch)\n- `Ch(e,f,g)`: non-linear mixing selecting between `f` and `g` based on `e`\n- `K[t]`: the round constant, ensuring this round is unique\n- `W[t]`: the message schedule word, injecting message content into the state\nT1 is a sum of five values, each coming from a different part of the state or from external inputs. The wide fanin (five sources) ensures that T1 is a function of virtually all current state bits plus the message schedule.\n**T2 = \u03a30(a) + Maj(a,b,c)**\n- `\u03a30(a)`: diffusion applied to `a`, the \"head\" variable\n- `Maj(a,b,c)`: majority vote over the three most recent \"head\" variables\nT2 is the \"other half\" of the state update, operating on the front of the pipeline (a, b, c) independently from T1's operation on the back (e, f, g, h).\n**The variable shift:**\n```\nh = g; g = f; f = e; e = d + T1;\nd = c; c = b; b = a; a = T1 + T2;\n```\nAll eight variables shift one position to the right in the pipeline, like a shift register. But two assignments break the pure shift: `e` receives `d + T1` (injecting T1 into the middle of the pipeline), and `a` receives `T1 + T2` (injecting the full update at the front). This asymmetric injection is the key design decision \u2014 T1 affects the state at two points (front and middle), ensuring that each round's message input influences the state globally, not just locally.\n\n![Anatomy of One Compression Round](./diagrams/diag-m3-compression-round-anatomy.svg)\n\nHere is the entire 64-round compression loop in C:\n```c\n/*\n * Execute 64 rounds of SHA-256 compression.\n *\n * Parameters:\n *   H  - the current hash state: H[0]..H[7] (modified in place)\n *   W  - the 64-word message schedule for this block\n */\nstatic void sha256_compress(uint32_t H[8], const uint32_t W[64]) {\n    /* Step 1: initialize working variables from hash state */\n    uint32_t a = H[0];\n    uint32_t b = H[1];\n    uint32_t c = H[2];\n    uint32_t d = H[3];\n    uint32_t e = H[4];\n    uint32_t f = H[5];\n    uint32_t g = H[6];\n    uint32_t h = H[7];\n    /* Step 2: 64 rounds */\n    for (int t = 0; t < 64; t++) {\n        uint32_t T1 = h + Sigma1(e) + Ch(e, f, g) + K[t] + W[t];\n        uint32_t T2 = Sigma0(a) + Maj(a, b, c);\n        h = g;\n        g = f;\n        f = e;\n        e = d + T1;\n        d = c;\n        c = b;\n        b = a;\n        a = T1 + T2;\n    }\n    /* Step 3: add compressed chunk to current hash value */\n    H[0] += a;\n    H[1] += b;\n    H[2] += c;\n    H[3] += d;\n    H[4] += e;\n    H[5] += f;\n    H[6] += g;\n    H[7] += h;\n}\n```\nThis is the complete compression function. Twelve lines of substantive code for the core cryptographic operation. Every line maps directly to a clause in FIPS 180-4 Section 6.2.2. The C `uint32_t` type handles all the modular arithmetic automatically.\n> \u26a0\ufe0f **Critical order of operations**: The variable assignments in the loop body must happen in the order shown, or you must use temporary variables. Specifically, you must compute T1 and T2 *before* updating any of the working variables. If you write `a = T1 + T2` before computing T2, or `e = d + T1` before computing T1, you'll use wrong values. The C code above computes both T1 and T2 first (two lines), then updates all variables using those precomputed values. This is correct.\n> \u26a0\ufe0f **The `e = d + T1` trap**: A very common mistake is writing `e = d + T1 + T2`. Look at the formula again \u2014 `T2` contributes only to `a`, not to `e`. The new `a = T1 + T2` and the new `e = d + T1`. These are two separate additions. The variable update is the most frequently mis-transcribed part of the spec.\n---\n## Tracing One Round Manually\nTo build confidence in your implementation, trace round 0 for the \"abc\" input by hand. You need:\n- Initial H[] values (from FIPS 180-4 Section 5.3.3 \u2014 you'll set these up properly in Milestone 4, but we'll use them here for testing)\n- W[0] = 0x61626380 (from your Milestone 2 output)\n- K[0] = 0x428A2F98\nThe initial hash values H[0]..H[7] are:\n```\nH[0] = 0x6A09E667\nH[1] = 0xBB67AE85\nH[2] = 0x3C6EF372\nH[3] = 0xA54FF53A\nH[4] = 0x510E527F\nH[5] = 0x9B05688C\nH[6] = 0x1F83D9AB\nH[7] = 0x5BE0CD19\n```\nSo at the start of round 0:\n- `a = 0x6A09E667`, `b = 0xBB67AE85`, `c = 0x3C6EF372`, `d = 0xA54FF53A`\n- `e = 0x510E527F`, `f = 0x9B05688C`, `g = 0x1F83D9AB`, `h = 0x5BE0CD19`\nCompute T1:\n```\n\u03a31(e) = ROTR(0x510E527F,  6) XOR\n        ROTR(0x510E527F, 11) XOR\n        ROTR(0x510E527F, 25)\nROTR(0x510E527F,  6):\n  0x510E527F >> 6  = 0x01443949\n  0x510E527F << 26 = 0xFC000000\n  = 0x01443949 | 0xFC000000 = 0xFD443949\nROTR(0x510E527F, 11):\n  0x510E527F >> 11 = 0x000A21CA\n  0x510E527F << 21 = 0xEFE00000\n  = 0x000A21CA | 0xEFE00000 = 0xEFEA21CA\nROTR(0x510E527F, 25):\n  0x510E527F >> 25 = 0x00000028\n  0x510E527F << 7  = 0x87297F80\n  = 0x00000028 | 0x87297F80 = 0x872980A8  (verify: last bits of 0x510E527F are 01111111, shifted left 7)\n```\nRather than carry this arithmetic through all 64 rounds by hand \u2014 which would take pages \u2014 the practical approach is to **instrument your code to print intermediate values** and compare them against the NIST SHA-256 example document's appendix. The NIST document provides the complete state (a through h) after every single round for both the \"abc\" test vector and the longer test vector. This byte-level comparison is how you debug the compression function.\nHere is a debugging-instrumented version of the compression loop:\n```c\nstatic void sha256_compress_debug(uint32_t H[8], const uint32_t W[64]) {\n    uint32_t a = H[0], b = H[1], c = H[2], d = H[3];\n    uint32_t e = H[4], f = H[5], g = H[6], h = H[7];\n    for (int t = 0; t < 64; t++) {\n        uint32_t T1 = h + Sigma1(e) + Ch(e, f, g) + K[t] + W[t];\n        uint32_t T2 = Sigma0(a) + Maj(a, b, c);\n        h = g; g = f; f = e; e = d + T1;\n        d = c; c = b; b = a; a = T1 + T2;\n        /*\n         * Print state after each round.\n         * Compare these values against NIST SHA-256 example document,\n         * Appendix B, \"SHA-256 Example\".\n         */\n        printf(\"Round %02d: a=%08X b=%08X c=%08X d=%08X \"\n               \"          e=%08X f=%08X g=%08X h=%08X\\n\",\n               t, a, b, c, d, e, f, g, h);\n    }\n    H[0] += a; H[1] += b; H[2] += c; H[3] += d;\n    H[4] += e; H[5] += f; H[6] += g; H[7] += h;\n}\n```\nRemove the `printf` once you've verified all 64 rounds match the NIST appendix. This two-phase approach \u2014 verbose debugging version for development, clean version for production \u2014 is standard practice for implementing cryptographic primitives.\n---\n## The Complete Compression Module\nHere is the full module, ready to compile:\n```c\n/* sha256_compress.h */\n#ifndef SHA256_COMPRESS_H\n#define SHA256_COMPRESS_H\n#include <stdint.h>\n/*\n * Compress one 512-bit block into the running hash state.\n *\n * Parameters:\n *   H  - hash state array of 8 uint32_t values (modified in place)\n *   W  - 64-word message schedule generated from the block\n *\n * After this call, H[0]..H[7] reflect the updated hash state for this block.\n */\nvoid sha256_compress(uint32_t H[8], const uint32_t W[64]);\n#endif /* SHA256_COMPRESS_H */\n```\n```c\n/* sha256_compress.c */\n#include \"sha256_compress.h\"\n#include <stdint.h>\n/* ------------------------------------------------------------------ */\n/* Internal helpers                                                     */\n/* ------------------------------------------------------------------ */\nstatic uint32_t rotr(uint32_t x, int n) {\n    return (x >> n) | (x << (32 - n));\n}\nstatic uint32_t Sigma0(uint32_t x) {\n    return rotr(x, 2) ^ rotr(x, 13) ^ rotr(x, 22);\n}\nstatic uint32_t Sigma1(uint32_t x) {\n    return rotr(x, 6) ^ rotr(x, 11) ^ rotr(x, 25);\n}\nstatic uint32_t Ch(uint32_t x, uint32_t y, uint32_t z) {\n    return (x & y) ^ (~x & z);\n}\nstatic uint32_t Maj(uint32_t x, uint32_t y, uint32_t z) {\n    return (x & y) ^ (x & z) ^ (y & z);\n}\n/* ------------------------------------------------------------------ */\n/* Round constants \u2014 FIPS 180-4 Section 4.2.2                          */\n/* ------------------------------------------------------------------ */\nstatic const uint32_t K[64] = {\n    0x428A2F98, 0x71374491, 0xB5C0FBCF, 0xE9B5DBA5,\n    0x3956C25B, 0x59F111F1, 0x923F82A4, 0xAB1C5ED5,\n    0xD807AA98, 0x12835B01, 0x243185BE, 0x550C7DC3,\n    0x72BE5D74, 0x80DEB1FE, 0x9BDC06A7, 0xC19BF174,\n    0xE49B69C1, 0xEFBE4786, 0x0FC19DC6, 0x240CA1CC,\n    0x2DE92C6F, 0x4A7484AA, 0x5CB0A9DC, 0x76F988DA,\n    0x983E5152, 0xA831C66D, 0xB00327C8, 0xBF597FC7,\n    0xC6E00BF3, 0xD5A79147, 0x06CA6351, 0x14292967,\n    0x27B70A85, 0x2E1B2138, 0x4D2C6DFC, 0x53380D13,\n    0x650A7354, 0x766A0ABB, 0x81C2C92E, 0x92722C85,\n    0xA2BFE8A1, 0xA81A664B, 0xC24B8B70, 0xC76C51A3,\n    0xD192E819, 0xD6990624, 0xF40E3585, 0x106AA070,\n    0x19A4C116, 0x1E376C08, 0x2748774C, 0x34B0BCB5,\n    0x391C0CB3, 0x4ED8AA4A, 0x5B9CCA4F, 0x682E6FF3,\n    0x748F82EE, 0x78A5636F, 0x84C87814, 0x8CC70208,\n    0x90BEFFFA, 0xA4506CEB, 0xBEF9A3F7, 0xC67178F2\n};\n/* ------------------------------------------------------------------ */\n/* Public API                                                           */\n/* ------------------------------------------------------------------ */\nvoid sha256_compress(uint32_t H[8], const uint32_t W[64]) {\n    uint32_t a = H[0];\n    uint32_t b = H[1];\n    uint32_t c = H[2];\n    uint32_t d = H[3];\n    uint32_t e = H[4];\n    uint32_t f = H[5];\n    uint32_t g = H[6];\n    uint32_t h = H[7];\n    for (int t = 0; t < 64; t++) {\n        uint32_t T1 = h + Sigma1(e) + Ch(e, f, g) + K[t] + W[t];\n        uint32_t T2 = Sigma0(a) + Maj(a, b, c);\n        h = g;\n        g = f;\n        f = e;\n        e = d + T1;\n        d = c;\n        c = b;\n        b = a;\n        a = T1 + T2;\n    }\n    H[0] += a;\n    H[1] += b;\n    H[2] += c;\n    H[3] += d;\n    H[4] += e;\n    H[5] += f;\n    H[6] += g;\n    H[7] += h;\n}\n```\n---\n## Testing the Compression Function\nTesting the compression function requires all three milestones working together: padding (Milestone 1) produces the block, schedule generation (Milestone 2) produces W[], and the compression function transforms H[]. Your tests for this milestone are integration tests that exercise the full chain.\n### Setting Up Test State\nFor testing, initialize H[] to SHA-256's standard initial values (you'll build the proper initialization in Milestone 4, but you can hardcode them here):\n```c\n/* SHA-256 initial hash values \u2014 FIPS 180-4 Section 5.3.3\n * First 32 bits of the fractional parts of the square roots of the first 8 primes */\nstatic uint32_t initial_H[8] = {\n    0x6A09E667, 0xBB67AE85, 0x3C6EF372, 0xA54FF53A,\n    0x510E527F, 0x9B05688C, 0x1F83D9AB, 0x5BE0CD19\n};\n```\n### Test 1: Intermediate Values After Round 0\nCompare the state after round 0 of the \"abc\" compression against the NIST example document. This isolates whether your T1 and T2 computation is correct before accumulating errors across 64 rounds.\n```c\n#include <stdio.h>\n#include <string.h>\n#include <assert.h>\n#include \"sha256_pad.h\"\n#include \"sha256_schedule.h\"\n#include \"sha256_compress.h\"\nvoid test_intermediate_round0(void) {\n    /*\n     * According to the NIST SHA-256 example document (Appendix B),\n     * after Round 0 of the \"abc\" compression (with the standard initial\n     * hash values), the working variables should be:\n     *\n     * a = 0x510E527F (verify exact value against NIST document)\n     * ...\n     *\n     * NOTE: Look up the exact NIST intermediate values and fill them in here.\n     * This test structure shows the pattern \u2014 the values must come from\n     * the official NIST SHA-256 example computation document.\n     */\n    printf(\"INFO: Implement round-by-round comparison against NIST Appendix B\\n\");\n    printf(\"      Load the NIST SHA-256 example document and compare each round's\\n\");\n    printf(\"      (a,b,c,d,e,f,g,h) output against the table in Appendix B.\\n\");\n}\n```\n### Test 2: Hash State After Processing \"abc\"\nThis is the critical integration test. After processing the \"abc\" padded block through the full 64-round compression and adding the results back to the initial state, the hash state H[0]..H[7] should match the NIST reference values. In Milestone 4, you'll format these as hex to produce the final digest \u2014 but you can check the raw state values here.\n```c\nvoid test_abc_compression(void) {\n    /* Build padded \"abc\" block */\n    const uint8_t msg[] = { 0x61, 0x62, 0x63 };\n    uint8_t padded[64];\n    sha256_pad(padded, msg, 3);\n    /* Generate message schedule */\n    uint32_t W[64];\n    sha256_schedule(padded, W);\n    /* Initialize hash state to SHA-256 initial values */\n    uint32_t H[8] = {\n        0x6A09E667, 0xBB67AE85, 0x3C6EF372, 0xA54FF53A,\n        0x510E527F, 0x9B05688C, 0x1F83D9AB, 0x5BE0CD19\n    };\n    /* Compress */\n    sha256_compress(H, W);\n    /*\n     * After compression of \"abc\" (one block), the state should be:\n     * H[0] = 0xBA7816BF  (first word of SHA-256(\"abc\"))\n     * H[1] = 0x8F01CFEA\n     * H[2] = 0x414140DE\n     * H[3] = 0x5DAE2223\n     * H[4] = 0xB00361A3\n     * H[5] = 0x96177A9C\n     * H[6] = 0xB410FF61\n     * H[7] = 0xF20015AD\n     *\n     * These are the 8 words of SHA-256(\"abc\") =\n     *   ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad\n     *\n     * Verify: concatenate H[0]..H[7] in big-endian order to get the hex string.\n     */\n    assert(H[0] == 0xBA7816BF);\n    assert(H[1] == 0x8F01CFEA);\n    assert(H[2] == 0x414140DE);\n    assert(H[3] == 0x5DAE2223);\n    assert(H[4] == 0xB00361A3);\n    assert(H[5] == 0x96177A9C);\n    assert(H[6] == 0xB410FF61);\n    assert(H[7] == 0xF20015AD);\n    printf(\"PASS: SHA-256('abc') compression produces correct hash state\\n\");\n    printf(\"      H[0]=%08X H[1]=%08X H[2]=%08X H[3]=%08X\\n\",\n           H[0], H[1], H[2], H[3]);\n    printf(\"      H[4]=%08X H[5]=%08X H[6]=%08X H[7]=%08X\\n\",\n           H[4], H[5], H[6], H[7]);\n}\n```\nIf this test passes, your entire implementation through Milestone 3 is correct. The hash state after \"abc\" compression is the SHA-256 hash of \"abc\" \u2014 in Milestone 4, you'll just serialize these 8 words as a big-endian hex string.\n### Test 3: Verify Individual Boolean Functions\nTest Ch and Maj against exhaustive known values before trusting the compression function:\n```c\nvoid test_ch_function(void) {\n    /* Ch(x, y, z): if x then y else z, bit by bit */\n    /* All ones in x: should select y entirely */\n    assert(Ch(0xFFFFFFFF, 0xAAAAAAAA, 0x55555555) == 0xAAAAAAAA);\n    /* All zeros in x: should select z entirely */\n    assert(Ch(0x00000000, 0xAAAAAAAA, 0x55555555) == 0x55555555);\n    /* Alternating: select alternating bits from y and z */\n    /* x = 0xF0F0F0F0: top 4 bits of each nibble select from y, bottom 4 from z */\n    uint32_t result = Ch(0xF0F0F0F0, 0xAAAAAAAA, 0x55555555);\n    assert(result == 0xA5A5A5A5);  /* top 4 bits: AAAA\u2192A, bottom 4: 5555\u21925 */\n    printf(\"PASS: Ch function \u2014 all test cases correct\\n\");\n}\nvoid test_maj_function(void) {\n    /* Maj(x, y, z): majority vote */\n    /* All zeros: majority is 0 */\n    assert(Maj(0x00000000, 0x00000000, 0x00000000) == 0x00000000);\n    /* All ones: majority is 1 */\n    assert(Maj(0xFFFFFFFF, 0xFFFFFFFF, 0xFFFFFFFF) == 0xFFFFFFFF);\n    /* Two inputs with a bit set: majority is 1 for that bit */\n    assert(Maj(0xFFFFFFFF, 0xFFFFFFFF, 0x00000000) == 0xFFFFFFFF);\n    assert(Maj(0xFFFFFFFF, 0x00000000, 0xFFFFFFFF) == 0xFFFFFFFF);\n    assert(Maj(0x00000000, 0xFFFFFFFF, 0xFFFFFFFF) == 0xFFFFFFFF);\n    /* One input with a bit set: majority is 0 for that bit */\n    assert(Maj(0xFFFFFFFF, 0x00000000, 0x00000000) == 0x00000000);\n    printf(\"PASS: Maj function \u2014 all test cases correct\\n\");\n}\nvoid test_sigma_uppercase(void) {\n    /* \u03a30 and \u03a31 of zero should be zero */\n    assert(Sigma0(0x00000000) == 0x00000000);\n    assert(Sigma1(0x00000000) == 0x00000000);\n    /* \u03a30(1): ROTR(1,2) XOR ROTR(1,13) XOR ROTR(1,22)\n     *   ROTR(0x00000001, 2)  = 0x40000000\n     *   ROTR(0x00000001, 13) = 0x00080000\n     *   ROTR(0x00000001, 22) = 0x00000400\n     *   XOR: 0x40080400 */\n    assert(Sigma0(0x00000001) == 0x40080400);\n    /* \u03a31(1): ROTR(1,6) XOR ROTR(1,11) XOR ROTR(1,25)\n     *   ROTR(0x00000001, 6)  = 0x04000000\n     *   ROTR(0x00000001, 11) = 0x00200000\n     *   ROTR(0x00000001, 25) = 0x00000080\n     *   XOR: 0x04200080 */\n    assert(Sigma1(0x00000001) == 0x04200080);\n    printf(\"PASS: Sigma0 and Sigma1 \u2014 spot checks correct\\n\");\n}\n```\n### Running All Tests\n```c\nint main(void) {\n    test_ch_function();\n    test_maj_function();\n    test_sigma_uppercase();\n    test_abc_compression();\n    printf(\"\\nAll compression tests passed.\\n\");\n    return 0;\n}\n```\n```bash\ngcc -Wall -Wextra -o test_compress \\\n    test_compress.c sha256_compress.c sha256_schedule.c sha256_pad.c\n./test_compress\n```\n---\n## Common Pitfalls and Debugging Checklist\n**Pitfall 1: Confusing uppercase \u03a3 and lowercase \u03c3 constants**\nThis is the single most common mistake. \u03a30 uses (2, 13, 22) and \u03a31 uses (6, 11, 25). \u03c30 uses (7, 18, 3) and \u03c31 uses (17, 19, 10). If you accidentally use your schedule sigma functions inside the compression function (or vice versa), your hash will be wrong for every input. The test `test_sigma_uppercase()` above catches this immediately.\n**Pitfall 2: Wrong formula for the new `e` value**\nWriting `e = d + T1 + T2` instead of `e = d + T1`. T2 contributes only to `a`. Check the spec formula character by character. This mistake is almost invisible \u2014 both expressions involve T1 \u2014 and produces wrong output only discovered when comparing against NIST intermediate values.\n**Pitfall 3: Using wrong K constants**\nTypos in the K array produce hashes that are wrong for every input in a way that's impossible to debug at the round level. Always verify K[0] = 0x428A2F98 and K[63] = 0xC67178F2 against the spec before debugging anything else.\n**Pitfall 4: Applying the state update before all rounds complete**\nWriting `H[0] += a` inside the round loop instead of after it. This makes each round add a partial result to the state, compounding errors across all 64 rounds. The state update must happen exactly once, after all 64 rounds complete.\n**Pitfall 5: Variable name collision with `h`**\nIn C, the variable `h` shadows the function parameter if you're not careful, and it also looks like an integer suffix in some contexts. Using the working variable name `h` is standard (the spec uses it), but be careful in your IDE \u2014 a search for `H[7]` and `h` will find very different things.\n**Debugging methodology when the hash is wrong:**\n1. Print all 64 W[] values and compare against NIST schedule (Milestone 2 test)\n2. Print (a,b,c,d,e,f,g,h) after round 0 only and compare against NIST appendix\n3. Print (a,b,c,d,e,f,g,h) after round 63 (before state update) and compare\n4. Print H[0]..H[7] after state update and compare\nFinding which step first diverges tells you exactly where the bug is.\n---\n## Knowledge Cascade: What the Compression Function Connects To\n### 1. Cryptanalytic Margins \u2014 Why Round Counts Are Security Budgets\nThe compression function teaches you that round count is not an aesthetic choice \u2014 it is a **security margin** calculated as the distance between the full design and the best known attack. When you read that AES-128 uses 10 rounds, AES-192 uses 12, and AES-256 uses 14, you now understand why: the margin increases with key size to prevent attacks that use the longer key period. The attack on 31-round SHA-256 tells you the current margin is 33 rounds (64 - 31). A breakthrough attack on, say, 50-round SHA-256 would prompt serious concern, even if 64-round SHA-256 remained unbroken \u2014 because the margin would have shrunk to 14 rounds.\nThis same framework governs every serious cryptographic primitive. SHA-3/Keccak uses 24 rounds of its permutation with a security margin that has been extensively analyzed since 2012. ChaCha20 (used in TLS 1.3) uses 20 rounds, reduced from Salsa20's original recommendation, based on the observation that 8-round ChaCha appears practically unbreakable with current techniques. Understanding SHA-256's 64 rounds makes every other round-count decision in cryptography immediately legible.\n### 2. Boolean Function Non-Linearity \u2014 S-Boxes, MUXes, and Circuit Design\nCh and Maj are instances of a general question: what makes a boolean function useful for cryptography? The key property you've seen is non-linearity \u2014 the function cannot be well-approximated by any linear function (any combination of XORs). This property appears in its most powerful form in **S-boxes**, the lookup tables at the heart of AES. The AES S-box is carefully constructed to maximize non-linearity across 8 input bits \u2014 it cannot be approximated well by any affine function over GF(2\u2078). The design principles that make Ch and Maj cryptographically useful are the same principles, generalized to larger input/output spaces, that govern AES S-box construction.\nCh also appears directly in digital logic as a **2-to-1 multiplexer (MUX)** gate \u2014 a fundamental building block in CPUs, FPGAs, and ASICs. Every CPU instruction decoder uses MUX chains. Understanding Ch at the bit level gives you an intuition for hardware that translates directly into reading FPGA HDL (Hardware Description Language) code and understanding why MUX trees are the natural structure for combinational logic.\n### 3. Nothing-Up-My-Sleeve Numbers \u2014 Algorithm Transparency as a Trust Mechanism\nThe derivation of K constants from prime cube roots is a specific instance of a broader design philosophy in cryptography: **public, verifiable parameter generation**. If algorithm designers can prove they had no freedom in choosing parameters (because the parameters follow from a fixed mathematical procedure applied to fixed inputs), they cannot have introduced a backdoor.\nThis philosophy has an interesting failure case: the NIST P-256 and P-384 elliptic curve parameters include a \"seed\" value (`c49d3608 86e70493 6a6678e1...` for P-256) that was allegedly generated randomly, but whose origin was never documented. Nobody has found an attack on P-256, but the lack of transparency causes discomfort in the cryptography community \u2014 unlike SHA-256's K constants, you cannot verify *why* that seed was chosen. This is why Curve25519 (designed by Daniel Bernstein) was created: its prime (2\u00b2\u2075\u2075 - 19) is the largest prime below 2\u00b2\u2075\u2075, and its base point is the smallest valid generator. No unexplained seeds, no freedom for the designer to have introduced structure. You can now evaluate any cryptographic primitive by asking: \"Can I verify how the constants were chosen?\"\n### 4. The Compression Function as a One-Way Function \u2014 Provable Security Reductions\nThe compression function is not just a building block. It is a **one-way function** \u2014 given output, finding input is computationally infeasible. The security of the full hash function *reduces* to the security of the compression function: if you can find a collision in SHA-256, you can find a collision in the compression function (contrapositive: if the compression function is collision-resistant, so is SHA-256, via the Merkle-Damg\u00e5rd security theorem).\nThis reduction is how cryptography achieves provable security without proving anything is hard in an absolute sense. Nobody knows if one-way functions exist \u2014 proving it would resolve P vs. NP. But we can prove: \"If the compression function is a random oracle, then SHA-256 is collision-resistant.\" This conditional guarantee is the foundation of the security argument. Understanding it prepares you to read security proofs throughout cryptography \u2014 for HMAC, for ECDSA, for TLS handshake key derivation \u2014 all of which use the same reduction style: \"if primitive X is secure, then protocol Y built from X is secure.\"\n### 5. State Machine Design \u2014 Shift Registers, CPU Pipelines, and Protocol Automata\nThe 8-variable rotation in the compression function is a **shift register** pattern: each round, all variables shift one position, and two new values are injected at specific positions. This structure appears everywhere in computer engineering:\nIn **CPU instruction pipelines**: fetch, decode, execute, memory, writeback stages form a 5-stage shift register where an instruction moves forward one stage per clock cycle. New instructions enter at the front (fetch) and results emerge at the back (writeback) \u2014 exactly analogous to how T1 and T2 inject new values into the front and middle of SHA-256's state pipeline.\nIn **Galois counters (GCM mode for AES encryption)**: the authentication tag computation uses a shift-feedback structure that is mathematically equivalent to the message schedule you built in Milestone 2.\nIn **protocol state machines** (TLS handshake, TCP connection establishment): each state takes the current state plus an external input (a message received from the network, analogous to W[t]) and produces a new state, advancing the protocol forward. The formalism of state transitions \u2014 current state + input \u2192 new state \u2014 is directly instantiated by SHA-256's compression function.\nOnce you see the shift-register pattern in SHA-256's compression function, you'll recognize it in every CPU pipeline diagram, every LFSR description, and every protocol state machine you encounter. It is one of the most universally recurring structures in discrete computing.\n---\n## Summary: What You Built and Why It Matters\nIn this milestone you built five things:\n1. **The \u03a30 and \u03a31 diffusion functions** for the compression function, distinct from the schedule's \u03c3 functions, using rotation-only mixing with constants (2, 13, 22) and (6, 11, 25).\n2. **The Ch (Choice) function** \u2014 a bit-level multiplexer, balanced and non-linear, the only such function of its type \u2014 which conditionally selects between `f` and `g` based on `e`.\n3. **The Maj (Majority) function** \u2014 a bit-level vote, also balanced and non-linear \u2014 which outputs the majority bit of `a`, `b`, and `c`.\n4. **The 64-round compression loop** that transforms the 8-variable state using T1 and T2 computed from schedule words, round constants, and the current state, with the variable rotation pattern that propagates changes through all eight state slots.\n5. **The state update** that adds the compressed output back to the running hash values, implementing the Davies-Meyer feed-forward construction that makes the compression function one-way.\nEvery operation in this function has a cryptanalytic purpose. The rotations provide diffusion. The Ch and Maj provide non-linear confusion. The modular additions provide additional non-linearity through carry. The K constants prevent round symmetry. The 64 rounds provide a security margin 33 rounds above the best known attack.\nThe compression function is SHA-256's core. Everything from Milestone 1 (preprocessing) and Milestone 2 (schedule generation) feeds into it. Everything in Milestone 4 (final hash output and streaming API) reads from it.\nRun your tests. Verify the \"abc\" compression produces H[0] = 0xBA7816BF. If it does, you have a correct SHA-256 compression function. Move on to Milestone 4, where you'll connect the full pipeline and produce the final hexadecimal digest.\n---\n<!-- END_MS -->\n\n\n<!-- MS_ID: hash-impl-m4 -->\n<!-- MS_ID: hash-impl-m4 -->\n# Milestone 4: Final Hash Output and Validation\n## Where We Are in the Pipeline\n\n![SHA-256 Complete Pipeline \u2014 Satellite Map](./diagrams/diag-L0-satellite-map.svg)\n\nYou have built every cryptographic component SHA-256 requires. Your padding function converts arbitrary messages into 512-bit-aligned blocks. Your schedule generator expands each block into 64 mixed words. Your compression function transforms the hash state through 64 rounds of Ch, Maj, \u03a30, and \u03a31. All three stages are independently verified against NIST intermediate values.\nThis milestone wires them together. By the end, you will have a complete, correct SHA-256 implementation that:\n- Passes all three NIST test vectors\n- Handles arbitrarily long messages through a streaming update/finalize API\n- Resets state correctly between invocations\n- Produces output indistinguishable from OpenSSL's implementation\nThe assembly looks simpler than what came before. It is not. Three distinct failure modes lurk here \u2014 each invisible until you run the test vectors, each silently producing wrong output that looks like a valid SHA-256 digest. You need to understand all three before you write a line of code.\n---\n## The Revelation: Three Bugs That Hide Until the Very End\n\n![H0..H7 Initial Values \u2014 From Prime Square Roots](./diagrams/diag-m4-initial-hash-values-origin.svg)\n\nHere is the assumption developers make when arriving at this milestone:\n> \"I've verified the compression function produces the right state for 'abc'. The rest is plumbing \u2014 initialize some variables, loop over blocks, format the output as hex. An hour of work, maybe two.\"\nThis assumption is wrong in exactly three places. Let's break them one by one.\n### Bug 1: The Initial Hash Values Are Not Arbitrary\nEvery SHA-256 computation begins by initializing eight 32-bit state words H[0] through H[7]. If you've been following along from Milestone 3, you've already seen these constants:\n```c\n0x6A09E667, 0xBB67AE85, 0x3C6EF372, 0xA54FF53A,\n0x510E527F, 0x9B05688C, 0x1F83D9AB, 0x5BE0CD19\n```\nThese look arbitrary \u2014 eight hex values with no obvious pattern. But they are not arbitrary. They are the **first 32 bits of the fractional parts of the square roots of the first eight prime numbers**.\nThe first prime is 2. The square root of 2 is 1.41421356... The fractional part is 0.41421356... Multiply by 2\u00b3\u00b2 and truncate to an integer: 0.41421356... \u00d7 4,294,967,296 \u2248 1,779,033,703 = 0x6A09E667. That is H[0].\nThis is the same nothing-up-my-sleeve principle you saw in Milestone 3's K constants. The designers had no freedom to choose these values arbitrarily \u2014 they follow from a fixed mathematical procedure applied to fixed inputs. Nobody can claim the initial values contain a backdoor, because anyone can reproduce them from scratch.\nNow here is the critical implication: **these exact byte values must be used, and no others.** If you mistype a single constant \u2014 say `0x6A09E669` instead of `0x6A09E667` \u2014 your implementation will produce a hash that looks like a valid SHA-256 output (64 lowercase hex characters, entirely plausible-looking), but will differ from the NIST test vectors and from every other SHA-256 implementation in the world. The bug is invisible until you test.\nFurthermore: **these initial values are what differentiates SHA-224 from SHA-256**. SHA-224 uses the identical algorithm \u2014 same padding, same schedule, same 64-round compression with the same K constants and the same bitwise functions. The only difference is eight different initial values (derived from the 9th through 16th primes instead of the 1st through 8th), and the output is truncated to 224 bits instead of 256. SHA-256 and SHA-224 are the same function instantiated with different initialization vectors. This is why the entire SHA-2 family \u2014 SHA-224, SHA-256, SHA-384, SHA-512, SHA-512/224, SHA-512/256 \u2014 can be understood as a single parameterized design with different initial values and word sizes. Once you understand SHA-256, you understand all of them.\n### Bug 2: The Streaming API Is a State Machine, Not a Wrapper\nThe obvious implementation of a streaming hash API looks like this:\n```c\n/* \u274c WRONG: naive implementation that seems correct but is not */\ntypedef struct {\n    uint8_t *accumulated;   /* pointer to all accumulated bytes */\n    size_t   count;         /* total bytes accumulated */\n} SHA256_CTX_NAIVE;\nvoid sha256_update_naive(SHA256_CTX_NAIVE *ctx, const uint8_t *data, size_t len) {\n    /* append data to accumulated buffer */\n    memcpy(ctx->accumulated + ctx->count, data, len);\n    ctx->count += len;\n}\nvoid sha256_finalize_naive(SHA256_CTX_NAIVE *ctx, uint8_t digest[32]) {\n    /* hash everything at once */\n    sha256_oneshot(ctx->accumulated, ctx->count, digest);\n}\n```\nThis approach has a fatal flaw: it requires allocating and maintaining a buffer large enough to hold the *entire* message. For a 1 GB file, that means 1 GB of heap allocation. For a network stream of unbounded length, it requires unbounded memory.\nThe correct approach processes data in **512-bit (64-byte) chunks** as they arrive, keeping only a small internal buffer for partial blocks. The context struct holds:\n1. The **current hash state** H[0..7] \u2014 32 bytes\n2. A **partial block buffer** of up to 63 bytes \u2014 for data that hasn't yet made a complete 64-byte block\n3. A **count of bytes processed** \u2014 needed for the length field at finalization\nThis means `update()` must implement a small state machine: data arrives, it may complete a partial block (triggering immediate compression), it may itself span multiple complete blocks (each compressed immediately), and it may leave a trailing partial block for later. `finalize()` pads and compresses whatever is left in the partial buffer.\nThe buffer management has exact edge cases that break na\u00efve implementations:\n- Calling `update()` with exactly 64 bytes when the buffer is empty\n- Calling `update()` with 1 byte when the buffer holds 63 bytes (triggering an immediate compression)\n- Calling `update()` with 128 bytes when the buffer holds 32 bytes (completing one block, processing one more, leaving zero bytes in the buffer)\n- Calling `finalize()` on a context that has processed exactly a multiple of 64 bytes (the buffer is empty \u2014 don't skip padding)\nEvery one of these cases must be tested explicitly.\n### Bug 3: State Reset Is Not Optional\nConsider this code:\n```c\nuint8_t digest1[32], digest2[32];\nSHA256_CTX ctx;\nsha256_init(&ctx);\nsha256_update(&ctx, (uint8_t*)\"hello\", 5);\nsha256_finalize(&ctx, digest1);  /* correct: SHA-256(\"hello\") */\n/* Now hash something else with the SAME context */\nsha256_update(&ctx, (uint8_t*)\"world\", 5);  /* \u2190 BUG: uses leftover state */\nsha256_finalize(&ctx, digest2);  /* WRONG: not SHA-256(\"world\") */\n```\nIf you do not reset H[0..7] to the initial values at the start of each computation, the second hash includes the state from the first hash as its starting point. The output is deterministic \u2014 you'll get the same wrong answer every time \u2014 but it's not SHA-256 of \"world\". It's SHA-256 of some undefined concatenation.\nThis bug is particularly dangerous in test suites that hash only one message per test. If every test creates a fresh context, the bug is invisible. It only appears when a single context is reused, which is exactly what happens in performance-sensitive code (avoiding repeated heap allocation by reusing a preallocated context). The canonical fix is: `sha256_init()` must set H[0..7] to the initial values, clear the buffer, and reset the byte count. It must be called before every computation.\nNow you know all three failure modes. Let's build the implementation that avoids them.\n---\n## The Initial Hash Values: Precise Constants\nFIPS 180-4 Section 5.3.3 specifies the initial hash values. Here they are, alongside their derivation for verification:\n\n![H0..H7 Initial Values \u2014 From Prime Square Roots](./diagrams/diag-m4-initial-hash-values-origin.svg)\n\n```c\n/*\n * SHA-256 Initial Hash Values \u2014 FIPS 180-4 Section 5.3.3\n *\n * Derivation: first 32 bits of the fractional parts of the\n * square roots of the first 8 prime numbers.\n *\n *  H[0]: sqrt(2)  = 1.41421356... \u2192 frac = 0.41421356... \u2192 0x6A09E667\n *  H[1]: sqrt(3)  = 1.73205080... \u2192 frac = 0.73205080... \u2192 0xBB67AE85\n *  H[2]: sqrt(5)  = 2.23606797... \u2192 frac = 0.23606797... \u2192 0x3C6EF372\n *  H[3]: sqrt(7)  = 2.64575131... \u2192 frac = 0.64575131... \u2192 0xA54FF53A\n *  H[4]: sqrt(11) = 3.31662479... \u2192 frac = 0.31662479... \u2192 0x510E527F\n *  H[5]: sqrt(13) = 3.60555127... \u2192 frac = 0.60555127... \u2192 0x9B05688C\n *  H[6]: sqrt(17) = 4.12310562... \u2192 frac = 0.12310562... \u2192 0x1F83D9AB\n *  H[7]: sqrt(19) = 4.35889894... \u2192 frac = 0.35889894... \u2192 0x5BE0CD19\n */\nstatic const uint32_t SHA256_INITIAL_H[8] = {\n    0x6A09E667, 0xBB67AE85, 0x3C6EF372, 0xA54FF53A,\n    0x510E527F, 0x9B05688C, 0x1F83D9AB, 0x5BE0CD19\n};\n```\n> \u26a0\ufe0f **Verification step**: Before writing any other code, check that `SHA256_INITIAL_H[0] == 0x6A09E667` and `SHA256_INITIAL_H[7] == 0x5BE0CD19` against your copy of FIPS 180-4. A single wrong digit here causes every hash output to be wrong, with no indication of where the fault lies. This is the fastest correctness check in the entire project.\n---\n## The Context Struct: Memory Layout for Streaming\n\n![SHA-256 Context Struct \u2014 Memory Layout](./diagrams/diag-m4-context-struct-layout.svg)\n\nThe context struct is the \"state envelope\" that carries all information needed to resume or finalize a hash computation at any point. Its design determines what operations are possible and how efficiently they execute.\n```c\n/* sha256.h */\n#ifndef SHA256_H\n#define SHA256_H\n#include <stdint.h>\n#include <stddef.h>\n#define SHA256_BLOCK_SIZE   64    /* bytes per 512-bit block */\n#define SHA256_DIGEST_SIZE  32    /* bytes in the final 256-bit hash */\n/*\n * SHA256_CTX: the complete state for one SHA-256 computation.\n *\n * This struct is everything sha256_update() and sha256_finalize() need.\n * Allocate one on the stack or heap, call sha256_init() to reset it,\n * then call sha256_update() any number of times, then sha256_finalize().\n *\n * Never read or write any field directly \u2014 treat the struct as opaque.\n */\ntypedef struct {\n    uint32_t H[8];                   /* current hash state (256 bits) */\n    uint8_t  buf[SHA256_BLOCK_SIZE]; /* partial block buffer (0\u201363 bytes) */\n    size_t   buf_len;                /* bytes currently in buf */\n    uint64_t total_len;              /* total bytes processed so far */\n} SHA256_CTX;\n/* Initialize a context \u2014 MUST be called before any update/finalize */\nvoid sha256_init(SHA256_CTX *ctx);\n/* Feed data into the running hash computation */\nvoid sha256_update(SHA256_CTX *ctx, const uint8_t *data, size_t len);\n/* Finalize the hash and write the 32-byte digest to out[] */\nvoid sha256_finalize(SHA256_CTX *ctx, uint8_t out[SHA256_DIGEST_SIZE]);\n/*\n * One-shot convenience function: hash a complete message in one call.\n * Equivalent to: init, update(msg, len), finalize.\n */\nvoid sha256(const uint8_t *msg, size_t len, uint8_t out[SHA256_DIGEST_SIZE]);\n#endif /* SHA256_H */\n```\nWalk through each field in the struct:\n**`H[8]`**: The eight 32-bit working state words. At initialization, these hold the FIPS 180-4 initial values. After each block is compressed, they hold the updated state. At finalization, they hold the final hash values before output formatting.\n**`buf[64]`**: A 64-byte buffer for data that hasn't yet formed a complete block. If you call `update()` with 20 bytes, all 20 bytes go here. If you then call `update()` with 50 more bytes, the first 44 bytes complete the block (44 + 20 = 64), triggering a compression; the remaining 6 bytes go back into `buf`.\n**`buf_len`**: How many bytes are currently valid in `buf`. This ranges from 0 to 63. When it reaches 64, the buffer is compressed and reset to 0.\n**`total_len`**: The total number of bytes fed to `update()` across all calls so far. This is used at finalization to compute the 64-bit length field in the padding. Note: this counts *bytes*, not bits. The padding function multiplies by 8 to get the bit count.\n---\n## Implementing `sha256_init`: State Reset\n```c\n#include \"sha256.h\"\n#include <string.h>   /* memset, memcpy */\nvoid sha256_init(SHA256_CTX *ctx) {\n    /* Set hash state to FIPS 180-4 Section 5.3.3 initial values */\n    ctx->H[0] = 0x6A09E667;\n    ctx->H[1] = 0xBB67AE85;\n    ctx->H[2] = 0x3C6EF372;\n    ctx->H[3] = 0xA54FF53A;\n    ctx->H[4] = 0x510E527F;\n    ctx->H[5] = 0x9B05688C;\n    ctx->H[6] = 0x1F83D9AB;\n    ctx->H[7] = 0x5BE0CD19;\n    /* Clear partial block buffer */\n    memset(ctx->buf, 0, SHA256_BLOCK_SIZE);\n    ctx->buf_len   = 0;\n    ctx->total_len = 0;\n}\n```\nThis function is the answer to Bug 3. Every field is reset to a known starting state. Calling `sha256_init()` on an already-used context returns it to exactly the state of a freshly created context. This means you can reuse contexts without heap allocations:\n```c\nSHA256_CTX ctx;\nsha256_init(&ctx);          /* first computation */\nsha256_update(&ctx, ...);\nsha256_finalize(&ctx, out1);\nsha256_init(&ctx);          /* reset and reuse */\nsha256_update(&ctx, ...);\nsha256_finalize(&ctx, out2);\n```\n---\n## Implementing `sha256_update`: The Streaming State Machine\n\n![Streaming API \u2014 State Machine Diagram](./diagrams/diag-m4-streaming-api-state-machine.svg)\n\nThe `update()` function is the heart of the streaming API. It must handle three distinct situations, potentially all within a single call:\n1. **The incoming data completes a partial block in `buf`**: copy enough bytes from `data` to fill `buf` to 64 bytes, compress it, then proceed.\n2. **The remaining data contains full blocks**: compress each one directly from `data` without copying into `buf`.\n3. **The remaining data is a partial block**: copy it into `buf` and stop.\n```c\n/* Forward declarations \u2014 implemented in sha256_schedule.c and sha256_compress.c */\nextern void sha256_schedule(const uint8_t *block, uint32_t W[64]);\nextern void sha256_compress(uint32_t H[8], const uint32_t W[64]);\nvoid sha256_update(SHA256_CTX *ctx, const uint8_t *data, size_t len) {\n    /* Nothing to do if called with zero bytes */\n    if (len == 0) return;\n    /* Track total bytes for the length field at finalization */\n    ctx->total_len += len;\n    size_t offset = 0;   /* our position in the input data[] */\n    /* ---------------------------------------------------------- */\n    /* Phase 1: complete the partial block in buf, if any         */\n    /* ---------------------------------------------------------- */\n    if (ctx->buf_len > 0) {\n        /*\n         * How many bytes do we need to fill the buffer to 64?\n         * space_in_buf = 64 - buf_len.\n         * Take the minimum of that and what the caller provided.\n         */\n        size_t space_in_buf = SHA256_BLOCK_SIZE - ctx->buf_len;\n        size_t to_copy = (len < space_in_buf) ? len : space_in_buf;\n        memcpy(ctx->buf + ctx->buf_len, data, to_copy);\n        ctx->buf_len += to_copy;\n        offset       += to_copy;\n        if (ctx->buf_len == SHA256_BLOCK_SIZE) {\n            /* Buffer is now a complete block \u2014 compress it */\n            uint32_t W[64];\n            sha256_schedule(ctx->buf, W);\n            sha256_compress(ctx->H, W);\n            ctx->buf_len = 0;\n        }\n    }\n    /* ---------------------------------------------------------- */\n    /* Phase 2: process full blocks directly from data[]          */\n    /* ---------------------------------------------------------- */\n    while (offset + SHA256_BLOCK_SIZE <= len) {\n        uint32_t W[64];\n        sha256_schedule(data + offset, W);\n        sha256_compress(ctx->H, W);\n        offset += SHA256_BLOCK_SIZE;\n    }\n    /* ---------------------------------------------------------- */\n    /* Phase 3: buffer any remaining partial block                */\n    /* ---------------------------------------------------------- */\n    size_t remaining = len - offset;\n    if (remaining > 0) {\n        memcpy(ctx->buf, data + offset, remaining);\n        ctx->buf_len = remaining;\n    }\n}\n```\nLet's trace this for a concrete example. Suppose you call `update()` with 100 bytes when the buffer already holds 30 bytes:\n- **Phase 1**: `space_in_buf = 64 - 30 = 34`. `to_copy = min(34, 100) = 34`. Copy 34 bytes into `buf`, making `buf_len = 64`. Compress `buf`. Reset `buf_len = 0`. `offset = 34`.\n- **Phase 2**: `remaining = 100 - 34 = 66 bytes`. Is `34 + 64 \u2264 100`? Yes (`98 \u2264 100`). Compress bytes `[34..97]` directly. `offset = 98`.\n- **Phase 3**: `remaining = 100 - 98 = 2 bytes`. Copy bytes `[98..99]` into `buf`. `buf_len = 2`.\nAfter this call: two blocks were compressed, two bytes sit in `buf`, `total_len` increased by 100. Correct.\n\n![Trace: Streaming Hash of 'abc' in Two Chunks](./diagrams/diag-m4-chunked-update-trace.svg)\n\n---\n## Implementing `sha256_finalize`: Padding and Output\nFinalization must do three things:\n1. **Pad and compress** the data remaining in `buf` (using the same padding logic from Milestone 1, but operating on the partial buffer rather than the full message)\n2. **Format the output** \u2014 serialize H[0..7] as a 32-byte big-endian sequence\n3. **Security: clear sensitive state** \u2014 overwrite the context to prevent leaking intermediate hash values\n```c\n/* Helper: write a 64-bit value as 8 big-endian bytes */\nstatic void write_uint64_be(uint8_t *p, uint64_t v) {\n    p[0] = (uint8_t)(v >> 56);\n    p[1] = (uint8_t)(v >> 48);\n    p[2] = (uint8_t)(v >> 40);\n    p[3] = (uint8_t)(v >> 32);\n    p[4] = (uint8_t)(v >> 24);\n    p[5] = (uint8_t)(v >> 16);\n    p[6] = (uint8_t)(v >>  8);\n    p[7] = (uint8_t)(v >>  0);\n}\n/* Helper: write a 32-bit value as 4 big-endian bytes */\nstatic void write_uint32_be(uint8_t *p, uint32_t v) {\n    p[0] = (uint8_t)(v >> 24);\n    p[1] = (uint8_t)(v >> 16);\n    p[2] = (uint8_t)(v >>  8);\n    p[3] = (uint8_t)(v >>  0);\n}\nvoid sha256_finalize(SHA256_CTX *ctx, uint8_t out[SHA256_DIGEST_SIZE]) {\n    /*\n     * At this point:\n     *   ctx->buf[0..buf_len-1] holds the remaining uncompressed bytes.\n     *   ctx->total_len holds the total message length in bytes.\n     *\n     * We need to apply SHA-256 padding to buf, then compress the\n     * resulting one or two final blocks, then serialize H[] to out[].\n     */\n    /* ---------------------------------------------------------- */\n    /* Step 1: Append 0x80 byte                                   */\n    /* ---------------------------------------------------------- */\n    ctx->buf[ctx->buf_len] = 0x80;\n    ctx->buf_len++;\n    /* ---------------------------------------------------------- */\n    /* Step 2: Determine if we need one or two padding blocks     */\n    /* ---------------------------------------------------------- */\n    /*\n     * We need room for the 8-byte length field at the END of the block.\n     * If buf_len > 56, there isn't enough room \u2014 we need a second block.\n     *\n     * Why 56? The block is 64 bytes. The last 8 bytes are the length field.\n     * 64 - 8 = 56. If our data (including the 0x80 byte) exceeds 56 bytes,\n     * we spill into a second block.\n     */\n    if (ctx->buf_len > 56) {\n        /* Fill rest of this block with zeros and compress it */\n        memset(ctx->buf + ctx->buf_len, 0,\n               SHA256_BLOCK_SIZE - ctx->buf_len);\n        uint32_t W[64];\n        sha256_schedule(ctx->buf, W);\n        sha256_compress(ctx->H, W);\n        /* Now start a fresh (all-zero) block for the length field */\n        memset(ctx->buf, 0, SHA256_BLOCK_SIZE);\n        ctx->buf_len = 0;\n    } else {\n        /* Zero out the space between 0x80 and the length field */\n        memset(ctx->buf + ctx->buf_len, 0, 56 - ctx->buf_len);\n    }\n    /* ---------------------------------------------------------- */\n    /* Step 3: Write the 64-bit message length (in BITS)          */\n    /* ---------------------------------------------------------- */\n    /*\n     * The length field is at bytes 56-63 of the final block.\n     * It encodes the ORIGINAL message length in bits.\n     * total_len is in bytes; multiply by 8 to get bits.\n     *\n     * Note: (uint64_t) cast prevents overflow for messages > 512 MB\n     * on systems where size_t is 32 bits.\n     */\n    uint64_t bit_length = (uint64_t)ctx->total_len * 8;\n    write_uint64_be(ctx->buf + 56, bit_length);\n    /* ---------------------------------------------------------- */\n    /* Step 4: Compress the final block                           */\n    /* ---------------------------------------------------------- */\n    {\n        uint32_t W[64];\n        sha256_schedule(ctx->buf, W);\n        sha256_compress(ctx->H, W);\n    }\n    /* ---------------------------------------------------------- */\n    /* Step 5: Serialize H[0..7] as 32 big-endian bytes           */\n    /* ---------------------------------------------------------- */\n    for (int i = 0; i < 8; i++) {\n        write_uint32_be(out + i * 4, ctx->H[i]);\n    }\n    /* ---------------------------------------------------------- */\n    /* Step 6: Clear the context (security hygiene)               */\n    /* ---------------------------------------------------------- */\n    /*\n     * Overwrite the internal state with zeros to prevent\n     * the intermediate hash values from leaking through memory\n     * if the context struct is later read by other code.\n     * This matters in security-sensitive contexts (password hashing,\n     * key derivation) where intermediate values are sensitive.\n     */\n    memset(ctx, 0, sizeof(SHA256_CTX));\n}\n```\nThe finalization logic has one subtlety worth examining closely: the condition `if (ctx->buf_len > 56)`. After appending the `0x80` byte, `buf_len` reflects the filled portion including that byte. If this exceeds 56, we compress the current block with zero-padding (no length field yet), then compose a second block that is entirely zero-padded except for the 8-byte length field at the end. If `buf_len` is 56 or less, we have enough room to fit the length field in the current block \u2014 just zero-fill bytes `[buf_len..55]` and write the length to bytes `[56..63]`.\n> \u26a0\ufe0f **One nuance about Step 6**: The `memset(ctx, 0, sizeof(SHA256_CTX))` call zeroes the `H[]` array, `buf[]`, `buf_len`, and `total_len`. This means the context is invalid for further use after `finalize()`. Callers who want to continue must call `sha256_init()` again. This is intentional \u2014 an API that silently allows using a finalized context as if it were initialized would be a source of subtle bugs.\n---\n## Implementing the One-Shot Interface\nThe one-shot `sha256()` function is a convenience wrapper that the test suite uses heavily:\n```c\nvoid sha256(const uint8_t *msg, size_t len, uint8_t out[SHA256_DIGEST_SIZE]) {\n    SHA256_CTX ctx;\n    sha256_init(&ctx);\n    sha256_update(&ctx, msg, len);\n    sha256_finalize(&ctx, out);\n}\n```\nThree lines. No state management, no buffer allocation. This is the composability benefit of building init/update/finalize correctly \u2014 the one-shot interface falls out for free.\n---\n## Producing the Hexadecimal Output\nThe 32-byte digest from `sha256_finalize()` is binary. Most consumers want a 64-character lowercase hexadecimal string. This conversion is straightforward but has one common error: forgetting to lowercase the hex digits.\n```c\n/*\n * sha256_hex: convert a 32-byte binary digest to a 65-byte\n *             null-terminated lowercase hex string.\n *\n * Parameters:\n *   digest - 32-byte binary digest from sha256_finalize()\n *   hex    - output buffer, must be at least 65 bytes\n *              (64 hex chars + 1 null terminator)\n */\nvoid sha256_hex(const uint8_t digest[SHA256_DIGEST_SIZE], char hex[65]) {\n    static const char HEX[] = \"0123456789abcdef\";\n    for (int i = 0; i < SHA256_DIGEST_SIZE; i++) {\n        hex[i * 2 + 0] = HEX[(digest[i] >> 4) & 0x0F];  /* high nibble */\n        hex[i * 2 + 1] = HEX[(digest[i] >> 0) & 0x0F];  /* low nibble  */\n    }\n    hex[64] = '\\0';\n}\n```\nA **nibble** is half a byte \u2014 four bits. Each byte `digest[i]` contains two nibbles: the upper four bits (the \"high nibble\") and the lower four bits (the \"low nibble\"). Each nibble maps to exactly one hex digit (0\u20139 or a\u2013f). The expression `(digest[i] >> 4) & 0x0F` shifts the upper nibble to the low position and masks to ensure only the lowest four bits survive; `(digest[i] >> 0) & 0x0F` (the `>> 0` is a no-op, included for visual symmetry) extracts the lower nibble directly.\nThe `HEX` lookup table ensures lowercase output. If you use `'A'` through `'F'` instead of `'a'` through `'f'`, your hex string will look like `BA7816BF...` instead of `ba7816bf...`, and string comparison against the NIST test vectors will fail even if the binary digest is correct. NIST vectors use lowercase.\n---\n## The Complete Module: All Files Together\nHere is the complete file structure for the SHA-256 implementation:\n```\nsha256/\n\u251c\u2500\u2500 sha256_pad.h      / sha256_pad.c       (Milestone 1)\n\u251c\u2500\u2500 sha256_schedule.h / sha256_schedule.c  (Milestone 2)\n\u251c\u2500\u2500 sha256_compress.h / sha256_compress.c  (Milestone 3)\n\u251c\u2500\u2500 sha256.h          / sha256.c           (Milestone 4 \u2014 this file)\n\u2514\u2500\u2500 test_sha256.c                          (test suite)\n```\nThe `sha256.c` implementation (combining everything above):\n```c\n/* sha256.c */\n#include \"sha256.h\"\n#include \"sha256_schedule.h\"\n#include \"sha256_compress.h\"\n#include <string.h>\n/* --- helpers ---------------------------------------------------- */\nstatic void write_uint32_be(uint8_t *p, uint32_t v) {\n    p[0] = (uint8_t)(v >> 24);\n    p[1] = (uint8_t)(v >> 16);\n    p[2] = (uint8_t)(v >>  8);\n    p[3] = (uint8_t)(v >>  0);\n}\nstatic void write_uint64_be(uint8_t *p, uint64_t v) {\n    p[0] = (uint8_t)(v >> 56); p[1] = (uint8_t)(v >> 48);\n    p[2] = (uint8_t)(v >> 40); p[3] = (uint8_t)(v >> 32);\n    p[4] = (uint8_t)(v >> 24); p[5] = (uint8_t)(v >> 16);\n    p[6] = (uint8_t)(v >>  8); p[7] = (uint8_t)(v >>  0);\n}\n/* --- public API -------------------------------------------------- */\nvoid sha256_init(SHA256_CTX *ctx) {\n    ctx->H[0] = 0x6A09E667; ctx->H[1] = 0xBB67AE85;\n    ctx->H[2] = 0x3C6EF372; ctx->H[3] = 0xA54FF53A;\n    ctx->H[4] = 0x510E527F; ctx->H[5] = 0x9B05688C;\n    ctx->H[6] = 0x1F83D9AB; ctx->H[7] = 0x5BE0CD19;\n    memset(ctx->buf, 0, SHA256_BLOCK_SIZE);\n    ctx->buf_len   = 0;\n    ctx->total_len = 0;\n}\nvoid sha256_update(SHA256_CTX *ctx, const uint8_t *data, size_t len) {\n    if (len == 0) return;\n    ctx->total_len += len;\n    size_t offset = 0;\n    if (ctx->buf_len > 0) {\n        size_t to_copy = SHA256_BLOCK_SIZE - ctx->buf_len;\n        if (to_copy > len) to_copy = len;\n        memcpy(ctx->buf + ctx->buf_len, data, to_copy);\n        ctx->buf_len += to_copy;\n        offset       += to_copy;\n        if (ctx->buf_len == SHA256_BLOCK_SIZE) {\n            uint32_t W[64];\n            sha256_schedule(ctx->buf, W);\n            sha256_compress(ctx->H, W);\n            ctx->buf_len = 0;\n        }\n    }\n    while (offset + SHA256_BLOCK_SIZE <= len) {\n        uint32_t W[64];\n        sha256_schedule(data + offset, W);\n        sha256_compress(ctx->H, W);\n        offset += SHA256_BLOCK_SIZE;\n    }\n    size_t remaining = len - offset;\n    if (remaining > 0) {\n        memcpy(ctx->buf, data + offset, remaining);\n        ctx->buf_len = remaining;\n    }\n}\nvoid sha256_finalize(SHA256_CTX *ctx, uint8_t out[SHA256_DIGEST_SIZE]) {\n    ctx->buf[ctx->buf_len++] = 0x80;\n    if (ctx->buf_len > 56) {\n        memset(ctx->buf + ctx->buf_len, 0,\n               SHA256_BLOCK_SIZE - ctx->buf_len);\n        uint32_t W[64];\n        sha256_schedule(ctx->buf, W);\n        sha256_compress(ctx->H, W);\n        memset(ctx->buf, 0, SHA256_BLOCK_SIZE);\n        ctx->buf_len = 0;\n    } else {\n        memset(ctx->buf + ctx->buf_len, 0, 56 - ctx->buf_len);\n    }\n    write_uint64_be(ctx->buf + 56, (uint64_t)ctx->total_len * 8);\n    uint32_t W[64];\n    sha256_schedule(ctx->buf, W);\n    sha256_compress(ctx->H, W);\n    for (int i = 0; i < 8; i++) {\n        write_uint32_be(out + i * 4, ctx->H[i]);\n    }\n    memset(ctx, 0, sizeof(SHA256_CTX));\n}\nvoid sha256(const uint8_t *msg, size_t len, uint8_t out[SHA256_DIGEST_SIZE]) {\n    SHA256_CTX ctx;\n    sha256_init(&ctx);\n    sha256_update(&ctx, msg, len);\n    sha256_finalize(&ctx, out);\n}\nvoid sha256_hex(const uint8_t digest[SHA256_DIGEST_SIZE], char hex[65]) {\n    static const char HEX[] = \"0123456789abcdef\";\n    for (int i = 0; i < SHA256_DIGEST_SIZE; i++) {\n        hex[i * 2 + 0] = HEX[(digest[i] >> 4) & 0x0F];\n        hex[i * 2 + 1] = HEX[(digest[i] >> 0) & 0x0F];\n    }\n    hex[64] = '\\0';\n}\n```\n---\n## Validating Against NIST Test Vectors\n\n![Complete SHA-256 Trace for 'abc' \u2014 End to End](./diagrams/diag-m4-full-pipeline-trace-abc.svg)\n\nNIST provides standard test vectors \u2014 pairs of (input, expected output) \u2014 that every conforming SHA-256 implementation must produce exactly. These are **known-answer tests (KATs)**: you know the correct answer in advance, and you're testing whether your implementation agrees with it. KATs are the gold standard for validating cryptographic implementations because they are unambiguous and authoritative.\nThe three primary NIST SHA-256 test vectors are:\n| Input | SHA-256 Hash |\n|-------|-------------|\n| `\"\"` (empty string) | `e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855` |\n| `\"abc\"` | `ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad` |\n| `\"abcdbcdecdefdefgefghfghighijhijkijkljklmklmnlmnomnopnopq\"` | `248d6a61d20638b8e5c026930c3e6039a33ce45964ff2167f6ecedd419db06c1` |\nThe third test vector is 56 bytes long \u2014 you will recognize this immediately as the 56-byte boundary case from Milestone 1. It requires two blocks. If your Milestone 1 implementation handled this correctly, this test vector will pass.\nHere is the complete test suite:\n```c\n/* test_sha256.c */\n#include <stdio.h>\n#include <string.h>\n#include <assert.h>\n#include <stdint.h>\n#include \"sha256.h\"\n/* ------------------------------------------------------------------ */\n/* Utility: compare digest against expected hex string, report result */\n/* ------------------------------------------------------------------ */\nstatic int check(const char *label,\n                 const uint8_t *digest,\n                 const char *expected_hex) {\n    char actual_hex[65];\n    sha256_hex(digest, actual_hex);\n    if (strcmp(actual_hex, expected_hex) == 0) {\n        printf(\"PASS [%s]\\n     %s\\n\", label, actual_hex);\n        return 1;\n    } else {\n        printf(\"FAIL [%s]\\n     got:      %s\\n     expected: %s\\n\",\n               label, actual_hex, expected_hex);\n        return 0;\n    }\n}\n/* ------------------------------------------------------------------ */\n/* Test 1: Empty string                                                */\n/* ------------------------------------------------------------------ */\nstatic void test_empty(void) {\n    uint8_t digest[32];\n    sha256(NULL, 0, digest);\n    /* Note: pass \"\" not NULL if sha256_update guards against NULL */\n    SHA256_CTX ctx;\n    sha256_init(&ctx);\n    sha256_finalize(&ctx, digest);\n    check(\"SHA-256('')\",\n          digest,\n          \"e3b0c44298fc1c149afbf4c8996fb924\"\n          \"27ae41e4649b934ca495991b7852b855\");\n}\n/* ------------------------------------------------------------------ */\n/* Test 2: \"abc\" \u2014 one block, classic test vector                     */\n/* ------------------------------------------------------------------ */\nstatic void test_abc(void) {\n    uint8_t digest[32];\n    const uint8_t msg[] = \"abc\";\n    sha256(msg, 3, digest);\n    check(\"SHA-256('abc')\",\n          digest,\n          \"ba7816bf8f01cfea414140de5dae2223\"\n          \"b00361a396177a9cb410ff61f20015ad\");\n}\n/* ------------------------------------------------------------------ */\n/* Test 3: 56-byte message \u2014 two blocks required                       */\n/* ------------------------------------------------------------------ */\nstatic void test_56_bytes(void) {\n    uint8_t digest[32];\n    /*\n     * \"abcdbcdecdefdefgefghfghighijhijkijkljklmklmnlmnomnopnopq\"\n     * Length: 56 bytes \u2014 the boundary case that forces two padding blocks.\n     */\n    const uint8_t msg[] =\n        \"abcdbcdecdefdefgefghfghighijhijk\"\n        \"ijkljklmklmnlmnomnopnopq\";\n    sha256(msg, 56, digest);\n    check(\"SHA-256(56-byte message)\",\n          digest,\n          \"248d6a61d20638b8e5c026930c3e6039\"\n          \"a33ce45964ff2167f6ecedd419db06c1\");\n}\n/* ------------------------------------------------------------------ */\n/* Test 4: Streaming \u2014 same result regardless of chunk size           */\n/* ------------------------------------------------------------------ */\nstatic void test_streaming(void) {\n    const uint8_t msg[] =\n        \"abcdbcdecdefdefgefghfghighijhijk\"\n        \"ijkljklmklmnlmnomnopnopq\";\n    const char *expected =\n        \"248d6a61d20638b8e5c026930c3e6039\"\n        \"a33ce45964ff2167f6ecedd419db06c1\";\n    /* Feed 56 bytes in chunks of 1 byte at a time */\n    {\n        uint8_t digest[32];\n        SHA256_CTX ctx;\n        sha256_init(&ctx);\n        for (int i = 0; i < 56; i++) {\n            sha256_update(&ctx, msg + i, 1);\n        }\n        sha256_finalize(&ctx, digest);\n        check(\"SHA-256(56 bytes, 1 byte/call)\", digest, expected);\n    }\n    /* Feed 56 bytes in chunks of 7 bytes at a time */\n    {\n        uint8_t digest[32];\n        SHA256_CTX ctx;\n        sha256_init(&ctx);\n        for (int i = 0; i < 56; i += 7) {\n            sha256_update(&ctx, msg + i, 7);\n        }\n        sha256_finalize(&ctx, digest);\n        check(\"SHA-256(56 bytes, 7 bytes/call)\", digest, expected);\n    }\n    /* Feed 56 bytes in chunks of 13 bytes */\n    {\n        uint8_t digest[32];\n        SHA256_CTX ctx;\n        sha256_init(&ctx);\n        for (size_t offset = 0; offset < 56; ) {\n            size_t chunk = (offset + 13 <= 56) ? 13 : 56 - offset;\n            sha256_update(&ctx, msg + offset, chunk);\n            offset += chunk;\n        }\n        sha256_finalize(&ctx, digest);\n        check(\"SHA-256(56 bytes, 13 bytes/call)\", digest, expected);\n    }\n}\n/* ------------------------------------------------------------------ */\n/* Test 5: Context reuse \u2014 state reset between invocations            */\n/* ------------------------------------------------------------------ */\nstatic void test_context_reuse(void) {\n    SHA256_CTX ctx;\n    uint8_t digest1[32], digest2[32];\n    /* First computation: hash \"abc\" */\n    sha256_init(&ctx);\n    sha256_update(&ctx, (const uint8_t *)\"abc\", 3);\n    sha256_finalize(&ctx, digest1);\n    /* Second computation: hash \"abc\" again with the SAME ctx variable\n     * (init() must fully reset it) */\n    sha256_init(&ctx);\n    sha256_update(&ctx, (const uint8_t *)\"abc\", 3);\n    sha256_finalize(&ctx, digest2);\n    if (memcmp(digest1, digest2, 32) == 0) {\n        printf(\"PASS [Context reuse \u2014 identical output on identical input]\\n\");\n    } else {\n        printf(\"FAIL [Context reuse \u2014 different output on same input!]\\n\");\n        char h1[65], h2[65];\n        sha256_hex(digest1, h1);\n        sha256_hex(digest2, h2);\n        printf(\"     first:  %s\\n     second: %s\\n\", h1, h2);\n    }\n    /* Third computation: hash \"\" \u2014 should equal the empty-string vector */\n    sha256_init(&ctx);\n    sha256_finalize(&ctx, digest2);\n    check(\"Context reuse \u2014 empty string after 'abc'\",\n          digest2,\n          \"e3b0c44298fc1c149afbf4c8996fb924\"\n          \"27ae41e4649b934ca495991b7852b855\");\n}\n/* ------------------------------------------------------------------ */\n/* Test 6: Exact block-boundary inputs                                */\n/* ------------------------------------------------------------------ */\nstatic void test_block_boundaries(void) {\n    uint8_t msg[128];\n    uint8_t digest_oneshot[32], digest_streaming[32];\n    /* Test: exactly 64 bytes (one complete block, no padding spill) */\n    memset(msg, 0x41, 64);  /* 64 'A' bytes */\n    sha256(msg, 64, digest_oneshot);\n    SHA256_CTX ctx;\n    sha256_init(&ctx);\n    sha256_update(&ctx, msg, 32);   /* first half */\n    sha256_update(&ctx, msg + 32, 32); /* second half */\n    sha256_finalize(&ctx, digest_streaming);\n    if (memcmp(digest_oneshot, digest_streaming, 32) == 0) {\n        printf(\"PASS [64-byte block boundary: oneshot == streaming]\\n\");\n    } else {\n        printf(\"FAIL [64-byte block boundary: oneshot != streaming]\\n\");\n    }\n    /* Test: exactly 128 bytes (two complete blocks) */\n    memset(msg, 0x42, 128);  /* 128 'B' bytes */\n    sha256(msg, 128, digest_oneshot);\n    sha256_init(&ctx);\n    sha256_update(&ctx, msg, 64);\n    sha256_update(&ctx, msg + 64, 64);\n    sha256_finalize(&ctx, digest_streaming);\n    if (memcmp(digest_oneshot, digest_streaming, 32) == 0) {\n        printf(\"PASS [128-byte block boundary: oneshot == streaming]\\n\");\n    } else {\n        printf(\"FAIL [128-byte block boundary: oneshot != streaming]\\n\");\n    }\n}\n/* ------------------------------------------------------------------ */\n/* main                                                                */\n/* ------------------------------------------------------------------ */\nint main(void) {\n    printf(\"=== SHA-256 Test Suite ===\\n\\n\");\n    test_empty();\n    test_abc();\n    test_56_bytes();\n    test_streaming();\n    test_context_reuse();\n    test_block_boundaries();\n    printf(\"\\n=== All tests complete. ===\\n\");\n    return 0;\n}\n```\nBuild and run:\n```bash\ngcc -Wall -Wextra -o test_sha256 \\\n    test_sha256.c sha256.c sha256_compress.c sha256_schedule.c sha256_pad.c\n./test_sha256\n```\nIf all tests pass, your implementation is correct for all scenarios the NIST specification defines. Every PASS line represents a guarantee: your implementation is compatible with every other SHA-256 implementation in the world for those inputs.\n---\n## Debugging When Tests Fail\n\n![State Reset Bug \u2014 Before and After Fix](./diagrams/diag-m4-state-reset-before-after.svg)\n\nWhen a test fails, the failure pattern tells you which component is wrong. Use this decision tree:\n**If test 1 (empty string) fails:**\n- Verify `H[0..7]` initial values byte-by-byte against FIPS 180-4\n- Verify the empty-input padding block from Milestone 1 (`0x80` at byte 0, zero length field)\n- Print the full 64-byte padded block and compare manually\n**If test 2 (\"abc\") fails but test 1 passes:**\n- Your compression function is likely wrong \u2014 \"abc\" tests the full pipeline\n- Print H[0..7] after compression and compare against the values from Milestone 3's test (`H[0] = 0xBA7816BF`)\n- If the state is correct but the output hex is wrong, check `write_uint32_be` endianness\n**If test 3 (56-byte message) fails but test 2 passes:**\n- Your two-block finalization is wrong\n- Check the condition `if (ctx->buf_len > 56)` \u2014 off-by-one here produces exactly one-block behavior for 56-byte inputs\n- Print `ctx->buf_len` before and after adding `0x80`; it should be 57 for a 56-byte message, triggering the two-block path\n**If test 4 (streaming) fails but test 3 passes:**\n- Your `update()` buffer management has an edge case bug\n- Check the case where incoming data exactly fills the buffer (`buf_len + incoming == 64`)\n- Check the case where `update()` is called with more than 64 bytes when the buffer is empty\n**If test 5 (context reuse) fails but test 4 passes:**\n- `sha256_init()` is not fully resetting some field\n- Check that `total_len`, `buf_len`, and all of `H[0..7]` are reset\n- Check that `buf[]` is zeroed (failure to clear the buffer doesn't always produce visible errors, but memset(ctx, 0) in finalize followed by sha256_init may be confused)\n**General technique**: Add temporary `printf` calls to print the state of `H[0..7]` and `buf_len` at key transition points. Compare against the NIST example computation values. The first point where your values diverge from the reference is the location of the bug.\n---\n## Complete End-to-End Trace for \"abc\"\n\n![Complete SHA-256 Trace for 'abc' \u2014 End to End](./diagrams/diag-m4-full-pipeline-trace-abc.svg)\n\nHere is the complete trace of every operation for SHA-256(\"abc\"), narrating what each stage produces:\n**Input**: 3 bytes `{0x61, 0x62, 0x63}` (\"abc\")\n**After `sha256_init()`**:\n- `H = {0x6A09E667, 0xBB67AE85, 0x3C6EF372, 0xA54FF53A, 0x510E527F, 0x9B05688C, 0x1F83D9AB, 0x5BE0CD19}`\n- `buf_len = 0`, `total_len = 0`\n**After `sha256_update(&ctx, \"abc\", 3)`**:\n- 3 bytes copied to `buf` (Phase 3 only \u2014 no complete blocks)\n- `buf = {0x61, 0x62, 0x63, 0x00, ...}`, `buf_len = 3`, `total_len = 3`\n- `H` unchanged (no compression yet)\n**During `sha256_finalize()`**:\n- Append `0x80`: `buf[3] = 0x80`, `buf_len = 4`\n- `buf_len (4) \u2264 56`: single-block path\n- Zero bytes `[4..55]` in `buf`\n- Write 64-bit length: `(uint64_t)3 * 8 = 24 = 0x18` \u2192 bytes 56-63 become `{0,0,0,0,0,0,0,0x18}`\n- Final `buf`: `{61 62 63 80 00...00 00 00 00 00 00 00 00 18}` (64 bytes)\n- Schedule expansion: `W[0] = 0x61626380`, `W[15] = 0x00000018`, W[16..63] expanded\n- Compression: 64 rounds transform H from initial values to:\n  - `H = {0xBA7816BF, 0x8F01CFEA, 0x414140DE, 0x5DAE2223, 0xB00361A3, 0x96177A9C, 0xB410FF61, 0xF20015AD}`\n**Output serialization**:\n```\nH[0]=0xBA7816BF \u2192 bytes: BA 78 16 BF\nH[1]=0x8F01CFEA \u2192 bytes: 8F 01 CF EA\nH[2]=0x414140DE \u2192 bytes: 41 41 40 DE\nH[3]=0x5DAE2223 \u2192 bytes: 5D AE 22 23\nH[4]=0xB00361A3 \u2192 bytes: B0 03 61 A3\nH[5]=0x96177A9C \u2192 bytes: 96 17 7A 9C\nH[6]=0xB410FF61 \u2192 bytes: B4 10 FF 61\nH[7]=0xF20015AD \u2192 bytes: F2 00 15 AD\n```\n**Hex string**: `ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad` \u2713\n---\n## Knowledge Cascade: What You've Actually Built\n### 1. The SHA-2 Family: One Algorithm, Eight Variants\nNow that you understand SHA-256 completely, the rest of the SHA-2 family is immediately legible. SHA-224 uses the same algorithm with different initial values (the fractional parts of the square roots of the 9th through 16th primes) and truncates the output to 224 bits (dropping H[7] from the final concatenation). SHA-512 uses 64-bit words instead of 32-bit words, an 80-round compression function, and 1024-bit blocks \u2014 but the same structural design: eight working variables, Ch, Maj, uppercase \u03a3 functions, a message schedule with lowercase \u03c3 functions, and initial values from prime square roots. SHA-384 is SHA-512 with different initial values and truncated output. SHA-512/256 is SHA-512 truncated to 256 bits with initial values derived by a different process, providing a 256-bit hash with better performance on 64-bit architectures than SHA-256.\nThe pattern is a **parameterized family**: one design with knobs for word size, number of rounds, initial values, and output truncation. Knowing SHA-256 deeply means you already understand the family's structure. When you encounter SHA-512 in a TLS certificate or SSH key fingerprint, you can reason about its security and performance directly from what you've built.\n> \ud83d\udd2d **Deep Dive**: FIPS 180-4 specifies all six members of SHA-2 in a single document, with a unified algorithmic description that makes the parameterization explicit. NIST's \"Secure Hash Standard\" (available at csrc.nist.gov/publications/detail/fips/180/4/final) is worth reading in full now that you've implemented one member of the family \u2014 the spec reads very differently once you've translated its pseudocode into running code.\n### 2. The update/finalize Pattern: Universal Incremental Processing\nThe streaming API you just built \u2014 `init()`, `update()`, `finalize()` \u2014 is one of the most universal patterns in systems programming. It appears wherever a computation must process unbounded input in bounded memory.\n**TLS record layer**: TLS breaks application data into records of up to 16 KB. Each record is encrypted and authenticated independently. The TLS implementation maintains a streaming context for the ongoing connection and processes records as they arrive, exactly as your `sha256_update()` processes 64-byte blocks.\n**Write-ahead logs (WAL) in databases**: PostgreSQL, SQLite, and MySQL all maintain logs where each write is appended incrementally. A background process periodically flushes (finalizes) the log segment. The partial-buffer management you built for SHA-256 is structurally identical to the page-buffer management in a WAL implementation.\n**Video codecs**: H.264 and H.265 process video frames in macroblocks. The codec context maintains state across frames. Each `update()` call corresponds to processing one macroblock; the flush at the end of a frame corresponds to `finalize()`.\n**Parser combinators**: Parsers for binary protocols (DNS wire format, TLS handshake messages, protobuf) process bytes as they arrive from the network. A streaming parser maintains a state machine that tracks partial message state \u2014 structurally identical to `buf_len` tracking how many bytes of the current block have been buffered.\nThe deep pattern is: **incremental computation with bounded working memory**. Any time you have a function that must process an unbounded stream but can only do useful work on fixed-size chunks, you need this pattern. SHA-256's streaming API is the cleanest, most minimal instantiation of it you'll encounter.\n### 3. State Machine Discipline: the Buffer as a Miniature Protocol\nThe internal state of your `SHA256_CTX` is a miniature state machine with three states:\n- **Empty**: `buf_len == 0`. No partial data buffered. The next `update()` call either stays empty (if `len < 64`) or immediately processes complete blocks (if `len \u2265 64`).\n- **Partial**: `0 < buf_len < 64`. Some data is buffered. The next `update()` may complete it (transition to Empty via compression) or add more (stay Partial).\n- **Ready to finalize**: Any state \u2014 `finalize()` pads whatever is in `buf` and produces output.\nThis three-state model recurs constantly in systems programming:\n**TCP reassembly**: TCP segments arrive out of order. The receive buffer maintains partial sequence state \u2014 bytes that have arrived but haven't yet formed a contiguous run from the expected sequence number. The application layer can only `read()` from contiguous runs, so partial state waits in the buffer.\n**Filesystem journaling**: The journal buffer accumulates filesystem operations. When the buffer fills (or on a timeout), the journal is flushed and a checkpoint is recorded. Between checkpoints, the buffer is in the \"partial\" state.\n**Tokenizers**: A lexer reading source code maintains partial token state \u2014 characters accumulated that could be part of a token but haven't yet seen the terminating character. Each `update()` call is equivalent to reading one more character; `finalize()` flushes any pending token at end-of-file.\nThe universal lesson: when you design any system that processes a stream in chunks, make the buffer's state explicit. Track exactly what partial work has been done. Define what init/flush/reset mean. Your SHA-256 context struct is a textbook template for this design.\n\n![Streaming API \u2014 State Machine Diagram](./diagrams/diag-m4-streaming-api-state-machine.svg)\n\n### 4. Known-Answer Tests: the Methodology That Verifies Specifications\nThe test methodology you used \u2014 feeding a known input to your implementation and comparing its output against a value from an authoritative source \u2014 is called a **Known-Answer Test (KAT)**. KATs are the gold standard for validating cryptographic implementations and any other system defined by a formal specification.\nThe same methodology appears throughout engineering:\n**IEEE 754 floating-point**: The IEEE 754 standard specifies exact results for specific floating-point operations, including edge cases like rounding modes, denormals, and NaN propagation. Conformance test suites (like the Berkeley TestFloat suite) consist entirely of KATs: feed a specific bit pattern to `sqrt()`, get a specific bit pattern out.\n**Unicode normalization**: Unicode defines normalization forms (NFC, NFD, NFKC, NFKD) with exact rules for how certain character sequences must be transformed. The Unicode Consortium provides test files with thousands of (input, expected_output) pairs. A conforming implementation must produce exactly the specified output.\n**Protocol compliance**: TLS 1.3 test suites feed specific client hello messages to server implementations and verify the exact bytes of the server response. HTTP/2 compression test suites verify that specific header sequences produce specific HPACK-encoded bytes.\n**NIST Cryptographic Algorithm Validation Program (CAVP)**: NIST maintains an extensive set of algorithm validation test vectors for AES, SHA, HMAC, ECDSA, RSA, and dozens of other primitives. Products used in U.S. government systems must pass these KAT suites before they can claim FIPS compliance. The test vectors you ran in this milestone are exactly the same type of validation.\nThe deeper insight: when you implement any formally specified computation, the specification's test vectors are not \"examples\" \u2014 they are the specification itself, expressed in concrete form. If your implementation passes all the test vectors, it is, by definition, a conforming implementation. The test vectors make the specification executable.\n### 5. Initialization Vectors and the Security of Starting Points\nThe initial hash values H[0..7] play the same role as an **initialization vector (IV)** in symmetric encryption. In AES-CBC (Cipher Block Chaining), an IV is XORed with the first plaintext block before encryption to ensure that identical plaintexts produce different ciphertexts when encrypted with the same key. In SHA-256, the initial values ensure that the compression function's output is the result of mixing the message with a fixed, known starting state \u2014 not with an attacker-controlled state.\nThe security implication is subtle but important. If an attacker could choose the initial hash state, they could construct inputs that produce any desired output. The fixed, nothing-up-my-sleeve initial values prevent this. The attacker cannot choose where the state starts, so they cannot guide the computation toward a chosen output.\nThis connects directly to IV requirements in encryption:\n- **AES-CBC**: IVs must be random and unpredictable to prevent chosen-plaintext attacks. If you reuse an IV with the same key, identical plaintext blocks produce identical ciphertext blocks \u2014 an information leak.\n- **AES-GCM** (Galois/Counter Mode): Nonces (similar to IVs) must never be reused with the same key. Nonce reuse in GCM catastrophically breaks authentication \u2014 an attacker can recover the authentication key. TLS 1.3 uses a counter-based nonce to guarantee uniqueness.\n- **Key Derivation Functions (KDFs)**: PBKDF2, scrypt, and Argon2 use a \"salt\" \u2014 essentially a random initial value \u2014 to ensure that the same password produces a different derived key for different users, preventing rainbow table attacks.\nIn each case, the principle is the same: the starting point of a cryptographic computation must be either fixed (SHA-256 initial values) or random-and-unique (IV/nonce), and it must not be attacker-controlled. Your `sha256_init()` guarantees the fixed case. The context reset between calls guarantees that the starting point is always the canonical FIPS initial values, never the residual state from a previous computation.\n---\n## Common Pitfalls and Final Checklist\nBefore closing out this project, run through this checklist:\n**\u2610 Initial values**: `ctx->H[0] == 0x6A09E667` before any compression. Print it to verify.\n**\u2610 Output endianness**: `sha256_hex()` produces `ba7816bf...` (lowercase, big-endian bytes) not `bf1678ba...` (reversed). The first byte of the hex string is the most significant byte of H[0].\n**\u2610 Length field in bits, not bytes**: `total_len * 8`, not `total_len`. A 3-byte message gets length field 24, not 3. Verify by checking that SHA-256(\"abc\") passes.\n**\u2610 Two-block finalization**: Test the 56-byte message vector explicitly. Print `buf_len` after appending `0x80` \u2014 it must be 57 for a 56-byte message, triggering the two-block path.\n**\u2610 State reset**: Call `sha256_init()` twice and hash the same message both times. Compare digests with `memcmp()` \u2014 they must be identical.\n**\u2610 Streaming invariant**: Hash a 100-byte message in one call, then hash the same message in ten 10-byte calls. Compare digests \u2014 they must be identical.\n**\u2610 Zero-length update**: Call `sha256_update(&ctx, data, 0)`. It must not change the state. Hash the same message with and without a zero-length update \u2014 digests must be identical.\n**\u2610 After finalize**: After `sha256_finalize()`, the context must be in a cleared state (H[0..7] all zero, buf zeroed, counts zero) \u2014 not usable for further hashing without `sha256_init()`.\n---\n## Summary: What You Built\nIn this milestone you completed four things:\n1. **The SHA-256 context struct** \u2014 a 108-byte state envelope holding the 256-bit hash state, a 64-byte partial block buffer, and a 64-bit byte counter; the minimal state needed to resume or finalize a hash computation at any point.\n2. **The streaming API** \u2014 `sha256_init()`, `sha256_update()`, and `sha256_finalize()` \u2014 implementing the universal incremental processing pattern with correct buffer management for all chunk sizes and all block boundary conditions.\n3. **The output serializer** \u2014 big-endian serialization of H[0..7] to 32 bytes and conversion to a 64-character lowercase hexadecimal string, matching the NIST output format exactly.\n4. **A comprehensive test suite** \u2014 seven test scenarios covering the three NIST test vectors, streaming invariance across multiple chunk sizes, context reuse correctness, and exact block boundary behavior.\nYou have built SHA-256 from the NIST specification, from scratch, verified against authoritative test vectors. Every stage \u2014 padding, schedule generation, compression, and finalization \u2014 was built independently, tested in isolation, and then connected into a single correct implementation.\nThe hash you've built is functionally equivalent to OpenSSL's SHA-256, Go's `crypto/sha256`, Python's `hashlib.sha256`, and every other conforming implementation. They all produce `ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad` for \"abc\". Yours does too. That is cryptographic correctness \u2014 not \"approximately right\" or \"right for most inputs,\" but exactly right for every input, provably identical to the FIPS specification.\n---\n<!-- END_MS -->\n",
  "current_ms_index": 4,
  "diagrams_to_generate": [],
  "diagram_attempt": 0,
  "current_diagram_code": null,
  "current_diagram_meta": null,
  "last_error": null,
  "status": "tdd_visualizing",
  "phase": "tdd",
  "tdd_blueprint": {
    "project_title": "SHA-256 Hash Function",
    "design_vision": "A specification-faithful, test-driven implementation of SHA-256 following NIST FIPS 180-4, decomposed into four independently verifiable modules: message preprocessing/padding, message schedule generation, 64-round compression function, and final hash output with streaming API. Each module is verified against NIST known-answer tests before integration. The design prioritizes byte-level correctness, big-endian discipline, and constant-time-safe uint32_t arithmetic throughout.",
    "modules": [
      {
        "id": "hash-impl-m1",
        "name": "Message Preprocessing and Padding",
        "description": "Converts an arbitrary byte sequence into one or more 512-bit (64-byte) blocks conforming to FIPS 180-4 Section 5.1.1. Appends the 0x80 marker, zero-fills to a 448 mod 512 boundary, and appends the 64-bit big-endian message length in bits. Provides a block accessor for sequential downstream consumption. Does NOT implement word extraction, schedule generation, or any compression logic.",
        "specs": {
          "inputs": "Arbitrary byte array (const uint8_t *msg, size_t msg_len); msg may be NULL when msg_len == 0.",
          "outputs": "Contiguous byte buffer of length sha256_padded_length(msg_len) \u2014 always a multiple of 64. Block accessor returns pointer to i-th 64-byte block within that buffer.",
          "abstractions": "sha256_padded_length(size_t msg_len) -> size_t; sha256_pad(uint8_t *out, const uint8_t *msg, size_t msg_len) -> size_t; sha256_get_block(const uint8_t *padded, size_t idx) -> const uint8_t *; sha256_num_blocks(size_t padded_len) -> size_t; write_uint64_be(uint8_t *buf, uint64_t v) -> void.",
          "error_categories": [
            "Buffer undersized (caller allocates fewer than sha256_padded_length bytes \u2014 undefined behavior, must be documented)",
            "NULL msg with nonzero msg_len (undefined behavior \u2014 guard with assertion)",
            "msg_len overflow when multiplied by 8 for bit-length field (theoretical on 64-bit systems for messages > 2^61 bytes \u2014 document limit)"
          ],
          "concurrency_model": "Stateless pure function \u2014 all output written to caller-provided buffer. No internal state, no threading concerns.",
          "performance_targets": [
            "sha256_padded_length: O(1), branchless formula",
            "sha256_pad: O(msg_len), dominated by memcpy \u2014 target memory-bandwidth-bound performance",
            "sha256_get_block: O(1) pointer arithmetic"
          ]
        },
        "implementation_phases": [
          {
            "phase": 1,
            "name": "write_uint64_be and padded_length formula",
            "estimated_hours": "0.5-1"
          },
          {
            "phase": 2,
            "name": "sha256_pad core \u2014 memcpy, 0x80 marker, memset zero-fill, length field",
            "estimated_hours": "0.5-1"
          },
          {
            "phase": 3,
            "name": "Block accessor helpers (sha256_get_block, sha256_num_blocks)",
            "estimated_hours": "0.25"
          },
          {
            "phase": 4,
            "name": "Test suite \u2014 empty input, abc, 55-byte boundary, 56-byte two-block case",
            "estimated_hours": "0.75-1"
          }
        ],
        "diagrams": [
          {
            "id": "tdd-diag-1",
            "title": "Module Architecture \u2014 Padding Module Structs and Functions",
            "description": "Shows the full public API surface: sha256_pad, sha256_padded_length, sha256_get_block, sha256_num_blocks, write_uint64_be. Annotates each function with parameter types, return types, and preconditions. Illustrates dependency: sha256_pad calls write_uint64_be internally. No external dependencies.",
            "type": "architecture",
            "anchor_target": "hash-impl-m1"
          },
          {
            "id": "tdd-diag-2",
            "title": "Data Flow \u2014 Raw Bytes to 512-bit Block Array",
            "description": "Traces data from (msg, msg_len) through sha256_pad: memcpy of message bytes \u2192 0x80 byte insertion \u2192 memset zero region \u2192 write_uint64_be length field \u2192 output padded buffer. Annotates each arrow with the byte range being written and the formula used to compute it. Shows sha256_get_block performing pointer arithmetic on the output buffer.",
            "type": "data_flow",
            "anchor_target": "hash-impl-m1"
          },
          {
            "id": "tdd-diag-3",
            "title": "Memory Layout \u2014 512-bit Padded Block for 'abc' (3 bytes)",
            "description": "Byte-level diagram of the single 64-byte output block for 'abc'. Byte 0\u20132: 0x61 0x62 0x63 (message). Byte 3: 0x80 (marker). Bytes 4\u201355: 0x00 (zero fill). Bytes 56\u201363: 0x00 0x00 0x00 0x00 0x00 0x00 0x00 0x18 (24 as big-endian uint64). Each region labeled with byte offset, byte count, and semantic name.",
            "type": "memory_layout",
            "anchor_target": "hash-impl-m1"
          },
          {
            "id": "tdd-diag-4",
            "title": "Memory Layout \u2014 Two-Block Padding for 56-byte Message (Boundary Case)",
            "description": "Byte-level diagram spanning 128 bytes. Block 1 (bytes 0\u201363): bytes 0\u201355 are message, byte 56 is 0x80, bytes 57\u201363 are 0x00. Block 2 (bytes 64\u2013127): bytes 64\u2013119 are 0x00, bytes 120\u2013127 are 0x00 0x00 0x00 0x00 0x00 0x00 0x01 0xC0 (448 = 56\u00d78 in big-endian). Clearly marks the 64-byte block boundary. Annotates why the length field cannot fit in block 1.",
            "type": "memory_layout",
            "anchor_target": "hash-impl-m1"
          },
          {
            "id": "tdd-diag-5",
            "title": "Algorithm Steps \u2014 Padding Length Decision and Zero-Fill Calculation",
            "description": "Step-by-step trace of sha256_padded_length and the zero-fill region calculation: (1) compute total = ((msg_len + 9 + 63) / 64) * 64; (2) zero_start = msg_len + 1; (3) zero_end = total - 8; (4) zero_count = zero_end - zero_start. Shows before-state (msg_len) and after-state (total, zero_start, zero_end) with concrete values for msg_len \u2208 {0, 3, 55, 56, 64}. Highlights the ceiling-division idiom.",
            "type": "algorithm_steps",
            "anchor_target": "hash-impl-m1"
          },
          {
            "id": "tdd-diag-6",
            "title": "Algorithm Steps \u2014 write_uint64_be Byte Extraction",
            "description": "Before/after diagram for writing a uint64_t value (e.g., 24 = 0x0000000000000018) into 8 bytes. Shows: buf[0] = v>>56, buf[1] = v>>48, ..., buf[7] = v>>0 with each shift value and resulting byte. Contrasts with little-endian layout that a naive cast would produce on x86. Highlights the cast to uint8_t at each step.",
            "type": "algorithm_steps",
            "anchor_target": "hash-impl-m1"
          }
        ]
      },
      {
        "id": "hash-impl-m2",
        "name": "Message Schedule Generation",
        "description": "For each 512-bit block produced by the padding module, parses the block into 16 big-endian 32-bit words (W[0]..W[15]) and expands them to 64 words (W[16]..W[63]) using the FIPS 180-4 recurrence relation with \u03c30 and \u03c31. Does NOT implement the compression function, hash state, or any output formatting.",
        "specs": {
          "inputs": "Pointer to exactly 64 bytes (one 512-bit block). Block must be a valid output of sha256_get_block from M1.",
          "outputs": "Array of 64 uint32_t values W[0..63] written to caller-provided storage.",
          "abstractions": "rotr(uint32_t x, int n) -> uint32_t; sigma0(uint32_t x) -> uint32_t [ROTR(x,7)^ROTR(x,18)^SHR(x,3)]; sigma1(uint32_t x) -> uint32_t [ROTR(x,17)^ROTR(x,19)^SHR(x,10)]; read_uint32_be(const uint8_t *buf, size_t i) -> uint32_t; sha256_parse_block(const uint8_t *block, uint32_t *W); sha256_schedule(const uint8_t *block, uint32_t W[64]).",
          "error_categories": [
            "Wrong rotation constants (\u03c30 vs \u03c31 swap) \u2014 produces plausible but wrong W values, caught only by KAT comparison",
            "SHR used in place of ROTR \u2014 bits destroyed instead of wrapped, diverges from NIST immediately at W[16]",
            "Little-endian block read via pointer cast \u2014 W[0] reads as 0x80636261 instead of 0x61626380 on x86",
            "Signed integer right shift \u2014 implementation-defined behavior fills high bits with sign bit instead of 0"
          ],
          "concurrency_model": "Pure function. Input block is read-only; W array is write-only. No shared state.",
          "performance_targets": [
            "sha256_schedule: 48 iterations of recurrence, each 4 additions + 2 sigma calls (each 3 ops) = ~200 operations per block",
            "Target: compiler auto-vectorization of the parse loop on SIMD-capable platforms",
            "rotr: must compile to single ROR instruction under -O2 \u2014 verify with objdump"
          ]
        },
        "implementation_phases": [
          {
            "phase": 1,
            "name": "rotr and read_uint32_be primitives with isolated unit tests",
            "estimated_hours": "0.5"
          },
          {
            "phase": 2,
            "name": "sigma0 and sigma1 with spot-check tests against NIST example values",
            "estimated_hours": "0.5"
          },
          {
            "phase": 3,
            "name": "sha256_parse_block \u2014 16-word big-endian extraction with endianness test",
            "estimated_hours": "0.25"
          },
          {
            "phase": 4,
            "name": "sha256_schedule recurrence expansion W[16..63]",
            "estimated_hours": "0.5"
          },
          {
            "phase": 5,
            "name": "Full schedule KAT \u2014 print all 64 words for 'abc' and compare against NIST document",
            "estimated_hours": "0.5-1"
          }
        ],
        "diagrams": [
          {
            "id": "tdd-diag-7",
            "title": "Module Architecture \u2014 Schedule Module Functions and Dependencies",
            "description": "Shows sha256_schedule as the public entry point calling sha256_parse_block (which calls read_uint32_be 16 times) and then the recurrence loop calling sigma0 and sigma1 (each calling rotr twice and performing one right-shift). All helper functions marked static. Dependency arrows show call graph. Data types annotated on each edge.",
            "type": "architecture",
            "anchor_target": "hash-impl-m2"
          },
          {
            "id": "tdd-diag-8",
            "title": "Data Flow \u2014 64-byte Block to 64-word Schedule",
            "description": "Shows 64-byte block entering sha256_parse_block, outputting W[0..15] as uint32_t array. Then the recurrence loop consuming W[t-16], W[t-15], W[t-7], W[t-2] to produce W[t] for t=16..63. Labels each arrow with the type (uint8_t* vs uint32_t), and annotates the sigma functions as transformers on individual words.",
            "type": "data_flow",
            "anchor_target": "hash-impl-m2"
          },
          {
            "id": "tdd-diag-9",
            "title": "Algorithm Steps \u2014 ROTR vs SHR on a 32-bit Value",
            "description": "Side-by-side bit-level diagram for a sample 32-bit value (e.g., 0x61626380). Left panel: SHR(x, 7) \u2014 bits shift right, 7 zeros appear at top, 7 bits fall off bottom. Right panel: ROTR(x, 7) \u2014 bits shift right, the 7 bits that fell off bottom wrap to top. Each bit position numbered 31..0. Implements the C expression (x>>n)|(x<<(32-n)) step by step.",
            "type": "algorithm_steps",
            "anchor_target": "hash-impl-m2"
          },
          {
            "id": "tdd-diag-10",
            "title": "Algorithm Steps \u2014 \u03c30 and \u03c31 Computation Trace",
            "description": "Two-panel step-by-step trace. Panel A (\u03c30): input x, compute ROTR(x,7), ROTR(x,18), SHR(x,3), XOR the three results, show final \u03c30(x). Panel B (\u03c31): same structure with rotations 17, 19 and shift 10. Uses concrete value x=0x61626380. Each intermediate value shown in hex and binary. Final XOR shown bit-by-bit for one nibble to make the operation concrete.",
            "type": "algorithm_steps",
            "anchor_target": "hash-impl-m2"
          },
          {
            "id": "tdd-diag-11",
            "title": "Memory Layout \u2014 Big-Endian Word Extraction from Block Bytes",
            "description": "Shows bytes 0\u20137 of the padded 'abc' block (0x61 0x62 0x63 0x80 0x00 0x00 0x00 0x00) with byte offsets labeled. Illustrates read_uint32_be assembling W[0] from bytes [0..3] via shift-OR: (0x61<<24)|(0x62<<16)|(0x63<<8)|0x80 = 0x61626380. Contrasts with the wrong result of a direct uint32_t* cast on a little-endian machine (0x80636261). Byte-offset annotations at each step.",
            "type": "memory_layout",
            "anchor_target": "hash-impl-m2"
          },
          {
            "id": "tdd-diag-12",
            "title": "Algorithm Steps \u2014 W[16..19] Recurrence Expansion with Dependency Trace",
            "description": "Step-by-step expansion of W[16], W[17], W[18], W[19] for the 'abc' schedule. For each word: lists the four source indices (t-2, t-7, t-15, t-16), their values at that point, the \u03c3 function applied, and the uint32_t addition result. W[16]: shows all four terms are effectively 0 or W[0], producing 0x61626380. W[17]: shows \u03c31(W[15])=\u03c31(0x18)=0x000F0000. Makes modular wraparound visible if any sum exceeds 0xFFFFFFFF.",
            "type": "algorithm_steps",
            "anchor_target": "hash-impl-m2"
          }
        ]
      },
      {
        "id": "hash-impl-m3",
        "name": "Compression Function",
        "description": "Implements the SHA-256 64-round compression function per FIPS 180-4 Section 6.2.2. Takes the current 8-word hash state H[0..7] and the 64-word message schedule W[0..63], transforms H in-place through 64 rounds using Ch, Maj, \u03a30, \u03a31, the 64 K constants, and modular 32-bit addition. Does NOT implement padding, schedule generation, initialization of H, or output serialization.",
        "specs": {
          "inputs": "uint32_t H[8] (current hash state, modified in-place); const uint32_t W[64] (message schedule from M2).",
          "outputs": "H[0..7] updated in-place to reflect compression of one block. No return value.",
          "abstractions": "rotr(uint32_t, int) -> uint32_t; Sigma0(uint32_t) -> uint32_t [ROTR(x,2)^ROTR(x,13)^ROTR(x,22)]; Sigma1(uint32_t) -> uint32_t [ROTR(x,6)^ROTR(x,11)^ROTR(x,25)]; Ch(uint32_t x, uint32_t y, uint32_t z) -> uint32_t [(x&y)^(~x&z)]; Maj(uint32_t x, uint32_t y, uint32_t z) -> uint32_t [(x&y)^(x&z)^(y&z)]; K[64] const array; sha256_compress(uint32_t H[8], const uint32_t W[64]).",
          "error_categories": [
            "Uppercase \u03a3 constants confused with lowercase \u03c3 constants \u2014 silent wrong output on all inputs",
            "e = d + T1 + T2 instead of e = d + T1 \u2014 most common transcription error from spec",
            "State update (H[i] += x) placed inside the round loop instead of after it \u2014 compounds partial state 64 times",
            "Wrong K constant values \u2014 verifiable by checking K[0]==0x428A2F98 and K[63]==0xC67178F2",
            "Using signed int for working variables \u2014 right-shift sign-extends on negative values"
          ],
          "concurrency_model": "Pure function on caller-provided state. Working variables a\u2013h are stack-allocated. No heap allocation, no shared mutable state.",
          "performance_targets": [
            "64 rounds \u00d7 ~10 operations each = ~640 uint32_t operations per block",
            "Target: ~200 MB/s on a modern CPU at 3 GHz (approximately 6 cycles/byte for unoptimized C)",
            "K array must be const to allow compiler to place in read-only section and avoid cache pressure",
            "All working variables should remain in registers \u2014 avoid taking addresses of a..h"
          ]
        },
        "implementation_phases": [
          {
            "phase": 1,
            "name": "Ch and Maj boolean functions with exhaustive truth-table unit tests",
            "estimated_hours": "0.5"
          },
          {
            "phase": 2,
            "name": "\u03a30 and \u03a31 (uppercase) with spot-check tests \u2014 verify distinct from \u03c30/\u03c31",
            "estimated_hours": "0.5"
          },
          {
            "phase": 3,
            "name": "K[64] constants array \u2014 transcribe from FIPS 180-4, verify K[0] and K[63]",
            "estimated_hours": "0.25"
          },
          {
            "phase": 4,
            "name": "64-round compression loop body with debug-print instrumentation",
            "estimated_hours": "1-1.5"
          },
          {
            "phase": 5,
            "name": "Round-by-round KAT against NIST Appendix B intermediate values for 'abc'",
            "estimated_hours": "1-1.5"
          },
          {
            "phase": 6,
            "name": "Integration test: full pipeline M1+M2+M3 verifying H[] state after 'abc' compression",
            "estimated_hours": "0.5"
          }
        ],
        "diagrams": [
          {
            "id": "tdd-diag-13",
            "title": "Module Architecture \u2014 Compression Module Functions and K Table",
            "description": "Shows sha256_compress as public entry. Internal static functions: Sigma0, Sigma1, Ch, Maj, rotr. Static const K[64] array. Annotates each function's input/output types. Shows that sha256_compress takes H[8] (in-out) and W[64] (in). Marks working variables a..h as stack-allocated locals within sha256_compress. No external dependencies beyond stdint.h.",
            "type": "architecture",
            "anchor_target": "hash-impl-m3"
          },
          {
            "id": "tdd-diag-14",
            "title": "Data Flow \u2014 Hash State Transformation Through 64 Rounds",
            "description": "High-level data flow: H[0..7] and W[0..63] enter sha256_compress. Inside: initialization copies H[] to {a,b,c,d,e,f,g,h}. The round loop reads W[t] and K[t] on each iteration and writes new {a..h}. After 64 rounds, H[i] += working_var[i] for each i. Shows that W and K are read-only, H is read then updated. Types and widths annotated on all edges.",
            "type": "data_flow",
            "anchor_target": "hash-impl-m3"
          },
          {
            "id": "tdd-diag-15",
            "title": "Algorithm Steps \u2014 Single Compression Round Anatomy (T1, T2, Variable Shift)",
            "description": "Detailed step-by-step for one round t: (1) compute \u03a31(e); (2) compute Ch(e,f,g); (3) T1 = h + \u03a31(e) + Ch(e,f,g) + K[t] + W[t]; (4) compute \u03a30(a); (5) compute Maj(a,b,c); (6) T2 = \u03a30(a) + Maj(a,b,c); (7) variable shift: h=g, g=f, f=e, e=d+T1, d=c, c=b, b=a, a=T1+T2. Each step shows before-value and after-value. Highlights that e receives d+T1 (not d+T1+T2) and a receives T1+T2.",
            "type": "algorithm_steps",
            "anchor_target": "hash-impl-m3"
          },
          {
            "id": "tdd-diag-16",
            "title": "State Machine \u2014 Working Variable Shift Register Across 4 Rounds",
            "description": "Four-column state machine showing {a,b,c,d,e,f,g,h} after rounds t=0,1,2,3. Arrows show how each variable moves: b\u2190a, c\u2190b, d\u2190c (pure shift); e\u2190d+T1 (injected); f\u2190e, g\u2190f, h\u2190g (pure shift); a\u2190T1+T2 (injected). Illustrates that T1 affects both e (middle of pipeline) and a (front, via T2 combination). Makes the asymmetric injection visible at a glance.",
            "type": "state_machine",
            "anchor_target": "hash-impl-m3"
          },
          {
            "id": "tdd-diag-17",
            "title": "Algorithm Steps \u2014 Ch Truth Table and MUX Interpretation",
            "description": "Two panels. Panel A: full 8-row truth table for Ch(x,y,z) = (x&y)^(~x&z) showing all input combinations and output. Counts: exactly 4 ones \u2014 balanced function. Panel B: MUX diagram showing x as select signal, y as input-0, z as input-1, output as Ch result. Annotates that for each bit position independently: x=1 selects y, x=0 selects z. Connects to hardware 2-to-1 MUX gate.",
            "type": "algorithm_steps",
            "anchor_target": "hash-impl-m3"
          },
          {
            "id": "tdd-diag-18",
            "title": "Algorithm Steps \u2014 Maj Truth Table and Majority Vote Interpretation",
            "description": "Two panels. Panel A: full 8-row truth table for Maj(x,y,z) = (x&y)^(x&z)^(y&z) showing all combinations. Counts: exactly 4 ones \u2014 balanced. Annotates: output=1 iff popcount(x,y,z) >= 2. Panel B: voting diagram \u2014 three voters {x,y,z}, output is majority. Side note: alternative form (x&y)|(z&(x|y)) saves one AND gate. Both produce identical truth tables.",
            "type": "algorithm_steps",
            "anchor_target": "hash-impl-m3"
          },
          {
            "id": "tdd-diag-19",
            "title": "\u03a3 (Uppercase) vs \u03c3 (Lowercase) \u2014 Constants Comparison Diagram",
            "description": "Side-by-side table of all four sigma functions. Columns: name, used-in, rotation constants, shift constant, formula. Rows: \u03c30 (schedule, 7/18/3), \u03c31 (schedule, 17/19/10), \u03a30 (compression/a, 2/13/22, no shift), \u03a31 (compression/e, 6/11/25, no shift). Color-codes schedule functions in one color, compression functions in another. Explicitly marks that \u03a3 functions have NO SHR term. This diagram is the single most important bug-prevention artifact in the project.",
            "type": "algorithm_steps",
            "anchor_target": "hash-impl-m3"
          },
          {
            "id": "tdd-diag-20",
            "title": "Sequence Diagram \u2014 Full Compression Call for One Block",
            "description": "Multi-component sequence diagram: caller \u2192 sha256_compress: passes H[8], W[64]. sha256_compress initializes {a..h} from H[]. Loop 0..63: sha256_compress calls Sigma1(e), Ch(e,f,g), Sigma0(a), Maj(a,b,c) internally; computes T1, T2; updates variables. After loop: sha256_compress updates H[0]+=a ... H[7]+=h. Returns. Annotates which calls are in the hot loop vs. setup/teardown. Shows that K[] is accessed as a static read, W[] is indexed by t.",
            "type": "sequence",
            "anchor_target": "hash-impl-m3"
          }
        ]
      },
      {
        "id": "hash-impl-m4",
        "name": "Final Hash Output and Validation",
        "description": "Wires the three prior modules into a complete SHA-256 implementation. Provides SHA256_CTX context struct, init/update/finalize streaming API, big-endian output serialization, hexadecimal formatting, and a one-shot sha256() convenience function. Validates correctness against all three NIST test vectors. Does NOT re-implement padding, schedule, or compression \u2014 it composes them.",
        "specs": {
          "inputs": "update(): const uint8_t *data, size_t len (may be called zero or more times with any chunk size including 0). finalize(): uint8_t out[32] (caller-provided output buffer). sha256(): const uint8_t *msg, size_t len, uint8_t out[32].",
          "outputs": "finalize() writes exactly 32 bytes of binary digest to out[]. sha256_hex() writes exactly 64 lowercase hex chars plus null terminator to hex[65].",
          "abstractions": "SHA256_CTX struct {uint32_t H[8]; uint8_t buf[64]; size_t buf_len; uint64_t total_len}; sha256_init(SHA256_CTX*); sha256_update(SHA256_CTX*, const uint8_t*, size_t); sha256_finalize(SHA256_CTX*, uint8_t[32]); sha256(const uint8_t*, size_t, uint8_t[32]); sha256_hex(const uint8_t[32], char[65]); write_uint32_be(uint8_t*, uint32_t); write_uint64_be(uint8_t*, uint64_t).",
          "error_categories": [
            "Wrong initial H values \u2014 wrong output on every input, caught immediately by KAT on empty string",
            "State not reset between calls \u2014 second hash incorporates state from first; only visible when context is reused",
            "total_len stored in bytes but length field must be bits \u2014 missing *8 multiplier; off by factor of 8 in length field",
            "Output serialized as little-endian \u2014 bytes of each H word reversed; looks like valid hex but wrong",
            "Streaming buffer partial-completion off-by-one \u2014 completing a block at exactly buf_len+incoming==64 may process an extra or miss a block",
            "Finalization two-block trigger off-by-one \u2014 using buf_len >= 56 instead of > 56 skips the two-block path for exactly 56-byte data",
            "Uppercase vs lowercase hex output \u2014 string comparison against NIST vectors fails silently"
          ],
          "concurrency_model": "SHA256_CTX is not thread-safe. Each goroutine/thread must own its own context. sha256_finalize zeroes the context after use \u2014 subsequent use without init() is undefined. sha256() stack-allocates its context \u2014 naturally thread-safe.",
          "performance_targets": [
            "sha256_init: O(1), 8 word stores + 2 memsets",
            "sha256_update: O(len) \u2014 zero extra copies for aligned full-block inputs in Phase 2 path",
            "sha256_finalize: O(1) \u2014 at most two compression calls regardless of message length",
            "sha256_hex: O(1) \u2014 exactly 32 iterations",
            "Full SHA-256 of 1 MB: target < 10 ms on a 3 GHz CPU (approximately 100 MB/s for unoptimized C)"
          ]
        },
        "implementation_phases": [
          {
            "phase": 1,
            "name": "SHA256_CTX struct definition and sha256_init with initial value constants",
            "estimated_hours": "0.25-0.5"
          },
          {
            "phase": 2,
            "name": "sha256_update \u2014 three-phase buffer management (complete partial, process full blocks, buffer remainder)",
            "estimated_hours": "1-1.5"
          },
          {
            "phase": 3,
            "name": "sha256_finalize \u2014 0x80 append, one-block vs two-block padding path, length field, H[] serialization, context zeroing",
            "estimated_hours": "1-1.5"
          },
          {
            "phase": 4,
            "name": "write_uint32_be, sha256_hex, and one-shot sha256() wrapper",
            "estimated_hours": "0.25-0.5"
          },
          {
            "phase": 5,
            "name": "NIST KAT suite \u2014 empty string, abc, 56-byte vector; streaming invariance; context reuse; block boundary tests",
            "estimated_hours": "1-2"
          }
        ],
        "diagrams": [
          {
            "id": "tdd-diag-21",
            "title": "Module Architecture \u2014 Full SHA-256 Public API and Internal Composition",
            "description": "Top-level architecture showing sha256.h public surface: sha256_init, sha256_update, sha256_finalize, sha256, sha256_hex. SHA256_CTX struct with all four fields annotated with types and sizes. Internal calls: update() \u2192 sha256_schedule + sha256_compress; finalize() \u2192 sha256_schedule + sha256_compress + write_uint32_be + write_uint64_be. Dependencies on M1 (sha256_pad is NOT used in streaming path \u2014 finalize replicates its logic on buf directly), M2 (sha256_schedule), M3 (sha256_compress).",
            "type": "architecture",
            "anchor_target": "hash-impl-m4"
          },
          {
            "id": "tdd-diag-22",
            "title": "Memory Layout \u2014 SHA256_CTX Struct Fields with Byte Offsets",
            "description": "Struct layout diagram: offset 0\u201331: H[0..7] (8 \u00d7 uint32_t = 32 bytes); offset 32\u201395: buf[0..63] (64 \u00d7 uint8_t = 64 bytes); offset 96\u2013103: buf_len (size_t = 8 bytes on 64-bit); offset 104\u2013111: total_len (uint64_t = 8 bytes). Total: 112 bytes. Annotates semantic role of each field. Notes that buf[0..buf_len-1] is valid data and buf[buf_len..63] is garbage (not read). Shows cache-line boundary at offset 64.",
            "type": "memory_layout",
            "anchor_target": "hash-impl-m4"
          },
          {
            "id": "tdd-diag-23",
            "title": "State Machine \u2014 SHA256_CTX Lifecycle",
            "description": "State machine with states: UNINITIALIZED \u2192 (sha256_init) \u2192 EMPTY_BUFFER [buf_len=0] \u2192 (update with len<64 and buf empty) \u2192 PARTIAL_BUFFER [0<buf_len<64] \u2192 (update that completes block) \u2192 EMPTY_BUFFER. PARTIAL_BUFFER \u2192 (update with large data) \u2192 loop back. EMPTY_BUFFER or PARTIAL_BUFFER \u2192 (sha256_finalize) \u2192 ZEROED [invalid]. ZEROED \u2192 (sha256_init) \u2192 EMPTY_BUFFER. Marks ILLEGAL transition: ZEROED \u2192 update (undefined behavior). Annotates which fields change at each transition.",
            "type": "state_machine",
            "anchor_target": "hash-impl-m4"
          },
          {
            "id": "tdd-diag-24",
            "title": "Sequence Diagram \u2014 sha256_update with Partial Buffer Completion",
            "description": "Sequence diagram for calling update() with 50 bytes when buf holds 30 bytes. Caller \u2192 ctx: update(data, 50). Phase 1: ctx copies min(34,50)=34 bytes to buf+30 \u2192 buf_len=64 \u2192 calls sha256_schedule(buf, W) \u2192 sha256_compress(H, W) \u2192 buf_len=0. offset=34. Phase 2: 50-34=16 < 64 \u2192 no full blocks to process. Phase 3: copies 16 bytes to buf \u2192 buf_len=16. Returns. Annotates offset variable at each step. Shows that H[] is the only persistent state that changes.",
            "type": "sequence",
            "anchor_target": "hash-impl-m4"
          },
          {
            "id": "tdd-diag-25",
            "title": "Sequence Diagram \u2014 sha256_finalize One-Block vs Two-Block Path",
            "description": "Two parallel sequence traces. Left (buf_len=3 after 'abc' update): finalize appends 0x80 \u2192 buf_len=4. 4 \u2264 56 \u2192 single-block path: memset buf[4..55]=0, write_uint64_be(buf+56, 24). sha256_schedule(buf,W) \u2192 sha256_compress(H,W). Serialize H[0..7] \u2192 out[0..31]. memset(ctx,0). Right (buf_len=56 after 56-byte message): finalize appends 0x80 \u2192 buf_len=57. 57 > 56 \u2192 two-block path: memset buf[57..63]=0, compress block 1, memset buf=0, write_uint64_be(buf+56,448), compress block 2. Serialize. Both paths annotated with buf_len values at each decision point.",
            "type": "sequence",
            "anchor_target": "hash-impl-m4"
          },
          {
            "id": "tdd-diag-26",
            "title": "Data Flow \u2014 H[0..7] to 32-byte Digest to 64-char Hex String",
            "description": "Two-stage data flow. Stage 1: H[0]=0xBA7816BF \u2192 write_uint32_be \u2192 bytes [0xBA, 0x78, 0x16, 0xBF] at out[0..3]. Repeat for H[1..7]. Result: 32-byte big-endian binary digest. Stage 2: sha256_hex \u2014 each byte split into high nibble and low nibble, each nibble indexed into HEX='0123456789abcdef', two chars produced per byte. Shows byte 0 (0xBA) \u2192 '8' and 'a' \u2192 first two chars of 'ba7816bf...'. Annotates (digest[i]>>4)&0x0F and (digest[i])&0x0F expressions.",
            "type": "data_flow",
            "anchor_target": "hash-impl-m4"
          },
          {
            "id": "tdd-diag-27",
            "title": "Algorithm Steps \u2014 Complete End-to-End Trace for SHA-256('abc')",
            "description": "Full pipeline trace annotated at each stage boundary. Step 1: input {0x61,0x62,0x63}, len=3. Step 2: sha256_init \u2014 H set to {0x6A09E667,...,0x5BE0CD19}, buf_len=0, total_len=0. Step 3: sha256_update(abc,3) \u2014 Phase 3 only, buf={0x61,0x62,0x63}, buf_len=3, total_len=3. Step 4: sha256_finalize \u2014 buf_len=3+1=4, single-block path, buf becomes the 64-byte padded block {61 62 63 80 00...00 18}. Step 5: sha256_schedule produces W[0]=0x61626380, W[15]=0x18, W[16..63] expanded. Step 6: sha256_compress transforms H from initial values to {0xBA7816BF,...,0xF20015AD}. Step 7: write_uint32_be serializes each H word. Step 8: sha256_hex produces 'ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad'.",
            "type": "algorithm_steps",
            "anchor_target": "hash-impl-m4"
          },
          {
            "id": "tdd-diag-28",
            "title": "Algorithm Steps \u2014 Initial Hash Values Derivation from Prime Square Roots",
            "description": "Table with 8 rows. Columns: prime, sqrt(prime) decimal, fractional part, fractional_part \u00d7 2^32 (integer), hex value. Row 1: 2, 1.41421356..., 0.41421356..., 1779033703, 0x6A09E667. Row 8: 19, 4.35889894..., 0.35889894..., 1541325730, 0x5BE0CD19. Annotates the nothing-up-my-sleeve property: derivation is fully public and reproducible. Highlights that SHA-224 uses primes 9\u201316 with same algorithm.",
            "type": "algorithm_steps",
            "anchor_target": "hash-impl-m4"
          }
        ]
      }
    ]
  },
  "tdd_accumulated_md": "\n\n# TDD\n\nA specification-faithful, test-driven implementation of SHA-256 following NIST FIPS 180-4, decomposed into four independently verifiable modules: message preprocessing/padding, message schedule generation, 64-round compression function, and final hash output with streaming API. Each module is verified against NIST known-answer tests before integration. The design prioritizes byte-level correctness, big-endian discipline, and constant-time-safe uint32_t arithmetic throughout.\n\n\n\n<!-- TDD_MOD_ID: hash-impl-m1 -->\n# MODULE TECHNICAL DESIGN SPECIFICATION: Message Preprocessing and Padding (hash-impl-m1)\n\n## 1. Module Charter\n\nThe **Message Preprocessing and Padding** module is the foundational stage of the SHA-256 pipeline. Its primary responsibility is to transform an arbitrary-length byte sequence (the \"message\") into a strictly formatted sequence of 512-bit (64-byte) blocks. This formatting is governed by the Merkle-Damg\u00e5rd strengthening requirements defined in FIPS 180-4, Section 5.1.1.\n\n**Core Responsibilities:**\n- Calculate the required memory allocation for a padded message before processing.\n- Append the mandatory '1' bit (represented as the byte `0x80` in byte-oriented implementations).\n- Calculate and append the necessary number of zero padding bits to align the message for the length field.\n- Encode and append the original message length as a 64-bit big-endian integer.\n- Provide a safe, indexed accessor for downstream modules (Message Schedule) to retrieve individual 64-byte blocks.\n\n**Non-Goals:**\n- This module does NOT perform word extraction (32-bit parsing).\n- This module does NOT implement any cryptographic logic (bitwise \u03c3/\u03a3 functions, compression rounds).\n- This module does NOT handle dynamic memory allocation (it writes to caller-provided buffers).\n\n**Invariants:**\n- The output length in bytes is always a multiple of 64.\n- The last 8 bytes of the final block always contain the original message length in bits, encoded in big-endian.\n- The byte immediately following the original message is always `0x80`.\n\n---\n\n## 2. File Structure\n\nThe implementation follows a standard C separation of concerns. Files should be created in the following order:\n\n1.  `sha256_pad.h`: Public interface definitions, constants, and function prototypes.\n2.  `sha256_pad.c`: Implementation of padding logic and byte-order utilities.\n3.  `test_pad.c`: Unit tests and NIST validation vectors for the padding stage.\n\n---\n\n## 3. Complete Data Model\n\nWhile this module is largely functional, the memory layout of the produced blocks is the \"Data Model.\" The caller provides a `uint8_t` buffer which is treated as a sequence of one or more 64-byte blocks.\n\n### 512-bit Block Memory Layout (FIPS 180-4)\n\n| Byte Offset | Field | Description |\n| :--- | :--- | :--- |\n| `0x00 - 0x37` | Message/Zeroes | Message data. If the message ends before offset 0x37, padding begins here. |\n| `0x38 - 0x3F` | Length Field | 64-bit (8-byte) original message bit-length, Big-Endian. |\n\n### The \"Spill-Over\" Case (56-64 Byte Messages)\nIf the message length is such that there is no room for the `0x80` byte AND the 8-byte length field in the current 64-byte block, a second block is appended.\n\n**Block N (Last Message Block):**\n| Byte Offset | Content |\n| :--- | :--- |\n| `msg_len % 64` | `0x80` (The '1' bit) |\n| `...` | `0x00` padding to end of block |\n\n**Block N+1 (Final Padding Block):**\n| Byte Offset | Content |\n| :--- | :--- |\n| `0x00 - 0x37` | `0x00` padding |\n| `0x38 - 0x3F` | 64-bit Big-Endian Bit Length |\n\n---\n\n## 4. Interface Contracts\n\n### 4.1. `sha256_padded_length`\nCalculates the total size required for the padded message.\n- **Signature:** `size_t sha256_padded_length(size_t msg_len)`\n- **Constraints:** `msg_len` must be less than $2^{61}$ bytes (to fit in a 64-bit bit-length field).\n- **Return:** A multiple of 64.\n\n### 4.2. `sha256_pad`\nApplies FIPS 180-4 padding to the message.\n- **Signature:** `size_t sha256_pad(uint8_t *out, const uint8_t *msg, size_t msg_len)`\n- **Inputs:**\n    - `out`: Target buffer. Must be pre-allocated to at least `sha256_padded_length(msg_len)`.\n    - `msg`: Source message. May be `NULL` if `msg_len == 0`.\n    - `msg_len`: Length of the source message in bytes.\n- **Return:** Total bytes written to `out`.\n- **Side Effects:** Zeroes out padding regions; copies message data.\n\n### 4.3. `sha256_get_block`\nAccessor for the compression function.\n- **Signature:** `const uint8_t *sha256_get_block(const uint8_t *padded, size_t idx)`\n- **Inputs:**\n    - `padded`: The buffer returned by `sha256_pad`.\n    - `idx`: Zero-based block index.\n- **Return:** Pointer to the start of the 64-byte block.\n\n### 4.4. `write_uint64_be` (Internal Utility)\nWrites a 64-bit integer to a byte buffer in Big-Endian order.\n- **Signature:** `void write_uint64_be(uint8_t *buf, uint64_t v)`\n\n---\n\n## 5. Algorithm Specification: The Padding Procedure\n\nThe padding procedure follows these exact steps:\n\n1.  **Calculate Bit Length**: Convert `msg_len` (bytes) to bits. $L = msg\\_len \\times 8$.\n2.  **Initial Copy**: Copy `msg_len` bytes from `msg` to `out`.\n3.  **Append Marker**: Set `out[msg_len] = 0x80`.\n4.  **Calculate Zero Fill**:\n    - Let $B$ be the number of bytes used so far ($msg\\_len + 1$).\n    - The number of zeros $Z$ must satisfy: $(B + Z) \\equiv 56 \\pmod{64}$.\n    - $Z = (56 - B) \\pmod{64}$. (Handle negative modulo by adding 64 if $B > 56$).\n5.  **Write Zeros**: `memset(out + msg_len + 1, 0, Z)`.\n6.  **Write Length**: Use `write_uint64_be` to place the 64-bit value $L$ at `out + msg_len + 1 + Z`.\n\n### Big-Endian Discipline\nSHA-256 requires Big-Endian bit lengths. Even on Little-Endian systems (x86), the length must be stored with the Most Significant Byte (MSB) at the lowest memory address.\n```c\nvoid write_uint64_be(uint8_t *buf, uint64_t v) {\n    buf[0] = (v >> 56) & 0xFF;\n    buf[1] = (v >> 48) & 0xFF;\n    buf[2] = (v >> 40) & 0xFF;\n    buf[3] = (v >> 32) & 0xFF;\n    buf[4] = (v >> 24) & 0xFF;\n    buf[5] = (v >> 16) & 0xFF;\n    buf[6] = (v >> 8)  & 0xFF;\n    buf[7] = (v >> 0)  & 0xFF;\n}\n```\n\n---\n\n## 6. Error Handling Matrix\n\n| Error Condition | Detected By | Recovery / Action | User Visible? |\n| :--- | :--- | :--- | :--- |\n| `msg_len` > $2^{61}$ | Logic check in `sha256_pad` | Return `0` (indicates error) | Yes (via return val) |\n| `out` buffer NULL | Caller responsibility | Undefined behavior / Assertion | No (crash) |\n| `msg` NULL with `len > 0` | Assertion in `sha256_pad` | Abort / Undefined | No (crash) |\n| Bit-length overflow | `msg_len * 8` check | Clamp or fail | Yes |\n\n---\n\n## 7. Implementation Sequence with Checkpoints\n\n### Phase 1: Utilities and Length Math (1 Hour)\nImplement `write_uint64_be` and `sha256_padded_length`.\n- **Checkpoint**: Call `sha256_padded_length(55)` -> should return 64. Call `sha256_padded_length(56)` -> should return 128.\n\n### Phase 2: Core Padding Logic (1.5 Hours)\nImplement `sha256_pad` using `memcpy`, `memset`, and the 55/56 boundary logic.\n- **Checkpoint**: Call `sha256_pad` for \"abc\". Check `out[3]` is `0x80`, and `out[63]` is `0x18` (24 bits).\n\n### Phase 3: Accessors and Validation (0.5 Hours)\nImplement `sha256_get_block` and `sha256_num_blocks`.\n- **Checkpoint**: Ensure `sha256_get_block(padded, 1)` for a 56-byte message returns a valid pointer 64 bytes offset from the start.\n\n---\n\n## 8. Test Specification\n\n### Test 1: Empty Input (NIST Minimal)\n- **Input**: `msg_len = 0`\n- **Expectation**: `padded_length = 64`. `out[0] = 0x80`. `out[1..55] = 0`. `out[56..63] = 0`.\n\n### Test 2: \"abc\" (Standard Vector)\n- **Input**: `0x61, 0x62, 0x63`\n- **Expectation**: `padded_length = 64`. `out[0..2] = 0x616263`. `out[3] = 0x80`. `out[63] = 0x18`.\n\n### Test 3: 55-Byte Boundary (One Block Max)\n- **Input**: 55 bytes of `0x41`.\n- **Expectation**: `padded_length = 64`. `out[55] = 0x80`. `out[56..63]` contains the length in bits ($55 \\times 8 = 440 = \\text{0x00000000000001B8}$).\n\n### Test 4: 56-Byte Boundary (Two Block Min)\n- **Input**: 56 bytes of `0x41`.\n- **Expectation**: `padded_length = 128`. `out[56] = 0x80`. Block 1 ends with `0x00` in the last 7 bytes. Block 2 ends with the length ($56 \\times 8 = 448 = \\text{0x00000000000001C0}$).\n\n---\n\n## 9. Performance Targets\n\n| Operation | Target | Measurement |\n| :--- | :--- | :--- |\n| `sha256_pad` | > 2 GB/s | `time` to process 1GB dummy buffer through padding only. |\n| Memory overhead | 0 bytes (heap) | Static analysis (no `malloc`). |\n\n---\n\n## 10. Adversary Soul: Threat Model\n\nAs this is a security project, the padding module must be resilient against the following:\n\n1.  **Buffer Overflows**: The `out` buffer MUST be checked against the size provided by `sha256_padded_length`. An attacker could provide a `msg_len` that triggers an integer wrap-around if the math is performed in 32-bit instead of 64-bit. Use `size_t` for all length calculations.\n2.  **Length Extension Attacks**: While this module is just the padding, the inclusion of the length field is the primary defense against length extension. An implementation that omits the length or fails to encode it in big-endian would leave downstream HMAC or digital signature implementations vulnerable.\n3.  **Ambiguity**: The `0x80` byte is critical. Without it, a message \"A\" and a message \"A\\x00\" would result in the same padded blocks, leading to a collision. The test suite must verify that messages differing only by trailing nulls produce distinct padded outputs.\n\n---\n\n## 11. Alternative Reality: Implementation in C\n\n### Memory Constraints\nIn an embedded environment, we might not have the memory to store a full \"padded buffer\" for a large file. In that case, the `sha256_pad` function would be refactored into a \"Streaming Padded Reader\" that generates padding bytes on-the-fly when the source message is exhausted. For this project level (intermediate), we assume a single contiguous buffer is acceptable.\n\n### Pointer Arithmetic Safety\n```c\nconst uint8_t *sha256_get_block(const uint8_t *padded, size_t idx) {\n    // Offset is idx * 64. \n    // Ensure idx doesn't exceed sha256_num_blocks to prevent OOB.\n    return padded + (idx << 6); // idx * 64\n}\n```\n\n---\n\n## 12. Constant-Time Analysis\nPadding logic depends on message length, which is public information in most threat models (network packets, file sizes). However, for highest-security applications, the *timing* of the padding should not reveal secret information.\n- The `memcpy` and `memset` operations are inherently linear with length.\n- The calculation of `Z` (zero fill count) involves branches or modulo.\n- Recommendation: Since message length is generally non-secret, standard `memcpy`/`memset` is sufficient. If `msg_len` were a secret, a constant-time memory copy from a fixed-maximum-size buffer would be required.\n\n---\n\n## 13. Summary of FIPS 180-4 Compliance\n- [x] Padding '1' bit (0x80)\n- [x] Zero fill $k$ bits such that total $\\equiv 448 \\pmod{512}$\n- [x] Append 64-bit Big-Endian Bit Length\n- [x] Output is multiple of 512 bits (64 bytes)\n<!-- END_TDD_MOD -->\n\n\n<!-- TDD_MOD_ID: hash-impl-m2 -->\n# MODULE TECHNICAL DESIGN SPECIFICATION: Message Schedule Generation (hash-impl-m2)\n\n## 1. Module Charter\n\nThe **Message Schedule Generation** module is responsible for the \"expansion\" phase of the SHA-256 compression function. In the Merkle-Damg\u00e5rd construction, a 512-bit message block is too small to provide sufficient diffusion across 64 rounds of compression. This module expands the 16 initial 32-bit words (512 bits) into a 64-word \"message schedule\" (2048 bits).\n\n**Core Responsibilities:**\n- Parse a 64-byte raw message block into sixteen 32-bit unsigned integers using **Big-Endian** byte ordering.\n- Implement the bitwise rotation (ROTR) and logical shift (SHR) primitives.\n- Implement the small-sigma ($\\sigma_0, \\sigma_1$) functions defined in FIPS 180-4, Section 4.1.2.\n- Execute the recurrence relation to populate words $W[16]$ through $W[63]$.\n- Ensure all additions are performed modulo $2^{32}$ through the natural behavior of C's `uint32_t`.\n\n**Non-Goals:**\n- This module does NOT perform message padding (handled in M1).\n- This module does NOT implement the 64-round compression state or working variables (handled in M3).\n- This module does NOT handle the round constants ($K_t$) (handled in M3).\n\n**Invariants:**\n- $W[0..15]$ must be a byte-perfect representation of the input block in Big-Endian order.\n- Every bit in the resulting 64-word schedule is a deterministic function of the input 512 bits.\n- The functions $\\sigma_0$ and $\\sigma_1$ are purely functional (no side effects).\n\n---\n\n## 2. File Structure\n\nThe implementation continues the modular C structure. Create files in the following sequence:\n\n1.  `sha256_schedule.h`: Definitions for the schedule array size and expansion prototypes.\n2.  `sha256_schedule.c`: Implementation of bitwise primitives, $\\sigma$ functions, and the expansion loop.\n3.  `test_schedule.c`: Validation suite comparing intermediate $W$ values against NIST Appendix B.\n\n---\n\n## 3. Complete Data Model\n\nThe primary data structure for this module is the **Message Schedule Array**.\n\n### 3.1. The Schedule Array (W)\nThe schedule is represented as a contiguous array of 64 unsigned 32-bit integers.\n\n```c\n#include <stdint.h>\n\n// The message schedule consists of 64 words of 32 bits each.\n// Total memory: 64 * 4 bytes = 256 bytes.\ntypedef uint32_t sha256_schedule_t[64];\n```\n\n### 3.2. Memory Layout and Bit Ordering\nSHA-256 is a big-endian algorithm. When parsing the input block (64 bytes), the first byte in memory corresponds to the most significant bits of the first word ($W[0]$).\n\n| Byte Offset (Block) | Word Index | Word Bits [31...24] | Word Bits [23...16] | Word Bits [15...8] | Word Bits [7...0] |\n| :--- | :--- | :--- | :--- | :--- | :--- |\n| 0x00 | $W[0]$ | Block[0] | Block[1] | Block[2] | Block[3] |\n| 0x04 | $W[1]$ | Block[4] | Block[5] | Block[6] | Block[7] |\n| ... | ... | ... | ... | ... | ... |\n| 0x3C | $W[15]$ | Block[60] | Block[61] | Block[62] | Block[63] |\n\n{{DIAGRAM:tdd-diag-7|Word Extraction Layout|Visualizes the mapping of 64 bytes to 16 words}}\n\n---\n\n## 4. Interface Contracts\n\n### 4.1. `read_uint32_be`\nConverts four bytes into a single 32-bit integer.\n- **Signature:** `static uint32_t read_uint32_be(const uint8_t *ptr)`\n- **Input:** `ptr` must point to at least 4 valid bytes.\n- **Constraint:** Must work correctly on little-endian hardware (x86/ARM).\n- **Implementation Note:** Use bit-shifting to ensure endianness independence.\n\n### 4.2. `sigma0` and `sigma1`\nInternal bit-mixing functions.\n- **Signatures:**\n    - `static uint32_t sigma0(uint32_t x)`\n    - `static uint32_t sigma1(uint32_t x)`\n- **Logic:**\n    - $\\sigma_0(x) = ROTR^7(x) \\oplus ROTR^{18}(x) \\oplus SHR^3(x)$\n    - $\\sigma_1(x) = ROTR^{17}(x) \\oplus ROTR^{19}(x) \\oplus SHR^{10}(x)$\n\n### 4.3. `sha256_schedule`\nThe primary entry point for the module.\n- **Signature:** `void sha256_schedule(const uint8_t *block, uint32_t W[64])`\n- **Inputs:**\n    - `block`: 64 bytes of padded message data (from M1).\n    - `W`: Destination array for the 64 expanded words.\n- **Guarantees:** Upon return, `W[0..63]` contains the full schedule.\n\n---\n\n## 5. Algorithm Specification\n\nThe expansion process is performed in two distinct steps: **Extraction** and **Recurrence**.\n\n### 5.1. Word Extraction (W[0..15])\n1. For $i$ from 0 to 15:\n    a. Extract 4 bytes from the block starting at index $i \\times 4$.\n    b. Pack bytes into $W[i]$ as: $(B_0 \\ll 24) | (B_1 \\ll 16) | (B_2 \\ll 8) | B_3$.\n\n### 5.2. Expansion Recurrence (W[16..63])\nFIPS 180-4, Section 6.2.2 defines the expansion as:\n$$W_t = \\sigma_1(W_{t-2}) + W_{t-7} + \\sigma_0(W_{t-15}) + W_{t-16}$$\nWhere $+$ denotes addition modulo $2^{32}$.\n\n1. For $t$ from 16 to 63:\n    a. Let $s_1 = \\sigma_1(W[t-2])$.\n    b. Let $s_0 = \\sigma_0(W[t-15])$.\n    c. $W[t] = s_1 + W[t-7] + s_0 + W[t-16]$.\n\n{{DIAGRAM:tdd-diag-8|Recurrence Dependency Web|Shows the 4-tap dependency for word expansion}}\n\n### 5.3. Bitwise Primitive: ROTR\nC does not have a native rotate operator. The `rotr` function must be implemented using shifts.\n```c\nstatic inline uint32_t rotr(uint32_t x, uint32_t n) {\n    return (x >> n) | (x << (32 - n));\n}\n```\n**Optimization Note:** Modern compilers (GCC/Clang) recognize this pattern and replace it with a single `ror` (Rotate Right) assembly instruction.\n\n---\n\n## 6. Error Handling Matrix\n\n| Error Condition | Detected By | Recovery / Action | User Visible? |\n| :--- | :--- | :--- | :--- |\n| Constant Swap ($\\sigma_0 \\leftrightarrow \\sigma_1$) | KAT Tests | Hard-coded fix. | No (Dev-only) |\n| Sign Extension | Type Audit | Ensure `uint32_t` is used for all shifts. | No |\n| LE Pointer Cast | Test Suite | W[0] will fail \"abc\" check. | No |\n| Integer Overflow | C Standard | Unsigned overflow is defined as modulo; no action needed. | No |\n\n---\n\n## 7. Implementation Sequence with Checkpoints\n\n### Phase 1: Bitwise Foundations (0.5 Hours)\nImplement `rotr`, `sigma0`, and `sigma1`.\n- **Checkpoint**: Create a small main function to compute `sigma0(0x12345678)`. Manually verify the result using a calculator or the NIST examples.\n- **Test Command**: `gcc test_bits.c -o test_bits && ./test_bits`\n\n### Phase 2: Block Parsing (0.5 Hours)\nImplement `read_uint32_be` and the first loop of `sha256_schedule`.\n- **Checkpoint**: Pass the 64-byte padded block for \"abc\" (from M1). Verify that `W[0] == 0x61626380`.\n- **Failure Mode**: If `W[0] == 0x80636261`, you have a little-endian read error.\n\n### Phase 3: Recurrence Loop (0.5 Hours)\nImplement the $t=16 \\dots 63$ loop.\n- **Checkpoint**: Print $W[16]$ and $W[17]$ for the \"abc\" block.\n- **Expected Values**:\n    - $W[16]$ for \"abc\" should be `0x61626380`.\n    - $W[17]$ for \"abc\" should be `0x000f0000`.\n\n### Phase 4: Full Schedule Validation (1 Hour)\nCompare the entire 64-word array against the NIST \"SHA-256 Example\" document.\n- **Checkpoint**: Use the provided values in `test_schedule.c`. All 64 assertions must pass.\n\n---\n\n## 8. Test Specification\n\n### 8.1. Bitwise Integrity\n- **ROTR Test**: `rotr(0x01000000, 8)` must equal `0x00010000`. `rotr(0x00000001, 1)` must equal `0x80000000`.\n- **Sigma Test**: `sigma0(0x00000001)`\n    - $ROTR^7(1) = 0x02000000$\n    - $ROTR^{18}(1) = 0x00004000$\n    - $SHR^3(1) = 0x00000000$\n    - Result: `0x02004000`.\n\n### 8.2. Recurrence Integration (\"abc\")\nUsing the padded block from M1 for \"abc\":\n- **W[0]**: `0x61626380`\n- **W[1..14]**: `0x00000000`\n- **W[15]**: `0x00000018`\n- **Calculated W[16]**: $\\sigma_1(W[14]) + W[9] + \\sigma_0(W[1]) + W[0] = 0 + 0 + 0 + 0x61626380 = 0x61626380$.\n- **Calculated W[17]**: $\\sigma_1(W[15]) + W[10] + \\sigma_0(W[2]) + W[1] = \\sigma_1(0x18) + 0 + 0 + 0 = 0x000f0000$.\n\n---\n\n## 9. Performance Targets\n\n| Operation | Target | Measurement |\n| :--- | :--- | :--- |\n| Word Expansion | < 500 cycles / block | Benchmark 1,000,000 calls using `rdtsc` or `clock_gettime`. |\n| Instruction Map | 1 `ror` per `rotr` | `objdump -d sha256_schedule.o` under `-O2`. |\n\n---\n\n## 10. Adversary Soul: Threat Model\n\n1.  **Bit-Bias Analysis**: An attacker might try to find a message block that produces a \"weak\" schedule (e.g., a schedule with many zeros). However, the $\\sigma$ functions are non-linear over the field of bits. Even if 15/16 words are zero, the recurrence spreads the non-zero bits rapidly.\n2.  **Timing Side-Channels**: Bitwise rotations and shifts are constant-time on almost all modern CPU architectures. This is why SHA-256 is resilient to timing attacks compared to algorithms using data-dependent memory lookups (like older versions of AES).\n3.  **Sign-Extension Vulnerability**: If the schedule used signed integers (`int32_t`), a right-shift on a value with the high bit set would fill the vacated bits with `1`s (arithmetic shift). This would completely corrupt the diffusion. The implementation **must** use `uint32_t`.\n\n---\n\n## 11. Alternative Reality: SIMD Optimization\n\nOn an x86 system with AVX2 or ARM with NEON, it is possible to calculate four or eight schedule words in parallel. The recurrence $W_t = \\sigma_1(W_{t-2}) + W_{t-7} + \\sigma_0(W_{t-15}) + W_{t-16}$ is serial in nature (each word depends on previous ones), but since you need 64 words, you can partially parallelize the computation of independent word-chains. For this project, a serial implementation is the ground truth.\n\n---\n\n## 12. Constant-Time Logic\nThe schedule generation is inherently constant-time with respect to the *values* of the input bits. The number of operations is fixed (exactly 48 iterations of the recurrence), and no branching occurs based on the message content.\n\n```c\n// CONSTANT-TIME PROPERTY VERIFICATION\nvoid sha256_schedule(const uint8_t *block, uint32_t W[64]) {\n    // No 'if' statements based on W[i]\n    // No data-dependent loops\n    // No cache-timing dependent lookups\n}\n```\n\n---\n\n## 13. Summary of FIPS 180-4 Compliance\n- [x] Correct $\\sigma_0$ constants: (7, 18, 3)\n- [x] Correct $\\sigma_1$ constants: (17, 19, 10)\n- [x] Big-Endian block parsing\n- [x] 64-word output storage\n- [x] Modulo $2^{32}$ arithmetic\n<!-- END_TDD_MOD -->\n\n\n<!-- TDD_MOD_ID: hash-impl-m3 -->\n# MODULE TECHNICAL DESIGN SPECIFICATION: Compression Function (hash-impl-m3)\n\n## 1. Module Charter\n\nThe **Compression Function** is the cryptographic engine of the SHA-256 algorithm. It is responsible for consuming the 64-word message schedule generated in Milestone 2 and using it to transform the 256-bit internal hash state. This module implements the core \"mixing\" logic that provides the properties of collision resistance and preimage resistance.\n\n**Core Responsibilities:**\n- Implement the 64-round transformation loop as defined in FIPS 180-4, Section 6.2.2.\n- Execute bitwise non-linear functions: **Choice (Ch)** and **Majority (Maj)**.\n- Execute bitwise diffusion functions: **Upper-case Sigma ($\\Sigma_0, \\Sigma_1$)**.\n- Maintain and rotate eight 32-bit working variables ($a, b, c, d, e, f, g, h$) per round.\n- Integrate the 64 unique round constants ($K_t$) derived from the cube roots of primes.\n- Perform the final state accumulation (Davies-Meyer construction) by adding the transformed working variables back to the original hash state modulo $2^{32}$.\n\n**Non-Goals:**\n- This module does NOT handle message padding or length encoding (handled in M1).\n- This module does NOT generate the message schedule $W_t$ (handled in M2).\n- This module does NOT handle the initialization of the hash state $H$ or its final hexadecimal serialization (handled in M4).\n\n**Invariants:**\n- The working variables $a \\dots h$ must be initialized exactly from $H[0 \\dots 7]$ at the start of every block.\n- The state update ($H[i] = H[i] + \\text{new\\_val}$) must occur exactly once per 512-bit block, after all 64 rounds.\n- All bitwise operations must be constant-time and free of data-dependent branching.\n\n---\n\n## 2. File Structure\n\nImplementation must proceed in the following order to ensure each primitive is verified before being used in the complex round loop.\n\n1.  `sha256_compress.h`: Prototypes for the compression function and declarations of the bitwise primitives.\n2.  `sha256_compress.c`: Implementation of the $K$ constants array, boolean functions (Ch, Maj), diffusion functions ($\\Sigma$), and the 64-round loop.\n3.  `test_compress.c`: A rigorous validation suite using NIST intermediate values to verify the state after Round 0, Round 1, and Round 63.\n\n---\n\n## 3. Complete Data Model\n\nThe compression function operates on two primary data structures: the **Internal State** and the **Round Constants**.\n\n### 3.1. Working Variables (Registers)\nDuring the 64 rounds, the algorithm uses eight local 32-bit unsigned integers. These are conceptually registers.\n\n| Variable | Initial Value | Role in Round |\n| :--- | :--- | :--- |\n| `a` | `H[0]` | Updated by $T_1 + T_2$ |\n| `b` | `H[1]` | Receives previous `a` |\n| `c` | `H[2]` | Receives previous `b` |\n| `d` | `H[3]` | Receives previous `c` |\n| `e` | `H[4]` | Updated by `d` + $T_1$ |\n| `f` | `H[5]` | Receives previous `e` |\n| `g` | `H[6]` | Receives previous `f` |\n| `h` | `H[7]` | Receives previous `g`; contributes to $T_1$ |\n\n### 3.2. Round Constants ($K$)\nThe 64 constants are stored in a static, read-only array. These values are non-random (nothing-up-my-sleeve numbers) and are critical for breaking symmetry between rounds.\n\n| Index | Value (Hex) | Prime Source |\n| :--- | :--- | :--- |\n| `K[0]` | `0x428a2f98` | $\\sqrt[3]{2}$ |\n| `K[1]` | `0x71374491` | $\\sqrt[3]{3}$ |\n| ... | ... | ... |\n| `K[63]` | `0xc67178f2` | $\\sqrt[3]{311}$ |\n\n### 3.3. Memory Layout: State Update\nAfter 64 rounds, the variables $a \\dots h$ are added to the input state $H$.\n\n{{DIAGRAM:tdd-diag-13|Davies-Meyer State Update|Shows the addition of a-h back into H0-H7}}\n\n```c\n// Layout of the Hash State H\ntypedef uint32_t sha256_state_t[8]; \n```\n\n---\n\n## 4. Interface Contracts\n\n### 4.1. `sha256_compress`\nThe main entry point for block processing.\n- **Signature:** `void sha256_compress(uint32_t state[8], const uint32_t schedule[64])`\n- **Constraints:** `state` must be initialized (either by M4 or by a previous compression call). `schedule` must be fully populated (by M2).\n- **Behavior:** Modifies `state` in-place.\n\n### 4.2. `Sigma0` and `Sigma1` (Upper-case)\nBitwise diffusion primitives.\n- **Signatures:**\n    - `static uint32_t Sigma0(uint32_t x)`\n    - `static uint32_t Sigma1(uint32_t x)`\n- **Formulae:**\n    - $\\Sigma_0(x) = ROTR^2(x) \\oplus ROTR^{13}(x) \\oplus ROTR^{22}(x)$\n    - $\\Sigma_1(x) = ROTR^6(x) \\oplus ROTR^{11}(x) \\oplus ROTR^{25}(x)$\n\n### 4.3. `Ch` and `Maj`\nBitwise non-linear boolean functions.\n- **Signatures:**\n    - `static uint32_t Ch(uint32_t x, uint32_t y, uint32_t z)`\n    - `static uint32_t Maj(uint32_t x, uint32_t y, uint32_t z)`\n- **Logic:**\n    - `Ch`: Choose $y$ if bit in $x$ is 1, else choose $z$.\n    - `Maj`: Return 1 if at least two bits in $x, y, z$ are 1.\n\n---\n\n## 5. Algorithm Specification: The 64-Round Transformation\n\n### 5.1. Initialization\nCopy the current hash state into working variables:\n$a \\leftarrow H_0, b \\leftarrow H_1, c \\leftarrow H_2, d \\leftarrow H_3, e \\leftarrow H_4, f \\leftarrow H_5, g \\leftarrow H_6, h \\leftarrow H_7$.\n\n### 5.2. Round Loop\nFor $t$ from 0 to 63:\n\n1.  **Calculate Temporary Variable $T_1$**:\n    $T_1 = h + \\Sigma_1(e) + Ch(e, f, g) + K_t + W_t$\n    *Rationale: $T_1$ concentrates the influence of the current message word $W_t$, the round constant $K_t$, and the \"back half\" of the state.*\n\n2.  **Calculate Temporary Variable $T_2$**:\n    $T_2 = \\Sigma_0(a) + Maj(a, b, c)$\n    *Rationale: $T_2$ provides diffusion and non-linearity for the \"front half\" of the state.*\n\n3.  **Variable Rotation and Injection**:\n    - $h \\leftarrow g$\n    - $g \\leftarrow f$\n    - $f \\leftarrow e$\n    - $e \\leftarrow d + T_1$  *(Injection Point 1)*\n    - $d \\leftarrow c$\n    - $c \\leftarrow b$\n    - $b \\leftarrow a$\n    - $a \\leftarrow T_1 + T_2$ *(Injection Point 2)*\n\n{{DIAGRAM:tdd-diag-14|Round Function Logic Flow|Detailing T1, T2 and variable shifting}}\n\n### 5.3. Final Addition (Davies-Meyer)\nOnce the loop finishes, the new hash state is calculated by adding the working variables to the original state:\n- $H_0 \\leftarrow H_0 + a$\n- $H_1 \\leftarrow H_1 + b$\n- ...\n- $H_7 \\leftarrow H_7 + h$\n\n*All additions are implicitly $modulo\\ 2^{32}$.*\n\n---\n\n## 6. Error Handling Matrix\n\n| Error Condition | Detected By | Recovery / Action | User Visible? |\n| :--- | :--- | :--- | :--- |\n| Using $\\sigma$ instead of $\\Sigma$ | Unit tests for $\\Sigma_0/\\Sigma_1$ | Correct rotation constants | No |\n| Injection bug: $e = d + T_1 + T_2$ | Intermediate KAT | Remove $T_2$ from $e$ update | No |\n| Accumulation bug: $H += a$ in loop | Multi-block KAT | Move addition outside loop | No |\n| Integer Overflow (Signed) | Static Analysis | Ensure `uint32_t` for all variables | No |\n| Typos in $K$ table | `K[0]/K[63]` spot-check | Transcribe from FIPS table | No |\n\n---\n\n## 7. Implementation Sequence with Checkpoints\n\n### Phase 1: Boolean and Diffusion Primitives (0.5 Hours)\nImplement `Ch`, `Maj`, `Sigma0`, and `Sigma1`.\n- **Checkpoint**: Run `test_compress.c` part 1. Verify `Ch(0xFF00FF00, 0xAAAAAAAA, 0x55555555)` produces `0xAA55AA55`.\n- **Checkpoint**: Verify `Sigma0(0x00000001)` produces `0x40080400`.\n\n### Phase 2: The Constant Table (0.25 Hours)\nTranscribe the 64 $K$ constants.\n- **Checkpoint**: Verify `K[0] == 0x428a2f98` and `K[63] == 0xc67178f2`.\n\n### Phase 3: The Compression Loop (1.5 Hours)\nImplement `sha256_compress` with the $T_1/T_2$ logic.\n- **Checkpoint**: Instrument the code to print `a..h` after Round 0.\n- **NIST \"abc\" Round 0 Check**:\n    - After Round 0, `a` should be `0xe0e766b1`.\n    - After Round 0, `e` should be `0xf21855a9`.\n- **Failure Mode**: If `a` is correct but `e` is wrong, you likely included $T_2$ in the update for $e$.\n\n### Phase 4: Final Accumulation (0.5 Hours)\nImplement the $H_i += \\text{var}_i$ logic.\n- **Checkpoint**: Pass the full 512-bit block for \"abc\" into the function.\n- **Result**: Verify $H[0]$ becomes `0xba7816bf`.\n\n---\n\n## 8. Test Specification\n\n### 8.1. Boolean Truth Tables\n- **Ch Test**: `Ch(1, 1, 0) = 1`, `Ch(1, 0, 1) = 0`, `Ch(0, 1, 0) = 0`, `Ch(0, 0, 1) = 1`.\n- **Maj Test**: `Maj(1, 1, 0) = 1`, `Maj(1, 0, 1) = 1`, `Maj(0, 1, 1) = 1`, `Maj(0, 0, 1) = 0`.\n\n### 8.2. Upper-case Sigma Verification\n- **Sigma0(x)**: Test with $x=1$. Result should be $(1 \\gg 2) | (1 \\ll 30) \\oplus (1 \\gg 13) | (1 \\ll 19) \\oplus (1 \\gg 22) | (1 \\ll 10)$.\n- **Sigma1(x)**: Test with $x=1$. Result should be $(1 \\gg 6) | (1 \\ll 26) \\oplus (1 \\gg 11) | (1 \\ll 21) \\oplus (1 \\gg 25) | (1 \\ll 7)$.\n\n### 8.3. NIST Known-Answer Test (Intermediate)\nInput: \"abc\" padded block.\n- **Initial H**: `0x6a09e667, 0xbb67ae85, 0x3c6ef372, 0xa54ff53a, 0x510e527f, 0x9b05688c, 0x1f83d9ab, 0x5be0cd19`\n- **After Round 0**:\n    - `a: e0e766b1`, `b: 6a09e667`, `c: bb67ae85`, `d: 3c6ef372`\n    - `e: f21855a9`, `f: 510e527f`, `g: 9b05688c`, `h: 1f83d9ab`\n- **Final H (after 64 rounds + initial H)**:\n    - `H0: ba7816bf`, `H1: 8f01cfea`, `H2: 414140de`, `H3: 5dae2223`\n    - `H4: b00361a3`, `H5: 96177a9c`, `H6: b410ff61`, `H7: f20015ad`\n\n---\n\n## 9. Performance Targets\n\n| Operation | Target | Measurement |\n| :--- | :--- | :--- |\n| Block Compression | < 2,000 cycles | Measured via `rdtsc` on x86_64. |\n| Memory usage | 0 bytes heap | Verified via `valgrind --tool=massif`. |\n| Register Pressure | 8 working + 2 temp | Compiler should keep $a \\dots h, T_1, T_2$ in registers. |\n\n---\n\n## 10. Threat Model & Adversary Soul\n\n### 10.1. Side-Channel Resistance\nThe compression function is the most frequently executed part of the hash. An adversary may use **Differential Power Analysis (DPA)** or **Timing Attacks**.\n- **Timing**: SHA-256 is naturally resistant to timing attacks because all operations (AND, XOR, NOT, ADD, ROTR) take a fixed number of clock cycles on modern CPUs, regardless of the input data.\n- **Prevention**: The implementation must avoid `if` statements or `switch` cases that depend on the message bits or state bits. The current design is purely arithmetic/logical and fulfills this.\n\n### 10.2. Fault Injection\nAn attacker with physical access might \"glitch\" the CPU to skip a round or flip a bit in a working variable.\n- **Avalanche Effect**: SHA-256's design ensures that a single bit flip in any round will cascade into approximately 128 bit flips in the final output. The $T_1/T_2$ injection points are specifically designed to maximize this cascade.\n- **Verification**: The 64-round limit is conservative. Even if an attacker could skip 20 rounds, the resulting hash would still be cryptographically strong (though no longer conforming to the spec).\n\n---\n\n## 11. Alternative Reality: Implementation in C\n\n### Memory Access\nThe $K$ table should be declared as `static const uint32_t K[64]` to ensure it is placed in the `.rodata` section of the binary. This allows the OS to share the memory across processes and prevents accidental modification.\n\n### Compiler Optimization\nThe loop should be written in a way that allows the compiler to unroll it.\n```c\nfor (int t = 0; t < 64; t++) {\n    // Round logic...\n}\n```\nIf the user requires extreme performance, they may unroll the loop manually into 8-round chunks to reduce branching overhead, but for an intermediate level project, the standard `for` loop is preferred for readability and spec-compliance.\n\n---\n\n## 12. Constant-Time Analysis\nThe compression function is a \"straight-line\" piece of code.\n- No data-dependent jumps.\n- No data-dependent memory lookups (the $K$ table is accessed via a linear index $t$).\n- Addition mod $2^{32}$ is a primitive hardware instruction.\n\nThe function is **Constant-Time** by construction.\n\n---\n\n## 13. Summary of FIPS 180-4 Compliance\n- [x] Correct $\\Sigma_0$ constants: (2, 13, 22)\n- [x] Correct $\\Sigma_1$ constants: (6, 11, 25)\n- [x] Correct $Ch$ and $Maj$ logic\n- [x] Full 64-word schedule consumption\n- [x] Davies-Meyer state accumulation ($H_i + \\text{var}_i$)\n- [x] Use of all 64 $K_t$ constants\n<!-- END_TDD_MOD -->\n\n\n<!-- TDD_MOD_ID: hash-impl-m4 -->\n# MODULE TECHNICAL DESIGN SPECIFICATION: Final Hash Output and Validation (hash-impl-m4)\n\n## 1. Module Charter\n\nThe **Final Hash Output and Validation** module is the architectural capstone of the SHA-256 implementation. It serves as the orchestrator that wires together the preprocessing (M1), message schedule (M2), and compression (M3) modules into a unified, high-performance, and security-hardened API. \n\n**Core Responsibilities:**\n- Implement the `SHA256_CTX` state machine to support incremental (streaming) hashing of unbounded data streams.\n- Manage internal buffering logic to ensure the compression function only receives perfectly aligned 512-bit blocks.\n- Execute the Merkle-Damg\u00e5rd finalization sequence: appending the `0x80` sentinel, performing multi-block padding if necessary, and encoding the 64-bit bit-length.\n- Serialize the internal `uint32_t` hash state into a standard-compliant Big-Endian byte array.\n- Provide defensive \"state-zeroing\" to prevent cryptographic material leakage after finalization.\n- Validate the entire pipeline against the official NIST FIPS 180-4 Known-Answer Tests (KATs).\n\n**Non-Goals:**\n- This module does not re-implement the internal bitwise logic of $\\Sigma$, $\\sigma$, $Ch$, or $Maj$.\n- It does not handle multi-threaded parallel hashing (each `SHA256_CTX` is strictly single-threaded).\n\n**Invariants:**\n- A context once finalized MUST be zeroed and rendered unusable until `sha256_init` is called again.\n- The output of the streaming API (`update` calls) must be bit-identical to the one-shot API regardless of chunk size.\n- Endianness conversion for the final digest must be consistent across all CPU architectures (x86, ARM, RISC-V).\n\n---\n\n## 2. File Structure\n\nImplementation follows this sequence to build from the data structure upward to the verification suite:\n\n1.  `sha256.h`: Public API, `SHA256_CTX` definition, and NIST constant definitions.\n2.  `sha256.c`: Implementation of the streaming state machine, finalization, and serialization.\n3.  `test_sha256.c`: Comprehensive validation suite including NIST vectors, streaming boundary tests, and state-reset checks.\n\n---\n\n## 3. Complete Data Model\n\nThe `SHA256_CTX` (Context) structure is the memory-resident representation of a hash-in-progress. It must be carefully laid out to prevent unnecessary padding and ensure alignment for 32-bit and 64-bit operations.\n\n### 3.1. SHA256_CTX Memory Layout\n\n| Offset | Field | Type | Size | Description |\n| :--- | :--- | :--- | :--- | :--- |\n| `0x00` | `h[8]` | `uint32_t` | 32B | The current 256-bit hash state ($H_0 \\dots H_7$). |\n| `0x20` | `buf[64]` | `uint8_t` | 64B | Internal 512-bit block buffer for partial data. |\n| `0x60` | `total_len` | `uint64_t` | 8B | Total count of **bytes** processed so far. |\n| `0x68` | `buf_len` | `size_t` | 4/8B | Number of valid bytes currently sitting in `buf`. |\n\n**Total Size:** ~108-112 bytes (depending on `size_t` width and compiler alignment).\n\n{{DIAGRAM:tdd-diag-21|Context Struct Memory Map|Visualizes the H-state, buffer, and counters}}\n\n### 3.2. Initial Hash Values (IV)\nThese are the \"Nothing-Up-My-Sleeve\" starting constants defined by NIST. They must be hardcoded in `sha256_init`.\n\n```c\nstatic const uint32_t SHA256_IV[8] = {\n    0x6a09e667, 0xbb67ae85, 0x3c6ef372, 0xa54ff53a,\n    0x510e527f, 0x9b05688c, 0x1f83d9ab, 0x5be0cd19\n};\n```\n*Origin: First 32 bits of the fractional parts of the square roots of the first 8 primes (2, 3, 5, 7, 11, 13, 17, 19).*\n\n---\n\n## 4. Interface Contracts\n\n### 4.1. `sha256_init`\nResets the context for a new computation.\n- **Signature:** `void sha256_init(SHA256_CTX *ctx)`\n- **Pre-condition:** `ctx` must point to allocated memory.\n- **Post-condition:** `h` is set to `SHA256_IV`, `buf` is cleared, `total_len` and `buf_len` are 0.\n\n### 4.2. `sha256_update`\nProcesses arbitrary chunks of data.\n- **Signature:** `void sha256_update(SHA256_CTX *ctx, const uint8_t *data, size_t len)`\n- **Constraints:** `len` can be 0. `data` can be any length.\n- **Safety:** Must handle chunks that are smaller than, larger than, or exactly equal to 64 bytes.\n\n### 4.3. `sha256_finalize`\nPerforms padding and produces the final 32-byte digest.\n- **Signature:** `void sha256_finalize(SHA256_CTX *ctx, uint8_t out[32])`\n- **Output:** Writes exactly 32 bytes in Big-Endian order to `out`.\n- **Security:** Must call `memset(ctx, 0, sizeof(SHA256_CTX))` before returning.\n\n### 4.4. `sha256_hex` (Utility)\nConverts binary digest to lowercase hex string.\n- **Signature:** `void sha256_hex(const uint8_t digest[32], char hex[65])`\n- **Constraint:** Output must be lowercase and null-terminated.\n\n---\n\n## 5. Algorithm Specification\n\n### 5.1. `sha256_update` (Streaming State Machine)\nThe logic must minimize memory copying by processing large blocks directly from the source pointer.\n\n1.  **Increment Counter**: `ctx->total_len += len`.\n2.  **Phase 1: Partial Buffer Fill**:\n    - If `ctx->buf_len > 0`:\n        - Calculate `needed = 64 - ctx->buf_len`.\n        - `copy_len = (len < needed) ? len : needed`.\n        - `memcpy` data into `ctx->buf` at offset `buf_len`.\n        - Update `ctx->buf_len` and `len`.\n        - If `ctx->buf_len == 64`:\n            - Call `sha256_schedule(ctx->buf, W)`.\n            - Call `sha256_compress(ctx->h, W)`.\n            - `ctx->buf_len = 0`.\n3.  **Phase 2: Direct Block Processing**:\n    - While `len >= 64`:\n        - Call `sha256_schedule(data_ptr, W)`.\n        - Call `sha256_compress(ctx->h, W)`.\n        - `data_ptr += 64`, `len -= 64`.\n4.  **Phase 3: Final Buffering**:\n    - If `len > 0`:\n        - `memcpy` remaining `len` bytes into `ctx->buf`.\n        - `ctx->buf_len = len`.\n\n{{DIAGRAM:tdd-diag-22|Streaming Logic Flow|Phases of the Update function}}\n\n### 5.2. `sha256_finalize` (Padding Logic)\nThis is the most sensitive part of the implementation.\n\n1.  **Append Sentinel**: `ctx->buf[ctx->buf_len++] = 0x80`.\n2.  **Evaluate Padding Room**:\n    - If `ctx->buf_len > 56`: \n        - We don't have room for the 8-byte length field.\n        - `memset` remaining `ctx->buf` with `0`.\n        - Compress current `ctx->buf`.\n        - Start new block: `memset(ctx->buf, 0, 64)`.\n        - `ctx->buf_len = 0`.\n    - Else:\n        - `memset` from `ctx->buf_len` to `56` with `0`.\n3.  **Append Bit Length**:\n    - Calculate `bits = ctx->total_len * 8`.\n    - Use `write_uint64_be(ctx->buf + 56, bits)`.\n4.  **Final Compression**:\n    - Call `sha256_schedule` and `sha256_compress` on the final block.\n5.  **Serialization**:\n    - For `i` in `0..7`: `write_uint32_be(out + i*4, ctx->h[i])`.\n6.  **Sanitization**: `memset(ctx, 0, sizeof(SHA256_CTX))`.\n\n### 5.3. Big-Endian Utilities\n```c\nstatic void write_uint32_be(uint8_t *buf, uint32_t val) {\n    buf[0] = (val >> 24) & 0xff;\n    buf[1] = (val >> 16) & 0xff;\n    buf[2] = (val >> 8)  & 0xff;\n    buf[3] = (val >> 0)  & 0xff;\n}\n```\n\n---\n\n## 6. Error Handling Matrix\n\n| Error Condition | Detected By | Recovery / Action | User Visible? |\n| :--- | :--- | :--- | :--- |\n| `len` > $2^{61}$ | Check in `update` | Fail/Abort (length limit) | Yes (via return) |\n| `ctx` NULL | Caller / Assertion | Crash (Standard C behavior) | No |\n| Reuse context after `finalize` | `finalize` zeroing | Produces wrong hash (IV will be 0) | No (logic error) |\n| Output buffer too small | Caller responsibility | Stack/Heap corruption | No |\n\n---\n\n## 7. Implementation Sequence with Checkpoints\n\n### Phase 1: Context & IV (0.5 Hours)\nDefine `SHA256_CTX` and implement `sha256_init`.\n- **Checkpoint**: Verify `ctx->h[0]` is `0x6a09e667` after init.\n\n### Phase 2: Update State Machine (1.5 Hours)\nImplement `sha256_update` with the 3-phase buffering.\n- **Checkpoint**: Feed 64 bytes. Verify `buf_len` returns to 0 and `compress` was called exactly once.\n\n### Phase 3: Finalization & Serialization (1.5 Hours)\nImplement `sha256_finalize` with Big-Endian encoding.\n- **Checkpoint**: Hash \"abc\". Verify the first word of the output is `0xba7816bf`.\n\n### Phase 4: NIST Validation (2 Hours)\nImplement `test_sha256.c` and verify all NIST vectors.\n- **Checkpoint**: Running `./test_sha256` outputs \"All NIST vectors passed\".\n\n---\n\n## 8. Test Specification\n\n### 8.1. NIST KATs\nVerify these three exact results:\n1.  `\"\"` (Empty): `e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855`\n2.  `\"abc\"`: `ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad`\n3.  `\"abcdbcdecdefdefgefghfghighijhijkijkljklmklmnlmnomnopnopq\"`: `248d6a61d20638b8e5c026930c3e6039a33ce45964ff2167f6ecedd419db06c1`\n\n### 8.2. Streaming Invariance\n1.  Initialize `ctx1`. `update(ctx1, \"hello world\", 11)`. `finalize`.\n2.  Initialize `ctx2`. `update(ctx2, \"hello \", 6)`. `update(ctx2, \"world\", 5)`. `finalize`.\n3.  Assert `digest1 == digest2`.\n\n### 8.3. Boundary Edge Cases\n1.  **Exactly 55 bytes**: Should result in exactly 1 padded block.\n2.  **Exactly 56 bytes**: Should result in exactly 2 padded blocks.\n3.  **Exactly 64 bytes**: Should result in 1 message block + 1 padding block.\n\n---\n\n## 9. Performance Targets\n\n| Operation | Target | Measurement |\n| :--- | :--- | :--- |\n| SHA-256 Throughput | > 100 MB/s | `time ./sha256_bench 100MB_file` |\n| Initialization | < 100ns | Average of 1M calls to `init`. |\n| Memory Overhead | ~112 Bytes | `sizeof(SHA256_CTX)` |\n\n---\n\n## 10. Adversary Soul: Threat Model\n\n1.  **Length Extension Attack**: While SHA-256 is vulnerable, the `total_len` inclusion in padding ensures that an attacker cannot easily extend a hash without knowing the original length.\n2.  **Memory Leakage**: By zeroing the `SHA256_CTX` in `finalize`, we ensure that if a server handles a secret (like a password hash) and then returns the buffer to a memory pool, the secret's intermediate hash state is not visible to the next user of that memory.\n3.  **Constant-Time**: The `update` and `finalize` logic contains branches (e.g., `if (len >= 64)`). However, these branches depend on the **length** of the message, which is typically public or non-sensitive. The **values** of the bits do not affect the branching or timing, preserving side-channel resistance.\n\n---\n\n## 11. Concurrency Specification\n\n`SHA256_CTX` is **not thread-safe**.\n- **Rule 1**: Concurrent calls to `sha256_update` on the same context from different threads will result in a data race on `buf` and `h`.\n- **Rule 2**: Users must create one `SHA256_CTX` per thread or use a mutex to serialize access.\n- **Rule 3**: The one-shot `sha256()` function is thread-safe because it allocates its context on the calling thread's stack.\n\n---\n\n## 12. Alternative Reality: Byte Ordering (x86 vs ARM)\n\nOn a Little-Endian system (x86), the `uint32_t` state in memory is stored \"backwards\" compared to the Big-Endian spec.\n**Spec requirement**: $H_0$ bits [31...24] are at the lowest address of the digest.\n**Implementation**: Our `write_uint32_be` handles this by manually shifting bits.\n```c\n// Correct: Independent of host endianness\nbuf[0] = (uint8_t)(h[0] >> 24); \n```\nDo **not** use `memcpy(&out, &ctx->h, 32)`, as this will produce correct results on Big-Endian machines but wrong results on x86.\n\n---\n\n## 13. Summary of FIPS 180-4 Compliance\n\n- [x] Correct Initial Hash Values (Square roots of primes).\n- [x] Standard Merkle-Damg\u00e5rd Padding (0x80 sentinel + zeros + 64-bit bit-length).\n- [x] Big-Endian serialization of the final digest.\n- [x] Context management for incremental hashing.\n- [x] Verified against all NIST test vectors.\n<!-- END_TDD_MOD -->\n",
  "tdd_current_mod_index": 4,
  "tdd_diagrams_to_generate": [
    {
      "id": "tdd-diag-9",
      "title": "Algorithm Steps \u2014 ROTR vs SHR on a 32-bit Value",
      "description": "Side-by-side bit-level diagram for a sample 32-bit value (e.g., 0x61626380). Left panel: SHR(x, 7) \u2014 bits shift right, 7 zeros appear at top, 7 bits fall off bottom. Right panel: ROTR(x, 7) \u2014 bits shift right, the 7 bits that fell off bottom wrap to top. Each bit position numbered 31..0. Implements the C expression (x>>n)|(x<<(32-n)) step by step.",
      "type": "algorithm_steps",
      "anchor_target": "hash-impl-m2"
    },
    {
      "id": "tdd-diag-10",
      "title": "Algorithm Steps \u2014 \u03c30 and \u03c31 Computation Trace",
      "description": "Two-panel step-by-step trace. Panel A (\u03c30): input x, compute ROTR(x,7), ROTR(x,18), SHR(x,3), XOR the three results, show final \u03c30(x). Panel B (\u03c31): same structure with rotations 17, 19 and shift 10. Uses concrete value x=0x61626380. Each intermediate value shown in hex and binary. Final XOR shown bit-by-bit for one nibble to make the operation concrete.",
      "type": "algorithm_steps",
      "anchor_target": "hash-impl-m2"
    },
    {
      "id": "tdd-diag-11",
      "title": "Memory Layout \u2014 Big-Endian Word Extraction from Block Bytes",
      "description": "Shows bytes 0\u20137 of the padded 'abc' block (0x61 0x62 0x63 0x80 0x00 0x00 0x00 0x00) with byte offsets labeled. Illustrates read_uint32_be assembling W[0] from bytes [0..3] via shift-OR: (0x61<<24)|(0x62<<16)|(0x63<<8)|0x80 = 0x61626380. Contrasts with the wrong result of a direct uint32_t* cast on a little-endian machine (0x80636261). Byte-offset annotations at each step.",
      "type": "memory_layout",
      "anchor_target": "hash-impl-m2"
    },
    {
      "id": "tdd-diag-12",
      "title": "Algorithm Steps \u2014 W[16..19] Recurrence Expansion with Dependency Trace",
      "description": "Step-by-step expansion of W[16], W[17], W[18], W[19] for the 'abc' schedule. For each word: lists the four source indices (t-2, t-7, t-15, t-16), their values at that point, the \u03c3 function applied, and the uint32_t addition result. W[16]: shows all four terms are effectively 0 or W[0], producing 0x61626380. W[17]: shows \u03c31(W[15])=\u03c31(0x18)=0x000F0000. Makes modular wraparound visible if any sum exceeds 0xFFFFFFFF.",
      "type": "algorithm_steps",
      "anchor_target": "hash-impl-m2"
    },
    {
      "id": "tdd-diag-13",
      "title": "Module Architecture \u2014 Compression Module Functions and K Table",
      "description": "Shows sha256_compress as public entry. Internal static functions: Sigma0, Sigma1, Ch, Maj, rotr. Static const K[64] array. Annotates each function's input/output types. Shows that sha256_compress takes H[8] (in-out) and W[64] (in). Marks working variables a..h as stack-allocated locals within sha256_compress. No external dependencies beyond stdint.h.",
      "type": "architecture",
      "anchor_target": "hash-impl-m3"
    },
    {
      "id": "tdd-diag-14",
      "title": "Data Flow \u2014 Hash State Transformation Through 64 Rounds",
      "description": "High-level data flow: H[0..7] and W[0..63] enter sha256_compress. Inside: initialization copies H[] to {a,b,c,d,e,f,g,h}. The round loop reads W[t] and K[t] on each iteration and writes new {a..h}. After 64 rounds, H[i] += working_var[i] for each i. Shows that W and K are read-only, H is read then updated. Types and widths annotated on all edges.",
      "type": "data_flow",
      "anchor_target": "hash-impl-m3"
    },
    {
      "id": "tdd-diag-15",
      "title": "Algorithm Steps \u2014 Single Compression Round Anatomy (T1, T2, Variable Shift)",
      "description": "Detailed step-by-step for one round t: (1) compute \u03a31(e); (2) compute Ch(e,f,g); (3) T1 = h + \u03a31(e) + Ch(e,f,g) + K[t] + W[t]; (4) compute \u03a30(a); (5) compute Maj(a,b,c); (6) T2 = \u03a30(a) + Maj(a,b,c); (7) variable shift: h=g, g=f, f=e, e=d+T1, d=c, c=b, b=a, a=T1+T2. Each step shows before-value and after-value. Highlights that e receives d+T1 (not d+T1+T2) and a receives T1+T2.",
      "type": "algorithm_steps",
      "anchor_target": "hash-impl-m3"
    },
    {
      "id": "tdd-diag-16",
      "title": "State Machine \u2014 Working Variable Shift Register Across 4 Rounds",
      "description": "Four-column state machine showing {a,b,c,d,e,f,g,h} after rounds t=0,1,2,3. Arrows show how each variable moves: b\u2190a, c\u2190b, d\u2190c (pure shift); e\u2190d+T1 (injected); f\u2190e, g\u2190f, h\u2190g (pure shift); a\u2190T1+T2 (injected). Illustrates that T1 affects both e (middle of pipeline) and a (front, via T2 combination). Makes the asymmetric injection visible at a glance.",
      "type": "state_machine",
      "anchor_target": "hash-impl-m3"
    },
    {
      "id": "tdd-diag-17",
      "title": "Algorithm Steps \u2014 Ch Truth Table and MUX Interpretation",
      "description": "Two panels. Panel A: full 8-row truth table for Ch(x,y,z) = (x&y)^(~x&z) showing all input combinations and output. Counts: exactly 4 ones \u2014 balanced function. Panel B: MUX diagram showing x as select signal, y as input-0, z as input-1, output as Ch result. Annotates that for each bit position independently: x=1 selects y, x=0 selects z. Connects to hardware 2-to-1 MUX gate.",
      "type": "algorithm_steps",
      "anchor_target": "hash-impl-m3"
    },
    {
      "id": "tdd-diag-18",
      "title": "Algorithm Steps \u2014 Maj Truth Table and Majority Vote Interpretation",
      "description": "Two panels. Panel A: full 8-row truth table for Maj(x,y,z) = (x&y)^(x&z)^(y&z) showing all combinations. Counts: exactly 4 ones \u2014 balanced. Annotates: output=1 iff popcount(x,y,z) >= 2. Panel B: voting diagram \u2014 three voters {x,y,z}, output is majority. Side note: alternative form (x&y)|(z&(x|y)) saves one AND gate. Both produce identical truth tables.",
      "type": "algorithm_steps",
      "anchor_target": "hash-impl-m3"
    },
    {
      "id": "tdd-diag-19",
      "title": "\u03a3 (Uppercase) vs \u03c3 (Lowercase) \u2014 Constants Comparison Diagram",
      "description": "Side-by-side table of all four sigma functions. Columns: name, used-in, rotation constants, shift constant, formula. Rows: \u03c30 (schedule, 7/18/3), \u03c31 (schedule, 17/19/10), \u03a30 (compression/a, 2/13/22, no shift), \u03a31 (compression/e, 6/11/25, no shift). Color-codes schedule functions in one color, compression functions in another. Explicitly marks that \u03a3 functions have NO SHR term. This diagram is the single most important bug-prevention artifact in the project.",
      "type": "algorithm_steps",
      "anchor_target": "hash-impl-m3"
    },
    {
      "id": "tdd-diag-20",
      "title": "Sequence Diagram \u2014 Full Compression Call for One Block",
      "description": "Multi-component sequence diagram: caller \u2192 sha256_compress: passes H[8], W[64]. sha256_compress initializes {a..h} from H[]. Loop 0..63: sha256_compress calls Sigma1(e), Ch(e,f,g), Sigma0(a), Maj(a,b,c) internally; computes T1, T2; updates variables. After loop: sha256_compress updates H[0]+=a ... H[7]+=h. Returns. Annotates which calls are in the hot loop vs. setup/teardown. Shows that K[] is accessed as a static read, W[] is indexed by t.",
      "type": "sequence",
      "anchor_target": "hash-impl-m3"
    },
    {
      "id": "tdd-diag-21",
      "title": "Module Architecture \u2014 Full SHA-256 Public API and Internal Composition",
      "description": "Top-level architecture showing sha256.h public surface: sha256_init, sha256_update, sha256_finalize, sha256, sha256_hex. SHA256_CTX struct with all four fields annotated with types and sizes. Internal calls: update() \u2192 sha256_schedule + sha256_compress; finalize() \u2192 sha256_schedule + sha256_compress + write_uint32_be + write_uint64_be. Dependencies on M1 (sha256_pad is NOT used in streaming path \u2014 finalize replicates its logic on buf directly), M2 (sha256_schedule), M3 (sha256_compress).",
      "type": "architecture",
      "anchor_target": "hash-impl-m4"
    },
    {
      "id": "tdd-diag-22",
      "title": "Memory Layout \u2014 SHA256_CTX Struct Fields with Byte Offsets",
      "description": "Struct layout diagram: offset 0\u201331: H[0..7] (8 \u00d7 uint32_t = 32 bytes); offset 32\u201395: buf[0..63] (64 \u00d7 uint8_t = 64 bytes); offset 96\u2013103: buf_len (size_t = 8 bytes on 64-bit); offset 104\u2013111: total_len (uint64_t = 8 bytes). Total: 112 bytes. Annotates semantic role of each field. Notes that buf[0..buf_len-1] is valid data and buf[buf_len..63] is garbage (not read). Shows cache-line boundary at offset 64.",
      "type": "memory_layout",
      "anchor_target": "hash-impl-m4"
    },
    {
      "id": "tdd-diag-23",
      "title": "State Machine \u2014 SHA256_CTX Lifecycle",
      "description": "State machine with states: UNINITIALIZED \u2192 (sha256_init) \u2192 EMPTY_BUFFER [buf_len=0] \u2192 (update with len<64 and buf empty) \u2192 PARTIAL_BUFFER [0<buf_len<64] \u2192 (update that completes block) \u2192 EMPTY_BUFFER. PARTIAL_BUFFER \u2192 (update with large data) \u2192 loop back. EMPTY_BUFFER or PARTIAL_BUFFER \u2192 (sha256_finalize) \u2192 ZEROED [invalid]. ZEROED \u2192 (sha256_init) \u2192 EMPTY_BUFFER. Marks ILLEGAL transition: ZEROED \u2192 update (undefined behavior). Annotates which fields change at each transition.",
      "type": "state_machine",
      "anchor_target": "hash-impl-m4"
    },
    {
      "id": "tdd-diag-24",
      "title": "Sequence Diagram \u2014 sha256_update with Partial Buffer Completion",
      "description": "Sequence diagram for calling update() with 50 bytes when buf holds 30 bytes. Caller \u2192 ctx: update(data, 50). Phase 1: ctx copies min(34,50)=34 bytes to buf+30 \u2192 buf_len=64 \u2192 calls sha256_schedule(buf, W) \u2192 sha256_compress(H, W) \u2192 buf_len=0. offset=34. Phase 2: 50-34=16 < 64 \u2192 no full blocks to process. Phase 3: copies 16 bytes to buf \u2192 buf_len=16. Returns. Annotates offset variable at each step. Shows that H[] is the only persistent state that changes.",
      "type": "sequence",
      "anchor_target": "hash-impl-m4"
    },
    {
      "id": "tdd-diag-25",
      "title": "Sequence Diagram \u2014 sha256_finalize One-Block vs Two-Block Path",
      "description": "Two parallel sequence traces. Left (buf_len=3 after 'abc' update): finalize appends 0x80 \u2192 buf_len=4. 4 \u2264 56 \u2192 single-block path: memset buf[4..55]=0, write_uint64_be(buf+56, 24). sha256_schedule(buf,W) \u2192 sha256_compress(H,W). Serialize H[0..7] \u2192 out[0..31]. memset(ctx,0). Right (buf_len=56 after 56-byte message): finalize appends 0x80 \u2192 buf_len=57. 57 > 56 \u2192 two-block path: memset buf[57..63]=0, compress block 1, memset buf=0, write_uint64_be(buf+56,448), compress block 2. Serialize. Both paths annotated with buf_len values at each decision point.",
      "type": "sequence",
      "anchor_target": "hash-impl-m4"
    },
    {
      "id": "tdd-diag-26",
      "title": "Data Flow \u2014 H[0..7] to 32-byte Digest to 64-char Hex String",
      "description": "Two-stage data flow. Stage 1: H[0]=0xBA7816BF \u2192 write_uint32_be \u2192 bytes [0xBA, 0x78, 0x16, 0xBF] at out[0..3]. Repeat for H[1..7]. Result: 32-byte big-endian binary digest. Stage 2: sha256_hex \u2014 each byte split into high nibble and low nibble, each nibble indexed into HEX='0123456789abcdef', two chars produced per byte. Shows byte 0 (0xBA) \u2192 '8' and 'a' \u2192 first two chars of 'ba7816bf...'. Annotates (digest[i]>>4)&0x0F and (digest[i])&0x0F expressions.",
      "type": "data_flow",
      "anchor_target": "hash-impl-m4"
    },
    {
      "id": "tdd-diag-27",
      "title": "Algorithm Steps \u2014 Complete End-to-End Trace for SHA-256('abc')",
      "description": "Full pipeline trace annotated at each stage boundary. Step 1: input {0x61,0x62,0x63}, len=3. Step 2: sha256_init \u2014 H set to {0x6A09E667,...,0x5BE0CD19}, buf_len=0, total_len=0. Step 3: sha256_update(abc,3) \u2014 Phase 3 only, buf={0x61,0x62,0x63}, buf_len=3, total_len=3. Step 4: sha256_finalize \u2014 buf_len=3+1=4, single-block path, buf becomes the 64-byte padded block {61 62 63 80 00...00 18}. Step 5: sha256_schedule produces W[0]=0x61626380, W[15]=0x18, W[16..63] expanded. Step 6: sha256_compress transforms H from initial values to {0xBA7816BF,...,0xF20015AD}. Step 7: write_uint32_be serializes each H word. Step 8: sha256_hex produces 'ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad'.",
      "type": "algorithm_steps",
      "anchor_target": "hash-impl-m4"
    },
    {
      "id": "tdd-diag-28",
      "title": "Algorithm Steps \u2014 Initial Hash Values Derivation from Prime Square Roots",
      "description": "Table with 8 rows. Columns: prime, sqrt(prime) decimal, fractional part, fractional_part \u00d7 2^32 (integer), hex value. Row 1: 2, 1.41421356..., 0.41421356..., 1779033703, 0x6A09E667. Row 8: 19, 4.35889894..., 0.35889894..., 1541325730, 0x5BE0CD19. Annotates the nothing-up-my-sleeve property: derivation is fully public and reproducible. Highlights that SHA-224 uses primes 9\u201316 with same algorithm.",
      "type": "algorithm_steps",
      "anchor_target": "hash-impl-m4"
    }
  ],
  "external_reading": "",
  "running_criteria": [
    {
      "milestone_id": "hash-impl-m1",
      "criteria": [
        "The sha256_pad() function appends a single 0x80 byte immediately after the last message byte (at index msg_len), followed by enough 0x00 bytes such that the total pre-length content is congruent to 56 bytes (mod 64), followed by the original message length in bits as an 8-byte big-endian integer, producing a padded output whose total length is a multiple of 64 bytes.",
        "The 64-bit length field encodes the message length in BITS (not bytes), written as a big-endian 8-byte integer in the final 8 bytes of the padded buffer. For 'abc' (3 bytes), the field must contain the value 24 (0x00 00 00 00 00 00 00 18).",
        "sha256_padded_length(msg_len) correctly returns 128 (two blocks) for any message_len in the range [56, 119] inclusive, and 64 (one block) for any message_len in the range [0, 55] inclusive.",
        "Empty input (0 bytes) produces exactly 64 bytes of padding: byte 0 is 0x80, bytes 1 through 55 are 0x00, and bytes 56 through 63 are all 0x00 (encoding bit length 0).",
        "A 3-byte message 'abc' (0x61 0x62 0x63) produces exactly one 64-byte block where bytes 0-2 are the message, byte 3 is 0x80, bytes 4-55 are 0x00, and bytes 56-63 encode 24 as a big-endian 64-bit integer.",
        "A 55-byte message produces exactly one 64-byte block: the 55 message bytes occupy bytes 0-54, byte 55 is 0x80, and bytes 56-63 encode 440 (= 55 \u00d7 8) as a big-endian 64-bit integer.",
        "A 56-byte message produces exactly two 64-byte blocks (128 bytes total): the 56 message bytes occupy bytes 0-55, byte 56 is 0x80, bytes 57-119 are 0x00, and bytes 120-127 encode 448 (= 56 \u00d7 8) as a big-endian 64-bit integer.",
        "sha256_get_block(padded_msg, i) returns a pointer to byte offset i * 64 within the padded buffer, and sha256_num_blocks(padded_len) returns padded_len / 64.",
        "The write_uint64_be() helper correctly writes a 64-bit value as 8 bytes with the most significant byte first, verified by checking that write_uint64_be(buf, 0x0102030405060708ULL) produces buf = {0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08}.",
        "The implementation handles messages of 0 bytes without undefined behavior (no null-pointer dereference in memcpy), and allocating sha256_padded_length(msg_len) bytes for the output buffer is always sufficient for any msg_len up to the tested range."
      ]
    },
    {
      "milestone_id": "hash-impl-m2",
      "criteria": [
        "The sha256_schedule() function accepts a pointer to exactly 64 bytes (one 512-bit block) and fills a uint32_t W[64] array, with W[0]..W[15] containing the 16 big-endian 32-bit words parsed from the block.",
        "Word extraction uses explicit byte shifting \u2014 read_uint32_be reads 4 bytes at offset i*4 using ((uint32_t)buf[i]<<24)|((uint32_t)buf[i+1]<<16)|((uint32_t)buf[i+2]<<8)|(uint32_t)buf[i+3] \u2014 and never casts the block pointer to uint32_t* directly.",
        "For the 'abc' padded block, W[0] == 0x61626380 and W[15] == 0x00000018, verifiable by running the test suite.",
        "sigma0 is implemented as rotr(x,7) ^ rotr(x,18) ^ (x>>3) using the exact rotation constants 7, 18 and shift constant 3 from FIPS 180-4 Section 4.1.2.",
        "sigma1 is implemented as rotr(x,17) ^ rotr(x,19) ^ (x>>10) using the exact rotation constants 17, 19 and shift constant 10 from FIPS 180-4 Section 4.1.2.",
        "rotr(x,n) is implemented as (x>>n)|(x<<(32-n)) using uint32_t so that the left shift wraps at 32 bits by C unsigned arithmetic rules.",
        "W[16] for the 'abc' schedule equals 0x61626380, verifiable because all surrounding input words (W[1]..W[14]) are zero so sigma1(0)+0+sigma0(0)+W[0] = W[0].",
        "W[17] for the 'abc' schedule equals 0x000F0000, verifiable from sigma1(0x00000018) = ROTR(0x18,17) XOR ROTR(0x18,19) XOR SHR(0x18,10) = 0x000C0000 XOR 0x00030000 XOR 0 = 0x000F0000.",
        "Words W[16]..W[63] are computed with the recurrence W[t] = sigma1(W[t-2]) + W[t-7] + sigma0(W[t-15]) + W[t-16] in that exact term order and with those exact index offsets (2, 7, 15, 16).",
        "All additions in the schedule loop produce uint32_t results that wrap naturally at 2^32 with no explicit masking \u2014 ensured by declaring W as uint32_t[64] and performing all additions in uint32_t arithmetic.",
        "All 64 schedule words W[0]..W[63] for the 'abc' input match the corresponding values in the NIST SHA-256 Example Computations document when printed in hexadecimal.",
        "sigma0 and sigma1 are declared static (or otherwise internal), not exposed in the public API, since they are implementation details of schedule generation.",
        "The word-extraction helper correctly casts each buf[i] to uint32_t before left-shifting, preventing sign-extension or shift-count undefined behavior on platforms where uint8_t promotes to signed int."
      ]
    },
    {
      "milestone_id": "hash-impl-m3",
      "criteria": [
        "Working variables a through h are initialized from H[0]..H[7] at the start of each block's compression, using exact uint32_t assignments with no implicit truncation.",
        "The Ch function is implemented as (x & y) ^ (~x & z) using uint32_t operands, and passes all truth-table tests: Ch(0xFFFFFFFF, A, B) == A, Ch(0x00000000, A, B) == B, and Ch(0xF0F0F0F0, 0xAAAAAAAA, 0x55555555) == 0xA5A5A5A5.",
        "The Maj function is implemented as (x & y) ^ (x & z) ^ (y & z) using uint32_t operands, and passes majority-vote tests: Maj(0xFFFFFFFF, 0xFFFFFFFF, 0x00000000) == 0xFFFFFFFF and Maj(0xFFFFFFFF, 0x00000000, 0x00000000) == 0x00000000.",
        "Sigma0 (uppercase) is implemented as ROTR(x,2) XOR ROTR(x,13) XOR ROTR(x,22), and Sigma1 (uppercase) is implemented as ROTR(x,6) XOR ROTR(x,11) XOR ROTR(x,25); both are distinct from the lowercase schedule sigma functions and verified: Sigma0(0x00000001) == 0x40080400 and Sigma1(0x00000001) == 0x04200080.",
        "64 rounds execute sequentially computing T1 = h + Sigma1(e) + Ch(e,f,g) + K[t] + W[t] and T2 = Sigma0(a) + Maj(a,b,c), then updating variables in the order: h=g, g=f, f=e, e=d+T1, d=c, c=b, b=a, a=T1+T2 \u2014 all mod 2^32 via uint32_t arithmetic.",
        "The new value of e is d + T1 (not d + T1 + T2), and the new value of a is T1 + T2; both T1 and T2 are fully computed before any working variable is updated within a round.",
        "All 64 round constants K[0]..K[63] match FIPS 180-4 Section 4.2.2: K[0] == 0x428A2F98 and K[63] == 0xC67178F2, verified by direct comparison.",
        "After all 64 rounds complete, the hash state is updated with H[i] += working_variable[i] for i in 0..7, all as uint32_t addition, and this update occurs exactly once per block, outside the round loop.",
        "Processing the 'abc' padded block with the FIPS 180-4 initial hash values produces final state: H[0]=0xBA7816BF, H[1]=0x8F01CFEA, H[2]=0x414140DE, H[3]=0x5DAE2223, H[4]=0xB00361A3, H[5]=0x96177A9C, H[6]=0xB410FF61, H[7]=0xF20015AD.",
        "The compression function can be called with a debug mode that prints (a,b,c,d,e,f,g,h) after each of the 64 rounds, and round 0 output matches the NIST SHA-256 Example Computation appendix intermediate values.",
        "The sha256_compress function accepts H as a uint32_t[8] modified in place and W as a const uint32_t[64], with no global mutable state \u2014 multiple calls with the same inputs produce identical outputs."
      ]
    },
    {
      "milestone_id": "hash-impl-m4",
      "criteria": [
        "SHA256_CTX struct contains exactly four fields: a uint32_t H[8] array for hash state, a uint8_t buf[64] partial block buffer, a size_t buf_len tracking bytes in buf (0-63), and a uint64_t total_len tracking total bytes processed.",
        "sha256_init() sets H[0..7] to exactly {0x6A09E667, 0xBB67AE85, 0x3C6EF372, 0xA54FF53A, 0x510E527F, 0x9B05688C, 0x1F83D9AB, 0x5BE0CD19}, zeroes buf with memset, and sets buf_len and total_len to zero.",
        "sha256_update() correctly handles Phase 1 (completing a partial block in buf when buf_len > 0), Phase 2 (processing full blocks directly from the input pointer without copying), and Phase 3 (buffering remaining partial data into buf).",
        "sha256_finalize() appends 0x80 to buf, then branches: if buf_len > 56 it zero-pads and compresses the current block before composing a second block; if buf_len <= 56 it zero-fills bytes [buf_len..55] in place.",
        "sha256_finalize() writes the 64-bit message length as (uint64_t)total_len * 8 into bytes [56..63] of the final block using big-endian byte order.",
        "sha256_finalize() serializes H[0..7] as consecutive 4-byte big-endian values into a 32-byte output array, and clears the context with memset after writing the digest.",
        "sha256_hex() converts a 32-byte binary digest to a 65-byte null-terminated lowercase hexadecimal string using the nibble-shift technique with the lookup string \"0123456789abcdef\".",
        "SHA-256 of the empty string (zero bytes, no update calls) equals e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855.",
        "SHA-256 of the 3-byte message \"abc\" equals ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad.",
        "SHA-256 of the 56-byte message \"abcdbcdecdefdefgefghfghighijhijkijkljklmklmnlmnomnopnopq\" equals 248d6a61d20638b8e5c026930c3e6039a33ce45964ff2167f6ecedd419db06c1, confirming correct two-block finalization.",
        "Streaming produces identical output to one-shot hashing: hashing a message in N calls to update() (for any chunk sizes that sum to the message length) produces the same digest as a single update() call.",
        "Calling sha256_init() on a previously used SHA256_CTX fully resets all fields, and two sequential hash computations using the same context variable produce identical results for identical inputs.",
        "The test suite explicitly tests the 64-byte and 128-byte exact block boundary cases, verifying that one-shot and two-call streaming produce identical digests.",
        "sha256_update() called with len=0 does not modify H[], buf, buf_len, or total_len."
      ]
    },
    {
      "module_id": "hash-impl-m1",
      "criteria": [
        "sha256_padded_length correctly calculates 64 for len 55 and 128 for len 56",
        "sha256_pad appends 0x80 immediately after message",
        "sha256_pad writes bit length in Big-Endian at the end of the final block",
        "sha256_get_block returns 64-byte aligned pointers",
        "Padding correctly handles empty message (0 bytes) resulting in one 64-byte block"
      ]
    },
    {
      "module_id": "hash-impl-m2",
      "criteria": [
        "W[0..15] extracted in big-endian order",
        "sigma0 uses ROTR(7), ROTR(18), SHR(3)",
        "sigma1 uses ROTR(17), ROTR(19), SHR(10)",
        "W[16..63] generated via W[t-2], W[t-7], W[t-15], W[t-16]",
        "All additions are modulo 2^32",
        "Passes NIST 'abc' schedule intermediate values test"
      ]
    },
    {
      "module_id": "hash-impl-m3",
      "criteria": [
        "Implement Sigma0/Sigma1 with correct rotation constants",
        "Implement Ch and Maj boolean functions",
        "Transcribe all 64 round constants accurately",
        "Execute 64 rounds of state transformation using T1 and T2",
        "Correctly shift and update working variables a-h",
        "Perform final state addition modulo 2^32"
      ]
    },
    {
      "module_id": "hash-impl-m4",
      "criteria": [
        "SHA256_CTX must contain 32-byte H state, 64-byte buffer, and length counters.",
        "sha256_init must reset H to NIST prime square root constants.",
        "sha256_update must implement 3-phase buffering (partial, direct, remainder).",
        "sha256_finalize must handle the 56-byte boundary case correctly (1 vs 2 blocks).",
        "Finalize must encode bit-length as Big-Endian 64-bit integer.",
        "Context must be zeroed in finalize to prevent info leaks.",
        "All 3 NIST KAT vectors (empty, abc, 56-byte) must pass.",
        "sha256_hex must produce lowercase hexadecimal strings.",
        "Endianness utilities must be host-agnostic using shifts."
      ]
    }
  ],
  "explained_concepts": [],
  "system_diagram_d2": null,
  "system_diagram_iteration": 0,
  "system_diagram_done": false,
  "project_structure_md": "",
  "project_charter_md": ""
}