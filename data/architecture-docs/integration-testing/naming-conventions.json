{
  "types": {
    "ContainerManager": "fields: containers Dict, logger",
    "DatabaseFixtureManager": "fields: connection_params Dict, connection",
    "IntegrationTestConfig": "fields: postgres_version str, redis_version str, container_startup_timeout int, app_host str, app_port int, mock_external_apis bool, log_level str, cleanup_strategy CleanupStrategy, max_parallel_containers int, container_network_name str, test_data_volume_path str, enable_container_logs bool, health_check_interval int, health_check_retries int",
    "CleanupStrategy": "enum: TRUNCATE_STRATEGY, ROLLBACK_STRATEGY, SCHEMA_STRATEGY",
    "ExecutionStatus": "enum: PASSED, FAILED, SKIPPED, ERROR, TIMEOUT, FLAKY",
    "FailureCategory": "enum: CONTAINER_STARTUP, DATABASE_CONNECTION, NETWORK_CONNECTIVITY, ASSERTION_FAILURE, TIMEOUT_EXCEEDED, EXTERNAL_SERVICE, RACE_CONDITION, RESOURCE_EXHAUSTION",
    "ServiceDefinition": "fields: definition_id str, display_name str, base_image str, supported_versions List[str], default_version str, required_environment_vars List[str], default_environment_vars Dict[str, str], standard_ports Dict[str, int], health_check_strategy str, initialization_timeout int, graceful_shutdown_timeout int, resource_requirements Dict[str, str]",
    "ServiceMetrics": "fields: service_name str, container_id str, image_name str, startup_duration_seconds float, health_check_attempts int, cpu_usage_percent float, memory_usage_mb float, network_bytes_sent int, network_bytes_received int, disk_io_read_mb float, disk_io_write_mb float, connection_count int, error_log_count int, restart_count int, final_status str",
    "ResourceUsageMetrics": "fields: total_cpu_percent float, total_memory_mb float, total_disk_io_mb float, total_network_io_mb float, peak_container_count int, resource_pressure_events List[Dict[str, Any]]",
    "TestResult": "fields: test_id str, test_suite_name str, test_case_name str, execution_status ExecutionStatus, start_timestamp str, end_timestamp str, total_duration_seconds float, setup_duration_seconds float, test_duration_seconds float, teardown_duration_seconds float, failure_reason Optional[str], failure_category Optional[FailureCategory], error_details Dict[str, Any], test_environment_info Dict[str, str], service_metrics List[ServiceMetrics], resource_usage Optional[ResourceUsageMetrics], flaky_test_indicators Dict[str, float]",
    "ContainerInfo": "container_id str, image str, ports Dict, status str, start_time float",
    "TestServerManager": "fields: config Dict, process Optional[subprocess.Popen], port Optional[int], logger",
    "HttpClientFactory": "fields: base_url str, default_timeout int, _clients Dict[str, requests.Session], _lock Lock, logger",
    "AuthenticationManager": "fields: base_url str, _tokens Dict[str, Dict[str, Any]], _lock RLock, logger",
    "MockServer": "fields: host str, port int, _server Optional[HTTPServer], _server_thread Optional[Thread], _stub_registry Dict[str, StubDefinition], _request_records List[RequestRecord], _lock RLock, _running bool",
    "StubDefinition": "fields: name str, url_pattern str, method str, response_status int, response_headers Dict[str, str], response_body str, response_delay_ms int, failure_rate float, request_matcher_headers Dict[str, str], verification_enabled bool",
    "RequestRecord": "fields: timestamp float, method str, url str, headers Dict[str, str], body bytes, matched_stub Optional[str]",
    "ResponseGenerator": "fields: _template_functions Dict[str, Callable]",
    "RequestVerifier": "fields: _mock_server MockServer",
    "RequestAssertion": "fields: description str, predicate Callable, failure_message str",
    "MockServerError": "base exception for mock server operations",
    "ContractDefinition": "fields: consumer_name str, provider_name str, contract_version str, interactions List[Dict[str, Any]], metadata Dict[str, str], created_timestamp str",
    "ContractVerificationResult": "fields: contract_id str, verification_status str, verification_timestamp str, provider_version str, consumer_version str, failed_interactions List[Dict[str, Any]], verification_details Dict[str, Any]",
    "ServiceDependency": "fields: service_name str, depends_on List[str], health_check_url str, startup_timeout int, ready_condition Optional[Callable]",
    "E2ETestEnvironment": "fields: environment_name str, services List[ServiceDependency], shared_network str, data_volumes Dict[str, str], environment_variables Dict[str, str], cleanup_strategy str",
    "EventMessage": "event_type str, source_component str, timestamp float, data Dict[str, Any], correlation_id Optional[str], severity EventSeverity, tags Optional[List[str]], format_version str",
    "ResourceHandle": "resource_id str, resource_type str, allocation_time float, connection_info Dict[str, Any], cleanup_callback Optional[Callable], state ResourceState, last_used Optional[float], metadata Optional[Dict[str, Any]]",
    "EventBus": "event processing and subscription management",
    "ResourceManager": "resource allocation and leak detection",
    "ResourceState": "enum: HEALTHY, WARNING, CRITICAL, UNKNOWN",
    "RecoveryAction": "fields: action_type str, parameters Dict[str, Any], max_attempts int, backoff_multiplier float, timeout_seconds int",
    "FrameworkInvariant": "fields: name str, description str, check_function callable, violation_handler callable, check_interval_seconds float, enabled bool",
    "FrameworkSelfValidator": "fields: resource_manager ResourceManager, event_bus EventBus, docker_client, invariants List, violation_history List, monitoring_active bool, monitoring_thread Optional[Thread]",
    "PerformanceMonitor": "fields: baseline_metrics Dict, current_metrics Dict, performance_history List, alert_thresholds Dict",
    "DockerInspector": "Docker environment inspection utilities",
    "NetworkDiagnostics": "Network connectivity and configuration diagnostics",
    "ResourceMonitor": "System resource monitoring for debugging",
    "PerformanceMeasurement": "Individual performance measurement record",
    "PerformanceAnalyzer": "Performance analysis and bottleneck identification",
    "IntegrationTestDiagnostics": "Comprehensive diagnostic system",
    "FlakyTestDetector": "Flaky test detection and analysis",
    "ParallelTestOrchestrator": "fields: workers List, resource_pools Dict, dependency_graph Dict, scheduler TestScheduler",
    "TestExecutionWorker": "fields: worker_id str, resource_handles Dict, execution_context Dict, status WorkerStatus",
    "ResourcePoolManager": "fields: pools Dict, allocation_policy str, monitoring_enabled bool",
    "DependencyAnalyzer": "fields: dependency_graph Dict, conflict_detector ConflictDetector",
    "ResultAggregator": "fields: result_store Dict, correlation_tracker Dict",
    "CloudDatabaseManager": "fields: provider_client Any, connection_pools Dict, credential_manager CredentialManager",
    "CloudServiceAbstractionLayer": "fields: service_registry Dict, provider_adapters Dict",
    "TestAnalyticsEngine": "fields: data_processors List, models Dict, insight_generators List",
    "TestPerformanceAnalyzer": "fields: baseline_metrics Dict, trend_models Dict",
    "FailurePatternDetector": "fields: pattern_library Dict, correlation_engine CorrelationEngine",
    "PerformancePredictor": "fields: models Dict, feature_extractors Dict",
    "TestMetric": "fields: timestamp float, test_id str, metric_name str, metric_value float, metadata Dict",
    "TestMetricsCollector": "fields: buffer_size int, flush_interval int, metrics_queue queue.Queue, storage_backends List",
    "WorkerStatus": "enum: IDLE, BUSY, STARTING, STOPPING, ERROR",
    "MetricsStorageBackend": "interface for metrics persistence"
  },
  "methods": {
    "start_postgres(database_name) -> Dict": "creates and starts PostgreSQL container",
    "start_redis() -> Dict": "creates and starts Redis container",
    "cleanup_all()": "stops and removes all containers",
    "setup_schema(migration_files)": "runs database migrations",
    "seed_test_data(fixture_data)": "inserts test data",
    "cleanup_data(strategy)": "cleans database between tests",
    "from_environment() -> IntegrationTestConfig": "create configuration from environment variables",
    "validate() -> List[str]": "validate configuration values and return error messages",
    "create_container_config(version, custom_env) -> Dict[str, Any]": "generate Docker container configuration",
    "to_json() -> str": "serialize test result to JSON",
    "from_json(json_str) -> TestResult": "deserialize test result from JSON",
    "validate_config(config) -> List[str]": "run validation rules and return error messages",
    "_find_available_port(start_port) -> int": "find available port starting from given port",
    "_wait_for_port(host, port, timeout) -> bool": "wait for port to become available",
    "start_test_transaction()": "begin transaction for rollback cleanup",
    "load_fixture_file(fixture_path) -> Dict": "load test data from JSON file",
    "start_server() -> Dict[str, Any]": "start application server with test configuration",
    "stop_server()": "gracefully stop application server",
    "get_client(client_type, auth_token, timeout) -> requests.Session": "get or create HTTP client with specified configuration",
    "get_token(user_role) -> str": "get valid authentication token for user role",
    "authenticate_user(username, password) -> Dict[str, Any]": "perform initial authentication",
    "refresh_token(user_role) -> bool": "refresh expired token using refresh token",
    "clear_tokens()": "clear all cached authentication tokens",
    "start() -> Dict[str, Any]": "start mock server and return connection info",
    "stop()": "stop mock server and clean up resources",
    "add_stub(stub)": "add or update stub configuration",
    "remove_stub(stub_name)": "remove stub configuration",
    "clear_stubs()": "remove all stub configurations",
    "get_request_records(stub_name=None) -> List[RequestRecord]": "get recorded requests optionally filtered by stub",
    "clear_request_records()": "clear all recorded request history",
    "generate_response(stub, request_context) -> str": "generate response with template substitution",
    "_extract_url_matches(url_pattern, actual_url) -> Dict[str, str]": "extract capture groups from URL pattern",
    "_apply_template_substitution(template, variables) -> str": "replace template variables with values",
    "assert_request_count(stub_name, expected_count)": "assert stub called exactly N times",
    "assert_request_made_with_headers(stub_name, expected_headers)": "assert requests included specific headers",
    "assert_requests_made_in_order(stub_names)": "assert services called in specific order",
    "assert_no_requests_made(stub_name)": "assert service was never called",
    "get_request_summary() -> Dict[str, Any]": "return summary of intercepted requests",
    "load_stubs_from_yaml(file_path) -> List[StubDefinition]": "load stub definitions from YAML file",
    "_find_matching_stub(method, path, headers) -> Optional[StubDefinition]": "find first stub matching request",
    "_wait_for_server_ready(timeout=5.0)": "wait for server to handle requests",
    "to_pact_format() -> Dict[str, Any]": "convert contract to Pact JSON format",
    "publish_contract(contract) -> bool": "publish consumer contract to broker",
    "get_contracts_for_verification(provider_name, provider_version) -> List[ContractDefinition]": "retrieve consumer contracts for provider verification",
    "publish_verification_result(result) -> bool": "publish provider verification result",
    "verify_contract(contract) -> ContractVerificationResult": "verify provider matches contract expectations",
    "wait_for_service_ready(service) -> bool": "wait for service health and readiness",
    "start_environment(environment) -> Dict[str, Any]": "start complete test environment with dependencies",
    "cleanup_environment()": "clean up test environment resources",
    "execute_consumer_contract_tests(consumer_name, contracts) -> List[TestResult]": "execute consumer contract test verification",
    "execute_provider_contract_verification(provider_name, version) -> List[ContractVerificationResult]": "verify provider against consumer contracts",
    "detect_contract_compatibility_issues(old_contract, new_contract) -> List[str]": "analyze contract changes for breaking compatibility",
    "execute_user_journey_test(journey_definition) -> TestResult": "execute complete user journey across services",
    "verify_cross_service_data_consistency(consistency_rules) -> List[str]": "verify data consistency across service boundaries",
    "execute_system_stress_test(load_profile) -> Dict[str, Any]": "execute system-wide load testing",
    "analyze_test_stability(test_history) -> Dict[str, Any]": "analyze test execution patterns for flakiness",
    "detect_environmental_correlations(test_results, environment_metrics) -> Dict[str, float]": "identify correlations between failures and environment",
    "generate_stability_report(analysis_period_days) -> Dict[str, Any]": "generate comprehensive stability report",
    "execute_test_suite(test_discovery_path) -> List[TestResult]": "coordinate complete integration test execution",
    "_discover_tests(discovery_path) -> List[Dict[str, Any]]": "discover and extract test metadata",
    "_create_execution_plan(test_cases) -> Dict[str, Any]": "create optimized test execution plan",
    "publish(event)": "publish event to all subscribers",
    "subscribe(event_type, callback)": "subscribe to events of specific type",
    "allocate_resource(resource_type, connection_info, cleanup_callback, metadata) -> str": "allocate new resource and return ID",
    "release_resource(resource_id) -> bool": "release resource and perform cleanup",
    "get_resource_summary() -> Dict[str, Any]": "get current resource allocation summary",
    "register_failure(failure_category, failure_details, affected_resources) -> str": "register failure and return recovery correlation ID",
    "execute_recovery(correlation_id) -> bool": "execute recovery strategy for registered failure",
    "detect_cascading_failures(failure_window_seconds) -> List[Dict[str, Any]]": "analyze failure history for cascading patterns",
    "predict_failure_risk(resource_id) -> Dict[str, float]": "predict failure risk based on metrics and history",
    "get_recovery_status(correlation_id) -> Optional[Dict[str, Any]]": "get current status of active recovery operation",
    "collect_service_metrics(container_id) -> Optional[ServiceMetrics]": "collect comprehensive metrics for specific container",
    "collect_system_metrics() -> ResourceUsageMetrics": "collect system-wide resource usage metrics",
    "start_collection()": "start background metrics collection",
    "stop_collection()": "stop collection and flush remaining metrics",
    "add_alert_callback(callback)": "add callback function for resource threshold alerts",
    "start_monitoring()": "start continuous invariant monitoring",
    "stop_monitoring()": "stop invariant monitoring and generate report",
    "record_operation_timing(operation_name, duration_seconds)": "record timing for framework operation",
    "record_resource_usage(resource_type, usage_amount)": "record resource usage measurement",
    "generate_performance_report() -> Dict": "generate comprehensive performance analysis report",
    "diagnose_test_failure(test_result) -> Dict[str, Any]": "comprehensive diagnosis of test failure",
    "diagnose_container_startup_failure(container_id, service_name) -> Dict[str, Any]": "diagnose container startup failures",
    "diagnose_database_connection_failure(connection_params, container_id) -> Dict[str, Any]": "diagnose database connection failures",
    "diagnose_performance_degradation(test_results, baseline_metrics) -> Dict[str, Any]": "diagnose performance degradation",
    "generate_debugging_playbook(diagnosis_results) -> str": "generate step-by-step debugging guide",
    "get_system_info() -> Dict[str, Any]": "collect comprehensive Docker system information",
    "get_container_details(container_id) -> Optional[Dict[str, Any]]": "get comprehensive container details",
    "test_container_connectivity(container_id, target_host, target_port) -> Dict[str, Any]": "test network connectivity from container",
    "collect_system_resources() -> Dict[str, Any]": "collect comprehensive system resource usage",
    "record_measurement(operation_name, duration_seconds, success, **metadata)": "record performance measurement",
    "analyze_operation_performance(operation_name) -> Dict[str, Any]": "analyze performance statistics for operation",
    "analyze_test_stability(test_name, execution_history) -> Dict[str, Any]": "analyze test stability and flakiness",
    "detect_environmental_correlations(test_results) -> Dict[str, Any]": "detect correlations between failures and environment",
    "predict_execution_time(test_metadata) -> Dict[str, float]": "predict test execution time with confidence intervals",
    "predict_resource_requirements(test_suite) -> Dict[str, Any]": "predict resource requirements for test suite",
    "update_model(actual_results)": "update prediction models with actual results",
    "record_metric(test_id, metric_name, value, **metadata)": "record test metric with minimal blocking",
    "add_storage_backend(backend)": "add storage backend for metrics persistence",
    "schedule_test_execution(test_queue) -> ExecutionPlan": "create optimized execution plan for test queue",
    "allocate_cloud_resources(requirements) -> ResourceAllocation": "provision cloud resources for testing",
    "analyze_failure_patterns(test_results) -> FailureAnalysis": "identify patterns in test failures",
    "generate_performance_report() -> PerformanceReport": "create comprehensive performance analysis",
    "create_prediction_features(test_metadata) -> FeatureVector": "extract features for ML prediction",
    "detect_performance_regression(current_metrics, baseline) -> RegressionAnalysis": "identify performance degradation"
  },
  "constants": {
    "DEFAULT_POSTGRES_VERSION": "13",
    "DEFAULT_REDIS_VERSION": "6-alpine",
    "DEFAULT_CONTAINER_TIMEOUT": "60 seconds",
    "TRUNCATE_STRATEGY": "truncate tables for cleanup",
    "ROLLBACK_STRATEGY": "rollback transactions for cleanup",
    "SCHEMA_STRATEGY": "separate schemas for cleanup",
    "DEFAULT_MOCK_SERVER_PORT": "0 (auto-assign)",
    "DEFAULT_REQUEST_TIMEOUT": "5.0 seconds",
    "HEALTH_CHECK_ENDPOINT": "/health",
    "DEFAULT_BUFFER_SIZE": "1000 metrics",
    "DEFAULT_FLUSH_INTERVAL": "10 seconds",
    "PREDICTION_CONFIDENCE_THRESHOLD": "0.8",
    "PARALLEL_WORKER_LIMIT": "10 workers",
    "CLOUD_RESOURCE_TIMEOUT": "300 seconds"
  },
  "terms": {
    "integration testing": "testing component interactions with real dependencies",
    "test isolation": "ensuring tests don't interfere through proper resource management",
    "container lifecycle": "startup, health checking, and cleanup phases",
    "database fixtures": "test data and schema setup for deterministic tests",
    "environmental realism": "using real dependencies versus mocks to achieve production-like test conditions",
    "containerized testing": "using Docker containers for test dependencies",
    "consumer-driven contracts": "API contracts defined by consuming services specifying their expectations",
    "contract testing": "verifying service interface compatibility using consumer-defined contracts",
    "flaky test detection": "identifying unreliable tests through statistical analysis",
    "service orchestration": "managing startup order, dependencies, and lifecycle of multiple test services",
    "configuration validation": "checking configuration correctness before test execution",
    "resource management": "controlling CPU, memory, and disk usage during tests",
    "health check strategies": "methods for determining when services are ready",
    "failure categorization": "automatic classification of test failure types",
    "service mocking": "intercepting and controlling external service calls during testing",
    "request interception": "capturing outbound HTTP requests before they reach real services",
    "stub configuration": "rules defining how mock server responds to specific requests",
    "response stubbing": "configured responses returned by mock server for matched requests",
    "request verification": "assertions about what external service calls were made during tests",
    "template substitution": "dynamic response generation using variables and functions",
    "failure simulation": "controlled injection of errors and delays in mock responses",
    "mock server lifecycle": "startup, configuration, request handling, and cleanup of mock infrastructure",
    "HTTP proxy interception": "routing application requests through mock server as HTTP proxy",
    "probabilistic error injection": "random failure generation based on configured probability rates",
    "end-to-end testing": "comprehensive user journey testing spanning multiple services and dependencies",
    "test stability": "consistency of test results across multiple executions under similar conditions",
    "contract verification": "validating provider implementation matches consumer contract expectations",
    "synchronous request-response": "blocking communication pattern for infrastructure operations",
    "asynchronous event notification": "non-blocking communication for monitoring and metrics",
    "resource acquisition and release": "structured resource management with automatic cleanup",
    "event correlation": "tracking related events across component boundaries",
    "dependency ordering": "ensuring services start in correct sequence",
    "health check polling": "verifying service readiness with retry logic",
    "resource leak detection": "identifying unreleased resources over time",
    "predictive resource management": "trend-based intervention before resource exhaustion",
    "framework component testing": "validation of individual framework components in isolation",
    "milestone verification checkpoints": "automated validation that milestone functionality works correctly",
    "self-validation": "framework monitoring its own behavior for inconsistencies",
    "invariant checking": "validating consistency constraints during operation",
    "performance regression detection": "monitoring framework timing to detect degradation",
    "dependency injection": "replacing external dependencies with test doubles",
    "failure injection": "artificially triggering error conditions for testing",
    "environmental validation": "checking that testing environment meets requirements",
    "component isolation": "testing framework components independently",
    "meta-testing": "testing the testing framework itself",
    "race condition detection": "identifying timing-dependent test failures",
    "evidence collection": "systematic gathering of diagnostic information",
    "root cause analysis": "tracing symptoms back to underlying problems",
    "parallel test execution": "executing multiple tests simultaneously across containers and machines",
    "cloud provider integration": "using managed cloud services for test dependencies",
    "predictive performance modeling": "using machine learning to forecast test execution characteristics",
    "resource pool management": "coordinating allocation of shared testing resources",
    "test analytics": "comprehensive analysis of test execution data and patterns",
    "failure pattern detection": "identifying recurring patterns in test failures",
    "performance benchmarking": "establishing baseline performance metrics for testing infrastructure",
    "cost-aware scheduling": "optimizing test execution considering cloud service costs",
    "geographic distribution": "running tests across multiple cloud regions",
    "advanced reporting": "interactive dashboards and automated insight generation"
  }
}