{
  "types": {
    "Logger": "name str, level int, parent Logger, handlers List[Handler], children Dict[str, Logger], context Dict[str, Any], propagate bool, _effective_level int, _lock RLock",
    "LogRecord": "timestamp str, level int, message str, logger_name str, context Dict[str, Any]",
    "Handler": "abstract base class for output destinations",
    "ThreadSafeCounter": "_value int, _lock Lock",
    "ThreadSafeDict": "_data Dict[str, Any], _lock RLock",
    "SafeJSONEncoder": "custom JSON encoder with circular reference protection",
    "LogLevel": "numeric constants DEBUG=10, INFO=20, WARN=30, ERROR=40, FATAL=50",
    "Context": "Dict[str, Any] with inheritance semantics",
    "LoggerRegistry": "_loggers Dict[str, Logger], _lock RLock",
    "BaseFormatter": "abstract base class with format method",
    "JSONFormatter": "concrete formatter for single-line JSON output",
    "PrettyFormatter": "concrete formatter for colored console output",
    "FormatterRegistry": "_formatters Dict[str, BaseFormatter], _lock RLock",
    "TimestampCache": "_cache Dict[str, str], _access_order List[str], max_size int",
    "CorrelationIDGenerator": "service_name str, _lock threading.Lock",
    "ContextStorage": "_thread_local threading.local, _async_var contextvars.ContextVar, _active_contexts weakref.WeakSet, _lock RLock",
    "RequestContextMiddleware": "app Callable, service_name str",
    "LoggingContext": "static methods for context management",
    "AsyncContextManager": "context Dict[str, Any], previous_context Dict[str, Any]",
    "CircuitBreaker": "failure_threshold int, timeout_seconds float, _failure_count ThreadSafeCounter, _last_failure_time Optional[float], _state HandlerState, _lock RLock",
    "ContextBuffer": "max_size int, max_memory_bytes int, _buffer deque, _current_memory int, _lock RLock",
    "BaseHandler": "name str, _circuit_breaker CircuitBreaker, _buffer ContextBuffer, _state HandlerState, _last_success_time float",
    "FileHandler": "file_path str, _file_handle Optional[File]",
    "HandlerState": "enum with HEALTHY, DEGRADED, FAILED, RECOVERING",
    "ControllableHandler": "test handler with programmable failure behavior",
    "CircularReferenceObject": "test object that references itself",
    "NonSerializableObject": "custom object that cannot be JSON serialized",
    "TraceLogger": "_lock Lock, _records deque, _output_file str, _start_time float",
    "ContextInspector": "_inspection_lock Lock, _context_history List, _active_contexts WeakSet",
    "ConcurrencyTestFramework": "max_workers int, test_results List, results_lock Lock",
    "SamplingConfig": "base_sample_rate float, max_sample_rate float, min_sample_rate float, adaptation_window int, importance_boost Dict[str, float]",
    "TokenBucketRateLimiter": "tokens_per_second float, burst_capacity int, _tokens float, _last_update float, _lock threading.Lock",
    "AdaptiveSampler": "config SamplingConfig, _current_rate float, _decision_cache Dict[str, bool], _load_monitor LoadMonitor, _lock threading.RLock",
    "LoadMonitor": "measurement_window int, _cpu_samples List, _memory_samples List, _lock threading.Lock, _monitoring bool",
    "ElasticsearchConfig": "hosts List[str], index_prefix str, batch_size int, flush_interval float, max_retries int, timeout float",
    "BulkProcessor": "config ElasticsearchConfig, client Any, _batch_buffer List[Dict[str, Any]], _batch_lock threading.Lock, _last_flush float",
    "ElasticsearchHandler": "config ElasticsearchConfig, _client Any, _bulk_processor BulkProcessor",
    "ConfigurationChange": "change_id str, timestamp float, changes Dict[str, Any], previous_values Dict[str, Any], source str",
    "ConfigurationValidator": "_validation_rules List[Callable], default rules",
    "ConfigurationManager": "logger_registry LoggerRegistry, _current_config Dict[str, Any], _config_history List[ConfigurationChange], _validator ConfigurationValidator, _lock threading.RLock"
  },
  "methods": {
    "log(level, message, **context)": "main logging entry point with filtering and dispatch",
    "debug/info/warn/error/fatal(message, **context)": "convenience methods for specific log levels",
    "safe_serialize(data, max_depth)": "serialize dict to JSON with circular reference protection",
    "estimate_serialized_size(data)": "estimate JSON size without full serialization",
    "safe_call(func, *args, default, **kwargs)": "safely execute function with exception handling",
    "should_log(message_level, configured_level)": "determine if message should be logged based on level filtering",
    "to_dict()": "convert log record to dictionary for JSON serialization",
    "should_log(message_level, configured_level) -> bool": "determine if message should be logged",
    "to_dict() -> Dict[str, Any]": "convert log record to dictionary for JSON serialization",
    "safe_serialize(data, max_depth) -> str": "serialize dict to JSON with circular reference protection",
    "estimate_serialized_size(data) -> int": "estimate JSON size without full serialization",
    "LogRecord.create(level, message, logger_name, context) -> LogRecord": "factory method to create LogRecord with current timestamp",
    "LoggingContext.get_current() -> Dict[str, Any]": "get current logging context from thread-local or async storage",
    "LoggingContext.set_current(context)": "set current logging context in both storage mechanisms",
    "LoggingContext.add_fields(**fields)": "add fields to current context without replacing existing context",
    "LoggingContext.clear()": "clear current logging context from all storage",
    "get_effective_level() -> int": "get effective level walking up hierarchy",
    "set_level(level)": "set logger level and invalidate caches",
    "collect_handlers() -> List[Handler]": "collect all applicable handlers from hierarchy",
    "get_logger(name) -> Logger": "factory function for logger creation with hierarchy",
    "format(record: LogRecord) -> str": "convert LogRecord to formatted string",
    "safe_serialize(data: Any, max_depth: int) -> str": "serialize with circular reference protection",
    "estimate_serialized_size(data: Any) -> int": "estimate JSON size without full serialization",
    "to_dict(record: LogRecord) -> Dict[str, Any]": "convert LogRecord to dictionary",
    "get_current_timestamp(precision: str) -> str": "generate UTC timestamp with specified precision",
    "format_timestamp(timestamp: str, format_type: str) -> str": "convert timestamp to specified format",
    "colorize(text: str, color: str) -> str": "apply terminal colors with fallback",
    "register_formatter(name: str, formatter: BaseFormatter)": "register formatter in global registry",
    "get_formatter(name: str) -> Optional[BaseFormatter]": "retrieve formatter by name",
    "generate() -> str": "generate new correlation ID with optional service prefix",
    "get_current() -> Dict[str, Any]": "get current logging context from storage",
    "set_current(context)": "set current logging context in storage",
    "add_fields(**fields)": "add fields to current context without replacing",
    "clear()": "clear current logging context from storage",
    "inherit(additional_context) -> ContextManager": "context manager for context inheritance",
    "propagate_to_async_task(task_func, *args, **kwargs)": "helper to propagate context to async task",
    "preserve_context(coro) -> T": "ensure logging context preserved across async operation",
    "create_task_with_context(coro, context) -> asyncio.Task": "create async task with explicit context propagation",
    "safe_call(func, *args, default, timeout, **kwargs)": "safely execute function with exception handling",
    "handle(record: LogRecord) -> bool": "process log record with error recovery",
    "recover() -> bool": "attempt handler recovery and buffer flush",
    "_write_record(record: LogRecord) -> None": "subclass implementation for actual output",
    "set_current(context: Dict[str, Any]) -> None": "set current logging context in storage",
    "cleanup_orphaned_contexts() -> int": "clean up contexts not accessed recently",
    "preserve_context_async(coro)": "decorator preserving context across async operations",
    "increment() -> int": "thread-safe counter increment",
    "reset() -> None": "thread-safe counter reset",
    "call(func, *args, **kwargs)": "execute function through circuit breaker",
    "add_record(record: LogRecord) -> bool": "add record to buffer with size limits",
    "flush_to_handler(handler: Handler) -> int": "flush buffered records to recovered handler",
    "simulate_failure(should_fail, delay)": "control handler failure behavior for testing",
    "get_records()": "thread-safe access to captured records",
    "generate_complex_context()": "generate context with various data types for testing",
    "generate_correlation_id()": "generate test correlation ID with realistic format",
    "trace(event_type, details)": "log trace event with timing and thread info",
    "get_records(event_type, thread_id) -> List": "retrieve filtered trace records",
    "dump_summary() -> str": "generate human-readable trace summary",
    "register_context(context_id, context_data, storage_type)": "register context for inspection tracking",
    "snapshot_all_contexts() -> Dict": "capture complete context state snapshot",
    "find_context_inconsistencies() -> List": "identify storage mechanism inconsistencies",
    "generate_context_report() -> str": "create comprehensive debugging report",
    "run_coordinated_test(test_func, num_threads, iterations) -> Dict": "execute coordinated multi-threaded test",
    "test_logger_hierarchy_creation(logger_factory) -> Dict": "test concurrent logger creation races",
    "test_concurrent_configuration_changes(logger_registry) -> Dict": "test concurrent config modification",
    "test_context_propagation_race_conditions(context_manager) -> Dict": "test context propagation under contention",
    "acquire(tokens=1) -> bool": "attempt to acquire tokens with rate limiting",
    "should_sample(record) -> bool": "determine if log record should be sampled",
    "_calculate_adaptive_rate(importance, load) -> float": "calculate sampling rate based on conditions",
    "get_current_load() -> Dict[str, float]": "get current system load metrics",
    "add_document(record) -> None": "add log record to bulk batch",
    "_generate_index_name(record) -> str": "create time-based index name",
    "flush_batch() -> bool": "flush current batch to Elasticsearch",
    "_write_record(record) -> None": "write log record to Elasticsearch",
    "validate_configuration(config) -> List[str]": "validate config and return errors",
    "apply_configuration(new_config, source) -> bool": "apply new configuration with validation",
    "rollback_to_previous() -> bool": "rollback to previous configuration",
    "LogRecord.create(level, message, logger_name, context)": "factory method to create LogRecord with current timestamp",
    "LoggingContext.get_current()": "get current logging context from thread-local or async storage",
    "get_effective_level()": "get effective level walking up hierarchy",
    "collect_handlers()": "collect all applicable handlers from hierarchy",
    "get_logger(name)": "factory function for logger creation with hierarchy",
    "format(record)": "convert LogRecord to formatted string",
    "get_current_timestamp(precision)": "generate UTC timestamp with specified precision",
    "format_timestamp(timestamp, format_type)": "convert timestamp to specified format",
    "colorize(text, color)": "apply terminal colors with fallback",
    "register_formatter(name, formatter)": "register formatter in global registry",
    "get_formatter(name)": "retrieve formatter by name",
    "generate()": "generate new correlation ID with optional service prefix",
    "inherit(additional_context)": "context manager for context inheritance",
    "preserve_context(coro)": "ensure logging context preserved across async operation",
    "create_task_with_context(coro, context)": "create async task with explicit context propagation",
    "handle(record)": "process log record with error recovery",
    "recover()": "attempt handler recovery and buffer flush",
    "_write_record(record)": "subclass implementation for actual output",
    "cleanup_orphaned_contexts()": "clean up contexts not accessed recently",
    "increment()": "thread-safe counter increment",
    "reset()": "thread-safe counter reset",
    "add_record(record)": "add record to buffer with size limits",
    "flush_to_handler(handler)": "flush buffered records to recovered handler"
  },
  "constants": {
    "DEBUG": "10",
    "INFO": "20",
    "WARN": "30",
    "ERROR": "40",
    "FATAL": "50",
    "MAX_DEPTH": "10 - maximum serialization depth",
    "DEFAULT_TIMEOUT": "5.0 - default timeout for operations",
    "LEVEL_NAMES": "mapping of numeric levels to string names",
    "X-Correlation-ID": "standard header for correlation ID propagation",
    "X-Request-ID": "alternative header for correlation ID",
    "X-Request-Duration": "response header with request processing time",
    "HEALTHY": "handler operating normally",
    "DEGRADED": "experiencing intermittent failures",
    "FAILED": "consecutive failures exceeded threshold",
    "RECOVERING": "attempting to return to service",
    "base_sample_rate": "1.0 - default sampling rate",
    "max_sample_rate": "1.0 - maximum sampling rate",
    "min_sample_rate": "0.01 - minimum sampling rate",
    "adaptation_window": "60 - seconds for adaptation",
    "batch_size": "100 - default Elasticsearch batch size",
    "flush_interval": "5.0 - seconds between flushes",
    "max_retries": "3 - maximum retry attempts",
    "timeout": "30.0 - default operation timeout"
  },
  "terms": {
    "structured logging": "logging with consistent queryable field structure",
    "correlation ID": "unique identifier linking related log entries across service boundaries",
    "context propagation": "mechanism for carrying contextual information through nested function calls",
    "handler dispatch": "routing log records to multiple output destinations",
    "thread safety": "correct behavior under concurrent access",
    "log level filtering": "suppressing messages below configured severity threshold",
    "async context preservation": "maintaining logging context across async/await boundaries",
    "immutability": "property where objects cannot be modified after creation",
    "inheritance": "child loggers inherit configuration from parents",
    "logger hierarchy": "tree of parent-child logger relationships",
    "level filtering": "suppressing messages below configured severity threshold",
    "propagation": "bubbling log records up hierarchy to parent handlers",
    "effective level": "actual level after walking inheritance chain",
    "JSON formatter": "formats LogRecord objects as single-line JSON strings",
    "pretty formatter": "human-readable colored console output for development",
    "formatter plugin system": "extensible architecture for custom output formats",
    "timestamp formatting": "conversion of temporal data to various string formats",
    "color terminal detection": "automatic detection of terminal color capabilities",
    "circular reference protection": "preventing infinite loops during object serialization",
    "context truncation": "limiting context object size to prevent memory issues",
    "async context bridge": "system preserving context across async boundaries",
    "request context middleware": "HTTP middleware extracting and establishing request-level logging context",
    "context inheritance": "child contexts inherit all fields from parents and can add additional fields",
    "dual storage strategy": "using both thread-local and async-local storage with synchronization",
    "context isolation": "ensuring changes in child contexts don't affect parent contexts",
    "ambient context": "contextual information available anywhere within request scope without parameter passing",
    "circuit breaker pattern": "preventing cascade failures during outages",
    "graceful degradation": "maintaining partial functionality when components fail",
    "handler isolation": "independent error handling per output destination",
    "safe serialization": "JSON encoding with protection against edge cases",
    "context cleanup": "automatic resource management for logging context objects",
    "memory leak prevention": "strategies to prevent unbounded context accumulation",
    "buffer management": "intelligent queuing of failed log records",
    "failure recovery": "automatic restoration of failed components",
    "milestone checkpoints": "concrete verification criteria for implementation stages",
    "integration testing": "verification that component interactions work correctly under realistic production conditions",
    "unit testing": "isolation of individual subsystems while simulating complex interactions",
    "thread safety testing": "verification of correct concurrent behavior",
    "race condition": "concurrency bug where timing affects correctness",
    "memory leak": "unbounded accumulation of unreferenced objects",
    "blocking I/O": "synchronous operations that halt thread execution",
    "trace logging": "internal debugging system for logging infrastructure",
    "context inspection": "examination of current context state across storage mechanisms",
    "adaptive sampling": "intelligent sampling that adjusts based on system load and log importance",
    "rate limiting": "controlling throughput to prevent system overload",
    "async handler dispatch": "non-blocking log processing using background threads",
    "Elasticsearch integration": "indexing logs for search and analytics",
    "metrics integration": "extracting quantitative signals from log entries",
    "distributed tracing integration": "connecting logs to trace spans for request correlation",
    "dynamic reconfiguration": "changing logging behavior at runtime without restart",
    "environment-based configuration": "automatic config adaptation based on deployment context",
    "configuration hot-reload": "applying config changes without service restart",
    "bulk indexing": "batching multiple documents for efficient writes",
    "index rotation": "time-based partitioning of log data",
    "token bucket": "smooth rate limiting algorithm with burst capacity",
    "correlation-aware sampling": "consistent sampling decisions within request context",
    "configuration validation": "ensuring config changes are safe before applying",
    "lazy evaluation": "deferring expensive operations until actually needed"
  }
}