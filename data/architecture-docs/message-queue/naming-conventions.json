{
  "types": {
    "Topic": "fields: Name string, Subscribers map[string]*Consumer, ConsumerGroups map[string]*ConsumerGroup, MessageQueue []Message, MessageIndex map[string]int, RetentionPolicy RetentionPolicy, CreatedAt int64, LastActivity int64, TotalMessages int64, ActiveMessages int64",
    "Publisher": "application sending messages",
    "Subscriber": "application receiving messages",
    "Consumer": "fields: ID string, ClientAddress string, SubscribedTopics []string, GroupID string, LastHeartbeat int64, MaxInflight int, CurrentInflight int, PendingMessages map[string]Message, ProcessedCount int64, ErrorCount int64",
    "ConsumerGroup": "fields: Name string, Topic string, Members map[string]*Consumer, AssignmentStrategy string, RebalanceInProgress bool, RebalanceGeneration int64, MessageAssignments map[string]string, NextAssignment int, CreatedAt int64, LastRebalance int64, TotalRebalances int64",
    "Message": "fields: ID string, Topic string, Payload []byte, Headers map[string]string, Timestamp int64, ProducerID string, RetryCount int, MaxRetries int, AckDeadline int64, AssignedConsumer string",
    "Exchange": "routing component in RabbitMQ",
    "Partition": "ordered log segment in Kafka",
    "BrokerConfig": "configuration parameters",
    "RetentionPolicy": "fields: MaxAge int64, MaxSize int64, MaxMessages int64, RequireAck bool, CompactionEnabled bool",
    "WALRecord": "fields: Magic uint32, Version uint32, RecordLength uint32, RecordType WALRecordType, Timestamp int64, TransactionID uint64, Checksum uint32, Data json.RawMessage",
    "FrameHeader": "fields: Magic uint32, Version uint8, FrameType uint8, Flags uint8, Reserved uint8, PayloadLength uint32",
    "Connection": "client connection wrapper",
    "Handler": "fields: connections sync.Map, topicManager interface{}",
    "TopicManager": "core component managing topics and subscriptions",
    "WildcardSubscription": "pattern-based subscription entry",
    "DeliveryTask": "message delivery work item",
    "Config": "topic manager configuration",
    "Metrics": "performance monitoring data",
    "HeartbeatTracker": "fields: heartbeats map[string]*ConsumerHeartbeat, timeoutThreshold time.Duration, cleanupInterval time.Duration, groupCoordinator GroupCoordinatorInterface, ackTracker AckTrackerInterface, cleanupTicker *time.Ticker, shutdownCh chan struct{}",
    "ConsumerHeartbeat": "fields: ConsumerID string, LastHeartbeat time.Time, ConsecutiveMisses int, ProcessingStatus string, PendingMessageCount int, AverageProcessingTime time.Duration, ErrorRate float64",
    "GroupCoordinator": "main component managing consumer groups",
    "AssignmentStrategy": "interface defining message assignment algorithms",
    "StrategyRegistry": "manages available assignment strategies",
    "RoundRobinStrategy": "implements round-robin assignment",
    "StickyStrategy": "implements sticky assignment",
    "AckTracker": "fields: pendingMessages map, consumerMessages map, timeoutQueue slice, ackTimeoutDefault time.Duration, maxRetries int, poisonDetector *PoisonDetector, walLogger WALLogger, mutex sync.RWMutex",
    "PendingMessage": "fields: Message *Message, ConsumerID string, AssignedAt time.Time, AckDeadline time.Time, DeliveryHistory []DeliveryAttempt, RetryCount int, LastRetryAt *time.Time",
    "DeliveryAttempt": "fields: AttemptID string, ConsumerID string, DeliveredAt time.Time, AckDeadline time.Time, CompletedAt *time.Time, Result DeliveryResult, ErrorReason string, ProcessingDuration time.Duration",
    "ConsumerLoadInfo": "fields: ConsumerID string, PendingCount int, MaxInflight int, OldestPending *time.Time, AvgProcessingTime time.Duration, RecentErrorRate float64, LastHeartbeat time.Time",
    "WALLogger": "interface for persistence integration",
    "AckEvent": "fields: EventType string, Timestamp time.Time, MessageID string, ConsumerID string, Data json.RawMessage",
    "WALWriter": "fields: file *os.File, writer *bufio.Writer, offset int64, fsyncPolicy FsyncPolicy, mutex sync.Mutex",
    "WALReader": "fields: file *os.File, reader *bufio.Reader, offset int64, mutex sync.RWMutex",
    "FsyncPolicy": "fields: Mode string, Interval time.Duration, BatchSize int",
    "WAL": "fields: writer *WALWriter, reader *WALReader, logDir string, compactor *LogCompactor, checkpointer *Checkpointer, config WALConfig, recordCount int64, bytesWritten int64, lastCompaction time.Time",
    "BrokerState": "recovered state structure",
    "LogCompactor": "background compaction component",
    "Checkpointer": "state snapshot component",
    "WALConfig": "configuration parameters",
    "CheckpointMetadata": "checkpoint information",
    "LogStatistics": "log metrics and stats",
    "FlowController": "fields: lagMonitor *LagMonitor, throttleManager *ThrottleManager, config *BackpressureConfig, metrics *SystemMetrics, publishers map[string]*PublisherState, mutex sync.RWMutex",
    "CapacityStatus": "fields: Status CapacityLevel, CurrentLag time.Duration, MessageBacklog int64, LagTrend TrendDirection, RecommendedAction ThrottleAction, EstimatedCatchupTime time.Duration, ActiveConsumers int",
    "LagMetricsCollector": "fields: measurements map[string]*CircularBuffer, trends map[string]*TrendAnalyzer, mutex sync.RWMutex, config MetricsConfig",
    "TokenBucketThrottler": "fields: buckets map[string]*TokenBucket, mutex sync.RWMutex, defaultRate time.Duration",
    "CircularBuffer": "fields: values []float64, index int, full bool, capacity int, mutex sync.RWMutex",
    "TokenBucket": "fields: tokens int, maxTokens int, refillRate time.Duration, lastRefill time.Time, mutex sync.Mutex",
    "ThrottleLevel": "enumeration of throttling intensity levels",
    "PublisherState": "publisher configuration and current throttle state",
    "LagMonitor": "component tracking consumer lag measurements",
    "ThrottleManager": "component implementing throttling strategies",
    "SystemMetrics": "comprehensive system health metrics",
    "BackpressureConfig": "configuration for thresholds and strategies",
    "DLQManager": "fields: storage DLQStorage, topicManager TopicManagerInterface, ackTracker AckTrackerInterface, progressTracker *ReplayProgressTracker, retentionPolicy *DLQRetentionPolicy, metrics *DLQMetrics, config *DLQConfig, shutdownCh chan struct{}, wg sync.WaitGroup",
    "DLQMessage": "fields: ID string, OriginalMessage *Message, FailureReason string, DeliveryHistory []DeliveryAttempt, ReceivedAt time.Time, LastAttempt time.Time, FailureCount int, OriginalTopic string, SourceConsumerGroup string, RetentionUntil time.Time",
    "ReplayResult": "fields: TotalRequested int, SuccessfulReplays int, FailedReplays []ReplayFailure, ReplayID string, StartedAt time.Time, CompletedAt *time.Time",
    "ReplayFailure": "fields: MessageID string, FailureReason string, RetryableError bool",
    "DLQStatistics": "fields: TotalMessages int64, MessagesByTopic map[string]int64, MessagesByFailureReason map[string]int64, OldestMessage *time.Time, DiskSpaceUsed int64, RetentionExpiredCount int64",
    "PurgeFilter": "fields: TopicPattern string, OlderThan time.Time, FailureReasonPattern string, MaxCount int, DryRun bool",
    "ReplayFilter": "fields: TopicPattern string, NewerThan time.Time, OlderThan time.Time, FailureReasonPattern string, ConsumerGroupFilter string, OrderBy ReplayOrdering",
    "ReplayPlan": "fields: Messages []*DLQMessage, EstimatedDuration time.Duration, Dependencies []ReplayDependency, ReplayOrder ReplayOrdering, Warnings []string",
    "SQLiteStorage": "fields: db *sql.DB, mutex sync.RWMutex",
    "ReplayProgressTracker": "fields: walLogger WALLogger, mutex sync.RWMutex, activeReplays map[string]*ReplayProgress",
    "ReplayProgress": "fields: ReplayID string, StartedAt time.Time, TotalMessages int, CompletedBatches int, LastCheckpoint time.Time, MessageIDs []string, TargetTopic string, Status ReplayStatus, ErrorMessage string",
    "MetricsCollector": "fields: series map[string]*TimeSeries, mutex sync.RWMutex, retention map[string]time.Duration, aggregationTicker *time.Ticker, persistenceTicker *time.Ticker, shutdownCh chan struct{}",
    "TimeSeries": "fields: points []DataPoint, capacity int, retention time.Duration, aggregated map[time.Time]DataPoint, mutex sync.RWMutex",
    "APIServer": "fields: router *mux.Router, broker *MessageBroker, auth *TokenAuthenticator, rateLimiter *RateLimiter, topicManager TopicManagerInterface, groupCoordinator GroupCoordinatorInterface, metricsCollector *MetricsCollector, healthTracker *HeartbeatTracker",
    "RateLimiter": "fields: buckets map[string]*TokenBucket, mutex sync.RWMutex, defaultReadRate time.Duration, defaultWriteRate time.Duration",
    "DataPoint": "fields: Value float64, Timestamp int64, Tags map[string]string",
    "ConsumerStatus": "fields: status information for consumer health tracking",
    "FlowCoordinator": "fields: topicManager TopicManagerInterface, groupCoordinator GroupCoordinatorInterface, ackTracker AckTrackerInterface, walLogger WALLogger, metrics *MetricsCollector",
    "ConsistencyError": "state validation error information",
    "RebalanceTrigger": "enumeration of rebalancing trigger events",
    "FlowIntegrationTest": "integration testing utilities",
    "FlowTracing": "observability and monitoring context",
    "SystemHealth": "fields: Status HealthStatus, LastCheck time.Time, ComponentHealth map[string]ComponentHealth, Recommendations []string, UptimeSeconds int64",
    "ComponentHealth": "fields: Status HealthStatus, LastCheck time.Time, ErrorCount int64, Latency time.Duration, Message string",
    "TimeoutConfig": "fields: ConnectionHeartbeat time.Duration, MessageAck time.Duration, ProcessingTimeout time.Duration, RebalanceTimeout time.Duration, HealthCheck time.Duration, AdaptiveEnabled bool, MinTimeout time.Duration, MaxTimeout time.Duration",
    "FailureClassifier": "fields: patterns map[string]FailurePattern, mutex sync.RWMutex",
    "FailurePattern": "fields: Type FailureType, Severity FailureSeverity, Recovery RecoveryStrategy, Retryable bool",
    "CircuitBreaker": "fields: maxFailures int, resetTimeout time.Duration, currentState CircuitState, failureCount int, lastFailureTime time.Time, mutex sync.RWMutex",
    "AutoHealer": "fields: classifier *FailureClassifier, recoveryStrategies map[RecoveryStrategy]RecoveryHandler, backoffStrategy BackoffStrategy, maxRetries int, retryState map[string]*RetryState, mutex sync.RWMutex",
    "DegradationManager": "fields: currentLevel DegradationLevel, thresholds map[string]float64, functions map[string]bool, resourceMonitor ResourceMonitor, transitionDelay time.Duration, mutex sync.RWMutex",
    "MockTimeProvider": "test utility for controlling time flow",
    "MockWALLogger": "test utility for recording WAL operations",
    "ChaosScenario": "chaos testing scenario definition",
    "FailureEvent": "single failure injection event",
    "FailureInjector": "chaos testing coordination component",
    "ScenarioResult": "chaos testing outcome data",
    "HealthStatus": "component health state information",
    "ActiveFailure": "currently active failure injection",
    "FailureTarget": "component that can have failures injected",
    "Logger": "fields: output io.Writer, level LogLevel",
    "LogEntry": "fields: Timestamp time.Time, Level string, Component string, EventType string, CorrelationID string, Message string, Details map[string]interface{}",
    "AdminAPI": "fields: topicManager TopicManagerInterface, groupCoordinator GroupCoordinatorInterface, ackTracker AckTrackerInterface",
    "ProtocolTracer": "fields: enabled bool, logger *Logger",
    "PerformanceProfiler": "fields: metrics *MetricsCollector, logger *Logger",
    "TopicManagerInterface": "interface for topic operations",
    "GroupCoordinatorInterface": "interface for consumer group operations",
    "AckTrackerInterface": "interface for acknowledgment tracking",
    "ClusterCoordinator": "fields: nodeID string, raftNode *raft.Raft, topology *ClusterTopology, partitionMgr *PartitionManager",
    "PartitionManager": "fields: partitions map[string]*PartitionReplica, assignments map[string][]string, localNode string, clusterTopo *ClusterTopology",
    "ReplicationEngine": "fields: streams map[string]*ReplicationStream, followers map[string]*FollowerState",
    "ClientRouter": "fields: topology *ClusterTopology, connections map[string]*Connection",
    "ConsensusModule": "fields: raftNode *raft.Raft, stateMachine StateMachine",
    "MessageFilter": "fields: Expression string, CompiledFilter *CompiledFilterExpression, FilterType FilterType",
    "ContentRouter": "fields: topicManager *TopicManager, filterEvaluator *FilterEvaluator, subscriptions map[string][]*ContentSubscription",
    "ExchangeManager": "fields: exchanges map[string]ExchangeType, routingRules map[string]*RoutingRule",
    "TransformationPipeline": "fields: stages []*TransformationStage, context TransformContext",
    "BatchProcessor": "fields: strategy BatchingStrategy, currentBatch *MessageBatch, flushTimer *time.Timer, walLogger WALLogger",
    "CompressionManager": "fields: algorithms map[string]CompressionAlgorithm, selector *CompressionSelector, dictionaries map[string][]byte",
    "ZeroCopyEngine": "fields: bufferPool *sync.Pool, mmapFiles map[string][]byte, directBuffers map[*Connection][]byte",
    "Extension": "interface for pluggable system enhancements",
    "ExtensionRegistry": "fields: extensions map[string]Extension, broker core.BrokerInterface, logger *Logger",
    "ClusterTopology": "fields: Nodes []*BrokerNode, Partitions map[string]*PartitionInfo",
    "MessageBatch": "fields: Messages []*Message, TotalSize int64, CreatedAt time.Time",
    "BatchingStrategy": "enumeration of batching trigger types",
    "CompressionAlgorithm": "interface for compression implementations",
    "FilterEvaluator": "fields: headerFilters map[string]*HeaderFilterSet, payloadFilters []*PayloadFilterExpression, cache map[string]bool",
    "BenchmarkSuite": "fields: brokerAddr string, testDuration time.Duration, messageSize int, producerCount int, consumerCount int, results *BenchmarkResults"
  },
  "methods": {
    "PUBLISH": "send message to topic",
    "SUBSCRIBE": "register for topic messages",
    "ACK": "acknowledge message receipt",
    "NACK": "negative acknowledgment",
    "JOIN_GROUP": "join consumer group",
    "NewMessage(topic, payload, producerID, headers)": "creates validated message with unique ID",
    "EnqueueMessage(msg) error": "adds message to topic queue with retention checks",
    "AssignNextMessage(msg) (*Consumer, error)": "assigns message to available consumer using group strategy",
    "AppendRecord(recordType, data) (int64, error)": "writes record to WAL with durability guarantees",
    "TransitionTo(newState, event) error": "validates and executes message state transition",
    "PUBLISH(topic, payload, headers)": "send message to topic",
    "SUBSCRIBE(pattern, group, maxInflight)": "register for topic messages",
    "ACK(messageID)": "acknowledge message receipt",
    "NACK(messageID, reason)": "negative acknowledgment",
    "ReadFrame() (*FrameHeader, []byte, error)": "reads one complete frame from connection",
    "WriteFrame(frameType, payload) error": "sends complete frame atomically",
    "ProcessPublishCommand(conn, payload) error": "handles PUBLISH frame from client",
    "ProcessSubscribeCommand(conn, payload) error": "handles SUBSCRIBE frame from client",
    "CreateTopic(name, retentionPolicy) error": "creates new topic with retention rules",
    "PublishMessage(msg) error": "delivers message to all topic subscribers",
    "Subscribe(consumerID, pattern, conn) error": "registers consumer for topic pattern",
    "Unsubscribe(consumerID, pattern) error": "removes consumer subscription",
    "findWildcardMatches(topicName) []*Consumer": "finds wildcard subscribers for topic",
    "matchPattern(pattern, segments) bool": "tests wildcard pattern against topic",
    "performCleanup()": "background cleanup of unused topics",
    "JoinGroup(groupName, consumerID, conn) error": "adds consumer to group and triggers rebalancing",
    "LeaveGroup(groupName, consumerID) error": "removes consumer from group",
    "AssignMessage(msg, groupName) (*Consumer, error)": "selects consumer for message delivery",
    "TriggerRebalance(groupName, reason) error": "initiates rebalancing process",
    "ProcessHeartbeat(groupName, consumerID) error": "updates consumer heartbeat",
    "GetDeadConsumers(groupName) []string": "returns consumers exceeding heartbeat TTL",
    "OnRebalance(group, newMembers) error": "recalculates assignments during membership changes",
    "TrackMessage(msg *Message, consumerID string, deadline time.Time) error": "registers message for acknowledgment tracking",
    "ProcessAck(messageID string, consumerID string) error": "handles successful acknowledgment",
    "ProcessNack(messageID string, consumerID string, reason string) error": "handles negative acknowledgment",
    "CheckTimeouts(currentTime time.Time) []Message": "scans for timed-out messages",
    "GetConsumerLoad(consumerID string) ConsumerLoadInfo": "returns consumer performance metrics",
    "CleanupConsumer(consumerID string) []Message": "removes consumer and returns pending messages",
    "GetPendingCount(consumerID string) int": "returns unacknowledged message count",
    "UpdateDeliveryStatus(messageID string, status DeliveryStatus) error": "updates tracking status",
    "GetMessageHistory(messageID string) []DeliveryAttempt": "returns delivery attempt history",
    "ReadRecord(offset int64) (*WALRecord, error)": "retrieves specific record by offset",
    "ReadRange(startOffset, endOffset int64) ([]*WALRecord, error)": "reads multiple consecutive records",
    "CreateCheckpoint(metadata CheckpointMetadata) (string, error)": "creates state snapshot",
    "GetLatestCheckpoint() (*CheckpointMetadata, error)": "returns most recent checkpoint",
    "CompactLog(beforeOffset int64) error": "removes old log entries",
    "GetLogStats() (*LogStatistics, error)": "returns log size and metrics",
    "Close() error": "graceful shutdown with flush",
    "WriteRecord(recordType, data) (int64, error)": "atomic record writing",
    "ReadNextRecord() (*WALRecord, error)": "sequential record reading",
    "RecoverFromCrash() (*BrokerState, error)": "rebuilds state from WAL",
    "TriggerCompaction(retentionPolicy) error": "starts background compaction",
    "CheckCapacity(topicName, consumerGroupID) (CapacityStatus, error)": "evaluates current system capacity",
    "ApplyBackpressure(publisherID, throttleLevel) error": "applies throttling to specific publisher",
    "ReleaseBackpressure(publisherID) error": "removes throttling restrictions",
    "ProcessLagUpdate(update) error": "handles incoming lag measurements and triggers backpressure decisions",
    "Add(value) void": "adds measurement to circular buffer",
    "GetAverage() float64": "calculates average of stored measurements",
    "TryConsume(tokens) bool": "attempts to consume tokens from bucket for rate limiting",
    "SendToDLQ(msg *Message, reason string, deliveryHistory []DeliveryAttempt) error": "moves poison message to DLQ with failure context",
    "InspectMessage(dlqMessageID string) (*DLQMessage, error)": "retrieves DLQ message with metadata for inspection",
    "ListMessages(topicFilter string, limit int, offset int) ([]*DLQMessage, int, error)": "returns paginated DLQ messages with filtering",
    "ReplayMessage(dlqMessageID string, targetTopic string) error": "replays single DLQ message back to topic",
    "ReplayBatch(messageIDs []string, targetTopic string) (*ReplayResult, error)": "replays multiple messages atomically with ordering",
    "GetStatistics(topicFilter string) (*DLQStatistics, error)": "returns DLQ metrics and statistics",
    "PurgeMessages(criteria *PurgeFilter) (*PurgeResult, error)": "permanently removes DLQ messages matching criteria",
    "CreateReplayPlan(criteria *ReplayFilter) (*ReplayPlan, error)": "analyzes DLQ messages and creates replay strategy",
    "RecordMetric(name, value, tags) error": "adds data point to specified metric time series",
    "QueryMetrics(name, start, end) []DataPoint": "retrieves time series data for specified time range",
    "AddPoint(value, timestamp, tags)": "inserts new data point in chronological order",
    "AggregateOldData(bucketDuration)": "combines detailed points into coarser time buckets",
    "ProcessHeartbeat(consumerID, status) error": "updates heartbeat timestamp for consumer",
    "CheckForTimeouts() []string": "scans consumers and identifies unhealthy ones",
    "CleanupUnhealthyConsumer(consumerID) error": "removes failed consumer and reassigns work",
    "HandleTopicList(w, r)": "returns paginated list of topics with metrics",
    "HandleConsumerGroupDetail(w, r)": "returns detailed consumer group information",
    "CheckRateLimit(token, operation) (bool, time.Duration)": "verifies if request is within rate limits",
    "PublishFlow(ctx, msg) error": "orchestrates complete message publication sequence",
    "ConsumptionFlow(ctx, topicName, groupName) ([]*Message, error)": "handles message delivery through consumer group assignment",
    "RebalancingFlow(ctx, groupName, trigger) error": "coordinates consumer group rebalancing operations",
    "RecoveryFlow(ctx) (*BrokerState, error)": "handles complete system state reconstruction from WAL",
    "TrackMessage(msg, consumerID, deadline) error": "registers message for acknowledgment tracking",
    "ProcessAck(messageID, consumerID) error": "handles successful acknowledgment",
    "ProcessNack(messageID, consumerID, reason) error": "handles negative acknowledgment",
    "ValidateLogIntegrity() error": "checks WAL for corruption and structural issues",
    "AttemptRecovery(failure) error": "tries automatic recovery from detected failure",
    "EvaluateDegradationNeed() DegradationLevel": "assesses system state for degradation necessity",
    "TransitionToDegradationLevel(level) error": "safely changes degradation level",
    "Execute(fn) error": "runs function with circuit breaker protection",
    "ReadRecord(offset) (*WALRecord, error)": "retrieves specific record by offset",
    "CheckTimeouts(currentTime) []Message": "scans for timed-out messages",
    "SendToDLQ(msg, reason, history) error": "moves poison message to DLQ with failure context",
    "InspectMessage(dlqMessageID) (*DLQMessage, error)": "retrieves DLQ message with metadata for inspection",
    "ReplayMessage(dlqMessageID, targetTopic) error": "replays single DLQ message back to topic",
    "Now() time.Time": "returns current simulated time",
    "After(duration) <-chan time.Time": "creates timer that fires after duration",
    "AdvanceTime(duration)": "moves simulated time forward and fires timers",
    "SetFailureAt(offset, err)": "configures mock to fail at specific offset",
    "GetRecordCount() int": "returns number of records written",
    "InjectScenario(ctx, scenario) (*ScenarioResult, error)": "executes complete chaos testing scenario",
    "Log(ctx, level, component, eventType, message, details)": "writes structured log entry with correlation",
    "TraceFrameReceived(conn, frameType, payload)": "logs protocol frame reception details",
    "TraceFrameSent(conn, frameType, payload)": "logs protocol frame transmission details",
    "ProfileOperation(ctx, operation, fn) error": "measures and logs operation performance",
    "handleTopics(w, r)": "returns topic information via HTTP",
    "handleConsumerGroups(w, r)": "returns consumer group information via HTTP",
    "handlePendingMessages(w, r)": "returns pending message information via HTTP",
    "CollectRuntimeMetrics()": "gathers system resource usage statistics",
    "JoinCluster(seedNodes []string) (*ClusterMembership, error)": "connects broker to existing cluster",
    "CreatePartition(topicName, partitionID string, replicationFactor int) error": "sets up distributed partition with replicas",
    "ReplicatePartition(partitionID string, logEntries []*WALRecord) error": "synchronizes partition data across nodes",
    "CreateContentSubscription(consumerID, topicPattern, filter string) error": "registers consumer with message filtering",
    "EvaluateMessage(msg *Message, filter *MessageFilter) (bool, error)": "determines if message matches filter criteria",
    "CollectMessage(msg *Message) error": "adds message to batch, flushing if needed",
    "FlushBatch(batch *MessageBatch) error": "processes accumulated messages atomically",
    "CompressMessage(msg *Message) (*CompressedMessage, error)": "applies compression to message payload",
    "ProcessMessageZeroCopy(conn *Connection, frameData []byte) error": "handles message without copying",
    "LoadExtension(ext Extension) error": "registers and initializes extension",
    "RunThroughputBenchmark() *ThroughputResult": "measures maximum sustained throughput",
    "RunLatencyBenchmark() *LatencyResult": "measures end-to-end delivery latency",
    "HandleNodeJoin(joinRequest *JoinRequest) (*JoinResponse, error)": "processes new broker joining cluster",
    "EvaluateSubscriptions(msg *Message) ([]*Consumer, error)": "determines subscribers for content routing"
  },
  "constants": {
    "AMQP": "Advanced Message Queuing Protocol",
    "RESP": "Redis Serialization Protocol",
    "TCP": "Transmission Control Protocol",
    "ACK": "acknowledge message receipt",
    "NACK": "negative acknowledgment",
    "FIFO": "first in, first out message ordering",
    "WAL": "Write-Ahead Log for persistence",
    "DLQ": "Dead Letter Queue for poison messages",
    "HTTP": "HyperText Transfer Protocol",
    "JSON": "JavaScript Object Notation",
    "YAML": "YAML Ain't Markup Language",
    "StateCreated": "message accepted by broker",
    "StatePending": "message waiting for consumer assignment",
    "StateAssigned": "message delivered to specific consumer",
    "StateAcknowledged": "message successfully processed",
    "StateDeadLetter": "message exceeded retry limit",
    "StateDeleted": "message permanently removed",
    "RecordMessagePublished": "WAL record type for new messages",
    "RecordMessageAcked": "WAL record type for acknowledgments",
    "ProtocolMagic": "0x4D515545 protocol identifier",
    "ProtocolVersion": "1 current protocol version",
    "MaxFrameSize": "10MB maximum frame size",
    "HeaderSize": "12 bytes fixed header size",
    "FramePublish": "1 PUBLISH command type",
    "FrameSubscribe": "2 SUBSCRIBE command type",
    "FrameAck": "3 ACK command type",
    "FrameNack": "4 NACK command type",
    "StatusSuccess": "0 success response code",
    "StatusTopicNotFound": "1 topic not found error",
    "PUBLISH": "send message to topic command",
    "SUBSCRIBE": "register for topic messages command",
    "round-robin": "assignment strategy distributing messages sequentially",
    "sticky": "assignment strategy minimizing reassignment during rebalancing",
    "DeliveryPending": "message awaiting acknowledgment",
    "DeliveryAcked": "message successfully acknowledged",
    "DeliveryNacked": "message negatively acknowledged",
    "DeliveryTimedOut": "message exceeded deadline",
    "DeliveryReassigned": "message reassigned to different consumer",
    "RecordMessageNacked": "WAL record type for negative acknowledgments",
    "RecordConsumerJoined": "WAL record type for group membership",
    "RecordConsumerLeft": "WAL record type for consumer departure",
    "RecordTopicCreated": "WAL record type for topic creation",
    "RecordCheckpointCreated": "WAL record type for snapshots",
    "fsync": "force disk synchronization",
    "Normal": "healthy capacity state",
    "Warning": "elevated lag but manageable",
    "Critical": "significant lag requiring intervention",
    "Overloaded": "system capacity exceeded",
    "NoAction": "no throttling needed",
    "LightThrottle": "minimal throttling intervention",
    "ModerateThrottle": "moderate throttling intervention",
    "HeavyThrottle": "aggressive throttling intervention",
    "Increasing": "lag trend getting worse",
    "Stable": "lag trend relatively constant",
    "Decreasing": "lag trend improving",
    "ReplayStatusPending": "replay operation is queued",
    "ReplayStatusRunning": "replay operation is executing",
    "ReplayStatusCompleted": "replay operation finished successfully",
    "ReplayStatusFailed": "replay operation encountered errors",
    "ReplayStatusAborted": "replay operation was cancelled",
    "REST": "Representational State Transfer",
    "HealthHealthy": "healthy system status",
    "HealthDegraded": "degraded system status",
    "HealthCritical": "critical system status",
    "FailureTypeNetwork": "network-related failure",
    "FailureTypeConsumer": "consumer process failure",
    "FailureTypeBroker": "broker system failure",
    "FailureTypeStorage": "storage/persistence failure",
    "SeverityLow": "low severity failure",
    "SeverityMedium": "medium severity failure",
    "SeverityHigh": "high severity failure",
    "SeverityCritical": "critical severity failure",
    "RecoveryReconnect": "reconnect recovery strategy",
    "RecoveryReassign": "message reassignment strategy",
    "RecoveryRestart": "process restart strategy",
    "RecoveryDegrade": "graceful degradation strategy",
    "CircuitClosed": "circuit breaker closed state",
    "CircuitOpen": "circuit breaker open state",
    "CircuitHalfOpen": "circuit breaker half-open state",
    "DEBUG": "debug log level",
    "INFO": "info log level",
    "WARN": "warning log level",
    "ERROR": "error log level",
    "DirectExchange": "exact routing key match exchange type",
    "TopicExchange": "wildcard pattern matching exchange type",
    "FanoutExchange": "broadcast to all bound queues exchange type",
    "HeadersExchange": "route based on message headers exchange type",
    "TimeBatching": "collect messages for fixed time window",
    "SizeBatching": "batch when size reaches threshold",
    "CountBatching": "batch when message count reaches limit",
    "AdaptiveBatching": "dynamic adjustment based on load",
    "MessageCompression": "individual message payload compression",
    "BatchCompression": "entire message batch compression",
    "LogCompression": "WAL file segment compression",
    "FilterTypeHeader": "filter based on message headers",
    "FilterTypePayload": "filter based on message payload",
    "FilterTypeComposite": "filter combining multiple conditions"
  },
  "terms": {
    "fan-out": "delivering one message to multiple subscribers",
    "temporal decoupling": "sender and receiver don't need to be online simultaneously",
    "spatial decoupling": "components don't need to know each other's location",
    "synchronization decoupling": "sender doesn't wait for receiver processing",
    "at-least-once delivery": "messages delivered one or more times with acknowledgment required",
    "at-most-once delivery": "messages delivered zero or one times",
    "exactly-once delivery": "messages delivered exactly one time",
    "horizontal scaling": "adding more broker nodes to handle increased load",
    "backpressure": "flow control mechanism for slow consumers",
    "dead letter queue": "destination for undeliverable messages",
    "consumer group rebalancing": "redistributing work when group membership changes",
    "scope creep": "uncontrolled expansion of project requirements",
    "wire protocol": "binary communication format between client and broker",
    "message framing": "technique for preserving message boundaries over TCP streams",
    "length-prefixed framing": "frame format with header containing payload size",
    "protocol multiplexing": "multiple operations on single connection",
    "partial TCP reads": "TCP delivering data in smaller chunks than requested",
    "frame boundary detection": "determining message boundaries in TCP stream",
    "connection cleanup": "removing state when client disconnects",
    "heartbeat": "periodic messages to detect connection failures",
    "wildcard subscription": "pattern-based topic subscription",
    "topic auto-creation": "automatic topic creation on first publish",
    "subscription indexing": "optimized lookup for wildcard patterns",
    "hierarchical topic naming": "path-like topic organization with slashes",
    "round-robin": "sequential distribution across available consumers",
    "sticky assignment": "minimizing reassignment during rebalancing",
    "generation number": "version counter preventing split-brain during rebalancing",
    "inflight messages": "messages delivered but not yet acknowledged",
    "assignment strategy": "algorithm determining how messages are distributed",
    "rebalance generation": "version number for coordinating membership changes",
    "thundering herd": "sudden traffic spike overwhelming recovering system",
    "poison message": "message that consistently causes processing failures",
    "head-of-line blocking": "slow message preventing processing of subsequent messages",
    "temporal safety": "explicit deadlines for all tracked operations",
    "exponential backoff": "increasing delay between retry attempts",
    "certified mail": "postal analogy for acknowledgment tracking",
    "redelivery": "reassigning message after processing failure",
    "acknowledgment deadline": "timeout for consumer to confirm processing",
    "append-only log": "log structure that only adds new entries never modifies existing ones",
    "Write-Ahead Log": "persistence mechanism recording operations before execution",
    "crash recovery": "process of rebuilding state after broker restart",
    "log compaction": "removing obsolete records to reclaim storage space",
    "checkpoint": "snapshot of broker state enabling faster recovery",
    "fsync": "file system operation forcing data to disk",
    "state consolidation": "combining multiple records into final state representation",
    "durability guarantees": "assurance that acknowledged operations survive crashes",
    "corruption detection": "validation mechanisms for identifying damaged records",
    "atomic log replacement": "safe substitution of compacted log files",
    "consumer lag": "time delay between message publication and processing",
    "throttling": "artificially limiting publisher throughput",
    "capacity status": "current health assessment of topic-consumer group combination",
    "lag monitoring": "continuous tracking of consumer performance metrics",
    "token bucket": "rate limiting algorithm using refillable token pool",
    "cascading failures": "failures that propagate through system components",
    "hysteresis": "different thresholds for activation vs deactivation",
    "poison messages": "messages that consistently cause processing failures",
    "replay transaction": "atomic operation for reintroducing DLQ messages",
    "dependency analysis": "identifying ordering relationships between messages",
    "retention-based lifecycle": "automatic expiration of old DLQ messages",
    "replay verification": "monitoring success of replayed message processing",
    "checkpoint-based replay": "resumable replay with intermediate progress saves",
    "rate limiting": "artificially limiting request throughput",
    "time-series database": "database optimized for chronological data",
    "aggregation": "combining multiple data points into summary statistics",
    "administrative API": "HTTP endpoints for inspecting system state",
    "health check": "active verification of component functionality",
    "metrics collection": "gathering performance and health measurements",
    "Write-Before-Deliver Consistency": "fundamental principle that persistence precedes delivery",
    "component responsibility isolation": "clear ownership boundaries preventing coordination complexity",
    "explicit state transition protocols": "clear handoff protocols with ownership transfer points",
    "orphaned messages": "messages delivered but never acknowledged before crash",
    "checkpoint-based recovery": "using state snapshots to accelerate recovery",
    "coordination patterns": "systematic approaches to multi-component collaboration",
    "failure isolation": "preventing failures in one component from cascading to others",
    "temporal consistency": "applying operations in strict chronological order",
    "conservative consistency resolution": "preferring data preservation over operational efficiency",
    "stabilization delay": "waiting period to batch multiple membership changes",
    "drain timeout": "maximum time to wait for pending message acknowledgments",
    "assignment freeze": "pausing new message assignments during rebalancing",
    "split-brain prevention": "ensuring consistent state during coordination failures",
    "graceful degradation": "reduced functionality operation during failures",
    "circuit breaker": "failure isolation pattern preventing cascading failures",
    "heartbeat monitoring": "active liveness detection for system components",
    "automatic healing": "self-recovery mechanisms without manual intervention",
    "failure classification": "categorizing failures for appropriate response",
    "consistency resolution": "restoring coherent state after failures",
    "backoff strategy": "progressive delay between retry attempts",
    "timeout detection": "failure detection based on operation duration limits",
    "unit testing": "testing individual components in isolation with mocked dependencies",
    "integration testing": "testing component interactions with real implementations",
    "chaos testing": "deliberate failure injection to test resilience",
    "mock objects": "test doubles that simulate dependency behavior",
    "dependency injection": "providing dependencies through constructor parameters",
    "behavioral contracts": "interfaces defining component interaction patterns",
    "time-controlled mocks": "test utilities that allow deterministic time simulation",
    "state-recording mocks": "test utilities that capture interactions for verification",
    "failure-injection mocks": "test utilities that can simulate specific error conditions",
    "test data builders": "utilities for creating valid test objects with targeted modifications",
    "milestone verification": "testing that milestone requirements are actually met",
    "end-to-end testing": "complete system testing from producer to consumer",
    "component coordination patterns": "systematic approaches to multi-component collaboration",
    "persistence-before-delivery": "pattern ensuring durability before confirmation",
    "coordination-with-timeout": "pattern handling multi-component operations with failure detection",
    "state-handoff pattern": "pattern managing ownership transfer between components",
    "crash recovery consistency": "maintaining data integrity across unexpected shutdowns",
    "rebalancing consistency": "maintaining group state coherence during membership changes",
    "network partition": "failure scenario where components cannot communicate",
    "cascading failure": "failure propagation through system components",
    "temporal failure injection": "injecting failures at specific timing windows",
    "recovery verification": "testing that recovery mechanisms work correctly",
    "failure orchestration": "coordinating complex multi-component failure scenarios",
    "system state monitoring": "capturing detailed state during failure scenarios",
    "failure blast radius": "scope of impact from a single failure",
    "structured logging": "consistent JSON log format with correlation IDs",
    "protocol tracing": "low-level debugging of wire protocol frames",
    "correlation ID": "unique identifier for tracking operations across components",
    "performance profiling": "measuring operation timing and resource usage",
    "state inspection": "examining runtime system state for debugging",
    "resource leak": "gradual consumption of system resources without cleanup",
    "ghost consumers": "disconnected consumers still assigned messages",
    "leader-follower replication": "one leader handles writes, followers maintain synchronized copies",
    "partition-based scaling": "dividing topics into independent partitions for parallel processing",
    "consensus algorithm": "protocol ensuring all cluster nodes agree on decisions",
    "content-based routing": "message delivery based on payload content or headers",
    "exchange types": "pluggable routing algorithms for different messaging patterns",
    "message transformation": "modifying message content during routing",
    "zero-copy optimization": "eliminating unnecessary memory copying operations",
    "pipeline parallelism": "overlapping processing stages for higher throughput",
    "memory-mapped files": "mapping files directly into process memory space",
    "append-only replication": "synchronizing write-ahead logs between cluster nodes",
    "replay": "process of reintroducing DLQ messages back into normal processing flow",
    "batching": "processing multiple messages together as a unit",
    "retention policy": "rules for message lifecycle management including time and size limits"
  }
}