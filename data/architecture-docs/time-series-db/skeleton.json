{
  "title": "TempoDB: A Modern Time-Series Database - Design Document",
  "overview": "This document outlines the design of TempoDB, a specialized database for storing and querying high-volume, timestamped data. It solves the core architectural challenge of achieving high write throughput for sequential data while enabling efficient range queries and compressing massive datasets with predictable patterns, making it essential for metrics, IoT, and financial applications.",
  "sections": [
    {
      "id": "context-problem",
      "title": "Context and Problem Statement",
      "summary": "Explains why time-series data is unique and challenging, comparing it to traditional databases. Introduces existing approaches and their trade-offs.",
      "subsections": [
        {
          "id": "mental-model",
          "title": "Mental Model: The Data Stream Conveyor Belt",
          "summary": "Frames time-series data as a high-speed conveyor belt of timestamped items. We must label, sort, compress, and archive items efficiently as they move from hot (recent) to cold (historical) storage."
        },
        {
          "id": "existing-approaches",
          "title": "Existing Approaches and Comparison",
          "summary": "Compares the characteristics and trade-offs of using generic databases (e.g., Postgres) vs. specialized time-series databases like InfluxDB and TimescaleDB."
        }
      ]
    },
    {
      "id": "goals-non-goals",
      "title": "Goals and Non-Goals",
      "summary": "Defines the core capabilities TempoDB must deliver and explicitly states what is out of scope for this educational project.",
      "subsections": [
        {
          "id": "goals-list",
          "title": "Goals",
          "summary": "Lists functional and non-functional requirements like high write throughput, compression, range queries, and downsampling."
        },
        {
          "id": "non-goals-list",
          "title": "Non-Goals",
          "summary": "Explicitly excludes features like horizontal scaling, full SQL support, ACID transactions, and advanced security to keep the project focused."
        }
      ]
    },
    {
      "id": "high-level-architecture",
      "title": "High-Level Architecture",
      "summary": "Presents the major components of TempoDB and how they interact. Introduces the core architectural pattern of separating the write-optimized memtable from read-optimized storage files.",
      "subsections": [
        {
          "id": "component-overview",
          "title": "Component Overview and Responsibilities",
          "summary": "Describes the role of each major component: Ingest API, Write-Ahead Log (WAL), Memtable, Storage Engine (TSM), Query Engine, and Compactor."
        },
        {
          "id": "file-structure",
          "title": "Recommended File/Module Structure",
          "summary": "Provides a suggested Go module layout to organize the codebase, separating concerns like API, storage, query, and utilities."
        }
      ]
    },
    {
      "id": "data-model",
      "title": "Data Model",
      "summary": "Defines the fundamental structures for representing a time series, including points, series keys, and the organization of data on disk. Links concepts to implementation types.",
      "subsections": [
        {
          "id": "core-concepts",
          "title": "Core Concepts: Measurement, Tags, Field",
          "summary": "Explains the InfluxDB-like data model: a measurement is a container, tags are indexed metadata, and fields are the actual values being tracked."
        },
        {
          "id": "type-definitions",
          "title": "Type Definitions and Relationships",
          "summary": "Describes key types like `DataPoint`, `SeriesKey`, `TSMBlock`, and their relationships using tables and a diagram."
        }
      ]
    },
    {
      "id": "storage-engine",
      "title": "Storage Engine Design",
      "summary": "Details the design of the Time-Structured Merge (TSM) tree storage engine, focusing on columnar layout, block-based storage, and compression algorithms.",
      "subsections": [
        {
          "id": "mental-model-storage",
          "title": "Mental Model: The Time-Indexed Filing Cabinet",
          "summary": "Compares the TSM engine to a filing cabinet where documents (data blocks) are filed by time range, and within each document, timestamps and values are stored in separate columns for fast access."
        },
        {
          "id": "tsm-format",
          "title": "TSM File Format and Block Layout",
          "summary": "Describes the on-disk structure of a TSM file, including the header, indexed data blocks for series, and the footer with a summary index."
        },
        {
          "id": "compression-adr",
          "title": "ADR: Choosing Compression Algorithms",
          "summary": "Architecture Decision Record for selecting Delta-of-Delta for timestamps and Gorilla XOR for floating-point values, versus other options like Snappy or simple delta encoding."
        },
        {
          "id": "implementation-guidance-storage",
          "title": "Implementation Guidance (Milestone 1)",
          "summary": "Provides Go-specific guidance, starter code for memory-mapped file access, and skeleton code for the TSM writer/reader and compression logic."
        }
      ]
    },
    {
      "id": "write-path",
      "title": "Write Path Design",
      "summary": "Explains the journey of a data point from ingestion to durable storage, covering buffering, durability via WAL, and flushing to TSM files.",
      "subsections": [
        {
          "id": "mental-model-write",
          "title": "Mental Model: The Airport Check-in and Baggage System",
          "summary": "Compares write ingestion to an airport check-in: points are checked (validated), a receipt is issued (WAL), luggage is briefly stored (memtable), and then loaded onto the plane (TSM file) in batches."
        },
        {
          "id": "wal-memtable",
          "title": "Write-Ahead Log and Memtable",
          "summary": "Details the purpose and format of the WAL, and the in-memory structure (sorted map or skip list) used for the memtable."
        },
        {
          "id": "flush-mechanism",
          "title": "Flush Mechanism and Out-of-Order Writes",
          "summary": "Describes the conditions triggering a memtable flush and the strategy for handling late-arriving data points."
        },
        {
          "id": "implementation-guidance-write",
          "title": "Implementation Guidance (Milestone 2)",
          "summary": "Provides starter code for a WAL segment file, skeleton code for the ingest API and memtable flush logic, and tips for handling backpressure."
        }
      ]
    },
    {
      "id": "query-engine",
      "title": "Query Engine Design",
      "summary": "Describes how queries are parsed, planned, and executed, focusing on pushing predicates down to the storage layer and performing aggregations efficiently.",
      "subsections": [
        {
          "id": "mental-model-query",
          "title": "Mental Model: The Library Research Assistant",
          "summary": "Frames the query engine as a research assistant who first consults the card catalog (index) to find relevant books (TSM files), then only photocopies the necessary pages (blocks), and finally summarizes the information (aggregation) before presenting it."
        },
        {
          "id": "query-execution",
          "title": "Query Parsing, Planning, and Execution",
          "summary": "Outlines the stages of query processing: parsing the language, creating a plan with predicate pushdown, executing the scan, and streaming results."
        },
        {
          "id": "aggregations-downsampling",
          "title": "Aggregations and Downsampling",
          "summary": "Explains how built-in aggregates (sum, avg) and GROUP BY time() queries work, including the mechanics of tumbling windows."
        },
        {
          "id": "implementation-guidance-query",
          "title": "Implementation Guidance (Milestone 3)",
          "summary": "Provides skeleton code for a query parser, plan executor, and iterator pattern for scanning TSM files, plus hints for optimizing range scans."
        }
      ]
    },
    {
      "id": "retention-compaction",
      "title": "Retention and Compaction Design",
      "summary": "Covers the background processes that manage data lifecycle: deleting old data, merging small files, and pre-computing rollups for performance.",
      "subsections": [
        {
          "id": "mental-model-compaction",
          "title": "Mental Model: The Warehouse Archivist",
          "summary": "Compares the compactor to a warehouse archivist who regularly cleans out old boxes (TTL), consolidates half-full boxes into full ones (compaction), and creates summary catalogs for old records (downsampling/rollups)."
        },
        {
          "id": "ttl-compaction",
          "title": "TTL Enforcement and Compaction Strategy",
          "summary": "Details how time-to-live is enforced by deleting whole TSM files and explains a level-based compaction strategy to merge files."
        },
        {
          "id": "rollups-adr",
          "title": "ADR: Continuous vs Scheduled Downsampling",
          "summary": "Architecture Decision Record comparing continuous rollup generation during compaction versus a scheduled job, choosing continuous for simplicity in this design."
        },
        {
          "id": "implementation-guidance-retention",
          "title": "Implementation Guidance (Milestone 4)",
          "summary": "Provides starter code for a background job scheduler, skeleton code for the TTL sweeper and compaction planner logic."
        }
      ]
    },
    {
      "id": "query-language-api",
      "title": "Query Language and API Design",
      "summary": "Specifies the external interfaces for writing data and executing queries, including a custom query language and compatibility with industry standards.",
      "subsections": [
        {
          "id": "mental-model-api",
          "title": "Mental Model: The Restaurant Menu and Kitchen Window",
          "summary": "The API is the menu customers (clients) order from. The query language is the specific recipe instructions sent to the kitchen (database). The results are served back on a plate (HTTP/GRPC response)."
        },
        {
          "id": "query-language-spec",
          "title": "Query Language Specification",
          "summary": "Defines the grammar for the SQL-like query language, supporting SELECT, FROM, WHERE (time and tag filters), and GROUP BY time()."
        },
        {
          "id": "apis",
          "title": "Write and Read APIs",
          "summary": "Describes the HTTP endpoints for writing data (using InfluxDB line protocol) and executing queries, including Prometheus remote read/write support."
        },
        {
          "id": "implementation-guidance-api",
          "title": "Implementation Guidance (Milestone 5)",
          "summary": "Provides starter code for HTTP server routing and line protocol parsing, and skeleton code for the query language parser and API handlers."
        }
      ]
    },
    {
      "id": "interactions-data-flow",
      "title": "Interactions and Data Flow",
      "summary": "Walks through the sequence of operations for key user journeys: writing a point and executing a query, showing how components interact.",
      "subsections": [
        {
          "id": "write-flow",
          "title": "Write Path Sequence",
          "summary": "Step-by-step description and sequence diagram for a write operation, from API receipt to WAL and memtable."
        },
        {
          "id": "query-flow",
          "title": "Query Path Sequence",
          "summary": "Step-by-step description and sequence diagram for a query operation, from parsing to plan execution and result streaming."
        }
      ]
    },
    {
      "id": "error-handling-edge-cases",
      "title": "Error Handling and Edge Cases",
      "summary": "Documents anticipated failure modes, such as disk full, corrupt files, and malformed queries, and the system's recovery strategies.",
      "subsections": [
        {
          "id": "failure-modes",
          "title": "Common Failure Modes and Recovery",
          "summary": "Lists scenarios like write failures, corrupt WAL/TSM files, and query timeouts, with strategies for detection and remediation."
        },
        {
          "id": "edge-cases",
          "title": "Data-Specific Edge Cases",
          "summary": "Covers handling of out-of-order data, gaps in time series, clock skew, and queries with very large time ranges."
        }
      ]
    },
    {
      "id": "testing-strategy",
      "title": "Testing Strategy",
      "summary": "Outlines how to verify the correctness and performance of TempoDB, including unit tests, integration tests, and milestone checkpoints.",
      "subsections": [
        {
          "id": "test-approaches",
          "title": "Testing Approaches and Property Verification",
          "summary": "Recommends strategies like golden file tests for TSM format, property-based tests for compression, and fuzzing for the query parser."
        },
        {
          "id": "milestone-checkpoints",
          "title": "Milestone Verification Checkpoints",
          "summary": "For each of the five milestones, provides a command to run and the expected output/behavior to confirm successful implementation."
        }
      ]
    },
    {
      "id": "debugging-guide",
      "title": "Debugging Guide",
      "summary": "A practical guide for learners to diagnose and fix common implementation bugs, organized by symptom and component.",
      "subsections": [
        {
          "id": "symptom-table",
          "title": "Common Bug Symptoms and Fixes",
          "summary": "Table listing symptoms (e.g., 'Query returns no data for a valid time range'), likely causes (e.g., incorrect block index min/max), and steps to diagnose and fix."
        },
        {
          "id": "techniques-tools",
          "title": "Debugging Techniques and Tools",
          "summary": "Suggests techniques like adding detailed operation logs, writing inspection tools for TSM files/WAL, and using Go's pprof for performance issues."
        }
      ]
    },
    {
      "id": "future-extensions",
      "title": "Future Extensions",
      "summary": "Explores potential enhancements to the design, such as clustering, new compression algorithms, and advanced query functions.",
      "subsections": [
        {
          "id": "extensions-list",
          "title": "Possible Enhancements",
          "summary": "Lists ideas like distributed architecture, support for new data types, continuous queries, and tiered storage integration."
        }
      ]
    },
    {
      "id": "glossary",
      "title": "Glossary",
      "summary": "Defines key terms, acronyms, and domain-specific vocabulary used throughout the document.",
      "subsections": [
        {
          "id": "terms",
          "title": "Terminology Reference",
          "summary": "Table of terms like Cardinality, Downsampling, Memtable, TSM, WAL, with clear definitions and references to their first use."
        }
      ]
    }
  ],
  "diagrams": [
    {
      "id": "system-component",
      "title": "TempoDB High-Level System Architecture",
      "description": "Shows all major components (HTTP API, WAL, Memtable, Storage Engine, Query Engine, Compactor) and their interactions. Arrows indicate data flow for writes and reads.",
      "type": "component",
      "relevant_sections": [
        "high-level-architecture"
      ]
    },
    {
      "id": "data-model-relationships",
      "title": "Data Model: Core Types and Relationships",
      "description": "A class diagram showing key types: Database, Measurement, SeriesKey (composed of Measurement + Tags), DataPoint (timestamp, value), and TSMFile (contains multiple SeriesBlocks).",
      "type": "class",
      "relevant_sections": [
        "data-model"
      ]
    },
    {
      "id": "write-path-sequence",
      "title": "Sequence Diagram: Write Path",
      "description": "Sequence diagram showing the flow of a write request from Client -> HTTP API -> WAL (log) -> Memtable (in-memory) -> eventual flush to Storage Engine (TSM file). Includes acknowledgment back to client.",
      "type": "sequence",
      "relevant_sections": [
        "write-path",
        "interactions-data-flow"
      ]
    },
    {
      "id": "query-path-sequence",
      "title": "Sequence Diagram: Query Path",
      "description": "Sequence diagram showing the flow of a query request: Client -> HTTP API -> Query Parser -> Query Planner -> Storage Engine (scan multiple TSM files) -> Aggregate/Process -> Stream results back to Client.",
      "type": "sequence",
      "relevant_sections": [
        "query-engine",
        "interactions-data-flow"
      ]
    },
    {
      "id": "tsm-file-layout",
      "title": "TSM File Internal Layout",
      "description": "A detailed flowchart or block diagram showing the structure of a TSM file: Header, Series Block 1 (Series Key, Block 1 metadata+data, Block 2...), Series Block 2..., Index (map of Series Key to block offsets), Footer. Within a data block, show separate columns for compressed timestamps and values.",
      "type": "flowchart",
      "relevant_sections": [
        "storage-engine"
      ]
    },
    {
      "id": "compaction-state",
      "title": "Compaction Tier State Machine",
      "description": "A state machine diagram showing the lifecycle of a TSM file from 'Active' (being written to) to 'Level 0' -> 'Level 1' -> ... via compaction, and finally to 'Deleted' via TTL or 'Rollup' after downsampling.",
      "type": "state-machine",
      "relevant_sections": [
        "retention-compaction"
      ]
    },
    {
      "id": "memtable-flush-flow",
      "title": "Memtable Flush Decision Flowchart",
      "description": "Flowchart for the decision logic to flush a memtable: Check if memtable size > threshold OR if a periodic timer fires. If yes, mark current memtable as immutable, create new active memtable, and schedule a background write to convert immutable memtable to a TSM file.",
      "type": "flowchart",
      "relevant_sections": [
        "write-path"
      ]
    }
  ]
}