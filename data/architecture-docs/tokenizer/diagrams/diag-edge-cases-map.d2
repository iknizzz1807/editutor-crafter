direction: right
vars: {
  d2-config: {
    layout-engine: elk
    theme-id: 4
  }
}

# --- CLASSES ---
classes: {
  token_stream: {
    shape: sql_table
    style: {
      stroke: "#2c3e50"
      fill: "#f8f9fa"
    }
  }
  input_code: {
    style: {
      stroke-dash: 3
      fill: "#eef2f7"
      font-color: "#2980b9"
    }
  }
}

title: "Edge Case Gallery: Scanner Boundary Conditions" {
  shape: text
  near: top-center
  style: {
    font-size: 24
    bold: true
  }
}

# --- GRID LAYOUT FOR EDGE CASES ---
gallery: {
  grid-columns: 2
  grid-gap: 50

  # CASE 1: Empty Input
  empty_input: {
    label: "Case 01: Null Buffer (scanner.py)"
    
    in: |md
      c
      "" // Empty string
      
    | {class: input_code}
    
    out: {
      class: token_stream
      label: "Token List (Output)"
      row1: "0x00 | EOF | \"\" | L:1 C:1"
      label_bottom: "Total: 1 token | Boundary: Initial state"
    }
    
    in -> out: "scan_tokens()"
  }

  # CASE 2: Single Valid Character
  single_char: {
    label: "Case 02: Minimal Munch (scanner.py)"
    
    in: |md
      c
      "+"
      
    | {class: input_code}
    
    out: {
      class: token_stream
      label: "Token List (Output)"
      row1: "0x00 | OPERATOR | \"+\" | L:1 C:1"
      row2: "0x01 | EOF      | \"\"  | L:1 C:2"
      label_bottom: "Total: 2 tokens | Boundary: Immediate terminal"
    }
    
    in -> out: "advance() -> emit"
  }

  # CASE 3: Whitespace / Newline
  whitespace_only: {
    label: "Case 03: The Silent Consumer (scanner.py)"
    
    in: |md
      c
      " \t\n "
      
    | {class: input_code}
    
    out: {
      class: token_stream
      label: "Token List (Output)"
      row1: "0x00 | EOF | \"\" | L:2 C:2"
      label_bottom: "Total: 1 token | Boundary: Pos tracking drift check"
    }
    
    in -> out: "skip whitespace"
  }

  # CASE 4: Number terminating at EOF
  number_eof: {
    label: "Case 04: Numeric Sentinel (scanner.py)"
    
    in: |md
      c
      "42"
      
    | {class: input_code}
    
    out: {
      class: token_stream
      label: "Token List (Output)"
      row1: "0x00 | NUMBER | \"42\" | L:1 C:1"
      row2: "0x02 | EOF    | \"\"   | L:1 C:3"
      label_bottom: "Total: 2 tokens | Boundary: EOF as delimiter"
    }
    
    in -> out: "while(isdigit)"
  }

  # CASE 5: Unterminated Construct
  unterminated_str: {
    label: "Case 05: Mode Failure (scanner.py)"
    
    in: |md
      c
      "\"hi"
      
    | {class: input_code}
    
    out: {
      class: token_stream
      label: "Token List (Output)"
      row1: "0x00 | ERROR | \"\"hi\" | L:1 C:1"
      row2: "0x03 | EOF   | \"\"    | L:1 C:4"
      label_bottom: "Total: 2 tokens | Boundary: EOF during IN_STRING"
    }
    
    in -> out: "panic mode"
  }

  # CASE 6: Massive Identifier
  max_id: {
    label: "Case 06: Buffer Stress (scanner.py)"
    
    in: |md
      c
      "a...a" // 10k chars
      
    | {class: input_code}
    
    out: {
      class: token_stream
      label: "Token List (Output)"
      row1: "0x00 | IDENTIFIER | \"a\"*10000 | L:1 C:1"
      row2: "0x2710 | EOF     | \"\"        | L:1 C:10001"
      label_bottom: "Total: 2 tokens | Boundary: O(n) slice check"
    }
    
    in -> out: "maximal munch"
  }
}

# Documentation link
legend: {
  near: bottom-right
  shape: text
  label: "Implementation Note: All tokens carry 1-based (Line, Column) metadata.\nEOF always acts as a terminal sentinel for the downstream Parser."
}