direction: right
vars: {
  d2-config: {
    layout-engine: elk
    theme-id: 4
  }
}

# L0: Token Type Taxonomy (scanner.py)
# This map defines the vocabulary of the language.

tokenizer_enum: {
  shape: class
  label: "enum TokenType (scanner.py)"
  
  definition: |md
    python
    from enum import Enum, auto

    class TokenType(Enum):
        # Literals
        NUMBER     = auto()
        STRING     = auto()
        IDENTIFIER = auto()
        
        # Reserved Words
        KEYWORD    = auto() # if, else, while, etc.
        
        # Operators
        PLUS       = auto() # +
        MINUS      = auto() # -
        STAR       = auto() # *
        SLASH      = auto() # /
        ASSIGN     = auto() # =
        EQUAL      = auto() # ==
        NOT_EQUAL  = auto() # !=
        LESS       = auto() # <
        LESS_EQ    = auto() # <=
        GREATER    = auto() # >
        GREATER_EQ = auto() # >=
        BANG       = auto() # !

        # Punctuation
        LPAREN     = auto() # (
        RPAREN     = auto() # )
        LBRACE     = auto() # {
        RBRACE     = auto() # }
        LBRACKET   = auto() # [
        RBRACKET   = auto() # ]
        SEMICOLON  = auto() # ;
        COMMA      = auto() # ,

        # Sentinels
        EOF        = auto()
        ERROR      = auto()
    
  |
}

categories: {
  direction: right
  
  literals: {
    shape: sql_table
    label: "LITERALS"
    style.fill: "#dae8fc" # Blue: Data flow
    
    NUMBER: "Value: 42, 3.14"
    STRING: "Value: \"hello\""
    IDENTIFIER: "Value: user_var, _tmp"
  }

  keywords: {
    shape: sql_table
    label: "KEYWORDS (RESERVED)"
    style.fill: "#e1d5e7" # Purple: Metadata/Control
    
    IF: "if"
    ELSE: "else"
    WHILE: "while"
    RETURN: "return"
    BOOLEAN: "true, false"
    NULL: "null"
  }

  operators: {
    shape: sql_table
    label: "OPERATORS (EXPRESSIONS)"
    style.fill: "#f8cecc" # Red: Hot path / Logic
    
    ARITHMETIC: "+, -, *, /"
    ASSIGNMENT: "="
    EQUALITY: "==, !="
    RELATIONAL: "<, <=, >, >="
    LOGICAL: "!"
  }

  punctuation: {
    shape: sql_table
    label: "PUNCTUATION (STRUCTURAL)"
    style.fill: "#d5e8d4" # Green: Structural glue
    
    DELIMITERS: "(, ), {, }, [, ]"
    TERMINATORS: ";, ,"
  }

  special: {
    shape: sql_table
    label: "SPECIAL"
    style.fill: "#f5f5f5" # Gray: Meta/Sentinels
    
    EOF: "End of Input"
    ERROR: "Lexical Fault"
  }
}

tokenizer_enum -> categories: "categorizes into" {style.stroke-dash: 5}

# Constraints & Implementation Notes
notes: {
  shape: text
  near: bottom-center
  label: |md
    ### Implementation Standards
    1. **Strict Immutability**: `TokenType` members are unique integer constants via `auto()`.
    2. **Maximal Munch**: Operators like `==` take precedence over `=` during scan dispatch.
    3. **Lexeme Capture**: Every token must store the original raw source string.
  |
}