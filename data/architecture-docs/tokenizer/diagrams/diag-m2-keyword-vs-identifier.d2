direction: right
vars: {
  d2-config: {
    layout-engine: elk
    theme-id: 4
  }
}

# GLOBAL KEYWORD REGISTRY
keywords_table: {
  shape: sql_table
  label: "KEYWORDS (dict[str, TokenType])"
  
  "\"if\"": "TokenType.KEYWORD"
  "\"else\"": "TokenType.KEYWORD"
  "\"while\"": "TokenType.KEYWORD"
  "\"return\"": "TokenType.KEYWORD"
  "\"true\"": "TokenType.KEYWORD"
  "\"false\"": "TokenType.KEYWORD"
  "\"null\"": "TokenType.KEYWORD"
  
  label_bottom: "Lookup: O(1) Hash Probe"
}

# SCENARIO A: IDENTIFIER SCANNING (PREFIX MATCH PREVENTION)
scenario_a: {
  label: "Scenario A: Input 'iffy '"
  direction: down

  input_stream: {
    shape: code
    label: "Source Buffer (lexer.py)"
    content: |'md
      index:  0   1   2   3   4
      char: [ i | f | f | y |   ]
              ^
              current_pos
    '|
  }

  logic_process: {
    shape: class
    label: "_scan_identifier('i') (lexer.py)"
    
    definition: |'python
    def _scan_identifier(self, first_char):
        lexeme = first_char # 'i'
        while self.peek().isalnum() or self.peek() == '_':
            lexeme += self.advance()
        # After 3 iterations, lexeme == "iffy"
        type = KEYWORDS.get(lexeme, IDENTIFIER)
        return Token(type, lexeme, self.pos)
    '|
  }

  lookup_action: {
    label: "Hash Check"
    shape: circle
  }

  output_token: {
    shape: sql_table
    label: "struct Token (token.h)"
    "type": "TokenType.IDENTIFIER"
    "lexeme": "\"iffy\""
    "pos": "1:1"
    label_bottom: "Total: 32 bytes"
  }

  input_stream -> logic_process: "advance() loops 4x"
  logic_process -> lookup_action: "str | 4 bytes | \"iffy\""
  lookup_action -> keywords_table: "get(\"iffy\")"
  keywords_table -> lookup_action: "None (Default)"
  lookup_action -> output_token: "Mapping: IDENTIFIER"
}

# SCENARIO B: KEYWORD SCANNING (MAXIMAL MUNCH)
scenario_b: {
  label: "Scenario B: Input 'if (x)'"
  direction: down

  input_stream: {
    shape: code
    label: "Source Buffer (lexer.py)"
    content: |'md
      index:  0   1   2   3
      char: [ i | f |   | ( ]
              ^
              current_pos
    '|
  }

  logic_process: {
    shape: class
    label: "_scan_identifier('i') (lexer.py)"
    
    definition: |'python
    def _scan_identifier(self, first_char):
        lexeme = "if"
        # peek() is ' ' (False)
        # LOOP TERMINATES
        type = KEYWORDS.get("if", IDENTIFIER)
        return Token(type, "if", self.pos)
    '|
  }

  lookup_action: {
    label: "Hash Check"
    shape: circle
  }

  output_token: {
    shape: sql_table
    label: "struct Token (token.h)"
    "type": "TokenType.KEYWORD"
    "lexeme": "\"if\""
    "pos": "1:1"
    label_bottom: "Total: 32 bytes"
  }

  input_stream -> logic_process: "advance() loops 2x"
  logic_process -> lookup_action: "str | 2 bytes | \"if\""
  lookup_action -> keywords_table: "get(\"if\")"
  keywords_table -> lookup_action: "MATCH: KEYWORD"
  lookup_action -> output_token: "Mapping: KEYWORD"
}

# LAYOUT AND STYLING
scenario_a -> scenario_b: "VS (Maximal Munch Rule)" {
  style: {
    stroke-dash: 5
    font-size: 14
  }
}

keywords_table.style.fill: "#E4DBFE"
scenario_a.logic_process.style.fill: "#C7F1FF"
scenario_b.logic_process.style.fill: "#C7F1FF"
scenario_a.lookup_action.style.fill: "#FFF9C9"
scenario_b.lookup_action.style.fill: "#FFF9C9"