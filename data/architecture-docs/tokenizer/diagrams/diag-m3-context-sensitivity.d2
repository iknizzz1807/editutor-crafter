direction: right
vars: {
  d2-config: {
    layout-engine: elk
    theme-id: 4
  }
}

# --- 1. SCANNER ARCHITECTURE ---
scanner_component: {
  direction: down
  label: "class Scanner (scanner.py)"
  
  scanner_struct: {
    shape: sql_table
    label: "Scanner State Memory Map"
    
    row0: "0x00 | str      | source   | Full source text buffer"
    row1: "0x08 | int      | current  | Index of next character"
    row2: "0x10 | int      | line     | Current line (1-indexed)"
    row3: "0x18 | int      | column   | Current column (1-indexed)"
    label_bottom: "Total: 32 bytes (64-bit pointers/ints)"
  }
  
  scanner_logic: {
    shape: class
    label: "Lexical State Methods"
    next_token: |md
      python
      def next_token(self) -> Token:
          # Main dispatch loop
          char = self.advance()
          if char == '/': return self._handle_slash()
          if char == '"': return self._scan_string()
      
    |
    scan_string: |md
      python
      def _scan_string(self) -> Token:
          # IN_STRING Sub-state
          while True:
              c = self.advance()
              if c == '\\': self._handle_escape()
              if c == '"': return Token(...)
      
    |
  }
}

# --- 2. CONTEXTUAL DISPATCH MATRIX ---
context_sensitivity: {
  label: "Context-Sensitive Interpretation Matrix"
  direction: down
  
  slash_scenarios: {
    shape: sql_table
    label: "Input: Character '/'"
    
    header: "Scanner State | Lookahead (peek) | Action Taken | Resulting Token"
    case1: "START (Top)    | not ('/' or '*') | emit(TokenType.SLASH) | Token(SLASH, '/', L:C)"
    case2: "START (Top)    | '/'              | skip_line_comment()   | (None) -> recurse"
    case3: "IN_STRING      | (any)            | lexeme.append('/')    | STRING content"
    case4: "IN_BLOCK_COMM  | (any)            | (discard)             | (None)"
  }
  
  quote_scenarios: {
    shape: sql_table
    label: "Input: Character '\"'"
    
    header: "Scanner State | Previous Char | Action Taken | Resulting State"
    case1: "START (Top)    | (any)         | capture start pos | Transition: IN_STRING"
    case2: "IN_STRING      | not '\\'      | close lexeme      | Transition: START"
    case3: "IN_STRING      | '\\' (Escape) | append literal '\"'| Stay: IN_STRING"
  }
}

# --- 3. DATA FLOW & TRANSITIONS ---
input_stream: {
  label: "Source Buffer Stream"
  direction: right
  
  stream_div: "a / b"
  stream_com: "// note"
  stream_str: "\"v/1\""
}

# Connections visualizing "The 10-Second Rule" logic
input_stream.stream_div -> context_sensitivity.slash_scenarios.case1: "State: START | 1 char | '/'"
input_stream.stream_com -> context_sensitivity.slash_scenarios.case2: "State: START | 2 chars | '//'"
input_stream.stream_str -> context_sensitivity.slash_scenarios.case3: "State: IN_STRING | 1 char | '/'"

context_sensitivity.quote_scenarios.case1 -> scanner_component.scanner_logic.scan_string: "calls"
scanner_component.scanner_logic.scan_string -> context_sensitivity.quote_scenarios.case3: "Internal logic"

# --- 4. MUTATION VISUALIZATION (BEFORE/AFTER) ---
quote_mutation: {
  label: "Lexeme Mutation Logic: Escaped Quotes"
  direction: right
  
  before: {
    label: "Input Sequence"
    shape: code
    language: "text"
    value: " \" hello \\\" world \" "
  }
  
  logic: {
    shape: diamond
    label: "Inside _scan_string\nchar == '\\'?"
  }
  
  after: {
    label: "Emitted Token"
    shape: sql_table
    t_type: "Type   | STRING"
    t_lex:  "Lexeme | \"hello\\\"world\""
    t_pos:  "Pos    | 1:1"
  }
  
  before -> logic: "15 bytes"
  logic -> after: "Raw mapping"
}

# Labels for pedagogical scale
scanner_component.scanner_struct -> context_sensitivity: "Logic determines interpretation" {
  style.stroke-dash: 5
}