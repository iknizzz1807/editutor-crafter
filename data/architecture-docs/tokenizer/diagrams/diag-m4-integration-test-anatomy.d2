direction: right
vars: {
  d2-config: {
    layout-engine: elk
    theme-id: 4
  }
}

# SATELLITE CONTEXT: Milestone 4 Integration Testing
title: "Integration Test Anatomy: Source Mapping to Token Stream" {
  shape: text
  near: top-center
  style: {
    font-size: 24
    bold: true
  }
}

# --- INPUT LAYER ---
input_segment: {
  label: "Source Buffer (source.c)"
  direction: down
  
  buffer_view: {
    shape: code
    language: text
    value: |md
      Index:  01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31
      Char:    i  f     (  x     >  =     4  2     )     {     r  e  t  u  r  n     t  r  u  e  ;     } \0
    |
  }

  metadata: {
    shape: sql_table
    label: "Scanner State (scanner.py)"
    row1: "current | uint32_t | 31 (EOF)"
    row2: "line    | uint32_t | 1"
    row3: "column  | uint32_t | 31"
  }
}

# --- EXPECTED OUTPUT LAYER ---
expected_stream: {
  label: "Expected Token Stream (list[Token])"
  
  token_table: {
    shape: sql_table
    
    header: "idx | TokenType | Lexeme | Line | Col"
    
    t01: "00 | KEYWORD    | 'if'     | 1    | 1"
    t02: "01 | LPAREN     | '('      | 1    | 4"
    t03: "02 | IDENTIFIER | 'x'      | 1    | 5"
    t04: "03 | GREATER_EQ | '>='     | 1    | 7"
    t05: "04 | NUMBER     | '42'     | 1    | 10"
    t06: "05 | RPAREN     | ')'      | 1    | 13"
    t07: "06 | LBRACE     | '{'      | 1    | 15"
    t08: "07 | KEYWORD    | 'return' | 1    | 17"
    t09: "08 | KEYWORD    | 'true'   | 1    | 24"
    t10: "09 | SEMICOLON  | ';'      | 1    | 28"
    t11: "10 | RBRACE     | '}'      | 1    | 30"
    t12: "11 | EOF        | ''       | 1    | 31"
    
    label_bottom: "Total: 12 Tokens Captured"
  }
}

# --- MAPPING & FLOW ---
input_segment.buffer_view -> expected_stream.token_table.t01: "Maximal Munch (2 chars)" {
  style: {
    stroke: blue
    stroke-width: 2
  }
}

input_segment.buffer_view -> expected_stream.token_table.t04: "Peek(1) Lookahead" {
  style: {
    stroke: purple
    stroke-dash: 3
  }
}

input_segment.buffer_view -> expected_stream.token_table.t05: "Scan-until-non-digit" {
  style: {
    stroke: green
  }
}

input_segment.buffer_view -> expected_stream.token_table.t12: "Sentinel Detection" {
  style: {
    stroke-dash: 5
  }
}

# --- ANNOTATIONS ---
legend: {
  near: bottom-right
  
  k: KEYWORD {
    style.fill: "#E4DBFE"
  }
  o: OPERATOR {
    style.fill: "#C7F1FF"
  }
  l: LITERAL {
    style.fill: "#AFBFDF"
  }
}

expected_stream.token_table.t01.style.fill: "#E4DBFE"
expected_stream.token_table.t08.style.fill: "#E4DBFE"
expected_stream.token_table.t09.style.fill: "#E4DBFE"

expected_stream.token_table.t04.style.fill: "#C7F1FF"

expected_stream.token_table.t05.style.fill: "#AFBFDF"

explanation: |md
  ### The Scanner Contract
  1. **Whitespace Invariant**: Spaces at indices 03, 06, 09, 12, 14, 16, 23, 29 are consumed by `_skip_whitespace()` but never emitted.
  2. **Maximal Munch**: The sequence `> =` at indices 07-08 is consumed as a single `GREATER_EQ` token because `_match('=')` returns `True`.
  3. **EOF Invariant**: The `\0` null terminator at index 31 ensures a terminal `EOF` token is emitted, allowing the parser to terminate gracefully.
| {
  near: bottom-left
}