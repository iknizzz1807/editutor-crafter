direction: right
vars: {
  d2-config: {
    layout-engine: elk
    theme-id: 4
  }
}

# -----------------------------------------------------------------------------
# GLOBAL CLASSES & STYLES
# -----------------------------------------------------------------------------
classes: {
  step_box: {
    style: {
      stroke-width: 2
      border-radius: 4
    }
  }
  token_struct: {
    shape: sql_table
    style: {
      fill: "#f8f9fa"
      stroke: "#343a40"
    }
  }
  code_snippet: {
    style: {
      font: mono
      fill: "#e9ecef"
    }
  }
  fail_path: {
    style: {
      stroke: "#d0021b"
      fill: "#fff5f5"
    }
  }
  success_path: {
    style: {
      stroke: "#28a745"
      fill: "#f4faf6"
    }
  }
}

# -----------------------------------------------------------------------------
# INPUT SOURCE
# -----------------------------------------------------------------------------
source_buffer: {
  shape: sql_table
  label: "char source[] (input.c)"
  
  idx0: "Offset 0x00 | '>'"
  idx1: "Offset 0x01 | '='"
  idx2: "Offset 0x02 | '\\0' (EOF)"
  
  label_bottom: "Length: 2 chars + NULL"
}

# -----------------------------------------------------------------------------
# WRONG APPROACH: NON-GREEDY
# -----------------------------------------------------------------------------
wrong_strategy: {
  label: "Approach A: Immediate Emission (Wrong)"
  class: fail_path
  direction: down

  step1: "1. Read '>'" {
    class: step_box
    tooltip: "No lookahead performed"
  }
  
  emit1: {
    label: "Token t1 (scanner.py)"
    class: token_struct
    type: "TokenType.GREATER_THAN"
    lexeme: "'>'"
    line: "1"
    col: "1"
  }

  step2: "2. Read '='" {
    class: step_box
  }

  emit2: {
    label: "Token t2 (scanner.py)"
    class: token_struct
    type: "TokenType.ASSIGN"
    lexeme: "'='"
    line: "1"
    col: "2"
  }

  parser_failure: {
    shape: cloud
    label: "PARSER ERROR: Expected Expression"
    style.fill: "#ffcfcf"
  }

  step1 -> emit1
  emit1 -> step2
  step2 -> emit2
  emit2 -> parser_failure: "Stream: [GT, ASSIGN]"
}

# -----------------------------------------------------------------------------
# CORRECT APPROACH: MAXIMAL MUNCH
# -----------------------------------------------------------------------------
correct_strategy: {
  label: "Approach B: Maximal Munch (Correct)"
  class: success_path
  direction: down

  logic: |md
    python
    # scanner.py
    def _match(self, expected: str) -> bool:
        if self.peek() == expected:
            self.advance()
            return True
        return False
    
  | {class: code_snippet}

  step1: "1. Read '>'" {
    class: step_box
  }

  lookahead: "2. Peek Context" {
    shape: diamond
    label: "next == '='"
  }

  consume: "3. Consume '='" {
    class: step_box
    label: "Consume both chars\n(start=0, current=2)"
  }

  emit_final: {
    label: "Token t1 (scanner.py)"
    class: token_struct
    type: "TokenType.GREATER_EQUAL"
    lexeme: "'>='"
    line: "1"
    col: "1"
  }

  parser_success: {
    shape: circle
    label: "PARSER SUCCESS"
    style.fill: "#d4edda"
  }

  step1 -> lookahead
  lookahead -> consume: "True (Greedy)"
  consume -> emit_final
  emit_final -> parser_success: "Stream: [GE]"
}

# -----------------------------------------------------------------------------
# RELATIONSHIPS
# -----------------------------------------------------------------------------
source_buffer -> wrong_strategy: "Non-Greedy Path" {
  style.stroke: "#d0021b"
}
source_buffer -> correct_strategy: "Maximal Munch Path" {
  style.stroke: "#28a745"
}

legend: {
  near: bottom-right
  label: "Formal Principle: Lexical Ambiguity Resolution\n'Always match the longest sequence of characters\nthat forms a valid token.'"
  style: {
    fill: "#fff3cd"
    stroke: "#ffeeba"
    font-size: 14
  }
}