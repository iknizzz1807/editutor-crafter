direction: right
vars: {
  d2-config: {
    layout-engine: elk
    theme-id: 4
  }
}

# --- DEFINITIONS LAYER (L1) ---
definitions: {
  label: "DATA DEFINITIONS (scanner.py)"
  direction: down

  token_type_enum: {
    shape: sql_table
    label: "enum TokenType (scanner.py)"
    
    NUMBER: "0x00 | auto()"
    STRING: "0x01 | auto()"
    IDENTIFIER: "0x02 | auto()"
    KEYWORD: "0x03 | auto()"
    OPERATOR: "0x04 | auto()"
    PUNCTUATION: "0x05 | auto()"
    EOF: "0x06 | auto()"
    ERROR: "0x07 | auto()"
  }

  token_struct: {
    shape: sql_table
    label: "class Token (scanner.py)"
    
    header: "Offset | Type | Field"
    row1: "0x00 | TokenType | type"
    row2: "0x08 | str       | lexeme"
    row3: "0x10 | int       | line"
    row4: "0x18 | int       | column"
    
    label_bottom: "Total: 32 bytes (64-bit Pointers/Ints)"
  }

  token_methods: {
    shape: class
    label: "Token Methods (scanner.py)"
    definition: |md
      python
      def __repr__(self) -> str:
          return f"Token({self.type.name}, {self.lexeme!r}, {self.line}:{self.column})"
      
    |
  }
  
  token_struct -> token_methods: "implemented in"
}

# --- INSTANCES & EXAMPLES LAYER (L2) ---
instances: {
  label: "TOKEN INSTANCES (In-Memory)"
  direction: down

  example_1: {
    shape: class
    label: "Instance: Keyword 'if'"
    fields: |md
      python
      type: TokenType.KEYWORD
      lexeme: "if"
      line: 1
      column: 1
      
    |
  }

  example_2: {
    shape: class
    label: "Instance: Number '42'"
    fields: |md
      python
      type: TokenType.NUMBER
      lexeme: "42"
      line: 3
      column: 10
      
    |
  }
}

# --- ERROR RECOVERY CONTEXT (L3) ---
error_context: {
  label: "ERROR MAPPING UTILITY"
  direction: down

  source_code: {
    shape: code
    label: "source.c"
    language: "c"
    value: "if (x @ 42)"
  }

  error_pointing: {
    shape: text
    label: "Line 1, Col 7: Unexpected Token Error"
    style: {
      font-color: red
      bold: true
    }
  }

  source_code -> error_pointing: "Scanner Yields -> Token(ERROR, '@', 1, 7)" {
    style: {
      stroke: red
      stroke-dash: 3
    }
  }
}

# --- TOP-LEVEL RELATIONSHIPS ---
definitions.token_struct -> instances.example_1: "instantiates"
definitions.token_struct -> instances.example_2: "instantiates"

instances.example_1 -> error_context.source_code: "references origin" {
  label: "Metadata | Pointer to source"
}

# Implementation Guide (Constant position for ELK compatibility)
note: |md
  ### Implementation Notes (scanner.py)
  - **TokenType**: Use `enum.auto()` for unique integer mapping.
  - **Lexeme**: Store raw substrings directly from the source buffer.
  - **Position**: Line and Column are 1-based indices for IDE integration.
  - **Size**: 32-byte layout assumes 64-bit architecture pointers.
| {
  near: top-left
}

# Styling for Information Density
definitions.token_type_enum.style.fill: "#E4DBFE"
definitions.token_struct.style.fill: "#C7F1FF"
error_context.error_pointing.style.stroke: red