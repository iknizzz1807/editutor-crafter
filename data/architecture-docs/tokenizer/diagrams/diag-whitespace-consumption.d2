direction: right
vars: {
  d2-config: {
    layout-engine: elk
    theme-id: 3
  }
}

# SATELLITE REFERENCE: tokenizer-m1
# DIAGRAM: Whitespace Consumption â€” The Silent Consumer

before: {
  label: "BEFORE: Raw Source Buffer (Memory Layout)"
  direction: down

  buffer: {
    shape: sql_table
    label: "char source[]"
    
    0x00: "0 | 'x'  | (char)"
    0x01: "1 | ' '  | (whitespace)" {style.fill: lightgray}
    0x02: "2 | ' '  | (whitespace)" {style.fill: lightgray}
    0x03: "3 | '+'  | (char)"
    0x04: "4 | ' '  | (whitespace)" {style.fill: lightgray}
    0x05: "5 | ' '  | (whitespace)" {style.fill: lightgray}
    0x06: "6 | 'y'  | (char)"
    0x07: "7 | '\\n' | (newline)" {style.fill: "#ffebcc"}
    0x08: "8 | ' '  | (whitespace)" {style.fill: lightgray}
    0x09: "9 | 'z'  | (char)"
    
    label_bottom: "Total: 10 bytes"
  }

  logic: |md
    python
    # Scanner.advance() updates state
    # but _scan_token returns None
    elif char in (' ', '\t', '\r', '\n'):
        return None 
    
  |
}

transition: {
  shape: parallelogram
  label: "Scanner.scan_tokens()"
  style.fill: "#e6f3ff"
}

after: {
  label: "AFTER: Sanitized Token Stream"
  direction: down

  stream: {
    grid-columns: 1
    grid-gap: 20

    t0: {
      shape: class
      label: "Token[0] (token.py)"
      type: "TokenType.IDENTIFIER"
      lexeme: "\"x\""
      line: "1"
      column: "1"
      style.fill: "#d1e7dd"
    }

    t1: {
      shape: class
      label: "Token[1] (token.py)"
      type: "TokenType.OPERATOR"
      lexeme: "\"+\""
      line: "1"
      column: "4"
      style.fill: "#d1e7dd"
    }

    t2: {
      shape: class
      label: "Token[2] (token.py)"
      type: "TokenType.IDENTIFIER"
      lexeme: "\"y\""
      line: "1"
      column: "7"
      style.fill: "#d1e7dd"
    }

    t3: {
      shape: class
      label: "Token[3] (token.py)"
      type: "TokenType.IDENTIFIER"
      lexeme: "\"z\""
      line: "2"
      column: "2"
      style.fill: "#d1e7dd"
    }
  }

  summary: |md
    ### The "Null Transition"
    - Characters at index **1, 2, 4, 5, 8** were consumed via `advance()`.
    - `self.column` incremented.
    - `self.line` incremented at index **7**.
    - **No Token objects were instantiated for these characters.**
  |
}

before.buffer -> transition: "consume(10 bytes)"
transition -> after.stream: "produce(4 tokens)"

# Annotations for "Information Density"
legend: {
  near: bottom-right
  
  ws: "Gray = Whitespace (Null Transition)" {
    style.fill: lightgray
  }
  nl: "Yellow = Newline (State Mutation Only)" {
    style.fill: "#ffebcc"
  }
  tok: "Green = Emitted Token" {
    style.fill: "#d1e7dd"
  }
}