layout-engine: elk
direction: right
vars: {
  d2-config: {
    theme-id: 0
  }
}

# Lexical Vocabulary: TokenType Enumeration
# High-fidelity definition of categorization grammar

TokenizerModel: {
  TokenType: {
    shape: class
    label: "enum TokenType\nsizeof=32 bytes (PyObject_Head + variants)"
    
    # Literals
    NUMBER: "auto() | Lexeme: [0-9]+('.'[0-9]+)?"
    STRING: "auto() | Lexeme: '\"' [^\"\\n]* '\"'"
    
    # Names
    IDENTIFIER: "auto() | Lexeme: [a-zA-Z_][a-zA-Z0-9_]*"
    KEYWORD: "auto() | Lexeme: 'if' | 'else' | 'while' | 'return' ..."
    
    # Operators & Structural
    OPERATOR: "auto() | Lexeme: '+' | '-' | '*' | '/' | '==' | '>=' ..."
    PUNCTUATION: "auto() | Lexeme: '(' | ')' | '{' | '}' | ';' | ','"
    
    # Control Sentinels (Highlighted as system variants)
    EOF: "auto() | Lexeme: '' (Sentinel)" {
      style: {
        fill: "#e1d5e7" # Purple: Header/Control
        stroke: "#9673a6"
        bold: true
      }
    }
    ERROR: "auto() | Lexeme: <offending_char> (Recovery)" {
      style: {
        fill: "#f8cecc" # Red: Error state
        stroke: "#b85450"
        bold: true
      }
    }
  }

  ScannerState: {
    shape: class
    label: "class Scanner\nsizeof=128 bytes (buffer + cursors)"
    _scan_number(): "-> NUMBER"
    _scan_string(): "-> STRING"
    _scan_identifier(): "-> IDENTIFIER | KEYWORD"
    _dispatch_char(): "-> OPERATOR | PUNCTUATION"
    _panic_mode(): "-> ERROR"
    _terminate(): "-> EOF"
  }
}

# Mapping Logic: Scanner Methods to Token Categories
TokenizerModel.ScannerState._scan_number -> TokenizerModel.TokenType.NUMBER: "DFA: Integer/Float" {style.stroke-dash: 3}
TokenizerModel.ScannerState._scan_string -> TokenizerModel.TokenType.STRING: "DFA: Escaped Buffer" {style.stroke-dash: 3}
TokenizerModel.ScannerState._scan_identifier -> TokenizerModel.TokenType.IDENTIFIER: "DFA: Alnum Hunt" {style.stroke-dash: 3}
TokenizerModel.ScannerState._scan_identifier -> TokenizerModel.TokenType.KEYWORD: "Dict: Constant Lookup" {style.stroke-dash: 3}
TokenizerModel.ScannerState._dispatch_char -> TokenizerModel.TokenType.OPERATOR: "Match: Maximal Munch" {style.stroke-dash: 3}
TokenizerModel.ScannerState._dispatch_char -> TokenizerModel.TokenType.PUNCTUATION: "Direct Mapping" {style.stroke-dash: 3}
TokenizerModel.ScannerState._terminate -> TokenizerModel.TokenType.EOF: "exhaustion" {style.stroke-dash: 3}
TokenizerModel.ScannerState._panic_mode -> TokenizerModel.TokenType.ERROR: "skip-one recovery" {style.stroke-dash: 3}

# Structural Legend
Legend: {
  near: bottom-right
  ControlVariant: "System Sentinel" {
    style.fill: "#e1d5e7"
  }
  ErrorVariant: "Recovery State" {
    style.fill: "#f8cecc"
  }
  Transition: "References" {
    style.stroke-dash: 3
  }
}

|'md
### TokenType Specification (Intel Manual Style)
The `TokenType` enum represents a disjoint set of lexical categories. 
**DFA Compatibility**: Every variant except `KEYWORD` corresponds to a unique accepting state in the scanner's state machine. `KEYWORD` is resolved via a post-scan filter on `IDENTIFIER`.
|'|