layout-engine: elk
theme-id: 0

# TDD-1: TokenType Categorization
tdd_diag_1: {
  shape: package
  label: "TokenType: Language Vocabulary"
  
  literals: {
    shape: class
    label: "Literals"
    style.fill: "#3b82f6"
    NUMBER: "Value: float/int"
    STRING: "Value: raw source text"
  }
  
  names: {
    shape: class
    label: "Names"
    style.fill: "#3b82f6"
    IDENTIFIER: "User variables/funcs"
    KEYWORD: "Reserved (if, while...)"
  }
  
  operators: {
    shape: class
    label: "Operators"
    style.fill: "#3b82f6"
    PLUS_MINUS_STAR_SLASH: "+ - * /"
    COMPARISON: "== != < <= > >="
    LOGIC: "!"
  }
  
  punctuation: {
    shape: class
    label: "Punctuation"
    style.fill: "#3b82f6"
    DELIMITERS: "( ) { } [ ] ; ,"
  }

  sentinels: {
    shape: class
    label: "Sentinels"
    style.fill: "#6e41ab"
    EOF: "End of Stream"
    ERROR: "Invalid Character"
  }
}

# TDD-2: Token Dataclass Memory Layout
tdd_diag_2_container: {
  label: "Token Instance: Memory Layout (64-bit CPython)"
  
  tdd_diag_2: {
    shape: sql_table
    "00": "Header (PyObject_HEAD)" {constraint: "16B"}
    "16": "type: TokenType (Pointer)" {constraint: "8B"}
    "24": "lexeme: str (Pointer)" {constraint: "8B"}
    "32": "line: int (PyLong)" {constraint: "4B"}
    "36": "column: int (PyLong)" {constraint: "4B"}
    "40": "Padding" {constraint: "24B"}
  }
}

# SQL Table Row Styles (Fixed: Moved out of table definition)
tdd_diag_2_container.tdd_diag_2."00".style.fill: "#6e41ab"
tdd_diag_2_container.tdd_diag_2."16".style.fill: "#f59e0b"
tdd_diag_2_container.tdd_diag_2."24".style.fill: "#f59e0b"
tdd_diag_2_container.tdd_diag_2."32".style.fill: "#3b82f6"
tdd_diag_2_container.tdd_diag_2."36".style.fill: "#3b82f6"
tdd_diag_2_container.tdd_diag_2."40".style.fill: "#9ca3af"
tdd_diag_2_container.tdd_diag_2."40".style.stroke-dash: 3

# Legend moved to root to fix 'near' restriction in ELK
tdd_diag_2_legend: {
  label: "Memory Legend"
  near: tdd_diag_2_container
  h: Header { style.fill: "#6e41ab" }
  p: Pointer { style.fill: "#f59e0b" }
  d: Data { style.fill: "#3b82f6" }
  pad: Padding { style.fill: "#9ca3af" }
}

# TDD-3: Scanner Class Architecture
tdd_diag_3: {
  label: "Scanner Architecture"
  
  Scanner: {
    shape: class
    source: "str (O(N) memory)"
    current: "int (Byte Index)"
    line: "int (1-indexed)"
    column: "int (1-indexed)"
    
    scan_tokens(): "list[Token]"
    next_token(): "Token"
    peek(): "str"
    advance(): "str"
    is_at_end(): "bool"
    style.fill: "#3b82f6"
  }
  
  Token: {
    shape: class
    style.fill: "#10b981"
  }
  
  TokenType: {
    shape: class
    style.fill: "#6e41ab"
  }
  
  Scanner -> Token: "Produces"
  Token -> TokenType: "Categorized By"
}

# TDD-4: Cursor Model Invariants
tdd_diag_4: {
  label: "Cursor Model: Source Invariants"
  
  source: {
    grid-columns: 8
    style.fill: "#9ca3af"
    c0: "i"
    c1: "f"
    c2: " "
    c3: "("
    c4: "x"
    c5: " "
    c6: ">"
    c7: "="
  }
  
  cursor: {
    shape: cylinder
    label: "current = 4"
    style.fill: "#f59e0b"
  }
  
  cursor -> source.c4: "Points to NEXT char"
  
  annotation: |md
    - **current**: index of next char to consume
    - **line/column**: track start of lexeme
    - **advance()**: current++, column++
  |
}

# TDD-5: advance() Step-by-Step
tdd_diag_5: {
  direction: right
  
  step1: {
    label: "Before advance()"
    current: 10
    line: 1
    column: 10
    char: " "
    style.fill: "#9ca3af"
  }
  
  step2: {
    label: "After advance('\\n')"
    current: 11
    style.fill: "#10b981"
    line: "2" {
      style: { font-color: red; bold: true }
    }
    column: "1" {
      style: { font-color: red; bold: true }
    }
  }
  
  step1 -> step2: "process \\n"
}

# TDD-6: peek() vs advance() Sequence
tdd_diag_6: {
  shape: sequence_diagram
  
  User: User
  Scanner: Scanner
  Source: Source
  
  User -> Scanner: peek()
  Scanner -> Source: read current
  Scanner -> User: "return 'x' (no increment)"
  
  User -> Scanner: advance()
  Scanner -> Source: read current
  Scanner -> Scanner: "current++"
  Scanner -> Scanner: "column++"
  Scanner -> User: "return 'x'"
}

# TDD-7: Scanner FSM START State
tdd_diag_7: {
  START: Waiting for Lexeme { style.fill: "#3b82f6" }
  ACCEPT_PUNCT: Single Char Match { style.fill: "#10b981" }
  ERROR_STATE: Unknown Char { style.fill: "#ef4444" }
  
  START -> START: "whitespace / skip"
  START -> ACCEPT_PUNCT: "char in {+, -, *, ...}"
  START -> ERROR_STATE: "char == '@'"
  ERROR_STATE -> START: "consume & report"
}

# TDD-8: next_token() Control Flow
tdd_diag_8: {
  label: "next_token() Decision Logic"
  
  entry: "Start next_token"
  skip: "skip_whitespace()"
  pos: "capture (line, col)"
  dispatch: {
    shape: diamond
    label: "char type?"
  }
  
  entry -> skip -> pos -> dispatch
  dispatch -> op: "Operator"
  dispatch -> alpha: "ID/Keyword"
  dispatch -> digit: "Number"
  dispatch -> err: "Fallback"
  
  op -> emit: "Token"
  alpha -> emit
  digit -> emit
  err -> emit: "Error Token"
}

# TDD-10: Windows Line Ending Trace
tdd_diag_10: {
  label: "Windows \\r\\n Invariant"
  
  input: "+\\r\\n+"
  
  t1: {
    label: "Consume \\r"
    action: "column++"
    line: "stays 1"
  }
  
  t2: {
    label: "Consume \\n"
    action: "line++, col=1"
    line: "becomes 2"
  }
  
  t1 -> t2: "Result: 1 increment"
}

# TDD-11: Operator Decision Tree
tdd_diag_11: {
  label: "Maximal Munch: Operator Pairs"
  
  root: ">"
  root -> single: "peek != '='"
  root -> double: "peek == '='"
  
  single: "TokenType.GREATER" { style.fill: "#3b82f6" }
  double: "TokenType.GREATER_EQ" { style.fill: "#10b981" }
}

# TDD-12: >== Trace
tdd_diag_12: {
  label: "Trace: '>==' Input"
  
  s1: ">" { style: { bold: true; stroke: red } }
  s2: "=" { style: { bold: true; stroke: red } }
  s3: "=" { style.stroke: blue }
  
  group1: "Token 1: '>='" {
    s1; s2
  }
  group2: "Token 2: '='" {
    s3
  }
  
  group1 -> group2: "maximal munch logic"
}

# TDD-13: _match() Logic
tdd_diag_13: {
  shape: sequence_diagram
  Scanner: Scanner
  Source: Source
  User: User
  
  Scanner -> Source: peek()
  Scanner -> Scanner: "if expected == peek()"
  Scanner -> Scanner: "advance() (consume)"
  Scanner -> User: "return True"
}

# TDD-14: Number Scanner FSM
tdd_diag_14: {
  label: "Number Scanner FSM"
  
  INTEGER: Consuming Digits { style.fill: "#3b82f6" }
  FRACTION: Consuming Decimals { style.fill: "#3b82f6" }
  DOT: {
    shape: diamond
    label: "Seen '.'"
  }
  EXIT: "Token Produced"
  
  INTEGER -> INTEGER: "char.isdigit()"
  INTEGER -> DOT: "char == '.'"
  DOT -> FRACTION: "peek_next().isdigit()"
  DOT -> EXIT: "else (trailing dot)"
  FRACTION -> FRACTION: "char.isdigit()"
}

# TDD-15: _peek_next()
tdd_diag_15: {
  label: "Lookahead Window"
  source: "3 . 1 4"
  curr: "ptr"
  p1: "peek"
  p2: "peek_next" {
    style.stroke: orange
    tooltip: "Crucial for Float disambiguation"
  }
  
  curr -> source
  p1 -> source
  p2 -> source
}

# TDD-16: Identifier Scan-then-Lookup
tdd_diag_16: {
  shape: sequence_diagram
  Scanner: Scanner
  KEYWORDS: KEYWORDS_MAP
  
  Scanner -> Scanner: "Consume [a-zA-Z_0-9]*"
  Scanner -> KEYWORDS: "Hash map lookup (O(1))"
  KEYWORDS -> Scanner: "Match? TokenType.KEYWORD : TokenType.IDENTIFIER"
}

# TDD-17: next_token() Dispatch Order
tdd_diag_17: {
  label: "Dispatch Priority"
  shape: sql_table
  "1": "1. Whitespace Skip"
  "2": "2. EOF Check"
  "3": "3. Symbols (+, -, *)"
  "4": "4. Multi-Char Ops (>, <, !)"
  "5": "5. Numbers (isdigit)"
  "6": "6. IDs/Keywords (isalpha)"
  "7": "7. Fallback (ERROR)"
}

# TDD-18: Extended FSM (M2)
tdd_diag_18: {
  START -> IN_NUMBER: "digit"
  START -> IN_ID: "alpha"
  START -> IN_OP: "{!, =, <, >}"
  IN_NUMBER -> START: "return token"
  IN_ID -> START: "lookup keyword"
}

# TDD-19: Context Sensitivity
tdd_diag_19: {
  label: "Context Sensitivity: char '/'"
  
  C1: "START state" { style.fill: "#10b981" }
  C2: "IN_STRING" { style.fill: "#f59e0b" }
  C3: "IN_COMMENT" { style.fill: "#9ca3af" }
  SLASH: "/"
  
  C1 -> SLASH: "TokenType.SLASH"
  C2 -> SLASH: "String Content"
  C3 -> SLASH: "Comment Content"
}

# TDD-20: String Literal FSM
tdd_diag_20: {
  label: "String Scanner Sub-FSM"
  
  NORMAL: Content
  ESCAPE: After \ { style.fill: "#f59e0b" }
  ERR: "Error" { style.stroke: red }
  DONE: "Terminal"
  
  NORMAL -> ESCAPE: "char == '\\'"
  ESCAPE -> NORMAL: 'char in {n, t, r, ", \\}'
  ESCAPE -> ERR: "invalid escape"
  NORMAL -> DONE: 'char == "'
  NORMAL -> ERR: "char == '\\n' | EOF"
}

# TDD-21: Escape Sequence Validation
tdd_diag_21: {
  grid-rows: 2
  "n": "Newline"
  "t": "Tab"
  "r": "CR"
  "quote": "Quote"
  "bs": "Backslash"
  "err": ERROR { style.fill: "#ef4444" }
}

# TDD-23: Block Comment FSM
tdd_diag_23: {
  label: "Block Comment Sub-FSM"
  
  BODY: "Skipping"
  STAR: "Seen *"
  DONE: "Terminal"
  ERR: "Error"
  
  BODY -> STAR: "char == '*'"
  STAR -> BODY: "char != '/'"
  STAR -> DONE: "char == '/'"
  BODY -> ERR: "EOF reached"
}

# TDD-25: Error Position - Blame the Cause
tdd_diag_25: {
  source: '" u n t e r m i n a t e d \n'
  
  marker: {
    shape: circle
    label: "Error Point"
    style.fill: "#ef4444"
  }
  
  detector: "Scanner gives up"
  
  marker -> source: "tok_line/tok_col captured here"
  source -> detector: "Error detected here"
}

# TDD-26: Full FSM (Milestone 3)
tdd_diag_26: {
  START -> IN_NUM: "[0-9]"
  START -> IN_ID: "[a-zA-Z_]"
  START -> IN_STR: "\""
  START -> IN_COMM: "/"
  
  IN_COMM -> LINE_COMM: "/"
  IN_COMM -> BLOCK_COMM: "*"
  IN_COMM -> START: "else (SLASH)"
}

# TDD-28: Performance: List Join vs Concat
tdd_diag_28: {
  direction: right
  
  concat: {
    label: "lexeme += char"
    complexity: "O(N^2)"
    reason: "New string alloc per char"
  }
  
  buffer: {
    label: "list.append() + join()"
    complexity: "O(N)"
    reason: "Amortized O(1) append"
  }
}

# TDD-29: Token Stream Contract
tdd_diag_29: {
  Scanner -> Stream: "O(N) Pass"
  Stream: "List[Token]" { style.fill: "#10b981" }
  Stream -> Parser: "Input Contract"
  Parser: { style.fill: "#6e41ab" }
}

# TDD-30: Error Recovery Circuit Breaker
tdd_diag_30: {
  label: "Error Recovery: Character Resync"
  
  S: START
  E: ERROR { style.fill: "#ef4444" }
  
  S -> E: "invalid char"
  E -> S: "advance(1) and resume"
  
  annotation: "Fault isolation: Bad chars don't halt stream."
}

# TDD-32: Position Drift Visualization
tdd_diag_32: {
  line1: "/* multiline"
  line2: "   comment */ if"
  
  drift_bad: "if -> line 1 (WRONG)" { style.stroke: red }
  drift_good: "if -> line 2 (CORRECT)" { style.stroke: green }
  
  drift_bad -> line1
  drift_good -> line2
}

# TDD-33: Position Invariant Suite
tdd_diag_33: {
  grid-columns: 1
  i1: "1. Monotonicity: col[i+1] > col[i] on same line"
  i2: "2. Line Bounds: 1 <= line <= max_lines"
  i3: "3. Column Bounds: col >= 1"
}

# TDD-34: Multi-line Test Line Calculation
tdd_diag_34: {
  direction: right
  source: "// line 1\n/* line 2\nline 3 */\nif"
  L1: "skip_line"
  L2: "skip_block"
  L3: "if (Captured as Line 4)"
  
  L1 -> L2 -> L3
}

# TDD-35: Benchmark Architecture
tdd_diag_35: {
  label: "Performance Benchmark (10k lines)"
  generator: "generate_large_source()"
  scanner: "scan_tokens()"
  timer: "perf_counter()"
  
  generator -> timer -> scanner -> timer: "diff < 1.0s"
}

# TDD-36: Coverage Map (Unit vs Integration)
tdd_diag_36: {
  label: "Unit vs Integration Coverage Map"
  
  unit: {
    label: "Unit Tests (Isolated)"
    style.fill: "#f5f5f5"
    s_num: "_scan_number"
    s_id: "_scan_identifier"
    s_op: "_scan_operator"
    s_str: "_scan_string"
  }
  
  integration: {
    label: "Integration Tests (Composite)"
    style.fill: "#e0f2fe"
    pos_comm: "pos after block comment"
    str_line: "line accuracy in string"
    adj_op: "adjacent ops no space"
    err_mix: "error + valid mixed"
  }
  
  overlap: {
    label: "Core Contract"
    style.fill: "#10b981"
    canon: "Canonical Statement"
    edge: "Empty Input / EOF"
  }
  
  unit -> overlap
  integration -> overlap
}

# Fixed 'near' on note (Moved to root scope as constant near keys restricted in ELK containers)
tdd_diag_36_note: "Bugs in right/center zones ONLY appear when components interact." {
  shape: text
  near: tdd_diag_36
}