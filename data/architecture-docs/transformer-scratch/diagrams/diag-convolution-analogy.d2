vars: {
  d2-config: {
    layout-engine: elk
    theme-id: 200
  }
}

direction: right

title: |md
  # Multi-Head Attention vs Convolution Channels
  Both extract parallel feature representations from the same input
| {near: top-center}

# ========== CNN SIDE ==========
cnn_side: "Convolutional Neural Network" {
  
  cnn_input: "Input Image\n[Batch, C_in, H, W]" {
    style.fill: "#E3F2FD"
    style.stroke: "#1976D2"
  }
  
  cnn_channels: "Parallel Convolution Channels" {
    
    cnn_ch1: "Head 1: Edge\nDetection" {
      style.fill: "#FFCDD2"
      style.stroke: "#D32F2F"
    }
    cnn_ch2: "Head 2: Texture\nPatterns" {
      style.fill: "#C8E6C9"
      style.stroke: "#388E3C"
    }
    cnn_ch3: "Head 3: Color\nGradients" {
      style.fill: "#BBDEFB"
      style.stroke: "#1976D2"
    }
    cnn_ch4: "Head 4: Shape\nBoundaries" {
      style.fill: "#FFF9C4"
      style.stroke: "#FBC02D"
    }
  }
  
  cnn_concat: "Concatenate\n[Batch, C_out, H', W']" {
    style.fill: "#E1BEE7"
    style.stroke: "#7B1FA2"
  }
  
  cnn_output: "Feature Maps\n(Multi-channel representation)" {
    style.fill: "#F5F5F5"
    style.stroke: "#616161"
  }
  
  cnn_input -> cnn_channels.cnn_ch1: "kernel₁\n3×3×C_in"
  cnn_input -> cnn_channels.cnn_ch2: "kernel₂\n3×3×C_in"
  cnn_input -> cnn_channels.cnn_ch3: "kernel₃\n3×3×C_in"
  cnn_input -> cnn_channels.cnn_ch4: "kernel₄\n3×3×C_in"
  
  cnn_channels.cnn_ch1 -> cnn_concat: "[B,1,H',W']"
  cnn_channels.cnn_ch2 -> cnn_concat: "[B,1,H',W']"
  cnn_channels.cnn_ch3 -> cnn_concat: "[B,1,H',W']"
  cnn_channels.cnn_ch4 -> cnn_concat: "[B,1,H',W']"
  
  cnn_concat -> cnn_output
}

# ========== ATTENTION SIDE ==========
attn_side: "Multi-Head Attention" {
  
  attn_input: "Input Tokens\n[Batch, Seq, d_model]" {
    style.fill: "#E3F2FD"
    style.stroke: "#1976D2"
  }
  
  attn_heads: "Parallel Attention Heads" {
    
    attn_h1: "Head 1: Syntactic\nDependencies" {
      style.fill: "#FFCDD2"
      style.stroke: "#D32F2F"
    }
    attn_h2: "Head 2: Semantic\nSimilarity" {
      style.fill: "#C8E6C9"
      style.stroke: "#388E3C"
    }
    attn_h3: "Head 3: Positional\nRelations" {
      style.fill: "#BBDEFB"
      style.stroke: "#1976D2"
    }
    attn_h4: "Head 4: Coreference\nResolution" {
      style.fill: "#FFF9C4"
      style.stroke: "#FBC02D"
    }
  }
  
  attn_concat: "Concatenate\n[Batch, Seq, h×d_k]" {
    style.fill: "#E1BEE7"
    style.stroke: "#7B1FA2"
  }
  
  attn_output: "Contextualized\nRepresentations" {
    style.fill: "#F5F5F5"
    style.stroke: "#616161"
  }
  
  attn_input -> attn_heads.attn_h1: "W_Q¹,W_K¹,W_V¹\n[d_model, d_k]"
  attn_input -> attn_heads.attn_h2: "W_Q²,W_K²,W_V²\n[d_model, d_k]"
  attn_input -> attn_heads.attn_h3: "W_Q³,W_K³,W_V³\n[d_model, d_k]"
  attn_input -> attn_heads.attn_h4: "W_Q⁴,W_K⁴,W_V⁴\n[d_model, d_k]"
  
  attn_heads.attn_h1 -> attn_concat: "[B,Seq,d_k]"
  attn_heads.attn_h2 -> attn_concat: "[B,Seq,d_k]"
  attn_heads.attn_h3 -> attn_concat: "[B,Seq,d_k]"
  attn_heads.attn_h4 -> attn_concat: "[B,Seq,d_k]"
  
  attn_concat -> attn_output
}

# ========== COMPARISON ANNOTATIONS ==========
comparison: "Key Insight" {
  comparison_text: |md
    **Both architectures share the same principle:**
    
    1. **Same input** → Multiple parallel transformations
    2. **Different projections** → Different feature patterns
    3. **Concatenation** → Unified multi-aspect representation
    4. **Learned projections** → Network discovers useful patterns
    
    **Difference in operation:**
    - CNN: Local receptive field (kernel size)
    - Attention: Global receptive field (entire sequence)
  |
  style.fill: "#FFF3E0"
  style.stroke: "#FF9800"
  style.stroke-width: 2
  near: bottom-center
}

# ========== SHARED CHARACTERISTICS ==========
shared: "Shared Characteristics" {
  
  parallel_box: "Parallel Processing" {
    style.fill: "#E8F5E9"
  }
  
  concat_box: "Concatenation Merge" {
    style.fill: "#E8F5E9"
  }
  
  learn_box: "Learned Transformations" {
    style.fill: "#E8F5E9"
  }
  
  parallel_box -> concat_box -> learn_box
}

cnn_side.cnn_channels -> shared.parallel_box: "h heads\nrun in\nparallel" {
  style.stroke-dash: 3
  style.stroke: "#4CAF50"
}

attn_side.attn_heads -> shared.parallel_box: "h heads\nrun in\nparallel" {
  style.stroke-dash: 3
  style.stroke: "#4CAF50"
}

# ========== STYLE CLASSES ==========
classes: {
  visual_feature: {
    style: {
      stroke-width: 2
      border-radius: 8
    }
  }
  
  linguistic_feature: {
    style: {
      stroke-width: 2
      border-radius: 8
    }
  }
}

cnn_side.cnn_channels.cnn_ch1.class: visual_feature
cnn_side.cnn_channels.cnn_ch2.class: visual_feature
cnn_side.cnn_channels.cnn_ch3.class: visual_feature
cnn_side.cnn_channels.cnn_ch4.class: visual_feature

attn_side.attn_heads.attn_h1.class: linguistic_feature
attn_side.attn_heads.attn_h2.class: linguistic_feature
attn_side.attn_heads.attn_h3.class: linguistic_feature
attn_side.attn_heads.attn_h4.class: linguistic_feature