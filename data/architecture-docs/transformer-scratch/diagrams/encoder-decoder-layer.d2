classes: {
  encoder_style: {
    style.fill: "#1a1a2e"
    style.stroke: "#3fb950"
    style.font-color: "#e6edf3"
    style.bold: true
  }
  decoder_style: {
    style.fill: "#16213e"
    style.stroke: "#8b949e"
    style.font-color: "#e6edf3"
    style.bold: true
  }
  sublayer_style: {
    style.fill: "#0f3460"
    style.stroke: "#3fb950"
    style.font-color: "#e6edf3"
  }
  residual_style: {
    style.fill: "#3fb950"
    style.font-color: "#1a1a2e"
    style.bold: true
  }
  norm_style: {
    style.fill: "#e17055"
    style.font-color: "#ffffff"
  }
}

title: Encoder and Decoder Layer Internal Structure {
  near: top-center
  style.font-size: 18
  style.font-color: "#e6edf3"
  style.bold: true
}

encoder_layer: Encoder Layer {
  class: encoder_style
  
  enc_input: Input\nEmbeddings {
    class: sublayer_style
  }
  
  enc_mha: Multi-Head\nAttention {
    class: sublayer_style
  }
  
  enc_add1: Add & Norm {
    class: residual_style
  }
  
  enc_ffn: Feed Forward\nNetwork {
    class: sublayer_style
  }
  
  enc_add2: Add & Norm {
    class: residual_style
  }
  
  enc_output: Output {
    class: sublayer_style
  }
  
  enc_input -> enc_mha: query, key, value
  enc_mha -> enc_add1: attention output
  enc_input -> enc_add1: residual
  enc_add1 -> enc_ffn: normalized
  enc_ffn -> enc_add2: ffn output
  enc_add1 -> enc_add2: residual
  enc_add2 -> enc_output: final output
}

decoder_layer: Decoder Layer {
  class: decoder_style
  
  dec_input: Input\nEmbeddings {
    class: sublayer_style
  }
  
  dec_self_attn: Masked\nSelf-Attention {
    class: sublayer_style
  }
  
  dec_add1: Add & Norm {
    class: residual_style
  }
  
  dec_cross_attn: Cross\nAttention {
    class: sublayer_style
  }
  
  dec_add2: Add & Norm {
    class: residual_style
  }
  
  dec_ffn: Feed Forward\nNetwork {
    class: sublayer_style
  }
  
  dec_add3: Add & Norm {
    class: residual_style
  }
  
  dec_output: Output {
    class: sublayer_style
  }
  
  dec_input -> dec_self_attn: self attention
  dec_self_attn -> dec_add1: masked output
  dec_input -> dec_add1: residual
  dec_add1 -> dec_cross_attn: query
  dec_cross_attn -> dec_add2: cross attention
  dec_add1 -> dec_add2: residual
  dec_add2 -> dec_ffn: normalized
  dec_ffn -> dec_add3: ffn output
  dec_add2 -> dec_add3: residual
  dec_add3 -> dec_output: final output
}

encoder_layer.enc_output -> decoder_layer.dec_cross_attn: encoder keys/values {
  style.stroke: "#3fb950"
  style.stroke-width: 3
  style.stroke-dash: 5
}

layer_norm_note: |md
  **Layer Normalization**
  Applied after each residual connection
  Stabilizes training and improves convergence
| {
  shape: page
  near: bottom-left
  class: norm_style
}

residual_note: |md
  **Residual Connections**
  Add input to sublayer output
  Enables gradient flow in deep networks
| {
  shape: page
  near: bottom-right
  class: norm_style
}