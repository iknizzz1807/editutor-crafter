vars: {
  d2-config: {
    layout-engine: elk
    theme-id: 200
  }
}

direction: right

title: |md
  # Scaled Dot-Product Attention: Tensor Shape Trace
  `x [B, L, D] → Q, K, V → scores [B, L, L] → weights [B, L, L] → output [B, L, D]`
| {near: top-center}

# Input tensor
input: {
  label: "Input Embeddings\nx\n\n**Shape:** `[B, L, D]`\n\n- B = batch size\n- L = sequence length\n- D = model dimension (d_model)"
  shape: rectangle
  style: {
    fill: "#E8F4FD"
    stroke: "#2196F3"
    stroke-width: 2
  }
}

# Learned projections container
projections: {
  label: "Learned Linear Projections\n(W_Q, W_K, W_V ∈ ℝ^(D×D))"
  style: {
    fill: "#FFF3E0"
    stroke: "#FF9800"
    stroke-dash: 3
  }

  W_Q: {
    label: "W_Q\nQuery\nProjection"
    shape: rectangle
    style: {
      fill: "#E1BEE7"
      stroke: "#9C27B0"
    }
  }
  
  W_K: {
    label: "W_K\nKey\nProjection"
    shape: rectangle
    style: {
      fill: "#E1BEE7"
      stroke: "#9C27B0"
    }
  }
  
  W_V: {
    label: "W_V\nValue\nProjection"
    shape: rectangle
    style: {
      fill: "#E1BEE7"
      stroke: "#9C27B0"
    }
  }
}

# Q, K, V tensors
Q: {
  label: "Query\nQ\n\n**Shape:** `[B, L, D]`\n\n`Q = x @ W_Q`"
  shape: rectangle
  style: {
    fill: "#C8E6C9"
    stroke: "#4CAF50"
    stroke-width: 2
  }
}

K: {
  label: "Key\nK\n\n**Shape:** `[B, L, D]`\n\n`K = x @ W_K`"
  shape: rectangle
  style: {
    fill: "#C8E6C9"
    stroke: "#4CAF50"
    stroke-width: 2
  }
}

V: {
  label: "Value\nV\n\n**Shape:** `[B, L, D]`\n\n`V = x @ W_V`"
  shape: rectangle
  style: {
    fill: "#C8E6C9"
    stroke: "#4CAF50"
    stroke-width: 2
  }
}

# Attention score computation
score_compute: {
  label: "Score Computation"
  style: {
    fill: "#FFEBEE"
    stroke: "#F44336"
    stroke-dash: 3
  }
  
  matmul1: {
    label: "Q @ K^T"
    shape: rectangle
    style: {
      fill: "#FFCDD2"
      stroke: "#E53935"
    }
  }
  
  scale: {
    label: "÷ √d_k"
    shape: rectangle
    style: {
      fill: "#FFCDD2"
      stroke: "#E53935"
    }
  }
  
  matmul1 -> scale
}

# Raw scores
scores: {
  label: "Attention\nScores\n\n**Shape:** `[B, L, L]`\n\n`scores = (Q @ K^T) / √d_k`\n\nRow i, col j = how much\nposition i attends to j"
  shape: rectangle
  style: {
    fill: "#FFCDD2"
    stroke: "#E53935"
    stroke-width: 2
  }
}

# Masking
mask: {
  label: "Optional Mask\n(Padding/Causal)"
  shape: diamond
  style: {
    fill: "#E0E0E0"
    stroke: "#757575"
  }
}

# Softmax
softmax: {
  label: "Softmax\n(dim=-1)"
  shape: rectangle
  style: {
    fill: "#B3E5FC"
    stroke: "#03A9F4"
    stroke-width: 2
  }
}

# Attention weights
weights: {
  label: "Attention\nWeights\n\n**Shape:** `[B, L, L]`\n\nEach row sums to 1.0\n`weights = softmax(scores)`"
  shape: rectangle
  style: {
    fill: "#B3E5FC"
    stroke: "#03A9F4"
    stroke-width: 2
  }
}

# Final matmul with V
final_matmul: {
  label: "weights @ V"
  shape: rectangle
  style: {
    fill: "#DCEDC8"
    stroke: "#8BC34A"
  }
}

# Output
output: {
  label: "Attention\nOutput\n\n**Shape:** `[B, L, D]`\n\nWeighted sum of values:\n`output_i = Σ_j(weights[i,j] × V[j])`"
  shape: rectangle
  style: {
    fill: "#DCEDC8"
    stroke: "#689F38"
    stroke-width: 2
  }
}

# Connections
input -> projections
projections.W_Q -> Q
projections.W_K -> K  
projections.W_V -> V

Q -> score_compute.matmul1
K -> score_compute.matmul1

score_compute -> scores
scores -> mask
mask -> softmax
softmax -> weights

weights -> final_matmul
V -> final_matmul
final_matmul -> output

# Dimension flow annotation
dim_flow: |md
  
  [B, L, D] → [B, L, D] → [B, L, L] → [B, L, L] → [B, L, D]
       x    →  Q, K, V  →  scores  → weights  → output
  
| {
  near: bottom-center
  shape: text
  style: {
    font: mono
    font-size: 16
  }
}