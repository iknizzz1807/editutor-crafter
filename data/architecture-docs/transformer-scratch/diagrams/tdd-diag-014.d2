vars: {
  d2-config: {
    layout-engine: elk
    theme-id: 200
  }
}

title: |md
  # Multi-Head Concatenation Algorithm
  ## Step-by-step tensor reshape: [batch, heads, seq, d_k] → [batch, seq, d_model]
| {near: top-center}

direction: right

step1: "Step 1: Per-Head Output" {
  style.fill: "#E8F4FD"
  style.stroke: "#2E86AB"
  
  input_tensor: |md
    **Input Shape:** `[batch, num_heads, seq, d_k]`
    
    
    batch=2, num_heads=8, seq=4, d_k=64
    
    
    Memory layout: heads × seq × d_k contiguous
  |
  
  visual_input: {
    grid-columns: 1
    grid-gap: 2
    
    h0: "Head 0: [seq=4, d_k=64]" {style.fill: "#FFE4B5"}
    h1: "Head 1: [seq=4, d_k=64]" {style.fill: "#E6E6FA"}
    h2: "Head 2: [seq=4, d_k=64]" {style.fill: "#B0E0E6"}
    ellipsis: "..." {style.fill: transparent; style.stroke: transparent}
    h7: "Head 7: [seq=4, d_k=64]" {style.fill: "#98FB98"}
  }
  visual_input.style.fill: white
}

step2: "Step 2: Transpose" {
  style.fill: "#FFF3E0"
  style.stroke: "#E65100"
  
  transpose_op: |md
    **Operation:** `transpose(1, 2)`
    
    Swap dimensions 1 and 2:
    - dim 1: `num_heads` ↔ `seq_len`
    
    **New Shape:** `[batch, seq, num_heads, d_k]`
  |
  
  visual_transpose: {
    grid-columns: 1
    grid-gap: 2
    
    s0: "Seq 0: [heads=8, d_k=64]" {style.fill: "#FFB6C1"}
    s1: "Seq 1: [heads=8, d_k=64]" {style.fill: "#DDA0DD"}
    s2: "Seq 2: [heads=8, d_k=64]" {style.fill: "#87CEEB"}
    s3: "Seq 3: [heads=8, d_k=64]" {style.fill: "#90EE90"}
  }
  visual_transpose.style.fill: white
  
  note: |md
    **Memory Effect:** Non-contiguous stride change
    - Old strides: `[seq*d_k, d_k, 1]` per head
    - New strides: `[heads*d_k, 1, d_k]` per position
  |
}

step3: "Step 3: Reshape/View" {
  style.fill: "#E8F5E9"
  style.stroke: "#2E7D32"
  
  reshape_op: |md
    **Operation:** `reshape(batch, seq, -1)` or `.view(batch, seq, num_heads * d_k)`
    
    Flatten last two dimensions:
    - `num_heads × d_k = 8 × 64 = 512 = d_model`
    
    **Final Shape:** `[batch, seq, d_model]`
  |
  
  visual_reshape: {
    grid-columns: 1
    grid-gap: 2
    
    out0: "Seq 0: [d_model=512]" {style.fill: "#98D8C8"}
    out1: "Seq 1: [d_model=512]" {style.fill: "#7FCDBB"}
    out2: "Seq 2: [d_model=512]" {style.fill: "#41B6C4"}
    out3: "Seq 3: [d_model=512]" {style.fill: "#1D91C0"}
  }
  visual_reshape.style.fill: white
  
  contiguous_note: |md
    **Contiguity Warning:**
    
    After transpose, tensor may be non-contiguous.
    Call `.contiguous()` before `.view()` if needed.
  |
}

step1 -> step2: "transpose(1, 2)" {
  style.stroke: "#E65100"
  style.stroke-width: 3
  style.bold: true
}

step2 -> step3: "reshape/view" {
  style.stroke: "#2E7D32"
  style.stroke-width: 3
  style.bold: true
}

dims: {
  near: bottom-center
  
  dim_table: ||md
    | Step | Shape | Total Elements | Contiguous |
    |------|-------|----------------|------------|
    | Input | `[B, H, S, D]` | B×H×S×D | Yes |
    | After transpose | `[B, S, H, D]` | B×S×H×D | No* |
    | After reshape | `[B, S, D_model]` | B×S×D_model | After `.contiguous()` |
    
    *Transpose only changes stride metadata, not data layout
  ||
}

code_ref: "Implementation Code" {
  near: center-right
  style.fill: "#2D2D2D"
  style.font-color: white
  style.font: mono
  
  code: ||py
    def concat_heads(
        head_outputs: Tensor  # [B, H, S, D]
    ) -> Tensor:
        batch, num_heads, seq, d_k = head_outputs.shape
        transposed = head_outputs.transpose(1, 2)
        output = transposed.contiguous().view(
            batch, seq, num_heads * d_k
        )
        return output  # [B, S, d_model]
  ||
}

memory_layout: "Memory Layout Transformation" {
  near: bottom-right
  style.fill: "#F5F5F5"
  
  before: "Before (heads-major)" {
    style.fill: "#FFE4B5"
    layout: |md
      [H0_S0][H0_S1][H0_S2][H0_S3]
      [H1_S0][H1_S1][H1_S2][H1_S3]
      [H2_S0]...
      
      Head 0's sequence is contiguous
    |
  }
  
  after: "After (sequence-major)" {
    style.fill: "#98D8C8"
    layout: |md
      [S0_H0][S0_H1][S0_H2]...[S0_H7]
      [S1_H0][S1_H1][S1_H2]...[S1_H7]
      [S2_H0]...
      
      Each position's heads are contiguous
    |
  }
  
  before -> after: "transpose\n+ reshape" {
    style.stroke: "#666"
    style.stroke-dash: 3
  }
}