vars: {
  d2-config: {
    layout-engine: elk
    theme-id: 200
  }
}

title: |md
  # Dropout Placement Strategy
  Transformer Regularization Points
| {near: top-center}

direction: down

classes: {
  component: {
    style: {
      fill: "#E8F4FD"
      stroke: "#2563EB"
      stroke-width: 2
      border-radius: 8
    }
  }
  dropout: {
    style: {
      fill: "#FEE2E2"
      stroke: "#DC2626"
      stroke-width: 3
      border-radius: 4
      font-color: "#991B1B"
      bold: true
    }
  }
  residual: {
    style: {
      fill: "#D1FAE5"
      stroke: "#059669"
      stroke-width: 2
      border-radius: 6
    }
  }
  label-box: {
    style: {
      fill: transparent
      stroke: "#9CA3AF"
      stroke-dash: 3
      font-color: "#6B7280"
    }
  }
}

Input: Input Embeddings {
  class: component
  style.fill: "#DBEAFE"
}

Dropout_1: Dropout (p=0.1) {
  class: dropout
  label: |md
    **Dropout**
    `p = 0.1`
    
    Applied after:
    Embedding + PE
  |
}

PE: Positional Encoding {
  class: component
  style.fill: "#FEF3C7"
}

Add_PE: Add {
  shape: circle
  style.fill: "#D1FAE5"
}

Input -> PE
Input -> Add_PE
PE -> Add_PE
Add_PE -> Dropout_1

Sublayer_1: Sublayer 1 (Self-Attention) {
  class: component
}

Dropout_2: Dropout (p=0.1) {
  class: dropout
  label: |md
    **Dropout**
    `p = 0.1`
    
    After attention
    before residual
  |
}

Add_1: Add {
  shape: circle
  style.fill: "#D1FAE5"
}

Norm_1: LayerNorm {
  class: residual
}

Dropout_1 -> Sublayer_1
Sublayer_1 -> Dropout_2
Dropout_1 -> Add_1
Dropout_2 -> Add_1
Add_1 -> Norm_1

Sublayer_2: Sublayer 2 (FFN) {
  class: component
}

Dropout_3: Dropout (p=0.1) {
  class: dropout
  label: |md
    **Dropout**
    `p = 0.1`
    
    After FFN
    before residual
  |
}

Add_2: Add {
  shape: circle
  style.fill: "#D1FAE5"
}

Norm_2: LayerNorm {
  class: residual
}

Norm_1 -> Sublayer_2
Sublayer_2 -> Dropout_3
Norm_1 -> Add_2
Dropout_3 -> Add_2
Add_2 -> Norm_2

Output: To Next Layer {
  class: component
  style.fill: "#DBEAFE"
}

Norm_2 -> Output

legend: Legend {
  near: bottom-right
  class: label-box
  
  drop: Dropout Layer {
    class: dropout
    width: 150
  }
  res: Residual Path {
    class: residual
    width: 150
  }
  comp: Transformer Component {
    class: component
    width: 150
  }
}

annotation: |md
  ## Dropout Placement Rules
  
  **1. After Embedding + PE**
  python
  x = self.dropout(x + self.pe(x))
  
  
  **2. After Each Sublayer (before Add)**
  python
  # Attention block
  x = x + self.dropout(self.attention(x))
  x = self.norm1(x)
  
  # FFN block
  x = x + self.dropout(self.ffn(x))
  x = self.norm2(x)
  
  
  **3. Never on Attention Weights**
  Dropout on softmax output breaks
  the probability distribution.
| {near: center-right}