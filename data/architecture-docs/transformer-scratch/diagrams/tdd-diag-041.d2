vars: {
  d2-config: {
    layout-engine: elk
    theme-id: 200
  }
}

title: |md
  # Causal Mask Regeneration
  ## Training vs Generation Sequence Lengths
| {near: top-center}

direction: right

training_context: Training Context {
  style.fill: "#E8F4FD"
  
  note_train: |md
    Fixed sequence length during training.
    Mask covers full `max_seq_len`.
  |
  
  train_seq: Input Batch {
    style.fill: white
    shape: sql_table
    pos0: int {constraint: PK}
    pos1: int
    pos2: int
    pos3: int
    pos4: int
    pos5: int
    pos6: int
    pos7: int
  }
  
  train_mask: "Full Causal Mask [8×8]" {
    style.fill: white
    
    grid-rows: 8
    grid-columns: 8
    grid-gap: 2
    
    m00: 1 {style.fill: "#4CAF50"}
    m01: 0 {style.fill: "#FF5722"}
    m02: 0 {style.fill: "#FF5722"}
    m03: 0 {style.fill: "#FF5722"}
    m04: 0 {style.fill: "#FF5722"}
    m05: 0 {style.fill: "#FF5722"}
    m06: 0 {style.fill: "#FF5722"}
    m07: 0 {style.fill: "#FF5722"}
    
    m10: 1 {style.fill: "#4CAF50"}
    m11: 1 {style.fill: "#4CAF50"}
    m12: 0 {style.fill: "#FF5722"}
    m13: 0 {style.fill: "#FF5722"}
    m14: 0 {style.fill: "#FF5722"}
    m15: 0 {style.fill: "#FF5722"}
    m16: 0 {style.fill: "#FF5722"}
    m17: 0 {style.fill: "#FF5722"}
    
    m20: 1 {style.fill: "#4CAF50"}
    m21: 1 {style.fill: "#4CAF50"}
    m22: 1 {style.fill: "#4CAF50"}
    m23: 0 {style.fill: "#FF5722"}
    m24: 0 {style.fill: "#FF5722"}
    m25: 0 {style.fill: "#FF5722"}
    m26: 0 {style.fill: "#FF5722"}
    m27: 0 {style.fill: "#FF5722"}
    
    m30: 1 {style.fill: "#4CAF50"}
    m31: 1 {style.fill: "#4CAF50"}
    m32: 1 {style.fill: "#4CAF50"}
    m33: 1 {style.fill: "#4CAF50"}
    m34: 0 {style.fill: "#FF5722"}
    m35: 0 {style.fill: "#FF5722"}
    m36: 0 {style.fill: "#FF5722"}
    m37: 0 {style.fill: "#FF5722"}
    
    m40: 1 {style.fill: "#4CAF50"}
    m41: 1 {style.fill: "#4CAF50"}
    m42: 1 {style.fill: "#4CAF50"}
    m43: 1 {style.fill: "#4CAF50"}
    m44: 1 {style.fill: "#4CAF50"}
    m45: 0 {style.fill: "#FF5722"}
    m46: 0 {style.fill: "#FF5722"}
    m47: 0 {style.fill: "#FF5722"}
    
    m50: 1 {style.fill: "#4CAF50"}
    m51: 1 {style.fill: "#4CAF50"}
    m52: 1 {style.fill: "#4CAF50"}
    m53: 1 {style.fill: "#4CAF50"}
    m54: 1 {style.fill: "#4CAF50"}
    m55: 1 {style.fill: "#4CAF50"}
    m56: 0 {style.fill: "#FF5722"}
    m57: 0 {style.fill: "#FF5722"}
    
    m60: 1 {style.fill: "#4CAF50"}
    m61: 1 {style.fill: "#4CAF50"}
    m62: 1 {style.fill: "#4CAF50"}
    m63: 1 {style.fill: "#4CAF50"}
    m64: 1 {style.fill: "#4CAF50"}
    m65: 1 {style.fill: "#4CAF50"}
    m66: 1 {style.fill: "#4CAF50"}
    m67: 0 {style.fill: "#FF5722"}
    
    m70: 1 {style.fill: "#4CAF50"}
    m71: 1 {style.fill: "#4CAF50"}
    m72: 1 {style.fill: "#4CAF50"}
    m73: 1 {style.fill: "#4CAF50"}
    m74: 1 {style.fill: "#4CAF50"}
    m75: 1 {style.fill: "#4CAF50"}
    m76: 1 {style.fill: "#4CAF50"}
    m77: 1 {style.fill: "#4CAF50"}
  }
  
  train_code: |python
    # Training: Pre-compute once
    seq_len = 8  # max_seq_len
    causal_mask = torch.tril(
        torch.ones(seq_len, seq_len)
    ).bool()
    # Shape: [8, 8]
  |
}

generation_context: Generation Context {
  style.fill: "#FFF3E0"
  
  note_gen: |md
    Growing sequence during autoregressive generation.
    Mask regrows each step.
  |
  
  step1: "Step 1 (len=1)" {
    style.fill: white
    
    gen_seq1: "Tokens [A]" {
      style.fill: "#FFEB3B"
      style.stroke: "#F57C00"
      style.bold: true
    }
    
    gen_mask1: "Mask [1×1]" {
      style.fill: white
      grid-rows: 1
      grid-columns: 1
      grid-gap: 2
      g1: 1 {style.fill: "#4CAF50"; style.bold: true}
    }
  }
  
  step2: "Step 2 (len=2)" {
    style.fill: white
    
    gen_seq2: "Tokens [A, B]" {
      style.fill: "#FFEB3B"
      style.stroke: "#F57C00"
      style.bold: true
    }
    
    gen_mask2: "Mask [2×2]" {
      style.fill: white
      grid-rows: 2
      grid-columns: 2
      grid-gap: 2
      g2_00: 1 {style.fill: "#4CAF50"}
      g2_01: 0 {style.fill: "#FF5722"}
      g2_10: 1 {style.fill: "#4CAF50"}
      g2_11: 1 {style.fill: "#4CAF50"; style.bold: true}
    }
  }
  
  step3: "Step 3 (len=3)" {
    style.fill: white
    
    gen_seq3: "Tokens [A, B, C]" {
      style.fill: "#FFEB3B"
      style.stroke: "#F57C00"
      style.bold: true
    }
    
    gen_mask3: "Mask [3×3]" {
      style.fill: white
      grid-rows: 3
      grid-columns: 3
      grid-gap: 2
      g3_00: 1 {style.fill: "#4CAF50"}
      g3_01: 0 {style.fill: "#FF5722"}
      g3_02: 0 {style.fill: "#FF5722"}
      g3_10: 1 {style.fill: "#4CAF50"}
      g3_11: 1 {style.fill: "#4CAF50"}
      g3_12: 0 {style.fill: "#FF5722"}
      g3_20: 1 {style.fill: "#4CAF50"}
      g3_21: 1 {style.fill: "#4CAF50"}
      g3_22: 1 {style.fill: "#4CAF50"; style.bold: true}
    }
  }
  
  step4: "Step 4 (len=4)" {
    style.fill: white
    
    gen_seq4: "Tokens [A, B, C, D]" {
      style.fill: "#FFEB3B"
      style.stroke: "#F57C00"
      style.bold: true
    }
    
    gen_mask4: "Mask [4×4]" {
      style.fill: white
      grid-rows: 4
      grid-columns: 4
      grid-gap: 2
      g4_00: 1 {style.fill: "#4CAF50"}
      g4_01: 0 {style.fill: "#FF5722"}
      g4_02: 0 {style.fill: "#FF5722"}
      g4_03: 0 {style.fill: "#FF5722"}
      g4_10: 1 {style.fill: "#4CAF50"}
      g4_11: 1 {style.fill: "#4CAF50"}
      g4_12: 0 {style.fill: "#FF5722"}
      g4_13: 0 {style.fill: "#FF5722"}
      g4_20: 1 {style.fill: "#4CAF50"}
      g4_21: 1 {style.fill: "#4CAF50"}
      g4_22: 1 {style.fill: "#4CAF50"}
      g4_23: 0 {style.fill: "#FF5722"}
      g4_30: 1 {style.fill: "#4CAF50"}
      g4_31: 1 {style.fill: "#4CAF50"}
      g4_32: 1 {style.fill: "#4CAF50"}
      g4_33: 1 {style.fill: "#4CAF50"; style.bold: true}
    }
  }
  
  gen_code: |python
    # Generation: Rebuild each step
    for step in range(max_len):
        cur_len = step + 1
        # Option 1: Create new mask
        causal_mask = torch.tril(
            torch.ones(cur_len, cur_len)
        ).bool()
        
        # Option 2: Slice pre-computed
        causal_mask = full_mask[:cur_len, :cur_len]
  |
}

optimization: KV-Cache Optimization {
  style.fill: "#E8F5E9"
  
  note_kv: |md
    **Key Insight**: With KV-cache, we don't need to recompute
    attention for previous positions. Only the NEW position
    attends to all previous + itself.
  |
  
  kv_step: Incremental Attention {
    style.fill: white
    
    kv_cache: KV-Cache {
      shape: cylinder
      style.fill: "#BBDEFB"
    }
    
    new_token: New Token {
      style.fill: "#4CAF50"
      style.font-color: white
      style.bold: true
    }
    
    new_q: "Query Qₙ" {
      style.fill: "#FFF9C4"
    }
    
    kv_cache -> new_q: "K₁...Kₙ₋₁, V₁...Vₙ₋₁"
    new_token -> new_q: "only new query"
  }
  
  kv_mask: Single-Row Mask {
    style.fill: white
    
    mask_row: |md
      `[1, 1, 1, ..., 1, 1]`
      
      Only ONE row needed—current position
      attending to all previous + self.
    |
  }
  
  kv_code: |python
    # With KV-cache: efficient generation
    # Only compute attention for new token
    new_q = W_Q(new_token)           # [1, d_k]
    all_k = torch.cat([cached_k, new_k])  # [n, d_k]
    all_v = torch.cat([cached_v, new_v])  # [n, d_v]
    
    # Single query attends to all keys
    scores = new_q @ all_k.T / sqrt(d_k)  # [1, n]
    # No causal mask needed for single row!
    # (new token only sees past + itself)
    
    output = softmax(scores) @ all_v  # [1, d_v]
  |
}

legend: Legend {
  near: bottom-center
  style.fill: white
  style.stroke: "#E0E0E0"
  
  green: Can Attend {style.fill: "#4CAF50"}
  red: "Cannot Attend (Future)" {style.fill: "#FF5722"}
  yellow: Current Token {style.fill: "#FFEB3B"; style.stroke: "#F57C00"}
}

training_context -> generation_context: "Different\nsequence\nlengths" {
  style.stroke-dash: 5
  style.stroke: "#9E9E9E"
}

generation_context -> optimization: "KV-cache\noptimization" {
  style.stroke-dash: 5
  style.stroke: "#4CAF50"
}