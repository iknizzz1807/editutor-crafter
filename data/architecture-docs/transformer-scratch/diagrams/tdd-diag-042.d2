vars: {
  d2-config: {
    layout-engine: elk
    theme-id: 200
  }
}

shape: sequence_diagram

# Define actors in order
Input: Input Sequence
Encoder_L1: Encoder Layer 1
Encoder_L2: Encoder Layer 2
Encoder_L3: Encoder Layer 3 {
  style.stroke-dash: 3
}
Encoder_Out: "Encoder Output [batch, src_len, d_model]"
Decoder_L1: Decoder Layer 1
Decoder_L2: Decoder Layer 2
Decoder_L3: Decoder Layer 3 {
  style.stroke-dash: 3
}
Output: Output Logits

# Encoder forward pass
Input -> Encoder_L1: "embeddings [batch, src_len, d_model]"
Encoder_L1 -> Encoder_L2: "+ residual [batch, src_len, d_model]"
Encoder_L2 -> Encoder_L3: "+ residual [batch, src_len, d_model]"
Encoder_L3 -> Encoder_Out: "encoder_memory [batch, src_len, d_model]"

# Cross-attention: EVERY decoder layer queries encoder
# Layer 1 cross-attention
Encoder_Out -> Decoder_L1.a: K, V from encoder
Decoder_L1 -> Decoder_L1.a: Q from decoder
Decoder_L1.a -> Decoder_L1: cross-attn output

# Layer 2 cross-attention  
Encoder_Out -> Decoder_L2.a: K, V from encoder
Decoder_L2 -> Decoder_L2.a: Q from decoder
Decoder_L2.a -> Decoder_L2: cross-attn output

# Layer 3 cross-attention (showing pattern continues)
Encoder_Out -> Decoder_L3.a: K, V from encoder
Decoder_L3 -> Decoder_L3.a: Q from decoder
Decoder_L3.a -> Decoder_L3: cross-attn output

# Decoder forward pass
Decoder_L1 -> Decoder_L2: "+ residual [batch, tgt_len, d_model]"
Decoder_L2 -> Decoder_L3: "+ residual [batch, tgt_len, d_model]"
Decoder_L3 -> Output: "logits [batch, tgt_len, vocab_size]"

# Styling
Encoder_L1.style.fill: "#E8D5B7"
Encoder_L2.style.fill: "#E8D5B7"
Encoder_L3.style.fill: "#E8D5B7"
Encoder_Out.style.fill: "#D4A574"
Decoder_L1.style.fill: "#B7D5E8"
Decoder_L2.style.fill: "#B7D5E8"
Decoder_L3.style.fill: "#B7D5E8"
Output.style.fill: "#7FB069"

Encoder_Out.tooltip: |md
  **Key Insight**: Encoder output is used by EVERY 
  decoder layer, not just the first or last.
  
  Each decoder layer performs independent 
  cross-attention with full access to source 
  representations.
|