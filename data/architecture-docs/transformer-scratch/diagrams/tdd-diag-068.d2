vars: {
  d2-config: {
    layout-engine: elk
    theme-id: 200
  }
}

title: |md
  # Encoder Output Reuse
  **Encode once, cache, reuse across all decoder steps**
| {near: top-center}

direction: right

classes: {
  encoder_box: {
    style: {
      fill: "#E8D5E0"
      stroke: "#8B5A8B"
      stroke-width: 2
      border-radius: 8
    }
  }
  decoder_box: {
    style: {
      fill: "#D5E8D4"
      stroke: "#5A8B5A"
      stroke-width: 2
      border-radius: 8
    }
  }
  cache_box: {
    style: {
      fill: "#FFF8DC"
      stroke: "#DAA520"
      stroke-width: 2
      stroke-dash: 4
      border-radius: 6
    }
  }
  data_flow: {
    style: {
      stroke: "#4A90D9"
      stroke-width: 2
      animated: true
    }
  }
  cache_flow: {
    style: {
      stroke: "#DAA520"
      stroke-width: 2
      stroke-dash: 4
    }
  }
  reuse_flow: {
    style: {
      stroke: "#2E8B57"
      stroke-width: 2
    }
  }
}

input_tokens: "Input Sequence\n[ batch, seq_len ]" {
  shape: rectangle
  style.fill: "#E3F2FD"
  style.stroke: "#1976D2"
}

encoder_stack: "Encoder Stack\n(6 layers)" {
  class: encoder_box
  
  self_attn: "Self-Attention\n+ FFN × 6"
  layer_norm: "Layer Norm\n+ Residual"
  
  self_attn -> layer_norm
}

encoder_output_cache: "Encoder Output Cache\nK_enc, V_enc\n[ batch, src_len, d_model ]" {
  class: cache_box
  shape: cylinder
}

decoder_steps: "Decoder Steps\n(t = 1, 2, 3, ... T)" {
  class: decoder_box
  
  step1: "Step 1:\n<t_start>"
  step2: "Step 2:\n<t_start> <w1>"
  step3: "Step 3:\n<t_start> <w1> <w2>"
  step_n: "Step N:\n<full sequence>"
  
  step1 -> step2 -> step3 -> step_n: {
    style.stroke: "#5A8B5A"
    style.stroke-dash: 3
  }
}

output_tokens: "Output Tokens\n[ batch, tgt_len ]" {
  shape: rectangle
  style.fill: "#E8F5E9"
  style.stroke: "#388E3C"
}

input_tokens -> encoder_stack: "encode once" {class: data_flow}
encoder_stack -> encoder_output_cache: "cache\nK, V" {class: cache_flow}
encoder_output_cache -> decoder_steps.step1: "cross-attention\nK, V reuse" {class: reuse_flow}
encoder_output_cache -> decoder_steps.step2: "cross-attention\nK, V reuse" {class: reuse_flow}
encoder_output_cache -> decoder_steps.step3: "cross-attention\nK, V reuse" {class: reuse_flow}
encoder_output_cache -> decoder_steps.step_n: "cross-attention\nK, V reuse" {class: reuse_flow}
decoder_steps -> output_tokens: "generate" {class: data_flow}

annotation: |md
  **Key Insight**: Cross-attention uses cached encoder outputs as K and V.
  - Query Q comes from decoder state at each step
  - Keys K and Values V are **fixed** from encoder
  - Same K, V used for ALL decoder steps
  - Complexity: O(n × m) per step, not O(m²) re-encode
| {near: bottom-center}