{"html":"<h1 id=\"-project-charter-event-loop-with-epoll\">ðŸŽ¯ Project Charter: Event Loop with epoll</h1>\n<h2 id=\"what-you-are-building\">What You Are Building</h2>\n<p>A high-performance, single-threaded server capable of handling 10,000+ concurrent connections (the &quot;C10K&quot; problem) using Linux&#39;s <code>epoll</code> facility and the Reactor pattern. You are building the foundational architecture used by NGINX, Redis, and Node.js: an event-driven core that manages non-blocking sockets, manual write-buffer backpressure, a min-heap timer system for idle timeouts, and an incremental HTTP/1.1 protocol parser.</p>\n<h2 id=\"why-this-project-exists\">Why This Project Exists</h2>\n<p>Modern high-scale systems achieve massive concurrency not by adding more threads, but by eliminating them. Building an event loop from scratch is the only way to understand how a single CPU core can manage thousands of connections without the devastating overhead of context switching. You will move past &quot;using&quot; async/await and learn the raw kernel mechanics of readiness notification and non-blocking I/O.</p>\n<h2 id=\"what-you-will-be-able-to-do-when-done\">What You Will Be Able to Do When Done</h2>\n<ul>\n<li>Implement <code>epoll</code> based I/O multiplexing with both Level-Triggered and Edge-Triggered semantics.</li>\n<li>Manage asynchronous backpressure by implementing per-connection write buffers and <code>EPOLLOUT</code> lifecycle management.</li>\n<li>Build a high-performance min-heap priority queue to manage thousands of concurrent connection timeouts.</li>\n<li>Design a Reactor-pattern API that abstracts raw syscalls into a clean, callback-based event system.</li>\n<li>Successfully benchmark and tune a Linux server to handle 10,000+ simultaneous connections with sub-100ms p99 latency.</li>\n</ul>\n<h2 id=\"final-deliverable\">Final Deliverable</h2>\n<p>A robust C or Rust systems project (~2,500+ lines) including a reusable Reactor library and a static file HTTP/1.1 server. The project features a comprehensive test suite for protocol fragmentation and a validated benchmark report demonstrating stable performance under 10,000 concurrent connections using tools like <code>wrk</code>.</p>\n<h2 id=\"is-this-project-for-you\">Is This Project For You?</h2>\n<p><strong>You should start this if you:</strong></p>\n<ul>\n<li>Are comfortable with C pointers, manual memory management, and <code>struct</code> design.</li>\n<li>Understand the basics of the TCP 3-way handshake and the standard socket API (<code>socket</code>, <code>bind</code>, <code>listen</code>).</li>\n<li>Want to transition from &quot;web developer&quot; to &quot;systems engineer&quot; by understanding the &quot;magic&quot; inside your runtime.</li>\n</ul>\n<p><strong>Come back after you&#39;ve learned:</strong></p>\n<ul>\n<li>Basic TCP socket programming (build a simple blocking &quot;Hello World&quot; echo server first).</li>\n<li>Standard C data structures (you should know how to implement a basic linked list or array-based queue).</li>\n</ul>\n<h2 id=\"estimated-effort\">Estimated Effort</h2>\n<table>\n<thead>\n<tr>\n<th>Phase</th>\n<th>Time</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>epoll Basics: Level-Triggered and Edge-Triggered</td>\n<td>~6-8 hours</td>\n</tr>\n<tr>\n<td>Write Buffering and Timer Management</td>\n<td>~5-8 hours</td>\n</tr>\n<tr>\n<td>Reactor API and Callback Dispatch</td>\n<td>~5-8 hours</td>\n</tr>\n<tr>\n<td>HTTP Server on Event Loop (C10K Target)</td>\n<td>~6-10 hours</td>\n</tr>\n<tr>\n<td><strong>Total</strong></td>\n<td><strong>~22-35 hours</strong></td>\n</tr>\n</tbody></table>\n<h2 id=\"definition-of-done\">Definition of Done</h2>\n<p>The project is complete when:</p>\n<ul>\n<li>The server successfully passes a C10K load test (10,000 concurrent connections) with zero dropped requests.</li>\n<li>The incremental HTTP parser correctly handles &quot;fragmented&quot; requests (headers split across multiple <code>read()</code> calls).</li>\n<li>Idle connections are automatically closed by the timer system after a 30-second timeout.</li>\n<li>Valgrind/ASAN reports zero memory leaks or use-after-free errors during high-churn connection tests.</li>\n<li>Static files are served with correct <code>Content-Length</code> and <code>Content-Type</code> headers.</li>\n</ul>\n<hr>\n<h1 id=\"-before-you-read-this-prerequisites-amp-further-reading\">ðŸ“š Before You Read This: Prerequisites &amp; Further Reading</h1>\n<blockquote>\n<p><strong>Read these first.</strong> The Atlas assumes you are familiar with the foundations below.\nResources are ordered by when you should encounter them â€” some before you start, some at specific milestones.</p>\n</blockquote>\n<h3 id=\"1-the-genesis-of-high-concurrency\">1. The Genesis of High Concurrency</h3>\n<p><strong>Concept</strong>: The C10K Problem</p>\n<ul>\n<li><strong>Paper</strong>: <a href=\"http://www.kegel.com/c10k.html\">The C10K Problem</a> by Dan Kegel (1999).</li>\n<li><strong>Why</strong>: The historical catalyst that moved the industry from thread-per-connection to event-driven architectures.</li>\n<li><strong>Pedagogical Timing</strong>: Read <strong>BEFORE Milestone 1</strong>. It provides the necessary context for why <code>select()</code> and <code>poll()</code> failed and why <code>epoll</code> was invented.</li>\n</ul>\n<h3 id=\"2-linux-kernel-io-multiplexing\">2. Linux Kernel I/O Multiplexing</h3>\n<p><strong>Concept</strong>: epoll Semantics and Internal Implementation</p>\n<ul>\n<li><strong>Spec</strong>: <a href=\"https://man7.org/linux/man-pages/man7/epoll.7.html\">epoll(7) Manual Page</a> by Michael Kerrisk.</li>\n<li><strong>Code</strong>: <a href=\"https://github.com/torvalds/linux/blob/master/fs/eventpoll.c\">linux/fs/eventpoll.c</a> â€” specifically the <code>ep_poll_callback</code> function.</li>\n<li><strong>Best Explanation</strong>: <a href=\"https://man7.org/tlpi/\">The Linux Programming Interface</a> (Book) by Michael Kerrisk, <strong>Chapter 63 (Alternative I/O Models)</strong>.</li>\n<li><strong>Why</strong>: The &quot;Bible&quot; of Linux system programming; the chapter on epoll is the most rigorous explanation of Edge-Triggered vs. Level-Triggered behavior in existence.</li>\n<li><strong>Pedagogical Timing</strong>: Read <strong>during Milestone 1</strong>. Refer to the spec while implementing your first <code>epoll_wait</code> loop to understand flag nuances like <code>EPOLLONESHOT</code> and <code>EPOLLET</code>.</li>\n</ul>\n<h3 id=\"3-the-reactor-design-pattern\">3. The Reactor Design Pattern</h3>\n<p><strong>Concept</strong>: Event Demultiplexing and Dispatching</p>\n<ul>\n<li><strong>Paper</strong>: <a href=\"https://www.dre.vanderbilt.edu/~schmidt/PDF/reactor-siemens.pdf\">Reactor: An Object Behavioral Pattern for Demultiplexing and Dispatching Handles for Synchronous Events</a> by Douglas C. Schmidt (1995).</li>\n<li><strong>Code</strong>: <a href=\"https://github.com/redis/redis/blob/7.2/src/ae.c\">Redis: ae.c</a>.</li>\n<li><strong>Best Explanation</strong>: <a href=\"https://gee.cs.oswego.edu/dl/cpjslides/nio.pdf\">Scalable IO in Java</a> (Slide Deck) by Doug Lea. </li>\n<li><strong>Why</strong>: Redisâ€™s <code>ae.c</code> is the cleanest, most readable production-grade implementation of a Reactor in the C language.</li>\n<li><strong>Pedagogical Timing</strong>: Read <strong>BEFORE Milestone 3</strong>. Schmidtâ€™s paper provides the theoretical blueprint, while Doug Leaâ€™s slides provide a visual mental model of the dispatcher/handler relationship.</li>\n</ul>\n<h3 id=\"4-efficient-timing-amp-priority-queues\">4. Efficient Timing &amp; Priority Queues</h3>\n<p><strong>Concept</strong>: Min-Heaps for Timeout Management</p>\n<ul>\n<li><strong>Code</strong>: <a href=\"https://github.com/libuv/libuv/blob/v1.x/src/timer.c\">libuv: timer.c</a>.</li>\n<li><strong>Best Explanation</strong>: <a href=\"https://mitpress.mit.edu/9780262046305/introduction-to-algorithms/\">Introduction to Algorithms (CLRS)</a>, <strong>Chapter 6 (Heapsort)</strong>.</li>\n<li><strong>Why</strong>: Libuv (Node.jsâ€™s core) uses a min-heap for its timers; studying their <code>uv__timer_close</code> demonstrates how to handle the &quot;arbitrary deletion&quot; problem in O(log N).</li>\n<li><strong>Pedagogical Timing</strong>: Read <strong>during Milestone 2</strong>. You will need the sift-up/sift-down algorithms to implement the idle-connection reaper.</li>\n</ul>\n<h3 id=\"5-http11-protocol-amp-parsing\">5. HTTP/1.1 Protocol &amp; Parsing</h3>\n<p><strong>Concept</strong>: Framing and Persistent Connections</p>\n<ul>\n<li><strong>Spec</strong>: <a href=\"https://datatracker.ietf.org/doc/html/rfc7230\">RFC 7230: HTTP/1.1 Message Syntax and Routing</a>.</li>\n<li><strong>Code</strong>: <a href=\"https://github.com/h2o/picohttpparser/blob/master/picohttpparser.c\">PicoHTTPParser</a>.</li>\n<li><strong>Best Explanation</strong>: <a href=\"https://hpbn.co/http1x/\">High Performance Browser Networking</a> (Book) by Ilya Grigorik, <strong>Chapter 9 (HTTP 1.1)</strong>.</li>\n<li><strong>Why</strong>: PicoHTTPParser shows how to use SSE4.2/AVX2 instructions to scan for <code>\\r\\n</code> significantly faster than standard <code>strstr</code>.</li>\n<li><strong>Pedagogical Timing</strong>: Read <strong>BEFORE Milestone 4</strong>. You must understand the rules for <code>Content-Length</code> and <code>Transfer-Encoding</code> to implement keep-alive correctly.</li>\n</ul>\n<h3 id=\"6-memory-management-and-backpressure\">6. Memory Management and Backpressure</h3>\n<p><strong>Concept</strong>: Write Buffering and User-Space Queuing</p>\n<ul>\n<li><strong>Best Explanation</strong>: <a href=\"https://bravenewgeek.com/you-cannot-have-exactly-once-delivery/\">Notes on Distributed Systems: Backpressure</a> by Tyler Treat.</li>\n<li><strong>Why</strong>: A masterclass in why unbounded buffers lead to cascading failures and how <code>EAGAIN</code> acts as a signal to propagate pressure upstream.</li>\n<li><strong>Pedagogical Timing</strong>: Read <strong>After Milestone 2</strong>. It will help you appreciate why we enforce a <code>WRITE_BUF_MAX</code> instead of letting the buffer grow to match the request size.</li>\n</ul>\n<h3 id=\"7-zero-copy-optimizations\">7. Zero-Copy Optimizations</h3>\n<p><strong>Concept</strong>: <code>sendfile(2)</code> and Kernel-Space Data Transfer</p>\n<ul>\n<li><strong>Spec</strong>: <a href=\"https://man7.org/linux/man-pages/man2/sendfile.2.html\">sendfile(2) Manual Page</a>.</li>\n<li><strong>Code</strong>: <a href=\"https://github.com/nginx/nginx/blob/master/src/os/unix/ngx_linux_sendfile_chain.c\">Nginx: ngx_linux_sendfile_chain.c</a>.</li>\n<li><strong>Why</strong>: Nginx is the gold standard for high-performance static file serving; their implementation handles the complexity of <code>sendfile</code> returning partial results.</li>\n<li><strong>Pedagogical Timing</strong>: Read <strong>After Milestone 4</strong> as an &quot;Extra Credit&quot; optimization to replace your manual read/write loop for static files.</li>\n</ul>\n<h3 id=\"8-the-future-asynchronous-completion-io\">8. The Future: Asynchronous Completion I/O</h3>\n<p><strong>Concept</strong>: io_uring (The Proactor Pattern on Linux)</p>\n<ul>\n<li><strong>Paper</strong>: <a href=\"https://kernel.dk/io_uring.pdf\">Efficient IO with io_uring</a> by Jens Axboe (2019).</li>\n<li><strong>Why</strong>: Written by the lead maintainer of the Linux block layer, this explains why the Reactor/epoll model is being superseded by completion queues.</li>\n<li><strong>Pedagogical Timing</strong>: Read <strong>after completing the project</strong>. It provides a &quot;what&#39;s next&quot; perspective on how to further reduce syscall overhead and context switching.</li>\n</ul>\n<hr>\n<h1 id=\"event-loop-with-epoll-building-a-reactor-pattern-server-from-scratch\">Event Loop with epoll: Building a Reactor-Pattern Server from Scratch</h1>\n<p>This project builds a single-threaded, high-concurrency server capable of handling 10,000+ simultaneous connections using Linux&#39;s epoll I/O multiplexing facility and the reactor pattern. You will start from raw epoll syscallsâ€”understanding the critical difference between edge-triggered and level-triggered semanticsâ€”then layer on write buffering with backpressure, timer management for idle timeouts, a clean reactor API that hides kernel details behind callbacks, and finally a complete HTTP/1.1 server that demonstrates the C10K capability.</p>\n<p>The architecture you build here is the exact foundation of NGINX, Redis, Node.js&#39;s libuv, and Tokio&#39;s mio. By implementing it yourself in C, you&#39;ll understand why these systems are single-threaded yet outperform multi-threaded alternatives, how they handle slow clients without blocking fast ones, and why edge-triggered epoll demands a fundamentally different coding discipline than the select/poll model most developers learn first.</p>\n<p>Every milestone produces a working, testable artifact: an echo server, a timer-driven connection reaper, a reactor library, and a benchmarked HTTP server. The progression is designed so that each layer reveals why the previous layer&#39;s naive approach breaks under load, creating a chain of &#39;aha&#39; moments that connect kernel internals to application architecture.</p>\n<!-- MS_ID: build-event-loop-m1 -->\n<h1 id=\"epoll-basics-level-triggered-and-edge-triggered\">epoll Basics: Level-Triggered and Edge-Triggered</h1>\n<h2 id=\"the-problem-that-makes-single-threaded-servers-hard\">The Problem That Makes Single-Threaded Servers Hard</h2>\n<p>Before you write a single line of epoll code, you need to feel the constraint that makes all of this necessary. Let&#39;s start with what you already know how to build.\nThe classic server model is simple: call <code>accept()</code> to get a new connection, hand it to a thread, and let that thread call <code>read()</code> to wait for data. The thread blocksâ€”suspended by the kernelâ€”until bytes arrive, then processes them, then blocks again. This works beautifully until you need to handle 10,000 connections simultaneously.\nTen thousand threads. Each thread needs a stack (commonly 8 MB default, though you&#39;d tune it down to 64â€“128 KB for a server). At 64 KB per thread, 10,000 threads consume 640 MB of RAM just for stacksâ€”before you store a single byte of application data. And RAM is the optimistic problem. The real killer is context switching: each time the kernel switches from one thread to another, it must save all CPU registers, flush parts of the TLB (the CPU&#39;s translation lookaside buffer, which caches virtual-to-physical address mappings), and potentially evict hot cache lines. At 10,000 threads with even modest activity, you spend more CPU time switching contexts than doing actual work.</p>\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Fdiag-m1-before-after-blocking-vs-nonblocking.svg\" alt=\"Before/After: Thread-per-Connection vs epoll Event Loop\"></p>\n<p>The kernel already knows which file descriptors have data ready. It maintains this information internally. The question is: how do you ask the kernel &quot;which of my 10,000 file descriptors are ready right now?&quot; without blocking on each one individually?\nThat&#39;s the problem <code>epoll</code> solves.</p>\n<blockquote>\n<p><strong>ðŸ”‘ Foundation: I/O multiplexing</strong></p>\n<p><strong>1. What it IS</strong>\nI/O Multiplexing is a technique that allows a single process or thread to monitor multiple file descriptors (FDs)â€”such as network socketsâ€”simultaneously. Instead of the application &quot;polling&quot; each socket one by one or getting stuck waiting for a single connection to respond, the application asks the operating system kernel to wake it up only when one or more of those sockets are actually ready for reading or writing.</p>\n</blockquote>\n<p><strong>2. Why you need it right now</strong>\nIn high-concurrency networking, the traditional &quot;thread-per-connection&quot; model fails. If you want to handle 10,000 concurrent users, creating 10,000 threads would consume massive amounts of memory (for thread stacks) and devastate performance due to CPU context-switching overhead. Multiplexing allows you to scale to thousands of connections using a single thread, keeping your memory footprint low and your CPU focused on processing data rather than managing thread lifecycles.</p>\n<p><strong>3. Key Insight: The Pager System</strong>\nImagine a waiter in a restaurant. Instead of standing at one table and waiting ten minutes for a guest to choose an appetizer (Blocking I/O), or running from table to table every ten seconds asking &quot;Are you ready yet?&quot; (Polling), the waiter gives every table a <strong>pager</strong>. The waiter can then relax or do other tasks; when a guest is ready, their pager buzzes. The waiter handles only the tables that signaled they are ready.</p>\n<h2 id=\"epoll-in-context-what-came-before\">epoll in Context: What Came Before</h2>\n<blockquote>\n<p><strong>ðŸ”‘ Foundation: epoll vs select/poll</strong></p>\n<p><strong>1. What it IS</strong>\n<code>select</code>, <code>poll</code>, and <code>epoll</code> are all system calls used for I/O multiplexing, but they differ in how they track which sockets are ready. <code>select</code> and <code>poll</code> are the older &quot;stateless&quot; methods, while <code>epoll</code> (exclusive to Linux) is a &quot;stateful&quot; event-notification facility.</p>\n</blockquote>\n<p><strong>2. Why you need it right now</strong>\nAt low connection counts (e.g., 10â€“100), the difference is negligible. However, <code>select</code> and <code>poll</code> have $O(N)$ complexity. Every time you call them, you must pass the entire list of FDs to the kernel, and the kernel must scan the entire list to see which ones are active. As you move toward 10,000+ FDs (the &quot;C10k problem&quot;), this scanning process becomes a massive bottleneck. <code>epoll</code> solves this by maintaining an &quot;interest list&quot; within the kernel itself. When a socket becomes ready, the kernel places it in a &quot;ready list.&quot; The application then calls <code>epoll_wait</code> and receives only the FDs that actually have events, making it $O(1)$ relative to the total number of connections.</p>\n<p><strong>3. Key Insight: Roll Call vs. The Sign-in Sheet</strong>\n<code>select</code> and <code>poll</code> are like a teacher performing a <strong>Roll Call</strong>: every morning, they must read every single name on the 1,000-person roster to see who is present. <code>epoll</code> is like a <strong>Sign-in Sheet</strong>: the teacher leaves a paper at the door, and only the students who actually show up write their names down. The teacher only has to look at the few names on the sheet to know who is ready.</p>\n<p>The short version: <code>select()</code> and <code>poll()</code> both require you to pass the <em>entire</em> set of file descriptors you&#39;re interested in on every call. For 10,000 FDs, that&#39;s copying a 10,000-element array into the kernel on every call, and the kernel scans the entire array to find ready ones. <code>epoll</code> inverts this: you register interest once with <code>epoll_ctl()</code>, and <code>epoll_wait()</code> returns only the ready eventsâ€”no full scan, no array copying.</p>\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Fdiag-satellite-system-map.svg\" alt=\"Satellite Map: Event Loop Architecture Overview\"></p>\n<h2 id=\"in-the-system-map-this-milestone-builds-the-foundation-layer-the-epoll-instance-and-the-non-blocking-socket-infrastructure-that-everything-above-it-depends-on\">In the system map, this milestone builds the foundation layer: the epoll instance and the non-blocking socket infrastructure that everything above it depends on.</h2>\n<h2 id=\"the-revelation-et-and-lt-are-different-contracts-not-different-speeds\">The Revelation: ET and LT Are Different Contracts, Not Different Speeds</h2>\n<p>Most developers who learn about epoll&#39;s edge-triggered mode read something like &quot;edge-triggered is more efficient than level-triggered&quot; and conclude: add <code>EPOLLET</code> to your flags for a free performance upgrade. This is the misconception that causes subtle, hard-to-reproduce data loss bugs.\nHere is the actual contract each mode makes with you:\n<strong>Level-Triggered (LT)</strong> says: <em>&quot;As long as there is data in the socket&#39;s receive buffer that you haven&#39;t read yet, I will report this file descriptor as readable on every call to <code>epoll_wait</code>.&quot;</em>\n<strong>Edge-Triggered (ET)</strong> says: <em>&quot;I will report this file descriptor as readable exactly onceâ€”when the kernel receives new data that transitions the buffer from empty to non-empty (or adds to existing unread data). After that, it&#39;s your responsibility to drain all the data. I will not remind you again until new data arrives from the network.&quot;</em>\nRead that second contract again. If 5,000 bytes arrive in the kernel&#39;s receive buffer and you read 1,024 bytes, LT will wake you up again on the next <code>epoll_wait</code>â€”there&#39;s still data. ET will <em>not</em> wake you up. It told you once. The remaining 3,976 bytes will sit in the receive buffer, invisible to you, until the remote end sends <em>more</em> dataâ€”at which point ET fires again, but now you have 3,976 stale bytes plus whatever just arrived, all mixed together.\nUnder controlled testing (small messages, quiet network), ET and LT look identical, because each message fits in a single <code>read()</code> call. Under load (large payloads, pipelined requests, bursts), ET with single-read-per-event silently drops data. The bug is timing-dependent and disappears in a debugger.</p>\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Fdiag-m1-lt-vs-et-data-walk.svg\" alt=\"Data Walk: Level-Triggered vs Edge-Triggered Read Behavior\"></p>\n<h2 id=\"this-is-not-a-performance-difference-it-is-a-different-programming-model-that-demands-different-code\">This is not a performance difference. It is a <strong>different programming model</strong> that demands different code.</h2>\n<h2 id=\"building-the-foundation-non-blocking-sockets\">Building the Foundation: Non-Blocking Sockets</h2>\n<p>Before epoll can work correctly, every socket must be in non-blocking mode. Let&#39;s understand why.</p>\n<blockquote>\n<p><strong>ðŸ”‘ Foundation: Blocking vs non-blocking I/O</strong></p>\n<p><strong>1. What it IS</strong>\nIn <strong>Blocking I/O</strong>, when you call <code>read()</code>, the kernel puts your thread to sleep until data arrives. In <strong>Non-blocking I/O</strong>, the call returns immediately. If data is ready, you get the data; if not, the kernel returns a specific error code: <code>EAGAIN</code> or <code>EWOULDBLOCK</code>.</p>\n</blockquote>\n<p><strong>2. Why you need it right now</strong>\nI/O Multiplexing (like <code>epoll</code>) only tells you that a socket <em>has</em> data. It doesn&#39;t tell you <em>how much</em>. If you use a blocking <code>read()</code> on a socket that <code>epoll</code> flagged, but you try to read 1024 bytes and only 500 are available, your entire thread will &quot;freeze&quot; while waiting for the remaining 524 bytes. In an event-driven server, this would stop the server from processing all other 9,999 clients. You must set your sockets to non-blocking mode so that you can read what is available and immediately move on if the source runs dry.</p>\n<p><strong>3. Key Insight: EAGAIN is not an Error</strong>\nIn non-blocking I/O, receiving an <code>EAGAIN</code> result is not a failure; it is a <strong>&quot;Call me back later&quot;</strong> message. It is the kernel telling you: &quot;I&#39;ve given you everything I have for now; go do something else and I&#39;ll notify you via the multiplexer when more arrives.&quot;</p>\n<p>In non-blocking mode, <code>read()</code> and <code>write()</code> return immediately. If there&#39;s no data to read, they return <code>-1</code> and set <code>errno</code> to <code>EAGAIN</code> (or its synonym <code>EWOULDBLOCK</code>â€”the kernel may use either; always check both, or check <code>errno == EAGAIN || errno == EWOULDBLOCK</code>). This is <em>not</em> an error. It means &quot;the kernel&#39;s buffer is empty right now; try again later.&quot; Your event loop handles the &quot;try again later&quot; part by going back to <code>epoll_wait</code>.\nHere&#39;s how you configure a socket for non-blocking mode:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;fcntl.h></span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * set_nonblocking - Configure a file descriptor for non-blocking I/O.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Returns 0 on success, -1 on failure (with errno set).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Why fcntl F_GETFL + F_SETFL: We must read existing flags first</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * to preserve them (e.g., O_RDWR, O_APPEND). Overwriting with just</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * O_NONBLOCK would clear all other flags, corrupting the fd's behavior.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\"> set_nonblocking</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> flags </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> fcntl</span><span style=\"color:#E1E4E8\">(fd, F_GETFL, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (flags </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#B392F0\"> fcntl</span><span style=\"color:#E1E4E8\">(fd, F_SETFL, flags </span><span style=\"color:#F97583\">|</span><span style=\"color:#E1E4E8\"> O_NONBLOCK);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<blockquote>\n<p><strong>Why <code>F_GETFL</code> before <code>F_SETFL</code>?</strong> The flags field holds multiple properties. If you write <code>fcntl(fd, F_SETFL, O_NONBLOCK)</code> directly, you erase <code>O_RDWR</code>, <code>O_APPEND</code>, and any other flags that were set. Always read first, then OR in your new flag.\nAn alternative on Linux is <code>accept4()</code> with <code>SOCK_NONBLOCK</code>, which creates the accepted socket already in non-blocking mode. We&#39;ll use this shortly to save the extra <code>fcntl</code> call on each accepted connection.</p>\n</blockquote>\n<hr>\n<h2 id=\"creating-the-epoll-instance\">Creating the epoll Instance</h2>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;sys/epoll.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;unistd.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdio.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdlib.h></span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * create_epoll - Create an epoll instance.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * epoll_create1(EPOLL_CLOEXEC):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   - EPOLL_CLOEXEC: automatically close the epoll fd if this process</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *     calls exec(). Without this flag, child processes after fork/exec</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *     inherit the epoll fd, which prevents the kernel from cleaning up</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *     the epoll interest list and leaks it into child processes.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   - The argument to epoll_create1 is a flags field, not a size hint</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *     (epoll_create's size argument is ignored since Linux 2.6.8 but</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *     must still be nonzero; epoll_create1 eliminates this confusion).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Returns: epoll file descriptor (> 0), or exits on failure.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\"> create_epoll</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> epoll_fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> epoll_create1</span><span style=\"color:#E1E4E8\">(EPOLL_CLOEXEC);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (epoll_fd </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        perror</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"epoll_create1\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        exit</span><span style=\"color:#E1E4E8\">(EXIT_FAILURE);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> epoll_fd;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<p>The epoll instance is itself a file descriptor. It refers to a kernel data structure that maintains two lists: the <strong>interest list</strong> (every fd you&#39;ve registered with <code>epoll_ctl</code>) and the <strong>ready list</strong> (fds that have events waiting). <code>epoll_wait</code> efficiently pulls from the ready list.\n{{DIAGRAM:diag-m1-epoll-syscall-flow}}</p>\n<h3 id=\"registering-file-descriptors\">Registering File Descriptors</h3>\n<p><code>epoll_ctl</code> takes four arguments: the epoll fd, an operation (<code>EPOLL_CTL_ADD</code>, <code>EPOLL_CTL_MOD</code>, or <code>EPOLL_CTL_DEL</code>), the target fd, and a pointer to an <code>epoll_event</code> struct:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">struct</span><span style=\"color:#E1E4E8\"> epoll_event {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint32_t</span><span style=\"color:#E1E4E8\">     events;</span><span style=\"color:#6A737D\">   /* event mask: EPOLLIN, EPOLLOUT, EPOLLET, etc. */</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    epoll_data_t</span><span style=\"color:#E1E4E8\"> data;</span><span style=\"color:#6A737D\">     /* union: ptr, fd, u32, u64 â€” your choice */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">};</span></span></code></pre></div>\n<p>The <code>data</code> field is a union you control entirely. Whatever you put in when registering, you get back when the event fires. For simple cases, store the fd. For the full reactor pattern (Milestone 3), you&#39;ll store a pointer to the per-connection state structure.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * epoll_add - Register fd for EPOLLIN events with epoll.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Stores fd in data.fd for retrieval in epoll_wait results.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\"> epoll_add</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> epoll_fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#FFAB70\"> events</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    struct</span><span style=\"color:#E1E4E8\"> epoll_event ev;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ev.events </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> events;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ev.data.fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> fd;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#B392F0\"> epoll_ctl</span><span style=\"color:#E1E4E8\">(epoll_fd, EPOLL_CTL_ADD, fd, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">ev);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * epoll_mod - Modify existing fd registration (e.g., add EPOLLOUT).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\"> epoll_mod</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> epoll_fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#FFAB70\"> events</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    struct</span><span style=\"color:#E1E4E8\"> epoll_event ev;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ev.events </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> events;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ev.data.fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> fd;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#B392F0\"> epoll_ctl</span><span style=\"color:#E1E4E8\">(epoll_fd, EPOLL_CTL_MOD, fd, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">ev);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * epoll_del - Remove fd from epoll interest list.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * On Linux >= 2.6.9, the event pointer can be NULL here.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\"> epoll_del</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> epoll_fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#B392F0\"> epoll_ctl</span><span style=\"color:#E1E4E8\">(epoll_fd, EPOLL_CTL_DEL, fd, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<hr>\n<h2 id=\"setting-up-the-listening-socket\">Setting Up the Listening Socket</h2>\n<p>The listening socket is your server&#39;s front door. It also must be non-blocking. The reason: if a client initiates a connection and then immediately sends a TCP RST before your <code>accept()</code> call runs (a race that happens under load), a blocking <code>accept()</code> can stall waiting for the <em>next</em> connection. With non-blocking mode, <code>accept()</code> returns <code>EAGAIN</code> immediately and you go back to <code>epoll_wait</code>.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;sys/socket.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;netinet/in.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;string.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> BACKLOG</span><span style=\"color:#79B8FF\"> 128</span><span style=\"color:#6A737D\">  /* listen() backlog: how many connections kernel queues */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> PORT</span><span style=\"color:#79B8FF\">    8080</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * create_listening_socket - Create, bind, and listen a non-blocking TCP socket.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * SO_REUSEADDR: allows rebinding to the port immediately after server restart,</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * bypassing the TCP TIME_WAIT state (which would otherwise block rebind for ~60s).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Returns: listening socket fd, or -1 on failure.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\"> create_listening_socket</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> listen_fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> socket</span><span style=\"color:#E1E4E8\">(AF_INET, SOCK_STREAM </span><span style=\"color:#F97583\">|</span><span style=\"color:#E1E4E8\"> SOCK_NONBLOCK </span><span style=\"color:#F97583\">|</span><span style=\"color:#E1E4E8\"> SOCK_CLOEXEC, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (listen_fd </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        perror</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"socket\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* SO_REUSEADDR: don't wait for TIME_WAIT to expire on restart */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> opt </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">setsockopt</span><span style=\"color:#E1E4E8\">(listen_fd, SOL_SOCKET, SO_REUSEADDR, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">opt, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(opt)) </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        perror</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"setsockopt SO_REUSEADDR\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        close</span><span style=\"color:#E1E4E8\">(listen_fd);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    struct</span><span style=\"color:#E1E4E8\"> sockaddr_in addr;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    memset</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">addr, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(addr));</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    addr.sin_family      </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> AF_INET;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    addr.sin_addr.s_addr </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> INADDR_ANY;</span><span style=\"color:#6A737D\">  /* listen on all interfaces */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    addr.sin_port        </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> htons</span><span style=\"color:#E1E4E8\">(PORT);</span><span style=\"color:#6A737D\"> /* htons: host-to-network byte order */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">bind</span><span style=\"color:#E1E4E8\">(listen_fd, (</span><span style=\"color:#F97583\">struct</span><span style=\"color:#E1E4E8\"> sockaddr </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">)</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">addr, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(addr)) </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        perror</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"bind\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        close</span><span style=\"color:#E1E4E8\">(listen_fd);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">listen</span><span style=\"color:#E1E4E8\">(listen_fd, BACKLOG) </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        perror</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"listen\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        close</span><span style=\"color:#E1E4E8\">(listen_fd);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> listen_fd;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<blockquote>\n<p><strong><code>SOCK_NONBLOCK | SOCK_CLOEXEC</code> in the <code>socket()</code> call</strong>: Linux allows ORing these flags directly into <code>socket()</code>&#39;s type argument since kernel 2.6.27. This avoids a race condition between <code>socket()</code> and a subsequent <code>fcntl()</code> where a signal could deliver between the two calls in a multi-threaded program. In a single-threaded event loop it&#39;s less critical, but it&#39;s good practice.\n<strong><code>htons(PORT)</code></strong>: Network protocols specify big-endian byte order for port numbers. <code>htons</code> (host-to-network-short) converts from the host&#39;s native byte order (likely little-endian on x86) to network byte order. Forgetting this causes your server to listen on the wrong portâ€”a classic source of &quot;why can&#39;t I connect?&quot; confusion.</p>\n</blockquote>\n<hr>\n<h2 id=\"per-connection-state-the-fd-state-map\">Per-Connection State: The fd â†’ State Map</h2>\n<p>Every active connection needs associated state: a read buffer, a write buffer, timers, and protocol parsing position. Since file descriptors are small non-negative integers, the most cache-friendly structure is a flat array indexed by fd value. The kernel guarantees fd values are less than the process&#39;s open file limit (by default 1,024 in many systems; configurable up to millions with <code>ulimit -n</code> and <code>/proc/sys/fs/file-max</code>).</p>\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Fdiag-m1-connection-state-struct.svg\" alt=\"Per-Connection State Structure: Memory Layout\"></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdint.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdbool.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> MAX_FDS</span><span style=\"color:#79B8FF\">       65536</span><span style=\"color:#6A737D\">   /* size of fdâ†’state array; must exceed ulimit -n */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> READ_BUF_SIZE</span><span style=\"color:#79B8FF\"> 4096</span><span style=\"color:#6A737D\">    /* one page; aligns with typical MTU and kernel recv buffer chunks */</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * conn_state - Per-connection state stored in the fd array.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Memory layout analysis (on 64-bit Linux):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   offset  0: read_buf[4096]   = 4096 bytes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   offset  4096: read_len      = 4 bytes (uint32_t)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   offset  4100: fd            = 4 bytes (int)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   offset  4104: active        = 1 byte (bool)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   offset  4105: [padding]     = 7 bytes (compiler aligns next field)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   Total: ~4112 bytes per connection</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * At 10,000 connections: 10,000 Ã— 4112 â‰ˆ 40 MB resident memory.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * The read_buf is the dominant cost â€” larger buffers mean fewer read() calls</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * but more memory footprint. 4096 is a common trade-off.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Cache note: read_buf[0..63] fits in one 64-byte cache line. Sequential</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * access to read_buf (filling it byte-by-byte) is prefetch-friendly.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * The conn_state structs themselves are too large to fit in L1 (32 KB),</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * so accessing state for a new connection will be an L2 or L3 cache miss.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\">     read_buf</span><span style=\"color:#E1E4E8\">[READ_BUF_SIZE];</span><span style=\"color:#6A737D\"> /* incoming bytes accumulate here */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint32_t</span><span style=\"color:#E1E4E8\"> read_len;</span><span style=\"color:#6A737D\">                /* bytes currently in read_buf */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\">      fd;</span><span style=\"color:#6A737D\">                      /* the file descriptor this represents */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\">     active;</span><span style=\"color:#6A737D\">                  /* is this slot in use? */</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Milestone 2 will add: write buffer, timer linkage */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} conn_state;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/* Global fdâ†’state array. Indexed directly by fd value. */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#E1E4E8\"> conn_state </span><span style=\"color:#FFAB70\">connections</span><span style=\"color:#E1E4E8\">[MAX_FDS];</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * conn_init - Initialize a new connection's state slot.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Called immediately after accept().</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> conn_init</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    conn_state </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">c </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#FFAB70\">connections</span><span style=\"color:#E1E4E8\">[fd];</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    c->fd       </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> fd;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    c->read_len </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    c->active   </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* No need to zero read_buf â€” we track length in read_len */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * conn_close - Clean up a connection's state slot and close its fd.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Must be called on any exit path: client disconnect, error, timeout.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> conn_close</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> epoll_fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    conn_state </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">c </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#FFAB70\">connections</span><span style=\"color:#E1E4E8\">[fd];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">c->active) </span><span style=\"color:#F97583\">return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    c->active   </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    c->read_len </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    c->fd       </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Remove from epoll before closing fd. Closing fd auto-removes it from</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">     * epoll on Linux (kernel does this when fd refcount drops to zero), but</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">     * explicit removal is safer and required if fd was dup()'d. */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    epoll_ctl</span><span style=\"color:#E1E4E8\">(epoll_fd, EPOLL_CTL_DEL, fd, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    close</span><span style=\"color:#E1E4E8\">(fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<blockquote>\n<p><strong>Why an array and not a hash map?</strong> File descriptors are already sparse integers in a bounded range. An array gives O(1) lookup with zero hash computation and excellent cache locality for sequential fd values. A hash map&#39;s overheadâ€”hashing, collision chains, pointer chasingâ€”is pure cost with no benefit when the key space is already integer-indexed. This is a common pattern in kernel-adjacent code: Redis uses a similar <code>ae_file_event *events</code> array in <code>ae.c</code>.</p>\n</blockquote>\n<hr>\n<h2 id=\"the-level-triggered-event-loop\">The Level-Triggered Event Loop</h2>\n<p>Now we have all the pieces. Here&#39;s a complete level-triggered event loop that drives an echo server:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;errno.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdio.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> MAX_EVENTS</span><span style=\"color:#79B8FF\"> 1024</span><span style=\"color:#6A737D\">  /* events to retrieve per epoll_wait call */</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * handle_new_connection_lt - Accept all pending connections in LT mode.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * In LT mode, we can accept one connection per EPOLLIN on the listen fd,</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * because if more connections are pending, epoll_wait will fire again.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * However, accepting in a loop until EAGAIN is still better practice:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * it reduces epoll_wait round trips under high connection rates.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * We use accept4() with SOCK_NONBLOCK | SOCK_CLOEXEC to atomically</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * create non-blocking, close-on-exec client sockets.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> handle_new_connection_lt</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> epoll_fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> listen_fd</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    struct</span><span style=\"color:#E1E4E8\"> sockaddr_in client_addr;</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    socklen_t</span><span style=\"color:#E1E4E8\"> addr_len </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> sizeof</span><span style=\"color:#E1E4E8\">(client_addr);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> client_fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> accept4</span><span style=\"color:#E1E4E8\">(listen_fd, (</span><span style=\"color:#F97583\">struct</span><span style=\"color:#E1E4E8\"> sockaddr </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">)</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">client_addr,</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                            &#x26;</span><span style=\"color:#E1E4E8\">addr_len, SOCK_NONBLOCK </span><span style=\"color:#F97583\">|</span><span style=\"color:#E1E4E8\"> SOCK_CLOEXEC);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (client_fd </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EAGAIN </span><span style=\"color:#F97583\">||</span><span style=\"color:#E1E4E8\"> errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EWOULDBLOCK) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\"> /* no more connections right now */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        perror</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"accept4\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (client_fd </span><span style=\"color:#F97583\">>=</span><span style=\"color:#E1E4E8\"> MAX_FDS) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        fprintf</span><span style=\"color:#E1E4E8\">(stderr, </span><span style=\"color:#9ECBFF\">\"fd </span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#9ECBFF\"> exceeds MAX_FDS, closing</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, client_fd);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        close</span><span style=\"color:#E1E4E8\">(client_fd);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    conn_init</span><span style=\"color:#E1E4E8\">(client_fd);</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Register for EPOLLIN only (LT mode â€” no EPOLLET flag) */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">epoll_add</span><span style=\"color:#E1E4E8\">(epoll_fd, client_fd, EPOLLIN) </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        perror</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"epoll_add client\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        conn_close</span><span style=\"color:#E1E4E8\">(epoll_fd, client_fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * handle_client_read_lt - Read and echo data in level-triggered mode.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * LT contract: epoll will re-notify us if data remains in the buffer.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * So we read ONE chunk per event â€” simple, but may cause extra epoll_wait</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * round trips if more than READ_BUF_SIZE bytes are waiting.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> handle_client_read_lt</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> epoll_fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    conn_state </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">c </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#FFAB70\">connections</span><span style=\"color:#E1E4E8\">[fd];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> buf</span><span style=\"color:#E1E4E8\">[READ_BUF_SIZE];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    ssize_t</span><span style=\"color:#E1E4E8\"> n </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> read</span><span style=\"color:#E1E4E8\">(fd, buf, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(buf));</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (n </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Echo: write it back. For now, assume write succeeds fully.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * Milestone 2 will add proper write buffering for partial writes. */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        ssize_t</span><span style=\"color:#E1E4E8\"> written </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        while</span><span style=\"color:#E1E4E8\"> (written </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> n) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            ssize_t</span><span style=\"color:#E1E4E8\"> w </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> write</span><span style=\"color:#E1E4E8\">(fd, buf </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> written, n </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> written);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (w </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> (errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EAGAIN </span><span style=\"color:#F97583\">||</span><span style=\"color:#E1E4E8\"> errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EWOULDBLOCK) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                    /* Send buffer full; Milestone 2 handles this properly */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    break</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                }</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">                conn_close</span><span style=\"color:#E1E4E8\">(epoll_fd, fd);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            written </span><span style=\"color:#F97583\">+=</span><span style=\"color:#E1E4E8\"> w;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    } </span><span style=\"color:#F97583\">else</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> (n </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Peer closed connection (graceful shutdown / EOF) */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        conn_close</span><span style=\"color:#E1E4E8\">(epoll_fd, fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    } </span><span style=\"color:#F97583\">else</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* n == -1 */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EAGAIN </span><span style=\"color:#F97583\">||</span><span style=\"color:#E1E4E8\"> errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EWOULDBLOCK) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            /* Spurious wakeup: no data right now. Not an error. */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Real error (ECONNRESET, ETIMEDOUT, etc.) */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        conn_close</span><span style=\"color:#E1E4E8\">(epoll_fd, fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * run_event_loop_lt - Level-triggered event loop. Main server loop.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> run_event_loop_lt</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> epoll_fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> listen_fd</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    struct</span><span style=\"color:#E1E4E8\"> epoll_event </span><span style=\"color:#FFAB70\">events</span><span style=\"color:#E1E4E8\">[MAX_EVENTS];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (;;) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * epoll_wait arguments:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         *   epoll_fd   - our epoll instance</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         *   events     - array to fill with ready events</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         *   MAX_EVENTS - max events to return per call</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         *   -1         - timeout: block forever until an event arrives</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         *                (Milestone 2 will replace -1 with timer-derived value)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\"> n_ready </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> epoll_wait</span><span style=\"color:#E1E4E8\">(epoll_fd, events, MAX_EVENTS, </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (n_ready </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EINTR) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                /* Signal interrupted epoll_wait (e.g., SIGCHLD). Not an error. */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                continue</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            perror</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"epoll_wait\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            break</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">; i </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> n_ready; i</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            int</span><span style=\"color:#E1E4E8\"> fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#FFAB70\"> events</span><span style=\"color:#E1E4E8\">[i].data.fd;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            uint32_t</span><span style=\"color:#E1E4E8\"> ev </span><span style=\"color:#F97583\">=</span><span style=\"color:#FFAB70\"> events</span><span style=\"color:#E1E4E8\">[i].events;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (fd </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> listen_fd) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">                handle_new_connection_lt</span><span style=\"color:#E1E4E8\">(epoll_fd, listen_fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            } </span><span style=\"color:#F97583\">else</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> (ev </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\"> (EPOLLERR </span><span style=\"color:#F97583\">|</span><span style=\"color:#E1E4E8\"> EPOLLHUP)) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                /* Error or hang-up: connection is broken */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">                conn_close</span><span style=\"color:#E1E4E8\">(epoll_fd, fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            } </span><span style=\"color:#F97583\">else</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> (ev </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\"> EPOLLIN) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">                handle_client_read_lt</span><span style=\"color:#E1E4E8\">(epoll_fd, fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<h2 id=\"test-this-with-nc-localhost-8080-type-text-hit-enter-and-it-echoes-back-now-try-piping-a-large-file-cat-devurandom-head-c-1000000-nc-localhost-8080-watch-it-work-correctlylt-mode-will-keep-waking-up-the-loop-until-all-the-data-is-read\">Test this with <code>nc localhost 8080</code>. Type text, hit Enter, and it echoes back. Now try piping a large file: <code>cat /dev/urandom | head -c 1000000 | nc localhost 8080</code>. Watch it work correctlyâ€”LT mode will keep waking up the loop until all the data is read.</h2>\n<h2 id=\"the-edge-triggered-event-loop-drain-until-eagain\">The Edge-Triggered Event Loop: Drain Until EAGAIN</h2>\n<p>Now we implement ET mode. The code structure looks similar, but the read handler is fundamentally different:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * handle_new_connection_et - Accept ALL pending connections in ET mode.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * </span><span style=\"color:#F97583\">CRITICAL:</span><span style=\"color:#6A737D\"> In ET mode, EPOLLIN on listen_fd fires ONCE when new connections</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * arrive. If 5 clients connect between epoll_wait calls, we get ONE wakeup.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * We MUST loop until accept() returns EAGAIN, or we miss connections entirely.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * This is the same \"drain until EAGAIN\" discipline applied to the listen socket.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> handle_new_connection_et</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> epoll_fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> listen_fd</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (;;) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        struct</span><span style=\"color:#E1E4E8\"> sockaddr_in client_addr;</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        socklen_t</span><span style=\"color:#E1E4E8\"> addr_len </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> sizeof</span><span style=\"color:#E1E4E8\">(client_addr);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\"> client_fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> accept4</span><span style=\"color:#E1E4E8\">(listen_fd, (</span><span style=\"color:#F97583\">struct</span><span style=\"color:#E1E4E8\"> sockaddr </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">)</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">client_addr,</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                                &#x26;</span><span style=\"color:#E1E4E8\">addr_len, SOCK_NONBLOCK </span><span style=\"color:#F97583\">|</span><span style=\"color:#E1E4E8\"> SOCK_CLOEXEC);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (client_fd </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EAGAIN </span><span style=\"color:#F97583\">||</span><span style=\"color:#E1E4E8\"> errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EWOULDBLOCK) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                break</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\"> /* no more pending connections */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            perror</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"accept4\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            break</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (client_fd </span><span style=\"color:#F97583\">>=</span><span style=\"color:#E1E4E8\"> MAX_FDS) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            fprintf</span><span style=\"color:#E1E4E8\">(stderr, </span><span style=\"color:#9ECBFF\">\"fd </span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#9ECBFF\"> exceeds MAX_FDS, closing</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, client_fd);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            close</span><span style=\"color:#E1E4E8\">(client_fd);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            continue</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        conn_init</span><span style=\"color:#E1E4E8\">(client_fd);</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Register with EPOLLIN | EPOLLET â€” edge-triggered mode */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">epoll_add</span><span style=\"color:#E1E4E8\">(epoll_fd, client_fd, EPOLLIN </span><span style=\"color:#F97583\">|</span><span style=\"color:#E1E4E8\"> EPOLLET) </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            perror</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"epoll_add client ET\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            conn_close</span><span style=\"color:#E1E4E8\">(epoll_fd, client_fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * handle_client_read_et - Read all available data in edge-triggered mode.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * THE KEY </span><span style=\"color:#F97583\">INVARIANT:</span><span style=\"color:#6A737D\"> We MUST read until EAGAIN. Here's why:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Suppose 8000 bytes arrive in the kernel buffer, and our read() call</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * processes 4096. The remaining 4096 bytes sit in the buffer. ET will</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * NOT fire again until the remote end sends MORE bytes. If the protocol</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * requires a response before the client sends more, you have a deadlock:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   - Server: waiting for more data (ET won't fire, buffer has stale data)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   - Client: waiting for response (won't send more until it gets one)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Solution: drain the entire buffer in this event handler.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> handle_client_read_et</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> epoll_fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (;;) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        char</span><span style=\"color:#FFAB70\"> buf</span><span style=\"color:#E1E4E8\">[READ_BUF_SIZE];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        ssize_t</span><span style=\"color:#E1E4E8\"> n </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> read</span><span style=\"color:#E1E4E8\">(fd, buf, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(buf));</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (n </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            /* Echo all bytes back. Same partial-write issue as LT version;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">             * Milestone 2 adds proper write buffering. */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            ssize_t</span><span style=\"color:#E1E4E8\"> written </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            while</span><span style=\"color:#E1E4E8\"> (written </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> n) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                ssize_t</span><span style=\"color:#E1E4E8\"> w </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> write</span><span style=\"color:#E1E4E8\">(fd, buf </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> written, n </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> written);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> (w </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    if</span><span style=\"color:#E1E4E8\"> (errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EAGAIN </span><span style=\"color:#F97583\">||</span><span style=\"color:#E1E4E8\"> errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EWOULDBLOCK) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                        /* Send buffer full. Milestone 2 handles this. */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                        break</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    }</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">                    conn_close</span><span style=\"color:#E1E4E8\">(epoll_fd, fd);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                written </span><span style=\"color:#F97583\">+=</span><span style=\"color:#E1E4E8\"> w;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            /* Continue the loop: may be more data in the receive buffer */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        } </span><span style=\"color:#F97583\">else</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> (n </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            /* Peer closed connection */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            conn_close</span><span style=\"color:#E1E4E8\">(epoll_fd, fd);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        } </span><span style=\"color:#F97583\">else</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            /* n == -1 */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EAGAIN </span><span style=\"color:#F97583\">||</span><span style=\"color:#E1E4E8\"> errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EWOULDBLOCK) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                /* Buffer fully drained. Done for this event. */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                break</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            /* Real error */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            conn_close</span><span style=\"color:#E1E4E8\">(epoll_fd, fd);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * run_event_loop_et - Edge-triggered event loop.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Structure identical to LT version; the difference is entirely in</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * the handlers (drain loops vs single reads).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> run_event_loop_et</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> epoll_fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> listen_fd</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    struct</span><span style=\"color:#E1E4E8\"> epoll_event </span><span style=\"color:#FFAB70\">events</span><span style=\"color:#E1E4E8\">[MAX_EVENTS];</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Register listen_fd with ET mode */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    struct</span><span style=\"color:#E1E4E8\"> epoll_event ev;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ev.events  </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> EPOLLIN </span><span style=\"color:#F97583\">|</span><span style=\"color:#E1E4E8\"> EPOLLET;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ev.data.fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> listen_fd;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">epoll_ctl</span><span style=\"color:#E1E4E8\">(epoll_fd, EPOLL_CTL_ADD, listen_fd, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">ev) </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        perror</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"epoll_ctl listen_fd ET\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (;;) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\"> n_ready </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> epoll_wait</span><span style=\"color:#E1E4E8\">(epoll_fd, events, MAX_EVENTS, </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (n_ready </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EINTR) </span><span style=\"color:#F97583\">continue</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            perror</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"epoll_wait\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            break</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">; i </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> n_ready; i</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            int</span><span style=\"color:#E1E4E8\"> fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#FFAB70\"> events</span><span style=\"color:#E1E4E8\">[i].data.fd;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            uint32_t</span><span style=\"color:#E1E4E8\"> ev_mask </span><span style=\"color:#F97583\">=</span><span style=\"color:#FFAB70\"> events</span><span style=\"color:#E1E4E8\">[i].events;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (fd </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> listen_fd) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">                handle_new_connection_et</span><span style=\"color:#E1E4E8\">(epoll_fd, listen_fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            } </span><span style=\"color:#F97583\">else</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> (ev_mask </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\"> (EPOLLERR </span><span style=\"color:#F97583\">|</span><span style=\"color:#E1E4E8\"> EPOLLHUP)) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">                conn_close</span><span style=\"color:#E1E4E8\">(epoll_fd, fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            } </span><span style=\"color:#F97583\">else</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> (ev_mask </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\"> EPOLLIN) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">                handle_client_read_et</span><span style=\"color:#E1E4E8\">(epoll_fd, fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Fdiag-m1-echo-server-event-flow.svg\" alt=\"Echo Server: Complete Event Flow for One Connection\"></p>\n<hr>\n<h2 id=\"the-bug-you-must-see-single-read-in-et-mode\">The Bug You Must See: Single Read in ET Mode</h2>\n<p>To truly understand the ET/LT difference, deliberately break the ET handler and observe the failure. Change <code>handle_client_read_et</code> to perform only a single read (as if you&#39;d naively copy the LT handler):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/* DELIBERATELY BROKEN: Single read in ET mode â€” demonstrates data loss */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> handle_client_read_et_BROKEN</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> epoll_fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> buf</span><span style=\"color:#E1E4E8\">[READ_BUF_SIZE];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    ssize_t</span><span style=\"color:#E1E4E8\"> n </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> read</span><span style=\"color:#E1E4E8\">(fd, buf, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(buf));</span><span style=\"color:#6A737D\">  /* reads only one chunk */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (n </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        write</span><span style=\"color:#E1E4E8\">(fd, buf, n);</span><span style=\"color:#6A737D\">  /* echo what we got */</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* BUG: if more data is in the buffer, ET will NOT fire again</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * until the remote sends new data. If protocol expects a response</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * first (request-response), we deadlock here. */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    } </span><span style=\"color:#F97583\">else</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> (n </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        conn_close</span><span style=\"color:#E1E4E8\">(epoll_fd, fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    } </span><span style=\"color:#F97583\">else</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> (errno </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> EAGAIN </span><span style=\"color:#F97583\">&#x26;&#x26;</span><span style=\"color:#E1E4E8\"> errno </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> EWOULDBLOCK) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        conn_close</span><span style=\"color:#E1E4E8\">(epoll_fd, fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<p>Now test it by sending a large payload in a single TCP segment that exceeds <code>READ_BUF_SIZE</code>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Generate 8192 bytes and pipe to server (larger than READ_BUF_SIZE=4096)</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python3</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"print('A' * 8192)\"</span><span style=\"color:#F97583\"> |</span><span style=\"color:#B392F0\"> nc</span><span style=\"color:#9ECBFF\"> localhost</span><span style=\"color:#79B8FF\"> 8080</span></span></code></pre></div>\n<h2 id=\"with-the-broken-handler-you39ll-receive-4096-bytes-echoed-back-then-silence-the-remaining-4096-bytes-are-trapped-in-the-kernel-receive-buffer-invisible-until-the-client-sends-more-data-with-the-correct-handler-drain-until-eagain-you-receive-all-8192-bytes-under-a-load-test-sending-large-requests-concurrently-this-bug-manifests-as-random-request-timeoutsconnections-that-appear-connected-but-never-complete\">With the broken handler, you&#39;ll receive 4,096 bytes echoed back, then silence. The remaining 4,096 bytes are trapped in the kernel receive buffer, invisible until the client sends more data. With the correct handler (drain until EAGAIN), you receive all 8,192 bytes.\nUnder a load test sending large requests concurrently, this bug manifests as random request timeoutsâ€”connections that appear connected but never complete.</h2>\n<h2 id=\"the-non-blocking-accept-loop-and-the-et-listening-socket\">The Non-Blocking Accept Loop and the ET Listening Socket</h2>\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Fdiag-m1-nonblocking-accept-loop.svg\" alt=\"Non-blocking accept() Loop with ET Mode\"></p>\n<p>When you register your listening socket with <code>EPOLLET</code>, a burst of incoming connections generates a single <code>EPOLLIN</code> notification. The <code>handle_new_connection_et</code> function&#39;s loop-until-EAGAIN is not optionalâ€”it&#39;s the same contract as the read loop.\nConsider this scenario:</p>\n<ul>\n<li>At time T=0: 50 clients simultaneously complete the TCP three-way handshake</li>\n<li>At time T=1: epoll_wait wakes up with EPOLLIN on listen_fd</li>\n<li>Your accept loop processes all 50 connections, calling accept4() until EAGAIN</li>\n<li>At time T=2: epoll_wait returns â€” no pending connection notifications (all were drained)\nWithout the loop, you&#39;d accept 1 connection and miss 49. The kernel queued them in the listen backlog (the <code>BACKLOG</code> constant in our <code>listen()</code> call), but ET won&#39;t re-notify you. They&#39;ll sit there until the next connection arrivesâ€”which may never happen.</li>\n</ul>\n<hr>\n<h2 id=\"putting-it-all-together-the-complete-echo-server\">Putting It All Together: The Complete Echo Server</h2>\n<p>Here&#39;s the full main function wiring everything together, with a compile switch to choose between LT and ET modes:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;sys/epoll.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;sys/socket.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;netinet/in.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;fcntl.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;unistd.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdio.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdlib.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;string.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;errno.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdbool.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdint.h></span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/* Forward declarations of all functions defined above */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\">  create_epoll</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\">  create_listening_socket</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\">  epoll_add</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> epoll_fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#FFAB70\"> events</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\">  epoll_mod</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> epoll_fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#FFAB70\"> events</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\">  epoll_del</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> epoll_fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> conn_init</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> conn_close</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> epoll_fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> run_event_loop_lt</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> epoll_fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> listen_fd</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> run_event_loop_et</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> epoll_fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> listen_fd</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\"> main</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> argc</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">argv</span><span style=\"color:#F97583\">[]</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Default to LT mode; pass \"et\" as argument for ET mode */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> use_et </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (argc </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#F97583\"> &#x26;&#x26;</span><span style=\"color:#B392F0\"> strcmp</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">argv</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">], </span><span style=\"color:#9ECBFF\">\"et\"</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Initialize all connection slots as inactive */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    memset</span><span style=\"color:#E1E4E8\">(connections, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(connections));</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">; i </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> MAX_FDS; i</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        connections</span><span style=\"color:#E1E4E8\">[i].fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> epoll_fd  </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> create_epoll</span><span style=\"color:#E1E4E8\">();</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> listen_fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> create_listening_socket</span><span style=\"color:#E1E4E8\">();</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    printf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Echo server starting on port </span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#9ECBFF\"> (</span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\"> mode)...</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">           PORT, use_et </span><span style=\"color:#F97583\">?</span><span style=\"color:#9ECBFF\"> \"edge-triggered\"</span><span style=\"color:#F97583\"> :</span><span style=\"color:#9ECBFF\"> \"level-triggered\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (use_et) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* ET mode: register listen_fd inside run_event_loop_et */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        run_event_loop_et</span><span style=\"color:#E1E4E8\">(epoll_fd, listen_fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    } </span><span style=\"color:#F97583\">else</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* LT mode: register listen_fd here, then start loop */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">epoll_add</span><span style=\"color:#E1E4E8\">(epoll_fd, listen_fd, EPOLLIN) </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            perror</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"epoll_add listen_fd\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            exit</span><span style=\"color:#E1E4E8\">(EXIT_FAILURE);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        run_event_loop_lt</span><span style=\"color:#E1E4E8\">(epoll_fd, listen_fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    close</span><span style=\"color:#E1E4E8\">(listen_fd);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    close</span><span style=\"color:#E1E4E8\">(epoll_fd);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<p>Compile with:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">gcc</span><span style=\"color:#79B8FF\"> -O2</span><span style=\"color:#79B8FF\"> -Wall</span><span style=\"color:#79B8FF\"> -Wextra</span><span style=\"color:#79B8FF\"> -o</span><span style=\"color:#9ECBFF\"> echo_server</span><span style=\"color:#9ECBFF\"> echo_server.c</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Run level-triggered</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">./echo_server</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Run edge-triggered</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">./echo_server</span><span style=\"color:#9ECBFF\"> et</span></span></code></pre></div>\n<p>Test:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Basic echo test</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#9ECBFF\"> \"hello world\"</span><span style=\"color:#F97583\"> |</span><span style=\"color:#B392F0\"> nc</span><span style=\"color:#9ECBFF\"> localhost</span><span style=\"color:#79B8FF\"> 8080</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Multiple simultaneous connections</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> $(</span><span style=\"color:#B392F0\">seq</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#79B8FF\"> 100</span><span style=\"color:#E1E4E8\">); </span><span style=\"color:#F97583\">do</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    echo</span><span style=\"color:#9ECBFF\"> \"connection </span><span style=\"color:#E1E4E8\">$i</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#F97583\"> |</span><span style=\"color:#B392F0\"> nc</span><span style=\"color:#79B8FF\"> -q</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#9ECBFF\"> localhost</span><span style=\"color:#79B8FF\"> 8080</span><span style=\"color:#E1E4E8\"> &#x26;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">done</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">wait</span></span></code></pre></div>\n<hr>\n<h2 id=\"hardware-soul-what-the-kernel-actually-does\">Hardware Soul: What the Kernel Actually Does</h2>\n<p>Understanding the hardware effects explains the performance difference between LT and ETâ€”and why it&#39;s smaller than people expect.\n<strong>Cache behavior</strong>: Each <code>epoll_wait</code> call returns up to <code>MAX_EVENTS</code> (1,024 in our code) events into a stack-allocated array. This array is 1,024 Ã— 12 bytes = 12 KB, which fits in L1 cache (typically 32â€“64 KB). Iterating over ready events is cache-hot.\n<strong>The ready list</strong>: Linux&#39;s epoll implementation (in <code>fs/eventpoll.c</code>) maintains the ready list (<code>rdllist</code>) as a doubly-linked list of <code>epitem</code> structures. When you call <code>epoll_wait</code>:</p>\n<ul>\n<li>LT mode: after returning an event, the fd is immediately re-added to <code>rdllist</code> if data remains. This requires an extra list manipulation per event.</li>\n<li>ET mode: the fd is removed from <code>rdllist</code> and only re-added when new data arrives (via the socket&#39;s <code>sock_def_readable</code> callback). Less overhead per event, but your drain loop does more work per event.\nThe net effect: ET has slightly lower kernel overhead per <code>epoll_wait</code> call, but your application does more work per event (the drain loop). At high throughput, the difference is measurable but often less than 5â€“10%. The real reason NGINX uses ET is <strong>correctness under high connection rates</strong>â€”ET&#39;s single-notification model eliminates redundant wakeups from partially-consumed buffers, keeping the event loop lean.\n<strong>TLB and page fault cost</strong>: The per-connection state array (<code>connections[MAX_FDS]</code>) is 65,536 Ã— 4,112 bytes â‰ˆ 256 MB. Not all of it is residentâ€”the kernel uses demand paging. Accessing the state for a new connection (touching a page not recently accessed) causes a page fault if it hasn&#39;t been accessed recently, adding ~1â€“10 Âµs to connection setup. Under sustained load with 10K active connections, these pages will all be resident and TLB-warm.\n<strong>Branch prediction</strong>: The <code>errno == EAGAIN || errno == EWOULDBLOCK</code> check in the read loop is nearly always false during drain (we expect to read data, not hit EAGAIN until the end). The branch predictor learns this quicklyâ€”after a few iterations, the EAGAIN branch is predicted not-taken with high accuracy, costing only 1 cycle.\n<strong>Memory access pattern</strong>: Reading the receive buffer sequentially (sequential bytes from <code>read()</code>) is prefetch-friendly. The hardware prefetcher recognizes the linear access pattern and loads upcoming cache lines before you need them, hiding memory latency.</li>\n</ul>\n<hr>\n<h2 id=\"design-decision-lt-vs-et-which-should-you-use\">Design Decision: LT vs ET â€” Which Should You Use?</h2>\n<table>\n<thead>\n<tr>\n<th>Property</th>\n<th>Level-Triggered (LT)</th>\n<th>Edge-Triggered (ET)</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Required read discipline</strong></td>\n<td>Single read per event is sufficient</td>\n<td>Must drain until EAGAIN</td>\n</tr>\n<tr>\n<td><strong>Required accept discipline</strong></td>\n<td>Can accept one per event</td>\n<td>Must accept until EAGAIN</td>\n</tr>\n<tr>\n<td><strong>Behavior on partial read</strong></td>\n<td>Re-notified on next epoll_wait</td>\n<td>Silent until more data arrives</td>\n</tr>\n<tr>\n<td><strong>Kernel overhead per event</strong></td>\n<td>Slightly higher (re-adds to rdllist)</td>\n<td>Slightly lower</td>\n</tr>\n<tr>\n<td><strong>Risk of data loss on bug</strong></td>\n<td>Low (just slower)</td>\n<td>High (silent data loss)</td>\n</tr>\n<tr>\n<td><strong>Who uses it</strong></td>\n<td>Node.js (libuv), Twisted</td>\n<td>NGINX, Redis (optionally), io_uring</td>\n</tr>\n<tr>\n<td><strong>Correct for beginners</strong></td>\n<td>âœ“ Easier to implement correctly</td>\n<td>âœ— Requires strict discipline</td>\n</tr>\n<tr>\n<td><strong>The verdict</strong>: Use LT for this milestone to build intuition. Implement ET to understand the constraint. In production, either works correctly if implemented correctlyâ€”the performance difference rarely justifies the cognitive overhead of ET for application-level code.</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Node.js explicitly chose LT for libuv after analysis showed that the complexity of ensuring every callback drains its socket was an unacceptable maintenance burden. NGINX chose ET because NGINX&#39;s architecture guarantees the drain discipline at the module API levelâ€”every handler is required to read until EAGAIN, and this is enforced by code review and convention.</td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<hr>\n<h2 id=\"the-three-level-view-one-read-call\">The Three-Level View: One Read Call</h2>\n<h2 id=\"let39s-trace-a-single-read-call-through-the-stack-level-1-application-your-code-calls-readfd-buf-4096-a-number-positive-bytes-read-0-eof-1-error-or-eagain-returns-level-2-kernel-the-read-syscall-enters-the-kernel-via-the-syscall-table-the-kernel39s-socket-layer-netsocketc-finds-the-tcp-socket39s-receive-buffer-sk_receive_queue-it-copies-bytes-from-the-socket-buffer-into-your-user-space-buf-using-copy_to_user-if-the-buffer-was-drained-below-a-threshold-the-kernel-updates-the-socket39s-readiness-state-in-et-mode-if-the-buffer-was-previously-non-empty-and-now-becomes-empty-the-epoll-subsystem-removes-the-epitem-from-the-ready-list-level-3-hardware-copy_to_user-is-essentially-a-memcpy-from-kernel-space-to-user-space-on-a-modern-cpu-with-virtual-memory-both-the-kernel-buffer-and-user-buffer-are-virtual-addresses-the-mmu-translates-them-to-physical-addresses-using-the-page-table-checked-via-tlb-if-the-user-space-buffer-page-is-in-tlb-likely-for-the-first-read-after-a-context-switch-into-the-epoll-loop-this-is-fast-the-actual-data-transfer-uses-sse2-or-avx-movdquvmovdqu-instructions-for-vectorized-16-or-32-byte-copies-at-4096-bytes-with-avx2-32-byte-copies-that39s-128-vector-instructionsapproximately-64-cycles-on-a-modern-cpu-or-20-ns-at-3-ghz\">Let&#39;s trace a single <code>read()</code> call through the stack:\n<strong>Level 1 â€” Application</strong>: Your code calls <code>read(fd, buf, 4096)</code>. A number (positive: bytes read, 0: EOF, -1: error or EAGAIN) returns.\n<strong>Level 2 â€” Kernel</strong>: The <code>read()</code> syscall enters the kernel via the syscall table. The kernel&#39;s socket layer (<code>net/socket.c</code>) finds the TCP socket&#39;s receive buffer (<code>sk_receive_queue</code>). It copies bytes from the socket buffer into your user-space <code>buf</code> using <code>copy_to_user()</code>. If the buffer was drained below a threshold, the kernel updates the socket&#39;s readiness state. In ET mode, if the buffer was previously non-empty and now becomes empty, the epoll subsystem removes the <code>epitem</code> from the ready list.\n<strong>Level 3 â€” Hardware</strong>: <code>copy_to_user()</code> is essentially a <code>memcpy</code> from kernel-space to user-space. On a modern CPU with virtual memory, both the kernel buffer and user buffer are virtual addresses. The MMU translates them to physical addresses using the page table, checked via TLB. If the user-space buffer page is in TLB (likely for the first read after a context switch into the epoll loop), this is fast. The actual data transfer uses SSE2 or AVX <code>movdqu</code>/<code>vmovdqu</code> instructions for vectorized 16- or 32-byte copies. At 4096 bytes with AVX2 (32-byte copies), that&#39;s 128 vector instructionsâ€”approximately 64 cycles on a modern CPU, or ~20 ns at 3 GHz.</h2>\n<h2 id=\"knowledge-cascade-what-this-unlocks\">Knowledge Cascade: What This Unlocks</h2>\n<h2 id=\"now-that-you-understand-epoll39s-fundamentals-and-the-etlt-contract-you-have-a-lens-for-understanding-systems-you39ll-encounter-throughout-your-career-1-nginx39s-module-bug-surface-nginx-uses-et-mode-exclusively-and-documents-that-every-module-must-call-ngx_handle_read_event-and-drain-the-socket-third-party-nginx-modules-are-a-frequent-source-of-bugs-precisely-because-module-authors-forget-the-drain-disciplinethe-module-works-correctly-in-unit-testing-small-payloads-but-loses-data-under-production-load-you-now-know-exactly-why-2-tcp-flow-control-and-et39s-hidden-interaction-when-you-drain-the-socket-buffer-aggressively-et39s-drain-until-eagain-you-keep-the-kernel39s-receive-buffer-empty-this-signals-to-the-tcp-stack-that-your-application-can-receive-more-data-tcp39s-receive-window-advertised-to-the-remote-sender-stays-large-if-you-don39t-drain-the-lt-partial-read-case-the-receive-buffer-fills-the-window-shrinks-and-tcp-backpressure-naturally-slows-the-sender-et-mode-thus-affects-tcp39s-flow-control-behavioraggressive-draining-can-increase-throughput-but-also-means-your-application-sees-larger-bursts-of-data-that-it-must-handle-efficiently-3-io_uring-epoll39s-eventual-successor-io_uring-linux-51-eliminates-the-epoll-wait-read-write-syscall-pattern-entirely-you-submit-read-and-write-operations-to-a-ring-buffer-and-completions-appear-in-another-ring-bufferno-epoll_wait-no-per-event-read-syscall-at-10k-connections-with-small-messages-epoll-spends-significant-cpu-time-in-syscall-overhead-context-switches-to-kernel-space-io_uring-amortizes-this-by-batching-the-etlt-distinction-doesn39t-exist-in-io_uring39s-completion-model-it39s-inherently-edge-notificationyou-get-one-completion-per-submitted-operation-understanding-epoll39s-model-makes-io_uring39s-design-decisions-legible-4-the-c10k-paper-and-historical-context-dan-kegel39s-1999-c10k-paper-cited-in-your-resources-described-this-exact-problem-before-linux-had-epoll-the-solutions-proposednon-blocking-io-event-driven-architectures-selectpoll-improvementsdirectly-led-to-epoll39s-design-reading-it-now-you39ll-recognize-every-problem-and-understand-why-epoll-solved-them-the-way-it-did-the-paper-is-a-time-capsule-of-the-moment-when-event-driven-architecture-stopped-being-exotic-and-became-necessary-5-cross-domain-browser-event-loops-javascript39s-event-loop-the-foundation-of-nodejs-and-browsers-is-the-same-reactor-pattern-you-just-builta-single-threaded-loop-that-dispatches-events-to-callbacks-settimeout-promisethen-and-eventlistener-callbacks-are-all-queued-events-processed-in-order-the-quotevent-loopquot-terminology-in-javascript-directly-inherits-from-the-networking-reactor-pattern-you39re-building-when-javascript-developers-talk-about-quotnot-blocking-the-event-loopquot-they-mean-exactly-what-you-now-know-if-a-callback-takes-100ms-all-other-events-are-delayed-by-100mssame-constraint-different-context\">Now that you understand epoll&#39;s fundamentals and the ET/LT contract, you have a lens for understanding systems you&#39;ll encounter throughout your career:\n<strong>1. NGINX&#39;s module bug surface</strong>: NGINX uses ET mode exclusively and documents that every module must call <code>ngx_handle_read_event()</code> and drain the socket. Third-party NGINX modules are a frequent source of bugs precisely because module authors forget the drain disciplineâ€”the module works correctly in unit testing (small payloads) but loses data under production load. You now know exactly why.\n<strong>2. TCP flow control and ET&#39;s hidden interaction</strong>: When you drain the socket buffer aggressively (ET&#39;s drain-until-EAGAIN), you keep the kernel&#39;s receive buffer empty. This signals to the TCP stack that your application can receive more data. TCP&#39;s receive window (advertised to the remote sender) stays large. If you <em>don&#39;t</em> drain (the LT partial-read case), the receive buffer fills, the window shrinks, and TCP backpressure naturally slows the sender. ET mode thus affects TCP&#39;s flow control behaviorâ€”aggressive draining can increase throughput but also means your application sees larger bursts of data that it must handle efficiently.\n<strong>3. io_uring: epoll&#39;s eventual successor</strong>: io_uring (Linux 5.1+) eliminates the epoll <code>wait â†’ read â†’ write</code> syscall pattern entirely. You submit <code>read</code> and <code>write</code> operations to a ring buffer, and completions appear in another ring bufferâ€”no <code>epoll_wait</code>, no per-event <code>read()</code> syscall. At 10K connections with small messages, epoll spends significant CPU time in syscall overhead (context switches to kernel space). io_uring amortizes this by batching. The ET/LT distinction doesn&#39;t exist in io_uring&#39;s completion model (it&#39;s inherently edge-notificationâ€”you get one completion per submitted operation). Understanding epoll&#39;s model makes io_uring&#39;s design decisions legible.\n<strong>4. The C10K paper and historical context</strong>: Dan Kegel&#39;s 1999 C10K paper (cited in your resources) described this exact problem before Linux had epoll. The solutions proposedâ€”non-blocking I/O, event-driven architectures, <code>select</code>/<code>poll</code> improvementsâ€”directly led to epoll&#39;s design. Reading it now, you&#39;ll recognize every problem and understand why epoll solved them the way it did. The paper is a time capsule of the moment when event-driven architecture stopped being exotic and became necessary.\n<strong>5. Cross-domain: Browser event loops</strong>: JavaScript&#39;s event loop (the foundation of Node.js and browsers) is the same reactor pattern you just builtâ€”a single-threaded loop that dispatches events to callbacks. <code>setTimeout</code>, <code>Promise.then</code>, and <code>EventListener</code> callbacks are all queued events, processed in order. The &quot;event loop&quot; terminology in JavaScript directly inherits from the networking reactor pattern you&#39;re building. When JavaScript developers talk about &quot;not blocking the event loop,&quot; they mean exactly what you now know: if a callback takes 100ms, all other events are delayed by 100msâ€”same constraint, different context.</h2>\n<h2 id=\"pitfall-reference-the-five-ways-this-breaks\">Pitfall Reference: The Five Ways This Breaks</h2>\n<h2 id=\"before-you-move-on-memorize-these-failure-modes-pitfall-1-et-with-single-read-per-event-symptom-works-in-testing-silently-loses-data-under-load-causing-protocol-level-deadlocks-fix-always-loop-until-eagain-in-et-mode-pitfall-2-et-listening-socket-without-accept-loop-symptom-under-connection-bursts-new-clients-connect-but-receive-no-response-their-connections-sit-in-the-listen-backlog-fix-accept-in-a-loop-until-eagain-in-both-the-listen-handler-and-the-accept-function-pitfall-3-treating-eagain-as-an-error-symptom-connections-closed-immediately-after-the-first-quotempty-readquot-or-spurious-connection-resets-fix-check-errno-eagain-errno-ewouldblock-and-return-without-closing-pitfall-4-not-setting-the-listen-socket-to-non-blocking-symptom-server-hangs-under-specific-tcp-rst-race-conditions-accept-blocks-briefly-on-a-connection-that-was-reset-before-accept-ran-fix-use-sock_nonblock-in-the-socket-call-or-set_nonblocking-before-listen-pitfall-5-max_events-too-small-symptom-under-high-load-epoll_wait-returns-the-maximum-each-call-requiring-many-calls-to-drain-the-ready-list-reduces-throughput-fix-set-max_events-between-512-and-4096-1024-is-a-common-default-tune-based-on-your-event-distribution\">Before you move on, memorize these failure modes:\n<strong>Pitfall 1: ET with single read per event</strong>\n<em>Symptom</em>: Works in testing, silently loses data under load, causing protocol-level deadlocks.\n<em>Fix</em>: Always loop until EAGAIN in ET mode.\n<strong>Pitfall 2: ET listening socket without accept loop</strong>\n<em>Symptom</em>: Under connection bursts, new clients connect but receive no response; their connections sit in the listen backlog.\n<em>Fix</em>: Accept in a loop until EAGAIN in both the listen handler and the accept function.\n<strong>Pitfall 3: Treating EAGAIN as an error</strong>\n<em>Symptom</em>: Connections closed immediately after the first &quot;empty read,&quot; or spurious connection resets.\n<em>Fix</em>: Check <code>errno == EAGAIN || errno == EWOULDBLOCK</code> and return without closing.\n<strong>Pitfall 4: Not setting the listen socket to non-blocking</strong>\n<em>Symptom</em>: Server hangs under specific TCP RST race conditions; <code>accept()</code> blocks briefly on a connection that was reset before accept ran.\n<em>Fix</em>: Use <code>SOCK_NONBLOCK</code> in the <code>socket()</code> call or <code>set_nonblocking()</code> before <code>listen()</code>.\n<strong>Pitfall 5: MAX_EVENTS too small</strong>\n<em>Symptom</em>: Under high load, <code>epoll_wait</code> returns the maximum each call, requiring many calls to drain the ready list; reduces throughput.\n<em>Fix</em>: Set <code>MAX_EVENTS</code> between 512 and 4096. 1024 is a common default; tune based on your event distribution.</h2>\n<!-- END_MS -->\n\n\n<!-- MS_ID: build-event-loop-m2 -->\n<!-- MS_ID: build-event-loop-m2 -->\n<h1 id=\"write-buffering-and-timer-management\">Write Buffering and Timer Management</h1>\n<h2 id=\"the-problem-you-haven39t-solved-yet\">The Problem You Haven&#39;t Solved Yet</h2>\n<p>Your echo server from Milestone 1 has a quiet bug. Look at the write path:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">ssize_t</span><span style=\"color:#E1E4E8\"> w </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> write</span><span style=\"color:#E1E4E8\">(fd, buf </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> written, n </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> written);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> (w </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EAGAIN </span><span style=\"color:#F97583\">||</span><span style=\"color:#E1E4E8\"> errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EWOULDBLOCK) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Send buffer full. Milestone 2 handles this. */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        break</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\">  // â† THIS IS THE BUG</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ...</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<p>When <code>write()</code> returns <code>EAGAIN</code>, you <code>break</code> out of the write loop and discard the unsent bytes. For an echo server with small payloads, the kernel&#39;s send buffer is almost always large enough that this never triggers. In production, under load, with large responses and slow clients, this path fires constantlyâ€”and every time it does, you silently drop data.\nBut the naive fixâ€”just retry <code>write()</code> in a loop until it succeedsâ€”transforms your elegant event loop into a blocking server. If one client&#39;s socket buffer is full, the server stalls waiting for it to drain, freezing all other 9,999 connections.\nThe correct solution requires two interlocking mechanisms:</p>\n<ol>\n<li><strong>A write buffer</strong>: When <code>write()</code> returns <code>EAGAIN</code>, save the unsent bytes in a per-connection queue. Don&#39;t drop them, don&#39;t retry synchronouslyâ€”save them.</li>\n<li><strong>EPOLLOUT management</strong>: Register interest in <code>EPOLLOUT</code> to be notified when the socket&#39;s send buffer drains. When it fires, flush the queued bytes. When the queue empties, <em>deregister</em> <code>EPOLLOUT</code>.\nThat deregistration is the critical step most developers missâ€”and it&#39;s the subject of this milestone&#39;s core revelation.\n{{DIAGRAM:diag-m2-write-buffer-lifecycle}}</li>\n</ol>\n<hr>\n<h2 id=\"the-revelation-epollout-is-not-like-epollin\">The Revelation: EPOLLOUT Is NOT Like EPOLLIN</h2>\n<p>Here&#39;s the misconception you need to shatter before writing a single line of code.\n<code>EPOLLIN</code> fires when data <em>arrives</em>. Between arrivals, the socket is quiet. <code>EPOLLIN</code> is an edge condition: something changed (data appeared). If no data is arriving, <code>EPOLLIN</code> doesn&#39;t fire, and <code>epoll_wait</code> correctly sleeps.\nNow consider <code>EPOLLOUT</code>. It fires when the socket&#39;s send buffer has space for writing. How often does a TCP socket have space in its send buffer?\nAlmost always.\nThe Linux TCP send buffer defaults to 87 KB (expandable to 208 KB with autotuning). Your server is sending kilobytes at a time. The send buffer drains rapidlyâ€”the kernel reads from it and hands bytes to the NIC continuously. A socket&#39;s send buffer is full only during a brief window where you&#39;re writing faster than the network can send.\nIf you leave <code>EPOLLOUT</code> registered when you have nothing to write, <code>epoll_wait</code> will return your fd as &quot;writable&quot; on <em>every single call</em>. There&#39;s nothing to write, so your handler returns immediately. Then <code>epoll_wait</code> returns again. And again. 100% CPU, no work done.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>[WITHOUT proper EPOLLOUT management]\nepoll_wait() returns â€” EPOLLOUT on fd 5 (nothing to write)\nepoll_wait() returns â€” EPOLLOUT on fd 5 (nothing to write)\nepoll_wait() returns â€” EPOLLOUT on fd 5 (nothing to write)\nâ†‘ This loop runs at ~1,000,000 iterations/second, pinning one CPU core.</code></pre></div>\n\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Fdiag-m2-epollout-busy-loop-trace.svg\" alt=\"Trace: EPOLLOUT Busy-Loop Bug\"></p>\n<p>The correct pattern is a three-step cycle:</p>\n<ol>\n<li><strong>Normal state</strong>: Only <code>EPOLLIN</code> is registered. <code>EPOLLOUT</code> is NOT registered.</li>\n<li><strong>write() returns EAGAIN</strong>: Buffer the remaining data. Register <code>EPOLLOUT</code> (using <code>epoll_ctl EPOLL_CTL_MOD</code>).</li>\n<li><strong>EPOLLOUT fires</strong>: Flush the write buffer. If the buffer empties, deregister <code>EPOLLOUT</code> (back to <code>EPOLLIN</code> only). If <code>EAGAIN</code> again, stay registered.\nThis register-flush-deregister cycle is not a clever optimization. It is the <em>only correct implementation</em>. Every production event loop that handles large responses does exactly this: libuv (Node.js), libevent, libev, NGINX, andâ€”as we&#39;ll see in the Knowledge Cascadeâ€”Redis.</li>\n</ol>\n<hr>\n<h2 id=\"building-the-write-buffer\">Building the Write Buffer</h2>\n<p>Before the code, understand what you&#39;re building. A write buffer is a byte queue attached to each connection. It holds data that <code>write()</code> couldn&#39;t send because the kernel&#39;s send buffer was full. It must:</p>\n<ul>\n<li>Store arbitrary amounts of data (bounded by a configured maximum)</li>\n<li>Track where in the buffer writing left off (the &quot;offset&quot;)</li>\n<li>Be efficient to append to and drain from</li>\n<li>Free its memory when the connection closes\nThe simplest correct implementation uses a dynamically allocated byte array with a capacity, a used-bytes count, and an offset indicating where draining left off.</li>\n</ul>\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Fdiag-m2-write-buffer-struct-layout.svg\" alt=\"Write Buffer: Byte-Level Memory Layout\"></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdlib.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;string.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdint.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdbool.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> WRITE_BUF_MAX</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">256</span><span style=\"color:#F97583\"> *</span><span style=\"color:#79B8FF\"> 1024</span><span style=\"color:#E1E4E8\">)</span><span style=\"color:#6A737D\">   /* 256 KB max write buffer per connection */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> WRITE_BUF_INIT</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">4</span><span style=\"color:#F97583\"> *</span><span style=\"color:#79B8FF\"> 1024</span><span style=\"color:#E1E4E8\">)</span><span style=\"color:#6A737D\">    /* Initial allocation: 4 KB */</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * write_buf - Dynamically-sized write buffer for a single connection.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Memory layout (on 64-bit):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   offset  0: data     (8 bytes â€” pointer)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   offset  8: len      (4 bytes â€” bytes in buf from offset onward)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   offset 12: cap      (4 bytes â€” total allocated bytes)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   offset 16: offset   (4 bytes â€” start of unwritten data)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   offset 20: [4 bytes padding]</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   Total: 24 bytes per connection</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Invariant: data[offset .. offset+len] contains unsent bytes.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * When len == 0, the buffer is empty; EPOLLOUT should be deregistered.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * When offset > cap/2, compact: memmove(data, data+offset, len); offset=0.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#F97583\">    *</span><span style=\"color:#E1E4E8\">data;</span><span style=\"color:#6A737D\">    /* heap-allocated byte array */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint32_t</span><span style=\"color:#E1E4E8\"> len;</span><span style=\"color:#6A737D\">     /* number of buffered (unsent) bytes */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint32_t</span><span style=\"color:#E1E4E8\"> cap;</span><span style=\"color:#6A737D\">     /* total allocated capacity */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint32_t</span><span style=\"color:#E1E4E8\"> offset;</span><span style=\"color:#6A737D\">  /* index of first unsent byte */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} write_buf;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * wbuf_init - Initialize a write buffer with no allocation.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Allocation is deferred until the first write failure.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> wbuf_init</span><span style=\"color:#E1E4E8\">(write_buf </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">wb</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    wb->data   </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    wb->len    </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    wb->cap    </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    wb->offset </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * wbuf_free - Release all memory held by the write buffer.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Must be called when the connection closes.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> wbuf_free</span><span style=\"color:#E1E4E8\">(write_buf </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">wb</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    free</span><span style=\"color:#E1E4E8\">(wb->data);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    wbuf_init</span><span style=\"color:#E1E4E8\">(wb);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * wbuf_append - Add bytes to the write buffer.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * First compacts the buffer if offset has consumed more than half the</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * allocation (avoids unbounded growth from repeated append+drain cycles).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Then grows the allocation if needed (doubling strategy).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Returns 0 on success, -1 if buffer would exceed WRITE_BUF_MAX.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\"> wbuf_append</span><span style=\"color:#E1E4E8\">(write_buf </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">wb</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">data</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#FFAB70\"> data_len</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Reject if this would exceed the hard cap */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (wb->len </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> data_len </span><span style=\"color:#F97583\">></span><span style=\"color:#E1E4E8\"> WRITE_BUF_MAX) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\">  /* caller should close this connection */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Compact if offset wasted more than half the capacity */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (wb->offset </span><span style=\"color:#F97583\">></span><span style=\"color:#E1E4E8\"> wb->cap </span><span style=\"color:#F97583\">/</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#F97583\"> &#x26;&#x26;</span><span style=\"color:#E1E4E8\"> wb->len </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        memmove</span><span style=\"color:#E1E4E8\">(wb->data, wb->data </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> wb->offset, wb->len);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        wb->offset </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Grow if needed */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint32_t</span><span style=\"color:#E1E4E8\"> needed </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> wb->offset </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> wb->len </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> data_len;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (needed </span><span style=\"color:#F97583\">></span><span style=\"color:#E1E4E8\"> wb->cap) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        uint32_t</span><span style=\"color:#E1E4E8\"> new_cap </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> wb->cap </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> ?</span><span style=\"color:#E1E4E8\"> WRITE_BUF_INIT </span><span style=\"color:#F97583\">:</span><span style=\"color:#E1E4E8\"> wb->cap </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        while</span><span style=\"color:#E1E4E8\"> (new_cap </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> needed) new_cap </span><span style=\"color:#F97583\">*=</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (new_cap </span><span style=\"color:#F97583\">></span><span style=\"color:#E1E4E8\"> WRITE_BUF_MAX) new_cap </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> WRITE_BUF_MAX;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\">new_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> realloc</span><span style=\"color:#E1E4E8\">(wb->data, new_cap);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">new_data) </span><span style=\"color:#F97583\">return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\">  /* OOM â€” close connection */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        wb->data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> new_data;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        wb->cap  </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> new_cap;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    memcpy</span><span style=\"color:#E1E4E8\">(wb->data </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> wb->offset </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> wb->len, data, data_len);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    wb->len </span><span style=\"color:#F97583\">+=</span><span style=\"color:#E1E4E8\"> data_len;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * wbuf_consume - Advance the buffer by 'n' bytes (those bytes were sent).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> inline</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> wbuf_consume</span><span style=\"color:#E1E4E8\">(write_buf </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">wb</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#FFAB70\"> n</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    wb->offset </span><span style=\"color:#F97583\">+=</span><span style=\"color:#E1E4E8\"> n;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    wb->len    </span><span style=\"color:#F97583\">-=</span><span style=\"color:#E1E4E8\"> n;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (wb->len </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        wb->offset </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\">  /* reset to avoid creeping offset */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * wbuf_is_empty - True when there are no unsent bytes.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> inline</span><span style=\"color:#F97583\"> bool</span><span style=\"color:#B392F0\"> wbuf_is_empty</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#E1E4E8\"> write_buf </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">wb</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> wb->len </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<blockquote>\n<p><strong>Why double the capacity?</strong> The doubling strategy amortizes <code>realloc</code> calls. If you added one byte at a time, each addition might require a new allocation and memory copy. By doubling, you pay O(log N) realloc calls for N bytes appended totalâ€”each byte&#39;s amortized allocation cost is O(1). This is the same strategy used by C++&#39;s <code>std::vector</code> and Rust&#39;s <code>Vec</code>.\n<strong>Why the compaction threshold?</strong> Consider a connection that repeatedly appends 100 bytes and sends 100 bytes. Without compaction, <code>offset</code> creeps forward: 100, 200, 300... eventually reaching <code>cap</code>, at which point <code>realloc</code> extends the buffer unnecessarily. By compacting when offset exceeds half the capacity, we bound this waste. The <code>memmove</code> cost (O(len)) is paid infrequentlyâ€”only when offset drifts far.</p>\n</blockquote>\n<hr>\n<h2 id=\"updated-per-connection-state\">Updated Per-Connection State</h2>\n<p>Now update the <code>conn_state</code> struct from Milestone 1 to include the write buffer and an EPOLLOUT-registered flag:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/* From Milestone 1: */</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/* #define READ_BUF_SIZE 4096 */</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/* #define MAX_FDS       65536 */</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * conn_state - Per-connection state (updated for Milestone 2).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Memory layout (approximate, 64-bit):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   offset     0: read_buf[4096]   = 4096 bytes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   offset  4096: wbuf             = 24 bytes (write_buf struct)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   offset  4120: read_len         = 4 bytes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   offset  4124: fd               = 4 bytes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   offset  4128: active           = 1 byte</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   offset  4129: epollout_armed   = 1 byte</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   offset  4130: [6 bytes padding]</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   offset  4136: timer_expiry_ms  = 8 bytes (uint64_t)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   offset  4144: timer_idx        = 4 bytes (index in timer heap, -1 if none)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   offset  4148: [4 bytes padding]</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   Total: ~4152 bytes per connection</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * At 10,000 connections: 10,000 Ã— 4152 â‰ˆ 40.5 MB resident.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * The write_buf.data pointer is separately heap-allocated on demand;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * connections that never need write buffering pay only the 24-byte struct.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\">      read_buf</span><span style=\"color:#E1E4E8\">[READ_BUF_SIZE];</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    write_buf wbuf;</span><span style=\"color:#6A737D\">              /* write queue for backpressured data */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint32_t</span><span style=\"color:#E1E4E8\">  read_len;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\">       fd;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\">      active;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\">      epollout_armed;</span><span style=\"color:#6A737D\">   /* true if EPOLLOUT is currently registered */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\">  timer_expiry_ms;</span><span style=\"color:#6A737D\">  /* absolute expiry time (monotonic ms), 0 = no timer */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\">       timer_idx;</span><span style=\"color:#6A737D\">        /* position in min-heap, -1 if not in heap */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} conn_state;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#E1E4E8\"> conn_state </span><span style=\"color:#FFAB70\">connections</span><span style=\"color:#E1E4E8\">[MAX_FDS];</span></span></code></pre></div>\n<blockquote>\n<p><strong><code>epollout_armed</code></strong>: This boolean is the guard that prevents the busy-loop bug. Before calling <code>epoll_ctl(EPOLL_CTL_MOD)</code> to add or remove <code>EPOLLOUT</code>, always check this flag. Redundant <code>epoll_ctl</code> calls are not catastrophic (they&#39;re idempotent), but they&#39;re unnecessary syscalls. More importantly, <code>epollout_armed</code> makes your intent explicit in the codeâ€”it&#39;s documentation that the event loop cares deeply about this state.</p>\n</blockquote>\n<hr>\n<h2 id=\"the-write-path-attempt-buffer-register\">The Write Path: Attempt, Buffer, Register</h2>\n<p>Here&#39;s the unified write function. Call it every time your server needs to send data to a clientâ€”whether it&#39;s an echo response, an HTTP reply, or any other output:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;errno.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;sys/epoll.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;unistd.h></span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * conn_write - Send data to a connection, buffering if the socket is full.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Flow:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   1. If the write buffer is non-empty, we MUST append to it (can't bypass</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *      the queue â€” data must arrive in order). Attempt to flush first.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   2. Attempt write() directly to the socket.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   3. If EAGAIN, buffer the unsent remainder and arm EPOLLOUT.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   4. If the write buffer grows beyond WRITE_BUF_MAX, close the connection</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *      (slow client defense â€” discussed in TCP Backpressure section below).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Returns 0 on success (data sent or queued), -1 if connection should close.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\"> conn_write</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> epoll_fd</span><span style=\"color:#E1E4E8\">, conn_state </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">c</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">data</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#FFAB70\"> len</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* If there's already buffered data, don't bypass it â€” append and flush */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#B392F0\">wbuf_is_empty</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">c->wbuf)) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">wbuf_append</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">c->wbuf, data, len) </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\">  /* buffer overflow â€” caller must close connection */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#B392F0\"> conn_flush</span><span style=\"color:#E1E4E8\">(epoll_fd, c);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Write buffer is empty: attempt direct write first (fast path) */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    ssize_t</span><span style=\"color:#E1E4E8\"> written </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    while</span><span style=\"color:#E1E4E8\"> ((</span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#E1E4E8\">)written </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> len) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        ssize_t</span><span style=\"color:#E1E4E8\"> w </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> write</span><span style=\"color:#E1E4E8\">(c->fd, data </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> written, len </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> written);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (w </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            written </span><span style=\"color:#F97583\">+=</span><span style=\"color:#E1E4E8\"> w;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            continue</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (w </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#F97583\"> &#x26;&#x26;</span><span style=\"color:#E1E4E8\"> (errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EAGAIN </span><span style=\"color:#F97583\">||</span><span style=\"color:#E1E4E8\"> errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EWOULDBLOCK)) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            /* Send buffer full: queue the unsent remainder */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            uint32_t</span><span style=\"color:#E1E4E8\"> remaining </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> len </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#E1E4E8\">)written;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">wbuf_append</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">c->wbuf, data </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> written, remaining) </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\">  /* buffer overflow */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            /* Arm EPOLLOUT so we're notified when buffer drains */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">c->epollout_armed) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                struct</span><span style=\"color:#E1E4E8\"> epoll_event ev;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                ev.events  </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> EPOLLIN </span><span style=\"color:#F97583\">|</span><span style=\"color:#E1E4E8\"> EPOLLOUT;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                ev.data.fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> c->fd;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">epoll_ctl</span><span style=\"color:#E1E4E8\">(epoll_fd, EPOLL_CTL_MOD, c->fd, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">ev) </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                c->epollout_armed </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\">  /* data queued; will be flushed when EPOLLOUT fires */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Real error (EPIPE, ECONNRESET, etc.) */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\">  /* fully written on the fast path */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * conn_flush - Drain the write buffer to the socket.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Called when EPOLLOUT fires. Writes as much as the socket will accept.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * If the buffer empties, deregisters EPOLLOUT to prevent busy-looping.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * If write() hits EAGAIN again, leaves EPOLLOUT armed and returns.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Returns 0 on success, -1 on error (caller must close connection).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\"> conn_flush</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> epoll_fd</span><span style=\"color:#E1E4E8\">, conn_state </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">c</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    while</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#B392F0\">wbuf_is_empty</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">c->wbuf)) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        const</span><span style=\"color:#F97583\"> char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\">ptr </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> c->wbuf.data </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> c->wbuf.offset;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        uint32_t</span><span style=\"color:#E1E4E8\">    n   </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> c->wbuf.len;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        ssize_t</span><span style=\"color:#E1E4E8\"> w </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> write</span><span style=\"color:#E1E4E8\">(c->fd, ptr, n);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (w </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            wbuf_consume</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">c->wbuf, (</span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#E1E4E8\">)w);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            continue</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (w </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#F97583\"> &#x26;&#x26;</span><span style=\"color:#E1E4E8\"> (errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EAGAIN </span><span style=\"color:#F97583\">||</span><span style=\"color:#E1E4E8\"> errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EWOULDBLOCK)) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            /* Socket buffer still full â€” stay armed, wait for next EPOLLOUT */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Real error */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Buffer is now empty â€” CRITICAL: deregister EPOLLOUT */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (c->epollout_armed) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        struct</span><span style=\"color:#E1E4E8\"> epoll_event ev;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ev.events  </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> EPOLLIN;</span><span style=\"color:#6A737D\">   /* back to read-only interest */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ev.data.fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> c->fd;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">epoll_ctl</span><span style=\"color:#E1E4E8\">(epoll_fd, EPOLL_CTL_MOD, c->fd, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">ev) </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        c->epollout_armed </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<h2 id=\"study-the-conn_flush-function39s-deregistration-block-this-is-the-heartbeat-of-the-epollout-cycle-when-wbuf_is_empty-returns-true-and-epollout_armed-is-true-a-single-epoll_ctlepoll_ctl_mod-call-switches-the-fd39s-interest-back-to-epollin-only-from-that-point-epoll_wait-will-not-return-this-fd-as-writable-until-you-arm-it-again-cpu-usage-drops-from-100-to-near-zero-during-idle-periods\">Study the <code>conn_flush</code> function&#39;s deregistration block. This is the heartbeat of the EPOLLOUT cycle. When <code>wbuf_is_empty()</code> returns true and <code>epollout_armed</code> is true, a single <code>epoll_ctl(EPOLL_CTL_MOD)</code> call switches the fd&#39;s interest back to <code>EPOLLIN</code> only. From that point, <code>epoll_wait</code> will not return this fd as writable until you arm it again. CPU usage drops from 100% to near-zero during idle periods.</h2>\n<h2 id=\"integrating-write-buffering-into-the-event-loop\">Integrating Write Buffering Into the Event Loop</h2>\n<p>The event loop from Milestone 1 needs two changes: handle <code>EPOLLOUT</code> events, and use <code>conn_write</code> instead of raw <code>write()</code>.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * handle_client_write - Called when EPOLLOUT fires for a client fd.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Flushes the write buffer. If flush fails, closes the connection.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> handle_client_write</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> epoll_fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    conn_state </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">c </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#FFAB70\">connections</span><span style=\"color:#E1E4E8\">[fd];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">conn_flush</span><span style=\"color:#E1E4E8\">(epoll_fd, c) </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        conn_close</span><span style=\"color:#E1E4E8\">(epoll_fd, fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/* In the main event dispatch loop: */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">; i </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> n_ready; i</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> fd          </span><span style=\"color:#F97583\">=</span><span style=\"color:#FFAB70\"> events</span><span style=\"color:#E1E4E8\">[i].data.fd;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint32_t</span><span style=\"color:#E1E4E8\"> ev     </span><span style=\"color:#F97583\">=</span><span style=\"color:#FFAB70\"> events</span><span style=\"color:#E1E4E8\">[i].events;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (fd </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> listen_fd) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        handle_new_connection</span><span style=\"color:#E1E4E8\">(epoll_fd, listen_fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    } </span><span style=\"color:#F97583\">else</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> (ev </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\"> (EPOLLERR </span><span style=\"color:#F97583\">|</span><span style=\"color:#E1E4E8\"> EPOLLHUP)) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        conn_close</span><span style=\"color:#E1E4E8\">(epoll_fd, fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    } </span><span style=\"color:#F97583\">else</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Handle EPOLLIN and EPOLLOUT independently â€” both can fire together */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (ev </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\"> EPOLLIN) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            handle_client_read</span><span style=\"color:#E1E4E8\">(epoll_fd, fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (ev </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\"> EPOLLOUT) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            /* Check active: EPOLLIN handler may have closed this connection */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">connections</span><span style=\"color:#E1E4E8\">[fd].active) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">                handle_client_write</span><span style=\"color:#E1E4E8\">(epoll_fd, fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<blockquote>\n<p><strong>Why check <code>connections[fd].active</code> before handling <code>EPOLLOUT</code>?</strong> <code>EPOLLIN</code> and <code>EPOLLOUT</code> can fire simultaneously on the same fd in the same <code>epoll_wait</code> batch. If <code>handle_client_read</code> closes the connection (because the client sent EOF or an invalid request), the fd is freed. Then the <code>EPOLLOUT</code> handler would access freed state. The <code>active</code> check prevents this. Milestone 3 will introduce deferred closure as a more robust solution.\n{{DIAGRAM:diag-m2-tcp-backpressure-flow}}</p>\n</blockquote>\n<hr>\n<h2 id=\"tcp-backpressure-and-the-slow-loris-defense\">TCP Backpressure and the Slow Loris Defense</h2>\n<p>Your write buffer is a queue between your application and the kernel&#39;s send buffer. But if the client reads slowly (or not at all), the kernel&#39;s send buffer fills and stays full. Every <code>conn_write</code> call hits <code>EAGAIN</code>, appending more data to your write buffer. The write buffer grows. Eventually it exceeds <code>WRITE_BUF_MAX</code>â€”what then?\nThis is the <strong>slow loris</strong> scenario (named after a slow-moving primateâ€”it&#39;s also a famous HTTP attack). A malicious client opens thousands of connections, sends partial HTTP requests to keep them alive, and never reads responses. Each connection accumulates an unbounded write buffer. Your server runs out of memory and crashes.\nThe defense: <code>WRITE_BUF_MAX</code>. When <code>wbuf_append</code> would exceed it, return -1, and the caller closes the connection. This is not user-friendlyâ€”we&#39;re cutting off a legitimate client whose network is slow. But it&#39;s the correct production behavior. Real-world servers (NGINX, Apache) configure this limit explicitly (<code>send_timeout</code>, <code>client_body_timeout</code>). The idle timeout you&#39;ll build in the next section provides a complementary defense: connections that haven&#39;t received data in 30 seconds are closed regardless of write buffer state.</p>\n<blockquote>\n<p><strong>Cross-domain connection: Distributed systems backpressure</strong>. When your write buffer fills because the client reads slowly, you&#39;re absorbing pressure that should propagate upstream. In a distributed system, this is exactly the problem that TCP&#39;s receive window mechanism handles between nodesâ€”it slows down the sender when the receiver&#39;s buffer fills. Your in-process write buffer serves the same role between your application logic and the network stack. Without a cap, you become an unbounded buffer that hides backpressure rather than propagating it. This is a fundamental distributed systems anti-pattern: the &quot;buffer bloat&quot; problem that causes latency spikes in routers and operating system network stacks.</p>\n</blockquote>\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Fdiag-m2-connection-lifecycle-state-evolution.svg\" alt=\"State Evolution: Connection Create â†’ Active â†’ Timeout â†’ Cleanup\"></p>\n<hr>\n<h2 id=\"timer-management-the-event-loop39s-internal-clock\">Timer Management: The Event Loop&#39;s Internal Clock</h2>\n<p>Your event loop has no notion of time. It sits in <code>epoll_wait</code> until I/O events arrive. But you need to close idle connectionsâ€”ones that connected and then went silent for 30 seconds. How do you implement &quot;do this in N seconds&quot; in a system that only wakes up on I/O?\nThe answer: <code>epoll_wait</code>&#39;s third argumentâ€”the timeout.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\"> n_ready </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> epoll_wait</span><span style=\"color:#E1E4E8\">(epoll_fd, events, MAX_EVENTS, timeout_ms);</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">//                                                     ^^^^^^^^^^</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">//                                         If no I/O events arrive within</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">//                                         timeout_ms milliseconds, epoll_wait</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">//                                         returns 0 (not an error). This is</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">//                                         your timer tick.</span></span></code></pre></div>\n<p>When <code>epoll_wait</code> returns 0, no I/O events firedâ€”you woke up because time passed. Check your timer data structure for expired timers and process them.\nThe timeout you pass should be: <strong>&quot;how many milliseconds until the next timer expires?&quot;</strong> If you have a connection that times out in 12,342 ms, pass 12,342. If no timers are pending, pass -1 (block forever). This way the event loop sleeps exactly as long as neededâ€”no more, no less.</p>\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Fdiag-m2-epoll-timeout-integration.svg\" alt=\"Timer Integration: epoll_wait Timeout Calculation\"></p>\n<h3 id=\"choosing-a-timer-data-structure\">Choosing a Timer Data Structure</h3>\n<p>You need a data structure that efficiently answers: &quot;what is the next timer to expire?&quot; This is a classic priority queue problem. Two main options:\n<strong>Min-Heap</strong> (recommended for this milestone):</p>\n<ul>\n<li>Insert: O(log N)</li>\n<li>Find minimum: O(1) (always the root)</li>\n<li>Delete minimum: O(log N)</li>\n<li>Cancel (arbitrary deletion): O(log N) with position tracking</li>\n<li>Simple to implement correctly</li>\n<li>Used by: Nginx&#39;s <code>ngx_event_timer_rbtree</code> (red-black tree variant), libuv&#39;s timer implementation\n<strong>Timer Wheel</strong>:</li>\n<li>Insert: O(1)</li>\n<li>Tick (process expired): O(1) amortized per slot</li>\n<li>Cancel: O(1)</li>\n<li>More complex; best when timers cluster around a fixed duration (like a 30-second idle timeout)</li>\n<li>Used by: Linux kernel&#39;s internal timer mechanism (hierarchical timer wheels), Kafka&#39;s <code>TimingWheel</code><blockquote>\n<p><strong>When does log(N) beat O(1)?</strong> The timer wheel&#39;s O(1) insert has a constant factor from the modulo operation (or bitwise AND for power-of-2 sizes) plus cache effects from touching potentially cold slots. For N &lt; ~10,000 timers, a min-heap&#39;s O(log N) â‰ˆ logâ‚‚(10,000) â‰ˆ 13 comparisons often beats the timer wheel in practice because the heap&#39;s root and first few levels stay cache-hot. At N &gt; 100,000, the wheel wins. For this projectâ€”targeting 10K connectionsâ€”a min-heap is simpler and fast enough.\n<strong>ðŸ”‘ Foundation: Min-Heap</strong></p>\n<p><strong>1. What it IS</strong>\nA min-heap is a binary tree stored in a flat array where every parent&#39;s value is less than or equal to its children&#39;s values. The minimum value is always at index 0. It&#39;s &quot;complete&quot;â€”all levels are fully filled except possibly the last, which fills left to right. This shape guarantee means the tree never becomes unbalanced and the array representation wastes no space.</p>\n<p><strong>2. Why you need it right now</strong>\nYou need to efficiently find the connection that times out <em>soonest</em> (the minimum expiry time) so you can pass the right timeout to <code>epoll_wait</code>. With a min-heap, this is always <code>heap[0]</code>â€”a single array access. Inserting a new timer or removing an expired one requires at most O(log N) operations where N is the number of active timers.</p>\n<p><strong>3. Key Insight: The Array Encoding</strong>\nThe parent of a node at index <code>i</code> is at index <code>(i - 1) / 2</code>. The left child is at <code>2*i + 1</code>, the right child at <code>2*i + 2</code>. This arithmetic eliminates pointers entirelyâ€”the tree structure is implicit in the indices. Inserting adds to the end, then &quot;bubbles up&quot; by swapping with the parent if smaller. Removing the minimum replaces it with the last element, then &quot;bubbles down&quot; by swapping with the smaller child if larger. Both operations are O(log N).</p>\n</blockquote>\n</li>\n</ul>\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Fdiag-m2-min-heap-timer-structure.svg\" alt=\"Min-Heap Timer: Insert, Cancel, Expire Operations\"></p>\n<h3 id=\"implementing-the-min-heap-timer\">Implementing the Min-Heap Timer</h3>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdint.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;time.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> TIMER_HEAP_MAX</span><span style=\"color:#79B8FF\"> 65536</span><span style=\"color:#6A737D\">   /* maximum simultaneous timers */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> IDLE_TIMEOUT_MS</span><span style=\"color:#79B8FF\"> 30000</span><span style=\"color:#6A737D\">  /* 30 seconds in milliseconds */</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * timer_entry - One entry in the timer min-heap.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * expiry_ms: absolute expiry time in monotonic milliseconds.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * fd:        the connection fd this timer belongs to.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Memory layout: 12 bytes per entry (8 + 4).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Full heap at 65536 entries: 65536 Ã— 12 = 768 KB â€” fits in L2 cache.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> expiry_ms;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\">      fd;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} timer_entry;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * timer_heap - Min-heap of timer_entry, ordered by expiry_ms.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * connections[fd].timer_idx stores each entry's current index in this heap,</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * enabling O(log N) cancellation without linear search.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#E1E4E8\"> timer_entry </span><span style=\"color:#FFAB70\">timer_heap</span><span style=\"color:#E1E4E8\">[TIMER_HEAP_MAX];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\">         timer_heap_size </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * now_ms - Return current monotonic time in milliseconds.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * CLOCK_MONOTONIC is critical here: it never jumps backward or forward</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * due to NTP adjustments or daylight saving time changes. Timer intervals</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * computed with wall-clock time (CLOCK_REALTIME) can be wrong by hours</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * if the clock is adjusted while the server runs.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">uint64_t</span><span style=\"color:#B392F0\"> now_ms</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    struct</span><span style=\"color:#E1E4E8\"> timespec ts;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    clock_gettime</span><span style=\"color:#E1E4E8\">(CLOCK_MONOTONIC, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">ts);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">uint64_t</span><span style=\"color:#E1E4E8\">)ts.tv_sec </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 1000</span><span style=\"color:#F97583\">ULL</span><span style=\"color:#F97583\"> +</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">uint64_t</span><span style=\"color:#E1E4E8\">)ts.tv_nsec </span><span style=\"color:#F97583\">/</span><span style=\"color:#79B8FF\"> 1000000</span><span style=\"color:#F97583\">ULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * heap_swap - Swap two entries in the heap, updating timer_idx in conn_state.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> heap_swap</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> i</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> j</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    timer_entry tmp  </span><span style=\"color:#F97583\">=</span><span style=\"color:#FFAB70\"> timer_heap</span><span style=\"color:#E1E4E8\">[i];</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    timer_heap</span><span style=\"color:#E1E4E8\">[i]    </span><span style=\"color:#F97583\">=</span><span style=\"color:#FFAB70\"> timer_heap</span><span style=\"color:#E1E4E8\">[j];</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    timer_heap</span><span style=\"color:#E1E4E8\">[j]    </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> tmp;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Keep conn_state.timer_idx in sync so we can find entries for cancellation */</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    connections</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#FFAB70\">timer_heap</span><span style=\"color:#E1E4E8\">[i].fd].timer_idx </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> i;</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    connections</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#FFAB70\">timer_heap</span><span style=\"color:#E1E4E8\">[j].fd].timer_idx </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> j;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * heap_sift_up - Restore min-heap property upward from index i.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Called after inserting at the end of the array.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> heap_sift_up</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> i</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    while</span><span style=\"color:#E1E4E8\"> (i </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\"> parent </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (i </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">/</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">timer_heap</span><span style=\"color:#E1E4E8\">[parent].expiry_ms </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#FFAB70\"> timer_heap</span><span style=\"color:#E1E4E8\">[i].expiry_ms) </span><span style=\"color:#F97583\">break</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        heap_swap</span><span style=\"color:#E1E4E8\">(i, parent);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        i </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> parent;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * heap_sift_down - Restore min-heap property downward from index i.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Called after removing the minimum (replacing it with the last element).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> heap_sift_down</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> i</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (;;) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\"> left  </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\"> right </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\"> smallest </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> i;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (left  </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> timer_heap_size </span><span style=\"color:#F97583\">&#x26;&#x26;</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            timer_heap</span><span style=\"color:#E1E4E8\">[left].expiry_ms  </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#FFAB70\"> timer_heap</span><span style=\"color:#E1E4E8\">[smallest].expiry_ms)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            smallest </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> left;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (right </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> timer_heap_size </span><span style=\"color:#F97583\">&#x26;&#x26;</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            timer_heap</span><span style=\"color:#E1E4E8\">[right].expiry_ms </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#FFAB70\"> timer_heap</span><span style=\"color:#E1E4E8\">[smallest].expiry_ms)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            smallest </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> right;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (smallest </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> i) </span><span style=\"color:#F97583\">break</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        heap_swap</span><span style=\"color:#E1E4E8\">(i, smallest);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        i </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> smallest;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * timer_set - Insert or reset a timer for connection fd.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * If the connection already has a timer (timer_idx >= 0), removes it first,</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * then inserts with the new expiry. This implements \"reset on activity.\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * expiry_ms: absolute time (from now_ms()) when this timer fires.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> timer_set</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">uint64_t</span><span style=\"color:#FFAB70\"> expiry_ms</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    conn_state </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">c </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#FFAB70\">connections</span><span style=\"color:#E1E4E8\">[fd];</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Cancel existing timer if present */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (c->timer_idx </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        timer_cancel</span><span style=\"color:#E1E4E8\">(fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (timer_heap_size </span><span style=\"color:#F97583\">>=</span><span style=\"color:#E1E4E8\"> TIMER_HEAP_MAX) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Heap full: can't add timer. In production, close oldest connection. */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> idx </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> timer_heap_size</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    timer_heap</span><span style=\"color:#E1E4E8\">[idx].expiry_ms </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> expiry_ms;</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    timer_heap</span><span style=\"color:#E1E4E8\">[idx].fd        </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> fd;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    c->timer_idx              </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> idx;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    c->timer_expiry_ms        </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> expiry_ms;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    heap_sift_up</span><span style=\"color:#E1E4E8\">(idx);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * timer_cancel - Remove a connection's timer from the heap.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Uses the O(1) lookup via conn_state.timer_idx, then removes in O(log N)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * by swapping with the last element and sifting.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> timer_cancel</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    conn_state </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">c </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#FFAB70\">connections</span><span style=\"color:#E1E4E8\">[fd];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> idx </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> c->timer_idx;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (idx </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">return</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\">  /* no timer */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    c->timer_idx       </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    c->timer_expiry_ms </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> last </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> --</span><span style=\"color:#E1E4E8\">timer_heap_size;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (idx </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> last) </span><span style=\"color:#F97583\">return</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\">  /* removing the last element â€” nothing to fix */</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Move last element into the vacated slot */</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    timer_heap</span><span style=\"color:#E1E4E8\">[idx] </span><span style=\"color:#F97583\">=</span><span style=\"color:#FFAB70\"> timer_heap</span><span style=\"color:#E1E4E8\">[last];</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    connections</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#FFAB70\">timer_heap</span><span style=\"color:#E1E4E8\">[idx].fd].timer_idx </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> idx;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* The moved element may be too small (sift up) or too large (sift down) */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    heap_sift_up</span><span style=\"color:#E1E4E8\">(idx);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    heap_sift_down</span><span style=\"color:#E1E4E8\">(idx);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * timer_next_ms - Return milliseconds until the next timer expires.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Returns -1 if no timers are pending (epoll_wait should block indefinitely).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Returns 0 if a timer is already expired (process immediately).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\"> timer_next_ms</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (timer_heap_size </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> now    </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> now_ms</span><span style=\"color:#E1E4E8\">();</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> expiry </span><span style=\"color:#F97583\">=</span><span style=\"color:#FFAB70\"> timer_heap</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">].expiry_ms;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (expiry </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#E1E4E8\"> now) </span><span style=\"color:#F97583\">return</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> diff </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> expiry </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> now;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Clamp to INT_MAX: epoll_wait timeout is int milliseconds */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> (diff </span><span style=\"color:#F97583\">></span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">uint64_t</span><span style=\"color:#E1E4E8\">)INT_MAX) </span><span style=\"color:#F97583\">?</span><span style=\"color:#E1E4E8\"> INT_MAX </span><span style=\"color:#F97583\">:</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\">)diff;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * timer_process_expired - Fire all timers whose expiry_ms &#x3C;= now.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Called after epoll_wait returns (whether due to I/O or timeout).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Must process ALL expired timers in a single call â€” multiple may expire</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * between epoll_wait invocations (especially under high load).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> timer_process_expired</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> epoll_fd</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> now </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> now_ms</span><span style=\"color:#E1E4E8\">();</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    while</span><span style=\"color:#E1E4E8\"> (timer_heap_size </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> &#x26;&#x26;</span><span style=\"color:#FFAB70\"> timer_heap</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">].expiry_ms </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#E1E4E8\"> now) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\"> fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#FFAB70\"> timer_heap</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">].fd;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* timer_cancel will be called inside conn_close */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        fprintf</span><span style=\"color:#E1E4E8\">(stderr, </span><span style=\"color:#9ECBFF\">\"Idle timeout: closing fd </span><span style=\"color:#79B8FF\">%d\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, fd);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        conn_close</span><span style=\"color:#E1E4E8\">(epoll_fd, fd);</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* conn_close calls timer_cancel(fd), which removes timer_heap[0]</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * and sifts down. The loop then checks the new heap[0]. */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<blockquote>\n<p><strong>Why both <code>sift_up</code> AND <code>sift_down</code> in <code>timer_cancel</code>?</strong> When you remove an arbitrary element by swapping it with the last, the replacement element&#39;s value is unknown relative to its new neighbors. It might be smaller than its new parent (needs sift up) or larger than its new children (needs sift down)â€”but not both. Only one of the two operations will actually move the element; the other is a no-op. Calling both is safe and correct, avoiding a conditional branch that would add complexity.\n<strong><code>CLOCK_MONOTONIC</code> vs <code>CLOCK_REALTIME</code></strong>: <code>CLOCK_REALTIME</code> is the wall clockâ€”it can jump backward or forward when NTP adjusts it. If your timer stores an absolute expiry time based on <code>CLOCK_REALTIME</code>, and NTP adjusts the clock forward by one hour (happens during daylight saving time in some configurations), all your timers expire simultaneously. <code>CLOCK_MONOTONIC</code> is guaranteed to only move forward, at a stable rate, making it the correct choice for interval timers.</p>\n</blockquote>\n<hr>\n<h2 id=\"integrating-timers-into-the-event-loop\">Integrating Timers Into the Event Loop</h2>\n<p>Here&#39;s the complete event loop with timer integration:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * run_event_loop - Main event loop with write buffering and timer support.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Changes from Milestone 1:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   1. epoll_wait timeout derived from timer_next_ms() instead of -1.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   2. timer_process_expired() called after every epoll_wait return.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   3. On new data received, idle timer is reset (timer_set with new expiry).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   4. EPOLLOUT events routed to handle_client_write().</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> run_event_loop</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> epoll_fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> listen_fd</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    struct</span><span style=\"color:#E1E4E8\"> epoll_event </span><span style=\"color:#FFAB70\">events</span><span style=\"color:#E1E4E8\">[MAX_EVENTS];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (;;) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\"> timeout </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> timer_next_ms</span><span style=\"color:#E1E4E8\">();</span><span style=\"color:#6A737D\">  /* -1, 0, or ms until next expiry */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\"> n_ready </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> epoll_wait</span><span style=\"color:#E1E4E8\">(epoll_fd, events, MAX_EVENTS, timeout);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (n_ready </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EINTR) </span><span style=\"color:#F97583\">continue</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            perror</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"epoll_wait\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            break</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Process timer expirations first â€” they're time-sensitive */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        timer_process_expired</span><span style=\"color:#E1E4E8\">(epoll_fd);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">; i </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> n_ready; i</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            int</span><span style=\"color:#E1E4E8\">      fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#FFAB70\"> events</span><span style=\"color:#E1E4E8\">[i].data.fd;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            uint32_t</span><span style=\"color:#E1E4E8\"> ev </span><span style=\"color:#F97583\">=</span><span style=\"color:#FFAB70\"> events</span><span style=\"color:#E1E4E8\">[i].events;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (fd </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> listen_fd) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">                handle_new_connection</span><span style=\"color:#E1E4E8\">(epoll_fd, listen_fd);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                continue</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            /* Guard against timer expiry closing this fd during timer processing */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#FFAB70\">connections</span><span style=\"color:#E1E4E8\">[fd].active) </span><span style=\"color:#F97583\">continue</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (ev </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\"> (EPOLLERR </span><span style=\"color:#F97583\">|</span><span style=\"color:#E1E4E8\"> EPOLLHUP)) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">                conn_close</span><span style=\"color:#E1E4E8\">(epoll_fd, fd);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                continue</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (ev </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\"> EPOLLIN) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">                handle_client_read</span><span style=\"color:#E1E4E8\">(epoll_fd, fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> ((ev </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\"> EPOLLOUT) </span><span style=\"color:#F97583\">&#x26;&#x26;</span><span style=\"color:#FFAB70\"> connections</span><span style=\"color:#E1E4E8\">[fd].active) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">                handle_client_write</span><span style=\"color:#E1E4E8\">(epoll_fd, fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<p>And <code>conn_init</code> / <code>conn_close</code> need updating to manage timer state:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * conn_init - Initialize connection state and set idle timer.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Called immediately after accept4() returns a new fd.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> conn_init</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    conn_state </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">c </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#FFAB70\">connections</span><span style=\"color:#E1E4E8\">[fd];</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    c->fd              </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> fd;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    c->read_len        </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    c->active          </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    c->epollout_armed  </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    c->timer_idx       </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    c->timer_expiry_ms </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    wbuf_init</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">c->wbuf);</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Set idle timeout: close if no data received for IDLE_TIMEOUT_MS */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    timer_set</span><span style=\"color:#E1E4E8\">(fd, </span><span style=\"color:#B392F0\">now_ms</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> IDLE_TIMEOUT_MS);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * conn_close - Tear down a connection completely.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Order matters:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   1. Mark inactive first â€” prevents double-close in edge cases.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   2. Cancel timer â€” prevents timer firing after fd is closed.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   3. Remove from epoll â€” prevents events on a closed fd.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   4. Free write buffer â€” releases heap memory.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   5. close(fd) â€” releases the file descriptor.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Violating this order causes use-after-free or file descriptor reuse bugs.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> conn_close</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> epoll_fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    conn_state </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">c </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#FFAB70\">connections</span><span style=\"color:#E1E4E8\">[fd];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">c->active) </span><span style=\"color:#F97583\">return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    c->active </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\">              /* 1. mark inactive */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    timer_cancel</span><span style=\"color:#E1E4E8\">(fd);</span><span style=\"color:#6A737D\">               /* 2. remove from timer heap */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    epoll_ctl</span><span style=\"color:#E1E4E8\">(epoll_fd, EPOLL_CTL_DEL, fd, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">);</span><span style=\"color:#6A737D\">  /* 3. remove from epoll */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    wbuf_free</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">c->wbuf);</span><span style=\"color:#6A737D\">            /* 4. free write buffer memory */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    close</span><span style=\"color:#E1E4E8\">(fd);</span><span style=\"color:#6A737D\">                      /* 5. release file descriptor */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    c->fd             </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    c->epollout_armed </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    c->read_len       </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * handle_client_read - Read data, reset idle timer on success.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * (Updated from Milestone 1 to use conn_write and timer reset.)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> handle_client_read</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> epoll_fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    conn_state </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">c </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#FFAB70\">connections</span><span style=\"color:#E1E4E8\">[fd];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> buf</span><span style=\"color:#E1E4E8\">[READ_BUF_SIZE];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    ssize_t</span><span style=\"color:#E1E4E8\"> n </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> read</span><span style=\"color:#E1E4E8\">(fd, buf, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(buf));</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (n </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Activity on this connection â€” reset idle timer */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        timer_set</span><span style=\"color:#E1E4E8\">(fd, </span><span style=\"color:#B392F0\">now_ms</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> IDLE_TIMEOUT_MS);</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Echo back using the buffered write path */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">conn_write</span><span style=\"color:#E1E4E8\">(epoll_fd, c, buf, (</span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#E1E4E8\">)n) </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            conn_close</span><span style=\"color:#E1E4E8\">(epoll_fd, fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    } </span><span style=\"color:#F97583\">else</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> (n </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        conn_close</span><span style=\"color:#E1E4E8\">(epoll_fd, fd);</span><span style=\"color:#6A737D\">  /* graceful EOF */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    } </span><span style=\"color:#F97583\">else</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EAGAIN </span><span style=\"color:#F97583\">||</span><span style=\"color:#E1E4E8\"> errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EWOULDBLOCK) </span><span style=\"color:#F97583\">return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        conn_close</span><span style=\"color:#E1E4E8\">(epoll_fd, fd);</span><span style=\"color:#6A737D\">  /* error */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<hr>\n<h2 id=\"the-three-level-view-one-epollout-event\">The Three-Level View: One EPOLLOUT Event</h2>\n<h2 id=\"let39s-trace-what-happens-from-kernel-to-hardware-when-a-slow-client39s-socket-buffer-finally-drains-and-epollout-fires-level-1-application-your-event-loop-calls-epoll_wait-it-returns-with-epollout-set-for-fd-42-your-code-calls-conn_flushepoll_fd-ampconnections42-level-2-oskernel-when-the-nic-sent-tcp-segments-and-received-acks-from-the-remote-client-the-kernel39s-tcp-stack-freed-space-in-the-socket39s-send-buffer-sk_send_head-advances-the-socket39s-sock_def_write_space-callback-fires-which-wakes-the-epoll-subsystem-the-epoll-epitem-for-fd-42-is-placed-on-the-ready-list-rdllist-on-your-next-epoll_wait-the-kernel-transfers-it-from-rdllist-to-your-events-array-via-copy_to_user-inside-conn_flush-your-write-call-copies-bytes-from-your-write-buffer-into-the-kernel39s-send-buffer-the-kernel-hands-these-to-the-tcp-stack-which-segments-them-and-queues-them-to-the-nic-level-3-hardware-the-kernel39s-tcp-stack-queues-a-dma-direct-memory-access-descriptor-to-the-nic39s-tx-ring-the-nic39s-dma-engine-reads-from-a-kernel-memory-region-pinned-not-pageable-directlyno-cpu-involvement-the-nic-serializes-bytes-to-the-wire-at-line-rate-1-gbps-125-mbs-an-interrupt-fires-when-the-tx-ring-entry-completes-or-is-batched-with-napi-polling-at-which-point-the-kernel-marks-the-send-buffer-space-as-free-and-can-trigger-another-epollout-if-you-still-have-data-to-send-the-write-path-in-conn_flushwrite-kernel-tcp-nic-dmatakes-roughly-15-s-end-to-end-on-a-modern-server\">Let&#39;s trace what happens from kernel to hardware when a slow client&#39;s socket buffer finally drains and EPOLLOUT fires:\n<strong>Level 1 â€” Application</strong>: Your event loop calls <code>epoll_wait</code>. It returns with <code>EPOLLOUT</code> set for fd 42. Your code calls <code>conn_flush(epoll_fd, &amp;connections[42])</code>.\n<strong>Level 2 â€” OS/Kernel</strong>: When the NIC sent TCP segments and received ACKs from the remote client, the kernel&#39;s TCP stack freed space in the socket&#39;s send buffer (<code>sk_send_head</code> advances). The socket&#39;s <code>sock_def_write_space</code> callback fires, which wakes the epoll subsystem. The epoll <code>epitem</code> for fd 42 is placed on the ready list (<code>rdllist</code>). On your next <code>epoll_wait</code>, the kernel transfers it from <code>rdllist</code> to your <code>events[]</code> array via <code>copy_to_user()</code>. Inside <code>conn_flush</code>, your <code>write()</code> call copies bytes from your write buffer into the kernel&#39;s send buffer. The kernel hands these to the TCP stack, which segments them and queues them to the NIC.\n<strong>Level 3 â€” Hardware</strong>: The kernel&#39;s TCP stack queues a DMA (Direct Memory Access) descriptor to the NIC&#39;s TX ring. The NIC&#39;s DMA engine reads from a kernel memory region (pinned, not pageable) directlyâ€”no CPU involvement. The NIC serializes bytes to the wire at line rate (1 Gbps â†’ 125 MB/s). An interrupt fires when the TX ring entry completes (or is batched with NAPI polling), at which point the kernel marks the send buffer space as free and can trigger another <code>EPOLLOUT</code> if you still have data to send. The write path in <code>conn_flush</code>â€”<code>write()</code> â†’ kernel TCP â†’ NIC DMAâ€”takes roughly 1â€“5 Âµs end-to-end on a modern server.</h2>\n<h2 id=\"putting-it-all-together-testing-the-implementation\">Putting It All Together: Testing the Implementation</h2>\n<p>Compile your server with the new write buffering and timer code:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">gcc</span><span style=\"color:#79B8FF\"> -O2</span><span style=\"color:#79B8FF\"> -Wall</span><span style=\"color:#79B8FF\"> -Wextra</span><span style=\"color:#79B8FF\"> -o</span><span style=\"color:#9ECBFF\"> echo_server_m2</span><span style=\"color:#9ECBFF\"> echo_server.c</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">./echo_server_m2</span></span></code></pre></div>\n<p><strong>Test 1: Write buffer correctness under backpressure</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Use tc (traffic control) to simulate a slow client</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># This limits the loopback interface to 1 Kbps â€” very slow</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">sudo</span><span style=\"color:#9ECBFF\"> tc</span><span style=\"color:#9ECBFF\"> qdisc</span><span style=\"color:#9ECBFF\"> add</span><span style=\"color:#9ECBFF\"> dev</span><span style=\"color:#9ECBFF\"> lo</span><span style=\"color:#9ECBFF\"> root</span><span style=\"color:#9ECBFF\"> tbf</span><span style=\"color:#9ECBFF\"> rate</span><span style=\"color:#9ECBFF\"> 1kbps</span><span style=\"color:#9ECBFF\"> burst</span><span style=\"color:#9ECBFF\"> 32kbit</span><span style=\"color:#9ECBFF\"> latency</span><span style=\"color:#9ECBFF\"> 400ms</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Send 64 KB â€” much larger than the 1 Kbps throughput can drain quickly</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python3</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"import socket; s = socket.create_connection(('127.0.0.1', 8080)); </span><span style=\"color:#79B8FF\">\\</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    data = b'X' * 65536; s.sendall(data); received = b''; </span><span style=\"color:#79B8FF\">\\</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    while len(received) &#x3C; len(data): received += s.recv(4096); </span><span style=\"color:#79B8FF\">\\</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    print('OK' if received == data else 'DATA MISMATCH')\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Clean up the traffic shaping</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">sudo</span><span style=\"color:#9ECBFF\"> tc</span><span style=\"color:#9ECBFF\"> qdisc</span><span style=\"color:#9ECBFF\"> del</span><span style=\"color:#9ECBFF\"> dev</span><span style=\"color:#9ECBFF\"> lo</span><span style=\"color:#9ECBFF\"> root</span></span></code></pre></div>\n<p>With correct write buffering, you should see &quot;OK&quot;. Without it (M1&#39;s broken write path), you&#39;d see a hang or &quot;DATA MISMATCH&quot;.\n<strong>Test 2: Idle timeout enforcement</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Open a connection and don't send anything</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">nc</span><span style=\"color:#9ECBFF\"> localhost</span><span style=\"color:#79B8FF\"> 8080</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Wait 31 seconds</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># The server should close the connection (you'll see the nc session end)</span></span></code></pre></div>\n<p>Check your server&#39;s stderr for &quot;Idle timeout: closing fd N&quot;.\n<strong>Test 3: EPOLLOUT deregistration (no CPU spin)</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Start the server</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">./echo_server_m2</span><span style=\"color:#E1E4E8\"> &#x26;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Check CPU usage while idle (should be ~0%)</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">top</span><span style=\"color:#79B8FF\"> -p</span><span style=\"color:#E1E4E8\"> $(</span><span style=\"color:#B392F0\">pgrep</span><span style=\"color:#9ECBFF\"> echo_server_m2</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n<p>If EPOLLOUT is incorrectly left armed, you&#39;ll see the process at 100% CPU even with no connected clients. Correct implementation idles at &lt;0.1% CPU.\n<strong>Test 4: Multiple simultaneous timers</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/* Add to main() for testing: verify heap ordering */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">timer_set</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#B392F0\">now_ms</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 30000</span><span style=\"color:#E1E4E8\">);</span><span style=\"color:#6A737D\">  /* fd 10 expires in 30s */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">timer_set</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">11</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#B392F0\">now_ms</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 5000</span><span style=\"color:#E1E4E8\">);</span><span style=\"color:#6A737D\">   /* fd 11 expires in 5s  */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">timer_set</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">12</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#B392F0\">now_ms</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 15000</span><span style=\"color:#E1E4E8\">);</span><span style=\"color:#6A737D\">  /* fd 12 expires in 15s */</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/* Heap root should be fd 11 (soonest) */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">assert</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">timer_heap</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">].fd </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 11</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">printf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Timer ordering: OK</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">);</span></span></code></pre></div>\n<hr>\n<h2 id=\"hardware-soul-memory-and-cache-analysis\">Hardware Soul: Memory and Cache Analysis</h2>\n<h2 id=\"write-buffer-access-pattern-when-conn_write-is-on-the-hot-path-every-response-triggers-a-write-attempt-the-write_buf-struct-and-the-first-cache-line-of-wb-gtdata-will-be-l1-hot-for-recently-active-connections-for-10k-connections-with-uniform-activity-the-working-set-is-10000-24-bytes-struct-4kb-average-buffer-40-mbfitting-in-l3-cache-on-a-server-cpu-but-exceeding-l1l2-connections-not-recently-active-will-cause-l3-cache-misses-on-first-access-40-cycles-each-timer-heap-cache-behavior-the-full-heap-at-65536-entries-is-768-kbfits-in-l2-cache-typically-256-kb2-mb-on-modern-server-cpus-heap_sift_down-from-the-root-accesses-indices-0-1-or-2-3-or-4-56-or-78-the-first-34-levels-15-nodes-180-bytes-fit-in-3-cache-lines-log10000-13-levels-deep-means-a-sift-operation-touches-13-cache-linesmostly-l1-hot-for-the-top-levels-l2-warm-for-lower-levels-clock_gettime-cost-each-now_ms-call-is-a-vdso-virtual-dynamic-shared-object-callthe-kernel-maps-a-page-into-your-process39s-address-space-containing-a-fast-timekeeping-function-that-reads-from-a-shared-memory-region-updated-by-the-kernel-avoiding-a-full-syscall-context-switch-on-modern-linux-with-clock_monotonic-this-costs-3050-ns-rather-than-the-200-ns-of-a-real-syscall-you-call-now_ms-at-least-twice-per-epoll_wait-return-once-for-timer_process_expired-once-for-timer-reset-on-data-receiptroughly-100-ns-total-per-event-loop-iteration-branch-prediction-in-heap_sift_down-the-comparison-timer_heapleftexpiry_ms-lt-timer_heapsmallestexpiry_ms-is-genuinely-unpredictabletimer-expiries-are-scattered-the-branch-predictor-achieves-50-accuracy-here-at-15-cycle-misprediction-cost-13-comparisons-per-sift-50-misprediction-rate-15-cycles-97-cycles-of-branch-misprediction-per-timer-operation-this-is-acceptabletimer-operations-happen-at-most-once-per-connection-per-event-loop-tick\"><strong>Write buffer access pattern</strong>: When <code>conn_write</code> is on the hot path (every response triggers a write attempt), the <code>write_buf</code> struct and the first cache line of <code>wb-&gt;data</code> will be L1-hot for recently active connections. For 10K connections with uniform activity, the working set is 10,000 Ã— (24 bytes struct + <del>4KB average buffer) â‰ˆ 40 MBâ€”fitting in L3 cache on a server CPU but exceeding L1/L2. Connections not recently active will cause L3 cache misses on first access (</del>40 cycles each).\n<strong>Timer heap cache behavior</strong>: The full heap at 65,536 entries is 768 KBâ€”fits in L2 cache (typically 256 KBâ€“2 MB) on modern server CPUs. <code>heap_sift_down</code> from the root accesses indices 0, 1 or 2, 3 or 4, 5â€“6 or 7â€“8... The first 3â€“4 levels (15 nodes, 180 bytes) fit in 3 cache lines. Logâ‚‚(10,000) â‰ˆ 13 levels deep means a sift operation touches ~13 cache linesâ€”mostly L1-hot for the top levels, L2-warm for lower levels.\n<strong><code>clock_gettime</code> cost</strong>: Each <code>now_ms()</code> call is a <code>vDSO</code> (virtual Dynamic Shared Object) callâ€”the kernel maps a page into your process&#39;s address space containing a fast timekeeping function that reads from a shared memory region updated by the kernel, avoiding a full syscall context switch. On modern Linux with CLOCK_MONOTONIC, this costs ~30â€“50 ns rather than the ~200 ns of a real syscall. You call <code>now_ms()</code> at least twice per <code>epoll_wait</code> return (once for <code>timer_process_expired</code>, once for timer reset on data receipt)â€”roughly 100 ns total per event loop iteration.\n<strong>Branch prediction in <code>heap_sift_down</code></strong>: The comparison <code>timer_heap[left].expiry_ms &lt; timer_heap[smallest].expiry_ms</code> is genuinely unpredictableâ€”timer expiries are scattered. The branch predictor achieves ~50% accuracy here. At 15-cycle misprediction cost, 13 comparisons per sift Ã— 50% misprediction rate Ã— 15 cycles â‰ˆ 97 cycles of branch misprediction per timer operation. This is acceptableâ€”timer operations happen at most once per connection per event loop tick.</h2>\n<h2 id=\"design-decision-min-heap-vs-timer-wheel\">Design Decision: Min-Heap vs Timer Wheel</h2>\n<table>\n<thead>\n<tr>\n<th>Property</th>\n<th>Min-Heap</th>\n<th>Single-Level Timer Wheel</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Insert</strong></td>\n<td>O(log N)</td>\n<td>O(1)</td>\n</tr>\n<tr>\n<td><strong>Find next</strong></td>\n<td>O(1) (root)</td>\n<td>O(W) worst case (scan slots)</td>\n</tr>\n<tr>\n<td><strong>Cancel</strong></td>\n<td>O(log N) with idx tracking</td>\n<td>O(1)</td>\n</tr>\n<tr>\n<td><strong>Memory</strong></td>\n<td>N Ã— sizeof(timer_entry)</td>\n<td>W Ã— list_head (W = wheel size)</td>\n</tr>\n<tr>\n<td><strong>Expires clustered at one duration</strong></td>\n<td>Works, but N items at same depth</td>\n<td>Ideal: single slot fires all</td>\n</tr>\n<tr>\n<td><strong>Expires uniformly distributed</strong></td>\n<td>âœ“ Ideal</td>\n<td>Acceptable with small W</td>\n</tr>\n<tr>\n<td><strong>Implementation complexity</strong></td>\n<td>Low</td>\n<td>Medium (slot management)</td>\n</tr>\n<tr>\n<td><strong>Cache behavior</strong></td>\n<td>Top levels cache-hot</td>\n<td>Slot access pattern-dependent</td>\n</tr>\n<tr>\n<td><strong>Used by</strong></td>\n<td>libuv, Nginx (red-black tree)</td>\n<td>Linux kernel, Kafka, Netty</td>\n</tr>\n<tr>\n<td><strong>For this project</strong>: Use the min-heap. Your timers have a fixed duration (30 seconds idle timeout), so N timers cluster at similar absolute timesâ€”but they&#39;re staggered by when connections arrived, so the heap stays balanced. The min-heap&#39;s simplicity is worth more than the timer wheel&#39;s O(1) insert at N &lt; 100K.</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>At N &gt; 100K connections (where logâ‚‚(N) â‰ˆ 17 and wheel overhead is constant), the timer wheel wins. This is why the Linux kernel&#39;s internal timer mechanism uses a hierarchical 4-level timer wheelâ€”it manages millions of kernel timers efficiently.</td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<hr>\n<h2 id=\"knowledge-cascade-what-this-unlocks\">Knowledge Cascade: What This Unlocks</h2>\n<h2 id=\"redis39s-write-behind-pattern-redis39s-event-loop-aec-implements-exactly-the-epollout-register-flush-deregister-cycle-you-just-built-when-a-redis-command-generates-a-reply-aec-calls-aecreatefileeventel-c-gtfd-ae_writable-sendreplytoclient-c-after-sendreplytoclient-drains-c-gtbuf-it-calls-aedeletefileeventel-c-gtfd-ae_writable-this-is-how-redis-serves-100k-clientssecond-without-a-dedicated-writer-threadthe-same-pattern-scaled-the-redis-source-in-networkingcwritetoclient-is-worth-reading-alongside-what-you39ve-built-here-you39ll-recognize-every-decision-the-go-runtime39s-timer-integration-go39s-runtime-uses-an-epoll_wait-based-netpoller-in-runtimenetpoll_epollgo-with-the-same-timeout-trick-you-implemented-when-a-goroutine-calls-timeafter30-timesecond-the-runtime-inserts-a-timer-into-a-min-heap-in-runtimetimego-and-adjusts-the-next-epoll_wait-timeout-when-epoll_wait-times-out-the-runtime-fires-timer-callbacks-which-resume-sleeping-goroutines-you39ve-now-implemented-in-c-and-from-scratch-the-exact-mechanism-that-makes-go39s-timesleep-and-contextwithtimeout-work-without-os-threads-timerfd_create-for-sub-millisecond-timers-your-current-implementation-has-1ms-timer-resolutionepoll_wait39s-timeout-is-in-integer-milliseconds-for-timers-needing-microsecond-precision-real-time-audio-trading-systems-sensor-fusion-use-timerfd_createclock_monotonic-tfd_nonblock-this-creates-a-file-descriptor-that-becomes-readable-when-a-timer-expiresyou-register-it-with-epoll-like-any-other-fd-timerfd_settime-accepts-nanosecond-precision-the-tradeoff-one-fd-per-timer-vs-your-heap39s-single-timeout-parameter-covering-all-timers-use-timerfd-when-you-need-precision-use-the-heap-timeout-pattern-when-you-need-scale-slow-loris-the-attack-you39ve-already-defended-against-write_buf_max-is-your-first-line-of-defense-against-the-slow-loris-http-attack-documented-by-robert-hansen-2009-the-attack-sends-partial-http-requests-just-enough-to-look-like-valid-traffic-and-never-completes-them-holding-connections-open-indefinitely-your-idle-timeout-is-the-second-defense-any-connection-that-hasn39t-sent-a-complete-request-in-30-seconds-is-closed-production-servers-combine-both-write_buf_max-guards-against-slow-readers-idle-timeout-guards-against-slow-senders-together-they-bound-both-memory-consumption-and-fd-exhaustion-io_uring-and-timer-integration-in-io_uring-linux-51-the-ioring_op_timeout-operation-submits-a-timer-to-the-ring-without-an-external-fd-the-completion-event-fires-after-n-nanoseconds-combined-with-ioring_op_link_timeout-you-can-automatically-cancel-an-in-flight-read-if-it-doesn39t-complete-within-a-deadlinesomething-epoll-cannot-express-natively-understanding-your-current-epoll_wait-timeout-mechanism-is-the-prerequisite-for-understanding-why-io_uring39s-timeout-model-is-more-expressive\"><strong>Redis&#39;s write-behind pattern</strong>: Redis&#39;s event loop (<code>ae.c</code>) implements exactly the EPOLLOUT register-flush-deregister cycle you just built. When a Redis command generates a reply, <code>ae.c</code> calls <code>aeCreateFileEvent(el, c-&gt;fd, AE_WRITABLE, sendReplyToClient, c)</code>. After <code>sendReplyToClient</code> drains <code>c-&gt;buf</code>, it calls <code>aeDeleteFileEvent(el, c-&gt;fd, AE_WRITABLE)</code>. This is how Redis serves 100K+ clients/second without a dedicated writer threadâ€”the same pattern, scaled. The Redis source in <code>networking.c:writeToClient()</code> is worth reading alongside what you&#39;ve built here; you&#39;ll recognize every decision.\n<strong>The Go runtime&#39;s timer integration</strong>: Go&#39;s runtime uses an <code>epoll_wait</code>-based netpoller (in <code>runtime/netpoll_epoll.go</code>) with the same timeout trick you implemented. When a goroutine calls <code>time.After(30 * time.Second)</code>, the runtime inserts a timer into a min-heap (in <code>runtime/time.go</code>) and adjusts the next <code>epoll_wait</code> timeout. When <code>epoll_wait</code> times out, the runtime fires timer callbacks, which resume sleeping goroutines. You&#39;ve now implemented, in C and from scratch, the exact mechanism that makes Go&#39;s <code>time.Sleep</code> and <code>context.WithTimeout</code> work without OS threads.\n<strong><code>timerfd_create</code> for sub-millisecond timers</strong>: Your current implementation has 1ms timer resolutionâ€”<code>epoll_wait</code>&#39;s timeout is in integer milliseconds. For timers needing microsecond precision (real-time audio, trading systems, sensor fusion), use <code>timerfd_create(CLOCK_MONOTONIC, TFD_NONBLOCK)</code>. This creates a file descriptor that becomes readable when a timer expiresâ€”you register it with epoll like any other fd. <code>timerfd_settime</code> accepts nanosecond precision. The tradeoff: one fd per timer, vs your heap&#39;s single timeout parameter covering all timers. Use <code>timerfd</code> when you need precision; use the heap timeout pattern when you need scale.\n<strong>Slow loris: the attack you&#39;ve already defended against</strong>: <code>WRITE_BUF_MAX</code> is your first line of defense against the slow loris HTTP attack (documented by Robert Hansen, 2009). The attack sends partial HTTP requests (just enough to look like valid traffic) and never completes them, holding connections open indefinitely. Your idle timeout is the second defense: any connection that hasn&#39;t sent a complete request in 30 seconds is closed. Production servers combine both: <code>WRITE_BUF_MAX</code> guards against slow readers, idle timeout guards against slow senders. Together they bound both memory consumption and fd exhaustion.\n<strong>io_uring and timer integration</strong>: In io_uring (Linux 5.1+), the <code>IORING_OP_TIMEOUT</code> operation submits a timer to the ring without an external fd. The completion event fires after N nanoseconds. Combined with <code>IORING_OP_LINK_TIMEOUT</code>, you can automatically cancel an in-flight read if it doesn&#39;t complete within a deadlineâ€”something epoll cannot express natively. Understanding your current <code>epoll_wait</code> timeout mechanism is the prerequisite for understanding why io_uring&#39;s timeout model is more expressive.</h2>\n<h2 id=\"pitfall-reference-the-five-ways-this-breaks\">Pitfall Reference: The Five Ways This Breaks</h2>\n<h2 id=\"pitfall-1-leaving-epollout-armed-when-write-buffer-is-empty-symptom-100-cpu-usage-even-with-zero-active-connections-top-shows-your-server-spinning-fix-in-conn_flush-always-call-epoll_ctlepoll_ctl_mod-to-remove-epollout-when-wbuf_is_empty-returns-true-pitfall-2-not-processing-all-expired-timers-per-tick-symptom-under-load-connections-stay-open-far-past-their-idle-timeout-timer-heap-grows-unboundedly-fix-timer_process_expired-loops-while-timer_heap_size-gt-0-ampamp-timer_heap0expiry_ms-lt-now-do-not-break-after-the-first-expiry-pitfall-3-missing-timer_cancel-in-conn_close-symptom-after-a-connection-closes-the-timer-fires-and-conn_close-is-called-again-on-an-already-freed-now-potentially-reused-fdclassic-use-after-free-fix-always-cancel-the-timer-in-conn_close-and-guard-with-if-c-gtactive-return-at-the-top-of-conn_close-pitfall-4-timer-wheel-slot-count-not-a-power-of-2-if-you-implement-a-timer-wheel-instead-of-a-min-heap-symptom-modulo-operation-is-expensive-integer-division-instead-of-bitwise-and-performance-degradation-visible-in-profiling-fix-use-wheel-size-as-a-power-of-2-eg-256-512-compute-slot-as-now_ms-resolution-amp-wheel_size-1-pitfall-5-closing-a-connection-without-freeing-the-write-buffer-symptom-memory-leak-at-4-kb-per-closed-connection-server-rss-grows-unboundedly-over-hours-fix-conn_close-must-call-wbuf_freeampc-gtwbuf-verify-with-valgrind-leak-checkfull-echo_server_m2-under-connection-churn\"><strong>Pitfall 1: Leaving EPOLLOUT armed when write buffer is empty</strong>\n<em>Symptom</em>: 100% CPU usage even with zero active connections; <code>top</code> shows your server spinning.\n<em>Fix</em>: In <code>conn_flush</code>, always call <code>epoll_ctl(EPOLL_CTL_MOD)</code> to remove <code>EPOLLOUT</code> when <code>wbuf_is_empty()</code> returns true.\n<strong>Pitfall 2: Not processing all expired timers per tick</strong>\n<em>Symptom</em>: Under load, connections stay open far past their idle timeout; timer heap grows unboundedly.\n<em>Fix</em>: <code>timer_process_expired</code> loops <code>while (timer_heap_size &gt; 0 &amp;&amp; timer_heap[0].expiry_ms &lt;= now)</code>. Do not break after the first expiry.\n<strong>Pitfall 3: Missing <code>timer_cancel</code> in <code>conn_close</code></strong>\n<em>Symptom</em>: After a connection closes, the timer fires and <code>conn_close</code> is called again on an already-freed (now potentially reused) fdâ€”classic use-after-free.\n<em>Fix</em>: Always cancel the timer in <code>conn_close</code>, and guard with <code>if (!c-&gt;active) return</code> at the top of <code>conn_close</code>.\n<strong>Pitfall 4: Timer wheel slot count not a power of 2</strong>\n<em>(If you implement a timer wheel instead of a min-heap)</em>\n<em>Symptom</em>: Modulo operation is expensive (integer division instead of bitwise AND); performance degradation visible in profiling.\n<em>Fix</em>: Use wheel size as a power of 2 (e.g., 256, 512); compute slot as <code>(now_ms / resolution) &amp; (WHEEL_SIZE - 1)</code>.\n<strong>Pitfall 5: Closing a connection without freeing the write buffer</strong>\n<em>Symptom</em>: Memory leak at ~4 KB per closed connection; server RSS grows unboundedly over hours.\n<em>Fix</em>: <code>conn_close</code> must call <code>wbuf_free(&amp;c-&gt;wbuf)</code>. Verify with <code>valgrind --leak-check=full ./echo_server_m2</code> under connection churn.</h2>\n<!-- END_MS -->\n\n\n<!-- MS_ID: build-event-loop-m3 -->\n<!-- MS_ID: build-event-loop-m3 -->\n<h1 id=\"reactor-api-and-callback-dispatch\">Reactor API and Callback Dispatch</h1>\n<h2 id=\"the-problem-with-what-you39ve-built-so-far\">The Problem With What You&#39;ve Built So Far</h2>\n<p>Look at your event loop from Milestone 2. It works. It handles 10,000 connections, buffers writes, fires idle timeouts. But examine the structure of the dispatch loop:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">; i </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> n_ready; i</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> fd      </span><span style=\"color:#F97583\">=</span><span style=\"color:#FFAB70\"> events</span><span style=\"color:#E1E4E8\">[i].data.fd;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint32_t</span><span style=\"color:#E1E4E8\"> ev </span><span style=\"color:#F97583\">=</span><span style=\"color:#FFAB70\"> events</span><span style=\"color:#E1E4E8\">[i].events;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (fd </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> listen_fd) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        handle_new_connection</span><span style=\"color:#E1E4E8\">(epoll_fd, listen_fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    } </span><span style=\"color:#F97583\">else</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> (ev </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\"> (EPOLLERR </span><span style=\"color:#F97583\">|</span><span style=\"color:#E1E4E8\"> EPOLLHUP)) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        conn_close</span><span style=\"color:#E1E4E8\">(epoll_fd, fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    } </span><span style=\"color:#F97583\">else</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (ev </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\"> EPOLLIN)  </span><span style=\"color:#B392F0\">handle_client_read</span><span style=\"color:#E1E4E8\">(epoll_fd, fd);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (ev </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\"> EPOLLOUT) </span><span style=\"color:#B392F0\">handle_client_write</span><span style=\"color:#E1E4E8\">(epoll_fd, fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<p>Every time you add a new type of fd to monitorâ€”a timer fd, a signal fd, a UNIX domain socket, a pipe from a worker threadâ€”you add another branch to this <code>if/else</code> chain. The event loop and the application logic are fused together. Want to use this event loop infrastructure for a different application (an HTTP server, a database client, a log tailer)? You rewrite it from scratch.\nThe echo server leaked through into the event loop. The write-buffer logic leaked through. The specific meaning of &quot;readable&quot; for the listen fd (accept a connection) versus a client fd (read data) is hardcoded.\nThis is the same problem that motivated operating systems to separate kernel from userspace, and web frameworks to separate routing from request handling. <strong>You need a contract</strong>â€”a stable interfaceâ€”between the event-detection machinery and the application code that responds to events.\nThat contract is the <strong>Reactor pattern</strong>.</p>\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Fdiag-m3-reactor-api-architecture.svg\" alt=\"Reactor Pattern: Component Architecture\"></p>\n<hr>\n<h2 id=\"the-revelation-modifying-state-during-iteration-is-a-minefield\">The Revelation: Modifying State During Iteration Is a Minefield</h2>\n<p>Before designing the API, you need to feel the hazard that makes this milestone&#39;s core design problem non-obvious.\nHere&#39;s what most developers assume: once you have a clean reactor API with <code>reactor_register(fd, callback)</code> and <code>reactor_deregister(fd)</code>, you can call those functions freely from inside any callback. After all, you&#39;re just updating a data structureâ€”how could that be dangerous?\nHere&#39;s the scenario that breaks this assumption.\n<code>epoll_wait</code> returns with 8 events. You begin iterating. Your callback for event <code>[2]</code> handles an error on <code>fd=7</code> and calls <code>reactor_deregister(fd=7)</code>, which calls <code>conn_close</code>, which calls <code>close(7)</code>. The fd is freed. The kernel can now reuse fd 7 for the very next <code>accept()</code> call or <code>socket()</code> callâ€”this can happen <em>immediately</em> if another thread calls <code>socket()</code>, or even within your own event loop if some other callback in this batch accepts a new connection.\nNow you process event <code>[5]</code>. The kernel told you <code>fd=7</code> was readable. But <code>fd=7</code> is now a <em>completely different connection</em>â€”or worse, <code>connections[7]</code> contains freed or re-initialized state from the new connection. You dispatch to a callback with the wrong data. The old callback thinks it&#39;s reading from the original connection; it&#39;s actually corrupting the new one.</p>\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Fdiag-m3-use-after-free-scenario.svg\" alt=\"Data Walk: Use-After-Free During Event Dispatch\"></p>\n<p>This is a <strong>use-after-free</strong> bug and an <strong>fd reuse race</strong> combined into one. It&#39;s timing-dependent: it appears in production under high load (when connection churn is high and fds are reused rapidly) and disappears in unit tests (where you control the single client). It manifests as corrupted state, wrong responses sent to wrong clients, and occasional segfaults in callback dispatch.\nThe same bug class exists in:</p>\n<ul>\n<li><strong>Browser DOM</strong>: calling <code>element.remove()</code> inside a <code>forEach</code> over a NodeList mutates the list you&#39;re iterating</li>\n<li><strong>Game engine ECS</strong>: destroying an entity during a system update invalidates the component array iterator</li>\n<li><strong>Database cursors</strong>: deleting a row while iterating a result set</li>\n<li><strong>Linux kernel softirqs</strong>: interrupt handlers modifying lists that the bottom-half processor is currently walking\nEvery event-driven system ever built has encountered this. Every one has solved it the same way: <strong>defer modifications to after the iteration completes</strong>.</li>\n</ul>\n<hr>\n<h2 id=\"designing-the-reactor-api\">Designing the Reactor API</h2>\n<p>The API you&#39;re about to build has exactly five public functions. Here&#39;s the contract each one makes:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/* reactor.h â€” Public API. Users of this library never touch epoll directly. */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#ifndef</span><span style=\"color:#B392F0\"> REACTOR_H</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> REACTOR_H</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdint.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdbool.h></span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/* Forward declaration â€” implementation is opaque */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> reactor reactor;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Event type flags â€” what a callback can be notified about.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Designed as a bitmask: READABLE | WRITABLE is valid.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> REACTOR_READABLE</span><span style=\"color:#E1E4E8\">   (</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#F97583\">u</span><span style=\"color:#F97583\"> &#x3C;&#x3C;</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">)</span><span style=\"color:#6A737D\">   /* data available to read */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> REACTOR_WRITABLE</span><span style=\"color:#E1E4E8\">   (</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#F97583\">u</span><span style=\"color:#F97583\"> &#x3C;&#x3C;</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">)</span><span style=\"color:#6A737D\">   /* socket buffer has space */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> REACTOR_ERROR</span><span style=\"color:#E1E4E8\">      (</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#F97583\">u</span><span style=\"color:#F97583\"> &#x3C;&#x3C;</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">)</span><span style=\"color:#6A737D\">   /* EPOLLERR: socket error */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> REACTOR_HANGUP</span><span style=\"color:#E1E4E8\">     (</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#F97583\">u</span><span style=\"color:#F97583\"> &#x3C;&#x3C;</span><span style=\"color:#79B8FF\"> 3</span><span style=\"color:#E1E4E8\">)</span><span style=\"color:#6A737D\">   /* EPOLLHUP: peer closed */</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * io_callback_fn â€” Signature for I/O event callbacks.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * fd:        the file descriptor that has an event</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * events:    bitmask of REACTOR_READABLE / REACTOR_WRITABLE / etc.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * user_data: opaque pointer registered with reactor_register()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * The callback may call reactor_register, reactor_deregister, or</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * reactor_defer. It must NOT free reactor itself.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> void</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">io_callback_fn)(</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\"> fd, </span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#E1E4E8\"> events, </span><span style=\"color:#F97583\">void</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\">user_data);</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * timer_callback_fn â€” Signature for timer callbacks.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * reactor: the reactor, so the callback can defer or schedule more timers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * user_data: opaque pointer passed to reactor_set_timeout / set_interval</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> void</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">timer_callback_fn)(reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">r, </span><span style=\"color:#F97583\">void</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\">user_data);</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * task_fn â€” Signature for deferred tasks.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * reactor: allows deferred tasks to schedule further deferred tasks</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * user_data: opaque pointer passed to reactor_defer()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> void</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">task_fn)(reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">r, </span><span style=\"color:#F97583\">void</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\">user_data);</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/* Lifecycle */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">reactor_create</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\">     reactor_destroy</span><span style=\"color:#E1E4E8\">(reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">r</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\">     reactor_run</span><span style=\"color:#E1E4E8\">(reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">r</span><span style=\"color:#E1E4E8\">);</span><span style=\"color:#6A737D\">        /* blocks until reactor_stop() called */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\">     reactor_stop</span><span style=\"color:#E1E4E8\">(reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">r</span><span style=\"color:#E1E4E8\">);</span><span style=\"color:#6A737D\">       /* causes reactor_run() to return */</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/* I/O event registration */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\">  reactor_register</span><span style=\"color:#E1E4E8\">(reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">r</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#FFAB70\"> events</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                      io_callback_fn </span><span style=\"color:#FFAB70\">cb</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">user_data</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> reactor_deregister</span><span style=\"color:#E1E4E8\">(reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">r</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/* Timer API */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\">  reactor_set_timeout</span><span style=\"color:#E1E4E8\">(reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">r</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#FFAB70\"> ms</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                         timer_callback_fn </span><span style=\"color:#FFAB70\">cb</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">user_data</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\">  reactor_set_interval</span><span style=\"color:#E1E4E8\">(reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">r</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#FFAB70\"> ms</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                          timer_callback_fn </span><span style=\"color:#FFAB70\">cb</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">user_data</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> reactor_cancel_timer</span><span style=\"color:#E1E4E8\">(reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">r</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> timer_id</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/* Deferred task queue */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> reactor_defer</span><span style=\"color:#E1E4E8\">(reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">r</span><span style=\"color:#E1E4E8\">, task_fn </span><span style=\"color:#FFAB70\">fn</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">user_data</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#endif</span><span style=\"color:#6A737D\"> /* REACTOR_H */</span></span></code></pre></div>\n<p>Notice what is absent from this header: <code>epoll_create1</code>, <code>epoll_ctl</code>, <code>epoll_wait</code>, <code>struct epoll_event</code>, anything from <code>&lt;sys/epoll.h&gt;</code>. The user of this library never touches epoll. They register interest, provide callbacks, and let the reactor handle the rest.</p>\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Fdiag-m3-callback-signature-design.svg\" alt=\"Callback Design: Function Pointer and void* user_data Pattern\"></p>\n<blockquote>\n<p><strong>Why <code>void *user_data</code>?</strong> C lacks generics. Without <code>void *user_data</code>, every callback would need to use global variables or cast integers to pointers. The <code>user_data</code> patternâ€”a single opaque pointer threaded from registration through to callback invocationâ€”is the standard solution in C event libraries (libevent, libev, libuv, GLib&#39;s main loop). You pass in a <code>conn_state *</code> cast to <code>void *</code>; the callback casts it back. This gives you type-safe (by convention) context without a garbage collector. In Rust, you&#39;d use closures that capture their environment; in C, <code>user_data</code> is the manual equivalent.</p>\n</blockquote>\n<hr>\n<h2 id=\"the-internal-structure-what-the-reactor-holds\">The Internal Structure: What the Reactor Holds</h2>\n<p>The reactor&#39;s internal state must track:</p>\n<ol>\n<li>The epoll fd (from Milestone 1)</li>\n<li>A per-fd registration table: which callback to call, what user_data to pass, what events are registered</li>\n<li>The timer heap (from Milestone 2)</li>\n<li>The deferred task queue</li>\n<li>A &quot;pending modifications&quot; queueâ€”the key addition of this milestone</li>\n<li>A flag indicating whether dispatch is currently in progress</li>\n</ol>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/* reactor_internal.h â€” implementation details, not exposed to users */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"reactor.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;sys/epoll.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> MAX_FDS</span><span style=\"color:#79B8FF\">       65536</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> MAX_EVENTS</span><span style=\"color:#79B8FF\">    1024</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> DEFER_QUEUE_INITIAL</span><span style=\"color:#79B8FF\"> 64</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * fd_handler - Per-fd registration record.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Memory layout (64-bit):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   offset  0: callback    (8 bytes â€” function pointer)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   offset  8: user_data   (8 bytes â€” void*)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   offset 16: events      (4 bytes â€” uint32_t)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   offset 20: registered  (1 byte  â€” bool)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   offset 21: zombie      (1 byte  â€” bool, see deferred close)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   offset 22: [2 bytes padding]</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   Total: 24 bytes Ã— 65536 = 1.5 MB for the registration table</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * 'zombie' means: callback called reactor_deregister(fd) while we were</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * in the dispatch loop. We mark it zombie and skip its pending events.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * The actual epoll_ctl(DEL) and cleanup happen after the loop.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    io_callback_fn callback;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    void</span><span style=\"color:#F97583\">          *</span><span style=\"color:#E1E4E8\">user_data;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint32_t</span><span style=\"color:#E1E4E8\">       events;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\">           registered;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\">           zombie;</span><span style=\"color:#6A737D\">       /* deregistration deferred */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} fd_handler;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * deferred_mod - A pending epoll_ctl operation to run after dispatch.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Operations that arrive during dispatch are queued here and executed</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * after all events in the current batch are processed.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> enum</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    MOD_ADD,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    MOD_MOD,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    MOD_DEL,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} mod_op;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    mod_op   op;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\">      fd;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint32_t</span><span style=\"color:#E1E4E8\"> events;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} deferred_mod;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * deferred_task - One entry in the post-dispatch task queue.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    task_fn  fn;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    void</span><span style=\"color:#F97583\">    *</span><span style=\"color:#E1E4E8\">user_data;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} deferred_task;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * reactor - The complete reactor state.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * This is the struct hidden behind the opaque typedef in reactor.h.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Fields are grouped by access pattern:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   Hot path (accessed every epoll_wait iteration): epoll_fd, handlers, dispatching</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   Cold path (accessed on modification): mods, defer_queue</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">struct</span><span style=\"color:#E1E4E8\"> reactor {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\">        epoll_fd;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\">       running;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\">       dispatching;</span><span style=\"color:#6A737D\">   /* true while iterating epoll_wait results */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    fd_handler </span><span style=\"color:#FFAB70\">handlers</span><span style=\"color:#E1E4E8\">[MAX_FDS];</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Timer heap from Milestone 2 â€” integrated here */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    timer_entry </span><span style=\"color:#FFAB70\">timer_heap</span><span style=\"color:#E1E4E8\">[TIMER_HEAP_MAX];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\">         timer_heap_size;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\">         next_timer_id;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Deferred epoll_ctl modifications â€” applied after dispatch loop */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    deferred_mod </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">mods;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\">           mods_len;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\">           mods_cap;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Deferred task queue â€” runs after I/O dispatch, before next epoll_wait */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    deferred_task </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">defer_queue;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\">            defer_len;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\">            defer_cap;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">};</span></span></code></pre></div>\n<h2 id=\"the-key-fields-are-dispatching-zombie-on-each-fd_handler-and-the-mods-queue-together-they-implement-the-deferred-modification-pattern\">The key fields are <code>dispatching</code>, <code>zombie</code> on each <code>fd_handler</code>, and the <code>mods</code> queue. Together they implement the deferred-modification pattern.</h2>\n<h2 id=\"creating-and-destroying-the-reactor\">Creating and Destroying the Reactor</h2>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"reactor_internal.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdlib.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;string.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdio.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;errno.h></span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">reactor_create</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">r </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> calloc</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(reactor));</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">r) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        perror</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"calloc reactor\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    r->epoll_fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> epoll_create1</span><span style=\"color:#E1E4E8\">(EPOLL_CLOEXEC);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (r->epoll_fd </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        perror</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"epoll_create1\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        free</span><span style=\"color:#E1E4E8\">(r);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Initialize all handler slots as unregistered */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">; i </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> MAX_FDS; i</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        r->handlers[i].registered </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        r->handlers[i].zombie     </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    r->mods </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> malloc</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(deferred_mod) </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> DEFER_QUEUE_INITIAL);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    r->mods_cap </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> DEFER_QUEUE_INITIAL;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    r->mods_len </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    r->defer_queue </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> malloc</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(deferred_task) </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> DEFER_QUEUE_INITIAL);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    r->defer_cap </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> DEFER_QUEUE_INITIAL;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    r->defer_len </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    r->running    </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    r->dispatching </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    r->next_timer_id </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\">  /* 0 is reserved for \"no timer\" */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> r;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> reactor_destroy</span><span style=\"color:#E1E4E8\">(reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">r</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">r) </span><span style=\"color:#F97583\">return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    close</span><span style=\"color:#E1E4E8\">(r->epoll_fd);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    free</span><span style=\"color:#E1E4E8\">(r->mods);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    free</span><span style=\"color:#E1E4E8\">(r->defer_queue);</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Note: we do NOT close registered fds â€” the user owns them */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    free</span><span style=\"color:#E1E4E8\">(r);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<blockquote>\n<p><strong><code>calloc</code> vs <code>malloc</code> + <code>memset</code></strong>: <code>calloc(1, sizeof(reactor))</code> allocates and zeroes the memory in one call. For a 1.5 MB struct, this matters: most modern allocators and the kernel deliver zeroed pages via lazy allocation (copy-on-write zero page), so <code>calloc</code> pays only for pages you actually touch. <code>malloc</code> + <code>memset</code> forces immediate writes to every page, paying the TLB fault and page-in cost upfront. For large structs whose fields are only partially used, <code>calloc</code> is measurably faster to initialize.</p>\n</blockquote>\n<hr>\n<h2 id=\"registering-and-deregistering-fd-handlers\">Registering and Deregistering fd Handlers</h2>\n<p>The registration functions must handle two cases: called outside dispatch (normal) and called inside dispatch (deferred):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * reactor_map_events - Convert REACTOR_* flags to epoll event flags.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * We always include EPOLLERR and EPOLLHUP â€” the kernel reports these</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * regardless of whether you register them, but including them makes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * the semantics explicit. EPOLLRDHUP detects peer half-close cleanly.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> uint32_t</span><span style=\"color:#B392F0\"> reactor_map_events</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#FFAB70\"> reactor_events</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint32_t</span><span style=\"color:#E1E4E8\"> ev </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> EPOLLERR </span><span style=\"color:#F97583\">|</span><span style=\"color:#E1E4E8\"> EPOLLHUP </span><span style=\"color:#F97583\">|</span><span style=\"color:#E1E4E8\"> EPOLLRDHUP;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (reactor_events </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\"> REACTOR_READABLE) ev </span><span style=\"color:#F97583\">|=</span><span style=\"color:#E1E4E8\"> EPOLLIN;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (reactor_events </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\"> REACTOR_WRITABLE) ev </span><span style=\"color:#F97583\">|=</span><span style=\"color:#E1E4E8\"> EPOLLOUT;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> ev;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * reactor_apply_mod - Execute one deferred_mod immediately.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Only call this outside the dispatch loop.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> reactor_apply_mod</span><span style=\"color:#E1E4E8\">(reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">r</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#E1E4E8\"> deferred_mod </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">mod</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (mod->op </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> MOD_DEL) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        epoll_ctl</span><span style=\"color:#E1E4E8\">(r->epoll_fd, EPOLL_CTL_DEL, mod->fd, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    struct</span><span style=\"color:#E1E4E8\"> epoll_event ev;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ev.events   </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> mod->events;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ev.data.ptr </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#E1E4E8\">r->handlers[mod->fd];</span><span style=\"color:#6A737D\">  /* store pointer, not int */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> op </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (mod->op </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> MOD_ADD) </span><span style=\"color:#F97583\">?</span><span style=\"color:#E1E4E8\"> EPOLL_CTL_ADD </span><span style=\"color:#F97583\">:</span><span style=\"color:#E1E4E8\"> EPOLL_CTL_MOD;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">epoll_ctl</span><span style=\"color:#E1E4E8\">(r->epoll_fd, op, mod->fd, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">ev) </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* ENOENT on MOD means fd was already removed â€” not fatal */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">(op </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EPOLL_CTL_MOD </span><span style=\"color:#F97583\">&#x26;&#x26;</span><span style=\"color:#E1E4E8\"> errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> ENOENT)) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            perror</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"epoll_ctl in apply_mod\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * enqueue_mod - Add a deferred_mod to the pending queue.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Called when modification arrives during dispatch.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> enqueue_mod</span><span style=\"color:#E1E4E8\">(reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">r</span><span style=\"color:#E1E4E8\">, mod_op </span><span style=\"color:#FFAB70\">op</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#FFAB70\"> events</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (r->mods_len </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> r->mods_cap) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\"> new_cap </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> r->mods_cap </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        deferred_mod </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">new_mods </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> realloc</span><span style=\"color:#E1E4E8\">(r->mods,</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                                         sizeof</span><span style=\"color:#E1E4E8\">(deferred_mod) </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> new_cap);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">new_mods) </span><span style=\"color:#F97583\">return</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\">  /* OOM: modification is lost, not ideal */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        r->mods     </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> new_mods;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        r->mods_cap </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> new_cap;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    r->mods[r->mods_len</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (deferred_mod){ .op </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> op, .fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> fd, .events </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> events };</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\"> reactor_register</span><span style=\"color:#E1E4E8\">(reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">r</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#FFAB70\"> events</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                     io_callback_fn </span><span style=\"color:#FFAB70\">cb</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">user_data</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (fd </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> ||</span><span style=\"color:#E1E4E8\"> fd </span><span style=\"color:#F97583\">>=</span><span style=\"color:#E1E4E8\"> MAX_FDS) </span><span style=\"color:#F97583\">return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    fd_handler </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">h </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#E1E4E8\">r->handlers[fd];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> was_registered </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> h->registered;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    h->callback   </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> cb;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    h->user_data  </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> user_data;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    h->events     </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> events;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    h->registered </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    h->zombie     </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\">  /* re-registration clears zombie status */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint32_t</span><span style=\"color:#E1E4E8\"> epoll_ev </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> reactor_map_events</span><span style=\"color:#E1E4E8\">(events);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    mod_op   op       </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> was_registered </span><span style=\"color:#F97583\">?</span><span style=\"color:#E1E4E8\"> MOD_MOD </span><span style=\"color:#F97583\">:</span><span style=\"color:#E1E4E8\"> MOD_ADD;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (r->dispatching) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * CRITICAL: We're inside the dispatch loop. Calling epoll_ctl now</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * would not corrupt the current events[] array (it's already been</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * copied from the kernel), but it could affect subsequent iterations</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * if we're processing events in batches. More importantly, if we're</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * re-registering an fd that was marked zombie, we must ensure the</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * zombie flag is cleared before any pending events for this fd are</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * dispatched â€” which we've done above. The epoll_ctl can be deferred.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        enqueue_mod</span><span style=\"color:#E1E4E8\">(r, op, fd, epoll_ev);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    } </span><span style=\"color:#F97583\">else</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        struct</span><span style=\"color:#E1E4E8\"> epoll_event ev;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ev.events   </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> epoll_ev;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ev.data.ptr </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> h;</span><span style=\"color:#6A737D\">  /* store pointer to handler, not fd int */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">epoll_ctl</span><span style=\"color:#E1E4E8\">(r->epoll_fd, op </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> MOD_ADD </span><span style=\"color:#F97583\">?</span><span style=\"color:#E1E4E8\"> EPOLL_CTL_ADD </span><span style=\"color:#F97583\">:</span><span style=\"color:#E1E4E8\"> EPOLL_CTL_MOD,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                      fd, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">ev) </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            h->registered </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> was_registered;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> reactor_deregister</span><span style=\"color:#E1E4E8\">(reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">r</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (fd </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> ||</span><span style=\"color:#E1E4E8\"> fd </span><span style=\"color:#F97583\">>=</span><span style=\"color:#E1E4E8\"> MAX_FDS) </span><span style=\"color:#F97583\">return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    fd_handler </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">h </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#E1E4E8\">r->handlers[fd];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">h->registered) </span><span style=\"color:#F97583\">return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (r->dispatching) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * Mark as zombie: the dispatch loop will see this flag and skip</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * any pending events for this fd in the current batch. The actual</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * epoll_ctl(DEL) is deferred to after the dispatch loop.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * WHY NOT call epoll_ctl(DEL) now? Calling it now is technically</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * safe for the current events[] array (it's a local copy), but:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * 1. It signals our intent to the kernel immediately â€” fine.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * 2. More importantly, the fd might be reused by another accept()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         *    before the dispatch loop ends, creating a new handler at the</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         *    same index. The zombie flag prevents dispatching to the OLD</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         *    callback after reuse.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * Setting zombie + deferring DEL is the complete defense.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        h->zombie </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        enqueue_mod</span><span style=\"color:#E1E4E8\">(r, MOD_DEL, fd, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    } </span><span style=\"color:#F97583\">else</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        h->registered </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        h->zombie     </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        epoll_ctl</span><span style=\"color:#E1E4E8\">(r->epoll_fd, EPOLL_CTL_DEL, fd, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<blockquote>\n<p><strong><code>ev.data.ptr</code> vs <code>ev.data.fd</code></strong>: In Milestones 1 and 2, you stored the fd integer in <code>ev.data.fd</code>. Here we store a pointer to the <code>fd_handler</code> struct directly. When the event fires, you retrieve the handler with a single pointer dereference rather than an array index. This is slightly faster (saves one multiplication) andâ€”more importantlyâ€”makes it possible to pass the handler directly to the callback dispatch code. The <code>fd</code> is still accessible via the handler&#39;s context or the file descriptor number recorded elsewhere. Both approaches are valid; production libraries like libevent use <code>data.ptr</code>.</p>\n</blockquote>\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Fdiag-m3-deferred-modification-queue.svg\" alt=\"Deferred Modification Queue: Safe epoll_ctl During Dispatch\"></p>\n<hr>\n<h2 id=\"the-deferred-task-queue\">The Deferred Task Queue</h2>\n<blockquote>\n<p><strong>ðŸ”‘ Foundation: Function pointers and callbacks in C</strong></p>\n<p><strong>1. What it IS</strong>\nA function pointer is a variable that stores the memory address of a function. When you call it, the CPU jumps to that address and executes whatever is there. In C, the syntax <code>void (*fn)(int, void *)</code> declares a variable <code>fn</code> that holds the address of a function taking an <code>int</code> and a <code>void *</code> and returning <code>void</code>.</p>\n<p><strong>2. Why you need it right now</strong>\nThe reactor can&#39;t know in advance what code to run when an event firesâ€”that&#39;s application logic, and the reactor is a library. Instead, the application <em>registers</em> its function by passing its address. The reactor stores that address in the <code>fd_handler.callback</code> field and calls it later via <code>h-&gt;callback(fd, events, h-&gt;user_data)</code>. This is inversion of control: you&#39;re not calling the library, the library is calling you, at a time and in a context it controls.</p>\n<p><strong>3. Key Insight: The Callback Table</strong>\nEvery time you call <code>reactor_register(r, fd, events, my_handler, ctx)</code>, you&#39;re filling in one row of a dispatch tableâ€”a mapping from fd to function. When <code>epoll_wait</code> returns fd 7 as readable, the reactor looks up row 7, finds <code>my_handler</code>, and calls it. This is exactly how virtual function tables (vtables) work in C++ and Rust trait objectsâ€”the function pointer table is the universal mechanism for runtime polymorphism in systems languages.</p>\n</blockquote>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * reactor_defer - Schedule a callback to run after the current I/O dispatch.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Timing guarantee: deferred tasks run after ALL I/O events in the current</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * epoll_wait batch are processed, but before the next epoll_wait call.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Use cases:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   - Close a connection after its callback finishes (safe deferred close)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   - Schedule follow-up work without blocking the I/O dispatch loop</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   - Batch multiple state changes that depend on the full event set</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Note: if called outside dispatch (e.g., from a timer callback that runs</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * after dispatch), the task still runs before the next epoll_wait. This is</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * correct: \"after dispatch\" and \"before next poll\" are the same moment.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> reactor_defer</span><span style=\"color:#E1E4E8\">(reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">r</span><span style=\"color:#E1E4E8\">, task_fn </span><span style=\"color:#FFAB70\">fn</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">user_data</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (r->defer_len </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> r->defer_cap) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\"> new_cap </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> r->defer_cap </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> ?</span><span style=\"color:#E1E4E8\"> DEFER_QUEUE_INITIAL </span><span style=\"color:#F97583\">:</span><span style=\"color:#E1E4E8\"> r->defer_cap </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        deferred_task </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">new_q </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> realloc</span><span style=\"color:#E1E4E8\">(r->defer_queue,</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                                       sizeof</span><span style=\"color:#E1E4E8\">(deferred_task) </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> new_cap);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">new_q) </span><span style=\"color:#F97583\">return</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\">  /* OOM: task is lost */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        r->defer_queue </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> new_q;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        r->defer_cap   </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> new_cap;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    r->defer_queue[r->defer_len</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (deferred_task){ .fn </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> fn, .user_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> user_data };</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * reactor_run_deferred - Execute all pending deferred tasks.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Called after the dispatch loop completes. Tasks themselves may call</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * reactor_defer(), adding new tasks to the queue. We use a snapshot</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * of the current length to process only tasks that existed at the start</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * of this run â€” newly added tasks will run in the next tick.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * WHY snapshot the length? If task[0] calls reactor_defer(task_X),</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * task_X is appended at defer_queue[1]. If we loop to defer_len (which</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * is now 2), we'd process task_X in the same tick. That's sometimes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * desirable, but it can cause unbounded work if tasks keep deferring</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * more tasks. Snapshotting runs exactly one \"generation\" per tick.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> reactor_run_deferred</span><span style=\"color:#E1E4E8\">(reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">r</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> count </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> r->defer_len;</span><span style=\"color:#6A737D\">    /* snapshot */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    r->defer_len </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\">            /* reset; new tasks go to fresh slots */</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* But we need to run old tasks first â€” they may be at index 0..count-1 */</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Swap to a temporary copy so re-entrant defer appends to the real queue */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    deferred_task </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">tasks </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> r->defer_queue;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    r->defer_queue </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> malloc</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(deferred_task) </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> r->defer_cap);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">r->defer_queue) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        r->defer_queue </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> tasks;</span><span style=\"color:#6A737D\">  /* fallback: run in place, re-entrancy broken */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">; i </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> count; i</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#FFAB70\">tasks</span><span style=\"color:#E1E4E8\">[i].</span><span style=\"color:#B392F0\">fn</span><span style=\"color:#E1E4E8\">(r, </span><span style=\"color:#FFAB70\">tasks</span><span style=\"color:#E1E4E8\">[i].user_data);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Execute the snapshot */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">; i </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> count; i</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        tasks</span><span style=\"color:#E1E4E8\">[i].</span><span style=\"color:#B392F0\">fn</span><span style=\"color:#E1E4E8\">(r, </span><span style=\"color:#FFAB70\">tasks</span><span style=\"color:#E1E4E8\">[i].user_data);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    free</span><span style=\"color:#E1E4E8\">(tasks);</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* r->defer_queue now holds any new tasks added during the above execution */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<hr>\n<h2 id=\"timer-integration-one-shot-and-repeating\">Timer Integration: One-Shot and Repeating</h2>\n<p>The timer heap from Milestone 2 gets wrapped in the reactor&#39;s timer API. The key new capability is the repeating interval timerâ€”and the re-entrancy concern it introduces.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * timer_record - Internal timer storage, extends Milestone 2's timer_entry.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * interval_ms: if > 0, timer auto-rearmed after each firing (set_interval)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *              if == 0, timer fires once and is removed (set_timeout)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * id:          user-visible handle for reactor_cancel_timer()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\">       expiry_ms;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint32_t</span><span style=\"color:#E1E4E8\">       interval_ms;</span><span style=\"color:#6A737D\">   /* 0 = one-shot, >0 = repeating */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\">            id;</span><span style=\"color:#6A737D\">            /* unique timer ID */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    timer_callback_fn callback;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    void</span><span style=\"color:#F97583\">          *</span><span style=\"color:#E1E4E8\">user_data;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} timer_record;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * reactor_set_timeout - Fire callback once after 'ms' milliseconds.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Returns a timer ID (> 0) that can be passed to reactor_cancel_timer.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\"> reactor_set_timeout</span><span style=\"color:#E1E4E8\">(reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">r</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#FFAB70\"> ms</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        timer_callback_fn </span><span style=\"color:#FFAB70\">cb</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">user_data</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#B392F0\"> reactor_timer_insert</span><span style=\"color:#E1E4E8\">(r, </span><span style=\"color:#B392F0\">now_ms</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> ms, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#6A737D\"> /* one-shot */</span><span style=\"color:#E1E4E8\">, cb, user_data);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * reactor_set_interval - Fire callback every 'ms' milliseconds.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Returns a timer ID. Call reactor_cancel_timer() to stop it.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Implementation note: on each firing, we re-insert with expiry =</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * previous_expiry + interval_ms (not now_ms() + interval_ms).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * This prevents timer drift: if a callback takes 5ms and the interval</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * is 100ms, the next firing is at 100ms from the original, not 105ms.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Over many iterations, drift accumulates; anchoring to the original</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * expiry keeps the interval accurate.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\"> reactor_set_interval</span><span style=\"color:#E1E4E8\">(reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">r</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#FFAB70\"> ms</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                         timer_callback_fn </span><span style=\"color:#FFAB70\">cb</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">user_data</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#B392F0\"> reactor_timer_insert</span><span style=\"color:#E1E4E8\">(r, </span><span style=\"color:#B392F0\">now_ms</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> ms, ms</span><span style=\"color:#6A737D\"> /* repeating */</span><span style=\"color:#E1E4E8\">, cb, user_data);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * reactor_process_timers - Fire all expired timers.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Called after each epoll_wait return, BEFORE processing I/O events.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Timers are time-sensitive; delaying them until after I/O dispatch</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * would make their precision depend on how long I/O handling takes.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Re-entrancy contract: a timer callback may call reactor_set_timeout,</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * reactor_set_interval, or reactor_cancel_timer. It must NOT call</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * reactor_cancel_timer(r, own_id) for an interval timer from inside</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * its own callback â€” use a flag and cancel from a deferred task instead.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Why? We're iterating the heap while a callback might modify it.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * reactor_cancel_timer calls heap_sift_up/down which changes indices.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * We defend against this by copying the fd/callback before firing,</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * then checking the timer still exists afterward.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> reactor_process_timers</span><span style=\"color:#E1E4E8\">(reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">r</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> now </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> now_ms</span><span style=\"color:#E1E4E8\">();</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    while</span><span style=\"color:#E1E4E8\"> (r->timer_heap_size </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        timer_record </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">top </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (timer_record </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">)</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">r->timer_heap[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (top->expiry_ms </span><span style=\"color:#F97583\">></span><span style=\"color:#E1E4E8\"> now) </span><span style=\"color:#F97583\">break</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Copy what we need before the heap is modified */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        timer_callback_fn cb        </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> top->callback;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        void</span><span style=\"color:#F97583\">             *</span><span style=\"color:#E1E4E8\">ud        </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> top->user_data;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        uint64_t</span><span style=\"color:#E1E4E8\">          prev_exp  </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> top->expiry_ms;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        uint32_t</span><span style=\"color:#E1E4E8\">          interval  </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> top->interval_ms;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\">               id        </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> top->id;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (interval </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            /* Re-arm interval timer BEFORE calling callback.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">             * This way, if the callback cancels the timer, the cancel</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">             * finds it in the heap and removes it cleanly. */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            top->expiry_ms </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> prev_exp </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> interval;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            heap_sift_down</span><span style=\"color:#E1E4E8\">(r, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        } </span><span style=\"color:#F97583\">else</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            /* One-shot: remove from heap */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            reactor_timer_remove_at</span><span style=\"color:#E1E4E8\">(r, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Fire the callback */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        cb</span><span style=\"color:#E1E4E8\">(r, ud);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        (</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">)id;</span><span style=\"color:#6A737D\">  /* used for cancel; not needed here after copy */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<hr>\n<h2 id=\"the-complete-dispatch-loop\">The Complete Dispatch Loop</h2>\n<p>Now all the pieces come together. The main <code>reactor_run</code> function is the nucleus:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> reactor_run</span><span style=\"color:#E1E4E8\">(reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">r</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    struct</span><span style=\"color:#E1E4E8\"> epoll_event </span><span style=\"color:#FFAB70\">events</span><span style=\"color:#E1E4E8\">[MAX_EVENTS];</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    r->running </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    while</span><span style=\"color:#E1E4E8\"> (r->running) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Compute how long to sleep: time until next timer, or forever */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\"> timeout </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> reactor_next_timeout</span><span style=\"color:#E1E4E8\">(r);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\"> n </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> epoll_wait</span><span style=\"color:#E1E4E8\">(r->epoll_fd, events, MAX_EVENTS, timeout);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (n </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EINTR) </span><span style=\"color:#F97583\">continue</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\">   /* signal interrupted: retry */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            perror</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"epoll_wait\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            break</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * Process timers FIRST â€” they may have expired during the I/O wait.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * Timer precision is bounded by how quickly we check after epoll_wait</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * returns. Checking before I/O dispatch gives timer callbacks ~0 extra</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * latency from I/O handling time.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        reactor_process_timers</span><span style=\"color:#E1E4E8\">(r);</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * I/O dispatch â€” THE CRITICAL SECTION.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * Set dispatching = true. Any reactor_register or reactor_deregister</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * calls from callbacks will enqueue to r->mods instead of calling</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * epoll_ctl directly.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        r->dispatching </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">; i </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> n; i</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            fd_handler </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">h </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (fd_handler </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">)</span><span style=\"color:#FFAB70\">events</span><span style=\"color:#E1E4E8\">[i].data.ptr;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            /* Zombie check: callback called reactor_deregister() for this fd</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">             * earlier in this batch. Skip its remaining events. */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (h->zombie </span><span style=\"color:#F97583\">||</span><span style=\"color:#F97583\"> !</span><span style=\"color:#E1E4E8\">h->registered) </span><span style=\"color:#F97583\">continue</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            /* Compute which REACTOR_* flags to pass to the callback */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            uint32_t</span><span style=\"color:#E1E4E8\"> ev_mask  </span><span style=\"color:#F97583\">=</span><span style=\"color:#FFAB70\"> events</span><span style=\"color:#E1E4E8\">[i].events;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            uint32_t</span><span style=\"color:#E1E4E8\"> r_events </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (ev_mask </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\"> EPOLLIN)                          r_events </span><span style=\"color:#F97583\">|=</span><span style=\"color:#E1E4E8\"> REACTOR_READABLE;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (ev_mask </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\"> EPOLLOUT)                         r_events </span><span style=\"color:#F97583\">|=</span><span style=\"color:#E1E4E8\"> REACTOR_WRITABLE;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (ev_mask </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\"> EPOLLERR)                         r_events </span><span style=\"color:#F97583\">|=</span><span style=\"color:#E1E4E8\"> REACTOR_ERROR;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (ev_mask </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\"> (EPOLLHUP </span><span style=\"color:#F97583\">|</span><span style=\"color:#E1E4E8\"> EPOLLRDHUP))          r_events </span><span style=\"color:#F97583\">|=</span><span style=\"color:#E1E4E8\"> REACTOR_HANGUP;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            /*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">             * Recover the fd from the handler pointer.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">             * We stored data.ptr = &#x26;handlers[fd], so fd = h - r->handlers.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">             * Using pointer arithmetic to avoid storing fd twice.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">             */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            int</span><span style=\"color:#E1E4E8\"> fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\">)(h </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> r->handlers);</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            /* Invoke the application's callback */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            h-></span><span style=\"color:#B392F0\">callback</span><span style=\"color:#E1E4E8\">(fd, r_events, h->user_data);</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            /*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">             * After callback: check if the handler became zombie during the</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">             * callback (e.g., callback called reactor_deregister for this fd).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">             * If so, complete the deregistration now while we have context.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">             * The MOD_DEL is also queued in r->mods, but we want to prevent</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">             * any subsequent iteration from seeing a live handler.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">             */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        r->dispatching </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * Apply deferred modifications.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * Now that we're not iterating events[], it's safe to call epoll_ctl.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">; i </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> r->mods_len; i</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            deferred_mod </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">mod </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#E1E4E8\">r->mods[i];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (mod->op </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> MOD_DEL) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                /* Complete the deregistration: clear handler state */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> (mod->fd </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> &#x26;&#x26;</span><span style=\"color:#E1E4E8\"> mod->fd </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> MAX_FDS) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    fd_handler </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">h </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#E1E4E8\">r->handlers[mod->fd];</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    h->registered </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    h->zombie     </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            reactor_apply_mod</span><span style=\"color:#E1E4E8\">(r, mod);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        r->mods_len </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\">   /* reset the deferred mod queue */</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * Run deferred tasks â€” AFTER all I/O events and after modifications.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * Deferred tasks may call reactor_register/deregister freely because</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * dispatching = false at this point.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        reactor_run_deferred</span><span style=\"color:#E1E4E8\">(r);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> reactor_stop</span><span style=\"color:#E1E4E8\">(reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">r</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    r->running </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Fdiag-m3-event-dispatch-loop-trace.svg\" alt=\"Trace: One Complete Event Loop Tick\"></p>\n<p>This loop embodies the complete set of ordering guarantees:</p>\n<ol>\n<li><strong>Timers fire before I/O events</strong> â€” time-sensitive</li>\n<li><strong>I/O events fire in the order epoll returns them</strong> â€” within a batch</li>\n<li><strong>Modifications are deferred</strong> â€” no corruption of the events array</li>\n<li><strong>Deferred tasks run after all I/O</strong> â€” they see the fully-dispatched state</li>\n<li><strong>Next <code>epoll_wait</code> reflects all modifications</strong> â€” applied between ticks</li>\n</ol>\n<hr>\n<h2 id=\"handling-epollhup-and-epollerr-correctly\">Handling EPOLLHUP and EPOLLERR Correctly</h2>\n<p>These two event flags deserve special attention. Developers frequently mishandle them by treating <code>EPOLLHUP</code> as an error when it&#39;s often a normal shutdown.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>EPOLLHUP â€” &quot;Hang Up&quot;\n    The remote peer closed the connection. On a TCP socket, this means\n    the peer sent FIN. The socket may still have data in its receive\n    buffer that you haven't read yet. Always try to read remaining data\n    before closing.\nEPOLLRDHUP â€” &quot;Read HUP&quot; (Linux 2.6.17+)\n    More precise than EPOLLHUP: specifically indicates the peer has shut\n    down the writing half of the connection (sent FIN for their outgoing\n    direction). This is the preferred way to detect peer close.\nEPOLLERR â€” &quot;Error&quot;\n    A socket error occurred. Read errno by calling getsockopt(fd,\n    SOL_SOCKET, SO_ERROR, &amp;err, &amp;len) â€” DO NOT call read() first.\n    Common causes: ECONNRESET (RST received), ETIMEDOUT, ENETUNREACH.</code></pre></div>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Example callback showing correct EPOLLHUP / EPOLLERR handling.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * This would be an application's callback registered with reactor_register.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> connection_callback</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#FFAB70\"> events</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">user_data</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    conn_state </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">conn </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (conn_state </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">)user_data;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    reactor    </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">r    </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> conn->reactor_ref;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (events </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\"> REACTOR_ERROR) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Query the actual error */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        socklen_t</span><span style=\"color:#E1E4E8\"> len </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> sizeof</span><span style=\"color:#E1E4E8\">(err);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        getsockopt</span><span style=\"color:#E1E4E8\">(fd, SOL_SOCKET, SO_ERROR, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">err, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">len);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        fprintf</span><span style=\"color:#E1E4E8\">(stderr, </span><span style=\"color:#9ECBFF\">\"Socket error on fd </span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#9ECBFF\">: </span><span style=\"color:#79B8FF\">%s\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, fd, </span><span style=\"color:#B392F0\">strerror</span><span style=\"color:#E1E4E8\">(err));</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Defer close so we don't invalidate the event batch */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        reactor_defer</span><span style=\"color:#E1E4E8\">(r, deferred_conn_close, conn);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (events </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\"> REACTOR_HANGUP) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Peer closed their write side. Drain any remaining data first. */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (events </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\"> REACTOR_READABLE) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            handle_readable</span><span style=\"color:#E1E4E8\">(fd, conn, r);</span><span style=\"color:#6A737D\">  /* read and process remaining data */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Schedule close after this callback returns */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        reactor_defer</span><span style=\"color:#E1E4E8\">(r, deferred_conn_close, conn);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (events </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\"> REACTOR_READABLE) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        handle_readable</span><span style=\"color:#E1E4E8\">(fd, conn, r);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (events </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\"> REACTOR_WRITABLE) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        handle_writable</span><span style=\"color:#E1E4E8\">(fd, conn, r);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<blockquote>\n<p><strong>Why defer the close even for EPOLLERR?</strong> By the time <code>connection_callback</code> is called, there may be other events in the current <code>epoll_wait</code> batch that reference this same fdâ€”for example, if EPOLLIN and EPOLLERR both fired simultaneously. If you call <code>close(fd)</code> directly, the zombie check in the dispatch loop catches it only if you went through <code>reactor_deregister</code>. Calling <code>close(fd)</code> directly without <code>reactor_deregister</code> leaves the handler marked as registered for a closed (and potentially reused) fd. Always close through the reactor&#39;s deregistration path, and defer it when inside a callback.</p>\n</blockquote>\n<hr>\n<h2 id=\"writing-applications-against-the-reactor\">Writing Applications Against the Reactor</h2>\n<p>Here&#39;s how the echo server from Milestones 1 and 2 looks when rewritten against this API. Notice how all the <code>epoll_ctl</code> calls disappear:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"reactor.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdio.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdlib.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;string.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;errno.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;unistd.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;sys/socket.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;netinet/in.h></span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/* Application-level connection state */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    reactor    </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">r;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    write_buf   wbuf;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\">         fd;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} echo_conn;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">r;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\">      listen_fd;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} server_ctx;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> echo_conn_close</span><span style=\"color:#E1E4E8\">(reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">r</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">user_data</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    echo_conn </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">conn </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (echo_conn </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">)user_data;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    reactor_deregister</span><span style=\"color:#E1E4E8\">(r, conn->fd);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    wbuf_free</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">conn->wbuf);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    close</span><span style=\"color:#E1E4E8\">(conn->fd);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    free</span><span style=\"color:#E1E4E8\">(conn);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> echo_readable</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#FFAB70\"> events</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">user_data</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    echo_conn </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">conn </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (echo_conn </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">)user_data;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    reactor   </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">r    </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> conn->r;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (events </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\"> (REACTOR_ERROR </span><span style=\"color:#F97583\">|</span><span style=\"color:#E1E4E8\"> REACTOR_HANGUP)) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        reactor_defer</span><span style=\"color:#E1E4E8\">(r, echo_conn_close, conn);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> buf</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">4096</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (;;) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        ssize_t</span><span style=\"color:#E1E4E8\"> n </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> read</span><span style=\"color:#E1E4E8\">(fd, buf, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(buf));</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (n </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            /* Queue for writing using the write buffer from M2 */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">conn_write_with_reactor</span><span style=\"color:#E1E4E8\">(r, conn, buf, (</span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#E1E4E8\">)n) </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">                reactor_defer</span><span style=\"color:#E1E4E8\">(r, echo_conn_close, conn);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        } </span><span style=\"color:#F97583\">else</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> (n </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            reactor_defer</span><span style=\"color:#E1E4E8\">(r, echo_conn_close, conn);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        } </span><span style=\"color:#F97583\">else</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EAGAIN </span><span style=\"color:#F97583\">||</span><span style=\"color:#E1E4E8\"> errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EWOULDBLOCK) </span><span style=\"color:#F97583\">break</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            reactor_defer</span><span style=\"color:#E1E4E8\">(r, echo_conn_close, conn);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> accept_callback</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> listen_fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#FFAB70\"> events</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">user_data</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    server_ctx </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">ctx </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (server_ctx </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">)user_data;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    (</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">)events;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (;;) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\"> fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> accept4</span><span style=\"color:#E1E4E8\">(listen_fd, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">, SOCK_NONBLOCK </span><span style=\"color:#F97583\">|</span><span style=\"color:#E1E4E8\"> SOCK_CLOEXEC);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (fd </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EAGAIN </span><span style=\"color:#F97583\">||</span><span style=\"color:#E1E4E8\"> errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EWOULDBLOCK) </span><span style=\"color:#F97583\">break</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            perror</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"accept4\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            break</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        echo_conn </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">conn </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> malloc</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(echo_conn));</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">conn) { </span><span style=\"color:#B392F0\">close</span><span style=\"color:#E1E4E8\">(fd); </span><span style=\"color:#F97583\">continue</span><span style=\"color:#E1E4E8\">; }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        conn->r  </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ctx->r;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        conn->fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> fd;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        wbuf_init</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">conn->wbuf);</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Register with reactor â€” no epoll_ctl calls needed */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        reactor_register</span><span style=\"color:#E1E4E8\">(ctx->r, fd, REACTOR_READABLE, echo_readable, conn);</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Set idle timeout â€” reusing M2's timer mechanism via reactor */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        reactor_set_timeout</span><span style=\"color:#E1E4E8\">(ctx->r, </span><span style=\"color:#79B8FF\">30000</span><span style=\"color:#E1E4E8\">, echo_timeout_cb, conn);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\"> main</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    reactor    </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">r   </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> reactor_create</span><span style=\"color:#E1E4E8\">();</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    server_ctx  ctx </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> { .r </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> r };</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ctx.listen_fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> create_listening_socket</span><span style=\"color:#E1E4E8\">();</span><span style=\"color:#6A737D\">  /* from M1 */</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* One registration call â€” no epoll_create1, no epoll_ctl */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    reactor_register</span><span style=\"color:#E1E4E8\">(r, ctx.listen_fd, REACTOR_READABLE, accept_callback, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">ctx);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    printf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Echo server on port 8080...</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    reactor_run</span><span style=\"color:#E1E4E8\">(r);</span><span style=\"color:#6A737D\">  /* blocks until reactor_stop() */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    close</span><span style=\"color:#E1E4E8\">(ctx.listen_fd);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    reactor_destroy</span><span style=\"color:#E1E4E8\">(r);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<p>Compare this to your Milestone 1 code. <code>epoll_create1</code>, <code>epoll_ctl</code>, <code>epoll_wait</code>, <code>EPOLLIN</code>, <code>EPOLLET</code>, <code>EPOLL_CTL_ADD</code>â€”none of them appear in application code. The application speaks in terms of <em>connections</em>, <em>readability</em>, and <em>timeouts</em>. The reactor speaks in terms of epoll. This separation is the entire point.</p>\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Fdiag-m3-reactor-vs-proactor.svg\" alt=\"Reactor vs Proactor: Architectural Comparison\"></p>\n<hr>\n<h2 id=\"the-three-level-view-one-callback-invocation\">The Three-Level View: One Callback Invocation</h2>\n<h2 id=\"let39s-trace-a-single-callback-invocation-from-hardware-interrupt-to-your-application-code-level-3-hardware-the-nic-receives-a-tcp-segment-from-a-client-its-dma-engine-writes-the-payload-directly-into-a-kernel-memory-region-the-socket39s-receive-queue-without-cpu-involvement-the-nic-raises-an-interrupt-line-the-cpu-pauses-its-current-instruction-stream-saves-registers-and-jumps-to-the-interrupt-handler-level-2-oskernel-the-interrupt-handler-running-in-interrupt-context-non-preemptible-dequeues-the-packet-from-the-nic39s-rx-ring-buffer-and-places-it-in-the-socket39s-sk_receive_queue-it-calls-sk-gtsk_data_readyskthe-socket39s-readiness-callbackwhich-wakes-the-epoll-subsystem-the-epoll-epitem-for-this-fd-is-moved-from-the-quotsleepingquot-list-to-rdllist-the-ready-list-the-interrupt-handler-returns-the-kernel-resumes-the-process-that-was-running-your-event-loop-sleeping-in-epoll_wait-the-kernel39s-epoll_wait-implementation-walks-rdllist-copies-events-data-pairs-into-your-user-space-events-array-via-copy_to_user-and-returns-the-count-level-1-application-your-reactor_run-loop-receives-n_ready-it-iterates-the-events-array-for-each-event-it-reads-eventsidataptr-casts-it-to-fd_handler-checks-the-zombie-flag-maps-the-epoll-event-flags-to-reactor_-flags-and-calls-h-gtcallbackfd-r_events-h-gtuser_data-your-application-code-runs-one-tcp-segment-one-dma-transfer-one-interrupt-one-syscall-return-one-array-index-one-function-pointer-dereference-the-entire-path-from-nic-interrupt-to-your-echo_readable-function-runs-in-under-5-s-on-a-modern-serverwire-to-callback-latency-this-is-what-makes-event-driven-servers-fast-no-thread-switching-no-scheduler-involvement-no-stack-swaps-one-path-end-to-end\">Let&#39;s trace a single callback invocation from hardware interrupt to your application code.\n<strong>Level 3 â€” Hardware</strong>: The NIC receives a TCP segment from a client. Its DMA engine writes the payload directly into a kernel memory region (the socket&#39;s receive queue) without CPU involvement. The NIC raises an interrupt line. The CPU pauses its current instruction stream, saves registers, and jumps to the interrupt handler.\n<strong>Level 2 â€” OS/Kernel</strong>: The interrupt handler (running in interrupt context, non-preemptible) dequeues the packet from the NIC&#39;s RX ring buffer and places it in the socket&#39;s <code>sk_receive_queue</code>. It calls <code>sk-&gt;sk_data_ready(sk)</code>â€”the socket&#39;s readiness callbackâ€”which wakes the epoll subsystem. The epoll <code>epitem</code> for this fd is moved from the &quot;sleeping&quot; list to <code>rdllist</code> (the ready list). The interrupt handler returns. The kernel resumes the process that was running (your event loop, sleeping in <code>epoll_wait</code>). The kernel&#39;s <code>epoll_wait</code> implementation walks <code>rdllist</code>, copies <code>{events, data}</code> pairs into your user-space <code>events[]</code> array via <code>copy_to_user()</code>, and returns the count.\n<strong>Level 1 â€” Application</strong>: Your <code>reactor_run</code> loop receives <code>n_ready</code>. It iterates the <code>events[]</code> array. For each event, it reads <code>events[i].data.ptr</code>, casts it to <code>fd_handler *</code>, checks the zombie flag, maps the epoll event flags to <code>REACTOR_*</code> flags, and calls <code>h-&gt;callback(fd, r_events, h-&gt;user_data)</code>. Your application code runs. One TCP segment, one DMA transfer, one interrupt, one syscall return, one array index, one function pointer dereference.\nThe entire path from NIC interrupt to your <code>echo_readable</code> function runs in under 5 Âµs on a modern serverâ€”wire-to-callback latency. This is what makes event-driven servers fast: no thread switching, no scheduler involvement, no stack swaps. One path, end to end.</h2>\n<h2 id=\"hardware-soul-cache-analysis-of-the-dispatch-loop\">Hardware Soul: Cache Analysis of the Dispatch Loop</h2>\n<h2 id=\"the-dispatch-loop39s-hot-path-touches-several-memory-regions-understanding-their-cache-behavior-reveals-why-the-design-choices-above-matter-at-scale-events-array-allocated-on-the-stack-in-reactor_run-with-max_events1024-and-sizeofstruct-epoll_event12-bytes-12288-bytes-fits-in-l1-cache-typically-3264-kb-iterating-over-it-is-sequential-and-prefetch-friendlythe-hardware-prefetcher-recognizes-stride-1-access-and-loads-upcoming-cache-lines-before-you-need-them-this-array-is-cache-hot-for-the-entire-dispatch-loop-fd_handler-handlers-the-registration-table-is-max_fds-24-bytes-15-mb-this-does-not-fit-in-l1-or-l2-typically-256-kb2-mb-and-barely-fits-in-l3-typically-832-mb-accessing-handlersfd-for-a-non-recently-seen-fd-is-an-l3-cache-miss-40-ns-under-10k-active-connections-with-uniform-distribution-the-working-set-of-recently-accessed-handler-entries-is-10000-24-240-kbfits-in-l2-connections-accessed-infrequently-idle-connections-will-cache-miss-on-every-event-but-that39s-acceptable-because-they39re-rare-dataptr-vs-datafd-dispatch-when-you-store-dataptr-amphandlersfd-retrieving-the-handler-requires-one-pointer-dereference-when-you-use-datafd-you39d-need-handlerseventsidatafdone-array-access-with-multiplication-the-pointer-approach-saves-35-cycles-per-event-on-average-because-the-pointer-is-already-the-exact-memory-address-however-it-means-the-events-array-holds-pointers-into-the-handlers-arrayif-handlers-is-ever-reallocated-it-isn39t-in-our-fixed-size-design-all-stored-pointers-become-dangling-this-is-why-we-use-a-fixed-size-array-not-a-dynamic-one-deferred-mods-queue-typically-empty-most-calls-happen-outside-dispatch-when-non-empty-it39s-small-a-handful-of-entries-per-tick-always-fits-in-l1-applying-deferred-mods-after-dispatch-is-fast-the-zombie-flag-checking-h-gtzombie-is-a-single-byte-read-for-a-recently-closed-fd-whose-handler-is-in-l1-cache-this-is-essentially-free-the-branch-itself-is-nearly-always-not-taken-zombie-fds-are-rare-and-quickly-predicted-by-the-branch-predictor\">The dispatch loop&#39;s hot path touches several memory regions. Understanding their cache behavior reveals why the design choices above matter at scale.\n<strong><code>events[]</code> array</strong>: Allocated on the stack in <code>reactor_run</code>. With <code>MAX_EVENTS=1024</code> and <code>sizeof(struct epoll_event)=12</code> bytes: 12,288 bytes, fits in L1 cache (typically 32â€“64 KB). Iterating over it is sequential and prefetch-friendlyâ€”the hardware prefetcher recognizes stride-1 access and loads upcoming cache lines before you need them. This array is cache-hot for the entire dispatch loop.\n<strong><code>fd_handler handlers[]</code></strong>: The registration table is <code>MAX_FDS Ã— 24 bytes = 1.5 MB</code>. This does not fit in L1 or L2 (typically 256 KBâ€“2 MB), and barely fits in L3 (typically 8â€“32 MB). Accessing <code>handlers[fd]</code> for a non-recently-seen fd is an L3 cache miss (~40 ns). Under 10K active connections with uniform distribution, the working set of recently-accessed handler entries is <code>10,000 Ã— 24 = 240 KB</code>â€”fits in L2. Connections accessed infrequently (idle connections) will cache-miss on every event, but that&#39;s acceptable because they&#39;re rare.\n<strong><code>data.ptr</code> vs <code>data.fd</code> dispatch</strong>: When you store <code>data.ptr = &amp;handlers[fd]</code>, retrieving the handler requires one pointer dereference. When you use <code>data.fd</code>, you&#39;d need <code>handlers[events[i].data.fd]</code>â€”one array access with multiplication. The pointer approach saves 3â€“5 cycles per event on average, because the pointer is already the exact memory address. However, it means the <code>events[]</code> array holds pointers into the <code>handlers[]</code> arrayâ€”if <code>handlers[]</code> is ever reallocated (it isn&#39;t in our fixed-size design), all stored pointers become dangling. This is why we use a fixed-size array, not a dynamic one.\n<strong>Deferred mods queue</strong>: Typically empty (most calls happen outside dispatch). When non-empty, it&#39;s small (a handful of entries per tick), always fits in L1. Applying deferred mods after dispatch is fast.\n<strong>The zombie flag</strong>: Checking <code>h-&gt;zombie</code> is a single byte read. For a recently-closed fd whose handler is in L1 cache, this is essentially free. The branch itself is nearly always not-taken (zombie fds are rare) and quickly predicted by the branch predictor.</h2>\n<h2 id=\"design-decision-which-deferred-modification-strategy\">Design Decision: Which Deferred-Modification Strategy?</h2>\n<p>Three strategies exist for handling modifications-during-dispatch. Here&#39;s the full tradeoff:</p>\n<table>\n<thead>\n<tr>\n<th>Strategy</th>\n<th>How It Works</th>\n<th>Pros</th>\n<th>Cons</th>\n<th>Used By</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Zombie + deferred mods âœ“</strong></td>\n<td>Mark fd as zombie; queue epoll_ctl for after dispatch</td>\n<td>Simple to reason about; correct for all cases</td>\n<td>Small queue allocation overhead</td>\n<td>libuv, our design</td>\n</tr>\n<tr>\n<td><strong>Events array copy</strong></td>\n<td>Snapshot all events before dispatch; modifications go to live kernel state immediately</td>\n<td>No deferred queue needed; always-fresh kernel state</td>\n<td>12 KB memcpy per tick; stale events still dispatched to wrong callbacks</td>\n<td>Some early libevent versions</td>\n</tr>\n<tr>\n<td><strong>Generation counter</strong></td>\n<td>Each handler has a generation number; events carry the generation they were generated for; mismatches are skipped</td>\n<td>Zero extra memory</td>\n<td>Complex; counter must be updated atomically</td>\n<td>Some game engine ECS systems</td>\n</tr>\n<tr>\n<td>The zombie + deferred mods approach is the cleanest. The invariant is clear: <code>zombie = true</code> means &quot;this handler is dead to this dispatch cycle.&quot; The deferred mod queue is small and short-lived. The correctness argument is local and mechanicalâ€”no global reasoning required.</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<hr>\n<h2 id=\"testing-the-reactor-a-validation-suite\">Testing the Reactor: A Validation Suite</h2>\n<p>Before moving to Milestone 4, verify these specific behaviors:\n<strong>Test 1: Deferred deregistration correctness</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/* Set up two connections. In the callback for conn A, close conn B.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Conn B must NOT receive a callback for events already in the batch. */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\"> closed_fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> conn_a_callback</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#FFAB70\"> events</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">user_data</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">r </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">)user_data;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    (</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">)fd; (</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">)events;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Close conn B from inside conn A's callback */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    reactor_deregister</span><span style=\"color:#E1E4E8\">(r, closed_fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> conn_b_callback</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#FFAB70\"> events</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">user_data</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    (</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">)fd; (</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">)events; (</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">)user_data;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* THIS MUST NEVER BE CALLED after conn_a_callback runs */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    fprintf</span><span style=\"color:#E1E4E8\">(stderr, </span><span style=\"color:#9ECBFF\">\"FAIL: conn_b_callback called after deregistration</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    abort</span><span style=\"color:#E1E4E8\">();</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<p>Trigger both fds to have events simultaneously (e.g., pipe both ends with data). Verify <code>conn_b_callback</code> is never called after <code>conn_a_callback</code> deregisters it.\n<strong>Test 2: Interval timer accuracy</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\"> tick_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> uint64_t</span><span style=\"color:#E1E4E8\"> first_tick_ms </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> interval_cb</span><span style=\"color:#E1E4E8\">(reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">r</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">user_data</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    (</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">)user_data;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    tick_count</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (tick_count </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">) first_tick_ms </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> now_ms</span><span style=\"color:#E1E4E8\">();</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (tick_count </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 10</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        uint64_t</span><span style=\"color:#E1E4E8\"> elapsed </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> now_ms</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> first_tick_ms;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* 9 intervals of 100ms = 900ms; allow Â±50ms tolerance */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        assert</span><span style=\"color:#E1E4E8\">(elapsed </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> 850</span><span style=\"color:#F97583\"> &#x26;&#x26;</span><span style=\"color:#E1E4E8\"> elapsed </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 950</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        printf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Interval timer: 10 ticks in </span><span style=\"color:#79B8FF\">%lu</span><span style=\"color:#9ECBFF\"> ms â€” PASS</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, elapsed);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        reactor_stop</span><span style=\"color:#E1E4E8\">(r);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/* In main: */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">reactor_set_interval</span><span style=\"color:#E1E4E8\">(r, </span><span style=\"color:#79B8FF\">100</span><span style=\"color:#E1E4E8\">, interval_cb, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">reactor_run</span><span style=\"color:#E1E4E8\">(r);</span></span></code></pre></div>\n<p><strong>Test 3: Deferred task ordering</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/* Verify: deferred tasks run AFTER all I/O callbacks in the current tick */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\"> io_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\"> defer_ran_at </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> check_defer</span><span style=\"color:#E1E4E8\">(reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">r</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">ud</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    defer_ran_at </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> io_count;</span><span style=\"color:#6A737D\">  /* should equal total_io_events_this_tick */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> io_cb</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#FFAB70\"> events</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">ud</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">r </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">)ud;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    io_count</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (io_count </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        reactor_defer</span><span style=\"color:#E1E4E8\">(r, check_defer, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">);</span><span style=\"color:#6A737D\">  /* deferred during first I/O event */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<p>After the tick completes, <code>defer_ran_at</code> should equal the total number of I/O callbacks that fired (not 1, because deferred tasks run after ALL I/O).\n<strong>Test 4: EPOLLHUP and EPOLLERR dispatch</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/* Create a socket pair. Close one end. Verify REACTOR_HANGUP fires. */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> sv</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">socketpair</span><span style=\"color:#E1E4E8\">(AF_UNIX, SOCK_STREAM, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, sv);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> bool</span><span style=\"color:#E1E4E8\"> got_hangup </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> hangup_cb</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#FFAB70\"> events</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">ud</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (events </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\"> REACTOR_HANGUP) got_hangup </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">reactor_register</span><span style=\"color:#E1E4E8\">(r, </span><span style=\"color:#FFAB70\">sv</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">], REACTOR_READABLE, hangup_cb, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">close</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">sv</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">]);</span><span style=\"color:#6A737D\">  /* close the other end */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">reactor_run</span><span style=\"color:#E1E4E8\">(r);</span><span style=\"color:#6A737D\">  /* should return after one tick */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">assert</span><span style=\"color:#E1E4E8\">(got_hangup);</span></span></code></pre></div>\n<hr>\n<h2 id=\"knowledge-cascade-what-this-unlocks\">Knowledge Cascade: What This Unlocks</h2>\n<p><strong>1. JavaScript&#39;s microtask queue (cross-domain: web frontend)</strong>\nThe <code>reactor_defer</code> you just built is exactly the mechanism behind JavaScript&#39;s microtask queue. In a browser, when a <code>Promise.then()</code> callback runs, it runs after the current &quot;task&quot; (macro-task: I/O event, setTimeout, user event) but before the browser re-renders or picks up the next macro-task. This is the microtask queue. React&#39;s <code>setState</code> batching works the same way: calling <code>setState</code> multiple times in a single event handler doesn&#39;t trigger multiple re-renders; React batches the state updates and applies them after the event handler returnsâ€”deferred modification of the component tree, applied after the current &quot;dispatch&quot; is complete.\nYour <code>reactor_run_deferred</code> is the C implementation of what V8&#39;s event loop calls &quot;drain the microtask queue.&quot; The mechanism is identical: collect tasks during dispatch, run them after, before the next poll.\n<strong>2. Game engine ECS and deferred destruction (cross-domain: game dev)</strong>\nEntity-Component Systemsâ€”the architecture behind Unity&#39;s DOTS, Bevy, and Flecsâ€”face the exact same problem you solved with zombie flags. An entity (like your fd) can be destroyed by a system (like your callback) while the system is iterating over all entities with a given component type. Destroying the entity directly invalidates the iterator. The standard solution is a &quot;deferred destruction queue&quot;: mark the entity as &quot;pending deletion,&quot; finish the current system&#39;s iteration, then process all pending deletions. Flecs calls this a &quot;deferred world.&quot; Your <code>h-&gt;zombie</code> flag and <code>mods</code> queue are precisely this pattern, applied to a networking context.\n<strong>3. Rust&#39;s borrow checker eliminates this class of bug at compile time</strong>\nThe bug you defended againstâ€”holding a reference to <code>handlers[fd]</code> while calling code that might free <code>handlers[fd]</code>â€”is the classic aliasing problem. In Rust, you cannot hold a shared reference (<code>&amp;fd_handler</code>) and simultaneously call a function that takes <code>&amp;mut reactor</code> (which would allow modifying <code>handlers</code>). The borrow checker statically prevents this. If you were building this reactor in Rust, the callback signature would force you to express the aliasing constraints explicitly, and incorrect code would fail at compile time rather than at 3am under load. This is the exact aliasing problem the borrow checker was designed to preventâ€”and it&#39;s why Rust is increasingly used for networking infrastructure.\n<strong>4. Linux kernel bottom-half processing (same mechanism, different context)</strong>\nLinux interrupt handlers face the same constraint: when a hardware interrupt fires, the CPU is executing in interrupt contextâ€”a non-preemptible, non-schedulable execution context. The interrupt handler must complete quickly and cannot sleep. But interrupt handling often requires complex work (network packet processing, disk completion handling) that would take too long in interrupt context. Linux&#39;s solution: the interrupt handler does minimal work (dequeues the NIC packet, records the event) and schedules a &quot;softirq&quot; (software interrupt) or &quot;tasklet&quot; to run the heavy work later, in a preemptible context, after the interrupt handler returns. This is Linux&#39;s deferred task queueâ€”your <code>reactor_defer</code> is the application-space equivalent of scheduling a softirq.\n<strong>5. Reactor vs Proactor: why io_uring is architecturally different</strong>\nThe reactor pattern is <em>synchronous dispatch</em>: you ask the kernel &quot;is this fd ready?&quot; and then do the I/O yourself. The proactor pattern is <em>asynchronous completion</em>: you submit an I/O operation to the kernel (&quot;read 4096 bytes into this buffer&quot;), and the kernel tells you when it&#39;s <em>done</em>â€”handing you the result, not just the readiness signal.\n<code>io_uring</code> (Linux 5.1+) is a proactor. You don&#39;t call <code>read()</code> after <code>epoll_wait</code> tells you there&#39;s data. You submit <code>IORING_OP_READ</code> to the submission ring, specifying the fd, buffer, and length. When the read completes, a completion entry appears in the completion ring with the bytes read. The callback re-entrancy problem you solved in this milestone largely disappears in the proactor modelâ€”by the time a completion fires, the I/O has already happened and the fd&#39;s state has already changed. There&#39;s no &quot;we&#39;re in the middle of dispatching&quot; state because operations are submitted and completed atomically from the application&#39;s perspective.\nUnderstanding the reactor pattern and its limitations is the direct prerequisite for understanding why io_uring&#39;s proactor model is worth the added complexity.</p>\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Fdiag-m3-reactor-vs-proactor.svg\" alt=\"Reactor vs Proactor: Architectural Comparison\"></p>\n<hr>\n<h2 id=\"pitfall-reference-the-five-ways-this-breaks\">Pitfall Reference: The Five Ways This Breaks</h2>\n<h2 id=\"pitfall-1-modifying-the-fd_handler-table-during-dispatch-without-zombie-protection-symptom-callbacks-fire-for-connections-that-were-closed-earlier-in-the-same-event-batch-data-sent-to-wrong-clients-occasional-segfault-in-callback-dispatch-fix-set-h-gtzombie-true-in-reactor_deregister-when-r-gtdispatching-true-check-h-gtzombie-at-the-start-of-each-dispatch-iteration-pitfall-2-deferred-tasks-running-interleaved-with-io-dispatch-symptom-a-deferred-task-that-closes-a-connection-runs-before-all-events-for-that-connection-are-processed-the-later-events-dispatch-to-freed-state-fix-run-reactor_run_deferred-after-the-for-i-0-i-lt-n-i-dispatch-loop-completes-not-inside-it-pitfall-3-a-timer-callback-that-cancels-itself-for-an-interval-timer-symptom-reactor_cancel_timer-modifies-the-heap-during-reactor_process_timers39s-iteration-heap-invariant-violated-subsequent-timer-operations-use-wrong-entries-fix-in-interval-timer-callbacks-that-want-to-stop-use-reactor_defer-to-cancel-the-timer-after-reactor_process_timers-returns-alternatively-set-a-flag-and-check-it-before-re-arming-pitfall-4-not-clearing-the-zombie-flag-on-re-registration-symptom-a-callback-closes-an-fd-the-fd-is-immediately-reused-by-accept4-reactor_register-is-called-for-the-new-connection-but-the-callback-is-never-invoked-because-h-gtzombie-is-still-true-fix-in-reactor_register-always-set-h-gtzombie-false-re-registration-on-a-zombie-fd-is-a-valid-and-common-pattern-pitfall-5-epollhup-without-epollin-closing-without-reading-remaining-data-symptom-http-pipelining-requests-are-silently-dropped-the-client-sends-a-second-request-closes-the-connection-but-the-server-never-processes-the-second-request-because-it-closes-immediately-on-epollhup-fix-when-reactor_hangup-fires-simultaneously-with-reactor_readable-always-process-readable-data-first-check-events-amp-reactor_readable-before-closing\"><strong>Pitfall 1: Modifying the fd_handler table during dispatch without zombie protection</strong>\n<em>Symptom</em>: Callbacks fire for connections that were closed earlier in the same event batch; data sent to wrong clients; occasional segfault in callback dispatch.\n<em>Fix</em>: Set <code>h-&gt;zombie = true</code> in <code>reactor_deregister</code> when <code>r-&gt;dispatching == true</code>. Check <code>h-&gt;zombie</code> at the start of each dispatch iteration.\n<strong>Pitfall 2: Deferred tasks running interleaved with I/O dispatch</strong>\n<em>Symptom</em>: A deferred task that closes a connection runs before all events for that connection are processed; the later events dispatch to freed state.\n<em>Fix</em>: Run <code>reactor_run_deferred</code> AFTER the <code>for (i = 0; i &lt; n; i++)</code> dispatch loop completes, not inside it.\n<strong>Pitfall 3: A timer callback that cancels itself for an interval timer</strong>\n<em>Symptom</em>: <code>reactor_cancel_timer</code> modifies the heap during <code>reactor_process_timers</code>&#39;s iteration; heap invariant violated; subsequent timer operations use wrong entries.\n<em>Fix</em>: In interval timer callbacks that want to stop, use <code>reactor_defer</code> to cancel the timer after <code>reactor_process_timers</code> returns. Alternatively, set a flag and check it before re-arming.\n<strong>Pitfall 4: Not clearing the zombie flag on re-registration</strong>\n<em>Symptom</em>: A callback closes an fd, the fd is immediately reused by <code>accept4</code>, <code>reactor_register</code> is called for the new connection, but the callback is never invoked because <code>h-&gt;zombie</code> is still true.\n<em>Fix</em>: In <code>reactor_register</code>, always set <code>h-&gt;zombie = false</code>. Re-registration on a zombie fd is a valid and common pattern.\n<strong>Pitfall 5: EPOLLHUP without EPOLLIN â€” closing without reading remaining data</strong>\n<em>Symptom</em>: HTTP pipelining requests are silently dropped; the client sends a second request, closes the connection, but the server never processes the second request because it closes immediately on EPOLLHUP.\n<em>Fix</em>: When <code>REACTOR_HANGUP</code> fires simultaneously with <code>REACTOR_READABLE</code>, always process readable data first. Check <code>events &amp; REACTOR_READABLE</code> before closing.</h2>\n<!-- END_MS -->\n\n\n<!-- MS_ID: build-event-loop-m4 -->\n<!-- MS_ID: build-event-loop-m4 -->\n<h1 id=\"http-server-on-event-loop\">HTTP Server on Event Loop</h1>\n<h2 id=\"the-illusion-that-breaks-under-load\">The Illusion That Breaks Under Load</h2>\n<p>You&#39;ve built a reactor. You&#39;ve built write buffering. You&#39;ve built timer management. Now it&#39;s time to put a real protocol on topâ€”HTTP/1.1â€”and watch every assumption from your experience with simple TCP echo servers get destroyed in the most instructive way possible.\nHere&#39;s the assumption: when a client sends an HTTP request, your <code>read()</code> call returns the complete request. The full <code>GET /index.html HTTP/1.1\\r\\nHost: example.com\\r\\nConnection: keep-alive\\r\\n\\r\\n</code> arrives in one chunk, you parse it, you respond. This assumption is correct roughly 95% of the time in local testing. It fails in exactly the scenarios that matter.\nTCP is a <strong>byte stream protocol</strong>. It makes one guarantee: bytes arrive in order. It makes no guarantee about how those bytes are grouped into <code>read()</code> calls. The kernel&#39;s TCP stack receives IP packets, reassembles them (handling reordering, retransmission, duplication), and places bytes into the socket&#39;s receive buffer. When you call <code>read()</code>, you get whatever is in that buffer at that momentâ€”which may be a fragment of a request, exactly one request, or multiple requests concatenated together.\nOver localhost, packets almost never fragment because the loopback MTU is 65,535 bytes. In production, over a real network with a 1,500-byte MTU, a 4,096-byte request header set fragments across 3 packets. If those packets arrive in separate TCP segments and your event loop processes them separatelyâ€”which it will, under loadâ€”you get three <code>read()</code> calls, each returning a piece of the headers.</p>\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Fdiag-m4-incremental-parse-data-walk.svg\" alt=\"Data Walk: Incremental HTTP Header Parsing Across 3 Reads\"></p>\n<p>Here&#39;s the concrete sequence that breaks a naive parser:</p>\n<ul>\n<li><strong>Read 1</strong> returns: <code>GET /index.html HTTP/1.1\\r\\nHost: exa</code></li>\n<li><strong>Read 2</strong> returns: <code>mple.com\\r\\nConnection: keep-alive\\r\\n</code></li>\n<li><strong>Read 3</strong> returns: <code>\\r\\n</code>\nA parser that expects the full request on <code>read()</code> call 1 either crashes on the incomplete data, or silently discards the partial request and waits for a &quot;new&quot; request that never comes. The connection hangs. Under load testing, this manifests as random timeouts at around the 95th percentileâ€”requests that take 10 seconds and then reset. The server appears to handle most traffic fine; the failures are intermittent and hard to reproduce in a debugger.\nThe correct design: <strong>the parser is a state machine that can pause at any byte boundary and resume correctly</strong>. The event loop feeds it bytes incrementally; the parser returns either &quot;complete&quot; (I have a full request) or &quot;incomplete&quot; (give me more bytes). This is how every production HTTP parser is designedâ€”<code>http_parser</code> (Node.js&#39;s original C library), <code>llhttp</code> (its successor), <code>picohttpparser</code> (used by H2O and others), and the parser in Go&#39;s <code>net/http</code> package. You&#39;re about to build a simplified version that captures all the key concepts.</li>\n</ul>\n<hr>\n<h2 id=\"the-per-connection-state-machine\">The Per-Connection State Machine</h2>\n<p>Before writing the parser, define the states a connection passes through. Every connection lives in exactly one state at a time, and valid state transitions are explicit. This is not optional architectureâ€”it&#39;s the mechanism that makes incremental parsing safe.</p>\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Fdiag-m4-http-state-machine.svg\" alt=\"Per-Connection HTTP State Machine\"></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * conn_http_state - States for an HTTP/1.1 connection's protocol lifecycle.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * READING_HEADERS: accumulating bytes until we see \\r\\n\\r\\n (end of headers)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * READING_BODY:    accumulating body bytes up to Content-Length</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * PROCESSING:      headers complete, preparing the response</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * WRITING_RESPONSE: sending response bytes (may span multiple writes)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * CLOSING:         response sent, Connection: close requested; close after flush</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Only READING_HEADERS â†’ READING_BODY is optional (GET has no body).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Most GET requests go: READING_HEADERS â†’ PROCESSING â†’ WRITING_RESPONSE</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *                        â†’ READING_HEADERS (keep-alive) or CLOSING</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> enum</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HTTP_READING_HEADERS  </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HTTP_READING_BODY     </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HTTP_PROCESSING       </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HTTP_WRITING_RESPONSE </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 3</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HTTP_CLOSING          </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 4</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} conn_http_state;</span></span></code></pre></div>\n<p>Now define the full per-connection HTTP context. This extends the connection state from Milestone 2 with HTTP-specific fields:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdint.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdbool.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;sys/stat.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> READ_BUF_SIZE</span><span style=\"color:#79B8FF\">      16384</span><span style=\"color:#6A737D\">   /* 16 KB: large enough for typical request headers */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> MAX_PATH_LEN</span><span style=\"color:#79B8FF\">       1024</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> MAX_METHOD_LEN</span><span style=\"color:#79B8FF\">     8</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> MAX_HEADER_VALUE</span><span style=\"color:#79B8FF\">   256</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> STATIC_DIR</span><span style=\"color:#9ECBFF\">         \"./public\"</span><span style=\"color:#6A737D\">  /* serve files from this directory */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> IDLE_TIMEOUT_MS</span><span style=\"color:#79B8FF\">    30000</span><span style=\"color:#6A737D\">       /* 30 seconds */</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * http_request - Parsed fields from one HTTP request.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Populated incrementally as headers are parsed.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Reset to zero at the start of each new request (keep-alive reuse).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Memory layout:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   method[8]          =   8 bytes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   path[1024]         = 1024 bytes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   content_length     =   8 bytes (uint64_t)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   body_received      =   8 bytes (uint64_t)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   keep_alive         =   1 byte  (bool)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   has_content_length =   1 byte  (bool)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   [6 bytes padding]</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   Total: ~1056 bytes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\">     method</span><span style=\"color:#E1E4E8\">[MAX_METHOD_LEN];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\">     path</span><span style=\"color:#E1E4E8\">[MAX_PATH_LEN];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> content_length;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> body_received;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\">     keep_alive;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\">     has_content_length;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} http_request;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * http_conn - Complete per-connection HTTP state.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * This is the user_data pointer registered with reactor_register().</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * The reactor knows nothing about HTTP; it just calls our callback</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * with this pointer as the context.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Memory layout (approximate, 64-bit):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   read_buf[16384]    = 16384 bytes  (incoming byte accumulator)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   wbuf               =    24 bytes  (write_buf from M2)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   req                =  1056 bytes  (parsed HTTP request)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   read_len           =     4 bytes  (bytes used in read_buf)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   fd                 =     4 bytes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   timer_id           =     4 bytes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   state              =     4 bytes  (conn_http_state enum)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   [4 bytes padding]</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   reactor_ref        =     8 bytes  (pointer back to reactor)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   Total: ~17488 bytes per connection</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * At 10,000 connections: ~171 MB resident. The read_buf is the dominant</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * cost. If memory is tight, reduce READ_BUF_SIZE to 4096 and handle</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * header lines > 4096 bytes as an error (RFC 7230 allows servers to</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * reject excessively large headers).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\">            read_buf</span><span style=\"color:#E1E4E8\">[READ_BUF_SIZE];</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    write_buf       wbuf;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    http_request    req;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint32_t</span><span style=\"color:#E1E4E8\">        read_len;</span><span style=\"color:#6A737D\">       /* bytes of valid data in read_buf */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\">             fd;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\">             timer_id;</span><span style=\"color:#6A737D\">       /* reactor timer handle, -1 if none */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    conn_http_state state;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    reactor        </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">reactor_ref;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} http_conn;</span></span></code></pre></div>\n<blockquote>\n<p><strong>Why a pointer back to the reactor?</strong> Each <code>http_conn</code> needs to call <code>reactor_defer</code>, <code>reactor_set_timeout</code>, and <code>reactor_deregister</code> when it processes events. In Milestone 3, your callbacks received the reactor as a separate argument in some designs. Storing it directly in the connection state avoids threading the reactor pointer through every function call. This is idiomatic in C event-driven codeâ€”connection objects hold a reference to their owning event loop.</p>\n</blockquote>\n<hr>\n<h2 id=\"the-incremental-http-parser\">The Incremental HTTP Parser</h2>\n<p>The parser&#39;s contract is simple: given a byte buffer of length N, return either a parsed request (complete) or <code>PARSE_INCOMPLETE</code> (need more bytes). Internally, it&#39;s a state machine that scans the buffer once, character by character, tracking which parsing sub-state it&#39;s in.\nFor this milestone, implement a header-only parser for GET requests. The HTTP body parsing for POST/PUT requests follows the same pattern but is left as an extension exercise.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * parse_result - What the parser returns after examining the buffer.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> enum</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PARSE_COMPLETE   </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">  0</span><span style=\"color:#E1E4E8\">,</span><span style=\"color:#6A737D\">  /* full request parsed; req is populated */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PARSE_INCOMPLETE </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">,</span><span style=\"color:#6A737D\">  /* need more data */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PARSE_ERROR      </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">,</span><span style=\"color:#6A737D\">  /* malformed request; close connection */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} parse_result;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * find_header_end - Scan buffer for the \\r\\n\\r\\n sequence marking end of headers.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Returns the byte offset AFTER the \\r\\n\\r\\n, or -1 if not found.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Implementation uses a simple scan. Production parsers (picohttpparser)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * use SIMD to scan 16 bytes at a time with SSE2 _mm_cmpeq_epi8 â€” scanning</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * for '\\r' across 16 bytes in 2 cycles instead of 16. For this milestone,</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * the naive scan is correct and measurable.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Cache note: buf is in L1 cache (just read from the socket). Sequential</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * scan is prefetch-friendly â€” the hardware prefetcher loads upcoming cache</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * lines before we need them.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> int</span><span style=\"color:#B392F0\"> find_header_end</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">buf</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#FFAB70\"> len</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Need at least 4 bytes for \\r\\n\\r\\n */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (len </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 4</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">; i </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#E1E4E8\"> len </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> 4</span><span style=\"color:#E1E4E8\">; i</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">buf</span><span style=\"color:#E1E4E8\">[i]   </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> '</span><span style=\"color:#79B8FF\">\\r</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#F97583\"> &#x26;&#x26;</span><span style=\"color:#FFAB70\"> buf</span><span style=\"color:#E1E4E8\">[i</span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> '</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#F97583\"> &#x26;&#x26;</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            buf</span><span style=\"color:#E1E4E8\">[i</span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> '</span><span style=\"color:#79B8FF\">\\r</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#F97583\"> &#x26;&#x26;</span><span style=\"color:#FFAB70\"> buf</span><span style=\"color:#E1E4E8\">[i</span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\">3</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> '</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\">)(i </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 4</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * parse_request_line - Extract method and path from \"METHOD /path HTTP/1.1\".</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Returns 0 on success, -1 on malformed request.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * line is NOT null-terminated; line_len is its length.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> int</span><span style=\"color:#B392F0\"> parse_request_line</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">line</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> line_len</span><span style=\"color:#E1E4E8\">, http_request </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">req</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Find first space (end of method) */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> method_end </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">; i </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> line_len; i</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">line</span><span style=\"color:#E1E4E8\">[i] </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> ' '</span><span style=\"color:#E1E4E8\">) { method_end </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> i; </span><span style=\"color:#F97583\">break</span><span style=\"color:#E1E4E8\">; }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (method_end </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> ||</span><span style=\"color:#E1E4E8\"> method_end </span><span style=\"color:#F97583\">>=</span><span style=\"color:#E1E4E8\"> MAX_METHOD_LEN) </span><span style=\"color:#F97583\">return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    memcpy</span><span style=\"color:#E1E4E8\">(req->method, line, method_end);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    req->method[method_end] </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> '</span><span style=\"color:#79B8FF\">\\0</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Find second space (end of path) */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> path_start </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> method_end </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> path_end   </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> path_start; i </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> line_len; i</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">line</span><span style=\"color:#E1E4E8\">[i] </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> ' '</span><span style=\"color:#E1E4E8\">) { path_end </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> i; </span><span style=\"color:#F97583\">break</span><span style=\"color:#E1E4E8\">; }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (path_end </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#E1E4E8\"> path_start) </span><span style=\"color:#F97583\">return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> path_len </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> path_end </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> path_start;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (path_len </span><span style=\"color:#F97583\">>=</span><span style=\"color:#E1E4E8\"> MAX_PATH_LEN) </span><span style=\"color:#F97583\">return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    memcpy</span><span style=\"color:#E1E4E8\">(req->path, line </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> path_start, path_len);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    req->path[path_len] </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> '</span><span style=\"color:#79B8FF\">\\0</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * parse_header_field - Process one \"Name: Value\\r\\n\" header line.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * We only extract the fields we care about: Content-Length and Connection.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Unknown headers are silently ignored â€” correct per RFC 7230.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> parse_header_field</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">line</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> line_len</span><span style=\"color:#E1E4E8\">, http_request </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">req</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Find the colon separator */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> colon </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">; i </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> line_len; i</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">line</span><span style=\"color:#E1E4E8\">[i] </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> ':'</span><span style=\"color:#E1E4E8\">) { colon </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> i; </span><span style=\"color:#F97583\">break</span><span style=\"color:#E1E4E8\">; }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (colon </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Skip whitespace after colon */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> val_start </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> colon </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    while</span><span style=\"color:#E1E4E8\"> (val_start </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> line_len </span><span style=\"color:#F97583\">&#x26;&#x26;</span><span style=\"color:#FFAB70\"> line</span><span style=\"color:#E1E4E8\">[val_start] </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> ' '</span><span style=\"color:#E1E4E8\">) val_start</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> val_len </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> line_len </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> val_start;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (val_len </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Case-insensitive header name comparison */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (colon </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 14</span><span style=\"color:#F97583\"> &#x26;&#x26;</span><span style=\"color:#B392F0\"> strncasecmp</span><span style=\"color:#E1E4E8\">(line, </span><span style=\"color:#9ECBFF\">\"Content-Length\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">14</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        char</span><span style=\"color:#FFAB70\"> tmp</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">32</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">};</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\">  copy    </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> val_len </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 31</span><span style=\"color:#F97583\"> ?</span><span style=\"color:#E1E4E8\"> val_len </span><span style=\"color:#F97583\">:</span><span style=\"color:#79B8FF\"> 31</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        memcpy</span><span style=\"color:#E1E4E8\">(tmp, line </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> val_start, copy);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        req->content_length     </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">uint64_t</span><span style=\"color:#E1E4E8\">)</span><span style=\"color:#B392F0\">strtoull</span><span style=\"color:#E1E4E8\">(tmp, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        req->has_content_length </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    } </span><span style=\"color:#F97583\">else</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> (colon </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 10</span><span style=\"color:#F97583\"> &#x26;&#x26;</span><span style=\"color:#B392F0\"> strncasecmp</span><span style=\"color:#E1E4E8\">(line, </span><span style=\"color:#9ECBFF\">\"Connection\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Check for \"close\" value */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (val_len </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> 5</span><span style=\"color:#F97583\"> &#x26;&#x26;</span><span style=\"color:#B392F0\"> strncasecmp</span><span style=\"color:#E1E4E8\">(line </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> val_start, </span><span style=\"color:#9ECBFF\">\"close\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            req->keep_alive </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * http_parse_headers - Attempt to parse complete HTTP headers from buf.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * CALLING CONVENTION:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   Call after every read(). If PARSE_INCOMPLETE, return to the event loop</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   and wait for more data. If PARSE_COMPLETE, buf[0..header_end] has been</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   consumed; remaining bytes (body or start of next request) begin at</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   buf[header_end].</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Returns: PARSE_COMPLETE, PARSE_INCOMPLETE, or PARSE_ERROR.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * On PARSE_COMPLETE, *header_end_out is set to the byte offset after \\r\\n\\r\\n.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">parse_result </span><span style=\"color:#B392F0\">http_parse_headers</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">buf</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#FFAB70\"> len</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                http_request </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">req</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">header_end_out</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> hdr_end </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> find_header_end</span><span style=\"color:#E1E4E8\">(buf, len);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (hdr_end </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Haven't seen \\r\\n\\r\\n yet */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (len </span><span style=\"color:#F97583\">>=</span><span style=\"color:#E1E4E8\"> READ_BUF_SIZE) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            /* Buffer full, no end found â€” headers too large */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> PARSE_ERROR;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> PARSE_INCOMPLETE;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Default: keep-alive for HTTP/1.1 (RFC 7230 Â§6.3) */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    req->keep_alive         </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    req->has_content_length </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    req->content_length     </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    req->body_received      </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Parse line by line. Lines are separated by \\r\\n. */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    const</span><span style=\"color:#F97583\"> char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\">pos     </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> buf;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    const</span><span style=\"color:#F97583\"> char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\">hdr_end_ptr </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> buf </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> hdr_end;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\">        first   </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    while</span><span style=\"color:#E1E4E8\"> (pos </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> hdr_end_ptr) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Find end of this line */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        const</span><span style=\"color:#F97583\"> char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\">line_end </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> pos;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        while</span><span style=\"color:#E1E4E8\"> (line_end </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#F97583\"> &#x3C;</span><span style=\"color:#E1E4E8\"> hdr_end_ptr </span><span style=\"color:#F97583\">&#x26;&#x26;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">               !</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">line_end</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> '</span><span style=\"color:#79B8FF\">\\r</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#F97583\"> &#x26;&#x26;</span><span style=\"color:#FFAB70\"> line_end</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> '</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            line_end</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\"> line_len </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\">)(line_end </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> pos);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (first) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">parse_request_line</span><span style=\"color:#E1E4E8\">(pos, line_len, req) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#E1E4E8\"> PARSE_ERROR;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            first </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        } </span><span style=\"color:#F97583\">else</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> (line_len </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            parse_header_field</span><span style=\"color:#E1E4E8\">(pos, line_len, req);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        pos </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> line_end </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\">  /* skip \\r\\n */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    *</span><span style=\"color:#E1E4E8\">header_end_out </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> hdr_end;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> PARSE_COMPLETE;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<blockquote>\n<p><strong>Why iterate byte-by-byte instead of using <code>strstr</code>?</strong> <code>strstr</code> would find <code>\\r\\n\\r\\n</code>, but it requires null-terminated input, and your read buffer may contain binary data in the body. More importantly, <code>strstr</code> on a large buffer scans from the beginning every call. Since you&#39;re accumulating bytes across multiple reads, you&#39;d rescan already-checked bytes on every invocation. A production optimization: remember the parse position between reads (store <code>parse_offset</code> in <code>http_conn</code>) and start scanning from there. For this milestone, rescanning from zero is correct; the optimization is straightforward once the basic structure works.</p>\n</blockquote>\n<hr>\n<h2 id=\"handling-the-read-event-accumulate-parse-dispatch\">Handling the Read Event: Accumulate, Parse, Dispatch</h2>\n<p>This is the read callback registered with the reactor for every client fd. It&#39;s the integration point where the event loop, the parser, and the state machine meet:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"reactor.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;errno.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;unistd.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;string.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdio.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdlib.h></span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/* Forward declarations */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> http_process_request</span><span style=\"color:#E1E4E8\">(http_conn </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">conn</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> http_conn_close_deferred</span><span style=\"color:#E1E4E8\">(reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">r</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">user_data</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> http_conn_reset_for_keepalive</span><span style=\"color:#E1E4E8\">(http_conn </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">conn</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * http_on_readable - Called by reactor when REACTOR_READABLE fires.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * This function embodies the incremental parsing loop:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   1. Read all available data into the accumulation buffer.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   2. After each read, attempt to parse.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   3. If parse completes: transition state, process request.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   4. If parse incomplete: return to event loop (wait for more data).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   5. Handle the ET discipline: read until EAGAIN.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * NOTE: This server registers with EPOLLIN | EPOLLET for efficiency.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * The drain-until-EAGAIN loop is therefore mandatory here (Milestone 1).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> http_on_readable</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#FFAB70\"> events</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">user_data</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    http_conn </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">conn </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (http_conn </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">)user_data;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    reactor   </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">r    </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> conn->reactor_ref;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Error or hangup: schedule cleanup and return */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (events </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\"> (REACTOR_ERROR </span><span style=\"color:#F97583\">|</span><span style=\"color:#E1E4E8\"> REACTOR_HANGUP)) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        reactor_defer</span><span style=\"color:#E1E4E8\">(r, http_conn_close_deferred, conn);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Only accept reads in the READING_HEADERS or READING_BODY states */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (conn->state </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> HTTP_READING_HEADERS </span><span style=\"color:#F97583\">&#x26;&#x26;</span><span style=\"color:#E1E4E8\"> conn->state </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> HTTP_READING_BODY) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Unexpected read during PROCESSING or WRITING â€” possible race.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * Ignore: the write path will close the connection when done. */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* ET mode: drain until EAGAIN */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (;;) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* How much space is left in the read buffer? */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        uint32_t</span><span style=\"color:#E1E4E8\"> space </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> READ_BUF_SIZE </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> conn->read_len;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (space </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            /* Buffer full without completing parse â€” headers too large */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            reactor_defer</span><span style=\"color:#E1E4E8\">(r, http_conn_close_deferred, conn);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        ssize_t</span><span style=\"color:#E1E4E8\"> n </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> read</span><span style=\"color:#E1E4E8\">(fd, conn->read_buf </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> conn->read_len, space);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (n </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            conn->read_len </span><span style=\"color:#F97583\">+=</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#E1E4E8\">)n;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            /* Reset idle timer: we received data */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (conn->timer_id </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">                reactor_cancel_timer</span><span style=\"color:#E1E4E8\">(r, conn->timer_id);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            conn->timer_id </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> reactor_set_timeout</span><span style=\"color:#E1E4E8\">(r, IDLE_TIMEOUT_MS,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                                  http_idle_timeout_cb, conn);</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            /* Attempt to parse after every read â€” don't wait for EAGAIN */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (conn->state </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> HTTP_READING_HEADERS) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                int</span><span style=\"color:#E1E4E8\"> header_end </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                parse_result pr </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> http_parse_headers</span><span style=\"color:#E1E4E8\">(conn->read_buf,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                                     conn->read_len,</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                                                     &#x26;</span><span style=\"color:#E1E4E8\">conn->req,</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                                                     &#x26;</span><span style=\"color:#E1E4E8\">header_end);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> (pr </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> PARSE_ERROR) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                    /* Malformed request: send 400, then close */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">                    http_send_error</span><span style=\"color:#E1E4E8\">(conn, </span><span style=\"color:#79B8FF\">400</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"Bad Request\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    conn->state </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> HTTP_CLOSING;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> (pr </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> PARSE_COMPLETE) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                    /* Headers done. Do we have a body? */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    if</span><span style=\"color:#E1E4E8\"> (conn->req.has_content_length </span><span style=\"color:#F97583\">&#x26;&#x26;</span><span style=\"color:#E1E4E8\"> conn->req.content_length </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                        /* Shift remaining bytes (body start) to front of buffer */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                        uint32_t</span><span style=\"color:#E1E4E8\"> remaining </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> conn->read_len </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#E1E4E8\">)header_end;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                        if</span><span style=\"color:#E1E4E8\"> (remaining </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">                            memmove</span><span style=\"color:#E1E4E8\">(conn->read_buf,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                    conn->read_buf </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> header_end,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                    remaining);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        conn->read_len </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> remaining;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        conn->req.body_received </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> remaining;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        conn->state </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> HTTP_READING_BODY;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                        /* Fall through to body reading below */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    } </span><span style=\"color:#F97583\">else</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                        /* No body: process immediately */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        conn->read_len </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        conn->state    </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> HTTP_PROCESSING;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">                        http_process_request</span><span style=\"color:#E1E4E8\">(conn);</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                        /* After processing, we may be back in READING_HEADERS</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                         * (keep-alive) or CLOSING. If writing started, the</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                         * EPOLLOUT path (from M2) handles the rest. */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                        if</span><span style=\"color:#E1E4E8\"> (conn->state </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> HTTP_CLOSING) </span><span style=\"color:#F97583\">return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                        /* Continue drain loop for pipelining */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                /* PARSE_INCOMPLETE: continue reading */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (conn->state </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> HTTP_READING_BODY) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                uint64_t</span><span style=\"color:#E1E4E8\"> needed </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> conn->req.content_length </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> conn->req.body_received;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                /* We only buffer up to READ_BUF_SIZE of the body.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                 * For large bodies, a production server would stream to disk. */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> (conn->req.body_received </span><span style=\"color:#F97583\">>=</span><span style=\"color:#E1E4E8\"> conn->req.content_length) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    conn->state </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> HTTP_PROCESSING;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">                    http_process_request</span><span style=\"color:#E1E4E8\">(conn);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    if</span><span style=\"color:#E1E4E8\"> (conn->state </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> HTTP_CLOSING) </span><span style=\"color:#F97583\">return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                } </span><span style=\"color:#F97583\">else</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    (</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">)needed;</span><span style=\"color:#6A737D\"> /* still accumulating */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        } </span><span style=\"color:#F97583\">else</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> (n </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            /* EOF: peer closed the connection */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            reactor_defer</span><span style=\"color:#E1E4E8\">(r, http_conn_close_deferred, conn);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        } </span><span style=\"color:#F97583\">else</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            /* n == -1 */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EAGAIN </span><span style=\"color:#F97583\">||</span><span style=\"color:#E1E4E8\"> errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EWOULDBLOCK) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                break</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\">  /* buffer fully drained â€” exit ET read loop */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            /* Real socket error */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            reactor_defer</span><span style=\"color:#E1E4E8\">(r, http_conn_close_deferred, conn);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Fdiag-m4-full-request-lifecycle-trace.svg\" alt=\"Complete Request Lifecycle: Accept to Response to Close\"></p>\n<h2 id=\"the-critical-insight-in-http_on_readable-http_parse_headers-is-called-inside-the-read-loop-after-every-successful-read-this-is-the-incremental-designdon39t-wait-for-eagain-to-try-parsing-the-moment-you-have-more-data-try-if-headers-are-complete-process-immediately-without-waiting-for-the-next-event-if-they39re-not-complete-the-loop-continues-reading-or-exits-on-eagain-and-the-reactor-will-re-notify-when-more-data-arrives-the-memmove-after-parsing-headers-deserves-attention-if-your-16-kb-read-buffer-received-512-bytes-of-headers-followed-by-the-first-128-bytes-of-a-post-body-header_end-points-to-byte-512-the-body-bytes-128-bytes-need-to-be-at-the-front-of-the-buffer-for-subsequent-reads-to-append-correctly-memmove-slides-them-there-this-is-obody_received-bytes-copiedsmall-for-this-use-case-but-worth-noting-for-large-streaming-bodies-where-you39d-want-a-ring-buffer-or-linked-list-of-chunks\">The critical insight in <code>http_on_readable</code>: <code>http_parse_headers</code> is called inside the read loop, after every successful <code>read()</code>. This is the incremental designâ€”don&#39;t wait for EAGAIN to try parsing. The moment you have more data, try. If headers are complete, process immediately without waiting for the next event. If they&#39;re not complete, the loop continues reading (or exits on EAGAIN, and the reactor will re-notify when more data arrives).\nThe <code>memmove</code> after parsing headers deserves attention. If your 16 KB read buffer received 512 bytes of headers followed by the first 128 bytes of a POST body, <code>header_end</code> points to byte 512. The body bytes (128 bytes) need to be at the <em>front</em> of the buffer for subsequent reads to append correctly. <code>memmove</code> slides them there. This is O(body_received) bytes copiedâ€”small for this use case, but worth noting for large streaming bodies where you&#39;d want a ring buffer or linked list of chunks.</h2>\n<h2 id=\"processing-the-request-and-serving-static-files\">Processing the Request and Serving Static Files</h2>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;fcntl.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;sys/stat.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;sys/sendfile.h></span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * get_content_type - Map file extension to MIME type string.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Returns \"application/octet-stream\" for unknown extensions.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> const</span><span style=\"color:#F97583\"> char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">get_content_type</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">path</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    const</span><span style=\"color:#F97583\"> char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\">dot </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> strrchr</span><span style=\"color:#E1E4E8\">(path, </span><span style=\"color:#9ECBFF\">'.'</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">dot) </span><span style=\"color:#F97583\">return</span><span style=\"color:#9ECBFF\"> \"application/octet-stream\"</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">strcmp</span><span style=\"color:#E1E4E8\">(dot, </span><span style=\"color:#9ECBFF\">\".html\"</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> ||</span><span style=\"color:#B392F0\"> strcmp</span><span style=\"color:#E1E4E8\">(dot, </span><span style=\"color:#9ECBFF\">\".htm\"</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> \"text/html; charset=utf-8\"</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">strcmp</span><span style=\"color:#E1E4E8\">(dot, </span><span style=\"color:#9ECBFF\">\".css\"</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">return</span><span style=\"color:#9ECBFF\"> \"text/css\"</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">strcmp</span><span style=\"color:#E1E4E8\">(dot, </span><span style=\"color:#9ECBFF\">\".js\"</span><span style=\"color:#E1E4E8\">)   </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">return</span><span style=\"color:#9ECBFF\"> \"application/javascript\"</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">strcmp</span><span style=\"color:#E1E4E8\">(dot, </span><span style=\"color:#9ECBFF\">\".json\"</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">return</span><span style=\"color:#9ECBFF\"> \"application/json\"</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">strcmp</span><span style=\"color:#E1E4E8\">(dot, </span><span style=\"color:#9ECBFF\">\".png\"</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">return</span><span style=\"color:#9ECBFF\"> \"image/png\"</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">strcmp</span><span style=\"color:#E1E4E8\">(dot, </span><span style=\"color:#9ECBFF\">\".jpg\"</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> ||</span><span style=\"color:#B392F0\"> strcmp</span><span style=\"color:#E1E4E8\">(dot, </span><span style=\"color:#9ECBFF\">\".jpeg\"</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> \"image/jpeg\"</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">strcmp</span><span style=\"color:#E1E4E8\">(dot, </span><span style=\"color:#9ECBFF\">\".ico\"</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">return</span><span style=\"color:#9ECBFF\"> \"image/x-icon\"</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">strcmp</span><span style=\"color:#E1E4E8\">(dot, </span><span style=\"color:#9ECBFF\">\".txt\"</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">return</span><span style=\"color:#9ECBFF\"> \"text/plain; charset=utf-8\"</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#9ECBFF\"> \"application/octet-stream\"</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * build_safe_path - Combine STATIC_DIR with the request path, rejecting</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * path traversal attacks (/../ sequences).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Returns 0 on success (out_path populated), -1 if path is unsafe.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Security note: Without this check, a request for</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   GET /../../../etc/passwd HTTP/1.1</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * would serve the system password file. Never skip this.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> int</span><span style=\"color:#B392F0\"> build_safe_path</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">req_path</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">out_path</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> out_len</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Reject any path containing \"..\" after normalization */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">strstr</span><span style=\"color:#E1E4E8\">(req_path, </span><span style=\"color:#9ECBFF\">\"..\"</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Reject paths not starting with '/' */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">req_path</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">!=</span><span style=\"color:#9ECBFF\"> '/'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Combine static dir + request path */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> n </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> snprintf</span><span style=\"color:#E1E4E8\">(out_path, out_len, </span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">%s%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, STATIC_DIR, req_path);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (n </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> ||</span><span style=\"color:#E1E4E8\"> n </span><span style=\"color:#F97583\">>=</span><span style=\"color:#E1E4E8\"> out_len) </span><span style=\"color:#F97583\">return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* If path ends with '/', append index.html */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">out_path</span><span style=\"color:#E1E4E8\">[n </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> '/'</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\"> rem </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> out_len </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> n;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">snprintf</span><span style=\"color:#E1E4E8\">(out_path </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> n, rem, </span><span style=\"color:#9ECBFF\">\"index.html\"</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">>=</span><span style=\"color:#E1E4E8\"> rem) </span><span style=\"color:#F97583\">return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * http_send_error - Send a simple error response and queue for closing.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Uses the write buffer from M2. Partial writes are handled by the</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * EPOLLOUT mechanism automatically.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> http_send_error</span><span style=\"color:#E1E4E8\">(http_conn </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">conn</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> status</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">reason</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> buf</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">256</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\">  n </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> snprintf</span><span style=\"color:#E1E4E8\">(buf, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(buf),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                      \"HTTP/1.1 </span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#79B8FF\"> %s\\r\\n</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                      \"Content-Length: 0</span><span style=\"color:#79B8FF\">\\r\\n</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                      \"Connection: close</span><span style=\"color:#79B8FF\">\\r\\n</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                      \"</span><span style=\"color:#79B8FF\">\\r\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                      status, reason);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (n </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        conn_write_buffered</span><span style=\"color:#E1E4E8\">(conn->reactor_ref, conn, buf, (</span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#E1E4E8\">)n);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    conn->req.keep_alive </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    conn->state </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> HTTP_CLOSING;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * http_process_request - Act on a fully-parsed HTTP request.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * This function is called from http_on_readable after parse completes.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * It builds the response and writes it via the buffered write path from M2.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * After this returns, the connection is either in WRITING_RESPONSE or CLOSING.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> http_process_request</span><span style=\"color:#E1E4E8\">(http_conn </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">conn</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    conn->state </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> HTTP_WRITING_RESPONSE;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Only handle GET and HEAD for this static file server */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> is_head </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">strcmp</span><span style=\"color:#E1E4E8\">(conn->req.method, </span><span style=\"color:#9ECBFF\">\"HEAD\"</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">strcmp</span><span style=\"color:#E1E4E8\">(conn->req.method, </span><span style=\"color:#9ECBFF\">\"GET\"</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> &#x26;&#x26;</span><span style=\"color:#F97583\"> !</span><span style=\"color:#E1E4E8\">is_head) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        http_send_error</span><span style=\"color:#E1E4E8\">(conn, </span><span style=\"color:#79B8FF\">405</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"Method Not Allowed\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Resolve the file path */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> file_path</span><span style=\"color:#E1E4E8\">[MAX_PATH_LEN </span><span style=\"color:#F97583\">+</span><span style=\"color:#F97583\"> sizeof</span><span style=\"color:#E1E4E8\">(STATIC_DIR) </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 16</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">build_safe_path</span><span style=\"color:#E1E4E8\">(conn->req.path, file_path, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(file_path)) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        http_send_error</span><span style=\"color:#E1E4E8\">(conn, </span><span style=\"color:#79B8FF\">400</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"Bad Request\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Stat the file to get its size and verify it exists */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    struct</span><span style=\"color:#E1E4E8\"> stat st;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">stat</span><span style=\"color:#E1E4E8\">(file_path, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">st) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> ||</span><span style=\"color:#F97583\"> !</span><span style=\"color:#B392F0\">S_ISREG</span><span style=\"color:#E1E4E8\">(st.st_mode)) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        http_send_error</span><span style=\"color:#E1E4E8\">(conn, </span><span style=\"color:#79B8FF\">404</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"Not Found\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    off_t</span><span style=\"color:#E1E4E8\"> file_size </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> st.st_size;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    const</span><span style=\"color:#F97583\"> char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\">content_type </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> get_content_type</span><span style=\"color:#E1E4E8\">(file_path);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    const</span><span style=\"color:#F97583\"> char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\">conn_header  </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> conn->req.keep_alive</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                               ?</span><span style=\"color:#9ECBFF\"> \"keep-alive\"</span><span style=\"color:#F97583\"> :</span><span style=\"color:#9ECBFF\"> \"close\"</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Build response headers */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> headers</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">512</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\">  hdr_len </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> snprintf</span><span style=\"color:#E1E4E8\">(headers, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(headers),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                            \"HTTP/1.1 200 OK</span><span style=\"color:#79B8FF\">\\r\\n</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                            \"Content-Type: </span><span style=\"color:#79B8FF\">%s\\r\\n</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                            \"Content-Length: </span><span style=\"color:#79B8FF\">%lld\\r\\n</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                            \"Connection: </span><span style=\"color:#79B8FF\">%s\\r\\n</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                            \"</span><span style=\"color:#79B8FF\">\\r\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                            content_type,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                            (</span><span style=\"color:#F97583\">long</span><span style=\"color:#F97583\"> long</span><span style=\"color:#E1E4E8\">)file_size,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                            conn_header);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (hdr_len </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> ||</span><span style=\"color:#E1E4E8\"> hdr_len </span><span style=\"color:#F97583\">>=</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\">)</span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(headers)) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        http_send_error</span><span style=\"color:#E1E4E8\">(conn, </span><span style=\"color:#79B8FF\">500</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"Internal Server Error\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Write headers via M2 write buffer */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">conn_write_buffered</span><span style=\"color:#E1E4E8\">(conn->reactor_ref, conn,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                             headers, (</span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#E1E4E8\">)hdr_len) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        reactor_defer</span><span style=\"color:#E1E4E8\">(conn->reactor_ref, http_conn_close_deferred, conn);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (is_head) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* HEAD: only headers, no body */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        http_finalize_response</span><span style=\"color:#E1E4E8\">(conn);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Read file and write body. For small files, read into a buffer.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">     * For large files, see the sendfile() optimization in the</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">     * Knowledge Cascade section. */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> file_fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> open</span><span style=\"color:#E1E4E8\">(file_path, O_RDONLY </span><span style=\"color:#F97583\">|</span><span style=\"color:#E1E4E8\"> O_CLOEXEC);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (file_fd </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Headers already sent; can't send 500 now. Close connection. */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        reactor_defer</span><span style=\"color:#E1E4E8\">(conn->reactor_ref, http_conn_close_deferred, conn);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> file_buf</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">65536</span><span style=\"color:#E1E4E8\">];</span><span style=\"color:#6A737D\">  /* 64 KB read chunks */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    off_t</span><span style=\"color:#E1E4E8\"> sent </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    while</span><span style=\"color:#E1E4E8\"> (sent </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> file_size) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        ssize_t</span><span style=\"color:#E1E4E8\"> n </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> read</span><span style=\"color:#E1E4E8\">(file_fd, file_buf, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(file_buf));</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (n </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">break</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\">  /* file read error or unexpected EOF */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">conn_write_buffered</span><span style=\"color:#E1E4E8\">(conn->reactor_ref, conn,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                 file_buf, (</span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#E1E4E8\">)n) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            close</span><span style=\"color:#E1E4E8\">(file_fd);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            reactor_defer</span><span style=\"color:#E1E4E8\">(conn->reactor_ref, http_conn_close_deferred, conn);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        sent </span><span style=\"color:#F97583\">+=</span><span style=\"color:#E1E4E8\"> n;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    close</span><span style=\"color:#E1E4E8\">(file_fd);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    http_finalize_response</span><span style=\"color:#E1E4E8\">(conn);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * http_finalize_response - Transition state after response is queued.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * If keep-alive: reset to READING_HEADERS for the next request.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * If Connection: close: go to CLOSING, which triggers close after flush.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> http_finalize_response</span><span style=\"color:#E1E4E8\">(http_conn </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">conn</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (conn->req.keep_alive) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Reuse connection: reset state machine for next request */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        http_conn_reset_for_keepalive</span><span style=\"color:#E1E4E8\">(conn);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    } </span><span style=\"color:#F97583\">else</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        conn->state </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> HTTP_CLOSING;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* The write path (conn_flush from M2) will close the fd after the</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">         * write buffer drains. We communicate this via the CLOSING state. */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<hr>\n<h2 id=\"http11-keep-alive-the-state-machine39s-cycle\">HTTP/1.1 Keep-Alive: The State Machine&#39;s Cycle</h2>\n<p>Keep-alive is HTTP&#39;s connection reuse mechanism. Instead of TCP teardown and re-establishment for every request (which costs one full round-trip for the handshake plus TIME_WAIT overhead), the same TCP connection carries multiple request-response cycles sequentially.</p>\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Fdiag-m4-keepalive-connection-reuse.svg\" alt=\"HTTP Keep-Alive: Connection Reuse Timeline\"></p>\n<blockquote>\n<p><strong>ðŸ”‘ Foundation: HTTP/1.1 keep-alive and Content-Length</strong></p>\n<p><strong>1. What it IS</strong>\nHTTP/1.1 defaults to keep-alive connections: the server keeps the TCP connection open after sending a response, and the client can send another request on the same connection. The critical constraint is framing: without <code>Content-Length</code> (or <code>Transfer-Encoding: chunked</code>), the client has no way to know where one response ends and the next begins in the TCP byte stream. <code>Content-Length</code> tells the client exactly how many bytes to read for the body, so it knows when the response is complete and the next request can begin.</p>\n<p><strong>2. Why you need it right now</strong>\nKeep-alive is not optional at C10K scale. Without it, every request requires a new TCP connection: 3-way handshake (<del>1 RTT), kernel allocates socket state, TIME_WAIT after close (</del>60 seconds holding the port pair). At 10,000 requests/second, that&#39;s 10,000 new connections per second and 600,000 connections in TIME_WAIT simultaneouslyâ€”your server exhausts its file descriptor limit in seconds. With keep-alive, the same 10,000 TCP connections carry all 10,000 requests/second indefinitely.</p>\n<p><strong>3. Key Insight: The Framing Contract</strong>\nHTTP/1.1&#39;s persistent connections work only because of strict framing. When your server sends <code>Content-Length: 1234</code>, you&#39;re making a contract: the response body is exactly 1,234 bytes, no more, no less. If you send 1,233 bytes and close the body, the client will wait forever for the 1,234th byte. If you send 1,235 bytes, the extra byte will be interpreted as the start of the next HTTP responseâ€”parse error. <code>Content-Length</code> is not metadata; it&#39;s the protocol&#39;s framing mechanism.\nResetting the connection for keep-alive means clearing all request-specific state while preserving connection-level infrastructure (the fd, the write buffer, the reactor registration, the idle timer):</p>\n</blockquote>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * http_conn_reset_for_keepalive - Reset parser state for next request.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Called after a response is fully sent on a keep-alive connection.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * MUST reset: read buffer, parsed request fields, state machine.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * MUST preserve: fd, wbuf, reactor_ref, timer_id.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * This is the state transition that makes keep-alive work.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Without it, the read buffer retains old request bytes and the parser</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * incorrectly appends new request bytes to old ones.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> http_conn_reset_for_keepalive</span><span style=\"color:#E1E4E8\">(http_conn </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">conn</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    conn->read_len </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    conn->state    </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> HTTP_READING_HEADERS;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    memset</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">conn->req, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(conn->req));</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* The write buffer (conn->wbuf) is preserved â€” may have pending data.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">     * The idle timer is already reset on each read; we don't reset it here</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">     * to avoid double-arming. */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<p>The write side needs to be aware of the CLOSING state. When <code>conn_flush</code> fully drains the write buffer for a CLOSING connection, instead of just deregistering EPOLLOUT, it should close the connection:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * http_on_writable - Called by reactor when REACTOR_WRITABLE fires.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Flushes the write buffer. If the buffer empties:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   - CLOSING state: close the connection (deregister EPOLLOUT then close fd)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   - Other states: deregister EPOLLOUT (already handled in conn_flush from M2)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> http_on_writable</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#FFAB70\"> events</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">user_data</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    http_conn </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">conn </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (http_conn </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">)user_data;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    reactor   </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">r    </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> conn->reactor_ref;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    (</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">)fd; (</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">)events;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Flush the write buffer (uses M2's conn_flush logic) */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> flush_result </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> conn_flush_http</span><span style=\"color:#E1E4E8\">(r, conn);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (flush_result </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Write error */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        reactor_defer</span><span style=\"color:#E1E4E8\">(r, http_conn_close_deferred, conn);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* If write buffer is now empty and we're in CLOSING state, close */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">wbuf_is_empty</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">conn->wbuf) </span><span style=\"color:#F97583\">&#x26;&#x26;</span><span style=\"color:#E1E4E8\"> conn->state </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> HTTP_CLOSING) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        reactor_defer</span><span style=\"color:#E1E4E8\">(r, http_conn_close_deferred, conn);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Fdiag-m4-write-integration-backpressure.svg\" alt=\"HTTP Response Write Path: Reactor Integration\"></p>\n<hr>\n<h2 id=\"connection-lifecycle-and-resource-cleanup\">Connection Lifecycle and Resource Cleanup</h2>\n<p>Every exit pathâ€”normal close after <code>Connection: close</code>, idle timeout, read error, write error, parse errorâ€”must free the same set of resources in the same order. Missing any one resource is a leak; closing in the wrong order causes use-after-free.</p>\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Fdiag-m4-resource-cleanup-all-paths.svg\" alt=\"Resource Cleanup: Every Exit Path Must Free Everything\"></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * http_conn_close - Fully tear down one HTTP connection.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * MUST be called as a deferred task (via reactor_defer) when inside</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * a callback, NEVER called directly from within an I/O handler.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Reason: the reactor's dispatch loop may have more events for this fd</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * in the current batch; direct close causes use-after-free (M3 explains this).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Cleanup order (MANDATORY):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   1. Check active flag â€” prevent double-free</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   2. Cancel idle timer â€” prevent timer firing after fd close</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   3. Deregister from reactor â€” prevent events on closed fd</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   4. Free write buffer heap memory â€” prevent memory leak</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   5. close(fd) â€” release file descriptor (kernel cleans up TCP state)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   6. free(conn) â€” release the conn struct itself</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> http_conn_close_deferred</span><span style=\"color:#E1E4E8\">(reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">r</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">user_data</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    http_conn </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">conn </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (http_conn </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">)user_data;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Guard against double-close (timer + I/O error firing simultaneously) */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (conn->fd </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* 2. Cancel idle timer */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (conn->timer_id </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        reactor_cancel_timer</span><span style=\"color:#E1E4E8\">(r, conn->timer_id);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        conn->timer_id </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* 3. Deregister from reactor (triggers epoll_ctl DEL) */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    reactor_deregister</span><span style=\"color:#E1E4E8\">(r, conn->fd);</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* 4. Free write buffer */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    wbuf_free</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">conn->wbuf);</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* 5. Close the file descriptor */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    close</span><span style=\"color:#E1E4E8\">(conn->fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    conn->fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* 6. Free the connection struct */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    free</span><span style=\"color:#E1E4E8\">(conn);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * http_idle_timeout_cb - Called by reactor when idle timer expires.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * A connection that hasn't sent data for IDLE_TIMEOUT_MS is closed.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * This defends against:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   - Slow loris: clients that send partial headers slowly</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   - Zombie connections: TCP connections where the client crashed</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *   - Resource exhaustion: fd accumulation from idle keep-alive connections</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> http_idle_timeout_cb</span><span style=\"color:#E1E4E8\">(reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">r</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">user_data</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    http_conn </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">conn </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (http_conn </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">)user_data;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    conn->timer_id  </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\">  /* timer has fired; don't try to cancel it */</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Defer the close to ensure we're not in the middle of I/O dispatch */</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    reactor_defer</span><span style=\"color:#E1E4E8\">(r, http_conn_close_deferred, conn);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<blockquote>\n<p><strong>Why <code>conn-&gt;fd = -1</code> as the guard instead of a boolean?</strong> Using the fd itself as the &quot;alive&quot; indicator eliminates one field. A valid fd is always â‰¥ 0 (0, 1, 2 are stdin/stdout/stderr; sockets start at 3 or higher). Setting <code>conn-&gt;fd = -1</code> is unambiguous &quot;this connection is dead,&quot; and the guard <code>if (conn-&gt;fd &lt; 0) return</code> catches all double-close attempts. This pattern appears throughout production C codeâ€”libuv marks closed handles with <code>UV__HANDLE_CLOSING</code>, NGINX sets <code>c-&gt;fd = -1</code> on close.</p>\n</blockquote>\n<hr>\n<h2 id=\"wiring-it-all-together-the-accept-path\">Wiring It All Together: The Accept Path</h2>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * http_accept_cb - Reactor callback for the listening socket.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Accepts all pending connections (ET discipline: drain until EAGAIN).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Allocates http_conn, registers with reactor, sets idle timer.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> http_accept_cb</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> listen_fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#FFAB70\"> events</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">user_data</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">r </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">)user_data;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    (</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">)events;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (;;) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\"> fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> accept4</span><span style=\"color:#E1E4E8\">(listen_fd, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">, SOCK_NONBLOCK </span><span style=\"color:#F97583\">|</span><span style=\"color:#E1E4E8\"> SOCK_CLOEXEC);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (fd </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EAGAIN </span><span style=\"color:#F97583\">||</span><span style=\"color:#E1E4E8\"> errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EWOULDBLOCK) </span><span style=\"color:#F97583\">break</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            perror</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"accept4\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            break</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        http_conn </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">conn </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> calloc</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(http_conn));</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">conn) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            fprintf</span><span style=\"color:#E1E4E8\">(stderr, </span><span style=\"color:#9ECBFF\">\"OOM: dropping connection fd=</span><span style=\"color:#79B8FF\">%d\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, fd);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            close</span><span style=\"color:#E1E4E8\">(fd);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            continue</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        conn->fd          </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> fd;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        conn->timer_id    </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        conn->state       </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> HTTP_READING_HEADERS;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        conn->reactor_ref </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> r;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        wbuf_init</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">conn->wbuf);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        memset</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">conn->req, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(conn->req));</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Register with reactor for read events, ET mode */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">reactor_register</span><span style=\"color:#E1E4E8\">(r, fd, REACTOR_READABLE,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                             http_on_readable, conn) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            perror</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"reactor_register\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            free</span><span style=\"color:#E1E4E8\">(conn);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            close</span><span style=\"color:#E1E4E8\">(fd);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            continue</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        /* Set initial idle timeout */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        conn->timer_id </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> reactor_set_timeout</span><span style=\"color:#E1E4E8\">(r, IDLE_TIMEOUT_MS,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                              http_idle_timeout_cb, conn);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\"> main</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    reactor </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">r </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> reactor_create</span><span style=\"color:#E1E4E8\">();</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">r) { </span><span style=\"color:#B392F0\">perror</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"reactor_create\"</span><span style=\"color:#E1E4E8\">); </span><span style=\"color:#F97583\">return</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">; }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> listen_fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> create_listening_socket</span><span style=\"color:#E1E4E8\">();</span><span style=\"color:#6A737D\">  /* from M1 */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (listen_fd </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) { </span><span style=\"color:#B392F0\">reactor_destroy</span><span style=\"color:#E1E4E8\">(r); </span><span style=\"color:#F97583\">return</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">; }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* Register listening socket */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">reactor_register</span><span style=\"color:#E1E4E8\">(r, listen_fd, REACTOR_READABLE,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                         http_accept_cb, r) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        perror</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"reactor_register listen\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        close</span><span style=\"color:#E1E4E8\">(listen_fd);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        reactor_destroy</span><span style=\"color:#E1E4E8\">(r);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    printf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"HTTP server on port 8080, serving files from </span><span style=\"color:#79B8FF\">%s\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, STATIC_DIR);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    printf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"ulimit -n: check with 'ulimit -n' â€” must be > 10000 for C10K</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    reactor_run</span><span style=\"color:#E1E4E8\">(r);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    close</span><span style=\"color:#E1E4E8\">(listen_fd);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    reactor_destroy</span><span style=\"color:#E1E4E8\">(r);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<hr>\n<h2 id=\"preparing-for-c10k-system-configuration\">Preparing for C10K: System Configuration</h2>\n<p>Before benchmarking, the operating system itself needs configuration. A stock Linux system limits file descriptors to 1,024 per processâ€”you&#39;ll hit this wall at connection 1,025. These limits exist to protect against runaway processes; override them deliberately:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Check current limits</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">ulimit</span><span style=\"color:#79B8FF\"> -n</span><span style=\"color:#6A737D\">           # soft limit (typically 1024)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">ulimit</span><span style=\"color:#79B8FF\"> -Hn</span><span style=\"color:#6A737D\">          # hard limit (typically 1048576 on modern systems)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Raise soft limit to 65536 for this session</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">ulimit</span><span style=\"color:#79B8FF\"> -n</span><span style=\"color:#79B8FF\"> 65536</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Permanent increase: add to /etc/security/limits.conf</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># *    soft    nofile    65536</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># *    hard    nofile    65536</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Kernel-level maximum (requires root)</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">sysctl</span><span style=\"color:#79B8FF\"> -w</span><span style=\"color:#9ECBFF\"> fs.file-max=</span><span style=\"color:#79B8FF\">200000</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># TCP tuning for high connection counts</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">sysctl</span><span style=\"color:#79B8FF\"> -w</span><span style=\"color:#9ECBFF\"> net.core.somaxconn=</span><span style=\"color:#79B8FF\">65535</span><span style=\"color:#6A737D\">          # listen() backlog</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">sysctl</span><span style=\"color:#79B8FF\"> -w</span><span style=\"color:#9ECBFF\"> net.ipv4.tcp_max_syn_backlog=</span><span style=\"color:#79B8FF\">65535</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">sysctl</span><span style=\"color:#79B8FF\"> -w</span><span style=\"color:#9ECBFF\"> net.core.netdev_max_backlog=</span><span style=\"color:#79B8FF\">5000</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">sysctl</span><span style=\"color:#79B8FF\"> -w</span><span style=\"color:#9ECBFF\"> net.ipv4.tcp_tw_reuse=</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#6A737D\">           # reuse TIME_WAIT sockets</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">sysctl</span><span style=\"color:#79B8FF\"> -w</span><span style=\"color:#9ECBFF\"> net.ipv4.ip_local_port_range=\"1024 65535\"</span><span style=\"color:#6A737D\">  # client port range</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Verify your server's actual fd limit</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">cat</span><span style=\"color:#9ECBFF\"> /proc/</span><span style=\"color:#E1E4E8\">$(</span><span style=\"color:#B392F0\">pgrep</span><span style=\"color:#9ECBFF\"> http_server</span><span style=\"color:#E1E4E8\">)</span><span style=\"color:#9ECBFF\">/limits</span><span style=\"color:#F97583\"> |</span><span style=\"color:#B392F0\"> grep</span><span style=\"color:#9ECBFF\"> 'open files'</span></span></code></pre></div>\n<blockquote>\n<p><strong><code>net.core.somaxconn</code></strong>: This controls the maximum length of the kernel&#39;s queue of fully-established TCP connections waiting for <code>accept()</code>. If your server can&#39;t call <code>accept()</code> fast enough (e.g., if it&#39;s doing expensive work), this queue fills. When full, new connection attempts are silently dropped. Set it high (65535) and ensure your accept loop drains it quicklyâ€”which your ET accept loop does.</p>\n</blockquote>\n<hr>\n<h2 id=\"benchmarking-verifying-c10k\">Benchmarking: Verifying C10K</h2>\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Fdiag-m4-c10k-benchmark-architecture.svg\" alt=\"C10K Benchmark Setup and Expected Results\"></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Install wrk (HTTP benchmark tool with Lua scripting support)</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">apt-get</span><span style=\"color:#9ECBFF\"> install</span><span style=\"color:#9ECBFF\"> wrk</span><span style=\"color:#6A737D\">  # or build from source: github.com/wg/wrk</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Create a static file to serve</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">mkdir</span><span style=\"color:#79B8FF\"> -p</span><span style=\"color:#9ECBFF\"> public</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">dd</span><span style=\"color:#9ECBFF\"> if=/dev/urandom</span><span style=\"color:#9ECBFF\"> bs=</span><span style=\"color:#79B8FF\">1024</span><span style=\"color:#9ECBFF\"> count=</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#F97583\"> |</span><span style=\"color:#B392F0\"> base64</span><span style=\"color:#F97583\"> ></span><span style=\"color:#9ECBFF\"> public/test.html</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Creates a ~1.3 KB HTML file (base64 encoding expands binary)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Compile with optimizations</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">gcc</span><span style=\"color:#79B8FF\"> -O2</span><span style=\"color:#79B8FF\"> -Wall</span><span style=\"color:#79B8FF\"> -Wextra</span><span style=\"color:#79B8FF\"> -o</span><span style=\"color:#9ECBFF\"> http_server</span><span style=\"color:#9ECBFF\"> http_server.c</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">./http_server</span><span style=\"color:#E1E4E8\"> &#x26;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Basic benchmark: 100 connections, 12 threads, 10 seconds</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">wrk</span><span style=\"color:#79B8FF\"> -t12</span><span style=\"color:#79B8FF\"> -c100</span><span style=\"color:#79B8FF\"> -d10s</span><span style=\"color:#9ECBFF\"> http://localhost:8080/test.html</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># C10K test: 10,000 connections, 12 threads, 30 seconds</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">wrk</span><span style=\"color:#79B8FF\"> -t12</span><span style=\"color:#79B8FF\"> -c10000</span><span style=\"color:#79B8FF\"> -d30s</span><span style=\"color:#9ECBFF\"> http://localhost:8080/test.html</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected output at C10K:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Running 30s test @ http://localhost:8080/test.html</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">#   12 threads and 10000 connections</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">#   Thread Stats   Avg      Stdev     Max   +/- Stdev</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">#     Latency     2.14ms   18.73ms 521.41ms  99.33%</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">#     Req/Sec     8.23k     2.14k   15.89k   70.00%</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">#   2,468,231 requests in 30.10s, 3.38GB read</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Requests/sec: 82,000</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Latency (p99): &#x3C; 100ms â† the target</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Measure latency percentiles explicitly</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">wrk</span><span style=\"color:#79B8FF\"> -t12</span><span style=\"color:#79B8FF\"> -c10000</span><span style=\"color:#79B8FF\"> -d30s</span><span style=\"color:#79B8FF\"> --latency</span><span style=\"color:#9ECBFF\"> http://localhost:8080/test.html</span></span></code></pre></div>\n<p>If your p99 latency exceeds 100ms, these are the usual culprits:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Check for file descriptor exhaustion</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">cat</span><span style=\"color:#9ECBFF\"> /proc/</span><span style=\"color:#E1E4E8\">$(</span><span style=\"color:#B392F0\">pgrep</span><span style=\"color:#9ECBFF\"> http_server</span><span style=\"color:#E1E4E8\">)</span><span style=\"color:#9ECBFF\">/fd</span><span style=\"color:#F97583\"> |</span><span style=\"color:#B392F0\"> wc</span><span style=\"color:#79B8FF\"> -l</span><span style=\"color:#6A737D\">   # current open fds</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">ss</span><span style=\"color:#79B8FF\"> -s</span><span style=\"color:#6A737D\">                                         # socket statistics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Check for CPU bottleneck (should be &#x3C; 100% for single-threaded)</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">top</span><span style=\"color:#79B8FF\"> -p</span><span style=\"color:#E1E4E8\"> $(</span><span style=\"color:#B392F0\">pgrep</span><span style=\"color:#9ECBFF\"> http_server</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Check for kernel TCP queue drops (should be 0)</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">netstat</span><span style=\"color:#79B8FF\"> -s</span><span style=\"color:#F97583\"> |</span><span style=\"color:#B392F0\"> grep</span><span style=\"color:#79B8FF\"> -i</span><span style=\"color:#9ECBFF\"> 'drop\\|overflow\\|fail'</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Profile hot paths with perf</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">perf</span><span style=\"color:#9ECBFF\"> stat</span><span style=\"color:#79B8FF\"> -p</span><span style=\"color:#E1E4E8\"> $(</span><span style=\"color:#B392F0\">pgrep</span><span style=\"color:#9ECBFF\"> http_server</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#79B8FF\">--</span><span style=\"color:#9ECBFF\"> sleep</span><span style=\"color:#79B8FF\"> 10</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">perf</span><span style=\"color:#9ECBFF\"> top</span><span style=\"color:#79B8FF\"> -p</span><span style=\"color:#E1E4E8\"> $(</span><span style=\"color:#B392F0\">pgrep</span><span style=\"color:#9ECBFF\"> http_server</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n<h2 id=\"the-most-common-performance-cliff-at-c10k-the-linux-kernel39s-tcp-accept-backlog-filled-because-the-accept-loop-ran-too-slowly-increase-netcoresomaxconn-and-verify-with-ss-lnt-look-at-the-recv-q-column-for-the-listening-socket-it-should-stay-near-0\">The most common performance cliff at C10K: the Linux kernel&#39;s TCP accept backlog filled because the accept loop ran too slowly. Increase <code>net.core.somaxconn</code> and verify with <code>ss -lnt</code> (look at the Recv-Q column for the listening socket; it should stay near 0).</h2>\n<h2 id=\"the-slow-loris-understanding-the-attack-you39ve-already-defended-against\">The Slow Loris: Understanding the Attack You&#39;ve Already Defended Against</h2>\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Fdiag-m4-slow-loris-attack-defense.svg\" alt=\"Slow Loris Attack and Defense Mechanisms\"></p>\n<p>Now that you&#39;ve built an incremental HTTP parser, you can understand the <strong>slow loris attack</strong> at a mechanistic levelâ€”not just as a description, but as a consequence of the exact code you wrote.\nYour parser accumulates bytes in <code>read_buf</code> until <code>find_header_end</code> finds <code>\\r\\n\\r\\n</code>. The parsed request&#39;s state machine stays in <code>HTTP_READING_HEADERS</code> until that happens. The connection holds <code>sizeof(http_conn)</code> â‰ˆ 17 KB of memory throughout.\nA slow loris client sends one byte of an HTTP request every 25 seconds. Your parser never finds <code>\\r\\n\\r\\n</code>. The connection stays open, consuming memory, with its idle timer reset each time the byte arrives. Against a server without idle timeouts, a single slow loris client with 1,000 connections can hold 17 MB of server memory indefinitely, and each of those connections consumes a file descriptorâ€”eventually exhausting the fd limit and making the server unable to accept legitimate connections.\nYour defense is already in place: <code>IDLE_TIMEOUT_MS = 30000</code>. A connection that sends one byte every 25 seconds will reset the timer each time, but a connection that sends nothing for 30 seconds will be closed. Against a more sophisticated slow loris that sends exactly one byte every 29 seconds, you&#39;d add a secondary defense: a maximum time-to-first-complete-request (separate from idle timeout), which limits how long the header accumulation state can last regardless of activity.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/* Secondary defense: maximum header accumulation time */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> MAX_HEADER_TIME_MS</span><span style=\"color:#79B8FF\">  60000</span><span style=\"color:#6A737D\">  /* 60 seconds maximum to send complete headers */</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/* In http_accept_cb, set TWO timers: */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">conn</span><span style=\"color:#F97583\">-></span><span style=\"color:#E1E4E8\">idle_timer_id    </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> reactor_set_timeout</span><span style=\"color:#E1E4E8\">(r, IDLE_TIMEOUT_MS, http_idle_timeout_cb, conn);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">conn</span><span style=\"color:#F97583\">-></span><span style=\"color:#E1E4E8\">header_timer_id  </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> reactor_set_timeout</span><span style=\"color:#E1E4E8\">(r, MAX_HEADER_TIME_MS, http_header_timeout_cb, conn);</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/* Cancel header_timer_id in http_process_request once headers complete */</span></span></code></pre></div>\n<hr>\n<h2 id=\"the-three-level-view-one-http-request\">The Three-Level View: One HTTP Request</h2>\n<h2 id=\"let39s-trace-a-complete-http-get-request-from-the-moment-the-nic-receives-the-tcp-segment-to-the-moment-your-http_process_request-is-called-level-3-hardware-a-tcp-segment-carrying-get-testhtml-http11rnhost-benchrnrn-arrives-at-the-nic-the-nic39s-dma-engine-writes-the-payload-into-a-kernel-ring-buffer-the-nic39s-rx-ring-without-cpu-involvement-the-nic-signals-the-cpu-via-an-interrupt-or-the-kernel-polls-with-napi-to-reduce-interrupt-overhead-at-high-packet-rates-the-hardware-interrupt-fires-level-2-oskernel-the-interrupt-handler-runs-in-interrupt-context-non-preemptible-cannot-sleep-it-dequeues-the-packet-from-the-nic39s-rx-ring-runs-it-through-the-network-stack-netipv4tcp_inputc-tcp-checksum-verification-sequence-number-validation-segment-reassembly-if-fragmented-reassembled-data-is-placed-into-the-socket39s-receive-buffer-sk-gtsk_receive_queue-the-socket39s-readiness-callback-firessock_def_readablewhich-wakes-the-epoll-subsystem-the-epitem-for-this-fd-moves-from-the-wait-queue-to-rdllist-at-some-point-your-process-sleeping-in-epoll_wait-is-scheduled-by-the-kernel39s-cfs-completely-fair-scheduler-the-kernel-copies-the-ready-event-from-rdllist-into-your-user-space-events-array-via-copy_to_user-epoll_wait-returns-level-1-application-your-reactor_run-loop-reads-n_ready-1-it-retrieves-fd_handler-h-events0dataptr-it-calls-h-gtcallbackfd-reactor_readable-h-gtuser_data-that39s-http_on_readable-inside-readfd-conn-gtread_buf-conn-gtread_len-space-copies-bytes-from-kernel-socket-buffer-to-user-space-another-copy_to_user-in-reversecopy_to_user-from-kernel39s-perspective-data-flows-from-kernel-to-your-process-http_parse_headers-scans-the-buffer-finds-rnrn-populates-conn-gtreq-http_process_request-opens-publictesthtml-reads-it-writes-headers-and-body-to-conn-gtwbuf-on-the-next-write-call-bytes-flow-from-conn-gtwbuf-back-into-the-kernel39s-socket-send-buffer-the-tcp-stack-segments-them-queues-dma-descriptors-to-the-nic39s-tx-ring-and-the-nic-sends-them-on-the-wire-total-latency-from-packet-arrival-to-response-queued-for-sending-roughly-50200-s-on-a-modern-server-at-low-load-the-dominant-costs-are-the-interrupt-handling-and-scheduling-latency-1030-s-the-two-memcpy-operations-kernelreceive-buffer-and-receive-buffersocket-send-buffer-each-15-s-for-kb-sized-payloads-and-the-file-read-call-520-s-for-a-cached-file-from-page-cache\">Let&#39;s trace a complete HTTP GET request from the moment the NIC receives the TCP segment to the moment your <code>http_process_request</code> is called.\n<strong>Level 3 â€” Hardware</strong>: A TCP segment carrying <code>GET /test.html HTTP/1.1\\r\\nHost: bench\\r\\n\\r\\n</code> arrives at the NIC. The NIC&#39;s DMA engine writes the payload into a kernel ring buffer (the NIC&#39;s RX ring) without CPU involvement. The NIC signals the CPU via an interrupt (or the kernel polls with NAPI to reduce interrupt overhead at high packet rates). The hardware interrupt fires.\n<strong>Level 2 â€” OS/Kernel</strong>: The interrupt handler runs in interrupt context (non-preemptible, cannot sleep). It dequeues the packet from the NIC&#39;s RX ring, runs it through the network stack (<code>net/ipv4/tcp_input.c</code>): TCP checksum verification, sequence number validation, segment reassembly if fragmented. Reassembled data is placed into the socket&#39;s receive buffer (<code>sk-&gt;sk_receive_queue</code>). The socket&#39;s readiness callback firesâ€”<code>sock_def_readable</code>â€”which wakes the epoll subsystem. The <code>epitem</code> for this fd moves from the wait queue to <code>rdllist</code>. At some point, your process (sleeping in <code>epoll_wait</code>) is scheduled by the kernel&#39;s CFS (Completely Fair Scheduler). The kernel copies the ready event from <code>rdllist</code> into your user-space <code>events[]</code> array via <code>copy_to_user</code>. <code>epoll_wait</code> returns.\n<strong>Level 1 â€” Application</strong>: Your <code>reactor_run</code> loop reads <code>n_ready = 1</code>. It retrieves <code>fd_handler *h = events[0].data.ptr</code>. It calls <code>h-&gt;callback(fd, REACTOR_READABLE, h-&gt;user_data)</code>. That&#39;s <code>http_on_readable</code>. Inside, <code>read(fd, conn-&gt;read_buf + conn-&gt;read_len, space)</code> copies bytes from kernel socket buffer to user space (another <code>copy_to_user</code> in reverseâ€”<code>copy_to_user</code> from kernel&#39;s perspective, data flows from kernel to your process). <code>http_parse_headers</code> scans the buffer, finds <code>\\r\\n\\r\\n</code>, populates <code>conn-&gt;req</code>. <code>http_process_request</code> opens <code>/public/test.html</code>, reads it, writes headers and body to <code>conn-&gt;wbuf</code>. On the next <code>write()</code> call, bytes flow from <code>conn-&gt;wbuf</code> back into the kernel&#39;s socket send buffer. The TCP stack segments them, queues DMA descriptors to the NIC&#39;s TX ring, and the NIC sends them on the wire.\nTotal latency from packet arrival to response queued for sending: roughly <strong>50â€“200 Âµs</strong> on a modern server at low load. The dominant costs are the interrupt handling and scheduling latency (<del>10â€“30 Âµs), the two <code>memcpy</code> operations (kernelâ†’receive buffer and receive bufferâ†’socket send buffer, each ~1â€“5 Âµs for KB-sized payloads), and the file <code>read()</code> call (</del>5â€“20 Âµs for a cached file from page cache).</h2>\n<h2 id=\"hardware-soul-what-limits-your-throughput\">Hardware Soul: What Limits Your Throughput</h2>\n<h2 id=\"at-10000-concurrent-connections-with-a-13-kb-response-file-what-are-the-hardware-bottlenecks-memory-bandwidth-each-request-involves-reading-17-kb-of-http_conn-state-cold-connections-cache-miss-plus-the-file-data-from-page-cache-at-80000-requestssecond-and-17-kb-per-connection-access-that39s-136-gbs-of-memory-readswell-within-a-modern-cpu39s-4080-gbs-memory-bandwidth-memory-is-not-the-bottleneck-here-cache-pressure-your-10000-active-connections-occupy-10000-17-kb-170-mb-of-heap-memory-l3-cache-is-typically-832-mb-most-http_conn-structures-are-cold-in-cache-accessing-one-for-the-first-time-costs-an-l3-miss-40-cycles-under-heavy-load-where-the-same-connections-are-active-repeatedly-the-working-set-shrinks-to-recently-active-connections-and-the-cache-hit-rate-improves-the-per-connection-state-size-is-therefore-a-real-performance-dialhalving-it-8-kb-instead-of-16-kb-for-the-read-buffer-approximately-doubles-the-number-of-quotwarmquot-connections-that-fit-in-l3-system-call-overhead-each-request-involves-epoll_wait-1-syscall-read-1-syscall-stat-1-syscall-open-1-syscall-read-file-possibly-multiple-syscalls-write-1-syscalls-at-80000-reqs-that39s-roughly-480000-syscallssecond-each-syscall-costs-200-ns-context-switch-to-kernel-and-back-at-480k-syscallss-96-ms-of-cpu-time-per-second-just-in-syscall-overheadabout-10-of-one-cpu-core-this-is-measurable-and-motivates-sendfile-eliminates-the-readwrite-pair-for-static-files-and-io_uring-eliminates-the-per-syscall-context-switch-overhead-entirely-branch-prediction-the-parser39s-find_header_end-scan-has-a-branch-the-rnrn-check-that39s-almost-always-not-taken-until-the-very-end-of-the-headers-the-branch-predictor-learns-this-quickly-the-state-machine-transitions-conn-gtstate-http_reading_headers-are-nearly-always-predictable-because-connections-spend-much-more-time-reading-than-transitioning\">At 10,000 concurrent connections with a 1.3 KB response file, what are the hardware bottlenecks?\n<strong>Memory bandwidth</strong>: Each request involves reading <del>17 KB of <code>http_conn</code> state (cold connections cache-miss) plus the file data from page cache. At 80,000 requests/second and 17 KB per connection access, that&#39;s 1.36 GB/s of memory readsâ€”well within a modern CPU&#39;s 40â€“80 GB/s memory bandwidth. Memory is not the bottleneck here.\n<strong>Cache pressure</strong>: Your 10,000 active connections occupy 10,000 Ã— 17 KB = 170 MB of heap memory. L3 cache is typically 8â€“32 MB. Most <code>http_conn</code> structures are cold in cache; accessing one for the first time costs an L3 miss (</del>40 cycles). Under heavy load where the same connections are active repeatedly, the working set shrinks to recently-active connections and the cache hit rate improves. The per-connection state size is therefore a real performance dialâ€”halving it (8 KB instead of 16 KB for the read buffer) approximately doubles the number of &quot;warm&quot; connections that fit in L3.\n<strong>System call overhead</strong>: Each request involves <code>epoll_wait</code> (1 syscall), <code>read</code> (1 syscall), <code>stat</code> (1 syscall), <code>open</code> (1 syscall), <code>read</code> (file, possibly multiple syscalls), <code>write</code> (1+ syscalls). At 80,000 req/s, that&#39;s roughly 480,000 syscalls/second. Each syscall costs ~200 ns (context switch to kernel and back). At 480K syscalls/s: 96 ms of CPU time per second just in syscall overheadâ€”about 10% of one CPU core. This is measurable and motivates <code>sendfile()</code> (eliminates the read+write pair for static files) and io_uring (eliminates the per-syscall context switch overhead entirely).\n<strong>Branch prediction</strong>: The parser&#39;s <code>find_header_end</code> scan has a branch (the <code>\\r\\n\\r\\n</code> check) that&#39;s almost always not-taken until the very end of the headers. The branch predictor learns this quickly. The state machine transitions (<code>conn-&gt;state == HTTP_READING_HEADERS</code>) are nearly always predictable because connections spend much more time reading than transitioning.</h2>\n<h2 id=\"knowledge-cascade-five-connections-to-carry-forward\">Knowledge Cascade: Five Connections to Carry Forward</h2>\n<h3 id=\"1-protocol-buffers-and-grpc-framing-cross-domain-distributed-systems\">1. Protocol Buffers and gRPC Framing (Cross-Domain: Distributed Systems)</h3>\n<p>Your incremental <code>\\r\\n\\r\\n</code> search is one specific solution to the <strong>message framing problem</strong>: given a byte stream, how do you know where one message ends and the next begins? HTTP headers use a text delimiter. Protocol Buffers over gRPC use <strong>length-prefixed framing</strong>: a 5-byte prefix (1 byte for compression flag, 4 bytes for message length in big-endian) precedes each message. The receiver must accumulate bytes until it has the 5-byte header, parse the length, then accumulate exactly that many more bytes.\nThe gRPC framing layer faces identical incremental parsing challenges: what if only 3 bytes of the 5-byte prefix have arrived? The receiver must buffer and wait for the remaining 2 bytes before it knows the message length. The state machine looks exactly like yoursâ€”<code>READING_FRAME_HEADER</code>, <code>READING_FRAME_BODY</code>, <code>PROCESSING</code>â€”with the same &quot;accumulate in a buffer, parse after each read, handle incomplete state&quot; discipline.\nThis is why gRPC requires HTTP/2 (not HTTP/1.1): HTTP/2&#39;s binary framing natively separates the transport layer from the RPC layer, making the framing problem explicit and well-specified. HTTP/1.1&#39;s text headers required every gRPC implementation to re-solve incremental parsing.</p>\n<h3 id=\"2-database-wire-protocols-cross-domain-databases\">2. Database Wire Protocols (Cross-Domain: Databases)</h3>\n<p>PostgreSQL&#39;s wire protocol, MySQL&#39;s packet protocol, and Redis&#39;s RESP (REdis Serialization Protocol) all face the same incremental parsing problem you just solved. Redis&#39;s <code>processInlineBuffer</code> and <code>processMultibulkBuffer</code> functions in <code>networking.c</code> are direct analogs to your <code>http_parse_headers</code>. They accumulate bytes in <code>c-&gt;querybuf</code>, scan for command terminators (<code>\\r\\n</code> for inline, the RESP <code>*</code> bulk count prefix for multibulk), and return to the event loop when incomplete. Redis&#39;s <code>readQueryFromClient</code> is structurally identical to your <code>http_on_readable</code>.\nThe reason these protocols are state-machine-based is not incidentalâ€”it&#39;s a consequence of being built on top of the same TCP byte stream model you&#39;re working with. Any protocol that expects to run over a reliable byte-stream transport must solve incremental framing. This is one of the deepest patterns in distributed systems engineering.</p>\n<h3 id=\"3-zero-copy-io-with-sendfile\">3. Zero-Copy I/O with <code>sendfile()</code></h3>\n<p>Your static file serving implementation reads the file into a user-space buffer, then writes that buffer to the socket. The data traverses memory twice:</p>\n<ol>\n<li>Kernel page cache â†’ user-space buffer (<code>read()</code>)</li>\n<li>User-space buffer â†’ kernel socket send buffer (<code>write()</code>)\nThe CPU touches every byte twice. For a 1 MB file at 10,000 requests/second, that&#39;s 20 GB/s of memory bandwidth wasted on unnecessary copies.\n<code>sendfile(out_fd, in_fd, offset, count)</code> is the Linux syscall that eliminates both copies. The kernel transfers data directly from the page cache to the socket send bufferâ€”no user-space involvement, no <code>malloc</code>, no buffer. The data never touches user space at all:</li>\n</ol>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/*</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Zero-copy file serving with sendfile(2).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * sendfile moves data between two kernel-managed regions without</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * copying through user space. CPU usage for file serving drops</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * significantly; kernel NIC drivers may use DMA directly from</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * the page cache to the NIC's TX ring (hardware scatter-gather).</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Limitation: sendfile doesn't work with non-blocking sockets</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * cleanly â€” it may return EAGAIN if the socket buffer is full,</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * requiring the same EPOLLOUT + retry pattern as regular writes.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> int</span><span style=\"color:#B392F0\"> serve_file_sendfile</span><span style=\"color:#E1E4E8\">(http_conn </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">conn</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> file_fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">off_t</span><span style=\"color:#FFAB70\"> file_size</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    off_t</span><span style=\"color:#E1E4E8\"> offset </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    while</span><span style=\"color:#E1E4E8\"> (offset </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> file_size) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        ssize_t</span><span style=\"color:#E1E4E8\"> sent </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> sendfile</span><span style=\"color:#E1E4E8\">(conn->fd, file_fd, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">offset, file_size </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> offset);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (sent </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            /* offset is updated by sendfile automatically */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            continue</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (sent </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#F97583\"> &#x26;&#x26;</span><span style=\"color:#E1E4E8\"> (errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EAGAIN </span><span style=\"color:#F97583\">||</span><span style=\"color:#E1E4E8\"> errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EWOULDBLOCK)) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            /* Socket buffer full. To do this correctly with the reactor,</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">             * we'd need to store the file_fd and offset in conn state,</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">             * register EPOLLOUT, and resume on EPOLLOUT firing.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">             * This is a meaningful extension exercise. */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\">  /* error */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<p>For a complete production implementation, <code>sendfile</code> with the reactor requires storing the in-progress file transfer state (<code>file_fd</code>, <code>offset</code>, <code>remaining</code>) in <code>http_conn</code>, resuming on <code>EPOLLOUT</code>. <code>io_uring</code>&#39;s <code>IORING_OP_SPLICE</code> does the same thing with the proactor modelâ€”submit the splice, get a completion when it&#39;s done, no EPOLLOUT management needed.</p>\n<h3 id=\"4-http11-head-of-line-blocking-and-the-path-to-http2\">4. HTTP/1.1 Head-of-Line Blocking and the Path to HTTP/2</h3>\n<p>HTTP/1.1 with keep-alive serializes requests on a connection: request 2 must wait for response 1 to fully send before the client sends request 2. (HTTP pipelining, which lets clients send request 2 before receiving response 1, was standardized but rarely implemented correctly and almost never enabled in practice.) This is <strong>head-of-line blocking</strong>: a large, slow response to request 1 blocks all subsequent requests on that connection.\nHTTP/2 solves this with <strong>stream multiplexing</strong>: multiple requests are interleaved as numbered streams on a single connection. The server can send partial response 1, then partial response 2, then more of response 1â€”interleaved. A slow response to request 1 no longer blocks request 2.\nBut notice what that requires: the HTTP/2 framing layer must label each frame with its stream ID, and the receiver must reassemble frames into their respective streams. This is a much more complex state machine than the one you builtâ€”instead of one per-connection state machine, you need one per-stream state machine, multiplexed over one TCP connection. The incremental parsing challenge multiplies: you&#39;re not just accumulating headers across reads, you&#39;re demultiplexing frames across reads and reassembling per-stream state.\nBuilding HTTP/1.1&#39;s state machine gives you direct intuition for what HTTP/2 adds and why it&#39;s more complex. Head-of-line blocking is the exact limitation your <code>http_finalize_response</code> â†’ <code>HTTP_READING_HEADERS</code> cycle creates.</p>\n<h3 id=\"5-the-slow-loris-at-protocol-level\">5. The Slow Loris at Protocol Level</h3>\n<p>Understanding slow loris reveals a deeper principle: <strong>every protocol that accumulates state before processing is vulnerable to resource exhaustion attacks</strong>. Your HTTP parser accumulates <code>http_conn</code> memory for the duration of header parsing. A slow loris exploits this accumulation window.\nThe general defense patternâ€”idle timeouts, maximum accumulation size, maximum accumulation timeâ€”applies everywhere:</p>\n<ul>\n<li>PostgreSQL: <code>client_connection_check_interval</code>, <code>statement_timeout</code></li>\n<li>Redis: <code>timeout</code> configuration for idle clients</li>\n<li>gRPC: <code>keepalive_timeout</code>, <code>max_connection_idle</code></li>\n<li>NGINX: <code>client_header_timeout</code>, <code>client_body_timeout</code>\nThese aren&#39;t configuration knobs added as afterthoughts. They&#39;re the engineering response to the exact resource accumulation pattern you&#39;ve implemented. Every production protocol server has them. Now you know why.</li>\n</ul>\n<hr>\n<h2 id=\"pitfall-reference-the-six-ways-this-breaks\">Pitfall Reference: The Six Ways This Breaks</h2>\n<h2 id=\"pitfall-1-expecting-complete-headers-in-a-single-read-call-symptom-works-perfectly-on-localhost-fails-intermittently-in-production-or-under-wrk-load-test-requests-over-1400-bytes-mtu-fail-at-the-95th-percentile-fix-always-accumulate-into-a-buffer-and-call-the-parser-after-each-read-never-assume-read-returns-complete-headers-pitfall-2-write-buffer-growing-unboundedly-for-slow-clients-symptom-server-rss-grows-steadily-under-load-eventually-oom-killed-or-exhausts-heap-fix-check-wbuf_append-return-value-if-1-buffer-exceeded-write_buf_max-close-the-connection-immediately-log-when-this-happensit-indicates-slow-clients-or-network-issues-pitfall-3-keep-alive-without-resetting-the-read-buffer-symptom-second-request-on-a-keep-alive-connection-fails-to-parse-or-gets-garbage-data-mixed-in-fix-http_conn_reset_for_keepalive-must-zero-read_len-and-memset-the-req-struct-do-not-skip-either-step-pitfall-4-path-traversal-vulnerability-symptom-get-etcpasswd-serves-etcpasswd-server-leaks-arbitrary-files-fix-build_safe_path-must-reject-any-path-containing-apply-this-check-before-any-file-system-access-pitfall-5-closing-connection-directly-from-within-a-callback-symptom-occasional-segfault-or-data-sent-to-wrong-client-after-high-churn-periods-fix-always-use-reactor_deferr-http_conn_close_deferred-conn-never-call-closeconn-gtfd-directly-from-within-http_on_readable-or-http_on_writable-this-is-the-core-lesson-from-milestone-339s-zombie-flag-mechanism-pitfall-6-not-benchmarking-with-real-file-descriptors-symptom-server-appears-healthy-in-initial-testing-crashes-or-times-out-when-wrk-uses-10000-connections-fix-run-ulimit-n-65536-before-starting-the-server-add-assertfd-lt-max_fds-in-the-accept-callback-monitor-cat-procpidlimits-during-benchmark\"><strong>Pitfall 1: Expecting complete headers in a single <code>read()</code> call</strong>\n<em>Symptom</em>: Works perfectly on localhost, fails intermittently in production or under wrk load test. Requests over ~1400 bytes (MTU) fail at the 95th percentile.\n<em>Fix</em>: Always accumulate into a buffer and call the parser after each <code>read()</code>. Never assume <code>read()</code> returns complete headers.\n<strong>Pitfall 2: Write buffer growing unboundedly for slow clients</strong>\n<em>Symptom</em>: Server RSS grows steadily under load; eventually OOM-killed or exhausts heap.\n<em>Fix</em>: Check <code>wbuf_append</code> return value; if -1 (buffer exceeded <code>WRITE_BUF_MAX</code>), close the connection immediately. Log when this happensâ€”it indicates slow clients or network issues.\n<strong>Pitfall 3: Keep-alive without resetting the read buffer</strong>\n<em>Symptom</em>: Second request on a keep-alive connection fails to parse or gets garbage data mixed in.\n<em>Fix</em>: <code>http_conn_reset_for_keepalive</code> must zero <code>read_len</code> and <code>memset</code> the <code>req</code> struct. Do not skip either step.\n<strong>Pitfall 4: Path traversal vulnerability</strong>\n<em>Symptom</em>: <code>GET /../../../etc/passwd</code> serves <code>/etc/passwd</code>. Server leaks arbitrary files.\n<em>Fix</em>: <code>build_safe_path</code> must reject any path containing <code>..</code>. Apply this check before any file system access.\n<strong>Pitfall 5: Closing connection directly from within a callback</strong>\n<em>Symptom</em>: Occasional segfault or data sent to wrong client after high-churn periods.\n<em>Fix</em>: Always use <code>reactor_defer(r, http_conn_close_deferred, conn)</code>. Never call <code>close(conn-&gt;fd)</code> directly from within <code>http_on_readable</code> or <code>http_on_writable</code>. This is the core lesson from Milestone 3&#39;s zombie flag mechanism.\n<strong>Pitfall 6: Not benchmarking with real file descriptors</strong>\n<em>Symptom</em>: Server appears healthy in initial testing; crashes or times out when wrk uses 10,000 connections.\n<em>Fix</em>: Run <code>ulimit -n 65536</code> before starting the server. Add <code>assert(fd &lt; MAX_FDS)</code> in the accept callback. Monitor <code>cat /proc/PID/limits</code> during benchmark.</h2>\n<!-- END_MS -->\n\n\n\n\n<h1 id=\"tdd\">TDD</h1>\n<p>A bottom-up implementation journey that transforms raw Linux syscalls into a production-grade HTTP/1.1 server capable of 10K+ concurrent connections. Each milestone builds a verifiable artifactâ€”echo server, timer-driven reaper, reactor library, benchmarked HTTP serverâ€”while revealing why naive approaches fail under load. The architecture mirrors NGINX, Redis, and Node.js&#39;s libuv at the structural level, making every design decision legible through the lens of hardware constraints: cache line behavior, TLB pressure, branch prediction, and DMA-driven NIC I/O.</p>\n<!-- TDD_MOD_ID: build-event-loop-m1 -->\n<h1 id=\"module-charter-epoll-basics-level-triggered-and-edge-triggered\">MODULE CHARTER: epoll Basics: Level-Triggered and Edge-Triggered</h1>\n<p>This module establishes the foundational I/O multiplexing layer for the entire server architecture. It focuses on the transition from blocking, thread-per-connection models to a single-threaded event loop using the Linux <code>epoll</code> facility. The primary objective is to implement a robust echo server that correctly handles both Level-Triggered (LT) and Edge-Triggered (ET) semantics. This module does NOT implement write buffering, timers, or application-layer protocols (HTTP); those are deferred to subsequent milestones. It enforces the invariant that all monitored file descriptors must be non-blocking and that the ET loop must drain the kernel receive buffer to <code>EAGAIN</code> to prevent data-loss deadlocks.</p>\n<h1 id=\"file-structure\">FILE STRUCTURE</h1>\n<ol>\n<li><code>reactor_core.h</code>: Common definitions, constants, and the per-connection state structure.</li>\n<li><code>reactor_core.c</code>: Core utilities for <code>epoll</code> manipulation and non-blocking configuration.</li>\n<li><code>echo_server.c</code>: Main entry point containing the LT and ET loop implementations and the socket acceptance logic.</li>\n<li><code>Makefile</code>: Build instructions with <code>-O2</code> and <code>-Wall -Wextra</code> flags.</li>\n</ol>\n<h1 id=\"complete-data-model\">COMPLETE DATA MODEL</h1>\n<h3 id=\"conn_state_t-per-connection-state\"><code>conn_state_t</code> (Per-Connection State)</h3>\n<p>The server maintains a global array of <code>conn_state_t</code> structures, indexed by the file descriptor (FD) integer value. This provides $O(1)$ lookup and avoids the overhead of a hash map.</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Field</th>\n<th align=\"left\">Type</th>\n<th align=\"left\">Offset (64-bit)</th>\n<th align=\"left\">Size</th>\n<th align=\"left\">Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\"><code>read_buf</code></td>\n<td align=\"left\"><code>char[4096]</code></td>\n<td align=\"left\">0x0000</td>\n<td align=\"left\">4096</td>\n<td align=\"left\">Accumulates raw bytes from <code>read()</code> calls. Matches page size.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>read_len</code></td>\n<td align=\"left\"><code>uint32_t</code></td>\n<td align=\"left\">0x1000</td>\n<td align=\"left\">4</td>\n<td align=\"left\">Number of active bytes in <code>read_buf</code>.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>fd</code></td>\n<td align=\"left\"><code>int</code></td>\n<td align=\"left\">0x1004</td>\n<td align=\"left\">4</td>\n<td align=\"left\">The underlying file descriptor.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>is_active</code></td>\n<td align=\"left\"><code>bool</code></td>\n<td align=\"left\">0x1008</td>\n<td align=\"left\">1</td>\n<td align=\"left\">Flag indicating if this slot is currently in use.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>padding</code></td>\n<td align=\"left\"><code>uint8_t[7]</code></td>\n<td align=\"left\">0x1009</td>\n<td align=\"left\">7</td>\n<td align=\"left\">Alignment padding to maintain 64-bit boundaries.</td>\n</tr>\n<tr>\n<td align=\"left\"><strong>Total Size</strong></td>\n<td align=\"left\"></td>\n<td align=\"left\"></td>\n<td align=\"left\"><strong>4112 bytes</strong></td>\n<td align=\"left\"></td>\n</tr>\n</tbody></table>\n<p><strong>Memory &amp; Cache Analysis:</strong></p>\n<ul>\n<li><strong>Cache Alignment:</strong> The <code>read_buf</code> starts at offset 0, ensuring the first chunk of data aligns with L1 cache lines (64 bytes).</li>\n<li><strong>Resident Set Size (RSS):</strong> For 10,000 connections, this array consumes ~41 MB. Because the array is allocated globally, the kernel uses demand-paging; memory is only physically mapped when a specific FD index is touched.</li>\n<li><strong>Cache Locality:</strong> When the event loop receives a batch of ready FDs, it accesses the <code>conn_state_t</code> array. If FDs are assigned sequentially by the kernel, these accesses exhibit high spatial locality.</li>\n</ul>\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Ftdd-diag-1.svg\" alt=\"Thread-per-Connection vs Single-Thread epoll: Stack Memory and Context Switch Cost\"></p>\n<h1 id=\"interface-contracts\">INTERFACE CONTRACTS</h1>\n<h3 id=\"1-int-set_nonblockingint-fd\">1. <code>int set_nonblocking(int fd)</code></h3>\n<ul>\n<li><strong>Purpose</strong>: Configures an FD for non-blocking I/O.</li>\n<li><strong>Arguments</strong>: <code>fd</code> (The target file descriptor).</li>\n<li><strong>Operation</strong>: Calls <code>fcntl(fd, F_GETFL)</code> to retrieve current flags, then <code>fcntl(fd, F_SETFL, flags | O_NONBLOCK)</code>.</li>\n<li><strong>Return</strong>: <code>0</code> on success, <code>-1</code> on error (sets <code>errno</code>).</li>\n<li><strong>Invariant</strong>: Must never clear existing flags (e.g., <code>O_APPEND</code>).</li>\n</ul>\n<h3 id=\"2-int-reactor_addint-epoll_fd-int-fd-uint32_t-events\">2. <code>int reactor_add(int epoll_fd, int fd, uint32_t events)</code></h3>\n<ul>\n<li><strong>Purpose</strong>: Registers a new FD into the kernel interest list.</li>\n<li><strong>Arguments</strong>: <code>epoll_fd</code> (The epoll instance), <code>fd</code> (The target FD), <code>events</code> (Bitmask like <code>EPOLLIN | EPOLLET</code>).</li>\n<li><strong>Return</strong>: <code>0</code> on success, <code>-1</code> on error.</li>\n<li><strong>Side Effect</strong>: Populates <code>struct epoll_event.data.fd</code> for retrieval during <code>epoll_wait</code>.</li>\n</ul>\n<h3 id=\"3-void-conn_initint-fd\">3. <code>void conn_init(int fd)</code></h3>\n<ul>\n<li><strong>Purpose</strong>: Initializes the <code>conn_state_t</code> entry in the global array.</li>\n<li><strong>Return</strong>: None.</li>\n<li><strong>Constraint</strong>: Must be called immediately after <code>accept4()</code> succeeds.</li>\n</ul>\n<h3 id=\"4-void-conn_closeint-epoll_fd-int-fd\">4. <code>void conn_close(int epoll_fd, int fd)</code></h3>\n<ul>\n<li><strong>Purpose</strong>: Cleans up resources for a terminating connection.</li>\n<li><strong>Operation</strong>: Removes FD from epoll via <code>EPOLL_CTL_DEL</code>, calls <code>close(fd)</code>, and marks <code>is_active = false</code>.</li>\n<li><strong>Constraint</strong>: Must handle cases where FD might have already been closed.</li>\n</ul>\n<h1 id=\"algorithm-specification\">ALGORITHM SPECIFICATION</h1>\n<h3 id=\"level-triggered-lt-loop-logic\">Level-Triggered (LT) Loop Logic</h3>\n<ol>\n<li>Call <code>epoll_wait(epoll_fd, events, MAX_EVENTS, -1)</code>.</li>\n<li>For each ready event:\n a. If <code>fd == listen_fd</code>, call <code>accept4(listen_fd, ...)</code> once.\n b. If <code>ev &amp; EPOLLIN</code>, call <code>read(fd, buf, 4096)</code>.\n c. If <code>read &gt; 0</code>, immediately call <code>write(fd, buf, read)</code>.\n d. If <code>read == 0</code> or <code>read &lt; 0</code> (and not <code>EAGAIN</code>), call <code>conn_close</code>.</li>\n<li><strong>Note</strong>: In LT mode, the kernel re-notifies if data remains in the socket buffer. A single <code>read()</code> call per iteration is functional but less efficient than a loop.</li>\n</ol>\n<h3 id=\"edge-triggered-et-loop-logic\">Edge-Triggered (ET) Loop Logic</h3>\n<ol>\n<li>Call <code>epoll_wait(epoll_fd, events, MAX_EVENTS, -1)</code>.</li>\n<li>For each ready event:\n a. If <code>fd == listen_fd</code>, <strong>LOOP</strong> <code>accept4</code> until it returns <code>-1</code> with <code>errno == EAGAIN</code>.\n b. If <code>ev &amp; EPOLLIN</code>:\n i. <strong>LOOP</strong> <code>read(fd, buf, 4096)</code>:\n     - If <code>read &gt; 0</code>: <code>write(fd, buf, read)</code>.\n     - If <code>read == 0</code>: <code>conn_close</code> and <code>break</code> loop.\n     - If <code>read &lt; 0</code>:\n         - If <code>errno == EAGAIN</code> or <code>EWOULDBLOCK</code>: <strong>Break loop</strong> (buffer drained).\n         - Otherwise: <code>conn_close</code> and <code>break</code> loop.</li>\n<li><strong>Invariant</strong>: Failure to drain to <code>EAGAIN</code> in ET mode will result in a connection stall if the client stops sending data but the server hasn&#39;t finished reading the previous burst.</li>\n</ol>\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Ftdd-diag-2.svg\" alt=\"epoll Syscall Sequence: epoll_create1 â†’ epoll_ctl ADD â†’ epoll_wait â†’ epoll_ctl DEL\"></p>\n<h1 id=\"hardware-soul-syscalls-and-pipelines\">HARDWARE SOUL: SYSCALLS AND PIPELINES</h1>\n<h3 id=\"1-the-cost-of-epoll_wait\">1. The Cost of <code>epoll_wait</code></h3>\n<p>When <code>epoll_wait</code> is called, the CPU transitions from Ring 3 (User) to Ring 0 (Kernel).</p>\n<ul>\n<li><strong>TLB Pressure</strong>: The kernel must access its internal <code>eventpoll</code> data structures. Modern CPUs use the PCID (Process-Context Identifier) to avoid flushing the TLB, but the context switch still incurs a ~200ns overhead.</li>\n<li><strong>The Ready List</strong>: Linux maintains a doubly-linked list (<code>rdllist</code>) of ready FDs. <code>epoll_wait</code> simply copies the contents of this list to the user-supplied <code>events[]</code> array. This is $O(k)$ where $k$ is the number of ready FDs, making it highly scalable.</li>\n</ul>\n<h3 id=\"2-branch-prediction-in-the-et-loop\">2. Branch Prediction in the ET Loop</h3>\n<p>The <code>while(1)</code> loop in ET mode contains a branch: <code>if (n &lt; 0 &amp;&amp; (errno == EAGAIN || errno == EWOULDBLOCK))</code>.</p>\n<ul>\n<li><strong>Prediction</strong>: During high-throughput bursts, this branch is predicted &quot;not taken&quot; by the CPU&#39;s Branch Target Buffer (BTB) because most <code>read()</code> calls return data.</li>\n<li><strong>Misprediction Cost</strong>: When the buffer finally empties, the CPU mispredicts the <code>EAGAIN</code> exit. This costs ~15-20 cycles. However, this is significantly cheaper than the overhead of a redundant <code>epoll_wait</code> call that LT would require to discover the same state.</li>\n</ul>\n<h3 id=\"3-simd-opportunities\">3. SIMD Opportunities</h3>\n<p>While not implemented in M1, the <code>read_buf</code> is sized at 4KB (64 cache lines). This prepares the memory layout for future vectorization (e.g., using AVX-512 to scan for protocol delimiters) by ensuring the buffer is large enough and potentially aligned to 64-byte boundaries.</p>\n<h1 id=\"error-handling-matrix\">ERROR HANDLING MATRIX</h1>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Error</th>\n<th align=\"left\">Detected By</th>\n<th align=\"left\">Recovery Action</th>\n<th align=\"left\">User-Visible?</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\"><code>EAGAIN</code> / <code>EWOULDBLOCK</code></td>\n<td align=\"left\"><code>read()</code> / <code>write()</code></td>\n<td align=\"left\">Stop loop, return to <code>epoll_wait</code>. This is the &quot;normal&quot; path for non-blocking.</td>\n<td align=\"left\">No</td>\n</tr>\n<tr>\n<td align=\"left\"><code>ECONNRESET</code></td>\n<td align=\"left\"><code>read()</code> / <code>write()</code></td>\n<td align=\"left\">Call <code>conn_close()</code>. Connection was forcibly closed by peer.</td>\n<td align=\"left\">No</td>\n</tr>\n<tr>\n<td align=\"left\"><code>EMFILE</code></td>\n<td align=\"left\"><code>accept4()</code></td>\n<td align=\"left\">Log &quot;Out of FDs&quot;. Stop accepting connections temporarily.</td>\n<td align=\"left\">No (Server log only)</td>\n</tr>\n<tr>\n<td align=\"left\"><code>EINTR</code></td>\n<td align=\"left\"><code>epoll_wait()</code></td>\n<td align=\"left\"><code>continue</code> the main loop immediately.</td>\n<td align=\"left\">No</td>\n</tr>\n<tr>\n<td align=\"left\"><code>EBADF</code></td>\n<td align=\"left\"><code>epoll_ctl()</code></td>\n<td align=\"left\">Internal logic error. Log error and abort or skip connection.</td>\n<td align=\"left\">No</td>\n</tr>\n</tbody></table>\n<h1 id=\"implementation-sequence\">IMPLEMENTATION SEQUENCE</h1>\n<h3 id=\"phase-1-socket-amp-non-blocking-helpers-15-hours\">Phase 1: Socket &amp; Non-blocking Helpers (1.5 Hours)</h3>\n<ul>\n<li>Implement <code>set_nonblocking</code>.</li>\n<li>Implement <code>create_listening_socket</code> (socket, bind, listen).</li>\n<li>Use <code>SO_REUSEADDR</code> to avoid <code>TIME_WAIT</code> rebind failures.</li>\n<li><strong>Checkpoint</strong>: Compile a small tool that opens a socket, sets it non-blocking, and verifies with <code>fcntl(F_GETFL)</code>.</li>\n</ul>\n<h3 id=\"phase-2-lt-event-loop-3-hours\">Phase 2: LT Event Loop (3 Hours)</h3>\n<ul>\n<li>Implement <code>conn_state_t</code> array management.</li>\n<li>Implement <code>epoll_create1(EPOLL_CLOEXEC)</code>.</li>\n<li>Implement the LT loop: single <code>accept</code>, single <code>read</code>/<code>write</code>.</li>\n<li><strong>Checkpoint</strong>: Run server. Connect with <code>nc localhost 8080</code>. Verify echo works. Use <code>strace</code> to confirm <code>epoll_wait</code> returns for every chunk of data.</li>\n</ul>\n<h3 id=\"phase-3-et-event-loop-amp-drain-3-hours\">Phase 3: ET Event Loop &amp; Drain (3 Hours)</h3>\n<ul>\n<li>Add <code>EPOLLET</code> to the <code>epoll_ctl</code> registration.</li>\n<li>Implement the &quot;Drain until EAGAIN&quot; loops for both <code>accept</code> and <code>read</code>.</li>\n<li>Implement the CLI switch (e.g., <code>./server --mode=et</code>).</li>\n<li><strong>Checkpoint</strong>: Use a Python script to send 10KB of data in one burst. Verify that in ET mode, one <code>epoll_wait</code> wakeup triggers multiple <code>read()</code> calls until <code>EAGAIN</code>.</li>\n</ul>\n<h1 id=\"test-specification\">TEST SPECIFICATION</h1>\n<h3 id=\"1-functional-echo-test-happy-path\">1. Functional Echo Test (Happy Path)</h3>\n<ul>\n<li><strong>Input</strong>: <code>echo &quot;Hello&quot; | nc -q 1 localhost 8080</code></li>\n<li><strong>Output</strong>: Server logs &quot;Read 6 bytes&quot;, client receives &quot;Hello&quot;.</li>\n<li><strong>Success Criteria</strong>: Data received matches data sent.</li>\n</ul>\n<h3 id=\"2-the-et-quotstallquot-test-edge-case\">2. The ET &quot;Stall&quot; Test (Edge Case)</h3>\n<ul>\n<li><strong>Input</strong>: Server in ET mode. Force the <code>read()</code> call to only read 2 bytes then return to <code>epoll_wait</code> (manual code hack). Send &quot;LongString&quot;.</li>\n<li><strong>Failure</strong>: Client hangs; server never reads the rest of the string.</li>\n<li><strong>Fix</strong>: Re-enable the loop-until-EAGAIN.</li>\n<li><strong>Success Criteria</strong>: Server reads the entire string in one event trigger.</li>\n</ul>\n<h3 id=\"3-thundering-herd-burst-accept\">3. Thundering Herd / Burst Accept</h3>\n<ul>\n<li><strong>Input</strong>: Use <code>ab -n 100 -c 10 http://localhost:8080/</code> (even though not HTTP, the TCP handshake will trigger accepts).</li>\n<li><strong>Success Criteria</strong>: All 100 connections accepted; no <code>ECONNREFUSED</code>.</li>\n</ul>\n<h1 id=\"performance-targets\">PERFORMANCE TARGETS</h1>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Operation</th>\n<th align=\"left\">Target</th>\n<th align=\"left\">Measurement Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">Connection Latency</td>\n<td align=\"left\">&lt; 500Î¼s</td>\n<td align=\"left\"><code>ping</code> local port vs <code>ping</code> loopback overhead</td>\n</tr>\n<tr>\n<td align=\"left\">Syscall Ratio</td>\n<td align=\"left\">1:1 <code>epoll_wait</code> to Read (LT)</td>\n<td align=\"left\"><code>strace -c</code></td>\n</tr>\n<tr>\n<td align=\"left\">Throughput</td>\n<td align=\"left\">100k+ ops/sec</td>\n<td align=\"left\"><code>tcp-echo-bench</code> or custom script</td>\n</tr>\n<tr>\n<td align=\"left\">Memory Footprint</td>\n<td align=\"left\">~45MB RSS (10k conns)</td>\n<td align=\"left\"><code>ps -o rss</code></td>\n</tr>\n</tbody></table>\n<h1 id=\"concurrency-specification\">CONCURRENCY SPECIFICATION</h1>\n<ul>\n<li><strong>Model</strong>: Single-threaded Reactor.</li>\n<li><strong>Thread Safety</strong>: None required.</li>\n<li><strong>Re-entrancy</strong>: The <code>conn_close</code> function must be re-entrant safe (or idempotent) in case multiple events (e.g., <code>EPOLLIN</code> and <code>EPOLLHUP</code>) trigger in the same batch for the same FD.</li>\n</ul>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/* Pseudocode for the ET read loop */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> handle_read_et</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    conn_state_t</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\">state </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#FFAB70\">global_connections</span><span style=\"color:#E1E4E8\">[fd];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    while</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        ssize_t</span><span style=\"color:#E1E4E8\"> n </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> read</span><span style=\"color:#E1E4E8\">(fd, state->read_buf, </span><span style=\"color:#79B8FF\">4096</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (n </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EAGAIN </span><span style=\"color:#F97583\">||</span><span style=\"color:#E1E4E8\"> errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EWOULDBLOCK) </span><span style=\"color:#F97583\">break</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\"> // Drained</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            conn_close</span><span style=\"color:#E1E4E8\">(epoll_fd, fd); </span><span style=\"color:#F97583\">break</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\"> // Error</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (n </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) { </span><span style=\"color:#B392F0\">conn_close</span><span style=\"color:#E1E4E8\">(epoll_fd, fd); </span><span style=\"color:#F97583\">break</span><span style=\"color:#E1E4E8\">; }</span><span style=\"color:#6A737D\"> // EOF</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        write</span><span style=\"color:#E1E4E8\">(fd, state->read_buf, n);</span><span style=\"color:#6A737D\"> // Echo</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<!-- END_TDD_MOD -->\n\n\n<!-- TDD_MOD_ID: build-event-loop-m2 -->\n<h1 id=\"module-charter-write-buffering-and-timer-management\">MODULE CHARTER: Write Buffering and Timer Management</h1>\n<p>This module extends the basic <code>epoll</code> event loop from Milestone 1 to handle two critical real-world constraints: asynchronous write backpressure and connection lifecycle management. In high-concurrency environments, a <code>write()</code> call may return <code>EAGAIN</code> if the kernel&#39;s socket send buffer is full; this module implements a per-connection dynamic write queue and manages the <code>EPOLLOUT</code> lifecycle to flush data only when the socket becomes writable, preventing both data loss and CPU-spinning busy loops. Additionally, it integrates a high-performance min-heap timer system to reap idle connections, utilizing the <code>epoll_wait</code> timeout parameter to create a precision tick-less event loop. This module does not yet abstract the reactor API but provides the internal logic necessary for the protocol-aware server in M4.</p>\n<h1 id=\"file-structure\">FILE STRUCTURE</h1>\n<ol>\n<li><code>write_buffer.h</code>: Definitions for the dynamic write queue.</li>\n<li><code>write_buffer.c</code>: Implementation of append, consume, and compaction logic.</li>\n<li><code>timer_heap.h</code>: Min-heap structures and priority queue logic.</li>\n<li><code>timer_heap.c</code>: Heap sift-up/down, insertion, and cancellation.</li>\n<li><code>reactor_core.h</code>: Updated <code>conn_state_t</code> and global context.</li>\n<li><code>main.c</code>: Updated event loop with write-flush logic and timer integration.</li>\n<li><code>Makefile</code>: Build script with updated object dependencies.</li>\n</ol>\n<h1 id=\"complete-data-model\">COMPLETE DATA MODEL</h1>\n<h3 id=\"write_buf_t-per-connection-output-queue\"><code>write_buf_t</code> (Per-Connection Output Queue)</h3>\n<p>Located within each <code>conn_state_t</code>. Manages bytes that cannot be sent immediately.</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Field</th>\n<th align=\"left\">Type</th>\n<th align=\"left\">Offset</th>\n<th align=\"left\">Size</th>\n<th align=\"left\">Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\"><code>data</code></td>\n<td align=\"left\"><code>char*</code></td>\n<td align=\"left\">0x00</td>\n<td align=\"left\">8</td>\n<td align=\"left\">Heap-allocated buffer for unsent bytes.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>len</code></td>\n<td align=\"left\"><code>uint32_t</code></td>\n<td align=\"left\">0x08</td>\n<td align=\"left\">4</td>\n<td align=\"left\">Current number of buffered bytes.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>cap</code></td>\n<td align=\"left\"><code>uint32_t</code></td>\n<td align=\"left\">0x0C</td>\n<td align=\"left\">4</td>\n<td align=\"left\">Total allocated capacity of <code>data</code>.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>offset</code></td>\n<td align=\"left\"><code>uint32_t</code></td>\n<td align=\"left\">0x10</td>\n<td align=\"left\">4</td>\n<td align=\"left\">Index of the first unsent byte (drain point).</td>\n</tr>\n<tr>\n<td align=\"left\"><code>padding</code></td>\n<td align=\"left\"><code>uint8_t[4]</code></td>\n<td align=\"left\">0x14</td>\n<td align=\"left\">4</td>\n<td align=\"left\">Padding for 8-byte alignment of the next struct.</td>\n</tr>\n<tr>\n<td align=\"left\"><strong>Total</strong></td>\n<td align=\"left\"></td>\n<td align=\"left\"></td>\n<td align=\"left\"><strong>24 bytes</strong></td>\n<td align=\"left\"></td>\n</tr>\n</tbody></table>\n<h3 id=\"timer_entry_t-heap-node\"><code>timer_entry_t</code> (Heap Node)</h3>\n<p>Represents a scheduled timeout.</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Field</th>\n<th align=\"left\">Type</th>\n<th align=\"left\">Offset</th>\n<th align=\"left\">Size</th>\n<th align=\"left\">Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\"><code>expiry_ms</code></td>\n<td align=\"left\"><code>uint64_t</code></td>\n<td align=\"left\">0x00</td>\n<td align=\"left\">8</td>\n<td align=\"left\">Absolute monotonic time (ms) when timer fires.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>fd</code></td>\n<td align=\"left\"><code>int</code></td>\n<td align=\"left\">0x08</td>\n<td align=\"left\">4</td>\n<td align=\"left\">The FD associated with this timer.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>padding</code></td>\n<td align=\"left\"><code>uint8_t[4]</code></td>\n<td align=\"left\">0x0C</td>\n<td align=\"left\">4</td>\n<td align=\"left\">Alignment.</td>\n</tr>\n<tr>\n<td align=\"left\"><strong>Total</strong></td>\n<td align=\"left\"></td>\n<td align=\"left\"></td>\n<td align=\"left\"><strong>16 bytes</strong></td>\n<td align=\"left\"></td>\n</tr>\n</tbody></table>\n<h3 id=\"conn_state_t-updated\"><code>conn_state_t</code> (Updated)</h3>\n<p>The per-connection state is expanded to track write interest and timer positions.</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Field</th>\n<th align=\"left\">Type</th>\n<th align=\"left\">Offset</th>\n<th align=\"left\">Size</th>\n<th align=\"left\">Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\"><code>read_buf</code></td>\n<td align=\"left\"><code>char[4096]</code></td>\n<td align=\"left\">0x0000</td>\n<td align=\"left\">4096</td>\n<td align=\"left\">Milestone 1 Read Buffer.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>wbuf</code></td>\n<td align=\"left\"><code>write_buf_t</code></td>\n<td align=\"left\">0x1000</td>\n<td align=\"left\">24</td>\n<td align=\"left\">The write queue defined above.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>read_len</code></td>\n<td align=\"left\"><code>uint32_t</code></td>\n<td align=\"left\">0x1018</td>\n<td align=\"left\">4</td>\n<td align=\"left\">Current read count.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>fd</code></td>\n<td align=\"left\"><code>int</code></td>\n<td align=\"left\">0x101C</td>\n<td align=\"left\">4</td>\n<td align=\"left\">File descriptor.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>epollout_armed</code></td>\n<td align=\"left\"><code>bool</code></td>\n<td align=\"left\">0x1020</td>\n<td align=\"left\">1</td>\n<td align=\"left\">Guard: is <code>EPOLLOUT</code> registered in the kernel?</td>\n</tr>\n<tr>\n<td align=\"left\"><code>is_active</code></td>\n<td align=\"left\"><code>bool</code></td>\n<td align=\"left\">0x1021</td>\n<td align=\"left\">1</td>\n<td align=\"left\">Liveness flag.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>timer_idx</code></td>\n<td align=\"left\"><code>int</code></td>\n<td align=\"left\">0x1024</td>\n<td align=\"left\">4</td>\n<td align=\"left\">Current index in <code>timer_heap[]</code> (for O(1) cancel).</td>\n</tr>\n<tr>\n<td align=\"left\"><code>timer_expiry</code></td>\n<td align=\"left\"><code>uint64_t</code></td>\n<td align=\"left\">0x1028</td>\n<td align=\"left\">8</td>\n<td align=\"left\">Absolute expiry time.</td>\n</tr>\n<tr>\n<td align=\"left\"><strong>Total</strong></td>\n<td align=\"left\"></td>\n<td align=\"left\"></td>\n<td align=\"left\"><strong>~4152 bytes</strong></td>\n<td align=\"left\"></td>\n</tr>\n</tbody></table>\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Ftdd-diag-8.svg\" alt=\"write_buf Struct: Byte-Level Memory Layout and Compaction Mechanics\"></p>\n<h1 id=\"interface-contracts\">INTERFACE CONTRACTS</h1>\n<h3 id=\"1-int-wbuf_appendwrite_buf_t-wb-const-char-src-uint32_t-n\">1. <code>int wbuf_append(write_buf_t *wb, const char *src, uint32_t n)</code></h3>\n<ul>\n<li><strong>Invariants</strong>: <code>wb-&gt;len + n</code> must not exceed <code>WRITE_BUF_MAX</code> (256KB).</li>\n<li><strong>Behavior</strong>: If <code>wb-&gt;offset</code> is large (e.g., &gt; <code>cap/2</code>), perform <code>memmove</code> to compact data to the front. If <code>cap</code> is insufficient, double <code>cap</code> via <code>realloc</code>.</li>\n<li><strong>Errors</strong>: Return <code>-1</code> on OOM or buffer overflow (indicates slow client).</li>\n</ul>\n<h3 id=\"2-int-conn_writeint-epoll_fd-int-fd-const-char-src-uint32_t-n\">2. <code>int conn_write(int epoll_fd, int fd, const char *src, uint32_t n)</code></h3>\n<ul>\n<li><strong>Constraints</strong>: Must attempt a direct <code>write()</code> first if <code>wbuf</code> is empty.</li>\n<li><strong>Backpressure</strong>: If <code>write()</code> returns <code>EAGAIN</code>, call <code>wbuf_append()</code> and use <code>epoll_ctl(MOD)</code> to add <code>EPOLLOUT</code>.</li>\n<li><strong>State Management</strong>: Update <code>epollout_armed</code> to <code>true</code>.</li>\n</ul>\n<h3 id=\"3-int-conn_flushint-epoll_fd-int-fd\">3. <code>int conn_flush(int epoll_fd, int fd)</code></h3>\n<ul>\n<li><strong>Constraints</strong>: Triggered by <code>EPOLLOUT</code>.</li>\n<li><strong>Behavior</strong>: Write as much of <code>wbuf</code> as possible. Update <code>wb-&gt;offset</code> and <code>wb-&gt;len</code>.</li>\n<li><strong>Termination</strong>: If <code>wbuf</code> becomes empty, use <code>epoll_ctl(MOD)</code> to remove <code>EPOLLOUT</code>. Update <code>epollout_armed</code> to <code>false</code>.</li>\n</ul>\n<h3 id=\"4-void-timer_setint-fd-uint64_t-ms_from_now\">4. <code>void timer_set(int fd, uint64_t ms_from_now)</code></h3>\n<ul>\n<li><strong>Logic</strong>: If <code>conn-&gt;timer_idx != -1</code>, update existing node and sift. Otherwise, append to heap and <code>sift_up</code>.</li>\n<li><strong>Complexity</strong>: $O(\\log N)$.</li>\n</ul>\n<h3 id=\"5-int-timer_next_ms\">5. <code>int timer_next_ms()</code></h3>\n<ul>\n<li><strong>Logic</strong>: Peek <code>timer_heap[0]</code>. Calculate <code>expiry - now()</code>.</li>\n<li><strong>Returns</strong>: Milliseconds for <code>epoll_wait</code> timeout, or <code>-1</code> if heap empty.</li>\n</ul>\n<h1 id=\"algorithm-specification\">ALGORITHM SPECIFICATION</h1>\n<h3 id=\"write-buffer-compaction-and-growth\">Write Buffer Compaction and Growth</h3>\n<p>To maintain $O(1)$ amortized performance and avoid memory fragmentation:</p>\n<ol>\n<li><strong>Compaction</strong>: When <code>wbuf-&gt;offset &gt; wbuf-&gt;cap / 2</code>, move <code>wbuf-&gt;data + wbuf-&gt;offset</code> to <code>wbuf-&gt;data</code> using <code>memmove</code>. Reset <code>offset = 0</code>. This prevents the &quot;creeping offset&quot; that leads to unnecessary allocations.</li>\n<li><strong>Growth</strong>: If <code>n &gt; free_space</code>, <code>new_cap = max(cap * 2, len + n)</code>. Caps at <code>WRITE_BUF_MAX</code>.</li>\n</ol>\n<h3 id=\"min-heap-sift-down-deletionupdate\">Min-Heap Sift-Down (Deletion/Update)</h3>\n<p>Used when the root timer expires or an arbitrary timer is cancelled via <code>timer_idx</code>.</p>\n<ol>\n<li>Replace the target node with the last node in the heap.</li>\n<li>Update the <code>timer_idx</code> in the <code>conn_state_t</code> of the moved node.</li>\n<li>Compare the moved node with its children.</li>\n<li>If larger than the smallest child, swap and repeat.</li>\n<li>If smaller than the parent (relevant for arbitrary cancel), call <code>sift_up</code>.</li>\n</ol>\n<p>{{DIAGRAM:tdd-diag-9}}</p>\n<h1 id=\"error-handling-matrix\">ERROR HANDLING MATRIX</h1>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Error</th>\n<th align=\"left\">Detected By</th>\n<th align=\"left\">Recovery Action</th>\n<th align=\"left\">User-Visible?</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\"><code>WRITE_BUF_MAX</code> Hit</td>\n<td align=\"left\"><code>wbuf_append</code></td>\n<td align=\"left\">Close connection immediately (slow loris defense).</td>\n<td align=\"left\">No</td>\n</tr>\n<tr>\n<td align=\"left\"><code>realloc</code> Fail</td>\n<td align=\"left\"><code>wbuf_append</code></td>\n<td align=\"left\">Close connection (OOM handling).</td>\n<td align=\"left\">No</td>\n</tr>\n<tr>\n<td align=\"left\"><code>EPOLLOUT</code> spin</td>\n<td align=\"left\"><code>epoll_wait</code></td>\n<td align=\"left\">If <code>wbuf_is_empty</code> but <code>EPOLLOUT</code> fires, disarm immediately.</td>\n<td align=\"left\">No</td>\n</tr>\n<tr>\n<td align=\"left\">Backward Clock</td>\n<td align=\"left\"><code>now_ms</code></td>\n<td align=\"left\">Use <code>CLOCK_MONOTONIC</code> to ensure time never flows backward.</td>\n<td align=\"left\">No</td>\n</tr>\n<tr>\n<td align=\"left\">Heap Overflow</td>\n<td align=\"left\"><code>timer_set</code></td>\n<td align=\"left\">Log error; close oldest connection to make room.</td>\n<td align=\"left\">No</td>\n</tr>\n</tbody></table>\n<h1 id=\"implementation-sequence\">IMPLEMENTATION SEQUENCE</h1>\n<h3 id=\"phase-1-the-byte-queue-2-hours\">Phase 1: The Byte Queue (2 Hours)</h3>\n<ul>\n<li>Implement <code>write_buf_t</code> lifecycle.</li>\n<li><strong>Compaction logic</strong>: Crucial to prevent <code>realloc</code> on every write.</li>\n<li><strong>Checkpoint</strong>: Unit test <code>wbuf_append</code> and <code>wbuf_consume</code> with a sequence of partial writes. Verify that <code>offset</code> resets and memory doesn&#39;t leak.</li>\n</ul>\n<h3 id=\"phase-2-epollout-lifecycle-2-hours\">Phase 2: EPOLLOUT Lifecycle (2 Hours)</h3>\n<ul>\n<li>Modify <code>handle_read</code> to use <code>conn_write</code>.</li>\n<li>Implement <code>conn_flush</code> to be called when <code>events[i].events &amp; EPOLLOUT</code>.</li>\n<li><strong>Crucial Invariant</strong>: <code>epoll_ctl(MOD)</code> must be called to <em>remove</em> <code>EPOLLOUT</code> when the queue is empty, or <code>epoll_wait</code> will return immediately in a tight loop.</li>\n<li><strong>Checkpoint</strong>: Run server with a simulated slow client (<code>trickle -d 1</code>). Verify CPU remains at 0% while the server is waiting for the client to drain its buffer.</li>\n</ul>\n<h3 id=\"phase-3-monotonic-timing-amp-heap-3-hours\">Phase 3: Monotonic Timing &amp; Heap (3 Hours)</h3>\n<ul>\n<li>Implement <code>now_ms()</code> using <code>clock_gettime(CLOCK_MONOTONIC, ...)</code>.</li>\n<li>Implement binary min-heap: <code>sift_up</code>, <code>sift_down</code>.</li>\n<li><strong>FD Mapping</strong>: Ensure <code>timer_heap[i].fd</code> allows you to update <code>connections[fd].timer_idx</code>.</li>\n<li><strong>Checkpoint</strong>: Insert 1000 random timers. Extract them one by one. Verify they are returned in strictly increasing chronological order.</li>\n</ul>\n<h3 id=\"phase-4-integrated-event-loop-2-hours\">Phase 4: Integrated Event Loop (2 Hours)</h3>\n<ul>\n<li>Calculate <code>epoll_wait</code> timeout using <code>timer_next_ms()</code>.</li>\n<li>Call <code>timer_process_expired()</code> after <code>epoll_wait</code> returns.</li>\n<li><strong>Re-entrancy</strong>: If a timer expires and closes an FD, ensure subsequent I/O events for that FD in the same <code>epoll_wait</code> batch are ignored.</li>\n<li><strong>Checkpoint</strong>: Set <code>IDLE_TIMEOUT</code> to 5s. Connect with <code>nc</code>. Wait 6s. Verify server closes the connection automatically.</li>\n</ul>\n<h1 id=\"test-specification\">TEST SPECIFICATION</h1>\n<h3 id=\"1-the-slow-reader-test-backpressure\">1. The Slow Reader Test (Backpressure)</h3>\n<ul>\n<li><strong>Setup</strong>: Start server. Use a python script to connect, send a request, but <code>recv()</code> only 1 byte per second.</li>\n<li><strong>Execution</strong>: Server should eventually trigger <code>EAGAIN</code> on <code>write()</code>, arm <code>EPOLLOUT</code>, and buffer bytes.</li>\n<li><strong>Success</strong>: Server memory stays bounded by <code>WRITE_BUF_MAX</code>. Connection is closed if buffer exceeds limit.</li>\n</ul>\n<h3 id=\"2-the-busy-loop-test-deregistration\">2. The Busy Loop Test (Deregistration)</h3>\n<ul>\n<li><strong>Setup</strong>: High-speed client sending many requests.</li>\n<li><strong>Execution</strong>: Monitor CPU usage with <code>top</code>.</li>\n<li><strong>Success</strong>: CPU usage drops to 0.0% when all responses are sent, even if connections remain open.</li>\n</ul>\n<h3 id=\"3-timer-stress-test\">3. Timer Stress Test</h3>\n<ul>\n<li><strong>Setup</strong>: 10,000 connections. Set random idle timeouts between 1s and 10s.</li>\n<li><strong>Success</strong>: Connections are closed precisely at their expiry times (+/- 10ms jitter). Heap property remains valid throughout.</li>\n</ul>\n<h1 id=\"performance-targets\">PERFORMANCE TARGETS</h1>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Operation</th>\n<th align=\"left\">Target</th>\n<th align=\"left\">Measurement Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">Timer Insert</td>\n<td align=\"left\">&lt; 1Î¼s</td>\n<td align=\"left\">Micro-benchmark 10k inserts</td>\n</tr>\n<tr>\n<td align=\"left\">Syscall Overhead</td>\n<td align=\"left\">0 <code>epoll_ctl</code> calls if buffer not full</td>\n<td align=\"left\"><code>strace -e epoll_ctl</code></td>\n</tr>\n<tr>\n<td align=\"left\">Memory Overhead</td>\n<td align=\"left\">&lt; 1MB for Timer Heap (64k nodes)</td>\n<td align=\"left\"><code>sizeof(timer_entry_t) * 65536</code></td>\n</tr>\n<tr>\n<td align=\"left\">Clock Resolution</td>\n<td align=\"left\">1ms</td>\n<td align=\"left\"><code>epoll_wait</code> timeout granularity</td>\n</tr>\n</tbody></table>\n<h1 id=\"soul-section-hardware-amp-kernel-interactions\">SOUL SECTION: HARDWARE &amp; KERNEL INTERACTIONS</h1>\n<h3 id=\"1-vdso-and-clock_gettime\">1. vDSO and <code>clock_gettime</code></h3>\n<p>We use <code>CLOCK_MONOTONIC</code>. On modern Linux, this syscall is mapped into the process address space via <strong>vDSO (virtual Dynamic Shared Object)</strong>. This allows the process to read the hardware TSC (Time Stamp Counter) directly without a full context switch to the kernel. This reduces <code>now_ms()</code> cost from ~200ns to ~30ns.</p>\n<h3 id=\"2-cache-line-alignment-of-heap-nodes\">2. Cache Line Alignment of Heap Nodes</h3>\n<p>The <code>timer_entry_t</code> is 16 bytes. A standard 64-byte cache line holds exactly 4 nodes. </p>\n<ul>\n<li>During <code>sift_up</code>, we access parent nodes at index <code>(i-1)/2</code>.</li>\n<li>Because the heap is a complete binary tree, the top 3 levels (indices 0-6) fit in <strong>two cache lines</strong>. </li>\n<li>This ensures that for almost every timer operation, the &quot;hot&quot; part of the priority queue is already in the L1/L2 cache.</li>\n</ul>\n<h3 id=\"3-write-buffer-compaction-vs-page-faults\">3. Write Buffer Compaction vs. Page Faults</h3>\n<p>We use <code>memmove</code> for compaction. For small <code>len</code>, this is a pure L1/L2 cache operation. However, we avoid <code>realloc</code> as much as possible because <code>realloc</code> might trigger the <code>mmap</code> syscall for large buffers, leading to page faults and TLB shootdowns across the CPU cores. The doubling strategy ensures we only pay the &quot;allocation tax&quot; $O(\\log N)$ times.</p>\n<h3 id=\"4-tcp-send-buffer-vs-epollout\">4. TCP Send Buffer vs. <code>EPOLLOUT</code></h3>\n<p>The kernel&#39;s <code>SO_SNDBUF</code> determines when <code>write()</code> returns <code>EAGAIN</code>. By default, this is tuned by the kernel (see <code>tcp_wmem</code>). When our <code>conn_flush</code> runs, the kernel initiates a DMA transfer from the kernel buffer to the NIC. Only after the NIC signals completion (or the TCP window opens) does the kernel free space and trigger <code>EPOLLOUT</code>. Our server effectively &quot;waits on the NIC&quot; without blocking the CPU.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/* Implementation Detail: The Timer Heap Swap */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> heap_swap</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> i</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> j</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    timer_entry_t</span><span style=\"color:#E1E4E8\"> tmp </span><span style=\"color:#F97583\">=</span><span style=\"color:#FFAB70\"> timer_heap</span><span style=\"color:#E1E4E8\">[i];</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    timer_heap</span><span style=\"color:#E1E4E8\">[i] </span><span style=\"color:#F97583\">=</span><span style=\"color:#FFAB70\"> timer_heap</span><span style=\"color:#E1E4E8\">[j];</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    timer_heap</span><span style=\"color:#E1E4E8\">[j] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> tmp;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    /* MANDATORY: Keep the FD -> Heap Index map in sync */</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    connections</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#FFAB70\">timer_heap</span><span style=\"color:#E1E4E8\">[i].fd].timer_idx </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> i;</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    connections</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#FFAB70\">timer_heap</span><span style=\"color:#E1E4E8\">[j].fd].timer_idx </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> j;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/* Implementation Detail: Write Backpressure Logic */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\"> conn_write</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> epoll_fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">data</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#FFAB70\"> n</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    conn_state_t</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\">c </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#FFAB70\">connections</span><span style=\"color:#E1E4E8\">[fd];</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 1. If buffer already has data, we must append to maintain order</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (c->wbuf.len </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#B392F0\"> wbuf_append</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">c->wbuf, data, n);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 2. Fast path: try to send directly</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    ssize_t</span><span style=\"color:#E1E4E8\"> sent </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> write</span><span style=\"color:#E1E4E8\">(fd, data, n);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (sent </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EAGAIN </span><span style=\"color:#F97583\">||</span><span style=\"color:#E1E4E8\"> errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EWOULDBLOCK) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            sent </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\"> // Prepare to buffer all</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        } </span><span style=\"color:#F97583\">else</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\"> // Real error</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 3. Buffer remaining</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> ((</span><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#E1E4E8\">)sent </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> n) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        wbuf_append</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">c->wbuf, data </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> sent, n </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> sent);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // 4. Arm EPOLLOUT if not already armed</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">c->epollout_armed) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            struct</span><span style=\"color:#E1E4E8\"> epoll_event ev;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            ev.events </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> EPOLLIN </span><span style=\"color:#F97583\">|</span><span style=\"color:#E1E4E8\"> EPOLLOUT </span><span style=\"color:#F97583\">|</span><span style=\"color:#E1E4E8\"> EPOLLET;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            ev.data.fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> fd;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            epoll_ctl</span><span style=\"color:#E1E4E8\">(epoll_fd, EPOLL_CTL_MOD, fd, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">ev);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            c->epollout_armed </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<!-- END_TDD_MOD -->\n\n\n<!-- TDD_MOD_ID: build-event-loop-m3 -->\n<h1 id=\"module-charter-reactor-api-and-callback-dispatch\">MODULE CHARTER: Reactor API and Callback Dispatch</h1>\n<p>This module decouples application logic from the underlying Linux <code>epoll</code> primitives by implementing the Reactor Pattern. It provides a clean, callback-based interface for I/O multiplexing, timer management, and deferred task execution. A primary objective is the elimination of &quot;use-after-free&quot; and &quot;file descriptor reuse&quot; bugs through a <strong>zombie flag</strong> mechanism and a <strong>deferred modification queue</strong>, ensuring that modifying the interest set during event dispatch does not corrupt the active event batch. This module does NOT implement any high-level protocols (like HTTP or Redis RESP); it serves as a pure infrastructure layer. Invariants include: (1) no direct <code>epoll_ctl</code> calls during dispatch, (2) guaranteed execution of deferred tasks after all I/O events in a tick, and (3) O(1) handler lookup via a fixed-size registration table.</p>\n<h1 id=\"file-structure\">FILE STRUCTURE</h1>\n<p>The implementation follows a strict separation between public API and internal implementation details.</p>\n<ol>\n<li><code>reactor.h</code>: Public interface definitions, constants, and function signatures.</li>\n<li><code>reactor_internal.h</code>: Internal structure definitions (opaque to users), heap logic, and queue types.</li>\n<li><code>reactor.c</code>: Core implementation of the dispatch loop and event management.</li>\n<li><code>Makefile</code>: Build instructions ensuring <code>-fPIC</code> (if building as library) and <code>-O2</code>.</li>\n</ol>\n<h1 id=\"complete-data-model\">COMPLETE DATA MODEL</h1>\n<h3 id=\"1-reactor_t-the-engine\">1. <code>reactor_t</code> (The Engine)</h3>\n<p>Hidden from the user via an opaque pointer. It encapsulates the kernel state and the user-space dispatch metadata.</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Field</th>\n<th align=\"left\">Type</th>\n<th align=\"left\">Offset</th>\n<th align=\"left\">Size</th>\n<th align=\"left\">Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\"><code>epoll_fd</code></td>\n<td align=\"left\"><code>int</code></td>\n<td align=\"left\">0x00</td>\n<td align=\"left\">4</td>\n<td align=\"left\">The kernel epoll instance.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>is_running</code></td>\n<td align=\"left\"><code>bool</code></td>\n<td align=\"left\">0x04</td>\n<td align=\"left\">1</td>\n<td align=\"left\">Controls the main loop execution.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>is_dispatching</code></td>\n<td align=\"left\"><code>bool</code></td>\n<td align=\"left\">0x05</td>\n<td align=\"left\">1</td>\n<td align=\"left\">Mutex-equivalent: true while iterating <code>epoll_wait</code> results.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>padding</code></td>\n<td align=\"left\"><code>uint8_t[2]</code></td>\n<td align=\"left\">0x06</td>\n<td align=\"left\">2</td>\n<td align=\"left\">Align subsequent pointer to 8 bytes.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>handlers</code></td>\n<td align=\"left\"><code>fd_handler_t*</code></td>\n<td align=\"left\">0x08</td>\n<td align=\"left\">8</td>\n<td align=\"left\">Array of 65,536 handlers (1.5 MB total).</td>\n</tr>\n<tr>\n<td align=\"left\"><code>timer_heap</code></td>\n<td align=\"left\"><code>timer_node_t*</code></td>\n<td align=\"left\">0x10</td>\n<td align=\"left\">8</td>\n<td align=\"left\">Min-heap array for scheduled timeouts.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>mod_queue</code></td>\n<td align=\"left\"><code>deferred_mod_t*</code></td>\n<td align=\"left\">0x18</td>\n<td align=\"left\">8</td>\n<td align=\"left\">Queue for <code>epoll_ctl</code> ops generated during dispatch.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>task_queue</code></td>\n<td align=\"left\"><code>deferred_task_t*</code></td>\n<td align=\"left\">0x20</td>\n<td align=\"left\">8</td>\n<td align=\"left\">Post-dispatch callback queue.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>timer_count</code></td>\n<td align=\"left\"><code>uint32_t</code></td>\n<td align=\"left\">0x28</td>\n<td align=\"left\">4</td>\n<td align=\"left\">Current number of active timers.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>mod_count</code></td>\n<td align=\"left\"><code>uint32_t</code></td>\n<td align=\"left\">0x2C</td>\n<td align=\"left\">4</td>\n<td align=\"left\">Current size of <code>mod_queue</code>.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>task_count</code></td>\n<td align=\"left\"><code>uint32_t</code></td>\n<td align=\"left\">0x30</td>\n<td align=\"left\">4</td>\n<td align=\"left\">Current size of <code>task_queue</code>.</td>\n</tr>\n</tbody></table>\n<h3 id=\"2-fd_handler_t-registration-metadata\">2. <code>fd_handler_t</code> (Registration Metadata)</h3>\n<p>Each entry in the <code>handlers</code> array tracks the application&#39;s intent for a specific file descriptor.</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Field</th>\n<th align=\"left\">Type</th>\n<th align=\"left\">Offset</th>\n<th align=\"left\">Size</th>\n<th align=\"left\">Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\"><code>callback</code></td>\n<td align=\"left\"><code>io_cb_fn</code></td>\n<td align=\"left\">0x00</td>\n<td align=\"left\">8</td>\n<td align=\"left\">Function pointer to execute on event.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>user_data</code></td>\n<td align=\"left\"><code>void*</code></td>\n<td align=\"left\">0x08</td>\n<td align=\"left\">8</td>\n<td align=\"left\">Opaque context passed to the callback.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>events</code></td>\n<td align=\"left\"><code>uint32_t</code></td>\n<td align=\"left\">0x10</td>\n<td align=\"left\">4</td>\n<td align=\"left\">Bitmask of <code>REACTOR_READABLE</code>, etc.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>is_registered</code></td>\n<td align=\"left\"><code>bool</code></td>\n<td align=\"left\">0x14</td>\n<td align=\"left\">1</td>\n<td align=\"left\">Is this FD currently in the epoll set?</td>\n</tr>\n<tr>\n<td align=\"left\"><code>is_zombie</code></td>\n<td align=\"left\"><code>bool</code></td>\n<td align=\"left\">0x15</td>\n<td align=\"left\">1</td>\n<td align=\"left\">Marked for deletion during current dispatch?</td>\n</tr>\n<tr>\n<td align=\"left\"><code>padding</code></td>\n<td align=\"left\"><code>uint8_t[2]</code></td>\n<td align=\"left\">0x16</td>\n<td align=\"left\">2</td>\n<td align=\"left\">Padding to 24-byte struct size.</td>\n</tr>\n</tbody></table>\n<p><strong>Memory &amp; Cache Analysis:</strong>\nThe <code>handlers</code> array is $65,536 \\times 24 \\text{ bytes} \\approx 1.5 \\text{ MB}$. In high-concurrency scenarios, the &quot;working set&quot; of active handlers fits into the L3 cache. Using <code>epoll_event.data.ptr</code> to point directly to these structs eliminates an array-index multiplication per event.</p>\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Ftdd-diag-17.svg\" alt=\"Reactor Module Architecture: All Structs, Typedefs, and Public API Functions\"></p>\n<h1 id=\"interface-contracts\">INTERFACE CONTRACTS</h1>\n<h3 id=\"1-int-reactor_registerreactor_t-r-int-fd-uint32_t-events-io_cb_fn-cb-void-ud\">1. <code>int reactor_register(reactor_t *r, int fd, uint32_t events, io_cb_fn cb, void *ud)</code></h3>\n<ul>\n<li><strong>Input</strong>: <code>events</code> as a bitmask (e.g., <code>REACTOR_READABLE | REACTOR_WRITABLE</code>).</li>\n<li><strong>Safety</strong>: If <code>r-&gt;is_dispatching</code> is true, it MUST NOT call <code>epoll_ctl</code> immediately. It must append to <code>r-&gt;mod_queue</code>.</li>\n<li><strong>Logic</strong>: If <code>handlers[fd].is_registered</code> is true, perform <code>EPOLL_CTL_MOD</code>. Otherwise, <code>EPOLL_CTL_ADD</code>.</li>\n<li><strong>Return</strong>: 0 on success, -1 on invalid FD or registration failure.</li>\n</ul>\n<h3 id=\"2-void-reactor_deregisterreactor_t-r-int-fd\">2. <code>void reactor_deregister(reactor_t *r, int fd)</code></h3>\n<ul>\n<li><strong>Safety</strong>: If <code>r-&gt;is_dispatching</code> is true, set <code>handlers[fd].is_zombie = true</code> and append <code>MOD_DEL</code> to <code>r-&gt;mod_queue</code>.</li>\n<li><strong>Logic</strong>: Prevents subsequent events in the same batch from firing for a closed FD.</li>\n</ul>\n<h3 id=\"3-void-reactor_deferreactor_t-r-task_fn-fn-void-ud\">3. <code>void reactor_defer(reactor_t *r, task_fn fn, void *ud)</code></h3>\n<ul>\n<li><strong>Behavior</strong>: Appends to <code>r-&gt;task_queue</code>.</li>\n<li><strong>Execution</strong>: Guaranteed to run after the I/O dispatch loop finishes but before the next <code>epoll_wait</code>.</li>\n</ul>\n<h3 id=\"4-int-reactor_runreactor_t-r\">4. <code>int reactor_run(reactor_t *r)</code></h3>\n<ul>\n<li><strong>Behavior</strong>: Enters a <code>while(r-&gt;is_running)</code> loop.</li>\n<li><strong>Tick Order</strong>: <ol>\n<li>Calculate <code>epoll_wait</code> timeout from min-heap.</li>\n<li>Execute expired timers.</li>\n<li><code>epoll_wait</code> for I/O events.</li>\n<li>Set <code>is_dispatching = true</code>, iterate results, skip zombies.</li>\n<li>Set <code>is_dispatching = false</code>, process <code>mod_queue</code>.</li>\n<li>Process <code>task_queue</code> (snapshot current size to handle re-entrant defers).</li>\n</ol>\n</li>\n</ul>\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Ftdd-diag-18.svg\" alt=\"fd_handler Struct: Byte-Level Memory Layout and Registration Table Size\"></p>\n<h1 id=\"algorithm-specification\">ALGORITHM SPECIFICATION</h1>\n<h3 id=\"1-the-quotzombiequot-guard-event-skipping\">1. The &quot;Zombie&quot; Guard (Event Skipping)</h3>\n<p>During <code>epoll_wait</code>, the kernel returns $N$ events. If callback for event $i$ calls <code>reactor_deregister(fd_j)</code>, and event $k$ (where $k &gt; i$) also involves <code>fd_j</code>:</p>\n<ol>\n<li><code>reactor_deregister</code> sets <code>handlers[fd_j].is_zombie = true</code>.</li>\n<li>When the loop reaches index $k$, it checks <code>if (handlers[fd].is_zombie) continue;</code>.</li>\n<li>This prevents dispatching to an FD that was just closed/removed, avoiding the FD reuse race where <code>fd_j</code> might already be reassigned to a new connection.</li>\n</ol>\n<h3 id=\"2-drift-free-interval-timers\">2. Drift-Free Interval Timers</h3>\n<p>When an interval timer (repeating) fires:</p>\n<ol>\n<li><code>next_expiry = previous_expiry + interval_ms</code>.</li>\n<li>Do NOT use <code>now() + interval_ms</code>, as the time taken to execute the callback would cause the timer to &quot;drift&quot; forward with every tick.</li>\n<li>If <code>next_expiry &lt; now()</code> (due to extreme system lag), catch up by increments of <code>interval_ms</code>.</li>\n</ol>\n<h3 id=\"3-deferred-modification-application\">3. Deferred Modification Application</h3>\n<p>After <code>is_dispatching</code> is set to <code>false</code>:</p>\n<ol>\n<li>Iterate <code>r-&gt;mod_queue</code>.</li>\n<li>For <code>MOD_DEL</code>: <code>epoll_ctl(r-&gt;epoll_fd, EPOLL_CTL_DEL, mod-&gt;fd, NULL)</code>. Set <code>is_registered = false</code> and <code>is_zombie = false</code>.</li>\n<li>For <code>MOD_ADD/MOD</code>: Convert <code>REACTOR_*</code> flags to <code>EPOLL*</code> flags and call <code>epoll_ctl</code>.</li>\n</ol>\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Ftdd-diag-19.svg\" alt=\"Use-After-Free Scenario: fd Reuse Within One epoll_wait Batch\"></p>\n<h1 id=\"error-handling-matrix\">ERROR HANDLING MATRIX</h1>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Error</th>\n<th align=\"left\">Detected By</th>\n<th align=\"left\">Recovery Action</th>\n<th align=\"left\">User-Visible?</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\"><code>reactor_register</code> during dispatch</td>\n<td align=\"left\"><code>is_dispatching</code> check</td>\n<td align=\"left\">Queue to <code>mod_queue</code>. Always succeeds unless queue is full.</td>\n<td align=\"left\">No</td>\n</tr>\n<tr>\n<td align=\"left\"><code>epoll_ctl(MOD)</code> returns <code>ENOENT</code></td>\n<td align=\"left\"><code>reactor_apply_mod</code></td>\n<td align=\"left\">FD was likely removed out-of-band. Convert to <code>EPOLL_CTL_ADD</code> or log and ignore.</td>\n<td align=\"left\">No</td>\n</tr>\n<tr>\n<td align=\"left\"><code>realloc</code> failure for queues</td>\n<td align=\"left\"><code>enqueue_mod</code></td>\n<td align=\"left\">Hard fail: log &quot;OOM&quot; and abort server. Memory is critical for event safety.</td>\n<td align=\"left\">Yes (log)</td>\n</tr>\n<tr>\n<td align=\"left\"><code>EINTR</code> in <code>epoll_wait</code></td>\n<td align=\"left\"><code>reactor_run</code></td>\n<td align=\"left\"><code>continue</code> the loop immediately.</td>\n<td align=\"left\">No</td>\n</tr>\n<tr>\n<td align=\"left\"><code>EAGAIN</code> in <code>accept</code></td>\n<td align=\"left\">App callback</td>\n<td align=\"left\">Return to reactor. Reactor will notify on next connection.</td>\n<td align=\"left\">No</td>\n</tr>\n</tbody></table>\n<h1 id=\"implementation-sequence\">IMPLEMENTATION SEQUENCE</h1>\n<h3 id=\"phase-1-core-lifecycle-amp-registry-2-hours\">Phase 1: Core Lifecycle &amp; Registry (2 Hours)</h3>\n<ul>\n<li>Implement <code>reactor_create</code> / <code>reactor_destroy</code>.</li>\n<li>Implement <code>handlers[65536]</code> fixed-size array initialization.</li>\n<li>Implement <code>reactor_register</code> / <code>reactor_deregister</code> (outside-dispatch versions first).</li>\n<li><strong>Checkpoint</strong>: Test adding an FD to epoll, verifying <code>epoll_ctl</code> is called, and removing it.</li>\n</ul>\n<h3 id=\"phase-2-the-safe-dispatch-loop-3-hours\">Phase 2: The Safe Dispatch Loop (3 Hours)</h3>\n<ul>\n<li>Implement <code>reactor_run</code>.</li>\n<li>Use <code>events[i].data.ptr</code> to store <code>&amp;handlers[fd]</code>.</li>\n<li>Implement the <code>is_dispatching</code> flag.</li>\n<li>Add <code>is_zombie</code> checks and the <code>mod_queue</code>.</li>\n<li><strong>Checkpoint</strong>: Register two FDs. Inside FD1&#39;s callback, deregister FD2. Verify FD2&#39;s callback never fires even if data was available.</li>\n</ul>\n<h3 id=\"phase-3-post-dispatch-tasks-15-hours\">Phase 3: Post-Dispatch Tasks (1.5 Hours)</h3>\n<ul>\n<li>Implement <code>reactor_defer</code>.</li>\n<li>Implement the &quot;generation snapshot&quot; logic for <code>task_queue</code> to handle tasks that schedule further tasks.</li>\n<li><strong>Checkpoint</strong>: Defer a function from within an I/O callback. Verify it runs <em>after</em> the I/O loop finishes.</li>\n</ul>\n<h3 id=\"phase-4-integrated-timer-api-25-hours\">Phase 4: Integrated Timer API (2.5 Hours)</h3>\n<ul>\n<li>Wrap Milestone 2&#39;s heap logic into <code>reactor_set_timeout</code> and <code>reactor_set_interval</code>.</li>\n<li>Ensure <code>timer_process_timers</code> is called at the top of every reactor tick.</li>\n<li>Implement the drift-free interval re-arming.</li>\n<li><strong>Checkpoint</strong>: Set a 100ms interval timer. Verify it fires 10 times in 1000ms +/- jitter.</li>\n</ul>\n<h1 id=\"test-specification\">TEST SPECIFICATION</h1>\n<h3 id=\"1-re-entrancy-test-the-fd-reuse-race\">1. Re-entrancy Test (The FD Reuse Race)</h3>\n<ul>\n<li><strong>Scenario</strong>: Callback for FD 5 calls <code>reactor_deregister(5)</code> then <code>accept4()</code> which happens to return FD 5. It then calls <code>reactor_register(5, ..., new_cb, new_ud)</code>.</li>\n<li><strong>Happy Path</strong>: The new registration clears the zombie flag. The reactor should NOT fire the old callback for FD 5 if it was already in the ready list.</li>\n<li><strong>Failure</strong>: Old callback fires with new user data, causing a crash.</li>\n</ul>\n<h3 id=\"2-deferred-task-order\">2. Deferred Task Order</h3>\n<ul>\n<li><strong>Scenario</strong>: In a single tick, three events fire. Event 1 and 3 call <code>reactor_defer</code>.</li>\n<li><strong>Verification</strong>: Ensure both tasks run after Event 3, in the order they were deferred.</li>\n</ul>\n<h3 id=\"3-timer-cancellation-inside-io\">3. Timer Cancellation inside I/O</h3>\n<ul>\n<li><strong>Scenario</strong>: I/O callback for FD 10 receives a &quot;QUIT&quot; command and calls <code>reactor_cancel_timer</code> for its own idle timer.</li>\n<li><strong>Verification</strong>: Verify the heap is updated correctly and the timer never fires.</li>\n</ul>\n<h1 id=\"performance-targets\">PERFORMANCE TARGETS</h1>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Operation</th>\n<th align=\"left\">Target</th>\n<th align=\"left\">Measurement Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">Handler Dispatch</td>\n<td align=\"left\">&lt; 50ns</td>\n<td align=\"left\">CPU cycles from <code>epoll_wait</code> return to callback entry.</td>\n</tr>\n<tr>\n<td align=\"left\">Memory Overhead</td>\n<td align=\"left\">1.5MB fixed</td>\n<td align=\"left\"><code>sizeof(fd_handler_t) * 65536</code></td>\n</tr>\n<tr>\n<td align=\"left\">Queue Allocation</td>\n<td align=\"left\">0 on steady state</td>\n<td align=\"left\">Use fixed-capacity queues with growth only on bursts.</td>\n</tr>\n<tr>\n<td align=\"left\">Loop Jitter</td>\n<td align=\"left\">&lt; 1ms</td>\n<td align=\"left\">Latency between timer expiry and callback firing.</td>\n</tr>\n</tbody></table>\n<h1 id=\"soul-section-hardware-soul\">SOUL SECTION: HARDWARE SOUL</h1>\n<h3 id=\"1-pointer-dispatch-vs-integer-lookup\">1. Pointer Dispatch vs. Integer Lookup</h3>\n<p>We store <code>data.ptr = &amp;handlers[fd]</code> in the <code>epoll_event</code>. </p>\n<ul>\n<li><strong>The Hardware View</strong>: When the kernel returns events, the CPU reads the <code>data.ptr</code> memory address. Since this address points directly to the <code>fd_handler_t</code> struct, we avoid the <code>shl</code> (shift left) and <code>add</code> instructions required to calculate <code>base_address + (index * 24)</code>. </li>\n<li><strong>Cycles Saved</strong>: ~3-5 cycles per event. At 1,000,000 events/sec, this saves ~5 million cycles/sec, keeping the L1 cache pipeline tighter.</li>\n</ul>\n<h3 id=\"2-the-zombie-branch\">2. The Zombie Branch</h3>\n<p><code>if (h-&gt;is_zombie) continue;</code></p>\n<ul>\n<li><strong>Branch Prediction</strong>: 99.9% of the time, this is false. The CPU&#39;s <strong>Branch Target Buffer (BTB)</strong> will mark this as &quot;not taken.&quot; The check becomes effectively free (0 cycles) as the CPU speculatively executes the callback invocation.</li>\n<li><strong>Cache Locality</strong>: Since we just fetched the handler via <code>data.ptr</code>, the <code>is_zombie</code> byte is already in the L1d cache.</li>\n</ul>\n<h3 id=\"3-tick-less-efficiency\">3. Tick-less Efficiency</h3>\n<p>By calculating <code>timeout = next_timer - now</code>, the reactor is <strong>tick-less</strong>. </p>\n<ul>\n<li><strong>Power Consumption</strong>: The CPU stays in a deep sleep state (C-state) via the kernel <code>HLT</code> instruction until the exact millisecond a timer or I/O arrives. </li>\n<li><strong>Context Switches</strong>: Zero unnecessary wakeups. The system only context switches when work is actually pending.</li>\n</ul>\n<h1 id=\"state-machine-reactor-lifecycle\">STATE MACHINE: REACTOR LIFECYCLE</h1>\n<table>\n<thead>\n<tr>\n<th align=\"left\">State</th>\n<th align=\"left\">Transition Event</th>\n<th align=\"left\">Allowed Actions</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\"><strong>INIT</strong></td>\n<td align=\"left\"><code>reactor_create()</code></td>\n<td align=\"left\">Register fds, set timers.</td>\n</tr>\n<tr>\n<td align=\"left\"><strong>POLLING</strong></td>\n<td align=\"left\"><code>epoll_wait()</code></td>\n<td align=\"left\">Kernel-level wait. No user code.</td>\n</tr>\n<tr>\n<td align=\"left\"><strong>DISPATCHING</strong></td>\n<td align=\"left\"><code>epoll_wait</code> returns</td>\n<td align=\"left\"><code>register</code>/<code>deregister</code> (queued), <code>defer</code>.</td>\n</tr>\n<tr>\n<td align=\"left\"><strong>MOD_APPLY</strong></td>\n<td align=\"left\">Dispatch loop ends</td>\n<td align=\"left\"><code>epoll_ctl</code> batching.</td>\n</tr>\n<tr>\n<td align=\"left\"><strong>TASK_RUN</strong></td>\n<td align=\"left\">Mod apply ends</td>\n<td align=\"left\">Run application-level deferred tasks.</td>\n</tr>\n<tr>\n<td align=\"left\"><strong>STOPPED</strong></td>\n<td align=\"left\"><code>reactor_stop()</code></td>\n<td align=\"left\"><code>reactor_destroy()</code> cleanup.</td>\n</tr>\n</tbody></table>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/* Pseudocode: reactor_run core logic */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> reactor_run</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">reactor_t</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">r</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    while</span><span style=\"color:#E1E4E8\"> (r->is_running) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\"> timeout </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> timer_heap_get_next_timeout</span><span style=\"color:#E1E4E8\">(r->timer_heap);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\"> n_ready </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> epoll_wait</span><span style=\"color:#E1E4E8\">(r->epoll_fd, r->event_batch, MAX_EVENTS, timeout);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // 1. Timers first</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        timer_heap_process_expired</span><span style=\"color:#E1E4E8\">(r, </span><span style=\"color:#B392F0\">now_ms</span><span style=\"color:#E1E4E8\">());</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // 2. I/O Dispatch</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        r->is_dispatching </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">; i </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> n_ready; i</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            fd_handler_t</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\">h </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">fd_handler_t</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">)r->event_batch[i].data.ptr;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (h->is_zombie </span><span style=\"color:#F97583\">||</span><span style=\"color:#F97583\"> !</span><span style=\"color:#E1E4E8\">h->is_registered) </span><span style=\"color:#F97583\">continue</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            uint32_t</span><span style=\"color:#E1E4E8\"> r_events </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> map_epoll_to_reactor</span><span style=\"color:#E1E4E8\">(r->event_batch[i].events);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            h-></span><span style=\"color:#B392F0\">callback</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">fd_from_ptr</span><span style=\"color:#E1E4E8\">(r, h), r_events, h->user_data);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        r->is_dispatching </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // 3. Mod Queue</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        process_mod_queue</span><span style=\"color:#E1E4E8\">(r);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // 4. Defer Queue (Snapshot-based)</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        process_defer_queue</span><span style=\"color:#E1E4E8\">(r);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<!-- END_TDD_MOD -->\n\n\n<!-- TDD_MOD_ID: build-event-loop-m4 -->\n<h1 id=\"module-charter-http-server-on-event-loop\">MODULE CHARTER: HTTP Server on Event Loop</h1>\n<p>This module implements a high-performance HTTP/1.1 static file server atop the Milestone 3 Reactor API. Its primary objective is to manage the transformation of raw TCP byte streams into structured HTTP requests and responses while maintaining the C10K concurrency target. The implementation must handle the &quot;Streaming Fragmentation&quot; reality of TCP, where HTTP headers and bodies may arrive across multiple <code>read()</code> calls or be multiplexed within a single read (pipelining). </p>\n<p>Key responsibilities include:</p>\n<ol>\n<li><strong>Incremental Parsing</strong>: A non-blocking state machine that accumulates bytes and pauses until delimiters (<code>\\r\\n\\r\\n</code>) are found.</li>\n<li><strong>Connection State Lifecycle</strong>: Managing transitions between <code>READING_HEADERS</code>, <code>READING_BODY</code>, <code>PROCESSING</code>, <code>WRITING</code>, and <code>KEEP_ALIVE</code>.</li>\n<li><strong>Resource Safety</strong>: Enforcing path-traversal defenses to prevent unauthorized file access and implementing canonical deferred cleanup to avoid use-after-free conditions.</li>\n<li><strong>Performance Integration</strong>: Utilizing the M2 write-buffer for backpressure and M2 timers for idle-connection reaping.</li>\n</ol>\n<p>This module does NOT implement HTTP/2, TLS/SSL, POST body processing beyond length tracking, or dynamic CGI-like execution.</p>\n<h1 id=\"file-structure\">FILE STRUCTURE</h1>\n<p>The implementation follows a modular structure, building on the previously established <code>reactor</code> and <code>write_buffer</code> components.</p>\n<ol>\n<li><code>http_server.h</code>: Protocol constants, MIME types, and public server initialization.</li>\n<li><code>http_parser.c</code>: The incremental state machine and header extraction logic.</li>\n<li><code>http_core.c</code>: Request dispatch, file I/O integration, and response generation.</li>\n<li><code>http_connection.c</code>: Lifecycle management (init, reset, deferred close).</li>\n<li><code>main.c</code>: Entry point, reactor initialization, and signal handling.</li>\n<li><code>Makefile</code>: Updated to include all objects with <code>-O3</code> and <code>-march=native</code> for performance.</li>\n</ol>\n<h1 id=\"complete-data-model\">COMPLETE DATA MODEL</h1>\n<h3 id=\"1-http_state_t-lifecycle-enum\">1. <code>http_state_t</code> (Lifecycle Enum)</h3>\n<p>Defines the current phase of the HTTP transaction.</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Value</th>\n<th align=\"left\">Name</th>\n<th align=\"left\">Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">0</td>\n<td align=\"left\"><code>HTTP_STATE_READING_HEADERS</code></td>\n<td align=\"left\">Accumulating bytes in <code>read_buf</code> searching for <code>\\r\\n\\r\\n</code>.</td>\n</tr>\n<tr>\n<td align=\"left\">1</td>\n<td align=\"left\"><code>HTTP_STATE_READING_BODY</code></td>\n<td align=\"left\">Headers done; waiting for <code>Content-Length</code> bytes to arrive.</td>\n</tr>\n<tr>\n<td align=\"left\">2</td>\n<td align=\"left\"><code>HTTP_STATE_PROCESSING</code></td>\n<td align=\"left\">Request fully received; resolving file path and generating headers.</td>\n</tr>\n<tr>\n<td align=\"left\">3</td>\n<td align=\"left\"><code>HTTP_STATE_WRITING_RESPONSE</code></td>\n<td align=\"left\">Data is being flushed from the M2 <code>write_buf</code>.</td>\n</tr>\n<tr>\n<td align=\"left\">4</td>\n<td align=\"left\"><code>HTTP_STATE_CLOSING</code></td>\n<td align=\"left\">Final flush in progress; connection will close once <code>write_buf</code> is empty.</td>\n</tr>\n</tbody></table>\n<h3 id=\"2-http_request_t-parsed-metadata\">2. <code>http_request_t</code> (Parsed Metadata)</h3>\n<p>Stores the result of the incremental parser. Reset every request in keep-alive cycles.</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Field</th>\n<th align=\"left\">Type</th>\n<th align=\"left\">Size</th>\n<th align=\"left\">Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\"><code>method</code></td>\n<td align=\"left\"><code>char[10]</code></td>\n<td align=\"left\">10</td>\n<td align=\"left\">&quot;GET&quot;, &quot;HEAD&quot;, etc.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>path</code></td>\n<td align=\"left\"><code>char[1024]</code></td>\n<td align=\"left\">1024</td>\n<td align=\"left\">URL path (e.g., &quot;/index.html&quot;).</td>\n</tr>\n<tr>\n<td align=\"left\"><code>content_length</code></td>\n<td align=\"left\"><code>size_t</code></td>\n<td align=\"left\">8</td>\n<td align=\"left\">From <code>Content-Length</code> header.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>body_received</code></td>\n<td align=\"left\"><code>size_t</code></td>\n<td align=\"left\">8</td>\n<td align=\"left\">Bytes of body currently in <code>read_buf</code>.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>keep_alive</code></td>\n<td align=\"left\"><code>bool</code></td>\n<td align=\"left\">1</td>\n<td align=\"left\">True if <code>Connection: keep-alive</code> (or default 1.1).</td>\n</tr>\n<tr>\n<td align=\"left\"><code>is_complete</code></td>\n<td align=\"left\"><code>bool</code></td>\n<td align=\"left\">1</td>\n<td align=\"left\">Internal parser flag.</td>\n</tr>\n</tbody></table>\n<h3 id=\"3-http_conn_t-the-connection-context\">3. <code>http_conn_t</code> (The Connection Context)</h3>\n<p>The &quot;Heart&quot; of the server. This struct is passed as <code>user_data</code> to all reactor callbacks.</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Field</th>\n<th align=\"left\">Type</th>\n<th align=\"left\">Offset</th>\n<th align=\"left\">Size</th>\n<th align=\"left\">Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\"><code>read_buf</code></td>\n<td align=\"left\"><code>char[16384]</code></td>\n<td align=\"left\">0x00</td>\n<td align=\"left\">16384</td>\n<td align=\"left\">Large buffer to catch fragmented headers.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>wbuf</code></td>\n<td align=\"left\"><code>write_buf_t</code></td>\n<td align=\"left\">0x4000</td>\n<td align=\"left\">24</td>\n<td align=\"left\">M2 Write Buffer for backpressure.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>req</code></td>\n<td align=\"left\"><code>http_request_t</code></td>\n<td align=\"left\">0x4018</td>\n<td align=\"left\">~1060</td>\n<td align=\"left\">Parsed request metadata.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>fd</code></td>\n<td align=\"left\"><code>int</code></td>\n<td align=\"left\">0x443C</td>\n<td align=\"left\">4</td>\n<td align=\"left\">Client socket descriptor.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>state</code></td>\n<td align=\"left\"><code>http_state_t</code></td>\n<td align=\"left\">0x4440</td>\n<td align=\"left\">4</td>\n<td align=\"left\">Current lifecycle state.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>read_pos</code></td>\n<td align=\"left\"><code>uint32_t</code></td>\n<td align=\"left\">0x4444</td>\n<td align=\"left\">4</td>\n<td align=\"left\">Current fill level of <code>read_buf</code>.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>timer_id</code></td>\n<td align=\"left\"><code>int</code></td>\n<td align=\"left\">0x4448</td>\n<td align=\"left\">4</td>\n<td align=\"left\">Reactor timer handle for idle timeout.</td>\n</tr>\n<tr>\n<td align=\"left\"><code>reactor</code></td>\n<td align=\"left\"><code>reactor_t*</code></td>\n<td align=\"left\">0x4450</td>\n<td align=\"left\">8</td>\n<td align=\"left\">Reference back to owning reactor.</td>\n</tr>\n<tr>\n<td align=\"left\"><strong>Total Size</strong></td>\n<td align=\"left\"></td>\n<td align=\"left\"></td>\n<td align=\"left\"><strong>~17.5 KB</strong></td>\n<td align=\"left\"></td>\n</tr>\n</tbody></table>\n<p><strong>Memory Analysis:</strong> At 10,000 connections, this requires ~175 MB of resident memory. The 16 KB <code>read_buf</code> is sized to accommodate most production HTTP header sets (typical limit 8-16 KB).</p>\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Ftdd-diag-26.svg\" alt=\"http_conn Struct: Byte-Level Memory Layout with Field Groups and Cache Line Boundaries\"></p>\n<h1 id=\"interface-contracts\">INTERFACE CONTRACTS</h1>\n<h3 id=\"1-parse_result_t-http_parse_incrementalhttp_conn_t-conn\">1. <code>parse_result_t http_parse_incremental(http_conn_t *conn)</code></h3>\n<ul>\n<li><strong>Behavior</strong>: Scans <code>conn-&gt;read_buf</code> from <code>0</code> to <code>conn-&gt;read_pos</code>.</li>\n<li><strong>Delimiters</strong>: Looks for <code>\\r\\n\\r\\n</code>.</li>\n<li><strong>Incremental logic</strong>: If not found, returns <code>PARSE_AGAIN</code>. If found, parses the first line and headers into <code>conn-&gt;req</code> and returns <code>PARSE_OK</code>.</li>\n<li><strong>Edge Case</strong>: If <code>read_pos == sizeof(read_buf)</code> and no delimiter found, returns <code>PARSE_LIMIT_EXCEEDED</code>.</li>\n</ul>\n<h3 id=\"2-int-http_build_responsehttp_conn_t-conn\">2. <code>int http_build_response(http_conn_t *conn)</code></h3>\n<ul>\n<li><strong>Safety</strong>: Calls <code>build_safe_path()</code> to sanitize <code>req-&gt;path</code>.</li>\n<li><strong>I/O</strong>: Uses <code>stat()</code> to get file size and <code>open()</code> for reading.</li>\n<li><strong>Generation</strong>: Writes HTTP/1.1 status, <code>Content-Type</code>, <code>Content-Length</code>, and <code>Connection</code> headers to <code>conn-&gt;wbuf</code>.</li>\n<li><strong>Body</strong>: Reads file chunks into <code>conn-&gt;wbuf</code> using <code>wbuf_append</code>.</li>\n</ul>\n<h3 id=\"3-void-http_conn_close_deferredreactor_t-r-void-arg\">3. <code>void http_conn_close_deferred(reactor_t *r, void *arg)</code></h3>\n<ul>\n<li><strong>Contract</strong>: The ONLY valid way to close an HTTP connection.</li>\n<li><strong>Cleanup</strong>: Cancels timers, deregisters from reactor, frees <code>wbuf</code> heap memory, closes <code>fd</code>, and finally <code>free(conn)</code>.</li>\n<li><strong>Rationale</strong>: Must be called via <code>reactor_defer</code> to ensure the reactor&#39;s current event batch processing is complete.</li>\n</ul>\n<h1 id=\"algorithm-specification\">ALGORITHM SPECIFICATION</h1>\n<h3 id=\"1-incremental-read-amp-shift-algorithm\">1. Incremental Read &amp; Shift Algorithm</h3>\n<p>When <code>REACTOR_READABLE</code> fires:</p>\n<ol>\n<li><strong>Read</strong>: <code>n = read(fd, read_buf + read_pos, space)</code>.</li>\n<li><strong>Parse</strong>: Call <code>http_parse_incremental</code>.</li>\n<li><strong>Shift</strong>: If headers are complete but part of a body (or next request) was read:<ul>\n<li><code>body_start = header_end_offset</code>.</li>\n<li><code>remaining = read_pos - body_start</code>.</li>\n<li><code>memmove(read_buf, read_buf + body_start, remaining)</code>.</li>\n<li><code>read_pos = remaining</code>.</li>\n</ul>\n</li>\n<li><strong>State Change</strong>: Transition to <code>HTTP_STATE_PROCESSING</code>.</li>\n</ol>\n<h3 id=\"2-path-sanitization-defense-in-depth\">2. Path Sanitization (Defense-in-Depth)</h3>\n<p><code>int build_safe_path(const char *input, char *output)</code></p>\n<ol>\n<li>Prepend <code>STATIC_ROOT</code>.</li>\n<li>Check for <code>..</code> substrings. If found, REJECT (400 Bad Request).</li>\n<li>Check for <code>//</code> or internal <code>\\0</code>.</li>\n<li>If path ends in <code>/</code>, append <code>index.html</code>.</li>\n<li>Verify result is within <code>MAX_PATH</code>.</li>\n</ol>\n<h3 id=\"3-keep-alive-cycle-logic\">3. Keep-Alive Cycle Logic</h3>\n<ol>\n<li>After response is fully appended to <code>wbuf</code>:</li>\n<li>If <code>req-&gt;keep_alive</code> is true:<ul>\n<li>Call <code>http_reset_connection(conn)</code>.</li>\n<li>Set <code>state = HTTP_STATE_READING_HEADERS</code>.</li>\n<li>Do NOT close FD. Reset idle timer to <code>now + 30s</code>.</li>\n</ul>\n</li>\n<li>If <code>keep_alive</code> is false:<ul>\n<li>Set <code>state = HTTP_STATE_CLOSING</code>.</li>\n<li>Write logic will close after last byte leaves <code>wbuf</code>.</li>\n</ul>\n</li>\n</ol>\n<p><img src=\"/api/project/build-event-loop/architecture-doc/asset?path=diagrams%2Ftdd-diag-27.svg\" alt=\"Per-Connection HTTP State Machine: All States, Valid Transitions, and Illegal Transitions\"></p>\n<h1 id=\"error-handling-matrix\">ERROR HANDLING MATRIX</h1>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Error</th>\n<th align=\"left\">Detected By</th>\n<th align=\"left\">Recovery Action</th>\n<th align=\"left\">User-Visible?</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\"><code>PARSE_LIMIT_EXCEEDED</code></td>\n<td align=\"left\"><code>http_parse</code></td>\n<td align=\"left\">Send <code>413 Payload Too Large</code>, defer close.</td>\n<td align=\"left\">Yes (413)</td>\n</tr>\n<tr>\n<td align=\"left\">Path Traversal (<code>..</code>)</td>\n<td align=\"left\"><code>build_safe_path</code></td>\n<td align=\"left\">Send <code>400 Bad Request</code>, defer close.</td>\n<td align=\"left\">Yes (400)</td>\n</tr>\n<tr>\n<td align=\"left\">File Not Found</td>\n<td align=\"left\"><code>stat()</code></td>\n<td align=\"left\">Send <code>404 Not Found</code>, keep-alive reset.</td>\n<td align=\"left\">Yes (404)</td>\n</tr>\n<tr>\n<td align=\"left\"><code>wbuf</code> Full</td>\n<td align=\"left\"><code>wbuf_append</code></td>\n<td align=\"left\">Defer close immediately (Slow Loris defense).</td>\n<td align=\"left\">No</td>\n</tr>\n<tr>\n<td align=\"left\"><code>open()</code> fails (after headers)</td>\n<td align=\"left\"><code>http_process</code></td>\n<td align=\"left\">Defer close immediately (Broken Pipe).</td>\n<td align=\"left\">No</td>\n</tr>\n<tr>\n<td align=\"left\">Idle Timeout</td>\n<td align=\"left\">Reactor Timer</td>\n<td align=\"left\"><code>reactor_defer(http_conn_close_deferred)</code>.</td>\n<td align=\"left\">No</td>\n</tr>\n</tbody></table>\n<h1 id=\"implementation-sequence\">IMPLEMENTATION SEQUENCE</h1>\n<h3 id=\"phase-1-data-structures-amp-handlers-2-hours\">Phase 1: Data Structures &amp; Handlers (2 Hours)</h3>\n<ul>\n<li>Define <code>http_conn_t</code> and <code>http_request_t</code>.</li>\n<li>Implement <code>http_accept_cb</code> to allocate <code>http_conn_t</code> and register with reactor.</li>\n<li><strong>Checkpoint</strong>: Server accepts connections, allocates memory, and assigns an idle timer. Verify via <code>valgrind</code> that memory is freed on manual close.</li>\n</ul>\n<h3 id=\"phase-2-incremental-parser-3-hours\">Phase 2: Incremental Parser (3 Hours)</h3>\n<ul>\n<li>Implement <code>find_header_end</code> (\\r\\n\\r\\n).</li>\n<li>Implement <code>parse_request_line</code> and <code>parse_header_field</code>.</li>\n<li>Integrate into <code>http_on_readable</code> with the <code>memmove</code> shift logic.</li>\n<li><strong>Checkpoint</strong>: Use <code>telnet</code> to send headers one character at a time. Verify the parser only triggers <code>PARSE_OK</code> after the final <code>\\r\\n\\r\\n</code>.</li>\n</ul>\n<h3 id=\"phase-3-response-generation-amp-file-io-3-hours\">Phase 3: Response Generation &amp; File I/O (3 Hours)</h3>\n<ul>\n<li>Implement <code>build_safe_path</code>.</li>\n<li>Implement <code>http_process_request</code> with <code>stat</code> and <code>Content-Type</code> mapping.</li>\n<li>Hook into M2 <code>conn_write_buffered</code>.</li>\n<li><strong>Checkpoint</strong>: <code>curl http://localhost:8080/index.html</code> successfully retrieves a file from the <code>public/</code> directory.</li>\n</ul>\n<h3 id=\"phase-4-lifecycle-amp-keep-alive-2-hours\">Phase 4: Lifecycle &amp; Keep-Alive (2 Hours)</h3>\n<ul>\n<li>Implement <code>http_reset_connection</code>.</li>\n<li>Handle <code>Connection: close</code> vs <code>keep-alive</code>.</li>\n<li>Implement <code>http_conn_close_deferred</code> and ensure all error paths use it.</li>\n<li><strong>Checkpoint</strong>: <code>ab -k</code> (keep-alive) shows multiple requests handled over a single TCP connection.</li>\n</ul>\n<h3 id=\"phase-5-tuning-amp-benchmarking-2-hours\">Phase 5: Tuning &amp; Benchmarking (2 Hours)</h3>\n<ul>\n<li>Set <code>ulimit -n 65535</code>.</li>\n<li>Run <code>wrk -c 10000</code>.</li>\n<li>Profile with <code>perf top</code> to identify hotspots (usually <code>find_header_end</code> or <code>memmove</code>).</li>\n<li><strong>Checkpoint</strong>: p99 latency &lt; 100ms under 10k concurrent load.</li>\n</ul>\n<h1 id=\"test-specification\">TEST SPECIFICATION</h1>\n<h3 id=\"1-fragmentation-stress-test\">1. Fragmentation Stress Test</h3>\n<ul>\n<li><strong>Tool</strong>: Custom python script.</li>\n<li><strong>Action</strong>: Send <code>GET /index.html HTT</code>, sleep 100ms, send <code>P/1.1\\r\\nHost: loc</code>, sleep 100ms, send <code>alhost\\r\\n\\r\\n</code>.</li>\n<li><strong>Expected</strong>: Server correctly parses and responds after the final chunk.</li>\n</ul>\n<h3 id=\"2-security-path-traversal\">2. Security: Path Traversal</h3>\n<ul>\n<li><strong>Input</strong>: <code>GET /../../../../etc/passwd HTTP/1.1</code></li>\n<li><strong>Expected</strong>: <code>400 Bad Request</code> or <code>404 Not Found</code> (depending on root configuration), but NEVER the content of <code>passwd</code>.</li>\n</ul>\n<h3 id=\"3-c10k-load-test\">3. C10K Load Test</h3>\n<ul>\n<li><strong>Tool</strong>: <code>wrk -t12 -c10000 -d30s http://localhost:8080/test.html</code></li>\n<li><strong>Success Criteria</strong>: 0 socket errors, 0 timeouts, p99 &lt; 100ms.</li>\n</ul>\n<h1 id=\"performance-targets\">PERFORMANCE TARGETS</h1>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Operation</th>\n<th align=\"left\">Target</th>\n<th align=\"left\">Measurement Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">Header Parsing</td>\n<td align=\"left\">&lt; 10Î¼s per req</td>\n<td align=\"left\"><code>perf</code> probe on <code>http_parse_incremental</code></td>\n</tr>\n<tr>\n<td align=\"left\">Memory Per Connection</td>\n<td align=\"left\">~17.5 KB</td>\n<td align=\"left\"><code>ps -o rss</code> / total_conns</td>\n</tr>\n<tr>\n<td align=\"left\">Throughput</td>\n<td align=\"left\">50,000+ RPS</td>\n<td align=\"left\"><code>wrk</code> on localhost</td>\n</tr>\n<tr>\n<td align=\"left\">Max Conns</td>\n<td align=\"left\">10,000+</td>\n<td align=\"left\">`netstat -an</td>\n</tr>\n</tbody></table>\n<h1 id=\"hardware-soul-performance-insights\">HARDWARE SOUL: PERFORMANCE INSIGHTS</h1>\n<h3 id=\"1-sequential-access-amp-prefetching\">1. Sequential Access &amp; Prefetching</h3>\n<p>The <code>find_header_end</code> function performs a linear scan of <code>read_buf</code>. </p>\n<ul>\n<li><strong>The Hardware View</strong>: Modern CPU prefetchers detect this linear read pattern (stride of 1). By the time the code is checking byte $N$, the hardware has already loaded bytes $N+64$ and $N+128$ into the L1 cache. </li>\n<li><strong>Optimization</strong>: To keep the pipeline full, we avoid complex branching inside the loop.</li>\n</ul>\n<h3 id=\"2-memmove-and-cache-pressure\">2. <code>memmove</code> and Cache Pressure</h3>\n<p>When we shift body bytes to the front of the <code>read_buf</code>, we use <code>memmove</code>. </p>\n<ul>\n<li><strong>Effect</strong>: This touches the memory twice (read then write). </li>\n<li><strong>Mitigation</strong>: By keeping <code>READ_BUF_SIZE</code> at 16 KB, we ensure the entire buffer fits in the L1 Data Cache (typically 32-64 KB). This makes the shift operation nearly as fast as register-to-register moves.</li>\n</ul>\n<h3 id=\"3-syscall-batching-the-quotamortizationquot\">3. Syscall Batching (The &quot;Amortization&quot;)</h3>\n<p>In the <code>http_accept_cb</code> and <code>http_on_readable</code>, we use <strong>ET (Edge-Triggered)</strong> mode with a loop until <code>EAGAIN</code>.</p>\n<ul>\n<li><strong>Benefit</strong>: This minimizes the number of <code>epoll_wait</code> entries/exits. If 100 packets arrive for 100 different FDs, <code>epoll_wait</code> returns them all in one array. We process all 100 in user-space before context-switching back to the kernel. This amortizes the ~200ns syscall cost across 100 requests.</li>\n</ul>\n<h3 id=\"4-sendfile2-optional-milestone\">4. <code>sendfile(2)</code> (Optional Milestone)</h3>\n<p>While the standard implementation uses <code>read/write</code>, a &quot;Hardware Soul&quot; optimization is <code>sendfile</code>. </p>\n<ul>\n<li><strong>Zero-Copy</strong>: It transfers data from the kernel Page Cache directly to the Socket Buffer without ever entering user-space memory. This eliminates two <code>memcpy</code> operations and reduces CPU usage by ~30% for large static files.</li>\n</ul>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/* Canonical Deferred Close implementation */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> http_conn_close_deferred</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">reactor_t</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">r</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">arg</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    http_conn_t</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\">conn </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">http_conn_t</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\">)arg;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (conn->fd </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">return</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\"> // Guard against double close</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 1. Stop all reactor interest</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (conn->timer_id </span><span style=\"color:#F97583\">!=</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        reactor_cancel_timer</span><span style=\"color:#E1E4E8\">(r, conn->timer_id);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    reactor_deregister</span><span style=\"color:#E1E4E8\">(r, conn->fd);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 2. Resource Release</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    wbuf_free</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">conn->wbuf);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    close</span><span style=\"color:#E1E4E8\">(conn->fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 3. Final Memory Release</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> old_fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> conn->fd;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    conn->fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\"> // Mark as dead</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    free</span><span style=\"color:#E1E4E8\">(conn);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    printf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"DEBUG: Cleaned up connection on fd </span><span style=\"color:#79B8FF\">%d\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, old_fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n<!-- END_TDD_MOD -->\n\n\n<h1 id=\"project-structure-event-loop-with-epoll\">Project Structure: Event Loop with epoll</h1>\n<h2 id=\"directory-tree\">Directory Tree</h2>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">text</span><pre class=\"arch-pre shiki-highlighted\"><code>event-loop-epoll/\nâ”œâ”€â”€ include/                 # Header files (API &amp; Internals)\nâ”‚   â”œâ”€â”€ reactor.h           # Public Reactor API (M3: Callback definitions)\nâ”‚   â”œâ”€â”€ reactor_internal.h  # Reactor private structs (M3: fd_handler, mod_queue)\nâ”‚   â”œâ”€â”€ write_buffer.h      # Write queue &amp; compaction logic (M2)\nâ”‚   â”œâ”€â”€ timer_heap.h        # Min-heap &amp; timing definitions (M2)\nâ”‚   â””â”€â”€ http_server.h       # HTTP constants, MIME types, &amp; states (M4)\nâ”œâ”€â”€ src/                    # Implementation files\nâ”‚   â”œâ”€â”€ reactor.c           # Core epoll loop &amp; dispatch logic (M1, M3)\nâ”‚   â”œâ”€â”€ write_buffer.c      # Dynamic buffer management (M2: Backpressure)\nâ”‚   â”œâ”€â”€ timer_heap.c        # Min-heap sift operations (M2: Idle timeouts)\nâ”‚   â”œâ”€â”€ http_parser.c       # Incremental state machine (M4: \\r\\n\\r\\n scanner)\nâ”‚   â”œâ”€â”€ http_core.c         # File I/O &amp; HTTP response generation (M4)\nâ”‚   â”œâ”€â”€ http_connection.c   # Connection lifecycle &amp; deferred cleanup (M4)\nâ”‚   â””â”€â”€ main.c              # Application entry &amp; server initialization (M4)\nâ”œâ”€â”€ public/                 # Static assets for HTTP server (M4)\nâ”‚   â””â”€â”€ index.html          # Default landing page for C10K testing\nâ”œâ”€â”€ Makefile                # Build system (M1-M4: -O3, -march=native)\nâ”œâ”€â”€ README.md               # Project overview and sysctl tuning guide\nâ””â”€â”€ .gitignore              # Ignores build artifacts (http_server, *.o)</code></pre></div>\n\n<h2 id=\"creation-order\">Creation Order</h2>\n<ol>\n<li><p><strong>Foundational I/O</strong> (M1)</p>\n<ul>\n<li>Create <code>Makefile</code> with basic flags (<code>-Wall -Wextra -O2</code>).</li>\n<li>Implement <code>set_nonblocking</code> and <code>create_listening_socket</code> in a temporary <code>echo_server.c</code>.</li>\n<li>Build the raw <code>epoll_wait</code> loop to verify Level-Triggered (LT) vs Edge-Triggered (ET) behavior.</li>\n</ul>\n</li>\n<li><p><strong>Reliability Layer</strong> (M2)</p>\n<ul>\n<li>Implement <code>src/write_buffer.c</code> and <code>src/timer_heap.c</code>.</li>\n<li>Integrate <code>wbuf_append</code> into the write path to handle <code>EAGAIN</code>.</li>\n<li>Integrate <code>timer_next_ms()</code> into the <code>epoll_wait</code> timeout to handle idle connections.</li>\n</ul>\n</li>\n<li><p><strong>The Reactor Library</strong> (M3)</p>\n<ul>\n<li>Refactor the raw loop into <code>include/reactor.h</code> and <code>src/reactor.c</code>.</li>\n<li>Implement the <code>is_dispatching</code> flag and <code>mod_queue</code> to prevent FD reuse races.</li>\n<li>Implement <code>reactor_defer()</code> to handle safe, post-dispatch cleanup.</li>\n</ul>\n</li>\n<li><p><strong>Protocol Implementation</strong> (M4)</p>\n<ul>\n<li>Implement <code>src/http_parser.c</code> with the <code>memmove</code> incremental shift logic.</li>\n<li>Implement <code>src/http_core.c</code> including the <code>build_safe_path</code> security check.</li>\n<li>Set up <code>src/http_connection.c</code> for keep-alive state resets.</li>\n</ul>\n</li>\n<li><p><strong>Optimization &amp; Load Testing</strong> (M4)</p>\n<ul>\n<li>Finalize <code>src/main.c</code> with signal handling.</li>\n<li>Tune <code>Makefile</code> with <code>-O3 -march=native</code>.</li>\n<li>Apply <code>sysctl</code> kernel tweaks for C10K and run <code>wrk</code> benchmarks.</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"file-count-summary\">File Count Summary</h2>\n<ul>\n<li><strong>Total Source Files</strong>: 7 (.c)</li>\n<li><strong>Total Header Files</strong>: 5 (.h)</li>\n<li><strong>Total Directories</strong>: 3</li>\n<li><strong>Estimated Lines of Code</strong>: ~1,800 LOC</li>\n<li><strong>Build Artifacts</strong>: <code>http_server</code> (executable), <code>*.o</code> (object files)</li>\n</ul>\n","toc":[{"level":1,"text":"ðŸŽ¯ Project Charter: Event Loop with epoll","id":"-project-charter-event-loop-with-epoll"},{"level":2,"text":"What You Are Building","id":"what-you-are-building"},{"level":2,"text":"Why This Project Exists","id":"why-this-project-exists"},{"level":2,"text":"What You Will Be Able to Do When Done","id":"what-you-will-be-able-to-do-when-done"},{"level":2,"text":"Final Deliverable","id":"final-deliverable"},{"level":2,"text":"Is This Project For You?","id":"is-this-project-for-you"},{"level":2,"text":"Estimated Effort","id":"estimated-effort"},{"level":2,"text":"Definition of Done","id":"definition-of-done"},{"level":1,"text":"ðŸ“š Before You Read This: Prerequisites &amp; Further Reading","id":"-before-you-read-this-prerequisites-amp-further-reading"},{"level":3,"text":"1. The Genesis of High Concurrency","id":"1-the-genesis-of-high-concurrency"},{"level":3,"text":"2. Linux Kernel I/O Multiplexing","id":"2-linux-kernel-io-multiplexing"},{"level":3,"text":"3. The Reactor Design Pattern","id":"3-the-reactor-design-pattern"},{"level":3,"text":"4. Efficient Timing &amp; Priority Queues","id":"4-efficient-timing-amp-priority-queues"},{"level":3,"text":"5. HTTP/1.1 Protocol &amp; Parsing","id":"5-http11-protocol-amp-parsing"},{"level":3,"text":"6. Memory Management and Backpressure","id":"6-memory-management-and-backpressure"},{"level":3,"text":"7. Zero-Copy Optimizations","id":"7-zero-copy-optimizations"},{"level":3,"text":"8. The Future: Asynchronous Completion I/O","id":"8-the-future-asynchronous-completion-io"},{"level":1,"text":"Event Loop with epoll: Building a Reactor-Pattern Server from Scratch","id":"event-loop-with-epoll-building-a-reactor-pattern-server-from-scratch"},{"level":1,"text":"epoll Basics: Level-Triggered and Edge-Triggered","id":"epoll-basics-level-triggered-and-edge-triggered"},{"level":2,"text":"The Problem That Makes Single-Threaded Servers Hard","id":"the-problem-that-makes-single-threaded-servers-hard"},{"level":2,"text":"epoll in Context: What Came Before","id":"epoll-in-context-what-came-before"},{"level":2,"text":"In the system map, this milestone builds the foundation layer: the epoll instance and the non-blocking socket infrastructure that everything above it depends on.","id":"in-the-system-map-this-milestone-builds-the-foundation-layer-the-epoll-instance-and-the-non-blocking-socket-infrastructure-that-everything-above-it-depends-on"},{"level":2,"text":"The Revelation: ET and LT Are Different Contracts, Not Different Speeds","id":"the-revelation-et-and-lt-are-different-contracts-not-different-speeds"},{"level":2,"text":"This is not a performance difference. It is a different programming model that demands different code.","id":"this-is-not-a-performance-difference-it-is-a-different-programming-model-that-demands-different-code"},{"level":2,"text":"Building the Foundation: Non-Blocking Sockets","id":"building-the-foundation-non-blocking-sockets"},{"level":2,"text":"Creating the epoll Instance","id":"creating-the-epoll-instance"},{"level":3,"text":"Registering File Descriptors","id":"registering-file-descriptors"},{"level":2,"text":"Setting Up the Listening Socket","id":"setting-up-the-listening-socket"},{"level":2,"text":"Per-Connection State: The fd â†’ State Map","id":"per-connection-state-the-fd-state-map"},{"level":2,"text":"The Level-Triggered Event Loop","id":"the-level-triggered-event-loop"},{"level":2,"text":"Test this with nc localhost 8080. Type text, hit Enter, and it echoes back. Now try piping a large file: cat /dev/urandom | head -c 1000000 | nc localhost 8080. Watch it work correctlyâ€”LT mode will keep waking up the loop until all the data is read.","id":"test-this-with-nc-localhost-8080-type-text-hit-enter-and-it-echoes-back-now-try-piping-a-large-file-cat-devurandom-head-c-1000000-nc-localhost-8080-watch-it-work-correctlylt-mode-will-keep-waking-up-the-loop-until-all-the-data-is-read"},{"level":2,"text":"The Edge-Triggered Event Loop: Drain Until EAGAIN","id":"the-edge-triggered-event-loop-drain-until-eagain"},{"level":2,"text":"The Bug You Must See: Single Read in ET Mode","id":"the-bug-you-must-see-single-read-in-et-mode"},{"level":2,"text":"With the broken handler, you&#39;ll receive 4,096 bytes echoed back, then silence. The remaining 4,096 bytes are trapped in the kernel receive buffer, invisible until the client sends more data. With the correct handler (drain until EAGAIN), you receive all 8,192 bytes.\nUnder a load test sending large requests concurrently, this bug manifests as random request timeoutsâ€”connections that appear connected but never complete.","id":"with-the-broken-handler-you39ll-receive-4096-bytes-echoed-back-then-silence-the-remaining-4096-bytes-are-trapped-in-the-kernel-receive-buffer-invisible-until-the-client-sends-more-data-with-the-correct-handler-drain-until-eagain-you-receive-all-8192-bytes-under-a-load-test-sending-large-requests-concurrently-this-bug-manifests-as-random-request-timeoutsconnections-that-appear-connected-but-never-complete"},{"level":2,"text":"The Non-Blocking Accept Loop and the ET Listening Socket","id":"the-non-blocking-accept-loop-and-the-et-listening-socket"},{"level":2,"text":"Putting It All Together: The Complete Echo Server","id":"putting-it-all-together-the-complete-echo-server"},{"level":2,"text":"Hardware Soul: What the Kernel Actually Does","id":"hardware-soul-what-the-kernel-actually-does"},{"level":2,"text":"Design Decision: LT vs ET â€” Which Should You Use?","id":"design-decision-lt-vs-et-which-should-you-use"},{"level":2,"text":"The Three-Level View: One Read Call","id":"the-three-level-view-one-read-call"},{"level":2,"text":"Let&#39;s trace a single read() call through the stack:\nLevel 1 â€” Application: Your code calls read(fd, buf, 4096). A number (positive: bytes read, 0: EOF, -1: error or EAGAIN) returns.\nLevel 2 â€” Kernel: The read() syscall enters the kernel via the syscall table. The kernel&#39;s socket layer (net/socket.c) finds the TCP socket&#39;s receive buffer (sk_receive_queue). It copies bytes from the socket buffer into your user-space buf using copy_to_user(). If the buffer was drained below a threshold, the kernel updates the socket&#39;s readiness state. In ET mode, if the buffer was previously non-empty and now becomes empty, the epoll subsystem removes the epitem from the ready list.\nLevel 3 â€” Hardware: copy_to_user() is essentially a memcpy from kernel-space to user-space. On a modern CPU with virtual memory, both the kernel buffer and user buffer are virtual addresses. The MMU translates them to physical addresses using the page table, checked via TLB. If the user-space buffer page is in TLB (likely for the first read after a context switch into the epoll loop), this is fast. The actual data transfer uses SSE2 or AVX movdqu/vmovdqu instructions for vectorized 16- or 32-byte copies. At 4096 bytes with AVX2 (32-byte copies), that&#39;s 128 vector instructionsâ€”approximately 64 cycles on a modern CPU, or ~20 ns at 3 GHz.","id":"let39s-trace-a-single-read-call-through-the-stack-level-1-application-your-code-calls-readfd-buf-4096-a-number-positive-bytes-read-0-eof-1-error-or-eagain-returns-level-2-kernel-the-read-syscall-enters-the-kernel-via-the-syscall-table-the-kernel39s-socket-layer-netsocketc-finds-the-tcp-socket39s-receive-buffer-sk_receive_queue-it-copies-bytes-from-the-socket-buffer-into-your-user-space-buf-using-copy_to_user-if-the-buffer-was-drained-below-a-threshold-the-kernel-updates-the-socket39s-readiness-state-in-et-mode-if-the-buffer-was-previously-non-empty-and-now-becomes-empty-the-epoll-subsystem-removes-the-epitem-from-the-ready-list-level-3-hardware-copy_to_user-is-essentially-a-memcpy-from-kernel-space-to-user-space-on-a-modern-cpu-with-virtual-memory-both-the-kernel-buffer-and-user-buffer-are-virtual-addresses-the-mmu-translates-them-to-physical-addresses-using-the-page-table-checked-via-tlb-if-the-user-space-buffer-page-is-in-tlb-likely-for-the-first-read-after-a-context-switch-into-the-epoll-loop-this-is-fast-the-actual-data-transfer-uses-sse2-or-avx-movdquvmovdqu-instructions-for-vectorized-16-or-32-byte-copies-at-4096-bytes-with-avx2-32-byte-copies-that39s-128-vector-instructionsapproximately-64-cycles-on-a-modern-cpu-or-20-ns-at-3-ghz"},{"level":2,"text":"Knowledge Cascade: What This Unlocks","id":"knowledge-cascade-what-this-unlocks"},{"level":2,"text":"Now that you understand epoll&#39;s fundamentals and the ET/LT contract, you have a lens for understanding systems you&#39;ll encounter throughout your career:\n1. NGINX&#39;s module bug surface: NGINX uses ET mode exclusively and documents that every module must call ngx_handle_read_event() and drain the socket. Third-party NGINX modules are a frequent source of bugs precisely because module authors forget the drain disciplineâ€”the module works correctly in unit testing (small payloads) but loses data under production load. You now know exactly why.\n2. TCP flow control and ET&#39;s hidden interaction: When you drain the socket buffer aggressively (ET&#39;s drain-until-EAGAIN), you keep the kernel&#39;s receive buffer empty. This signals to the TCP stack that your application can receive more data. TCP&#39;s receive window (advertised to the remote sender) stays large. If you don&#39;t drain (the LT partial-read case), the receive buffer fills, the window shrinks, and TCP backpressure naturally slows the sender. ET mode thus affects TCP&#39;s flow control behaviorâ€”aggressive draining can increase throughput but also means your application sees larger bursts of data that it must handle efficiently.\n3. io_uring: epoll&#39;s eventual successor: io_uring (Linux 5.1+) eliminates the epoll wait â†’ read â†’ write syscall pattern entirely. You submit read and write operations to a ring buffer, and completions appear in another ring bufferâ€”no epoll_wait, no per-event read() syscall. At 10K connections with small messages, epoll spends significant CPU time in syscall overhead (context switches to kernel space). io_uring amortizes this by batching. The ET/LT distinction doesn&#39;t exist in io_uring&#39;s completion model (it&#39;s inherently edge-notificationâ€”you get one completion per submitted operation). Understanding epoll&#39;s model makes io_uring&#39;s design decisions legible.\n4. The C10K paper and historical context: Dan Kegel&#39;s 1999 C10K paper (cited in your resources) described this exact problem before Linux had epoll. The solutions proposedâ€”non-blocking I/O, event-driven architectures, select/poll improvementsâ€”directly led to epoll&#39;s design. Reading it now, you&#39;ll recognize every problem and understand why epoll solved them the way it did. The paper is a time capsule of the moment when event-driven architecture stopped being exotic and became necessary.\n5. Cross-domain: Browser event loops: JavaScript&#39;s event loop (the foundation of Node.js and browsers) is the same reactor pattern you just builtâ€”a single-threaded loop that dispatches events to callbacks. setTimeout, Promise.then, and EventListener callbacks are all queued events, processed in order. The &quot;event loop&quot; terminology in JavaScript directly inherits from the networking reactor pattern you&#39;re building. When JavaScript developers talk about &quot;not blocking the event loop,&quot; they mean exactly what you now know: if a callback takes 100ms, all other events are delayed by 100msâ€”same constraint, different context.","id":"now-that-you-understand-epoll39s-fundamentals-and-the-etlt-contract-you-have-a-lens-for-understanding-systems-you39ll-encounter-throughout-your-career-1-nginx39s-module-bug-surface-nginx-uses-et-mode-exclusively-and-documents-that-every-module-must-call-ngx_handle_read_event-and-drain-the-socket-third-party-nginx-modules-are-a-frequent-source-of-bugs-precisely-because-module-authors-forget-the-drain-disciplinethe-module-works-correctly-in-unit-testing-small-payloads-but-loses-data-under-production-load-you-now-know-exactly-why-2-tcp-flow-control-and-et39s-hidden-interaction-when-you-drain-the-socket-buffer-aggressively-et39s-drain-until-eagain-you-keep-the-kernel39s-receive-buffer-empty-this-signals-to-the-tcp-stack-that-your-application-can-receive-more-data-tcp39s-receive-window-advertised-to-the-remote-sender-stays-large-if-you-don39t-drain-the-lt-partial-read-case-the-receive-buffer-fills-the-window-shrinks-and-tcp-backpressure-naturally-slows-the-sender-et-mode-thus-affects-tcp39s-flow-control-behavioraggressive-draining-can-increase-throughput-but-also-means-your-application-sees-larger-bursts-of-data-that-it-must-handle-efficiently-3-io_uring-epoll39s-eventual-successor-io_uring-linux-51-eliminates-the-epoll-wait-read-write-syscall-pattern-entirely-you-submit-read-and-write-operations-to-a-ring-buffer-and-completions-appear-in-another-ring-bufferno-epoll_wait-no-per-event-read-syscall-at-10k-connections-with-small-messages-epoll-spends-significant-cpu-time-in-syscall-overhead-context-switches-to-kernel-space-io_uring-amortizes-this-by-batching-the-etlt-distinction-doesn39t-exist-in-io_uring39s-completion-model-it39s-inherently-edge-notificationyou-get-one-completion-per-submitted-operation-understanding-epoll39s-model-makes-io_uring39s-design-decisions-legible-4-the-c10k-paper-and-historical-context-dan-kegel39s-1999-c10k-paper-cited-in-your-resources-described-this-exact-problem-before-linux-had-epoll-the-solutions-proposednon-blocking-io-event-driven-architectures-selectpoll-improvementsdirectly-led-to-epoll39s-design-reading-it-now-you39ll-recognize-every-problem-and-understand-why-epoll-solved-them-the-way-it-did-the-paper-is-a-time-capsule-of-the-moment-when-event-driven-architecture-stopped-being-exotic-and-became-necessary-5-cross-domain-browser-event-loops-javascript39s-event-loop-the-foundation-of-nodejs-and-browsers-is-the-same-reactor-pattern-you-just-builta-single-threaded-loop-that-dispatches-events-to-callbacks-settimeout-promisethen-and-eventlistener-callbacks-are-all-queued-events-processed-in-order-the-quotevent-loopquot-terminology-in-javascript-directly-inherits-from-the-networking-reactor-pattern-you39re-building-when-javascript-developers-talk-about-quotnot-blocking-the-event-loopquot-they-mean-exactly-what-you-now-know-if-a-callback-takes-100ms-all-other-events-are-delayed-by-100mssame-constraint-different-context"},{"level":2,"text":"Pitfall Reference: The Five Ways This Breaks","id":"pitfall-reference-the-five-ways-this-breaks"},{"level":2,"text":"Before you move on, memorize these failure modes:\nPitfall 1: ET with single read per event\nSymptom: Works in testing, silently loses data under load, causing protocol-level deadlocks.\nFix: Always loop until EAGAIN in ET mode.\nPitfall 2: ET listening socket without accept loop\nSymptom: Under connection bursts, new clients connect but receive no response; their connections sit in the listen backlog.\nFix: Accept in a loop until EAGAIN in both the listen handler and the accept function.\nPitfall 3: Treating EAGAIN as an error\nSymptom: Connections closed immediately after the first &quot;empty read,&quot; or spurious connection resets.\nFix: Check errno == EAGAIN || errno == EWOULDBLOCK and return without closing.\nPitfall 4: Not setting the listen socket to non-blocking\nSymptom: Server hangs under specific TCP RST race conditions; accept() blocks briefly on a connection that was reset before accept ran.\nFix: Use SOCK_NONBLOCK in the socket() call or set_nonblocking() before listen().\nPitfall 5: MAX_EVENTS too small\nSymptom: Under high load, epoll_wait returns the maximum each call, requiring many calls to drain the ready list; reduces throughput.\nFix: Set MAX_EVENTS between 512 and 4096. 1024 is a common default; tune based on your event distribution.","id":"before-you-move-on-memorize-these-failure-modes-pitfall-1-et-with-single-read-per-event-symptom-works-in-testing-silently-loses-data-under-load-causing-protocol-level-deadlocks-fix-always-loop-until-eagain-in-et-mode-pitfall-2-et-listening-socket-without-accept-loop-symptom-under-connection-bursts-new-clients-connect-but-receive-no-response-their-connections-sit-in-the-listen-backlog-fix-accept-in-a-loop-until-eagain-in-both-the-listen-handler-and-the-accept-function-pitfall-3-treating-eagain-as-an-error-symptom-connections-closed-immediately-after-the-first-quotempty-readquot-or-spurious-connection-resets-fix-check-errno-eagain-errno-ewouldblock-and-return-without-closing-pitfall-4-not-setting-the-listen-socket-to-non-blocking-symptom-server-hangs-under-specific-tcp-rst-race-conditions-accept-blocks-briefly-on-a-connection-that-was-reset-before-accept-ran-fix-use-sock_nonblock-in-the-socket-call-or-set_nonblocking-before-listen-pitfall-5-max_events-too-small-symptom-under-high-load-epoll_wait-returns-the-maximum-each-call-requiring-many-calls-to-drain-the-ready-list-reduces-throughput-fix-set-max_events-between-512-and-4096-1024-is-a-common-default-tune-based-on-your-event-distribution"},{"level":1,"text":"Write Buffering and Timer Management","id":"write-buffering-and-timer-management"},{"level":2,"text":"The Problem You Haven&#39;t Solved Yet","id":"the-problem-you-haven39t-solved-yet"},{"level":2,"text":"The Revelation: EPOLLOUT Is NOT Like EPOLLIN","id":"the-revelation-epollout-is-not-like-epollin"},{"level":2,"text":"Building the Write Buffer","id":"building-the-write-buffer"},{"level":2,"text":"Updated Per-Connection State","id":"updated-per-connection-state"},{"level":2,"text":"The Write Path: Attempt, Buffer, Register","id":"the-write-path-attempt-buffer-register"},{"level":2,"text":"Study the conn_flush function&#39;s deregistration block. This is the heartbeat of the EPOLLOUT cycle. When wbuf_is_empty() returns true and epollout_armed is true, a single epoll_ctl(EPOLL_CTL_MOD) call switches the fd&#39;s interest back to EPOLLIN only. From that point, epoll_wait will not return this fd as writable until you arm it again. CPU usage drops from 100% to near-zero during idle periods.","id":"study-the-conn_flush-function39s-deregistration-block-this-is-the-heartbeat-of-the-epollout-cycle-when-wbuf_is_empty-returns-true-and-epollout_armed-is-true-a-single-epoll_ctlepoll_ctl_mod-call-switches-the-fd39s-interest-back-to-epollin-only-from-that-point-epoll_wait-will-not-return-this-fd-as-writable-until-you-arm-it-again-cpu-usage-drops-from-100-to-near-zero-during-idle-periods"},{"level":2,"text":"Integrating Write Buffering Into the Event Loop","id":"integrating-write-buffering-into-the-event-loop"},{"level":2,"text":"TCP Backpressure and the Slow Loris Defense","id":"tcp-backpressure-and-the-slow-loris-defense"},{"level":2,"text":"Timer Management: The Event Loop&#39;s Internal Clock","id":"timer-management-the-event-loop39s-internal-clock"},{"level":3,"text":"Choosing a Timer Data Structure","id":"choosing-a-timer-data-structure"},{"level":3,"text":"Implementing the Min-Heap Timer","id":"implementing-the-min-heap-timer"},{"level":2,"text":"Integrating Timers Into the Event Loop","id":"integrating-timers-into-the-event-loop"},{"level":2,"text":"The Three-Level View: One EPOLLOUT Event","id":"the-three-level-view-one-epollout-event"},{"level":2,"text":"Let&#39;s trace what happens from kernel to hardware when a slow client&#39;s socket buffer finally drains and EPOLLOUT fires:\nLevel 1 â€” Application: Your event loop calls epoll_wait. It returns with EPOLLOUT set for fd 42. Your code calls conn_flush(epoll_fd, &amp;connections[42]).\nLevel 2 â€” OS/Kernel: When the NIC sent TCP segments and received ACKs from the remote client, the kernel&#39;s TCP stack freed space in the socket&#39;s send buffer (sk_send_head advances). The socket&#39;s sock_def_write_space callback fires, which wakes the epoll subsystem. The epoll epitem for fd 42 is placed on the ready list (rdllist). On your next epoll_wait, the kernel transfers it from rdllist to your events[] array via copy_to_user(). Inside conn_flush, your write() call copies bytes from your write buffer into the kernel&#39;s send buffer. The kernel hands these to the TCP stack, which segments them and queues them to the NIC.\nLevel 3 â€” Hardware: The kernel&#39;s TCP stack queues a DMA (Direct Memory Access) descriptor to the NIC&#39;s TX ring. The NIC&#39;s DMA engine reads from a kernel memory region (pinned, not pageable) directlyâ€”no CPU involvement. The NIC serializes bytes to the wire at line rate (1 Gbps â†’ 125 MB/s). An interrupt fires when the TX ring entry completes (or is batched with NAPI polling), at which point the kernel marks the send buffer space as free and can trigger another EPOLLOUT if you still have data to send. The write path in conn_flushâ€”write() â†’ kernel TCP â†’ NIC DMAâ€”takes roughly 1â€“5 Âµs end-to-end on a modern server.","id":"let39s-trace-what-happens-from-kernel-to-hardware-when-a-slow-client39s-socket-buffer-finally-drains-and-epollout-fires-level-1-application-your-event-loop-calls-epoll_wait-it-returns-with-epollout-set-for-fd-42-your-code-calls-conn_flushepoll_fd-ampconnections42-level-2-oskernel-when-the-nic-sent-tcp-segments-and-received-acks-from-the-remote-client-the-kernel39s-tcp-stack-freed-space-in-the-socket39s-send-buffer-sk_send_head-advances-the-socket39s-sock_def_write_space-callback-fires-which-wakes-the-epoll-subsystem-the-epoll-epitem-for-fd-42-is-placed-on-the-ready-list-rdllist-on-your-next-epoll_wait-the-kernel-transfers-it-from-rdllist-to-your-events-array-via-copy_to_user-inside-conn_flush-your-write-call-copies-bytes-from-your-write-buffer-into-the-kernel39s-send-buffer-the-kernel-hands-these-to-the-tcp-stack-which-segments-them-and-queues-them-to-the-nic-level-3-hardware-the-kernel39s-tcp-stack-queues-a-dma-direct-memory-access-descriptor-to-the-nic39s-tx-ring-the-nic39s-dma-engine-reads-from-a-kernel-memory-region-pinned-not-pageable-directlyno-cpu-involvement-the-nic-serializes-bytes-to-the-wire-at-line-rate-1-gbps-125-mbs-an-interrupt-fires-when-the-tx-ring-entry-completes-or-is-batched-with-napi-polling-at-which-point-the-kernel-marks-the-send-buffer-space-as-free-and-can-trigger-another-epollout-if-you-still-have-data-to-send-the-write-path-in-conn_flushwrite-kernel-tcp-nic-dmatakes-roughly-15-s-end-to-end-on-a-modern-server"},{"level":2,"text":"Putting It All Together: Testing the Implementation","id":"putting-it-all-together-testing-the-implementation"},{"level":2,"text":"Hardware Soul: Memory and Cache Analysis","id":"hardware-soul-memory-and-cache-analysis"},{"level":2,"text":"Write buffer access pattern: When conn_write is on the hot path (every response triggers a write attempt), the write_buf struct and the first cache line of wb-&gt;data will be L1-hot for recently active connections. For 10K connections with uniform activity, the working set is 10,000 Ã— (24 bytes struct + 4KB average buffer) â‰ˆ 40 MBâ€”fitting in L3 cache on a server CPU but exceeding L1/L2. Connections not recently active will cause L3 cache misses on first access (40 cycles each).\nTimer heap cache behavior: The full heap at 65,536 entries is 768 KBâ€”fits in L2 cache (typically 256 KBâ€“2 MB) on modern server CPUs. heap_sift_down from the root accesses indices 0, 1 or 2, 3 or 4, 5â€“6 or 7â€“8... The first 3â€“4 levels (15 nodes, 180 bytes) fit in 3 cache lines. Logâ‚‚(10,000) â‰ˆ 13 levels deep means a sift operation touches ~13 cache linesâ€”mostly L1-hot for the top levels, L2-warm for lower levels.\nclock_gettime cost: Each now_ms() call is a vDSO (virtual Dynamic Shared Object) callâ€”the kernel maps a page into your process&#39;s address space containing a fast timekeeping function that reads from a shared memory region updated by the kernel, avoiding a full syscall context switch. On modern Linux with CLOCK_MONOTONIC, this costs ~30â€“50 ns rather than the ~200 ns of a real syscall. You call now_ms() at least twice per epoll_wait return (once for timer_process_expired, once for timer reset on data receipt)â€”roughly 100 ns total per event loop iteration.\nBranch prediction in heap_sift_down: The comparison timer_heap[left].expiry_ms &lt; timer_heap[smallest].expiry_ms is genuinely unpredictableâ€”timer expiries are scattered. The branch predictor achieves ~50% accuracy here. At 15-cycle misprediction cost, 13 comparisons per sift Ã— 50% misprediction rate Ã— 15 cycles â‰ˆ 97 cycles of branch misprediction per timer operation. This is acceptableâ€”timer operations happen at most once per connection per event loop tick.","id":"write-buffer-access-pattern-when-conn_write-is-on-the-hot-path-every-response-triggers-a-write-attempt-the-write_buf-struct-and-the-first-cache-line-of-wb-gtdata-will-be-l1-hot-for-recently-active-connections-for-10k-connections-with-uniform-activity-the-working-set-is-10000-24-bytes-struct-4kb-average-buffer-40-mbfitting-in-l3-cache-on-a-server-cpu-but-exceeding-l1l2-connections-not-recently-active-will-cause-l3-cache-misses-on-first-access-40-cycles-each-timer-heap-cache-behavior-the-full-heap-at-65536-entries-is-768-kbfits-in-l2-cache-typically-256-kb2-mb-on-modern-server-cpus-heap_sift_down-from-the-root-accesses-indices-0-1-or-2-3-or-4-56-or-78-the-first-34-levels-15-nodes-180-bytes-fit-in-3-cache-lines-log10000-13-levels-deep-means-a-sift-operation-touches-13-cache-linesmostly-l1-hot-for-the-top-levels-l2-warm-for-lower-levels-clock_gettime-cost-each-now_ms-call-is-a-vdso-virtual-dynamic-shared-object-callthe-kernel-maps-a-page-into-your-process39s-address-space-containing-a-fast-timekeeping-function-that-reads-from-a-shared-memory-region-updated-by-the-kernel-avoiding-a-full-syscall-context-switch-on-modern-linux-with-clock_monotonic-this-costs-3050-ns-rather-than-the-200-ns-of-a-real-syscall-you-call-now_ms-at-least-twice-per-epoll_wait-return-once-for-timer_process_expired-once-for-timer-reset-on-data-receiptroughly-100-ns-total-per-event-loop-iteration-branch-prediction-in-heap_sift_down-the-comparison-timer_heapleftexpiry_ms-lt-timer_heapsmallestexpiry_ms-is-genuinely-unpredictabletimer-expiries-are-scattered-the-branch-predictor-achieves-50-accuracy-here-at-15-cycle-misprediction-cost-13-comparisons-per-sift-50-misprediction-rate-15-cycles-97-cycles-of-branch-misprediction-per-timer-operation-this-is-acceptabletimer-operations-happen-at-most-once-per-connection-per-event-loop-tick"},{"level":2,"text":"Design Decision: Min-Heap vs Timer Wheel","id":"design-decision-min-heap-vs-timer-wheel"},{"level":2,"text":"Knowledge Cascade: What This Unlocks","id":"knowledge-cascade-what-this-unlocks"},{"level":2,"text":"Redis&#39;s write-behind pattern: Redis&#39;s event loop (ae.c) implements exactly the EPOLLOUT register-flush-deregister cycle you just built. When a Redis command generates a reply, ae.c calls aeCreateFileEvent(el, c-&gt;fd, AE_WRITABLE, sendReplyToClient, c). After sendReplyToClient drains c-&gt;buf, it calls aeDeleteFileEvent(el, c-&gt;fd, AE_WRITABLE). This is how Redis serves 100K+ clients/second without a dedicated writer threadâ€”the same pattern, scaled. The Redis source in networking.c:writeToClient() is worth reading alongside what you&#39;ve built here; you&#39;ll recognize every decision.\nThe Go runtime&#39;s timer integration: Go&#39;s runtime uses an epoll_wait-based netpoller (in runtime/netpoll_epoll.go) with the same timeout trick you implemented. When a goroutine calls time.After(30 * time.Second), the runtime inserts a timer into a min-heap (in runtime/time.go) and adjusts the next epoll_wait timeout. When epoll_wait times out, the runtime fires timer callbacks, which resume sleeping goroutines. You&#39;ve now implemented, in C and from scratch, the exact mechanism that makes Go&#39;s time.Sleep and context.WithTimeout work without OS threads.\ntimerfd_create for sub-millisecond timers: Your current implementation has 1ms timer resolutionâ€”epoll_wait&#39;s timeout is in integer milliseconds. For timers needing microsecond precision (real-time audio, trading systems, sensor fusion), use timerfd_create(CLOCK_MONOTONIC, TFD_NONBLOCK). This creates a file descriptor that becomes readable when a timer expiresâ€”you register it with epoll like any other fd. timerfd_settime accepts nanosecond precision. The tradeoff: one fd per timer, vs your heap&#39;s single timeout parameter covering all timers. Use timerfd when you need precision; use the heap timeout pattern when you need scale.\nSlow loris: the attack you&#39;ve already defended against: WRITE_BUF_MAX is your first line of defense against the slow loris HTTP attack (documented by Robert Hansen, 2009). The attack sends partial HTTP requests (just enough to look like valid traffic) and never completes them, holding connections open indefinitely. Your idle timeout is the second defense: any connection that hasn&#39;t sent a complete request in 30 seconds is closed. Production servers combine both: WRITE_BUF_MAX guards against slow readers, idle timeout guards against slow senders. Together they bound both memory consumption and fd exhaustion.\nio_uring and timer integration: In io_uring (Linux 5.1+), the IORING_OP_TIMEOUT operation submits a timer to the ring without an external fd. The completion event fires after N nanoseconds. Combined with IORING_OP_LINK_TIMEOUT, you can automatically cancel an in-flight read if it doesn&#39;t complete within a deadlineâ€”something epoll cannot express natively. Understanding your current epoll_wait timeout mechanism is the prerequisite for understanding why io_uring&#39;s timeout model is more expressive.","id":"redis39s-write-behind-pattern-redis39s-event-loop-aec-implements-exactly-the-epollout-register-flush-deregister-cycle-you-just-built-when-a-redis-command-generates-a-reply-aec-calls-aecreatefileeventel-c-gtfd-ae_writable-sendreplytoclient-c-after-sendreplytoclient-drains-c-gtbuf-it-calls-aedeletefileeventel-c-gtfd-ae_writable-this-is-how-redis-serves-100k-clientssecond-without-a-dedicated-writer-threadthe-same-pattern-scaled-the-redis-source-in-networkingcwritetoclient-is-worth-reading-alongside-what-you39ve-built-here-you39ll-recognize-every-decision-the-go-runtime39s-timer-integration-go39s-runtime-uses-an-epoll_wait-based-netpoller-in-runtimenetpoll_epollgo-with-the-same-timeout-trick-you-implemented-when-a-goroutine-calls-timeafter30-timesecond-the-runtime-inserts-a-timer-into-a-min-heap-in-runtimetimego-and-adjusts-the-next-epoll_wait-timeout-when-epoll_wait-times-out-the-runtime-fires-timer-callbacks-which-resume-sleeping-goroutines-you39ve-now-implemented-in-c-and-from-scratch-the-exact-mechanism-that-makes-go39s-timesleep-and-contextwithtimeout-work-without-os-threads-timerfd_create-for-sub-millisecond-timers-your-current-implementation-has-1ms-timer-resolutionepoll_wait39s-timeout-is-in-integer-milliseconds-for-timers-needing-microsecond-precision-real-time-audio-trading-systems-sensor-fusion-use-timerfd_createclock_monotonic-tfd_nonblock-this-creates-a-file-descriptor-that-becomes-readable-when-a-timer-expiresyou-register-it-with-epoll-like-any-other-fd-timerfd_settime-accepts-nanosecond-precision-the-tradeoff-one-fd-per-timer-vs-your-heap39s-single-timeout-parameter-covering-all-timers-use-timerfd-when-you-need-precision-use-the-heap-timeout-pattern-when-you-need-scale-slow-loris-the-attack-you39ve-already-defended-against-write_buf_max-is-your-first-line-of-defense-against-the-slow-loris-http-attack-documented-by-robert-hansen-2009-the-attack-sends-partial-http-requests-just-enough-to-look-like-valid-traffic-and-never-completes-them-holding-connections-open-indefinitely-your-idle-timeout-is-the-second-defense-any-connection-that-hasn39t-sent-a-complete-request-in-30-seconds-is-closed-production-servers-combine-both-write_buf_max-guards-against-slow-readers-idle-timeout-guards-against-slow-senders-together-they-bound-both-memory-consumption-and-fd-exhaustion-io_uring-and-timer-integration-in-io_uring-linux-51-the-ioring_op_timeout-operation-submits-a-timer-to-the-ring-without-an-external-fd-the-completion-event-fires-after-n-nanoseconds-combined-with-ioring_op_link_timeout-you-can-automatically-cancel-an-in-flight-read-if-it-doesn39t-complete-within-a-deadlinesomething-epoll-cannot-express-natively-understanding-your-current-epoll_wait-timeout-mechanism-is-the-prerequisite-for-understanding-why-io_uring39s-timeout-model-is-more-expressive"},{"level":2,"text":"Pitfall Reference: The Five Ways This Breaks","id":"pitfall-reference-the-five-ways-this-breaks"},{"level":2,"text":"Pitfall 1: Leaving EPOLLOUT armed when write buffer is empty\nSymptom: 100% CPU usage even with zero active connections; top shows your server spinning.\nFix: In conn_flush, always call epoll_ctl(EPOLL_CTL_MOD) to remove EPOLLOUT when wbuf_is_empty() returns true.\nPitfall 2: Not processing all expired timers per tick\nSymptom: Under load, connections stay open far past their idle timeout; timer heap grows unboundedly.\nFix: timer_process_expired loops while (timer_heap_size &gt; 0 &amp;&amp; timer_heap[0].expiry_ms &lt;= now). Do not break after the first expiry.\nPitfall 3: Missing timer_cancel in conn_close\nSymptom: After a connection closes, the timer fires and conn_close is called again on an already-freed (now potentially reused) fdâ€”classic use-after-free.\nFix: Always cancel the timer in conn_close, and guard with if (!c-&gt;active) return at the top of conn_close.\nPitfall 4: Timer wheel slot count not a power of 2\n(If you implement a timer wheel instead of a min-heap)\nSymptom: Modulo operation is expensive (integer division instead of bitwise AND); performance degradation visible in profiling.\nFix: Use wheel size as a power of 2 (e.g., 256, 512); compute slot as (now_ms / resolution) &amp; (WHEEL_SIZE - 1).\nPitfall 5: Closing a connection without freeing the write buffer\nSymptom: Memory leak at ~4 KB per closed connection; server RSS grows unboundedly over hours.\nFix: conn_close must call wbuf_free(&amp;c-&gt;wbuf). Verify with valgrind --leak-check=full ./echo_server_m2 under connection churn.","id":"pitfall-1-leaving-epollout-armed-when-write-buffer-is-empty-symptom-100-cpu-usage-even-with-zero-active-connections-top-shows-your-server-spinning-fix-in-conn_flush-always-call-epoll_ctlepoll_ctl_mod-to-remove-epollout-when-wbuf_is_empty-returns-true-pitfall-2-not-processing-all-expired-timers-per-tick-symptom-under-load-connections-stay-open-far-past-their-idle-timeout-timer-heap-grows-unboundedly-fix-timer_process_expired-loops-while-timer_heap_size-gt-0-ampamp-timer_heap0expiry_ms-lt-now-do-not-break-after-the-first-expiry-pitfall-3-missing-timer_cancel-in-conn_close-symptom-after-a-connection-closes-the-timer-fires-and-conn_close-is-called-again-on-an-already-freed-now-potentially-reused-fdclassic-use-after-free-fix-always-cancel-the-timer-in-conn_close-and-guard-with-if-c-gtactive-return-at-the-top-of-conn_close-pitfall-4-timer-wheel-slot-count-not-a-power-of-2-if-you-implement-a-timer-wheel-instead-of-a-min-heap-symptom-modulo-operation-is-expensive-integer-division-instead-of-bitwise-and-performance-degradation-visible-in-profiling-fix-use-wheel-size-as-a-power-of-2-eg-256-512-compute-slot-as-now_ms-resolution-amp-wheel_size-1-pitfall-5-closing-a-connection-without-freeing-the-write-buffer-symptom-memory-leak-at-4-kb-per-closed-connection-server-rss-grows-unboundedly-over-hours-fix-conn_close-must-call-wbuf_freeampc-gtwbuf-verify-with-valgrind-leak-checkfull-echo_server_m2-under-connection-churn"},{"level":1,"text":"Reactor API and Callback Dispatch","id":"reactor-api-and-callback-dispatch"},{"level":2,"text":"The Problem With What You&#39;ve Built So Far","id":"the-problem-with-what-you39ve-built-so-far"},{"level":2,"text":"The Revelation: Modifying State During Iteration Is a Minefield","id":"the-revelation-modifying-state-during-iteration-is-a-minefield"},{"level":2,"text":"Designing the Reactor API","id":"designing-the-reactor-api"},{"level":2,"text":"The Internal Structure: What the Reactor Holds","id":"the-internal-structure-what-the-reactor-holds"},{"level":2,"text":"The key fields are dispatching, zombie on each fd_handler, and the mods queue. Together they implement the deferred-modification pattern.","id":"the-key-fields-are-dispatching-zombie-on-each-fd_handler-and-the-mods-queue-together-they-implement-the-deferred-modification-pattern"},{"level":2,"text":"Creating and Destroying the Reactor","id":"creating-and-destroying-the-reactor"},{"level":2,"text":"Registering and Deregistering fd Handlers","id":"registering-and-deregistering-fd-handlers"},{"level":2,"text":"The Deferred Task Queue","id":"the-deferred-task-queue"},{"level":2,"text":"Timer Integration: One-Shot and Repeating","id":"timer-integration-one-shot-and-repeating"},{"level":2,"text":"The Complete Dispatch Loop","id":"the-complete-dispatch-loop"},{"level":2,"text":"Handling EPOLLHUP and EPOLLERR Correctly","id":"handling-epollhup-and-epollerr-correctly"},{"level":2,"text":"Writing Applications Against the Reactor","id":"writing-applications-against-the-reactor"},{"level":2,"text":"The Three-Level View: One Callback Invocation","id":"the-three-level-view-one-callback-invocation"},{"level":2,"text":"Let&#39;s trace a single callback invocation from hardware interrupt to your application code.\nLevel 3 â€” Hardware: The NIC receives a TCP segment from a client. Its DMA engine writes the payload directly into a kernel memory region (the socket&#39;s receive queue) without CPU involvement. The NIC raises an interrupt line. The CPU pauses its current instruction stream, saves registers, and jumps to the interrupt handler.\nLevel 2 â€” OS/Kernel: The interrupt handler (running in interrupt context, non-preemptible) dequeues the packet from the NIC&#39;s RX ring buffer and places it in the socket&#39;s sk_receive_queue. It calls sk-&gt;sk_data_ready(sk)â€”the socket&#39;s readiness callbackâ€”which wakes the epoll subsystem. The epoll epitem for this fd is moved from the &quot;sleeping&quot; list to rdllist (the ready list). The interrupt handler returns. The kernel resumes the process that was running (your event loop, sleeping in epoll_wait). The kernel&#39;s epoll_wait implementation walks rdllist, copies {events, data} pairs into your user-space events[] array via copy_to_user(), and returns the count.\nLevel 1 â€” Application: Your reactor_run loop receives n_ready. It iterates the events[] array. For each event, it reads events[i].data.ptr, casts it to fd_handler *, checks the zombie flag, maps the epoll event flags to REACTOR_* flags, and calls h-&gt;callback(fd, r_events, h-&gt;user_data). Your application code runs. One TCP segment, one DMA transfer, one interrupt, one syscall return, one array index, one function pointer dereference.\nThe entire path from NIC interrupt to your echo_readable function runs in under 5 Âµs on a modern serverâ€”wire-to-callback latency. This is what makes event-driven servers fast: no thread switching, no scheduler involvement, no stack swaps. One path, end to end.","id":"let39s-trace-a-single-callback-invocation-from-hardware-interrupt-to-your-application-code-level-3-hardware-the-nic-receives-a-tcp-segment-from-a-client-its-dma-engine-writes-the-payload-directly-into-a-kernel-memory-region-the-socket39s-receive-queue-without-cpu-involvement-the-nic-raises-an-interrupt-line-the-cpu-pauses-its-current-instruction-stream-saves-registers-and-jumps-to-the-interrupt-handler-level-2-oskernel-the-interrupt-handler-running-in-interrupt-context-non-preemptible-dequeues-the-packet-from-the-nic39s-rx-ring-buffer-and-places-it-in-the-socket39s-sk_receive_queue-it-calls-sk-gtsk_data_readyskthe-socket39s-readiness-callbackwhich-wakes-the-epoll-subsystem-the-epoll-epitem-for-this-fd-is-moved-from-the-quotsleepingquot-list-to-rdllist-the-ready-list-the-interrupt-handler-returns-the-kernel-resumes-the-process-that-was-running-your-event-loop-sleeping-in-epoll_wait-the-kernel39s-epoll_wait-implementation-walks-rdllist-copies-events-data-pairs-into-your-user-space-events-array-via-copy_to_user-and-returns-the-count-level-1-application-your-reactor_run-loop-receives-n_ready-it-iterates-the-events-array-for-each-event-it-reads-eventsidataptr-casts-it-to-fd_handler-checks-the-zombie-flag-maps-the-epoll-event-flags-to-reactor_-flags-and-calls-h-gtcallbackfd-r_events-h-gtuser_data-your-application-code-runs-one-tcp-segment-one-dma-transfer-one-interrupt-one-syscall-return-one-array-index-one-function-pointer-dereference-the-entire-path-from-nic-interrupt-to-your-echo_readable-function-runs-in-under-5-s-on-a-modern-serverwire-to-callback-latency-this-is-what-makes-event-driven-servers-fast-no-thread-switching-no-scheduler-involvement-no-stack-swaps-one-path-end-to-end"},{"level":2,"text":"Hardware Soul: Cache Analysis of the Dispatch Loop","id":"hardware-soul-cache-analysis-of-the-dispatch-loop"},{"level":2,"text":"The dispatch loop&#39;s hot path touches several memory regions. Understanding their cache behavior reveals why the design choices above matter at scale.\nevents[] array: Allocated on the stack in reactor_run. With MAX_EVENTS=1024 and sizeof(struct epoll_event)=12 bytes: 12,288 bytes, fits in L1 cache (typically 32â€“64 KB). Iterating over it is sequential and prefetch-friendlyâ€”the hardware prefetcher recognizes stride-1 access and loads upcoming cache lines before you need them. This array is cache-hot for the entire dispatch loop.\nfd_handler handlers[]: The registration table is MAX_FDS Ã— 24 bytes = 1.5 MB. This does not fit in L1 or L2 (typically 256 KBâ€“2 MB), and barely fits in L3 (typically 8â€“32 MB). Accessing handlers[fd] for a non-recently-seen fd is an L3 cache miss (~40 ns). Under 10K active connections with uniform distribution, the working set of recently-accessed handler entries is 10,000 Ã— 24 = 240 KBâ€”fits in L2. Connections accessed infrequently (idle connections) will cache-miss on every event, but that&#39;s acceptable because they&#39;re rare.\ndata.ptr vs data.fd dispatch: When you store data.ptr = &amp;handlers[fd], retrieving the handler requires one pointer dereference. When you use data.fd, you&#39;d need handlers[events[i].data.fd]â€”one array access with multiplication. The pointer approach saves 3â€“5 cycles per event on average, because the pointer is already the exact memory address. However, it means the events[] array holds pointers into the handlers[] arrayâ€”if handlers[] is ever reallocated (it isn&#39;t in our fixed-size design), all stored pointers become dangling. This is why we use a fixed-size array, not a dynamic one.\nDeferred mods queue: Typically empty (most calls happen outside dispatch). When non-empty, it&#39;s small (a handful of entries per tick), always fits in L1. Applying deferred mods after dispatch is fast.\nThe zombie flag: Checking h-&gt;zombie is a single byte read. For a recently-closed fd whose handler is in L1 cache, this is essentially free. The branch itself is nearly always not-taken (zombie fds are rare) and quickly predicted by the branch predictor.","id":"the-dispatch-loop39s-hot-path-touches-several-memory-regions-understanding-their-cache-behavior-reveals-why-the-design-choices-above-matter-at-scale-events-array-allocated-on-the-stack-in-reactor_run-with-max_events1024-and-sizeofstruct-epoll_event12-bytes-12288-bytes-fits-in-l1-cache-typically-3264-kb-iterating-over-it-is-sequential-and-prefetch-friendlythe-hardware-prefetcher-recognizes-stride-1-access-and-loads-upcoming-cache-lines-before-you-need-them-this-array-is-cache-hot-for-the-entire-dispatch-loop-fd_handler-handlers-the-registration-table-is-max_fds-24-bytes-15-mb-this-does-not-fit-in-l1-or-l2-typically-256-kb2-mb-and-barely-fits-in-l3-typically-832-mb-accessing-handlersfd-for-a-non-recently-seen-fd-is-an-l3-cache-miss-40-ns-under-10k-active-connections-with-uniform-distribution-the-working-set-of-recently-accessed-handler-entries-is-10000-24-240-kbfits-in-l2-connections-accessed-infrequently-idle-connections-will-cache-miss-on-every-event-but-that39s-acceptable-because-they39re-rare-dataptr-vs-datafd-dispatch-when-you-store-dataptr-amphandlersfd-retrieving-the-handler-requires-one-pointer-dereference-when-you-use-datafd-you39d-need-handlerseventsidatafdone-array-access-with-multiplication-the-pointer-approach-saves-35-cycles-per-event-on-average-because-the-pointer-is-already-the-exact-memory-address-however-it-means-the-events-array-holds-pointers-into-the-handlers-arrayif-handlers-is-ever-reallocated-it-isn39t-in-our-fixed-size-design-all-stored-pointers-become-dangling-this-is-why-we-use-a-fixed-size-array-not-a-dynamic-one-deferred-mods-queue-typically-empty-most-calls-happen-outside-dispatch-when-non-empty-it39s-small-a-handful-of-entries-per-tick-always-fits-in-l1-applying-deferred-mods-after-dispatch-is-fast-the-zombie-flag-checking-h-gtzombie-is-a-single-byte-read-for-a-recently-closed-fd-whose-handler-is-in-l1-cache-this-is-essentially-free-the-branch-itself-is-nearly-always-not-taken-zombie-fds-are-rare-and-quickly-predicted-by-the-branch-predictor"},{"level":2,"text":"Design Decision: Which Deferred-Modification Strategy?","id":"design-decision-which-deferred-modification-strategy"},{"level":2,"text":"Testing the Reactor: A Validation Suite","id":"testing-the-reactor-a-validation-suite"},{"level":2,"text":"Knowledge Cascade: What This Unlocks","id":"knowledge-cascade-what-this-unlocks"},{"level":2,"text":"Pitfall Reference: The Five Ways This Breaks","id":"pitfall-reference-the-five-ways-this-breaks"},{"level":2,"text":"Pitfall 1: Modifying the fd_handler table during dispatch without zombie protection\nSymptom: Callbacks fire for connections that were closed earlier in the same event batch; data sent to wrong clients; occasional segfault in callback dispatch.\nFix: Set h-&gt;zombie = true in reactor_deregister when r-&gt;dispatching == true. Check h-&gt;zombie at the start of each dispatch iteration.\nPitfall 2: Deferred tasks running interleaved with I/O dispatch\nSymptom: A deferred task that closes a connection runs before all events for that connection are processed; the later events dispatch to freed state.\nFix: Run reactor_run_deferred AFTER the for (i = 0; i &lt; n; i++) dispatch loop completes, not inside it.\nPitfall 3: A timer callback that cancels itself for an interval timer\nSymptom: reactor_cancel_timer modifies the heap during reactor_process_timers&#39;s iteration; heap invariant violated; subsequent timer operations use wrong entries.\nFix: In interval timer callbacks that want to stop, use reactor_defer to cancel the timer after reactor_process_timers returns. Alternatively, set a flag and check it before re-arming.\nPitfall 4: Not clearing the zombie flag on re-registration\nSymptom: A callback closes an fd, the fd is immediately reused by accept4, reactor_register is called for the new connection, but the callback is never invoked because h-&gt;zombie is still true.\nFix: In reactor_register, always set h-&gt;zombie = false. Re-registration on a zombie fd is a valid and common pattern.\nPitfall 5: EPOLLHUP without EPOLLIN â€” closing without reading remaining data\nSymptom: HTTP pipelining requests are silently dropped; the client sends a second request, closes the connection, but the server never processes the second request because it closes immediately on EPOLLHUP.\nFix: When REACTOR_HANGUP fires simultaneously with REACTOR_READABLE, always process readable data first. Check events &amp; REACTOR_READABLE before closing.","id":"pitfall-1-modifying-the-fd_handler-table-during-dispatch-without-zombie-protection-symptom-callbacks-fire-for-connections-that-were-closed-earlier-in-the-same-event-batch-data-sent-to-wrong-clients-occasional-segfault-in-callback-dispatch-fix-set-h-gtzombie-true-in-reactor_deregister-when-r-gtdispatching-true-check-h-gtzombie-at-the-start-of-each-dispatch-iteration-pitfall-2-deferred-tasks-running-interleaved-with-io-dispatch-symptom-a-deferred-task-that-closes-a-connection-runs-before-all-events-for-that-connection-are-processed-the-later-events-dispatch-to-freed-state-fix-run-reactor_run_deferred-after-the-for-i-0-i-lt-n-i-dispatch-loop-completes-not-inside-it-pitfall-3-a-timer-callback-that-cancels-itself-for-an-interval-timer-symptom-reactor_cancel_timer-modifies-the-heap-during-reactor_process_timers39s-iteration-heap-invariant-violated-subsequent-timer-operations-use-wrong-entries-fix-in-interval-timer-callbacks-that-want-to-stop-use-reactor_defer-to-cancel-the-timer-after-reactor_process_timers-returns-alternatively-set-a-flag-and-check-it-before-re-arming-pitfall-4-not-clearing-the-zombie-flag-on-re-registration-symptom-a-callback-closes-an-fd-the-fd-is-immediately-reused-by-accept4-reactor_register-is-called-for-the-new-connection-but-the-callback-is-never-invoked-because-h-gtzombie-is-still-true-fix-in-reactor_register-always-set-h-gtzombie-false-re-registration-on-a-zombie-fd-is-a-valid-and-common-pattern-pitfall-5-epollhup-without-epollin-closing-without-reading-remaining-data-symptom-http-pipelining-requests-are-silently-dropped-the-client-sends-a-second-request-closes-the-connection-but-the-server-never-processes-the-second-request-because-it-closes-immediately-on-epollhup-fix-when-reactor_hangup-fires-simultaneously-with-reactor_readable-always-process-readable-data-first-check-events-amp-reactor_readable-before-closing"},{"level":1,"text":"HTTP Server on Event Loop","id":"http-server-on-event-loop"},{"level":2,"text":"The Illusion That Breaks Under Load","id":"the-illusion-that-breaks-under-load"},{"level":2,"text":"The Per-Connection State Machine","id":"the-per-connection-state-machine"},{"level":2,"text":"The Incremental HTTP Parser","id":"the-incremental-http-parser"},{"level":2,"text":"Handling the Read Event: Accumulate, Parse, Dispatch","id":"handling-the-read-event-accumulate-parse-dispatch"},{"level":2,"text":"The critical insight in http_on_readable: http_parse_headers is called inside the read loop, after every successful read(). This is the incremental designâ€”don&#39;t wait for EAGAIN to try parsing. The moment you have more data, try. If headers are complete, process immediately without waiting for the next event. If they&#39;re not complete, the loop continues reading (or exits on EAGAIN, and the reactor will re-notify when more data arrives).\nThe memmove after parsing headers deserves attention. If your 16 KB read buffer received 512 bytes of headers followed by the first 128 bytes of a POST body, header_end points to byte 512. The body bytes (128 bytes) need to be at the front of the buffer for subsequent reads to append correctly. memmove slides them there. This is O(body_received) bytes copiedâ€”small for this use case, but worth noting for large streaming bodies where you&#39;d want a ring buffer or linked list of chunks.","id":"the-critical-insight-in-http_on_readable-http_parse_headers-is-called-inside-the-read-loop-after-every-successful-read-this-is-the-incremental-designdon39t-wait-for-eagain-to-try-parsing-the-moment-you-have-more-data-try-if-headers-are-complete-process-immediately-without-waiting-for-the-next-event-if-they39re-not-complete-the-loop-continues-reading-or-exits-on-eagain-and-the-reactor-will-re-notify-when-more-data-arrives-the-memmove-after-parsing-headers-deserves-attention-if-your-16-kb-read-buffer-received-512-bytes-of-headers-followed-by-the-first-128-bytes-of-a-post-body-header_end-points-to-byte-512-the-body-bytes-128-bytes-need-to-be-at-the-front-of-the-buffer-for-subsequent-reads-to-append-correctly-memmove-slides-them-there-this-is-obody_received-bytes-copiedsmall-for-this-use-case-but-worth-noting-for-large-streaming-bodies-where-you39d-want-a-ring-buffer-or-linked-list-of-chunks"},{"level":2,"text":"Processing the Request and Serving Static Files","id":"processing-the-request-and-serving-static-files"},{"level":2,"text":"HTTP/1.1 Keep-Alive: The State Machine&#39;s Cycle","id":"http11-keep-alive-the-state-machine39s-cycle"},{"level":2,"text":"Connection Lifecycle and Resource Cleanup","id":"connection-lifecycle-and-resource-cleanup"},{"level":2,"text":"Wiring It All Together: The Accept Path","id":"wiring-it-all-together-the-accept-path"},{"level":2,"text":"Preparing for C10K: System Configuration","id":"preparing-for-c10k-system-configuration"},{"level":2,"text":"Benchmarking: Verifying C10K","id":"benchmarking-verifying-c10k"},{"level":2,"text":"The most common performance cliff at C10K: the Linux kernel&#39;s TCP accept backlog filled because the accept loop ran too slowly. Increase net.core.somaxconn and verify with ss -lnt (look at the Recv-Q column for the listening socket; it should stay near 0).","id":"the-most-common-performance-cliff-at-c10k-the-linux-kernel39s-tcp-accept-backlog-filled-because-the-accept-loop-ran-too-slowly-increase-netcoresomaxconn-and-verify-with-ss-lnt-look-at-the-recv-q-column-for-the-listening-socket-it-should-stay-near-0"},{"level":2,"text":"The Slow Loris: Understanding the Attack You&#39;ve Already Defended Against","id":"the-slow-loris-understanding-the-attack-you39ve-already-defended-against"},{"level":2,"text":"The Three-Level View: One HTTP Request","id":"the-three-level-view-one-http-request"},{"level":2,"text":"Let&#39;s trace a complete HTTP GET request from the moment the NIC receives the TCP segment to the moment your http_process_request is called.\nLevel 3 â€” Hardware: A TCP segment carrying GET /test.html HTTP/1.1\\r\\nHost: bench\\r\\n\\r\\n arrives at the NIC. The NIC&#39;s DMA engine writes the payload into a kernel ring buffer (the NIC&#39;s RX ring) without CPU involvement. The NIC signals the CPU via an interrupt (or the kernel polls with NAPI to reduce interrupt overhead at high packet rates). The hardware interrupt fires.\nLevel 2 â€” OS/Kernel: The interrupt handler runs in interrupt context (non-preemptible, cannot sleep). It dequeues the packet from the NIC&#39;s RX ring, runs it through the network stack (net/ipv4/tcp_input.c): TCP checksum verification, sequence number validation, segment reassembly if fragmented. Reassembled data is placed into the socket&#39;s receive buffer (sk-&gt;sk_receive_queue). The socket&#39;s readiness callback firesâ€”sock_def_readableâ€”which wakes the epoll subsystem. The epitem for this fd moves from the wait queue to rdllist. At some point, your process (sleeping in epoll_wait) is scheduled by the kernel&#39;s CFS (Completely Fair Scheduler). The kernel copies the ready event from rdllist into your user-space events[] array via copy_to_user. epoll_wait returns.\nLevel 1 â€” Application: Your reactor_run loop reads n_ready = 1. It retrieves fd_handler *h = events[0].data.ptr. It calls h-&gt;callback(fd, REACTOR_READABLE, h-&gt;user_data). That&#39;s http_on_readable. Inside, read(fd, conn-&gt;read_buf + conn-&gt;read_len, space) copies bytes from kernel socket buffer to user space (another copy_to_user in reverseâ€”copy_to_user from kernel&#39;s perspective, data flows from kernel to your process). http_parse_headers scans the buffer, finds \\r\\n\\r\\n, populates conn-&gt;req. http_process_request opens /public/test.html, reads it, writes headers and body to conn-&gt;wbuf. On the next write() call, bytes flow from conn-&gt;wbuf back into the kernel&#39;s socket send buffer. The TCP stack segments them, queues DMA descriptors to the NIC&#39;s TX ring, and the NIC sends them on the wire.\nTotal latency from packet arrival to response queued for sending: roughly 50â€“200 Âµs on a modern server at low load. The dominant costs are the interrupt handling and scheduling latency (10â€“30 Âµs), the two memcpy operations (kernelâ†’receive buffer and receive bufferâ†’socket send buffer, each ~1â€“5 Âµs for KB-sized payloads), and the file read() call (5â€“20 Âµs for a cached file from page cache).","id":"let39s-trace-a-complete-http-get-request-from-the-moment-the-nic-receives-the-tcp-segment-to-the-moment-your-http_process_request-is-called-level-3-hardware-a-tcp-segment-carrying-get-testhtml-http11rnhost-benchrnrn-arrives-at-the-nic-the-nic39s-dma-engine-writes-the-payload-into-a-kernel-ring-buffer-the-nic39s-rx-ring-without-cpu-involvement-the-nic-signals-the-cpu-via-an-interrupt-or-the-kernel-polls-with-napi-to-reduce-interrupt-overhead-at-high-packet-rates-the-hardware-interrupt-fires-level-2-oskernel-the-interrupt-handler-runs-in-interrupt-context-non-preemptible-cannot-sleep-it-dequeues-the-packet-from-the-nic39s-rx-ring-runs-it-through-the-network-stack-netipv4tcp_inputc-tcp-checksum-verification-sequence-number-validation-segment-reassembly-if-fragmented-reassembled-data-is-placed-into-the-socket39s-receive-buffer-sk-gtsk_receive_queue-the-socket39s-readiness-callback-firessock_def_readablewhich-wakes-the-epoll-subsystem-the-epitem-for-this-fd-moves-from-the-wait-queue-to-rdllist-at-some-point-your-process-sleeping-in-epoll_wait-is-scheduled-by-the-kernel39s-cfs-completely-fair-scheduler-the-kernel-copies-the-ready-event-from-rdllist-into-your-user-space-events-array-via-copy_to_user-epoll_wait-returns-level-1-application-your-reactor_run-loop-reads-n_ready-1-it-retrieves-fd_handler-h-events0dataptr-it-calls-h-gtcallbackfd-reactor_readable-h-gtuser_data-that39s-http_on_readable-inside-readfd-conn-gtread_buf-conn-gtread_len-space-copies-bytes-from-kernel-socket-buffer-to-user-space-another-copy_to_user-in-reversecopy_to_user-from-kernel39s-perspective-data-flows-from-kernel-to-your-process-http_parse_headers-scans-the-buffer-finds-rnrn-populates-conn-gtreq-http_process_request-opens-publictesthtml-reads-it-writes-headers-and-body-to-conn-gtwbuf-on-the-next-write-call-bytes-flow-from-conn-gtwbuf-back-into-the-kernel39s-socket-send-buffer-the-tcp-stack-segments-them-queues-dma-descriptors-to-the-nic39s-tx-ring-and-the-nic-sends-them-on-the-wire-total-latency-from-packet-arrival-to-response-queued-for-sending-roughly-50200-s-on-a-modern-server-at-low-load-the-dominant-costs-are-the-interrupt-handling-and-scheduling-latency-1030-s-the-two-memcpy-operations-kernelreceive-buffer-and-receive-buffersocket-send-buffer-each-15-s-for-kb-sized-payloads-and-the-file-read-call-520-s-for-a-cached-file-from-page-cache"},{"level":2,"text":"Hardware Soul: What Limits Your Throughput","id":"hardware-soul-what-limits-your-throughput"},{"level":2,"text":"At 10,000 concurrent connections with a 1.3 KB response file, what are the hardware bottlenecks?\nMemory bandwidth: Each request involves reading 17 KB of http_conn state (cold connections cache-miss) plus the file data from page cache. At 80,000 requests/second and 17 KB per connection access, that&#39;s 1.36 GB/s of memory readsâ€”well within a modern CPU&#39;s 40â€“80 GB/s memory bandwidth. Memory is not the bottleneck here.\nCache pressure: Your 10,000 active connections occupy 10,000 Ã— 17 KB = 170 MB of heap memory. L3 cache is typically 8â€“32 MB. Most http_conn structures are cold in cache; accessing one for the first time costs an L3 miss (40 cycles). Under heavy load where the same connections are active repeatedly, the working set shrinks to recently-active connections and the cache hit rate improves. The per-connection state size is therefore a real performance dialâ€”halving it (8 KB instead of 16 KB for the read buffer) approximately doubles the number of &quot;warm&quot; connections that fit in L3.\nSystem call overhead: Each request involves epoll_wait (1 syscall), read (1 syscall), stat (1 syscall), open (1 syscall), read (file, possibly multiple syscalls), write (1+ syscalls). At 80,000 req/s, that&#39;s roughly 480,000 syscalls/second. Each syscall costs ~200 ns (context switch to kernel and back). At 480K syscalls/s: 96 ms of CPU time per second just in syscall overheadâ€”about 10% of one CPU core. This is measurable and motivates sendfile() (eliminates the read+write pair for static files) and io_uring (eliminates the per-syscall context switch overhead entirely).\nBranch prediction: The parser&#39;s find_header_end scan has a branch (the \\r\\n\\r\\n check) that&#39;s almost always not-taken until the very end of the headers. The branch predictor learns this quickly. The state machine transitions (conn-&gt;state == HTTP_READING_HEADERS) are nearly always predictable because connections spend much more time reading than transitioning.","id":"at-10000-concurrent-connections-with-a-13-kb-response-file-what-are-the-hardware-bottlenecks-memory-bandwidth-each-request-involves-reading-17-kb-of-http_conn-state-cold-connections-cache-miss-plus-the-file-data-from-page-cache-at-80000-requestssecond-and-17-kb-per-connection-access-that39s-136-gbs-of-memory-readswell-within-a-modern-cpu39s-4080-gbs-memory-bandwidth-memory-is-not-the-bottleneck-here-cache-pressure-your-10000-active-connections-occupy-10000-17-kb-170-mb-of-heap-memory-l3-cache-is-typically-832-mb-most-http_conn-structures-are-cold-in-cache-accessing-one-for-the-first-time-costs-an-l3-miss-40-cycles-under-heavy-load-where-the-same-connections-are-active-repeatedly-the-working-set-shrinks-to-recently-active-connections-and-the-cache-hit-rate-improves-the-per-connection-state-size-is-therefore-a-real-performance-dialhalving-it-8-kb-instead-of-16-kb-for-the-read-buffer-approximately-doubles-the-number-of-quotwarmquot-connections-that-fit-in-l3-system-call-overhead-each-request-involves-epoll_wait-1-syscall-read-1-syscall-stat-1-syscall-open-1-syscall-read-file-possibly-multiple-syscalls-write-1-syscalls-at-80000-reqs-that39s-roughly-480000-syscallssecond-each-syscall-costs-200-ns-context-switch-to-kernel-and-back-at-480k-syscallss-96-ms-of-cpu-time-per-second-just-in-syscall-overheadabout-10-of-one-cpu-core-this-is-measurable-and-motivates-sendfile-eliminates-the-readwrite-pair-for-static-files-and-io_uring-eliminates-the-per-syscall-context-switch-overhead-entirely-branch-prediction-the-parser39s-find_header_end-scan-has-a-branch-the-rnrn-check-that39s-almost-always-not-taken-until-the-very-end-of-the-headers-the-branch-predictor-learns-this-quickly-the-state-machine-transitions-conn-gtstate-http_reading_headers-are-nearly-always-predictable-because-connections-spend-much-more-time-reading-than-transitioning"},{"level":2,"text":"Knowledge Cascade: Five Connections to Carry Forward","id":"knowledge-cascade-five-connections-to-carry-forward"},{"level":3,"text":"1. Protocol Buffers and gRPC Framing (Cross-Domain: Distributed Systems)","id":"1-protocol-buffers-and-grpc-framing-cross-domain-distributed-systems"},{"level":3,"text":"2. Database Wire Protocols (Cross-Domain: Databases)","id":"2-database-wire-protocols-cross-domain-databases"},{"level":3,"text":"3. Zero-Copy I/O with sendfile()","id":"3-zero-copy-io-with-sendfile"},{"level":3,"text":"4. HTTP/1.1 Head-of-Line Blocking and the Path to HTTP/2","id":"4-http11-head-of-line-blocking-and-the-path-to-http2"},{"level":3,"text":"5. The Slow Loris at Protocol Level","id":"5-the-slow-loris-at-protocol-level"},{"level":2,"text":"Pitfall Reference: The Six Ways This Breaks","id":"pitfall-reference-the-six-ways-this-breaks"},{"level":2,"text":"Pitfall 1: Expecting complete headers in a single read() call\nSymptom: Works perfectly on localhost, fails intermittently in production or under wrk load test. Requests over ~1400 bytes (MTU) fail at the 95th percentile.\nFix: Always accumulate into a buffer and call the parser after each read(). Never assume read() returns complete headers.\nPitfall 2: Write buffer growing unboundedly for slow clients\nSymptom: Server RSS grows steadily under load; eventually OOM-killed or exhausts heap.\nFix: Check wbuf_append return value; if -1 (buffer exceeded WRITE_BUF_MAX), close the connection immediately. Log when this happensâ€”it indicates slow clients or network issues.\nPitfall 3: Keep-alive without resetting the read buffer\nSymptom: Second request on a keep-alive connection fails to parse or gets garbage data mixed in.\nFix: http_conn_reset_for_keepalive must zero read_len and memset the req struct. Do not skip either step.\nPitfall 4: Path traversal vulnerability\nSymptom: GET /../../../etc/passwd serves /etc/passwd. Server leaks arbitrary files.\nFix: build_safe_path must reject any path containing ... Apply this check before any file system access.\nPitfall 5: Closing connection directly from within a callback\nSymptom: Occasional segfault or data sent to wrong client after high-churn periods.\nFix: Always use reactor_defer(r, http_conn_close_deferred, conn). Never call close(conn-&gt;fd) directly from within http_on_readable or http_on_writable. This is the core lesson from Milestone 3&#39;s zombie flag mechanism.\nPitfall 6: Not benchmarking with real file descriptors\nSymptom: Server appears healthy in initial testing; crashes or times out when wrk uses 10,000 connections.\nFix: Run ulimit -n 65536 before starting the server. Add assert(fd &lt; MAX_FDS) in the accept callback. Monitor cat /proc/PID/limits during benchmark.","id":"pitfall-1-expecting-complete-headers-in-a-single-read-call-symptom-works-perfectly-on-localhost-fails-intermittently-in-production-or-under-wrk-load-test-requests-over-1400-bytes-mtu-fail-at-the-95th-percentile-fix-always-accumulate-into-a-buffer-and-call-the-parser-after-each-read-never-assume-read-returns-complete-headers-pitfall-2-write-buffer-growing-unboundedly-for-slow-clients-symptom-server-rss-grows-steadily-under-load-eventually-oom-killed-or-exhausts-heap-fix-check-wbuf_append-return-value-if-1-buffer-exceeded-write_buf_max-close-the-connection-immediately-log-when-this-happensit-indicates-slow-clients-or-network-issues-pitfall-3-keep-alive-without-resetting-the-read-buffer-symptom-second-request-on-a-keep-alive-connection-fails-to-parse-or-gets-garbage-data-mixed-in-fix-http_conn_reset_for_keepalive-must-zero-read_len-and-memset-the-req-struct-do-not-skip-either-step-pitfall-4-path-traversal-vulnerability-symptom-get-etcpasswd-serves-etcpasswd-server-leaks-arbitrary-files-fix-build_safe_path-must-reject-any-path-containing-apply-this-check-before-any-file-system-access-pitfall-5-closing-connection-directly-from-within-a-callback-symptom-occasional-segfault-or-data-sent-to-wrong-client-after-high-churn-periods-fix-always-use-reactor_deferr-http_conn_close_deferred-conn-never-call-closeconn-gtfd-directly-from-within-http_on_readable-or-http_on_writable-this-is-the-core-lesson-from-milestone-339s-zombie-flag-mechanism-pitfall-6-not-benchmarking-with-real-file-descriptors-symptom-server-appears-healthy-in-initial-testing-crashes-or-times-out-when-wrk-uses-10000-connections-fix-run-ulimit-n-65536-before-starting-the-server-add-assertfd-lt-max_fds-in-the-accept-callback-monitor-cat-procpidlimits-during-benchmark"},{"level":1,"text":"TDD","id":"tdd"},{"level":1,"text":"MODULE CHARTER: epoll Basics: Level-Triggered and Edge-Triggered","id":"module-charter-epoll-basics-level-triggered-and-edge-triggered"},{"level":1,"text":"FILE STRUCTURE","id":"file-structure"},{"level":1,"text":"COMPLETE DATA MODEL","id":"complete-data-model"},{"level":3,"text":"conn_state_t (Per-Connection State)","id":"conn_state_t-per-connection-state"},{"level":1,"text":"INTERFACE CONTRACTS","id":"interface-contracts"},{"level":3,"text":"1. int set_nonblocking(int fd)","id":"1-int-set_nonblockingint-fd"},{"level":3,"text":"2. int reactor_add(int epoll_fd, int fd, uint32_t events)","id":"2-int-reactor_addint-epoll_fd-int-fd-uint32_t-events"},{"level":3,"text":"3. void conn_init(int fd)","id":"3-void-conn_initint-fd"},{"level":3,"text":"4. void conn_close(int epoll_fd, int fd)","id":"4-void-conn_closeint-epoll_fd-int-fd"},{"level":1,"text":"ALGORITHM SPECIFICATION","id":"algorithm-specification"},{"level":3,"text":"Level-Triggered (LT) Loop Logic","id":"level-triggered-lt-loop-logic"},{"level":3,"text":"Edge-Triggered (ET) Loop Logic","id":"edge-triggered-et-loop-logic"},{"level":1,"text":"HARDWARE SOUL: SYSCALLS AND PIPELINES","id":"hardware-soul-syscalls-and-pipelines"},{"level":3,"text":"1. The Cost of epoll_wait","id":"1-the-cost-of-epoll_wait"},{"level":3,"text":"2. Branch Prediction in the ET Loop","id":"2-branch-prediction-in-the-et-loop"},{"level":3,"text":"3. SIMD Opportunities","id":"3-simd-opportunities"},{"level":1,"text":"ERROR HANDLING MATRIX","id":"error-handling-matrix"},{"level":1,"text":"IMPLEMENTATION SEQUENCE","id":"implementation-sequence"},{"level":3,"text":"Phase 1: Socket &amp; Non-blocking Helpers (1.5 Hours)","id":"phase-1-socket-amp-non-blocking-helpers-15-hours"},{"level":3,"text":"Phase 2: LT Event Loop (3 Hours)","id":"phase-2-lt-event-loop-3-hours"},{"level":3,"text":"Phase 3: ET Event Loop &amp; Drain (3 Hours)","id":"phase-3-et-event-loop-amp-drain-3-hours"},{"level":1,"text":"TEST SPECIFICATION","id":"test-specification"},{"level":3,"text":"1. Functional Echo Test (Happy Path)","id":"1-functional-echo-test-happy-path"},{"level":3,"text":"2. The ET &quot;Stall&quot; Test (Edge Case)","id":"2-the-et-quotstallquot-test-edge-case"},{"level":3,"text":"3. Thundering Herd / Burst Accept","id":"3-thundering-herd-burst-accept"},{"level":1,"text":"PERFORMANCE TARGETS","id":"performance-targets"},{"level":1,"text":"CONCURRENCY SPECIFICATION","id":"concurrency-specification"},{"level":1,"text":"MODULE CHARTER: Write Buffering and Timer Management","id":"module-charter-write-buffering-and-timer-management"},{"level":1,"text":"FILE STRUCTURE","id":"file-structure"},{"level":1,"text":"COMPLETE DATA MODEL","id":"complete-data-model"},{"level":3,"text":"write_buf_t (Per-Connection Output Queue)","id":"write_buf_t-per-connection-output-queue"},{"level":3,"text":"timer_entry_t (Heap Node)","id":"timer_entry_t-heap-node"},{"level":3,"text":"conn_state_t (Updated)","id":"conn_state_t-updated"},{"level":1,"text":"INTERFACE CONTRACTS","id":"interface-contracts"},{"level":3,"text":"1. int wbuf_append(write_buf_t *wb, const char *src, uint32_t n)","id":"1-int-wbuf_appendwrite_buf_t-wb-const-char-src-uint32_t-n"},{"level":3,"text":"2. int conn_write(int epoll_fd, int fd, const char *src, uint32_t n)","id":"2-int-conn_writeint-epoll_fd-int-fd-const-char-src-uint32_t-n"},{"level":3,"text":"3. int conn_flush(int epoll_fd, int fd)","id":"3-int-conn_flushint-epoll_fd-int-fd"},{"level":3,"text":"4. void timer_set(int fd, uint64_t ms_from_now)","id":"4-void-timer_setint-fd-uint64_t-ms_from_now"},{"level":3,"text":"5. int timer_next_ms()","id":"5-int-timer_next_ms"},{"level":1,"text":"ALGORITHM SPECIFICATION","id":"algorithm-specification"},{"level":3,"text":"Write Buffer Compaction and Growth","id":"write-buffer-compaction-and-growth"},{"level":3,"text":"Min-Heap Sift-Down (Deletion/Update)","id":"min-heap-sift-down-deletionupdate"},{"level":1,"text":"ERROR HANDLING MATRIX","id":"error-handling-matrix"},{"level":1,"text":"IMPLEMENTATION SEQUENCE","id":"implementation-sequence"},{"level":3,"text":"Phase 1: The Byte Queue (2 Hours)","id":"phase-1-the-byte-queue-2-hours"},{"level":3,"text":"Phase 2: EPOLLOUT Lifecycle (2 Hours)","id":"phase-2-epollout-lifecycle-2-hours"},{"level":3,"text":"Phase 3: Monotonic Timing &amp; Heap (3 Hours)","id":"phase-3-monotonic-timing-amp-heap-3-hours"},{"level":3,"text":"Phase 4: Integrated Event Loop (2 Hours)","id":"phase-4-integrated-event-loop-2-hours"},{"level":1,"text":"TEST SPECIFICATION","id":"test-specification"},{"level":3,"text":"1. The Slow Reader Test (Backpressure)","id":"1-the-slow-reader-test-backpressure"},{"level":3,"text":"2. The Busy Loop Test (Deregistration)","id":"2-the-busy-loop-test-deregistration"},{"level":3,"text":"3. Timer Stress Test","id":"3-timer-stress-test"},{"level":1,"text":"PERFORMANCE TARGETS","id":"performance-targets"},{"level":1,"text":"SOUL SECTION: HARDWARE &amp; KERNEL INTERACTIONS","id":"soul-section-hardware-amp-kernel-interactions"},{"level":3,"text":"1. vDSO and clock_gettime","id":"1-vdso-and-clock_gettime"},{"level":3,"text":"2. Cache Line Alignment of Heap Nodes","id":"2-cache-line-alignment-of-heap-nodes"},{"level":3,"text":"3. Write Buffer Compaction vs. Page Faults","id":"3-write-buffer-compaction-vs-page-faults"},{"level":3,"text":"4. TCP Send Buffer vs. EPOLLOUT","id":"4-tcp-send-buffer-vs-epollout"},{"level":1,"text":"MODULE CHARTER: Reactor API and Callback Dispatch","id":"module-charter-reactor-api-and-callback-dispatch"},{"level":1,"text":"FILE STRUCTURE","id":"file-structure"},{"level":1,"text":"COMPLETE DATA MODEL","id":"complete-data-model"},{"level":3,"text":"1. reactor_t (The Engine)","id":"1-reactor_t-the-engine"},{"level":3,"text":"2. fd_handler_t (Registration Metadata)","id":"2-fd_handler_t-registration-metadata"},{"level":1,"text":"INTERFACE CONTRACTS","id":"interface-contracts"},{"level":3,"text":"1. int reactor_register(reactor_t *r, int fd, uint32_t events, io_cb_fn cb, void *ud)","id":"1-int-reactor_registerreactor_t-r-int-fd-uint32_t-events-io_cb_fn-cb-void-ud"},{"level":3,"text":"2. void reactor_deregister(reactor_t *r, int fd)","id":"2-void-reactor_deregisterreactor_t-r-int-fd"},{"level":3,"text":"3. void reactor_defer(reactor_t *r, task_fn fn, void *ud)","id":"3-void-reactor_deferreactor_t-r-task_fn-fn-void-ud"},{"level":3,"text":"4. int reactor_run(reactor_t *r)","id":"4-int-reactor_runreactor_t-r"},{"level":1,"text":"ALGORITHM SPECIFICATION","id":"algorithm-specification"},{"level":3,"text":"1. The &quot;Zombie&quot; Guard (Event Skipping)","id":"1-the-quotzombiequot-guard-event-skipping"},{"level":3,"text":"2. Drift-Free Interval Timers","id":"2-drift-free-interval-timers"},{"level":3,"text":"3. Deferred Modification Application","id":"3-deferred-modification-application"},{"level":1,"text":"ERROR HANDLING MATRIX","id":"error-handling-matrix"},{"level":1,"text":"IMPLEMENTATION SEQUENCE","id":"implementation-sequence"},{"level":3,"text":"Phase 1: Core Lifecycle &amp; Registry (2 Hours)","id":"phase-1-core-lifecycle-amp-registry-2-hours"},{"level":3,"text":"Phase 2: The Safe Dispatch Loop (3 Hours)","id":"phase-2-the-safe-dispatch-loop-3-hours"},{"level":3,"text":"Phase 3: Post-Dispatch Tasks (1.5 Hours)","id":"phase-3-post-dispatch-tasks-15-hours"},{"level":3,"text":"Phase 4: Integrated Timer API (2.5 Hours)","id":"phase-4-integrated-timer-api-25-hours"},{"level":1,"text":"TEST SPECIFICATION","id":"test-specification"},{"level":3,"text":"1. Re-entrancy Test (The FD Reuse Race)","id":"1-re-entrancy-test-the-fd-reuse-race"},{"level":3,"text":"2. Deferred Task Order","id":"2-deferred-task-order"},{"level":3,"text":"3. Timer Cancellation inside I/O","id":"3-timer-cancellation-inside-io"},{"level":1,"text":"PERFORMANCE TARGETS","id":"performance-targets"},{"level":1,"text":"SOUL SECTION: HARDWARE SOUL","id":"soul-section-hardware-soul"},{"level":3,"text":"1. Pointer Dispatch vs. Integer Lookup","id":"1-pointer-dispatch-vs-integer-lookup"},{"level":3,"text":"2. The Zombie Branch","id":"2-the-zombie-branch"},{"level":3,"text":"3. Tick-less Efficiency","id":"3-tick-less-efficiency"},{"level":1,"text":"STATE MACHINE: REACTOR LIFECYCLE","id":"state-machine-reactor-lifecycle"},{"level":1,"text":"MODULE CHARTER: HTTP Server on Event Loop","id":"module-charter-http-server-on-event-loop"},{"level":1,"text":"FILE STRUCTURE","id":"file-structure"},{"level":1,"text":"COMPLETE DATA MODEL","id":"complete-data-model"},{"level":3,"text":"1. http_state_t (Lifecycle Enum)","id":"1-http_state_t-lifecycle-enum"},{"level":3,"text":"2. http_request_t (Parsed Metadata)","id":"2-http_request_t-parsed-metadata"},{"level":3,"text":"3. http_conn_t (The Connection Context)","id":"3-http_conn_t-the-connection-context"},{"level":1,"text":"INTERFACE CONTRACTS","id":"interface-contracts"},{"level":3,"text":"1. parse_result_t http_parse_incremental(http_conn_t *conn)","id":"1-parse_result_t-http_parse_incrementalhttp_conn_t-conn"},{"level":3,"text":"2. int http_build_response(http_conn_t *conn)","id":"2-int-http_build_responsehttp_conn_t-conn"},{"level":3,"text":"3. void http_conn_close_deferred(reactor_t *r, void *arg)","id":"3-void-http_conn_close_deferredreactor_t-r-void-arg"},{"level":1,"text":"ALGORITHM SPECIFICATION","id":"algorithm-specification"},{"level":3,"text":"1. Incremental Read &amp; Shift Algorithm","id":"1-incremental-read-amp-shift-algorithm"},{"level":3,"text":"2. Path Sanitization (Defense-in-Depth)","id":"2-path-sanitization-defense-in-depth"},{"level":3,"text":"3. Keep-Alive Cycle Logic","id":"3-keep-alive-cycle-logic"},{"level":1,"text":"ERROR HANDLING MATRIX","id":"error-handling-matrix"},{"level":1,"text":"IMPLEMENTATION SEQUENCE","id":"implementation-sequence"},{"level":3,"text":"Phase 1: Data Structures &amp; Handlers (2 Hours)","id":"phase-1-data-structures-amp-handlers-2-hours"},{"level":3,"text":"Phase 2: Incremental Parser (3 Hours)","id":"phase-2-incremental-parser-3-hours"},{"level":3,"text":"Phase 3: Response Generation &amp; File I/O (3 Hours)","id":"phase-3-response-generation-amp-file-io-3-hours"},{"level":3,"text":"Phase 4: Lifecycle &amp; Keep-Alive (2 Hours)","id":"phase-4-lifecycle-amp-keep-alive-2-hours"},{"level":3,"text":"Phase 5: Tuning &amp; Benchmarking (2 Hours)","id":"phase-5-tuning-amp-benchmarking-2-hours"},{"level":1,"text":"TEST SPECIFICATION","id":"test-specification"},{"level":3,"text":"1. Fragmentation Stress Test","id":"1-fragmentation-stress-test"},{"level":3,"text":"2. Security: Path Traversal","id":"2-security-path-traversal"},{"level":3,"text":"3. C10K Load Test","id":"3-c10k-load-test"},{"level":1,"text":"PERFORMANCE TARGETS","id":"performance-targets"},{"level":1,"text":"HARDWARE SOUL: PERFORMANCE INSIGHTS","id":"hardware-soul-performance-insights"},{"level":3,"text":"1. Sequential Access &amp; Prefetching","id":"1-sequential-access-amp-prefetching"},{"level":3,"text":"2. memmove and Cache Pressure","id":"2-memmove-and-cache-pressure"},{"level":3,"text":"3. Syscall Batching (The &quot;Amortization&quot;)","id":"3-syscall-batching-the-quotamortizationquot"},{"level":3,"text":"4. sendfile(2) (Optional Milestone)","id":"4-sendfile2-optional-milestone"},{"level":1,"text":"Project Structure: Event Loop with epoll","id":"project-structure-event-loop-with-epoll"},{"level":2,"text":"Directory Tree","id":"directory-tree"},{"level":2,"text":"Creation Order","id":"creation-order"},{"level":2,"text":"File Count Summary","id":"file-count-summary"}],"title":"ðŸŽ¯ Project Charter: Event Loop with epoll","markdown":"# ðŸŽ¯ Project Charter: Event Loop with epoll\n\n## What You Are Building\nA high-performance, single-threaded server capable of handling 10,000+ concurrent connections (the \"C10K\" problem) using Linux's `epoll` facility and the Reactor pattern. You are building the foundational architecture used by NGINX, Redis, and Node.js: an event-driven core that manages non-blocking sockets, manual write-buffer backpressure, a min-heap timer system for idle timeouts, and an incremental HTTP/1.1 protocol parser.\n\n## Why This Project Exists\nModern high-scale systems achieve massive concurrency not by adding more threads, but by eliminating them. Building an event loop from scratch is the only way to understand how a single CPU core can manage thousands of connections without the devastating overhead of context switching. You will move past \"using\" async/await and learn the raw kernel mechanics of readiness notification and non-blocking I/O.\n\n## What You Will Be Able to Do When Done\n- Implement `epoll` based I/O multiplexing with both Level-Triggered and Edge-Triggered semantics.\n- Manage asynchronous backpressure by implementing per-connection write buffers and `EPOLLOUT` lifecycle management.\n- Build a high-performance min-heap priority queue to manage thousands of concurrent connection timeouts.\n- Design a Reactor-pattern API that abstracts raw syscalls into a clean, callback-based event system.\n- Successfully benchmark and tune a Linux server to handle 10,000+ simultaneous connections with sub-100ms p99 latency.\n\n## Final Deliverable\nA robust C or Rust systems project (~2,500+ lines) including a reusable Reactor library and a static file HTTP/1.1 server. The project features a comprehensive test suite for protocol fragmentation and a validated benchmark report demonstrating stable performance under 10,000 concurrent connections using tools like `wrk`.\n\n## Is This Project For You?\n**You should start this if you:**\n- Are comfortable with C pointers, manual memory management, and `struct` design.\n- Understand the basics of the TCP 3-way handshake and the standard socket API (`socket`, `bind`, `listen`).\n- Want to transition from \"web developer\" to \"systems engineer\" by understanding the \"magic\" inside your runtime.\n\n**Come back after you've learned:**\n- Basic TCP socket programming (build a simple blocking \"Hello World\" echo server first).\n- Standard C data structures (you should know how to implement a basic linked list or array-based queue).\n\n## Estimated Effort\n| Phase | Time |\n|-------|------|\n| epoll Basics: Level-Triggered and Edge-Triggered | ~6-8 hours |\n| Write Buffering and Timer Management | ~5-8 hours |\n| Reactor API and Callback Dispatch | ~5-8 hours |\n| HTTP Server on Event Loop (C10K Target) | ~6-10 hours |\n| **Total** | **~22-35 hours** |\n\n## Definition of Done\nThe project is complete when:\n- The server successfully passes a C10K load test (10,000 concurrent connections) with zero dropped requests.\n- The incremental HTTP parser correctly handles \"fragmented\" requests (headers split across multiple `read()` calls).\n- Idle connections are automatically closed by the timer system after a 30-second timeout.\n- Valgrind/ASAN reports zero memory leaks or use-after-free errors during high-churn connection tests.\n- Static files are served with correct `Content-Length` and `Content-Type` headers.\n\n---\n\n# ðŸ“š Before You Read This: Prerequisites & Further Reading\n\n> **Read these first.** The Atlas assumes you are familiar with the foundations below.\n> Resources are ordered by when you should encounter them â€” some before you start, some at specific milestones.\n\n### 1. The Genesis of High Concurrency\n**Concept**: The C10K Problem\n- **Paper**: [The C10K Problem](http://www.kegel.com/c10k.html) by Dan Kegel (1999).\n- **Why**: The historical catalyst that moved the industry from thread-per-connection to event-driven architectures.\n- **Pedagogical Timing**: Read **BEFORE Milestone 1**. It provides the necessary context for why `select()` and `poll()` failed and why `epoll` was invented.\n\n### 2. Linux Kernel I/O Multiplexing\n**Concept**: epoll Semantics and Internal Implementation\n- **Spec**: [epoll(7) Manual Page](https://man7.org/linux/man-pages/man7/epoll.7.html) by Michael Kerrisk.\n- **Code**: [linux/fs/eventpoll.c](https://github.com/torvalds/linux/blob/master/fs/eventpoll.c) â€” specifically the `ep_poll_callback` function.\n- **Best Explanation**: [The Linux Programming Interface](https://man7.org/tlpi/) (Book) by Michael Kerrisk, **Chapter 63 (Alternative I/O Models)**.\n- **Why**: The \"Bible\" of Linux system programming; the chapter on epoll is the most rigorous explanation of Edge-Triggered vs. Level-Triggered behavior in existence.\n- **Pedagogical Timing**: Read **during Milestone 1**. Refer to the spec while implementing your first `epoll_wait` loop to understand flag nuances like `EPOLLONESHOT` and `EPOLLET`.\n\n### 3. The Reactor Design Pattern\n**Concept**: Event Demultiplexing and Dispatching\n- **Paper**: [Reactor: An Object Behavioral Pattern for Demultiplexing and Dispatching Handles for Synchronous Events](https://www.dre.vanderbilt.edu/~schmidt/PDF/reactor-siemens.pdf) by Douglas C. Schmidt (1995).\n- **Code**: [Redis: ae.c](https://github.com/redis/redis/blob/7.2/src/ae.c).\n- **Best Explanation**: [Scalable IO in Java](https://gee.cs.oswego.edu/dl/cpjslides/nio.pdf) (Slide Deck) by Doug Lea. \n- **Why**: Redisâ€™s `ae.c` is the cleanest, most readable production-grade implementation of a Reactor in the C language.\n- **Pedagogical Timing**: Read **BEFORE Milestone 3**. Schmidtâ€™s paper provides the theoretical blueprint, while Doug Leaâ€™s slides provide a visual mental model of the dispatcher/handler relationship.\n\n### 4. Efficient Timing & Priority Queues\n**Concept**: Min-Heaps for Timeout Management\n- **Code**: [libuv: timer.c](https://github.com/libuv/libuv/blob/v1.x/src/timer.c).\n- **Best Explanation**: [Introduction to Algorithms (CLRS)](https://mitpress.mit.edu/9780262046305/introduction-to-algorithms/), **Chapter 6 (Heapsort)**.\n- **Why**: Libuv (Node.jsâ€™s core) uses a min-heap for its timers; studying their `uv__timer_close` demonstrates how to handle the \"arbitrary deletion\" problem in O(log N).\n- **Pedagogical Timing**: Read **during Milestone 2**. You will need the sift-up/sift-down algorithms to implement the idle-connection reaper.\n\n### 5. HTTP/1.1 Protocol & Parsing\n**Concept**: Framing and Persistent Connections\n- **Spec**: [RFC 7230: HTTP/1.1 Message Syntax and Routing](https://datatracker.ietf.org/doc/html/rfc7230).\n- **Code**: [PicoHTTPParser](https://github.com/h2o/picohttpparser/blob/master/picohttpparser.c).\n- **Best Explanation**: [High Performance Browser Networking](https://hpbn.co/http1x/) (Book) by Ilya Grigorik, **Chapter 9 (HTTP 1.1)**.\n- **Why**: PicoHTTPParser shows how to use SSE4.2/AVX2 instructions to scan for `\\r\\n` significantly faster than standard `strstr`.\n- **Pedagogical Timing**: Read **BEFORE Milestone 4**. You must understand the rules for `Content-Length` and `Transfer-Encoding` to implement keep-alive correctly.\n\n### 6. Memory Management and Backpressure\n**Concept**: Write Buffering and User-Space Queuing\n- **Best Explanation**: [Notes on Distributed Systems: Backpressure](https://bravenewgeek.com/you-cannot-have-exactly-once-delivery/) by Tyler Treat.\n- **Why**: A masterclass in why unbounded buffers lead to cascading failures and how `EAGAIN` acts as a signal to propagate pressure upstream.\n- **Pedagogical Timing**: Read **After Milestone 2**. It will help you appreciate why we enforce a `WRITE_BUF_MAX` instead of letting the buffer grow to match the request size.\n\n### 7. Zero-Copy Optimizations\n**Concept**: `sendfile(2)` and Kernel-Space Data Transfer\n- **Spec**: [sendfile(2) Manual Page](https://man7.org/linux/man-pages/man2/sendfile.2.html).\n- **Code**: [Nginx: ngx_linux_sendfile_chain.c](https://github.com/nginx/nginx/blob/master/src/os/unix/ngx_linux_sendfile_chain.c).\n- **Why**: Nginx is the gold standard for high-performance static file serving; their implementation handles the complexity of `sendfile` returning partial results.\n- **Pedagogical Timing**: Read **After Milestone 4** as an \"Extra Credit\" optimization to replace your manual read/write loop for static files.\n\n### 8. The Future: Asynchronous Completion I/O\n**Concept**: io_uring (The Proactor Pattern on Linux)\n- **Paper**: [Efficient IO with io_uring](https://kernel.dk/io_uring.pdf) by Jens Axboe (2019).\n- **Why**: Written by the lead maintainer of the Linux block layer, this explains why the Reactor/epoll model is being superseded by completion queues.\n- **Pedagogical Timing**: Read **after completing the project**. It provides a \"what's next\" perspective on how to further reduce syscall overhead and context switching.\n\n---\n\n# Event Loop with epoll: Building a Reactor-Pattern Server from Scratch\n\nThis project builds a single-threaded, high-concurrency server capable of handling 10,000+ simultaneous connections using Linux's epoll I/O multiplexing facility and the reactor pattern. You will start from raw epoll syscallsâ€”understanding the critical difference between edge-triggered and level-triggered semanticsâ€”then layer on write buffering with backpressure, timer management for idle timeouts, a clean reactor API that hides kernel details behind callbacks, and finally a complete HTTP/1.1 server that demonstrates the C10K capability.\n\nThe architecture you build here is the exact foundation of NGINX, Redis, Node.js's libuv, and Tokio's mio. By implementing it yourself in C, you'll understand why these systems are single-threaded yet outperform multi-threaded alternatives, how they handle slow clients without blocking fast ones, and why edge-triggered epoll demands a fundamentally different coding discipline than the select/poll model most developers learn first.\n\nEvery milestone produces a working, testable artifact: an echo server, a timer-driven connection reaper, a reactor library, and a benchmarked HTTP server. The progression is designed so that each layer reveals why the previous layer's naive approach breaks under load, creating a chain of 'aha' moments that connect kernel internals to application architecture.\n\n\n\n<!-- MS_ID: build-event-loop-m1 -->\n# epoll Basics: Level-Triggered and Edge-Triggered\n## The Problem That Makes Single-Threaded Servers Hard\nBefore you write a single line of epoll code, you need to feel the constraint that makes all of this necessary. Let's start with what you already know how to build.\nThe classic server model is simple: call `accept()` to get a new connection, hand it to a thread, and let that thread call `read()` to wait for data. The thread blocksâ€”suspended by the kernelâ€”until bytes arrive, then processes them, then blocks again. This works beautifully until you need to handle 10,000 connections simultaneously.\nTen thousand threads. Each thread needs a stack (commonly 8 MB default, though you'd tune it down to 64â€“128 KB for a server). At 64 KB per thread, 10,000 threads consume 640 MB of RAM just for stacksâ€”before you store a single byte of application data. And RAM is the optimistic problem. The real killer is context switching: each time the kernel switches from one thread to another, it must save all CPU registers, flush parts of the TLB (the CPU's translation lookaside buffer, which caches virtual-to-physical address mappings), and potentially evict hot cache lines. At 10,000 threads with even modest activity, you spend more CPU time switching contexts than doing actual work.\n\n![Before/After: Thread-per-Connection vs epoll Event Loop](./diagrams/diag-m1-before-after-blocking-vs-nonblocking.svg)\n\nThe kernel already knows which file descriptors have data ready. It maintains this information internally. The question is: how do you ask the kernel \"which of my 10,000 file descriptors are ready right now?\" without blocking on each one individually?\nThat's the problem `epoll` solves.\n\n> **ðŸ”‘ Foundation: I/O multiplexing**\n> \n> **1. What it IS**\nI/O Multiplexing is a technique that allows a single process or thread to monitor multiple file descriptors (FDs)â€”such as network socketsâ€”simultaneously. Instead of the application \"polling\" each socket one by one or getting stuck waiting for a single connection to respond, the application asks the operating system kernel to wake it up only when one or more of those sockets are actually ready for reading or writing.\n\n**2. Why you need it right now**\nIn high-concurrency networking, the traditional \"thread-per-connection\" model fails. If you want to handle 10,000 concurrent users, creating 10,000 threads would consume massive amounts of memory (for thread stacks) and devastate performance due to CPU context-switching overhead. Multiplexing allows you to scale to thousands of connections using a single thread, keeping your memory footprint low and your CPU focused on processing data rather than managing thread lifecycles.\n\n**3. Key Insight: The Pager System**\nImagine a waiter in a restaurant. Instead of standing at one table and waiting ten minutes for a guest to choose an appetizer (Blocking I/O), or running from table to table every ten seconds asking \"Are you ready yet?\" (Polling), the waiter gives every table a **pager**. The waiter can then relax or do other tasks; when a guest is ready, their pager buzzes. The waiter handles only the tables that signaled they are ready.\n\n## epoll in Context: What Came Before\n\n> **ðŸ”‘ Foundation: epoll vs select/poll**\n> \n> **1. What it IS**\n`select`, `poll`, and `epoll` are all system calls used for I/O multiplexing, but they differ in how they track which sockets are ready. `select` and `poll` are the older \"stateless\" methods, while `epoll` (exclusive to Linux) is a \"stateful\" event-notification facility.\n\n**2. Why you need it right now**\nAt low connection counts (e.g., 10â€“100), the difference is negligible. However, `select` and `poll` have $O(N)$ complexity. Every time you call them, you must pass the entire list of FDs to the kernel, and the kernel must scan the entire list to see which ones are active. As you move toward 10,000+ FDs (the \"C10k problem\"), this scanning process becomes a massive bottleneck. `epoll` solves this by maintaining an \"interest list\" within the kernel itself. When a socket becomes ready, the kernel places it in a \"ready list.\" The application then calls `epoll_wait` and receives only the FDs that actually have events, making it $O(1)$ relative to the total number of connections.\n\n**3. Key Insight: Roll Call vs. The Sign-in Sheet**\n`select` and `poll` are like a teacher performing a **Roll Call**: every morning, they must read every single name on the 1,000-person roster to see who is present. `epoll` is like a **Sign-in Sheet**: the teacher leaves a paper at the door, and only the students who actually show up write their names down. The teacher only has to look at the few names on the sheet to know who is ready.\n\nThe short version: `select()` and `poll()` both require you to pass the *entire* set of file descriptors you're interested in on every call. For 10,000 FDs, that's copying a 10,000-element array into the kernel on every call, and the kernel scans the entire array to find ready ones. `epoll` inverts this: you register interest once with `epoll_ctl()`, and `epoll_wait()` returns only the ready eventsâ€”no full scan, no array copying.\n\n![Satellite Map: Event Loop Architecture Overview](./diagrams/diag-satellite-system-map.svg)\n\nIn the system map, this milestone builds the foundation layer: the epoll instance and the non-blocking socket infrastructure that everything above it depends on.\n---\n## The Revelation: ET and LT Are Different Contracts, Not Different Speeds\nMost developers who learn about epoll's edge-triggered mode read something like \"edge-triggered is more efficient than level-triggered\" and conclude: add `EPOLLET` to your flags for a free performance upgrade. This is the misconception that causes subtle, hard-to-reproduce data loss bugs.\nHere is the actual contract each mode makes with you:\n**Level-Triggered (LT)** says: *\"As long as there is data in the socket's receive buffer that you haven't read yet, I will report this file descriptor as readable on every call to `epoll_wait`.\"*\n**Edge-Triggered (ET)** says: *\"I will report this file descriptor as readable exactly onceâ€”when the kernel receives new data that transitions the buffer from empty to non-empty (or adds to existing unread data). After that, it's your responsibility to drain all the data. I will not remind you again until new data arrives from the network.\"*\nRead that second contract again. If 5,000 bytes arrive in the kernel's receive buffer and you read 1,024 bytes, LT will wake you up again on the next `epoll_wait`â€”there's still data. ET will *not* wake you up. It told you once. The remaining 3,976 bytes will sit in the receive buffer, invisible to you, until the remote end sends *more* dataâ€”at which point ET fires again, but now you have 3,976 stale bytes plus whatever just arrived, all mixed together.\nUnder controlled testing (small messages, quiet network), ET and LT look identical, because each message fits in a single `read()` call. Under load (large payloads, pipelined requests, bursts), ET with single-read-per-event silently drops data. The bug is timing-dependent and disappears in a debugger.\n\n![Data Walk: Level-Triggered vs Edge-Triggered Read Behavior](./diagrams/diag-m1-lt-vs-et-data-walk.svg)\n\nThis is not a performance difference. It is a **different programming model** that demands different code.\n---\n## Building the Foundation: Non-Blocking Sockets\nBefore epoll can work correctly, every socket must be in non-blocking mode. Let's understand why.\n\n> **ðŸ”‘ Foundation: Blocking vs non-blocking I/O**\n> \n> **1. What it IS**\nIn **Blocking I/O**, when you call `read()`, the kernel puts your thread to sleep until data arrives. In **Non-blocking I/O**, the call returns immediately. If data is ready, you get the data; if not, the kernel returns a specific error code: `EAGAIN` or `EWOULDBLOCK`.\n\n**2. Why you need it right now**\nI/O Multiplexing (like `epoll`) only tells you that a socket *has* data. It doesn't tell you *how much*. If you use a blocking `read()` on a socket that `epoll` flagged, but you try to read 1024 bytes and only 500 are available, your entire thread will \"freeze\" while waiting for the remaining 524 bytes. In an event-driven server, this would stop the server from processing all other 9,999 clients. You must set your sockets to non-blocking mode so that you can read what is available and immediately move on if the source runs dry.\n\n**3. Key Insight: EAGAIN is not an Error**\nIn non-blocking I/O, receiving an `EAGAIN` result is not a failure; it is a **\"Call me back later\"** message. It is the kernel telling you: \"I've given you everything I have for now; go do something else and I'll notify you via the multiplexer when more arrives.\"\n\nIn non-blocking mode, `read()` and `write()` return immediately. If there's no data to read, they return `-1` and set `errno` to `EAGAIN` (or its synonym `EWOULDBLOCK`â€”the kernel may use either; always check both, or check `errno == EAGAIN || errno == EWOULDBLOCK`). This is *not* an error. It means \"the kernel's buffer is empty right now; try again later.\" Your event loop handles the \"try again later\" part by going back to `epoll_wait`.\nHere's how you configure a socket for non-blocking mode:\n```c\n#include <fcntl.h>\n/**\n * set_nonblocking - Configure a file descriptor for non-blocking I/O.\n *\n * Returns 0 on success, -1 on failure (with errno set).\n *\n * Why fcntl F_GETFL + F_SETFL: We must read existing flags first\n * to preserve them (e.g., O_RDWR, O_APPEND). Overwriting with just\n * O_NONBLOCK would clear all other flags, corrupting the fd's behavior.\n */\nint set_nonblocking(int fd) {\n    int flags = fcntl(fd, F_GETFL, 0);\n    if (flags == -1) {\n        return -1;\n    }\n    return fcntl(fd, F_SETFL, flags | O_NONBLOCK);\n}\n```\n> **Why `F_GETFL` before `F_SETFL`?** The flags field holds multiple properties. If you write `fcntl(fd, F_SETFL, O_NONBLOCK)` directly, you erase `O_RDWR`, `O_APPEND`, and any other flags that were set. Always read first, then OR in your new flag.\nAn alternative on Linux is `accept4()` with `SOCK_NONBLOCK`, which creates the accepted socket already in non-blocking mode. We'll use this shortly to save the extra `fcntl` call on each accepted connection.\n---\n## Creating the epoll Instance\n```c\n#include <sys/epoll.h>\n#include <unistd.h>\n#include <stdio.h>\n#include <stdlib.h>\n/**\n * create_epoll - Create an epoll instance.\n *\n * epoll_create1(EPOLL_CLOEXEC):\n *   - EPOLL_CLOEXEC: automatically close the epoll fd if this process\n *     calls exec(). Without this flag, child processes after fork/exec\n *     inherit the epoll fd, which prevents the kernel from cleaning up\n *     the epoll interest list and leaks it into child processes.\n *   - The argument to epoll_create1 is a flags field, not a size hint\n *     (epoll_create's size argument is ignored since Linux 2.6.8 but\n *     must still be nonzero; epoll_create1 eliminates this confusion).\n *\n * Returns: epoll file descriptor (> 0), or exits on failure.\n */\nint create_epoll(void) {\n    int epoll_fd = epoll_create1(EPOLL_CLOEXEC);\n    if (epoll_fd == -1) {\n        perror(\"epoll_create1\");\n        exit(EXIT_FAILURE);\n    }\n    return epoll_fd;\n}\n```\nThe epoll instance is itself a file descriptor. It refers to a kernel data structure that maintains two lists: the **interest list** (every fd you've registered with `epoll_ctl`) and the **ready list** (fds that have events waiting). `epoll_wait` efficiently pulls from the ready list.\n{{DIAGRAM:diag-m1-epoll-syscall-flow}}\n### Registering File Descriptors\n`epoll_ctl` takes four arguments: the epoll fd, an operation (`EPOLL_CTL_ADD`, `EPOLL_CTL_MOD`, or `EPOLL_CTL_DEL`), the target fd, and a pointer to an `epoll_event` struct:\n```c\nstruct epoll_event {\n    uint32_t     events;   /* event mask: EPOLLIN, EPOLLOUT, EPOLLET, etc. */\n    epoll_data_t data;     /* union: ptr, fd, u32, u64 â€” your choice */\n};\n```\nThe `data` field is a union you control entirely. Whatever you put in when registering, you get back when the event fires. For simple cases, store the fd. For the full reactor pattern (Milestone 3), you'll store a pointer to the per-connection state structure.\n```c\n/**\n * epoll_add - Register fd for EPOLLIN events with epoll.\n * Stores fd in data.fd for retrieval in epoll_wait results.\n */\nint epoll_add(int epoll_fd, int fd, uint32_t events) {\n    struct epoll_event ev;\n    ev.events = events;\n    ev.data.fd = fd;\n    return epoll_ctl(epoll_fd, EPOLL_CTL_ADD, fd, &ev);\n}\n/**\n * epoll_mod - Modify existing fd registration (e.g., add EPOLLOUT).\n */\nint epoll_mod(int epoll_fd, int fd, uint32_t events) {\n    struct epoll_event ev;\n    ev.events = events;\n    ev.data.fd = fd;\n    return epoll_ctl(epoll_fd, EPOLL_CTL_MOD, fd, &ev);\n}\n/**\n * epoll_del - Remove fd from epoll interest list.\n * On Linux >= 2.6.9, the event pointer can be NULL here.\n */\nint epoll_del(int epoll_fd, int fd) {\n    return epoll_ctl(epoll_fd, EPOLL_CTL_DEL, fd, NULL);\n}\n```\n---\n## Setting Up the Listening Socket\nThe listening socket is your server's front door. It also must be non-blocking. The reason: if a client initiates a connection and then immediately sends a TCP RST before your `accept()` call runs (a race that happens under load), a blocking `accept()` can stall waiting for the *next* connection. With non-blocking mode, `accept()` returns `EAGAIN` immediately and you go back to `epoll_wait`.\n```c\n#include <sys/socket.h>\n#include <netinet/in.h>\n#include <string.h>\n#define BACKLOG 128  /* listen() backlog: how many connections kernel queues */\n#define PORT    8080\n/**\n * create_listening_socket - Create, bind, and listen a non-blocking TCP socket.\n *\n * SO_REUSEADDR: allows rebinding to the port immediately after server restart,\n * bypassing the TCP TIME_WAIT state (which would otherwise block rebind for ~60s).\n *\n * Returns: listening socket fd, or -1 on failure.\n */\nint create_listening_socket(void) {\n    int listen_fd = socket(AF_INET, SOCK_STREAM | SOCK_NONBLOCK | SOCK_CLOEXEC, 0);\n    if (listen_fd == -1) {\n        perror(\"socket\");\n        return -1;\n    }\n    /* SO_REUSEADDR: don't wait for TIME_WAIT to expire on restart */\n    int opt = 1;\n    if (setsockopt(listen_fd, SOL_SOCKET, SO_REUSEADDR, &opt, sizeof(opt)) == -1) {\n        perror(\"setsockopt SO_REUSEADDR\");\n        close(listen_fd);\n        return -1;\n    }\n    struct sockaddr_in addr;\n    memset(&addr, 0, sizeof(addr));\n    addr.sin_family      = AF_INET;\n    addr.sin_addr.s_addr = INADDR_ANY;  /* listen on all interfaces */\n    addr.sin_port        = htons(PORT); /* htons: host-to-network byte order */\n    if (bind(listen_fd, (struct sockaddr *)&addr, sizeof(addr)) == -1) {\n        perror(\"bind\");\n        close(listen_fd);\n        return -1;\n    }\n    if (listen(listen_fd, BACKLOG) == -1) {\n        perror(\"listen\");\n        close(listen_fd);\n        return -1;\n    }\n    return listen_fd;\n}\n```\n> **`SOCK_NONBLOCK | SOCK_CLOEXEC` in the `socket()` call**: Linux allows ORing these flags directly into `socket()`'s type argument since kernel 2.6.27. This avoids a race condition between `socket()` and a subsequent `fcntl()` where a signal could deliver between the two calls in a multi-threaded program. In a single-threaded event loop it's less critical, but it's good practice.\n> **`htons(PORT)`**: Network protocols specify big-endian byte order for port numbers. `htons` (host-to-network-short) converts from the host's native byte order (likely little-endian on x86) to network byte order. Forgetting this causes your server to listen on the wrong portâ€”a classic source of \"why can't I connect?\" confusion.\n---\n## Per-Connection State: The fd â†’ State Map\nEvery active connection needs associated state: a read buffer, a write buffer, timers, and protocol parsing position. Since file descriptors are small non-negative integers, the most cache-friendly structure is a flat array indexed by fd value. The kernel guarantees fd values are less than the process's open file limit (by default 1,024 in many systems; configurable up to millions with `ulimit -n` and `/proc/sys/fs/file-max`).\n\n![Per-Connection State Structure: Memory Layout](./diagrams/diag-m1-connection-state-struct.svg)\n\n```c\n#include <stdint.h>\n#include <stdbool.h>\n#define MAX_FDS       65536   /* size of fdâ†’state array; must exceed ulimit -n */\n#define READ_BUF_SIZE 4096    /* one page; aligns with typical MTU and kernel recv buffer chunks */\n/**\n * conn_state - Per-connection state stored in the fd array.\n *\n * Memory layout analysis (on 64-bit Linux):\n *   offset  0: read_buf[4096]   = 4096 bytes\n *   offset  4096: read_len      = 4 bytes (uint32_t)\n *   offset  4100: fd            = 4 bytes (int)\n *   offset  4104: active        = 1 byte (bool)\n *   offset  4105: [padding]     = 7 bytes (compiler aligns next field)\n *   Total: ~4112 bytes per connection\n *\n * At 10,000 connections: 10,000 Ã— 4112 â‰ˆ 40 MB resident memory.\n * The read_buf is the dominant cost â€” larger buffers mean fewer read() calls\n * but more memory footprint. 4096 is a common trade-off.\n *\n * Cache note: read_buf[0..63] fits in one 64-byte cache line. Sequential\n * access to read_buf (filling it byte-by-byte) is prefetch-friendly.\n * The conn_state structs themselves are too large to fit in L1 (32 KB),\n * so accessing state for a new connection will be an L2 or L3 cache miss.\n */\ntypedef struct {\n    char     read_buf[READ_BUF_SIZE]; /* incoming bytes accumulate here */\n    uint32_t read_len;                /* bytes currently in read_buf */\n    int      fd;                      /* the file descriptor this represents */\n    bool     active;                  /* is this slot in use? */\n    /* Milestone 2 will add: write buffer, timer linkage */\n} conn_state;\n/* Global fdâ†’state array. Indexed directly by fd value. */\nstatic conn_state connections[MAX_FDS];\n/**\n * conn_init - Initialize a new connection's state slot.\n * Called immediately after accept().\n */\nvoid conn_init(int fd) {\n    conn_state *c = &connections[fd];\n    c->fd       = fd;\n    c->read_len = 0;\n    c->active   = true;\n    /* No need to zero read_buf â€” we track length in read_len */\n}\n/**\n * conn_close - Clean up a connection's state slot and close its fd.\n * Must be called on any exit path: client disconnect, error, timeout.\n */\nvoid conn_close(int epoll_fd, int fd) {\n    conn_state *c = &connections[fd];\n    if (!c->active) return;\n    c->active   = false;\n    c->read_len = 0;\n    c->fd       = -1;\n    /* Remove from epoll before closing fd. Closing fd auto-removes it from\n     * epoll on Linux (kernel does this when fd refcount drops to zero), but\n     * explicit removal is safer and required if fd was dup()'d. */\n    epoll_ctl(epoll_fd, EPOLL_CTL_DEL, fd, NULL);\n    close(fd);\n}\n```\n> **Why an array and not a hash map?** File descriptors are already sparse integers in a bounded range. An array gives O(1) lookup with zero hash computation and excellent cache locality for sequential fd values. A hash map's overheadâ€”hashing, collision chains, pointer chasingâ€”is pure cost with no benefit when the key space is already integer-indexed. This is a common pattern in kernel-adjacent code: Redis uses a similar `ae_file_event *events` array in `ae.c`.\n---\n## The Level-Triggered Event Loop\nNow we have all the pieces. Here's a complete level-triggered event loop that drives an echo server:\n```c\n#include <errno.h>\n#include <stdio.h>\n#define MAX_EVENTS 1024  /* events to retrieve per epoll_wait call */\n/**\n * handle_new_connection_lt - Accept all pending connections in LT mode.\n *\n * In LT mode, we can accept one connection per EPOLLIN on the listen fd,\n * because if more connections are pending, epoll_wait will fire again.\n * However, accepting in a loop until EAGAIN is still better practice:\n * it reduces epoll_wait round trips under high connection rates.\n *\n * We use accept4() with SOCK_NONBLOCK | SOCK_CLOEXEC to atomically\n * create non-blocking, close-on-exec client sockets.\n */\nvoid handle_new_connection_lt(int epoll_fd, int listen_fd) {\n    struct sockaddr_in client_addr;\n    socklen_t addr_len = sizeof(client_addr);\n    int client_fd = accept4(listen_fd, (struct sockaddr *)&client_addr,\n                            &addr_len, SOCK_NONBLOCK | SOCK_CLOEXEC);\n    if (client_fd == -1) {\n        if (errno == EAGAIN || errno == EWOULDBLOCK) {\n            return; /* no more connections right now */\n        }\n        perror(\"accept4\");\n        return;\n    }\n    if (client_fd >= MAX_FDS) {\n        fprintf(stderr, \"fd %d exceeds MAX_FDS, closing\\n\", client_fd);\n        close(client_fd);\n        return;\n    }\n    conn_init(client_fd);\n    /* Register for EPOLLIN only (LT mode â€” no EPOLLET flag) */\n    if (epoll_add(epoll_fd, client_fd, EPOLLIN) == -1) {\n        perror(\"epoll_add client\");\n        conn_close(epoll_fd, client_fd);\n    }\n}\n/**\n * handle_client_read_lt - Read and echo data in level-triggered mode.\n *\n * LT contract: epoll will re-notify us if data remains in the buffer.\n * So we read ONE chunk per event â€” simple, but may cause extra epoll_wait\n * round trips if more than READ_BUF_SIZE bytes are waiting.\n */\nvoid handle_client_read_lt(int epoll_fd, int fd) {\n    conn_state *c = &connections[fd];\n    char buf[READ_BUF_SIZE];\n    ssize_t n = read(fd, buf, sizeof(buf));\n    if (n > 0) {\n        /* Echo: write it back. For now, assume write succeeds fully.\n         * Milestone 2 will add proper write buffering for partial writes. */\n        ssize_t written = 0;\n        while (written < n) {\n            ssize_t w = write(fd, buf + written, n - written);\n            if (w == -1) {\n                if (errno == EAGAIN || errno == EWOULDBLOCK) {\n                    /* Send buffer full; Milestone 2 handles this properly */\n                    break;\n                }\n                conn_close(epoll_fd, fd);\n                return;\n            }\n            written += w;\n        }\n    } else if (n == 0) {\n        /* Peer closed connection (graceful shutdown / EOF) */\n        conn_close(epoll_fd, fd);\n    } else {\n        /* n == -1 */\n        if (errno == EAGAIN || errno == EWOULDBLOCK) {\n            /* Spurious wakeup: no data right now. Not an error. */\n            return;\n        }\n        /* Real error (ECONNRESET, ETIMEDOUT, etc.) */\n        conn_close(epoll_fd, fd);\n    }\n}\n/**\n * run_event_loop_lt - Level-triggered event loop. Main server loop.\n */\nvoid run_event_loop_lt(int epoll_fd, int listen_fd) {\n    struct epoll_event events[MAX_EVENTS];\n    for (;;) {\n        /*\n         * epoll_wait arguments:\n         *   epoll_fd   - our epoll instance\n         *   events     - array to fill with ready events\n         *   MAX_EVENTS - max events to return per call\n         *   -1         - timeout: block forever until an event arrives\n         *                (Milestone 2 will replace -1 with timer-derived value)\n         */\n        int n_ready = epoll_wait(epoll_fd, events, MAX_EVENTS, -1);\n        if (n_ready == -1) {\n            if (errno == EINTR) {\n                /* Signal interrupted epoll_wait (e.g., SIGCHLD). Not an error. */\n                continue;\n            }\n            perror(\"epoll_wait\");\n            break;\n        }\n        for (int i = 0; i < n_ready; i++) {\n            int fd = events[i].data.fd;\n            uint32_t ev = events[i].events;\n            if (fd == listen_fd) {\n                handle_new_connection_lt(epoll_fd, listen_fd);\n            } else if (ev & (EPOLLERR | EPOLLHUP)) {\n                /* Error or hang-up: connection is broken */\n                conn_close(epoll_fd, fd);\n            } else if (ev & EPOLLIN) {\n                handle_client_read_lt(epoll_fd, fd);\n            }\n        }\n    }\n}\n```\nTest this with `nc localhost 8080`. Type text, hit Enter, and it echoes back. Now try piping a large file: `cat /dev/urandom | head -c 1000000 | nc localhost 8080`. Watch it work correctlyâ€”LT mode will keep waking up the loop until all the data is read.\n---\n## The Edge-Triggered Event Loop: Drain Until EAGAIN\nNow we implement ET mode. The code structure looks similar, but the read handler is fundamentally different:\n```c\n/**\n * handle_new_connection_et - Accept ALL pending connections in ET mode.\n *\n * CRITICAL: In ET mode, EPOLLIN on listen_fd fires ONCE when new connections\n * arrive. If 5 clients connect between epoll_wait calls, we get ONE wakeup.\n * We MUST loop until accept() returns EAGAIN, or we miss connections entirely.\n * This is the same \"drain until EAGAIN\" discipline applied to the listen socket.\n */\nvoid handle_new_connection_et(int epoll_fd, int listen_fd) {\n    for (;;) {\n        struct sockaddr_in client_addr;\n        socklen_t addr_len = sizeof(client_addr);\n        int client_fd = accept4(listen_fd, (struct sockaddr *)&client_addr,\n                                &addr_len, SOCK_NONBLOCK | SOCK_CLOEXEC);\n        if (client_fd == -1) {\n            if (errno == EAGAIN || errno == EWOULDBLOCK) {\n                break; /* no more pending connections */\n            }\n            perror(\"accept4\");\n            break;\n        }\n        if (client_fd >= MAX_FDS) {\n            fprintf(stderr, \"fd %d exceeds MAX_FDS, closing\\n\", client_fd);\n            close(client_fd);\n            continue;\n        }\n        conn_init(client_fd);\n        /* Register with EPOLLIN | EPOLLET â€” edge-triggered mode */\n        if (epoll_add(epoll_fd, client_fd, EPOLLIN | EPOLLET) == -1) {\n            perror(\"epoll_add client ET\");\n            conn_close(epoll_fd, client_fd);\n        }\n    }\n}\n/**\n * handle_client_read_et - Read all available data in edge-triggered mode.\n *\n * THE KEY INVARIANT: We MUST read until EAGAIN. Here's why:\n *\n * Suppose 8000 bytes arrive in the kernel buffer, and our read() call\n * processes 4096. The remaining 4096 bytes sit in the buffer. ET will\n * NOT fire again until the remote end sends MORE bytes. If the protocol\n * requires a response before the client sends more, you have a deadlock:\n *   - Server: waiting for more data (ET won't fire, buffer has stale data)\n *   - Client: waiting for response (won't send more until it gets one)\n *\n * Solution: drain the entire buffer in this event handler.\n */\nvoid handle_client_read_et(int epoll_fd, int fd) {\n    for (;;) {\n        char buf[READ_BUF_SIZE];\n        ssize_t n = read(fd, buf, sizeof(buf));\n        if (n > 0) {\n            /* Echo all bytes back. Same partial-write issue as LT version;\n             * Milestone 2 adds proper write buffering. */\n            ssize_t written = 0;\n            while (written < n) {\n                ssize_t w = write(fd, buf + written, n - written);\n                if (w == -1) {\n                    if (errno == EAGAIN || errno == EWOULDBLOCK) {\n                        /* Send buffer full. Milestone 2 handles this. */\n                        break;\n                    }\n                    conn_close(epoll_fd, fd);\n                    return;\n                }\n                written += w;\n            }\n            /* Continue the loop: may be more data in the receive buffer */\n        } else if (n == 0) {\n            /* Peer closed connection */\n            conn_close(epoll_fd, fd);\n            return;\n        } else {\n            /* n == -1 */\n            if (errno == EAGAIN || errno == EWOULDBLOCK) {\n                /* Buffer fully drained. Done for this event. */\n                break;\n            }\n            /* Real error */\n            conn_close(epoll_fd, fd);\n            return;\n        }\n    }\n}\n/**\n * run_event_loop_et - Edge-triggered event loop.\n *\n * Structure identical to LT version; the difference is entirely in\n * the handlers (drain loops vs single reads).\n */\nvoid run_event_loop_et(int epoll_fd, int listen_fd) {\n    struct epoll_event events[MAX_EVENTS];\n    /* Register listen_fd with ET mode */\n    struct epoll_event ev;\n    ev.events  = EPOLLIN | EPOLLET;\n    ev.data.fd = listen_fd;\n    if (epoll_ctl(epoll_fd, EPOLL_CTL_ADD, listen_fd, &ev) == -1) {\n        perror(\"epoll_ctl listen_fd ET\");\n        return;\n    }\n    for (;;) {\n        int n_ready = epoll_wait(epoll_fd, events, MAX_EVENTS, -1);\n        if (n_ready == -1) {\n            if (errno == EINTR) continue;\n            perror(\"epoll_wait\");\n            break;\n        }\n        for (int i = 0; i < n_ready; i++) {\n            int fd = events[i].data.fd;\n            uint32_t ev_mask = events[i].events;\n            if (fd == listen_fd) {\n                handle_new_connection_et(epoll_fd, listen_fd);\n            } else if (ev_mask & (EPOLLERR | EPOLLHUP)) {\n                conn_close(epoll_fd, fd);\n            } else if (ev_mask & EPOLLIN) {\n                handle_client_read_et(epoll_fd, fd);\n            }\n        }\n    }\n}\n```\n\n![Echo Server: Complete Event Flow for One Connection](./diagrams/diag-m1-echo-server-event-flow.svg)\n\n---\n## The Bug You Must See: Single Read in ET Mode\nTo truly understand the ET/LT difference, deliberately break the ET handler and observe the failure. Change `handle_client_read_et` to perform only a single read (as if you'd naively copy the LT handler):\n```c\n/* DELIBERATELY BROKEN: Single read in ET mode â€” demonstrates data loss */\nvoid handle_client_read_et_BROKEN(int epoll_fd, int fd) {\n    char buf[READ_BUF_SIZE];\n    ssize_t n = read(fd, buf, sizeof(buf));  /* reads only one chunk */\n    if (n > 0) {\n        write(fd, buf, n);  /* echo what we got */\n        /* BUG: if more data is in the buffer, ET will NOT fire again\n         * until the remote sends new data. If protocol expects a response\n         * first (request-response), we deadlock here. */\n    } else if (n == 0) {\n        conn_close(epoll_fd, fd);\n    } else if (errno != EAGAIN && errno != EWOULDBLOCK) {\n        conn_close(epoll_fd, fd);\n    }\n}\n```\nNow test it by sending a large payload in a single TCP segment that exceeds `READ_BUF_SIZE`:\n```bash\n# Generate 8192 bytes and pipe to server (larger than READ_BUF_SIZE=4096)\npython3 -c \"print('A' * 8192)\" | nc localhost 8080\n```\nWith the broken handler, you'll receive 4,096 bytes echoed back, then silence. The remaining 4,096 bytes are trapped in the kernel receive buffer, invisible until the client sends more data. With the correct handler (drain until EAGAIN), you receive all 8,192 bytes.\nUnder a load test sending large requests concurrently, this bug manifests as random request timeoutsâ€”connections that appear connected but never complete.\n---\n## The Non-Blocking Accept Loop and the ET Listening Socket\n\n![Non-blocking accept() Loop with ET Mode](./diagrams/diag-m1-nonblocking-accept-loop.svg)\n\nWhen you register your listening socket with `EPOLLET`, a burst of incoming connections generates a single `EPOLLIN` notification. The `handle_new_connection_et` function's loop-until-EAGAIN is not optionalâ€”it's the same contract as the read loop.\nConsider this scenario:\n- At time T=0: 50 clients simultaneously complete the TCP three-way handshake\n- At time T=1: epoll_wait wakes up with EPOLLIN on listen_fd\n- Your accept loop processes all 50 connections, calling accept4() until EAGAIN\n- At time T=2: epoll_wait returns â€” no pending connection notifications (all were drained)\nWithout the loop, you'd accept 1 connection and miss 49. The kernel queued them in the listen backlog (the `BACKLOG` constant in our `listen()` call), but ET won't re-notify you. They'll sit there until the next connection arrivesâ€”which may never happen.\n---\n## Putting It All Together: The Complete Echo Server\nHere's the full main function wiring everything together, with a compile switch to choose between LT and ET modes:\n```c\n#include <sys/epoll.h>\n#include <sys/socket.h>\n#include <netinet/in.h>\n#include <fcntl.h>\n#include <unistd.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <errno.h>\n#include <stdbool.h>\n#include <stdint.h>\n/* Forward declarations of all functions defined above */\nint  create_epoll(void);\nint  create_listening_socket(void);\nint  epoll_add(int epoll_fd, int fd, uint32_t events);\nint  epoll_mod(int epoll_fd, int fd, uint32_t events);\nint  epoll_del(int epoll_fd, int fd);\nvoid conn_init(int fd);\nvoid conn_close(int epoll_fd, int fd);\nvoid run_event_loop_lt(int epoll_fd, int listen_fd);\nvoid run_event_loop_et(int epoll_fd, int listen_fd);\nint main(int argc, char *argv[]) {\n    /* Default to LT mode; pass \"et\" as argument for ET mode */\n    bool use_et = (argc > 1 && strcmp(argv[1], \"et\") == 0);\n    /* Initialize all connection slots as inactive */\n    memset(connections, 0, sizeof(connections));\n    for (int i = 0; i < MAX_FDS; i++) {\n        connections[i].fd = -1;\n    }\n    int epoll_fd  = create_epoll();\n    int listen_fd = create_listening_socket();\n    printf(\"Echo server starting on port %d (%s mode)...\\n\",\n           PORT, use_et ? \"edge-triggered\" : \"level-triggered\");\n    if (use_et) {\n        /* ET mode: register listen_fd inside run_event_loop_et */\n        run_event_loop_et(epoll_fd, listen_fd);\n    } else {\n        /* LT mode: register listen_fd here, then start loop */\n        if (epoll_add(epoll_fd, listen_fd, EPOLLIN) == -1) {\n            perror(\"epoll_add listen_fd\");\n            exit(EXIT_FAILURE);\n        }\n        run_event_loop_lt(epoll_fd, listen_fd);\n    }\n    close(listen_fd);\n    close(epoll_fd);\n    return 0;\n}\n```\nCompile with:\n```bash\ngcc -O2 -Wall -Wextra -o echo_server echo_server.c\n# Run level-triggered\n./echo_server\n# Run edge-triggered\n./echo_server et\n```\nTest:\n```bash\n# Basic echo test\necho \"hello world\" | nc localhost 8080\n# Multiple simultaneous connections\nfor i in $(seq 1 100); do\n    echo \"connection $i\" | nc -q 1 localhost 8080 &\ndone\nwait\n```\n---\n## Hardware Soul: What the Kernel Actually Does\nUnderstanding the hardware effects explains the performance difference between LT and ETâ€”and why it's smaller than people expect.\n**Cache behavior**: Each `epoll_wait` call returns up to `MAX_EVENTS` (1,024 in our code) events into a stack-allocated array. This array is 1,024 Ã— 12 bytes = 12 KB, which fits in L1 cache (typically 32â€“64 KB). Iterating over ready events is cache-hot.\n**The ready list**: Linux's epoll implementation (in `fs/eventpoll.c`) maintains the ready list (`rdllist`) as a doubly-linked list of `epitem` structures. When you call `epoll_wait`:\n- LT mode: after returning an event, the fd is immediately re-added to `rdllist` if data remains. This requires an extra list manipulation per event.\n- ET mode: the fd is removed from `rdllist` and only re-added when new data arrives (via the socket's `sock_def_readable` callback). Less overhead per event, but your drain loop does more work per event.\nThe net effect: ET has slightly lower kernel overhead per `epoll_wait` call, but your application does more work per event (the drain loop). At high throughput, the difference is measurable but often less than 5â€“10%. The real reason NGINX uses ET is **correctness under high connection rates**â€”ET's single-notification model eliminates redundant wakeups from partially-consumed buffers, keeping the event loop lean.\n**TLB and page fault cost**: The per-connection state array (`connections[MAX_FDS]`) is 65,536 Ã— 4,112 bytes â‰ˆ 256 MB. Not all of it is residentâ€”the kernel uses demand paging. Accessing the state for a new connection (touching a page not recently accessed) causes a page fault if it hasn't been accessed recently, adding ~1â€“10 Âµs to connection setup. Under sustained load with 10K active connections, these pages will all be resident and TLB-warm.\n**Branch prediction**: The `errno == EAGAIN || errno == EWOULDBLOCK` check in the read loop is nearly always false during drain (we expect to read data, not hit EAGAIN until the end). The branch predictor learns this quicklyâ€”after a few iterations, the EAGAIN branch is predicted not-taken with high accuracy, costing only 1 cycle.\n**Memory access pattern**: Reading the receive buffer sequentially (sequential bytes from `read()`) is prefetch-friendly. The hardware prefetcher recognizes the linear access pattern and loads upcoming cache lines before you need them, hiding memory latency.\n---\n## Design Decision: LT vs ET â€” Which Should You Use?\n| Property | Level-Triggered (LT) | Edge-Triggered (ET) |\n|----------|----------------------|---------------------|\n| **Required read discipline** | Single read per event is sufficient | Must drain until EAGAIN |\n| **Required accept discipline** | Can accept one per event | Must accept until EAGAIN |\n| **Behavior on partial read** | Re-notified on next epoll_wait | Silent until more data arrives |\n| **Kernel overhead per event** | Slightly higher (re-adds to rdllist) | Slightly lower |\n| **Risk of data loss on bug** | Low (just slower) | High (silent data loss) |\n| **Who uses it** | Node.js (libuv), Twisted | NGINX, Redis (optionally), io_uring |\n| **Correct for beginners** | âœ“ Easier to implement correctly | âœ— Requires strict discipline |\n**The verdict**: Use LT for this milestone to build intuition. Implement ET to understand the constraint. In production, either works correctly if implemented correctlyâ€”the performance difference rarely justifies the cognitive overhead of ET for application-level code.\nNode.js explicitly chose LT for libuv after analysis showed that the complexity of ensuring every callback drains its socket was an unacceptable maintenance burden. NGINX chose ET because NGINX's architecture guarantees the drain discipline at the module API levelâ€”every handler is required to read until EAGAIN, and this is enforced by code review and convention.\n---\n## The Three-Level View: One Read Call\nLet's trace a single `read()` call through the stack:\n**Level 1 â€” Application**: Your code calls `read(fd, buf, 4096)`. A number (positive: bytes read, 0: EOF, -1: error or EAGAIN) returns.\n**Level 2 â€” Kernel**: The `read()` syscall enters the kernel via the syscall table. The kernel's socket layer (`net/socket.c`) finds the TCP socket's receive buffer (`sk_receive_queue`). It copies bytes from the socket buffer into your user-space `buf` using `copy_to_user()`. If the buffer was drained below a threshold, the kernel updates the socket's readiness state. In ET mode, if the buffer was previously non-empty and now becomes empty, the epoll subsystem removes the `epitem` from the ready list.\n**Level 3 â€” Hardware**: `copy_to_user()` is essentially a `memcpy` from kernel-space to user-space. On a modern CPU with virtual memory, both the kernel buffer and user buffer are virtual addresses. The MMU translates them to physical addresses using the page table, checked via TLB. If the user-space buffer page is in TLB (likely for the first read after a context switch into the epoll loop), this is fast. The actual data transfer uses SSE2 or AVX `movdqu`/`vmovdqu` instructions for vectorized 16- or 32-byte copies. At 4096 bytes with AVX2 (32-byte copies), that's 128 vector instructionsâ€”approximately 64 cycles on a modern CPU, or ~20 ns at 3 GHz.\n---\n## Knowledge Cascade: What This Unlocks\nNow that you understand epoll's fundamentals and the ET/LT contract, you have a lens for understanding systems you'll encounter throughout your career:\n**1. NGINX's module bug surface**: NGINX uses ET mode exclusively and documents that every module must call `ngx_handle_read_event()` and drain the socket. Third-party NGINX modules are a frequent source of bugs precisely because module authors forget the drain disciplineâ€”the module works correctly in unit testing (small payloads) but loses data under production load. You now know exactly why.\n**2. TCP flow control and ET's hidden interaction**: When you drain the socket buffer aggressively (ET's drain-until-EAGAIN), you keep the kernel's receive buffer empty. This signals to the TCP stack that your application can receive more data. TCP's receive window (advertised to the remote sender) stays large. If you *don't* drain (the LT partial-read case), the receive buffer fills, the window shrinks, and TCP backpressure naturally slows the sender. ET mode thus affects TCP's flow control behaviorâ€”aggressive draining can increase throughput but also means your application sees larger bursts of data that it must handle efficiently.\n**3. io_uring: epoll's eventual successor**: io_uring (Linux 5.1+) eliminates the epoll `wait â†’ read â†’ write` syscall pattern entirely. You submit `read` and `write` operations to a ring buffer, and completions appear in another ring bufferâ€”no `epoll_wait`, no per-event `read()` syscall. At 10K connections with small messages, epoll spends significant CPU time in syscall overhead (context switches to kernel space). io_uring amortizes this by batching. The ET/LT distinction doesn't exist in io_uring's completion model (it's inherently edge-notificationâ€”you get one completion per submitted operation). Understanding epoll's model makes io_uring's design decisions legible.\n**4. The C10K paper and historical context**: Dan Kegel's 1999 C10K paper (cited in your resources) described this exact problem before Linux had epoll. The solutions proposedâ€”non-blocking I/O, event-driven architectures, `select`/`poll` improvementsâ€”directly led to epoll's design. Reading it now, you'll recognize every problem and understand why epoll solved them the way it did. The paper is a time capsule of the moment when event-driven architecture stopped being exotic and became necessary.\n**5. Cross-domain: Browser event loops**: JavaScript's event loop (the foundation of Node.js and browsers) is the same reactor pattern you just builtâ€”a single-threaded loop that dispatches events to callbacks. `setTimeout`, `Promise.then`, and `EventListener` callbacks are all queued events, processed in order. The \"event loop\" terminology in JavaScript directly inherits from the networking reactor pattern you're building. When JavaScript developers talk about \"not blocking the event loop,\" they mean exactly what you now know: if a callback takes 100ms, all other events are delayed by 100msâ€”same constraint, different context.\n---\n## Pitfall Reference: The Five Ways This Breaks\nBefore you move on, memorize these failure modes:\n**Pitfall 1: ET with single read per event**\n*Symptom*: Works in testing, silently loses data under load, causing protocol-level deadlocks.\n*Fix*: Always loop until EAGAIN in ET mode.\n**Pitfall 2: ET listening socket without accept loop**\n*Symptom*: Under connection bursts, new clients connect but receive no response; their connections sit in the listen backlog.\n*Fix*: Accept in a loop until EAGAIN in both the listen handler and the accept function.\n**Pitfall 3: Treating EAGAIN as an error**\n*Symptom*: Connections closed immediately after the first \"empty read,\" or spurious connection resets.\n*Fix*: Check `errno == EAGAIN || errno == EWOULDBLOCK` and return without closing.\n**Pitfall 4: Not setting the listen socket to non-blocking**\n*Symptom*: Server hangs under specific TCP RST race conditions; `accept()` blocks briefly on a connection that was reset before accept ran.\n*Fix*: Use `SOCK_NONBLOCK` in the `socket()` call or `set_nonblocking()` before `listen()`.\n**Pitfall 5: MAX_EVENTS too small**\n*Symptom*: Under high load, `epoll_wait` returns the maximum each call, requiring many calls to drain the ready list; reduces throughput.\n*Fix*: Set `MAX_EVENTS` between 512 and 4096. 1024 is a common default; tune based on your event distribution.\n---\n<!-- END_MS -->\n\n\n<!-- MS_ID: build-event-loop-m2 -->\n<!-- MS_ID: build-event-loop-m2 -->\n# Write Buffering and Timer Management\n## The Problem You Haven't Solved Yet\nYour echo server from Milestone 1 has a quiet bug. Look at the write path:\n```c\nssize_t w = write(fd, buf + written, n - written);\nif (w == -1) {\n    if (errno == EAGAIN || errno == EWOULDBLOCK) {\n        /* Send buffer full. Milestone 2 handles this. */\n        break;  // â† THIS IS THE BUG\n    }\n    ...\n}\n```\nWhen `write()` returns `EAGAIN`, you `break` out of the write loop and discard the unsent bytes. For an echo server with small payloads, the kernel's send buffer is almost always large enough that this never triggers. In production, under load, with large responses and slow clients, this path fires constantlyâ€”and every time it does, you silently drop data.\nBut the naive fixâ€”just retry `write()` in a loop until it succeedsâ€”transforms your elegant event loop into a blocking server. If one client's socket buffer is full, the server stalls waiting for it to drain, freezing all other 9,999 connections.\nThe correct solution requires two interlocking mechanisms:\n1. **A write buffer**: When `write()` returns `EAGAIN`, save the unsent bytes in a per-connection queue. Don't drop them, don't retry synchronouslyâ€”save them.\n2. **EPOLLOUT management**: Register interest in `EPOLLOUT` to be notified when the socket's send buffer drains. When it fires, flush the queued bytes. When the queue empties, *deregister* `EPOLLOUT`.\nThat deregistration is the critical step most developers missâ€”and it's the subject of this milestone's core revelation.\n{{DIAGRAM:diag-m2-write-buffer-lifecycle}}\n---\n## The Revelation: EPOLLOUT Is NOT Like EPOLLIN\nHere's the misconception you need to shatter before writing a single line of code.\n`EPOLLIN` fires when data *arrives*. Between arrivals, the socket is quiet. `EPOLLIN` is an edge condition: something changed (data appeared). If no data is arriving, `EPOLLIN` doesn't fire, and `epoll_wait` correctly sleeps.\nNow consider `EPOLLOUT`. It fires when the socket's send buffer has space for writing. How often does a TCP socket have space in its send buffer?\nAlmost always.\nThe Linux TCP send buffer defaults to 87 KB (expandable to 208 KB with autotuning). Your server is sending kilobytes at a time. The send buffer drains rapidlyâ€”the kernel reads from it and hands bytes to the NIC continuously. A socket's send buffer is full only during a brief window where you're writing faster than the network can send.\nIf you leave `EPOLLOUT` registered when you have nothing to write, `epoll_wait` will return your fd as \"writable\" on *every single call*. There's nothing to write, so your handler returns immediately. Then `epoll_wait` returns again. And again. 100% CPU, no work done.\n```\n[WITHOUT proper EPOLLOUT management]\nepoll_wait() returns â€” EPOLLOUT on fd 5 (nothing to write)\nepoll_wait() returns â€” EPOLLOUT on fd 5 (nothing to write)\nepoll_wait() returns â€” EPOLLOUT on fd 5 (nothing to write)\nâ†‘ This loop runs at ~1,000,000 iterations/second, pinning one CPU core.\n```\n\n![Trace: EPOLLOUT Busy-Loop Bug](./diagrams/diag-m2-epollout-busy-loop-trace.svg)\n\nThe correct pattern is a three-step cycle:\n1. **Normal state**: Only `EPOLLIN` is registered. `EPOLLOUT` is NOT registered.\n2. **write() returns EAGAIN**: Buffer the remaining data. Register `EPOLLOUT` (using `epoll_ctl EPOLL_CTL_MOD`).\n3. **EPOLLOUT fires**: Flush the write buffer. If the buffer empties, deregister `EPOLLOUT` (back to `EPOLLIN` only). If `EAGAIN` again, stay registered.\nThis register-flush-deregister cycle is not a clever optimization. It is the *only correct implementation*. Every production event loop that handles large responses does exactly this: libuv (Node.js), libevent, libev, NGINX, andâ€”as we'll see in the Knowledge Cascadeâ€”Redis.\n---\n## Building the Write Buffer\nBefore the code, understand what you're building. A write buffer is a byte queue attached to each connection. It holds data that `write()` couldn't send because the kernel's send buffer was full. It must:\n- Store arbitrary amounts of data (bounded by a configured maximum)\n- Track where in the buffer writing left off (the \"offset\")\n- Be efficient to append to and drain from\n- Free its memory when the connection closes\nThe simplest correct implementation uses a dynamically allocated byte array with a capacity, a used-bytes count, and an offset indicating where draining left off.\n\n![Write Buffer: Byte-Level Memory Layout](./diagrams/diag-m2-write-buffer-struct-layout.svg)\n\n```c\n#include <stdlib.h>\n#include <string.h>\n#include <stdint.h>\n#include <stdbool.h>\n#define WRITE_BUF_MAX (256 * 1024)   /* 256 KB max write buffer per connection */\n#define WRITE_BUF_INIT (4 * 1024)    /* Initial allocation: 4 KB */\n/**\n * write_buf - Dynamically-sized write buffer for a single connection.\n *\n * Memory layout (on 64-bit):\n *   offset  0: data     (8 bytes â€” pointer)\n *   offset  8: len      (4 bytes â€” bytes in buf from offset onward)\n *   offset 12: cap      (4 bytes â€” total allocated bytes)\n *   offset 16: offset   (4 bytes â€” start of unwritten data)\n *   offset 20: [4 bytes padding]\n *   Total: 24 bytes per connection\n *\n * Invariant: data[offset .. offset+len] contains unsent bytes.\n * When len == 0, the buffer is empty; EPOLLOUT should be deregistered.\n * When offset > cap/2, compact: memmove(data, data+offset, len); offset=0.\n */\ntypedef struct {\n    char    *data;    /* heap-allocated byte array */\n    uint32_t len;     /* number of buffered (unsent) bytes */\n    uint32_t cap;     /* total allocated capacity */\n    uint32_t offset;  /* index of first unsent byte */\n} write_buf;\n/**\n * wbuf_init - Initialize a write buffer with no allocation.\n * Allocation is deferred until the first write failure.\n */\nvoid wbuf_init(write_buf *wb) {\n    wb->data   = NULL;\n    wb->len    = 0;\n    wb->cap    = 0;\n    wb->offset = 0;\n}\n/**\n * wbuf_free - Release all memory held by the write buffer.\n * Must be called when the connection closes.\n */\nvoid wbuf_free(write_buf *wb) {\n    free(wb->data);\n    wbuf_init(wb);\n}\n/**\n * wbuf_append - Add bytes to the write buffer.\n *\n * First compacts the buffer if offset has consumed more than half the\n * allocation (avoids unbounded growth from repeated append+drain cycles).\n * Then grows the allocation if needed (doubling strategy).\n *\n * Returns 0 on success, -1 if buffer would exceed WRITE_BUF_MAX.\n */\nint wbuf_append(write_buf *wb, const char *data, uint32_t data_len) {\n    /* Reject if this would exceed the hard cap */\n    if (wb->len + data_len > WRITE_BUF_MAX) {\n        return -1;  /* caller should close this connection */\n    }\n    /* Compact if offset wasted more than half the capacity */\n    if (wb->offset > wb->cap / 2 && wb->len > 0) {\n        memmove(wb->data, wb->data + wb->offset, wb->len);\n        wb->offset = 0;\n    }\n    /* Grow if needed */\n    uint32_t needed = wb->offset + wb->len + data_len;\n    if (needed > wb->cap) {\n        uint32_t new_cap = wb->cap == 0 ? WRITE_BUF_INIT : wb->cap * 2;\n        while (new_cap < needed) new_cap *= 2;\n        if (new_cap > WRITE_BUF_MAX) new_cap = WRITE_BUF_MAX;\n        char *new_data = realloc(wb->data, new_cap);\n        if (!new_data) return -1;  /* OOM â€” close connection */\n        wb->data = new_data;\n        wb->cap  = new_cap;\n    }\n    memcpy(wb->data + wb->offset + wb->len, data, data_len);\n    wb->len += data_len;\n    return 0;\n}\n/**\n * wbuf_consume - Advance the buffer by 'n' bytes (those bytes were sent).\n */\nstatic inline void wbuf_consume(write_buf *wb, uint32_t n) {\n    wb->offset += n;\n    wb->len    -= n;\n    if (wb->len == 0) {\n        wb->offset = 0;  /* reset to avoid creeping offset */\n    }\n}\n/**\n * wbuf_is_empty - True when there are no unsent bytes.\n */\nstatic inline bool wbuf_is_empty(const write_buf *wb) {\n    return wb->len == 0;\n}\n```\n> **Why double the capacity?** The doubling strategy amortizes `realloc` calls. If you added one byte at a time, each addition might require a new allocation and memory copy. By doubling, you pay O(log N) realloc calls for N bytes appended totalâ€”each byte's amortized allocation cost is O(1). This is the same strategy used by C++'s `std::vector` and Rust's `Vec`.\n> **Why the compaction threshold?** Consider a connection that repeatedly appends 100 bytes and sends 100 bytes. Without compaction, `offset` creeps forward: 100, 200, 300... eventually reaching `cap`, at which point `realloc` extends the buffer unnecessarily. By compacting when offset exceeds half the capacity, we bound this waste. The `memmove` cost (O(len)) is paid infrequentlyâ€”only when offset drifts far.\n---\n## Updated Per-Connection State\nNow update the `conn_state` struct from Milestone 1 to include the write buffer and an EPOLLOUT-registered flag:\n```c\n/* From Milestone 1: */\n/* #define READ_BUF_SIZE 4096 */\n/* #define MAX_FDS       65536 */\n/**\n * conn_state - Per-connection state (updated for Milestone 2).\n *\n * Memory layout (approximate, 64-bit):\n *   offset     0: read_buf[4096]   = 4096 bytes\n *   offset  4096: wbuf             = 24 bytes (write_buf struct)\n *   offset  4120: read_len         = 4 bytes\n *   offset  4124: fd               = 4 bytes\n *   offset  4128: active           = 1 byte\n *   offset  4129: epollout_armed   = 1 byte\n *   offset  4130: [6 bytes padding]\n *   offset  4136: timer_expiry_ms  = 8 bytes (uint64_t)\n *   offset  4144: timer_idx        = 4 bytes (index in timer heap, -1 if none)\n *   offset  4148: [4 bytes padding]\n *   Total: ~4152 bytes per connection\n *\n * At 10,000 connections: 10,000 Ã— 4152 â‰ˆ 40.5 MB resident.\n * The write_buf.data pointer is separately heap-allocated on demand;\n * connections that never need write buffering pay only the 24-byte struct.\n */\ntypedef struct {\n    char      read_buf[READ_BUF_SIZE];\n    write_buf wbuf;              /* write queue for backpressured data */\n    uint32_t  read_len;\n    int       fd;\n    bool      active;\n    bool      epollout_armed;   /* true if EPOLLOUT is currently registered */\n    uint64_t  timer_expiry_ms;  /* absolute expiry time (monotonic ms), 0 = no timer */\n    int       timer_idx;        /* position in min-heap, -1 if not in heap */\n} conn_state;\nstatic conn_state connections[MAX_FDS];\n```\n> **`epollout_armed`**: This boolean is the guard that prevents the busy-loop bug. Before calling `epoll_ctl(EPOLL_CTL_MOD)` to add or remove `EPOLLOUT`, always check this flag. Redundant `epoll_ctl` calls are not catastrophic (they're idempotent), but they're unnecessary syscalls. More importantly, `epollout_armed` makes your intent explicit in the codeâ€”it's documentation that the event loop cares deeply about this state.\n---\n## The Write Path: Attempt, Buffer, Register\nHere's the unified write function. Call it every time your server needs to send data to a clientâ€”whether it's an echo response, an HTTP reply, or any other output:\n```c\n#include <errno.h>\n#include <sys/epoll.h>\n#include <unistd.h>\n/**\n * conn_write - Send data to a connection, buffering if the socket is full.\n *\n * Flow:\n *   1. If the write buffer is non-empty, we MUST append to it (can't bypass\n *      the queue â€” data must arrive in order). Attempt to flush first.\n *   2. Attempt write() directly to the socket.\n *   3. If EAGAIN, buffer the unsent remainder and arm EPOLLOUT.\n *   4. If the write buffer grows beyond WRITE_BUF_MAX, close the connection\n *      (slow client defense â€” discussed in TCP Backpressure section below).\n *\n * Returns 0 on success (data sent or queued), -1 if connection should close.\n */\nint conn_write(int epoll_fd, conn_state *c, const char *data, uint32_t len) {\n    /* If there's already buffered data, don't bypass it â€” append and flush */\n    if (!wbuf_is_empty(&c->wbuf)) {\n        if (wbuf_append(&c->wbuf, data, len) == -1) {\n            return -1;  /* buffer overflow â€” caller must close connection */\n        }\n        return conn_flush(epoll_fd, c);\n    }\n    /* Write buffer is empty: attempt direct write first (fast path) */\n    ssize_t written = 0;\n    while ((uint32_t)written < len) {\n        ssize_t w = write(c->fd, data + written, len - written);\n        if (w > 0) {\n            written += w;\n            continue;\n        }\n        if (w == -1 && (errno == EAGAIN || errno == EWOULDBLOCK)) {\n            /* Send buffer full: queue the unsent remainder */\n            uint32_t remaining = len - (uint32_t)written;\n            if (wbuf_append(&c->wbuf, data + written, remaining) == -1) {\n                return -1;  /* buffer overflow */\n            }\n            /* Arm EPOLLOUT so we're notified when buffer drains */\n            if (!c->epollout_armed) {\n                struct epoll_event ev;\n                ev.events  = EPOLLIN | EPOLLOUT;\n                ev.data.fd = c->fd;\n                if (epoll_ctl(epoll_fd, EPOLL_CTL_MOD, c->fd, &ev) == -1) {\n                    return -1;\n                }\n                c->epollout_armed = true;\n            }\n            return 0;  /* data queued; will be flushed when EPOLLOUT fires */\n        }\n        /* Real error (EPIPE, ECONNRESET, etc.) */\n        return -1;\n    }\n    return 0;  /* fully written on the fast path */\n}\n/**\n * conn_flush - Drain the write buffer to the socket.\n *\n * Called when EPOLLOUT fires. Writes as much as the socket will accept.\n * If the buffer empties, deregisters EPOLLOUT to prevent busy-looping.\n * If write() hits EAGAIN again, leaves EPOLLOUT armed and returns.\n *\n * Returns 0 on success, -1 on error (caller must close connection).\n */\nint conn_flush(int epoll_fd, conn_state *c) {\n    while (!wbuf_is_empty(&c->wbuf)) {\n        const char *ptr = c->wbuf.data + c->wbuf.offset;\n        uint32_t    n   = c->wbuf.len;\n        ssize_t w = write(c->fd, ptr, n);\n        if (w > 0) {\n            wbuf_consume(&c->wbuf, (uint32_t)w);\n            continue;\n        }\n        if (w == -1 && (errno == EAGAIN || errno == EWOULDBLOCK)) {\n            /* Socket buffer still full â€” stay armed, wait for next EPOLLOUT */\n            return 0;\n        }\n        /* Real error */\n        return -1;\n    }\n    /* Buffer is now empty â€” CRITICAL: deregister EPOLLOUT */\n    if (c->epollout_armed) {\n        struct epoll_event ev;\n        ev.events  = EPOLLIN;   /* back to read-only interest */\n        ev.data.fd = c->fd;\n        if (epoll_ctl(epoll_fd, EPOLL_CTL_MOD, c->fd, &ev) == -1) {\n            return -1;\n        }\n        c->epollout_armed = false;\n    }\n    return 0;\n}\n```\nStudy the `conn_flush` function's deregistration block. This is the heartbeat of the EPOLLOUT cycle. When `wbuf_is_empty()` returns true and `epollout_armed` is true, a single `epoll_ctl(EPOLL_CTL_MOD)` call switches the fd's interest back to `EPOLLIN` only. From that point, `epoll_wait` will not return this fd as writable until you arm it again. CPU usage drops from 100% to near-zero during idle periods.\n---\n## Integrating Write Buffering Into the Event Loop\nThe event loop from Milestone 1 needs two changes: handle `EPOLLOUT` events, and use `conn_write` instead of raw `write()`.\n```c\n/**\n * handle_client_write - Called when EPOLLOUT fires for a client fd.\n * Flushes the write buffer. If flush fails, closes the connection.\n */\nvoid handle_client_write(int epoll_fd, int fd) {\n    conn_state *c = &connections[fd];\n    if (conn_flush(epoll_fd, c) == -1) {\n        conn_close(epoll_fd, fd);\n    }\n}\n/* In the main event dispatch loop: */\nfor (int i = 0; i < n_ready; i++) {\n    int fd          = events[i].data.fd;\n    uint32_t ev     = events[i].events;\n    if (fd == listen_fd) {\n        handle_new_connection(epoll_fd, listen_fd);\n    } else if (ev & (EPOLLERR | EPOLLHUP)) {\n        conn_close(epoll_fd, fd);\n    } else {\n        /* Handle EPOLLIN and EPOLLOUT independently â€” both can fire together */\n        if (ev & EPOLLIN) {\n            handle_client_read(epoll_fd, fd);\n        }\n        if (ev & EPOLLOUT) {\n            /* Check active: EPOLLIN handler may have closed this connection */\n            if (connections[fd].active) {\n                handle_client_write(epoll_fd, fd);\n            }\n        }\n    }\n}\n```\n> **Why check `connections[fd].active` before handling `EPOLLOUT`?** `EPOLLIN` and `EPOLLOUT` can fire simultaneously on the same fd in the same `epoll_wait` batch. If `handle_client_read` closes the connection (because the client sent EOF or an invalid request), the fd is freed. Then the `EPOLLOUT` handler would access freed state. The `active` check prevents this. Milestone 3 will introduce deferred closure as a more robust solution.\n{{DIAGRAM:diag-m2-tcp-backpressure-flow}}\n---\n## TCP Backpressure and the Slow Loris Defense\nYour write buffer is a queue between your application and the kernel's send buffer. But if the client reads slowly (or not at all), the kernel's send buffer fills and stays full. Every `conn_write` call hits `EAGAIN`, appending more data to your write buffer. The write buffer grows. Eventually it exceeds `WRITE_BUF_MAX`â€”what then?\nThis is the **slow loris** scenario (named after a slow-moving primateâ€”it's also a famous HTTP attack). A malicious client opens thousands of connections, sends partial HTTP requests to keep them alive, and never reads responses. Each connection accumulates an unbounded write buffer. Your server runs out of memory and crashes.\nThe defense: `WRITE_BUF_MAX`. When `wbuf_append` would exceed it, return -1, and the caller closes the connection. This is not user-friendlyâ€”we're cutting off a legitimate client whose network is slow. But it's the correct production behavior. Real-world servers (NGINX, Apache) configure this limit explicitly (`send_timeout`, `client_body_timeout`). The idle timeout you'll build in the next section provides a complementary defense: connections that haven't received data in 30 seconds are closed regardless of write buffer state.\n> **Cross-domain connection: Distributed systems backpressure**. When your write buffer fills because the client reads slowly, you're absorbing pressure that should propagate upstream. In a distributed system, this is exactly the problem that TCP's receive window mechanism handles between nodesâ€”it slows down the sender when the receiver's buffer fills. Your in-process write buffer serves the same role between your application logic and the network stack. Without a cap, you become an unbounded buffer that hides backpressure rather than propagating it. This is a fundamental distributed systems anti-pattern: the \"buffer bloat\" problem that causes latency spikes in routers and operating system network stacks.\n\n![State Evolution: Connection Create â†’ Active â†’ Timeout â†’ Cleanup](./diagrams/diag-m2-connection-lifecycle-state-evolution.svg)\n\n---\n## Timer Management: The Event Loop's Internal Clock\nYour event loop has no notion of time. It sits in `epoll_wait` until I/O events arrive. But you need to close idle connectionsâ€”ones that connected and then went silent for 30 seconds. How do you implement \"do this in N seconds\" in a system that only wakes up on I/O?\nThe answer: `epoll_wait`'s third argumentâ€”the timeout.\n```c\nint n_ready = epoll_wait(epoll_fd, events, MAX_EVENTS, timeout_ms);\n//                                                     ^^^^^^^^^^\n//                                         If no I/O events arrive within\n//                                         timeout_ms milliseconds, epoll_wait\n//                                         returns 0 (not an error). This is\n//                                         your timer tick.\n```\nWhen `epoll_wait` returns 0, no I/O events firedâ€”you woke up because time passed. Check your timer data structure for expired timers and process them.\nThe timeout you pass should be: **\"how many milliseconds until the next timer expires?\"** If you have a connection that times out in 12,342 ms, pass 12,342. If no timers are pending, pass -1 (block forever). This way the event loop sleeps exactly as long as neededâ€”no more, no less.\n\n![Timer Integration: epoll_wait Timeout Calculation](./diagrams/diag-m2-epoll-timeout-integration.svg)\n\n### Choosing a Timer Data Structure\nYou need a data structure that efficiently answers: \"what is the next timer to expire?\" This is a classic priority queue problem. Two main options:\n**Min-Heap** (recommended for this milestone):\n- Insert: O(log N)\n- Find minimum: O(1) (always the root)\n- Delete minimum: O(log N)\n- Cancel (arbitrary deletion): O(log N) with position tracking\n- Simple to implement correctly\n- Used by: Nginx's `ngx_event_timer_rbtree` (red-black tree variant), libuv's timer implementation\n**Timer Wheel**:\n- Insert: O(1)\n- Tick (process expired): O(1) amortized per slot\n- Cancel: O(1)\n- More complex; best when timers cluster around a fixed duration (like a 30-second idle timeout)\n- Used by: Linux kernel's internal timer mechanism (hierarchical timer wheels), Kafka's `TimingWheel`\n> **When does log(N) beat O(1)?** The timer wheel's O(1) insert has a constant factor from the modulo operation (or bitwise AND for power-of-2 sizes) plus cache effects from touching potentially cold slots. For N < ~10,000 timers, a min-heap's O(log N) â‰ˆ logâ‚‚(10,000) â‰ˆ 13 comparisons often beats the timer wheel in practice because the heap's root and first few levels stay cache-hot. At N > 100,000, the wheel wins. For this projectâ€”targeting 10K connectionsâ€”a min-heap is simpler and fast enough.\n> **ðŸ”‘ Foundation: Min-Heap**\n>\n> **1. What it IS**\n> A min-heap is a binary tree stored in a flat array where every parent's value is less than or equal to its children's values. The minimum value is always at index 0. It's \"complete\"â€”all levels are fully filled except possibly the last, which fills left to right. This shape guarantee means the tree never becomes unbalanced and the array representation wastes no space.\n>\n> **2. Why you need it right now**\n> You need to efficiently find the connection that times out *soonest* (the minimum expiry time) so you can pass the right timeout to `epoll_wait`. With a min-heap, this is always `heap[0]`â€”a single array access. Inserting a new timer or removing an expired one requires at most O(log N) operations where N is the number of active timers.\n>\n> **3. Key Insight: The Array Encoding**\n> The parent of a node at index `i` is at index `(i - 1) / 2`. The left child is at `2*i + 1`, the right child at `2*i + 2`. This arithmetic eliminates pointers entirelyâ€”the tree structure is implicit in the indices. Inserting adds to the end, then \"bubbles up\" by swapping with the parent if smaller. Removing the minimum replaces it with the last element, then \"bubbles down\" by swapping with the smaller child if larger. Both operations are O(log N).\n\n![Min-Heap Timer: Insert, Cancel, Expire Operations](./diagrams/diag-m2-min-heap-timer-structure.svg)\n\n### Implementing the Min-Heap Timer\n```c\n#include <stdint.h>\n#include <time.h>\n#define TIMER_HEAP_MAX 65536   /* maximum simultaneous timers */\n#define IDLE_TIMEOUT_MS 30000  /* 30 seconds in milliseconds */\n/**\n * timer_entry - One entry in the timer min-heap.\n *\n * expiry_ms: absolute expiry time in monotonic milliseconds.\n * fd:        the connection fd this timer belongs to.\n *\n * Memory layout: 12 bytes per entry (8 + 4).\n * Full heap at 65536 entries: 65536 Ã— 12 = 768 KB â€” fits in L2 cache.\n */\ntypedef struct {\n    uint64_t expiry_ms;\n    int      fd;\n} timer_entry;\n/**\n * timer_heap - Min-heap of timer_entry, ordered by expiry_ms.\n *\n * connections[fd].timer_idx stores each entry's current index in this heap,\n * enabling O(log N) cancellation without linear search.\n */\nstatic timer_entry timer_heap[TIMER_HEAP_MAX];\nstatic int         timer_heap_size = 0;\n/**\n * now_ms - Return current monotonic time in milliseconds.\n *\n * CLOCK_MONOTONIC is critical here: it never jumps backward or forward\n * due to NTP adjustments or daylight saving time changes. Timer intervals\n * computed with wall-clock time (CLOCK_REALTIME) can be wrong by hours\n * if the clock is adjusted while the server runs.\n */\nuint64_t now_ms(void) {\n    struct timespec ts;\n    clock_gettime(CLOCK_MONOTONIC, &ts);\n    return (uint64_t)ts.tv_sec * 1000ULL + (uint64_t)ts.tv_nsec / 1000000ULL;\n}\n/**\n * heap_swap - Swap two entries in the heap, updating timer_idx in conn_state.\n */\nstatic void heap_swap(int i, int j) {\n    timer_entry tmp  = timer_heap[i];\n    timer_heap[i]    = timer_heap[j];\n    timer_heap[j]    = tmp;\n    /* Keep conn_state.timer_idx in sync so we can find entries for cancellation */\n    connections[timer_heap[i].fd].timer_idx = i;\n    connections[timer_heap[j].fd].timer_idx = j;\n}\n/**\n * heap_sift_up - Restore min-heap property upward from index i.\n * Called after inserting at the end of the array.\n */\nstatic void heap_sift_up(int i) {\n    while (i > 0) {\n        int parent = (i - 1) / 2;\n        if (timer_heap[parent].expiry_ms <= timer_heap[i].expiry_ms) break;\n        heap_swap(i, parent);\n        i = parent;\n    }\n}\n/**\n * heap_sift_down - Restore min-heap property downward from index i.\n * Called after removing the minimum (replacing it with the last element).\n */\nstatic void heap_sift_down(int i) {\n    for (;;) {\n        int left  = 2 * i + 1;\n        int right = 2 * i + 2;\n        int smallest = i;\n        if (left  < timer_heap_size &&\n            timer_heap[left].expiry_ms  < timer_heap[smallest].expiry_ms)\n            smallest = left;\n        if (right < timer_heap_size &&\n            timer_heap[right].expiry_ms < timer_heap[smallest].expiry_ms)\n            smallest = right;\n        if (smallest == i) break;\n        heap_swap(i, smallest);\n        i = smallest;\n    }\n}\n/**\n * timer_set - Insert or reset a timer for connection fd.\n *\n * If the connection already has a timer (timer_idx >= 0), removes it first,\n * then inserts with the new expiry. This implements \"reset on activity.\"\n *\n * expiry_ms: absolute time (from now_ms()) when this timer fires.\n */\nvoid timer_set(int fd, uint64_t expiry_ms) {\n    conn_state *c = &connections[fd];\n    /* Cancel existing timer if present */\n    if (c->timer_idx >= 0) {\n        timer_cancel(fd);\n    }\n    if (timer_heap_size >= TIMER_HEAP_MAX) {\n        /* Heap full: can't add timer. In production, close oldest connection. */\n        return;\n    }\n    int idx = timer_heap_size++;\n    timer_heap[idx].expiry_ms = expiry_ms;\n    timer_heap[idx].fd        = fd;\n    c->timer_idx              = idx;\n    c->timer_expiry_ms        = expiry_ms;\n    heap_sift_up(idx);\n}\n/**\n * timer_cancel - Remove a connection's timer from the heap.\n *\n * Uses the O(1) lookup via conn_state.timer_idx, then removes in O(log N)\n * by swapping with the last element and sifting.\n */\nvoid timer_cancel(int fd) {\n    conn_state *c = &connections[fd];\n    int idx = c->timer_idx;\n    if (idx < 0) return;  /* no timer */\n    c->timer_idx       = -1;\n    c->timer_expiry_ms = 0;\n    int last = --timer_heap_size;\n    if (idx == last) return;  /* removing the last element â€” nothing to fix */\n    /* Move last element into the vacated slot */\n    timer_heap[idx] = timer_heap[last];\n    connections[timer_heap[idx].fd].timer_idx = idx;\n    /* The moved element may be too small (sift up) or too large (sift down) */\n    heap_sift_up(idx);\n    heap_sift_down(idx);\n}\n/**\n * timer_next_ms - Return milliseconds until the next timer expires.\n * Returns -1 if no timers are pending (epoll_wait should block indefinitely).\n * Returns 0 if a timer is already expired (process immediately).\n */\nint timer_next_ms(void) {\n    if (timer_heap_size == 0) return -1;\n    uint64_t now    = now_ms();\n    uint64_t expiry = timer_heap[0].expiry_ms;\n    if (expiry <= now) return 0;\n    uint64_t diff = expiry - now;\n    /* Clamp to INT_MAX: epoll_wait timeout is int milliseconds */\n    return (diff > (uint64_t)INT_MAX) ? INT_MAX : (int)diff;\n}\n/**\n * timer_process_expired - Fire all timers whose expiry_ms <= now.\n *\n * Called after epoll_wait returns (whether due to I/O or timeout).\n * Must process ALL expired timers in a single call â€” multiple may expire\n * between epoll_wait invocations (especially under high load).\n */\nvoid timer_process_expired(int epoll_fd) {\n    uint64_t now = now_ms();\n    while (timer_heap_size > 0 && timer_heap[0].expiry_ms <= now) {\n        int fd = timer_heap[0].fd;\n        /* timer_cancel will be called inside conn_close */\n        fprintf(stderr, \"Idle timeout: closing fd %d\\n\", fd);\n        conn_close(epoll_fd, fd);\n        /* conn_close calls timer_cancel(fd), which removes timer_heap[0]\n         * and sifts down. The loop then checks the new heap[0]. */\n    }\n}\n```\n> **Why both `sift_up` AND `sift_down` in `timer_cancel`?** When you remove an arbitrary element by swapping it with the last, the replacement element's value is unknown relative to its new neighbors. It might be smaller than its new parent (needs sift up) or larger than its new children (needs sift down)â€”but not both. Only one of the two operations will actually move the element; the other is a no-op. Calling both is safe and correct, avoiding a conditional branch that would add complexity.\n> **`CLOCK_MONOTONIC` vs `CLOCK_REALTIME`**: `CLOCK_REALTIME` is the wall clockâ€”it can jump backward or forward when NTP adjusts it. If your timer stores an absolute expiry time based on `CLOCK_REALTIME`, and NTP adjusts the clock forward by one hour (happens during daylight saving time in some configurations), all your timers expire simultaneously. `CLOCK_MONOTONIC` is guaranteed to only move forward, at a stable rate, making it the correct choice for interval timers.\n---\n## Integrating Timers Into the Event Loop\nHere's the complete event loop with timer integration:\n```c\n/**\n * run_event_loop - Main event loop with write buffering and timer support.\n *\n * Changes from Milestone 1:\n *   1. epoll_wait timeout derived from timer_next_ms() instead of -1.\n *   2. timer_process_expired() called after every epoll_wait return.\n *   3. On new data received, idle timer is reset (timer_set with new expiry).\n *   4. EPOLLOUT events routed to handle_client_write().\n */\nvoid run_event_loop(int epoll_fd, int listen_fd) {\n    struct epoll_event events[MAX_EVENTS];\n    for (;;) {\n        int timeout = timer_next_ms();  /* -1, 0, or ms until next expiry */\n        int n_ready = epoll_wait(epoll_fd, events, MAX_EVENTS, timeout);\n        if (n_ready == -1) {\n            if (errno == EINTR) continue;\n            perror(\"epoll_wait\");\n            break;\n        }\n        /* Process timer expirations first â€” they're time-sensitive */\n        timer_process_expired(epoll_fd);\n        for (int i = 0; i < n_ready; i++) {\n            int      fd = events[i].data.fd;\n            uint32_t ev = events[i].events;\n            if (fd == listen_fd) {\n                handle_new_connection(epoll_fd, listen_fd);\n                continue;\n            }\n            /* Guard against timer expiry closing this fd during timer processing */\n            if (!connections[fd].active) continue;\n            if (ev & (EPOLLERR | EPOLLHUP)) {\n                conn_close(epoll_fd, fd);\n                continue;\n            }\n            if (ev & EPOLLIN) {\n                handle_client_read(epoll_fd, fd);\n            }\n            if ((ev & EPOLLOUT) && connections[fd].active) {\n                handle_client_write(epoll_fd, fd);\n            }\n        }\n    }\n}\n```\nAnd `conn_init` / `conn_close` need updating to manage timer state:\n```c\n/**\n * conn_init - Initialize connection state and set idle timer.\n * Called immediately after accept4() returns a new fd.\n */\nvoid conn_init(int fd) {\n    conn_state *c = &connections[fd];\n    c->fd              = fd;\n    c->read_len        = 0;\n    c->active          = true;\n    c->epollout_armed  = false;\n    c->timer_idx       = -1;\n    c->timer_expiry_ms = 0;\n    wbuf_init(&c->wbuf);\n    /* Set idle timeout: close if no data received for IDLE_TIMEOUT_MS */\n    timer_set(fd, now_ms() + IDLE_TIMEOUT_MS);\n}\n/**\n * conn_close - Tear down a connection completely.\n *\n * Order matters:\n *   1. Mark inactive first â€” prevents double-close in edge cases.\n *   2. Cancel timer â€” prevents timer firing after fd is closed.\n *   3. Remove from epoll â€” prevents events on a closed fd.\n *   4. Free write buffer â€” releases heap memory.\n *   5. close(fd) â€” releases the file descriptor.\n *\n * Violating this order causes use-after-free or file descriptor reuse bugs.\n */\nvoid conn_close(int epoll_fd, int fd) {\n    conn_state *c = &connections[fd];\n    if (!c->active) return;\n    c->active = false;              /* 1. mark inactive */\n    timer_cancel(fd);               /* 2. remove from timer heap */\n    epoll_ctl(epoll_fd, EPOLL_CTL_DEL, fd, NULL);  /* 3. remove from epoll */\n    wbuf_free(&c->wbuf);            /* 4. free write buffer memory */\n    close(fd);                      /* 5. release file descriptor */\n    c->fd             = -1;\n    c->epollout_armed = false;\n    c->read_len       = 0;\n}\n/**\n * handle_client_read - Read data, reset idle timer on success.\n * (Updated from Milestone 1 to use conn_write and timer reset.)\n */\nvoid handle_client_read(int epoll_fd, int fd) {\n    conn_state *c = &connections[fd];\n    char buf[READ_BUF_SIZE];\n    ssize_t n = read(fd, buf, sizeof(buf));\n    if (n > 0) {\n        /* Activity on this connection â€” reset idle timer */\n        timer_set(fd, now_ms() + IDLE_TIMEOUT_MS);\n        /* Echo back using the buffered write path */\n        if (conn_write(epoll_fd, c, buf, (uint32_t)n) == -1) {\n            conn_close(epoll_fd, fd);\n        }\n    } else if (n == 0) {\n        conn_close(epoll_fd, fd);  /* graceful EOF */\n    } else {\n        if (errno == EAGAIN || errno == EWOULDBLOCK) return;\n        conn_close(epoll_fd, fd);  /* error */\n    }\n}\n```\n---\n## The Three-Level View: One EPOLLOUT Event\nLet's trace what happens from kernel to hardware when a slow client's socket buffer finally drains and EPOLLOUT fires:\n**Level 1 â€” Application**: Your event loop calls `epoll_wait`. It returns with `EPOLLOUT` set for fd 42. Your code calls `conn_flush(epoll_fd, &connections[42])`.\n**Level 2 â€” OS/Kernel**: When the NIC sent TCP segments and received ACKs from the remote client, the kernel's TCP stack freed space in the socket's send buffer (`sk_send_head` advances). The socket's `sock_def_write_space` callback fires, which wakes the epoll subsystem. The epoll `epitem` for fd 42 is placed on the ready list (`rdllist`). On your next `epoll_wait`, the kernel transfers it from `rdllist` to your `events[]` array via `copy_to_user()`. Inside `conn_flush`, your `write()` call copies bytes from your write buffer into the kernel's send buffer. The kernel hands these to the TCP stack, which segments them and queues them to the NIC.\n**Level 3 â€” Hardware**: The kernel's TCP stack queues a DMA (Direct Memory Access) descriptor to the NIC's TX ring. The NIC's DMA engine reads from a kernel memory region (pinned, not pageable) directlyâ€”no CPU involvement. The NIC serializes bytes to the wire at line rate (1 Gbps â†’ 125 MB/s). An interrupt fires when the TX ring entry completes (or is batched with NAPI polling), at which point the kernel marks the send buffer space as free and can trigger another `EPOLLOUT` if you still have data to send. The write path in `conn_flush`â€”`write()` â†’ kernel TCP â†’ NIC DMAâ€”takes roughly 1â€“5 Âµs end-to-end on a modern server.\n---\n## Putting It All Together: Testing the Implementation\nCompile your server with the new write buffering and timer code:\n```bash\ngcc -O2 -Wall -Wextra -o echo_server_m2 echo_server.c\n./echo_server_m2\n```\n**Test 1: Write buffer correctness under backpressure**\n```bash\n# Use tc (traffic control) to simulate a slow client\n# This limits the loopback interface to 1 Kbps â€” very slow\nsudo tc qdisc add dev lo root tbf rate 1kbps burst 32kbit latency 400ms\n# Send 64 KB â€” much larger than the 1 Kbps throughput can drain quickly\npython3 -c \"import socket; s = socket.create_connection(('127.0.0.1', 8080)); \\\n    data = b'X' * 65536; s.sendall(data); received = b''; \\\n    while len(received) < len(data): received += s.recv(4096); \\\n    print('OK' if received == data else 'DATA MISMATCH')\"\n# Clean up the traffic shaping\nsudo tc qdisc del dev lo root\n```\nWith correct write buffering, you should see \"OK\". Without it (M1's broken write path), you'd see a hang or \"DATA MISMATCH\".\n**Test 2: Idle timeout enforcement**\n```bash\n# Open a connection and don't send anything\nnc localhost 8080\n# Wait 31 seconds\n# The server should close the connection (you'll see the nc session end)\n```\nCheck your server's stderr for \"Idle timeout: closing fd N\".\n**Test 3: EPOLLOUT deregistration (no CPU spin)**\n```bash\n# Start the server\n./echo_server_m2 &\n# Check CPU usage while idle (should be ~0%)\ntop -p $(pgrep echo_server_m2)\n```\nIf EPOLLOUT is incorrectly left armed, you'll see the process at 100% CPU even with no connected clients. Correct implementation idles at <0.1% CPU.\n**Test 4: Multiple simultaneous timers**\n```c\n/* Add to main() for testing: verify heap ordering */\ntimer_set(10, now_ms() + 30000);  /* fd 10 expires in 30s */\ntimer_set(11, now_ms() + 5000);   /* fd 11 expires in 5s  */\ntimer_set(12, now_ms() + 15000);  /* fd 12 expires in 15s */\n/* Heap root should be fd 11 (soonest) */\nassert(timer_heap[0].fd == 11);\nprintf(\"Timer ordering: OK\\n\");\n```\n---\n## Hardware Soul: Memory and Cache Analysis\n**Write buffer access pattern**: When `conn_write` is on the hot path (every response triggers a write attempt), the `write_buf` struct and the first cache line of `wb->data` will be L1-hot for recently active connections. For 10K connections with uniform activity, the working set is 10,000 Ã— (24 bytes struct + ~4KB average buffer) â‰ˆ 40 MBâ€”fitting in L3 cache on a server CPU but exceeding L1/L2. Connections not recently active will cause L3 cache misses on first access (~40 cycles each).\n**Timer heap cache behavior**: The full heap at 65,536 entries is 768 KBâ€”fits in L2 cache (typically 256 KBâ€“2 MB) on modern server CPUs. `heap_sift_down` from the root accesses indices 0, 1 or 2, 3 or 4, 5â€“6 or 7â€“8... The first 3â€“4 levels (15 nodes, 180 bytes) fit in 3 cache lines. Logâ‚‚(10,000) â‰ˆ 13 levels deep means a sift operation touches ~13 cache linesâ€”mostly L1-hot for the top levels, L2-warm for lower levels.\n**`clock_gettime` cost**: Each `now_ms()` call is a `vDSO` (virtual Dynamic Shared Object) callâ€”the kernel maps a page into your process's address space containing a fast timekeeping function that reads from a shared memory region updated by the kernel, avoiding a full syscall context switch. On modern Linux with CLOCK_MONOTONIC, this costs ~30â€“50 ns rather than the ~200 ns of a real syscall. You call `now_ms()` at least twice per `epoll_wait` return (once for `timer_process_expired`, once for timer reset on data receipt)â€”roughly 100 ns total per event loop iteration.\n**Branch prediction in `heap_sift_down`**: The comparison `timer_heap[left].expiry_ms < timer_heap[smallest].expiry_ms` is genuinely unpredictableâ€”timer expiries are scattered. The branch predictor achieves ~50% accuracy here. At 15-cycle misprediction cost, 13 comparisons per sift Ã— 50% misprediction rate Ã— 15 cycles â‰ˆ 97 cycles of branch misprediction per timer operation. This is acceptableâ€”timer operations happen at most once per connection per event loop tick.\n---\n## Design Decision: Min-Heap vs Timer Wheel\n| Property | Min-Heap | Single-Level Timer Wheel |\n|----------|----------|--------------------------|\n| **Insert** | O(log N) | O(1) |\n| **Find next** | O(1) (root) | O(W) worst case (scan slots) |\n| **Cancel** | O(log N) with idx tracking | O(1) |\n| **Memory** | N Ã— sizeof(timer_entry) | W Ã— list_head (W = wheel size) |\n| **Expires clustered at one duration** | Works, but N items at same depth | Ideal: single slot fires all |\n| **Expires uniformly distributed** | âœ“ Ideal | Acceptable with small W |\n| **Implementation complexity** | Low | Medium (slot management) |\n| **Cache behavior** | Top levels cache-hot | Slot access pattern-dependent |\n| **Used by** | libuv, Nginx (red-black tree) | Linux kernel, Kafka, Netty |\n**For this project**: Use the min-heap. Your timers have a fixed duration (30 seconds idle timeout), so N timers cluster at similar absolute timesâ€”but they're staggered by when connections arrived, so the heap stays balanced. The min-heap's simplicity is worth more than the timer wheel's O(1) insert at N < 100K.\nAt N > 100K connections (where logâ‚‚(N) â‰ˆ 17 and wheel overhead is constant), the timer wheel wins. This is why the Linux kernel's internal timer mechanism uses a hierarchical 4-level timer wheelâ€”it manages millions of kernel timers efficiently.\n---\n## Knowledge Cascade: What This Unlocks\n**Redis's write-behind pattern**: Redis's event loop (`ae.c`) implements exactly the EPOLLOUT register-flush-deregister cycle you just built. When a Redis command generates a reply, `ae.c` calls `aeCreateFileEvent(el, c->fd, AE_WRITABLE, sendReplyToClient, c)`. After `sendReplyToClient` drains `c->buf`, it calls `aeDeleteFileEvent(el, c->fd, AE_WRITABLE)`. This is how Redis serves 100K+ clients/second without a dedicated writer threadâ€”the same pattern, scaled. The Redis source in `networking.c:writeToClient()` is worth reading alongside what you've built here; you'll recognize every decision.\n**The Go runtime's timer integration**: Go's runtime uses an `epoll_wait`-based netpoller (in `runtime/netpoll_epoll.go`) with the same timeout trick you implemented. When a goroutine calls `time.After(30 * time.Second)`, the runtime inserts a timer into a min-heap (in `runtime/time.go`) and adjusts the next `epoll_wait` timeout. When `epoll_wait` times out, the runtime fires timer callbacks, which resume sleeping goroutines. You've now implemented, in C and from scratch, the exact mechanism that makes Go's `time.Sleep` and `context.WithTimeout` work without OS threads.\n**`timerfd_create` for sub-millisecond timers**: Your current implementation has 1ms timer resolutionâ€”`epoll_wait`'s timeout is in integer milliseconds. For timers needing microsecond precision (real-time audio, trading systems, sensor fusion), use `timerfd_create(CLOCK_MONOTONIC, TFD_NONBLOCK)`. This creates a file descriptor that becomes readable when a timer expiresâ€”you register it with epoll like any other fd. `timerfd_settime` accepts nanosecond precision. The tradeoff: one fd per timer, vs your heap's single timeout parameter covering all timers. Use `timerfd` when you need precision; use the heap timeout pattern when you need scale.\n**Slow loris: the attack you've already defended against**: `WRITE_BUF_MAX` is your first line of defense against the slow loris HTTP attack (documented by Robert Hansen, 2009). The attack sends partial HTTP requests (just enough to look like valid traffic) and never completes them, holding connections open indefinitely. Your idle timeout is the second defense: any connection that hasn't sent a complete request in 30 seconds is closed. Production servers combine both: `WRITE_BUF_MAX` guards against slow readers, idle timeout guards against slow senders. Together they bound both memory consumption and fd exhaustion.\n**io_uring and timer integration**: In io_uring (Linux 5.1+), the `IORING_OP_TIMEOUT` operation submits a timer to the ring without an external fd. The completion event fires after N nanoseconds. Combined with `IORING_OP_LINK_TIMEOUT`, you can automatically cancel an in-flight read if it doesn't complete within a deadlineâ€”something epoll cannot express natively. Understanding your current `epoll_wait` timeout mechanism is the prerequisite for understanding why io_uring's timeout model is more expressive.\n---\n## Pitfall Reference: The Five Ways This Breaks\n**Pitfall 1: Leaving EPOLLOUT armed when write buffer is empty**\n*Symptom*: 100% CPU usage even with zero active connections; `top` shows your server spinning.\n*Fix*: In `conn_flush`, always call `epoll_ctl(EPOLL_CTL_MOD)` to remove `EPOLLOUT` when `wbuf_is_empty()` returns true.\n**Pitfall 2: Not processing all expired timers per tick**\n*Symptom*: Under load, connections stay open far past their idle timeout; timer heap grows unboundedly.\n*Fix*: `timer_process_expired` loops `while (timer_heap_size > 0 && timer_heap[0].expiry_ms <= now)`. Do not break after the first expiry.\n**Pitfall 3: Missing `timer_cancel` in `conn_close`**\n*Symptom*: After a connection closes, the timer fires and `conn_close` is called again on an already-freed (now potentially reused) fdâ€”classic use-after-free.\n*Fix*: Always cancel the timer in `conn_close`, and guard with `if (!c->active) return` at the top of `conn_close`.\n**Pitfall 4: Timer wheel slot count not a power of 2**\n*(If you implement a timer wheel instead of a min-heap)*\n*Symptom*: Modulo operation is expensive (integer division instead of bitwise AND); performance degradation visible in profiling.\n*Fix*: Use wheel size as a power of 2 (e.g., 256, 512); compute slot as `(now_ms / resolution) & (WHEEL_SIZE - 1)`.\n**Pitfall 5: Closing a connection without freeing the write buffer**\n*Symptom*: Memory leak at ~4 KB per closed connection; server RSS grows unboundedly over hours.\n*Fix*: `conn_close` must call `wbuf_free(&c->wbuf)`. Verify with `valgrind --leak-check=full ./echo_server_m2` under connection churn.\n---\n<!-- END_MS -->\n\n\n<!-- MS_ID: build-event-loop-m3 -->\n<!-- MS_ID: build-event-loop-m3 -->\n# Reactor API and Callback Dispatch\n## The Problem With What You've Built So Far\nLook at your event loop from Milestone 2. It works. It handles 10,000 connections, buffers writes, fires idle timeouts. But examine the structure of the dispatch loop:\n```c\nfor (int i = 0; i < n_ready; i++) {\n    int fd      = events[i].data.fd;\n    uint32_t ev = events[i].events;\n    if (fd == listen_fd) {\n        handle_new_connection(epoll_fd, listen_fd);\n    } else if (ev & (EPOLLERR | EPOLLHUP)) {\n        conn_close(epoll_fd, fd);\n    } else {\n        if (ev & EPOLLIN)  handle_client_read(epoll_fd, fd);\n        if (ev & EPOLLOUT) handle_client_write(epoll_fd, fd);\n    }\n}\n```\nEvery time you add a new type of fd to monitorâ€”a timer fd, a signal fd, a UNIX domain socket, a pipe from a worker threadâ€”you add another branch to this `if/else` chain. The event loop and the application logic are fused together. Want to use this event loop infrastructure for a different application (an HTTP server, a database client, a log tailer)? You rewrite it from scratch.\nThe echo server leaked through into the event loop. The write-buffer logic leaked through. The specific meaning of \"readable\" for the listen fd (accept a connection) versus a client fd (read data) is hardcoded.\nThis is the same problem that motivated operating systems to separate kernel from userspace, and web frameworks to separate routing from request handling. **You need a contract**â€”a stable interfaceâ€”between the event-detection machinery and the application code that responds to events.\nThat contract is the **Reactor pattern**.\n\n![Reactor Pattern: Component Architecture](./diagrams/diag-m3-reactor-api-architecture.svg)\n\n---\n## The Revelation: Modifying State During Iteration Is a Minefield\nBefore designing the API, you need to feel the hazard that makes this milestone's core design problem non-obvious.\nHere's what most developers assume: once you have a clean reactor API with `reactor_register(fd, callback)` and `reactor_deregister(fd)`, you can call those functions freely from inside any callback. After all, you're just updating a data structureâ€”how could that be dangerous?\nHere's the scenario that breaks this assumption.\n`epoll_wait` returns with 8 events. You begin iterating. Your callback for event `[2]` handles an error on `fd=7` and calls `reactor_deregister(fd=7)`, which calls `conn_close`, which calls `close(7)`. The fd is freed. The kernel can now reuse fd 7 for the very next `accept()` call or `socket()` callâ€”this can happen *immediately* if another thread calls `socket()`, or even within your own event loop if some other callback in this batch accepts a new connection.\nNow you process event `[5]`. The kernel told you `fd=7` was readable. But `fd=7` is now a *completely different connection*â€”or worse, `connections[7]` contains freed or re-initialized state from the new connection. You dispatch to a callback with the wrong data. The old callback thinks it's reading from the original connection; it's actually corrupting the new one.\n\n![Data Walk: Use-After-Free During Event Dispatch](./diagrams/diag-m3-use-after-free-scenario.svg)\n\nThis is a **use-after-free** bug and an **fd reuse race** combined into one. It's timing-dependent: it appears in production under high load (when connection churn is high and fds are reused rapidly) and disappears in unit tests (where you control the single client). It manifests as corrupted state, wrong responses sent to wrong clients, and occasional segfaults in callback dispatch.\nThe same bug class exists in:\n- **Browser DOM**: calling `element.remove()` inside a `forEach` over a NodeList mutates the list you're iterating\n- **Game engine ECS**: destroying an entity during a system update invalidates the component array iterator\n- **Database cursors**: deleting a row while iterating a result set\n- **Linux kernel softirqs**: interrupt handlers modifying lists that the bottom-half processor is currently walking\nEvery event-driven system ever built has encountered this. Every one has solved it the same way: **defer modifications to after the iteration completes**.\n---\n## Designing the Reactor API\nThe API you're about to build has exactly five public functions. Here's the contract each one makes:\n```c\n/* reactor.h â€” Public API. Users of this library never touch epoll directly. */\n#ifndef REACTOR_H\n#define REACTOR_H\n#include <stdint.h>\n#include <stdbool.h>\n/* Forward declaration â€” implementation is opaque */\ntypedef struct reactor reactor;\n/*\n * Event type flags â€” what a callback can be notified about.\n * Designed as a bitmask: READABLE | WRITABLE is valid.\n */\n#define REACTOR_READABLE   (1u << 0)   /* data available to read */\n#define REACTOR_WRITABLE   (1u << 1)   /* socket buffer has space */\n#define REACTOR_ERROR      (1u << 2)   /* EPOLLERR: socket error */\n#define REACTOR_HANGUP     (1u << 3)   /* EPOLLHUP: peer closed */\n/*\n * io_callback_fn â€” Signature for I/O event callbacks.\n *\n * fd:        the file descriptor that has an event\n * events:    bitmask of REACTOR_READABLE / REACTOR_WRITABLE / etc.\n * user_data: opaque pointer registered with reactor_register()\n *\n * The callback may call reactor_register, reactor_deregister, or\n * reactor_defer. It must NOT free reactor itself.\n */\ntypedef void (*io_callback_fn)(int fd, uint32_t events, void *user_data);\n/*\n * timer_callback_fn â€” Signature for timer callbacks.\n *\n * reactor: the reactor, so the callback can defer or schedule more timers\n * user_data: opaque pointer passed to reactor_set_timeout / set_interval\n */\ntypedef void (*timer_callback_fn)(reactor *r, void *user_data);\n/*\n * task_fn â€” Signature for deferred tasks.\n *\n * reactor: allows deferred tasks to schedule further deferred tasks\n * user_data: opaque pointer passed to reactor_defer()\n */\ntypedef void (*task_fn)(reactor *r, void *user_data);\n/* Lifecycle */\nreactor *reactor_create(void);\nvoid     reactor_destroy(reactor *r);\nvoid     reactor_run(reactor *r);        /* blocks until reactor_stop() called */\nvoid     reactor_stop(reactor *r);       /* causes reactor_run() to return */\n/* I/O event registration */\nint  reactor_register(reactor *r, int fd, uint32_t events,\n                      io_callback_fn cb, void *user_data);\nvoid reactor_deregister(reactor *r, int fd);\n/* Timer API */\nint  reactor_set_timeout(reactor *r, uint32_t ms,\n                         timer_callback_fn cb, void *user_data);\nint  reactor_set_interval(reactor *r, uint32_t ms,\n                          timer_callback_fn cb, void *user_data);\nvoid reactor_cancel_timer(reactor *r, int timer_id);\n/* Deferred task queue */\nvoid reactor_defer(reactor *r, task_fn fn, void *user_data);\n#endif /* REACTOR_H */\n```\nNotice what is absent from this header: `epoll_create1`, `epoll_ctl`, `epoll_wait`, `struct epoll_event`, anything from `<sys/epoll.h>`. The user of this library never touches epoll. They register interest, provide callbacks, and let the reactor handle the rest.\n\n![Callback Design: Function Pointer and void* user_data Pattern](./diagrams/diag-m3-callback-signature-design.svg)\n\n> **Why `void *user_data`?** C lacks generics. Without `void *user_data`, every callback would need to use global variables or cast integers to pointers. The `user_data` patternâ€”a single opaque pointer threaded from registration through to callback invocationâ€”is the standard solution in C event libraries (libevent, libev, libuv, GLib's main loop). You pass in a `conn_state *` cast to `void *`; the callback casts it back. This gives you type-safe (by convention) context without a garbage collector. In Rust, you'd use closures that capture their environment; in C, `user_data` is the manual equivalent.\n---\n## The Internal Structure: What the Reactor Holds\nThe reactor's internal state must track:\n1. The epoll fd (from Milestone 1)\n2. A per-fd registration table: which callback to call, what user_data to pass, what events are registered\n3. The timer heap (from Milestone 2)\n4. The deferred task queue\n5. A \"pending modifications\" queueâ€”the key addition of this milestone\n6. A flag indicating whether dispatch is currently in progress\n```c\n/* reactor_internal.h â€” implementation details, not exposed to users */\n#include \"reactor.h\"\n#include <sys/epoll.h>\n#define MAX_FDS       65536\n#define MAX_EVENTS    1024\n#define DEFER_QUEUE_INITIAL 64\n/*\n * fd_handler - Per-fd registration record.\n *\n * Memory layout (64-bit):\n *   offset  0: callback    (8 bytes â€” function pointer)\n *   offset  8: user_data   (8 bytes â€” void*)\n *   offset 16: events      (4 bytes â€” uint32_t)\n *   offset 20: registered  (1 byte  â€” bool)\n *   offset 21: zombie      (1 byte  â€” bool, see deferred close)\n *   offset 22: [2 bytes padding]\n *   Total: 24 bytes Ã— 65536 = 1.5 MB for the registration table\n *\n * 'zombie' means: callback called reactor_deregister(fd) while we were\n * in the dispatch loop. We mark it zombie and skip its pending events.\n * The actual epoll_ctl(DEL) and cleanup happen after the loop.\n */\ntypedef struct {\n    io_callback_fn callback;\n    void          *user_data;\n    uint32_t       events;\n    bool           registered;\n    bool           zombie;       /* deregistration deferred */\n} fd_handler;\n/*\n * deferred_mod - A pending epoll_ctl operation to run after dispatch.\n *\n * Operations that arrive during dispatch are queued here and executed\n * after all events in the current batch are processed.\n */\ntypedef enum {\n    MOD_ADD,\n    MOD_MOD,\n    MOD_DEL,\n} mod_op;\ntypedef struct {\n    mod_op   op;\n    int      fd;\n    uint32_t events;\n} deferred_mod;\n/*\n * deferred_task - One entry in the post-dispatch task queue.\n */\ntypedef struct {\n    task_fn  fn;\n    void    *user_data;\n} deferred_task;\n/*\n * reactor - The complete reactor state.\n *\n * This is the struct hidden behind the opaque typedef in reactor.h.\n * Fields are grouped by access pattern:\n *   Hot path (accessed every epoll_wait iteration): epoll_fd, handlers, dispatching\n *   Cold path (accessed on modification): mods, defer_queue\n */\nstruct reactor {\n    int        epoll_fd;\n    bool       running;\n    bool       dispatching;   /* true while iterating epoll_wait results */\n    fd_handler handlers[MAX_FDS];\n    /* Timer heap from Milestone 2 â€” integrated here */\n    timer_entry timer_heap[TIMER_HEAP_MAX];\n    int         timer_heap_size;\n    int         next_timer_id;\n    /* Deferred epoll_ctl modifications â€” applied after dispatch loop */\n    deferred_mod *mods;\n    int           mods_len;\n    int           mods_cap;\n    /* Deferred task queue â€” runs after I/O dispatch, before next epoll_wait */\n    deferred_task *defer_queue;\n    int            defer_len;\n    int            defer_cap;\n};\n```\nThe key fields are `dispatching`, `zombie` on each `fd_handler`, and the `mods` queue. Together they implement the deferred-modification pattern.\n---\n## Creating and Destroying the Reactor\n```c\n#include \"reactor_internal.h\"\n#include <stdlib.h>\n#include <string.h>\n#include <stdio.h>\n#include <errno.h>\nreactor *reactor_create(void) {\n    reactor *r = calloc(1, sizeof(reactor));\n    if (!r) {\n        perror(\"calloc reactor\");\n        return NULL;\n    }\n    r->epoll_fd = epoll_create1(EPOLL_CLOEXEC);\n    if (r->epoll_fd == -1) {\n        perror(\"epoll_create1\");\n        free(r);\n        return NULL;\n    }\n    /* Initialize all handler slots as unregistered */\n    for (int i = 0; i < MAX_FDS; i++) {\n        r->handlers[i].registered = false;\n        r->handlers[i].zombie     = false;\n    }\n    r->mods = malloc(sizeof(deferred_mod) * DEFER_QUEUE_INITIAL);\n    r->mods_cap = DEFER_QUEUE_INITIAL;\n    r->mods_len = 0;\n    r->defer_queue = malloc(sizeof(deferred_task) * DEFER_QUEUE_INITIAL);\n    r->defer_cap = DEFER_QUEUE_INITIAL;\n    r->defer_len = 0;\n    r->running    = false;\n    r->dispatching = false;\n    r->next_timer_id = 1;  /* 0 is reserved for \"no timer\" */\n    return r;\n}\nvoid reactor_destroy(reactor *r) {\n    if (!r) return;\n    close(r->epoll_fd);\n    free(r->mods);\n    free(r->defer_queue);\n    /* Note: we do NOT close registered fds â€” the user owns them */\n    free(r);\n}\n```\n> **`calloc` vs `malloc` + `memset`**: `calloc(1, sizeof(reactor))` allocates and zeroes the memory in one call. For a 1.5 MB struct, this matters: most modern allocators and the kernel deliver zeroed pages via lazy allocation (copy-on-write zero page), so `calloc` pays only for pages you actually touch. `malloc` + `memset` forces immediate writes to every page, paying the TLB fault and page-in cost upfront. For large structs whose fields are only partially used, `calloc` is measurably faster to initialize.\n---\n## Registering and Deregistering fd Handlers\nThe registration functions must handle two cases: called outside dispatch (normal) and called inside dispatch (deferred):\n```c\n/*\n * reactor_map_events - Convert REACTOR_* flags to epoll event flags.\n *\n * We always include EPOLLERR and EPOLLHUP â€” the kernel reports these\n * regardless of whether you register them, but including them makes\n * the semantics explicit. EPOLLRDHUP detects peer half-close cleanly.\n */\nstatic uint32_t reactor_map_events(uint32_t reactor_events) {\n    uint32_t ev = EPOLLERR | EPOLLHUP | EPOLLRDHUP;\n    if (reactor_events & REACTOR_READABLE) ev |= EPOLLIN;\n    if (reactor_events & REACTOR_WRITABLE) ev |= EPOLLOUT;\n    return ev;\n}\n/*\n * reactor_apply_mod - Execute one deferred_mod immediately.\n * Only call this outside the dispatch loop.\n */\nstatic void reactor_apply_mod(reactor *r, const deferred_mod *mod) {\n    if (mod->op == MOD_DEL) {\n        epoll_ctl(r->epoll_fd, EPOLL_CTL_DEL, mod->fd, NULL);\n        return;\n    }\n    struct epoll_event ev;\n    ev.events   = mod->events;\n    ev.data.ptr = &r->handlers[mod->fd];  /* store pointer, not int */\n    int op = (mod->op == MOD_ADD) ? EPOLL_CTL_ADD : EPOLL_CTL_MOD;\n    if (epoll_ctl(r->epoll_fd, op, mod->fd, &ev) == -1) {\n        /* ENOENT on MOD means fd was already removed â€” not fatal */\n        if (!(op == EPOLL_CTL_MOD && errno == ENOENT)) {\n            perror(\"epoll_ctl in apply_mod\");\n        }\n    }\n}\n/*\n * enqueue_mod - Add a deferred_mod to the pending queue.\n * Called when modification arrives during dispatch.\n */\nstatic void enqueue_mod(reactor *r, mod_op op, int fd, uint32_t events) {\n    if (r->mods_len == r->mods_cap) {\n        int new_cap = r->mods_cap * 2;\n        deferred_mod *new_mods = realloc(r->mods,\n                                         sizeof(deferred_mod) * new_cap);\n        if (!new_mods) return;  /* OOM: modification is lost, not ideal */\n        r->mods     = new_mods;\n        r->mods_cap = new_cap;\n    }\n    r->mods[r->mods_len++] = (deferred_mod){ .op = op, .fd = fd, .events = events };\n}\nint reactor_register(reactor *r, int fd, uint32_t events,\n                     io_callback_fn cb, void *user_data) {\n    if (fd < 0 || fd >= MAX_FDS) return -1;\n    fd_handler *h = &r->handlers[fd];\n    bool was_registered = h->registered;\n    h->callback   = cb;\n    h->user_data  = user_data;\n    h->events     = events;\n    h->registered = true;\n    h->zombie     = false;  /* re-registration clears zombie status */\n    uint32_t epoll_ev = reactor_map_events(events);\n    mod_op   op       = was_registered ? MOD_MOD : MOD_ADD;\n    if (r->dispatching) {\n        /*\n         * CRITICAL: We're inside the dispatch loop. Calling epoll_ctl now\n         * would not corrupt the current events[] array (it's already been\n         * copied from the kernel), but it could affect subsequent iterations\n         * if we're processing events in batches. More importantly, if we're\n         * re-registering an fd that was marked zombie, we must ensure the\n         * zombie flag is cleared before any pending events for this fd are\n         * dispatched â€” which we've done above. The epoll_ctl can be deferred.\n         */\n        enqueue_mod(r, op, fd, epoll_ev);\n    } else {\n        struct epoll_event ev;\n        ev.events   = epoll_ev;\n        ev.data.ptr = h;  /* store pointer to handler, not fd int */\n        if (epoll_ctl(r->epoll_fd, op == MOD_ADD ? EPOLL_CTL_ADD : EPOLL_CTL_MOD,\n                      fd, &ev) == -1) {\n            h->registered = was_registered;\n            return -1;\n        }\n    }\n    return 0;\n}\nvoid reactor_deregister(reactor *r, int fd) {\n    if (fd < 0 || fd >= MAX_FDS) return;\n    fd_handler *h = &r->handlers[fd];\n    if (!h->registered) return;\n    if (r->dispatching) {\n        /*\n         * Mark as zombie: the dispatch loop will see this flag and skip\n         * any pending events for this fd in the current batch. The actual\n         * epoll_ctl(DEL) is deferred to after the dispatch loop.\n         *\n         * WHY NOT call epoll_ctl(DEL) now? Calling it now is technically\n         * safe for the current events[] array (it's a local copy), but:\n         * 1. It signals our intent to the kernel immediately â€” fine.\n         * 2. More importantly, the fd might be reused by another accept()\n         *    before the dispatch loop ends, creating a new handler at the\n         *    same index. The zombie flag prevents dispatching to the OLD\n         *    callback after reuse.\n         *\n         * Setting zombie + deferring DEL is the complete defense.\n         */\n        h->zombie = true;\n        enqueue_mod(r, MOD_DEL, fd, 0);\n    } else {\n        h->registered = false;\n        h->zombie     = false;\n        epoll_ctl(r->epoll_fd, EPOLL_CTL_DEL, fd, NULL);\n    }\n}\n```\n> **`ev.data.ptr` vs `ev.data.fd`**: In Milestones 1 and 2, you stored the fd integer in `ev.data.fd`. Here we store a pointer to the `fd_handler` struct directly. When the event fires, you retrieve the handler with a single pointer dereference rather than an array index. This is slightly faster (saves one multiplication) andâ€”more importantlyâ€”makes it possible to pass the handler directly to the callback dispatch code. The `fd` is still accessible via the handler's context or the file descriptor number recorded elsewhere. Both approaches are valid; production libraries like libevent use `data.ptr`.\n\n![Deferred Modification Queue: Safe epoll_ctl During Dispatch](./diagrams/diag-m3-deferred-modification-queue.svg)\n\n---\n## The Deferred Task Queue\n> **ðŸ”‘ Foundation: Function pointers and callbacks in C**\n>\n> **1. What it IS**\n> A function pointer is a variable that stores the memory address of a function. When you call it, the CPU jumps to that address and executes whatever is there. In C, the syntax `void (*fn)(int, void *)` declares a variable `fn` that holds the address of a function taking an `int` and a `void *` and returning `void`.\n>\n> **2. Why you need it right now**\n> The reactor can't know in advance what code to run when an event firesâ€”that's application logic, and the reactor is a library. Instead, the application *registers* its function by passing its address. The reactor stores that address in the `fd_handler.callback` field and calls it later via `h->callback(fd, events, h->user_data)`. This is inversion of control: you're not calling the library, the library is calling you, at a time and in a context it controls.\n>\n> **3. Key Insight: The Callback Table**\n> Every time you call `reactor_register(r, fd, events, my_handler, ctx)`, you're filling in one row of a dispatch tableâ€”a mapping from fd to function. When `epoll_wait` returns fd 7 as readable, the reactor looks up row 7, finds `my_handler`, and calls it. This is exactly how virtual function tables (vtables) work in C++ and Rust trait objectsâ€”the function pointer table is the universal mechanism for runtime polymorphism in systems languages.\n```c\n/*\n * reactor_defer - Schedule a callback to run after the current I/O dispatch.\n *\n * Timing guarantee: deferred tasks run after ALL I/O events in the current\n * epoll_wait batch are processed, but before the next epoll_wait call.\n *\n * Use cases:\n *   - Close a connection after its callback finishes (safe deferred close)\n *   - Schedule follow-up work without blocking the I/O dispatch loop\n *   - Batch multiple state changes that depend on the full event set\n *\n * Note: if called outside dispatch (e.g., from a timer callback that runs\n * after dispatch), the task still runs before the next epoll_wait. This is\n * correct: \"after dispatch\" and \"before next poll\" are the same moment.\n */\nvoid reactor_defer(reactor *r, task_fn fn, void *user_data) {\n    if (r->defer_len == r->defer_cap) {\n        int new_cap = r->defer_cap == 0 ? DEFER_QUEUE_INITIAL : r->defer_cap * 2;\n        deferred_task *new_q = realloc(r->defer_queue,\n                                       sizeof(deferred_task) * new_cap);\n        if (!new_q) return;  /* OOM: task is lost */\n        r->defer_queue = new_q;\n        r->defer_cap   = new_cap;\n    }\n    r->defer_queue[r->defer_len++] = (deferred_task){ .fn = fn, .user_data = user_data };\n}\n/*\n * reactor_run_deferred - Execute all pending deferred tasks.\n *\n * Called after the dispatch loop completes. Tasks themselves may call\n * reactor_defer(), adding new tasks to the queue. We use a snapshot\n * of the current length to process only tasks that existed at the start\n * of this run â€” newly added tasks will run in the next tick.\n *\n * WHY snapshot the length? If task[0] calls reactor_defer(task_X),\n * task_X is appended at defer_queue[1]. If we loop to defer_len (which\n * is now 2), we'd process task_X in the same tick. That's sometimes\n * desirable, but it can cause unbounded work if tasks keep deferring\n * more tasks. Snapshotting runs exactly one \"generation\" per tick.\n */\nstatic void reactor_run_deferred(reactor *r) {\n    int count = r->defer_len;    /* snapshot */\n    r->defer_len = 0;            /* reset; new tasks go to fresh slots */\n    /* But we need to run old tasks first â€” they may be at index 0..count-1 */\n    /* Swap to a temporary copy so re-entrant defer appends to the real queue */\n    deferred_task *tasks = r->defer_queue;\n    r->defer_queue = malloc(sizeof(deferred_task) * r->defer_cap);\n    if (!r->defer_queue) {\n        r->defer_queue = tasks;  /* fallback: run in place, re-entrancy broken */\n        for (int i = 0; i < count; i++) tasks[i].fn(r, tasks[i].user_data);\n        return;\n    }\n    /* Execute the snapshot */\n    for (int i = 0; i < count; i++) {\n        tasks[i].fn(r, tasks[i].user_data);\n    }\n    free(tasks);\n    /* r->defer_queue now holds any new tasks added during the above execution */\n}\n```\n---\n## Timer Integration: One-Shot and Repeating\nThe timer heap from Milestone 2 gets wrapped in the reactor's timer API. The key new capability is the repeating interval timerâ€”and the re-entrancy concern it introduces.\n```c\n/*\n * timer_record - Internal timer storage, extends Milestone 2's timer_entry.\n *\n * interval_ms: if > 0, timer auto-rearmed after each firing (set_interval)\n *              if == 0, timer fires once and is removed (set_timeout)\n * id:          user-visible handle for reactor_cancel_timer()\n */\ntypedef struct {\n    uint64_t       expiry_ms;\n    uint32_t       interval_ms;   /* 0 = one-shot, >0 = repeating */\n    int            id;            /* unique timer ID */\n    timer_callback_fn callback;\n    void          *user_data;\n} timer_record;\n/*\n * reactor_set_timeout - Fire callback once after 'ms' milliseconds.\n * Returns a timer ID (> 0) that can be passed to reactor_cancel_timer.\n */\nint reactor_set_timeout(reactor *r, uint32_t ms,\n                        timer_callback_fn cb, void *user_data) {\n    return reactor_timer_insert(r, now_ms() + ms, 0 /* one-shot */, cb, user_data);\n}\n/*\n * reactor_set_interval - Fire callback every 'ms' milliseconds.\n * Returns a timer ID. Call reactor_cancel_timer() to stop it.\n *\n * Implementation note: on each firing, we re-insert with expiry =\n * previous_expiry + interval_ms (not now_ms() + interval_ms).\n * This prevents timer drift: if a callback takes 5ms and the interval\n * is 100ms, the next firing is at 100ms from the original, not 105ms.\n * Over many iterations, drift accumulates; anchoring to the original\n * expiry keeps the interval accurate.\n */\nint reactor_set_interval(reactor *r, uint32_t ms,\n                         timer_callback_fn cb, void *user_data) {\n    return reactor_timer_insert(r, now_ms() + ms, ms /* repeating */, cb, user_data);\n}\n/*\n * reactor_process_timers - Fire all expired timers.\n *\n * Called after each epoll_wait return, BEFORE processing I/O events.\n * Timers are time-sensitive; delaying them until after I/O dispatch\n * would make their precision depend on how long I/O handling takes.\n *\n * Re-entrancy contract: a timer callback may call reactor_set_timeout,\n * reactor_set_interval, or reactor_cancel_timer. It must NOT call\n * reactor_cancel_timer(r, own_id) for an interval timer from inside\n * its own callback â€” use a flag and cancel from a deferred task instead.\n *\n * Why? We're iterating the heap while a callback might modify it.\n * reactor_cancel_timer calls heap_sift_up/down which changes indices.\n * We defend against this by copying the fd/callback before firing,\n * then checking the timer still exists afterward.\n */\nstatic void reactor_process_timers(reactor *r) {\n    uint64_t now = now_ms();\n    while (r->timer_heap_size > 0) {\n        timer_record *top = (timer_record *)&r->timer_heap[0];\n        if (top->expiry_ms > now) break;\n        /* Copy what we need before the heap is modified */\n        timer_callback_fn cb        = top->callback;\n        void             *ud        = top->user_data;\n        uint64_t          prev_exp  = top->expiry_ms;\n        uint32_t          interval  = top->interval_ms;\n        int               id        = top->id;\n        if (interval > 0) {\n            /* Re-arm interval timer BEFORE calling callback.\n             * This way, if the callback cancels the timer, the cancel\n             * finds it in the heap and removes it cleanly. */\n            top->expiry_ms = prev_exp + interval;\n            heap_sift_down(r, 0);\n        } else {\n            /* One-shot: remove from heap */\n            reactor_timer_remove_at(r, 0);\n        }\n        /* Fire the callback */\n        cb(r, ud);\n        (void)id;  /* used for cancel; not needed here after copy */\n    }\n}\n```\n---\n## The Complete Dispatch Loop\nNow all the pieces come together. The main `reactor_run` function is the nucleus:\n```c\nvoid reactor_run(reactor *r) {\n    struct epoll_event events[MAX_EVENTS];\n    r->running = true;\n    while (r->running) {\n        /* Compute how long to sleep: time until next timer, or forever */\n        int timeout = reactor_next_timeout(r);\n        int n = epoll_wait(r->epoll_fd, events, MAX_EVENTS, timeout);\n        if (n == -1) {\n            if (errno == EINTR) continue;   /* signal interrupted: retry */\n            perror(\"epoll_wait\");\n            break;\n        }\n        /*\n         * Process timers FIRST â€” they may have expired during the I/O wait.\n         * Timer precision is bounded by how quickly we check after epoll_wait\n         * returns. Checking before I/O dispatch gives timer callbacks ~0 extra\n         * latency from I/O handling time.\n         */\n        reactor_process_timers(r);\n        /*\n         * I/O dispatch â€” THE CRITICAL SECTION.\n         *\n         * Set dispatching = true. Any reactor_register or reactor_deregister\n         * calls from callbacks will enqueue to r->mods instead of calling\n         * epoll_ctl directly.\n         */\n        r->dispatching = true;\n        for (int i = 0; i < n; i++) {\n            fd_handler *h = (fd_handler *)events[i].data.ptr;\n            /* Zombie check: callback called reactor_deregister() for this fd\n             * earlier in this batch. Skip its remaining events. */\n            if (h->zombie || !h->registered) continue;\n            /* Compute which REACTOR_* flags to pass to the callback */\n            uint32_t ev_mask  = events[i].events;\n            uint32_t r_events = 0;\n            if (ev_mask & EPOLLIN)                          r_events |= REACTOR_READABLE;\n            if (ev_mask & EPOLLOUT)                         r_events |= REACTOR_WRITABLE;\n            if (ev_mask & EPOLLERR)                         r_events |= REACTOR_ERROR;\n            if (ev_mask & (EPOLLHUP | EPOLLRDHUP))          r_events |= REACTOR_HANGUP;\n            /*\n             * Recover the fd from the handler pointer.\n             * We stored data.ptr = &handlers[fd], so fd = h - r->handlers.\n             * Using pointer arithmetic to avoid storing fd twice.\n             */\n            int fd = (int)(h - r->handlers);\n            /* Invoke the application's callback */\n            h->callback(fd, r_events, h->user_data);\n            /*\n             * After callback: check if the handler became zombie during the\n             * callback (e.g., callback called reactor_deregister for this fd).\n             * If so, complete the deregistration now while we have context.\n             * The MOD_DEL is also queued in r->mods, but we want to prevent\n             * any subsequent iteration from seeing a live handler.\n             */\n        }\n        r->dispatching = false;\n        /*\n         * Apply deferred modifications.\n         * Now that we're not iterating events[], it's safe to call epoll_ctl.\n         */\n        for (int i = 0; i < r->mods_len; i++) {\n            deferred_mod *mod = &r->mods[i];\n            if (mod->op == MOD_DEL) {\n                /* Complete the deregistration: clear handler state */\n                if (mod->fd >= 0 && mod->fd < MAX_FDS) {\n                    fd_handler *h = &r->handlers[mod->fd];\n                    h->registered = false;\n                    h->zombie     = false;\n                }\n            }\n            reactor_apply_mod(r, mod);\n        }\n        r->mods_len = 0;   /* reset the deferred mod queue */\n        /*\n         * Run deferred tasks â€” AFTER all I/O events and after modifications.\n         * Deferred tasks may call reactor_register/deregister freely because\n         * dispatching = false at this point.\n         */\n        reactor_run_deferred(r);\n    }\n}\nvoid reactor_stop(reactor *r) {\n    r->running = false;\n}\n```\n\n![Trace: One Complete Event Loop Tick](./diagrams/diag-m3-event-dispatch-loop-trace.svg)\n\nThis loop embodies the complete set of ordering guarantees:\n1. **Timers fire before I/O events** â€” time-sensitive\n2. **I/O events fire in the order epoll returns them** â€” within a batch\n3. **Modifications are deferred** â€” no corruption of the events array\n4. **Deferred tasks run after all I/O** â€” they see the fully-dispatched state\n5. **Next `epoll_wait` reflects all modifications** â€” applied between ticks\n---\n## Handling EPOLLHUP and EPOLLERR Correctly\nThese two event flags deserve special attention. Developers frequently mishandle them by treating `EPOLLHUP` as an error when it's often a normal shutdown.\n```\nEPOLLHUP â€” \"Hang Up\"\n    The remote peer closed the connection. On a TCP socket, this means\n    the peer sent FIN. The socket may still have data in its receive\n    buffer that you haven't read yet. Always try to read remaining data\n    before closing.\nEPOLLRDHUP â€” \"Read HUP\" (Linux 2.6.17+)\n    More precise than EPOLLHUP: specifically indicates the peer has shut\n    down the writing half of the connection (sent FIN for their outgoing\n    direction). This is the preferred way to detect peer close.\nEPOLLERR â€” \"Error\"\n    A socket error occurred. Read errno by calling getsockopt(fd,\n    SOL_SOCKET, SO_ERROR, &err, &len) â€” DO NOT call read() first.\n    Common causes: ECONNRESET (RST received), ETIMEDOUT, ENETUNREACH.\n```\n```c\n/*\n * Example callback showing correct EPOLLHUP / EPOLLERR handling.\n * This would be an application's callback registered with reactor_register.\n */\nvoid connection_callback(int fd, uint32_t events, void *user_data) {\n    conn_state *conn = (conn_state *)user_data;\n    reactor    *r    = conn->reactor_ref;\n    if (events & REACTOR_ERROR) {\n        /* Query the actual error */\n        int err = 0;\n        socklen_t len = sizeof(err);\n        getsockopt(fd, SOL_SOCKET, SO_ERROR, &err, &len);\n        fprintf(stderr, \"Socket error on fd %d: %s\\n\", fd, strerror(err));\n        /* Defer close so we don't invalidate the event batch */\n        reactor_defer(r, deferred_conn_close, conn);\n        return;\n    }\n    if (events & REACTOR_HANGUP) {\n        /* Peer closed their write side. Drain any remaining data first. */\n        if (events & REACTOR_READABLE) {\n            handle_readable(fd, conn, r);  /* read and process remaining data */\n        }\n        /* Schedule close after this callback returns */\n        reactor_defer(r, deferred_conn_close, conn);\n        return;\n    }\n    if (events & REACTOR_READABLE) {\n        handle_readable(fd, conn, r);\n    }\n    if (events & REACTOR_WRITABLE) {\n        handle_writable(fd, conn, r);\n    }\n}\n```\n> **Why defer the close even for EPOLLERR?** By the time `connection_callback` is called, there may be other events in the current `epoll_wait` batch that reference this same fdâ€”for example, if EPOLLIN and EPOLLERR both fired simultaneously. If you call `close(fd)` directly, the zombie check in the dispatch loop catches it only if you went through `reactor_deregister`. Calling `close(fd)` directly without `reactor_deregister` leaves the handler marked as registered for a closed (and potentially reused) fd. Always close through the reactor's deregistration path, and defer it when inside a callback.\n---\n## Writing Applications Against the Reactor\nHere's how the echo server from Milestones 1 and 2 looks when rewritten against this API. Notice how all the `epoll_ctl` calls disappear:\n```c\n#include \"reactor.h\"\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <errno.h>\n#include <unistd.h>\n#include <sys/socket.h>\n#include <netinet/in.h>\n/* Application-level connection state */\ntypedef struct {\n    reactor    *r;\n    write_buf   wbuf;\n    int         fd;\n} echo_conn;\ntypedef struct {\n    reactor *r;\n    int      listen_fd;\n} server_ctx;\nstatic void echo_conn_close(reactor *r, void *user_data) {\n    echo_conn *conn = (echo_conn *)user_data;\n    reactor_deregister(r, conn->fd);\n    wbuf_free(&conn->wbuf);\n    close(conn->fd);\n    free(conn);\n}\nstatic void echo_readable(int fd, uint32_t events, void *user_data) {\n    echo_conn *conn = (echo_conn *)user_data;\n    reactor   *r    = conn->r;\n    if (events & (REACTOR_ERROR | REACTOR_HANGUP)) {\n        reactor_defer(r, echo_conn_close, conn);\n        return;\n    }\n    char buf[4096];\n    for (;;) {\n        ssize_t n = read(fd, buf, sizeof(buf));\n        if (n > 0) {\n            /* Queue for writing using the write buffer from M2 */\n            if (conn_write_with_reactor(r, conn, buf, (uint32_t)n) == -1) {\n                reactor_defer(r, echo_conn_close, conn);\n                return;\n            }\n        } else if (n == 0) {\n            reactor_defer(r, echo_conn_close, conn);\n            return;\n        } else {\n            if (errno == EAGAIN || errno == EWOULDBLOCK) break;\n            reactor_defer(r, echo_conn_close, conn);\n            return;\n        }\n    }\n}\nstatic void accept_callback(int listen_fd, uint32_t events, void *user_data) {\n    server_ctx *ctx = (server_ctx *)user_data;\n    (void)events;\n    for (;;) {\n        int fd = accept4(listen_fd, NULL, NULL, SOCK_NONBLOCK | SOCK_CLOEXEC);\n        if (fd == -1) {\n            if (errno == EAGAIN || errno == EWOULDBLOCK) break;\n            perror(\"accept4\");\n            break;\n        }\n        echo_conn *conn = malloc(sizeof(echo_conn));\n        if (!conn) { close(fd); continue; }\n        conn->r  = ctx->r;\n        conn->fd = fd;\n        wbuf_init(&conn->wbuf);\n        /* Register with reactor â€” no epoll_ctl calls needed */\n        reactor_register(ctx->r, fd, REACTOR_READABLE, echo_readable, conn);\n        /* Set idle timeout â€” reusing M2's timer mechanism via reactor */\n        reactor_set_timeout(ctx->r, 30000, echo_timeout_cb, conn);\n    }\n}\nint main(void) {\n    reactor    *r   = reactor_create();\n    server_ctx  ctx = { .r = r };\n    ctx.listen_fd = create_listening_socket();  /* from M1 */\n    /* One registration call â€” no epoll_create1, no epoll_ctl */\n    reactor_register(r, ctx.listen_fd, REACTOR_READABLE, accept_callback, &ctx);\n    printf(\"Echo server on port 8080...\\n\");\n    reactor_run(r);  /* blocks until reactor_stop() */\n    close(ctx.listen_fd);\n    reactor_destroy(r);\n    return 0;\n}\n```\nCompare this to your Milestone 1 code. `epoll_create1`, `epoll_ctl`, `epoll_wait`, `EPOLLIN`, `EPOLLET`, `EPOLL_CTL_ADD`â€”none of them appear in application code. The application speaks in terms of *connections*, *readability*, and *timeouts*. The reactor speaks in terms of epoll. This separation is the entire point.\n\n![Reactor vs Proactor: Architectural Comparison](./diagrams/diag-m3-reactor-vs-proactor.svg)\n\n---\n## The Three-Level View: One Callback Invocation\nLet's trace a single callback invocation from hardware interrupt to your application code.\n**Level 3 â€” Hardware**: The NIC receives a TCP segment from a client. Its DMA engine writes the payload directly into a kernel memory region (the socket's receive queue) without CPU involvement. The NIC raises an interrupt line. The CPU pauses its current instruction stream, saves registers, and jumps to the interrupt handler.\n**Level 2 â€” OS/Kernel**: The interrupt handler (running in interrupt context, non-preemptible) dequeues the packet from the NIC's RX ring buffer and places it in the socket's `sk_receive_queue`. It calls `sk->sk_data_ready(sk)`â€”the socket's readiness callbackâ€”which wakes the epoll subsystem. The epoll `epitem` for this fd is moved from the \"sleeping\" list to `rdllist` (the ready list). The interrupt handler returns. The kernel resumes the process that was running (your event loop, sleeping in `epoll_wait`). The kernel's `epoll_wait` implementation walks `rdllist`, copies `{events, data}` pairs into your user-space `events[]` array via `copy_to_user()`, and returns the count.\n**Level 1 â€” Application**: Your `reactor_run` loop receives `n_ready`. It iterates the `events[]` array. For each event, it reads `events[i].data.ptr`, casts it to `fd_handler *`, checks the zombie flag, maps the epoll event flags to `REACTOR_*` flags, and calls `h->callback(fd, r_events, h->user_data)`. Your application code runs. One TCP segment, one DMA transfer, one interrupt, one syscall return, one array index, one function pointer dereference.\nThe entire path from NIC interrupt to your `echo_readable` function runs in under 5 Âµs on a modern serverâ€”wire-to-callback latency. This is what makes event-driven servers fast: no thread switching, no scheduler involvement, no stack swaps. One path, end to end.\n---\n## Hardware Soul: Cache Analysis of the Dispatch Loop\nThe dispatch loop's hot path touches several memory regions. Understanding their cache behavior reveals why the design choices above matter at scale.\n**`events[]` array**: Allocated on the stack in `reactor_run`. With `MAX_EVENTS=1024` and `sizeof(struct epoll_event)=12` bytes: 12,288 bytes, fits in L1 cache (typically 32â€“64 KB). Iterating over it is sequential and prefetch-friendlyâ€”the hardware prefetcher recognizes stride-1 access and loads upcoming cache lines before you need them. This array is cache-hot for the entire dispatch loop.\n**`fd_handler handlers[]`**: The registration table is `MAX_FDS Ã— 24 bytes = 1.5 MB`. This does not fit in L1 or L2 (typically 256 KBâ€“2 MB), and barely fits in L3 (typically 8â€“32 MB). Accessing `handlers[fd]` for a non-recently-seen fd is an L3 cache miss (~40 ns). Under 10K active connections with uniform distribution, the working set of recently-accessed handler entries is `10,000 Ã— 24 = 240 KB`â€”fits in L2. Connections accessed infrequently (idle connections) will cache-miss on every event, but that's acceptable because they're rare.\n**`data.ptr` vs `data.fd` dispatch**: When you store `data.ptr = &handlers[fd]`, retrieving the handler requires one pointer dereference. When you use `data.fd`, you'd need `handlers[events[i].data.fd]`â€”one array access with multiplication. The pointer approach saves 3â€“5 cycles per event on average, because the pointer is already the exact memory address. However, it means the `events[]` array holds pointers into the `handlers[]` arrayâ€”if `handlers[]` is ever reallocated (it isn't in our fixed-size design), all stored pointers become dangling. This is why we use a fixed-size array, not a dynamic one.\n**Deferred mods queue**: Typically empty (most calls happen outside dispatch). When non-empty, it's small (a handful of entries per tick), always fits in L1. Applying deferred mods after dispatch is fast.\n**The zombie flag**: Checking `h->zombie` is a single byte read. For a recently-closed fd whose handler is in L1 cache, this is essentially free. The branch itself is nearly always not-taken (zombie fds are rare) and quickly predicted by the branch predictor.\n---\n## Design Decision: Which Deferred-Modification Strategy?\nThree strategies exist for handling modifications-during-dispatch. Here's the full tradeoff:\n| Strategy | How It Works | Pros | Cons | Used By |\n|----------|--------------|------|------|---------|\n| **Zombie + deferred mods âœ“** | Mark fd as zombie; queue epoll_ctl for after dispatch | Simple to reason about; correct for all cases | Small queue allocation overhead | libuv, our design |\n| **Events array copy** | Snapshot all events before dispatch; modifications go to live kernel state immediately | No deferred queue needed; always-fresh kernel state | 12 KB memcpy per tick; stale events still dispatched to wrong callbacks | Some early libevent versions |\n| **Generation counter** | Each handler has a generation number; events carry the generation they were generated for; mismatches are skipped | Zero extra memory | Complex; counter must be updated atomically | Some game engine ECS systems |\nThe zombie + deferred mods approach is the cleanest. The invariant is clear: `zombie = true` means \"this handler is dead to this dispatch cycle.\" The deferred mod queue is small and short-lived. The correctness argument is local and mechanicalâ€”no global reasoning required.\n---\n## Testing the Reactor: A Validation Suite\nBefore moving to Milestone 4, verify these specific behaviors:\n**Test 1: Deferred deregistration correctness**\n```c\n/* Set up two connections. In the callback for conn A, close conn B.\n * Conn B must NOT receive a callback for events already in the batch. */\nstatic int closed_fd = -1;\nstatic void conn_a_callback(int fd, uint32_t events, void *user_data) {\n    reactor *r = (reactor *)user_data;\n    (void)fd; (void)events;\n    /* Close conn B from inside conn A's callback */\n    reactor_deregister(r, closed_fd);\n}\nstatic void conn_b_callback(int fd, uint32_t events, void *user_data) {\n    (void)fd; (void)events; (void)user_data;\n    /* THIS MUST NEVER BE CALLED after conn_a_callback runs */\n    fprintf(stderr, \"FAIL: conn_b_callback called after deregistration\\n\");\n    abort();\n}\n```\nTrigger both fds to have events simultaneously (e.g., pipe both ends with data). Verify `conn_b_callback` is never called after `conn_a_callback` deregisters it.\n**Test 2: Interval timer accuracy**\n```c\nstatic int tick_count = 0;\nstatic uint64_t first_tick_ms = 0;\nstatic void interval_cb(reactor *r, void *user_data) {\n    (void)user_data;\n    tick_count++;\n    if (tick_count == 1) first_tick_ms = now_ms();\n    if (tick_count == 10) {\n        uint64_t elapsed = now_ms() - first_tick_ms;\n        /* 9 intervals of 100ms = 900ms; allow Â±50ms tolerance */\n        assert(elapsed >= 850 && elapsed <= 950);\n        printf(\"Interval timer: 10 ticks in %lu ms â€” PASS\\n\", elapsed);\n        reactor_stop(r);\n    }\n}\n/* In main: */\nreactor_set_interval(r, 100, interval_cb, NULL);\nreactor_run(r);\n```\n**Test 3: Deferred task ordering**\n```c\n/* Verify: deferred tasks run AFTER all I/O callbacks in the current tick */\nstatic int io_count = 0;\nstatic int defer_ran_at = -1;\nstatic void check_defer(reactor *r, void *ud) {\n    defer_ran_at = io_count;  /* should equal total_io_events_this_tick */\n}\nstatic void io_cb(int fd, uint32_t events, void *ud) {\n    reactor *r = (reactor *)ud;\n    io_count++;\n    if (io_count == 1) {\n        reactor_defer(r, check_defer, NULL);  /* deferred during first I/O event */\n    }\n}\n```\nAfter the tick completes, `defer_ran_at` should equal the total number of I/O callbacks that fired (not 1, because deferred tasks run after ALL I/O).\n**Test 4: EPOLLHUP and EPOLLERR dispatch**\n```c\n/* Create a socket pair. Close one end. Verify REACTOR_HANGUP fires. */\nint sv[2];\nsocketpair(AF_UNIX, SOCK_STREAM, 0, sv);\nstatic bool got_hangup = false;\nstatic void hangup_cb(int fd, uint32_t events, void *ud) {\n    if (events & REACTOR_HANGUP) got_hangup = true;\n}\nreactor_register(r, sv[0], REACTOR_READABLE, hangup_cb, NULL);\nclose(sv[1]);  /* close the other end */\nreactor_run(r);  /* should return after one tick */\nassert(got_hangup);\n```\n---\n## Knowledge Cascade: What This Unlocks\n**1. JavaScript's microtask queue (cross-domain: web frontend)**\nThe `reactor_defer` you just built is exactly the mechanism behind JavaScript's microtask queue. In a browser, when a `Promise.then()` callback runs, it runs after the current \"task\" (macro-task: I/O event, setTimeout, user event) but before the browser re-renders or picks up the next macro-task. This is the microtask queue. React's `setState` batching works the same way: calling `setState` multiple times in a single event handler doesn't trigger multiple re-renders; React batches the state updates and applies them after the event handler returnsâ€”deferred modification of the component tree, applied after the current \"dispatch\" is complete.\nYour `reactor_run_deferred` is the C implementation of what V8's event loop calls \"drain the microtask queue.\" The mechanism is identical: collect tasks during dispatch, run them after, before the next poll.\n**2. Game engine ECS and deferred destruction (cross-domain: game dev)**\nEntity-Component Systemsâ€”the architecture behind Unity's DOTS, Bevy, and Flecsâ€”face the exact same problem you solved with zombie flags. An entity (like your fd) can be destroyed by a system (like your callback) while the system is iterating over all entities with a given component type. Destroying the entity directly invalidates the iterator. The standard solution is a \"deferred destruction queue\": mark the entity as \"pending deletion,\" finish the current system's iteration, then process all pending deletions. Flecs calls this a \"deferred world.\" Your `h->zombie` flag and `mods` queue are precisely this pattern, applied to a networking context.\n**3. Rust's borrow checker eliminates this class of bug at compile time**\nThe bug you defended againstâ€”holding a reference to `handlers[fd]` while calling code that might free `handlers[fd]`â€”is the classic aliasing problem. In Rust, you cannot hold a shared reference (`&fd_handler`) and simultaneously call a function that takes `&mut reactor` (which would allow modifying `handlers`). The borrow checker statically prevents this. If you were building this reactor in Rust, the callback signature would force you to express the aliasing constraints explicitly, and incorrect code would fail at compile time rather than at 3am under load. This is the exact aliasing problem the borrow checker was designed to preventâ€”and it's why Rust is increasingly used for networking infrastructure.\n**4. Linux kernel bottom-half processing (same mechanism, different context)**\nLinux interrupt handlers face the same constraint: when a hardware interrupt fires, the CPU is executing in interrupt contextâ€”a non-preemptible, non-schedulable execution context. The interrupt handler must complete quickly and cannot sleep. But interrupt handling often requires complex work (network packet processing, disk completion handling) that would take too long in interrupt context. Linux's solution: the interrupt handler does minimal work (dequeues the NIC packet, records the event) and schedules a \"softirq\" (software interrupt) or \"tasklet\" to run the heavy work later, in a preemptible context, after the interrupt handler returns. This is Linux's deferred task queueâ€”your `reactor_defer` is the application-space equivalent of scheduling a softirq.\n**5. Reactor vs Proactor: why io_uring is architecturally different**\nThe reactor pattern is *synchronous dispatch*: you ask the kernel \"is this fd ready?\" and then do the I/O yourself. The proactor pattern is *asynchronous completion*: you submit an I/O operation to the kernel (\"read 4096 bytes into this buffer\"), and the kernel tells you when it's *done*â€”handing you the result, not just the readiness signal.\n`io_uring` (Linux 5.1+) is a proactor. You don't call `read()` after `epoll_wait` tells you there's data. You submit `IORING_OP_READ` to the submission ring, specifying the fd, buffer, and length. When the read completes, a completion entry appears in the completion ring with the bytes read. The callback re-entrancy problem you solved in this milestone largely disappears in the proactor modelâ€”by the time a completion fires, the I/O has already happened and the fd's state has already changed. There's no \"we're in the middle of dispatching\" state because operations are submitted and completed atomically from the application's perspective.\nUnderstanding the reactor pattern and its limitations is the direct prerequisite for understanding why io_uring's proactor model is worth the added complexity.\n\n![Reactor vs Proactor: Architectural Comparison](./diagrams/diag-m3-reactor-vs-proactor.svg)\n\n---\n## Pitfall Reference: The Five Ways This Breaks\n**Pitfall 1: Modifying the fd_handler table during dispatch without zombie protection**\n*Symptom*: Callbacks fire for connections that were closed earlier in the same event batch; data sent to wrong clients; occasional segfault in callback dispatch.\n*Fix*: Set `h->zombie = true` in `reactor_deregister` when `r->dispatching == true`. Check `h->zombie` at the start of each dispatch iteration.\n**Pitfall 2: Deferred tasks running interleaved with I/O dispatch**\n*Symptom*: A deferred task that closes a connection runs before all events for that connection are processed; the later events dispatch to freed state.\n*Fix*: Run `reactor_run_deferred` AFTER the `for (i = 0; i < n; i++)` dispatch loop completes, not inside it.\n**Pitfall 3: A timer callback that cancels itself for an interval timer**\n*Symptom*: `reactor_cancel_timer` modifies the heap during `reactor_process_timers`'s iteration; heap invariant violated; subsequent timer operations use wrong entries.\n*Fix*: In interval timer callbacks that want to stop, use `reactor_defer` to cancel the timer after `reactor_process_timers` returns. Alternatively, set a flag and check it before re-arming.\n**Pitfall 4: Not clearing the zombie flag on re-registration**\n*Symptom*: A callback closes an fd, the fd is immediately reused by `accept4`, `reactor_register` is called for the new connection, but the callback is never invoked because `h->zombie` is still true.\n*Fix*: In `reactor_register`, always set `h->zombie = false`. Re-registration on a zombie fd is a valid and common pattern.\n**Pitfall 5: EPOLLHUP without EPOLLIN â€” closing without reading remaining data**\n*Symptom*: HTTP pipelining requests are silently dropped; the client sends a second request, closes the connection, but the server never processes the second request because it closes immediately on EPOLLHUP.\n*Fix*: When `REACTOR_HANGUP` fires simultaneously with `REACTOR_READABLE`, always process readable data first. Check `events & REACTOR_READABLE` before closing.\n---\n<!-- END_MS -->\n\n\n<!-- MS_ID: build-event-loop-m4 -->\n<!-- MS_ID: build-event-loop-m4 -->\n# HTTP Server on Event Loop\n## The Illusion That Breaks Under Load\nYou've built a reactor. You've built write buffering. You've built timer management. Now it's time to put a real protocol on topâ€”HTTP/1.1â€”and watch every assumption from your experience with simple TCP echo servers get destroyed in the most instructive way possible.\nHere's the assumption: when a client sends an HTTP request, your `read()` call returns the complete request. The full `GET /index.html HTTP/1.1\\r\\nHost: example.com\\r\\nConnection: keep-alive\\r\\n\\r\\n` arrives in one chunk, you parse it, you respond. This assumption is correct roughly 95% of the time in local testing. It fails in exactly the scenarios that matter.\nTCP is a **byte stream protocol**. It makes one guarantee: bytes arrive in order. It makes no guarantee about how those bytes are grouped into `read()` calls. The kernel's TCP stack receives IP packets, reassembles them (handling reordering, retransmission, duplication), and places bytes into the socket's receive buffer. When you call `read()`, you get whatever is in that buffer at that momentâ€”which may be a fragment of a request, exactly one request, or multiple requests concatenated together.\nOver localhost, packets almost never fragment because the loopback MTU is 65,535 bytes. In production, over a real network with a 1,500-byte MTU, a 4,096-byte request header set fragments across 3 packets. If those packets arrive in separate TCP segments and your event loop processes them separatelyâ€”which it will, under loadâ€”you get three `read()` calls, each returning a piece of the headers.\n\n![Data Walk: Incremental HTTP Header Parsing Across 3 Reads](./diagrams/diag-m4-incremental-parse-data-walk.svg)\n\nHere's the concrete sequence that breaks a naive parser:\n- **Read 1** returns: `GET /index.html HTTP/1.1\\r\\nHost: exa`\n- **Read 2** returns: `mple.com\\r\\nConnection: keep-alive\\r\\n`\n- **Read 3** returns: `\\r\\n`\nA parser that expects the full request on `read()` call 1 either crashes on the incomplete data, or silently discards the partial request and waits for a \"new\" request that never comes. The connection hangs. Under load testing, this manifests as random timeouts at around the 95th percentileâ€”requests that take 10 seconds and then reset. The server appears to handle most traffic fine; the failures are intermittent and hard to reproduce in a debugger.\nThe correct design: **the parser is a state machine that can pause at any byte boundary and resume correctly**. The event loop feeds it bytes incrementally; the parser returns either \"complete\" (I have a full request) or \"incomplete\" (give me more bytes). This is how every production HTTP parser is designedâ€”`http_parser` (Node.js's original C library), `llhttp` (its successor), `picohttpparser` (used by H2O and others), and the parser in Go's `net/http` package. You're about to build a simplified version that captures all the key concepts.\n---\n## The Per-Connection State Machine\nBefore writing the parser, define the states a connection passes through. Every connection lives in exactly one state at a time, and valid state transitions are explicit. This is not optional architectureâ€”it's the mechanism that makes incremental parsing safe.\n\n![Per-Connection HTTP State Machine](./diagrams/diag-m4-http-state-machine.svg)\n\n```c\n/*\n * conn_http_state - States for an HTTP/1.1 connection's protocol lifecycle.\n *\n * READING_HEADERS: accumulating bytes until we see \\r\\n\\r\\n (end of headers)\n * READING_BODY:    accumulating body bytes up to Content-Length\n * PROCESSING:      headers complete, preparing the response\n * WRITING_RESPONSE: sending response bytes (may span multiple writes)\n * CLOSING:         response sent, Connection: close requested; close after flush\n *\n * Only READING_HEADERS â†’ READING_BODY is optional (GET has no body).\n * Most GET requests go: READING_HEADERS â†’ PROCESSING â†’ WRITING_RESPONSE\n *                        â†’ READING_HEADERS (keep-alive) or CLOSING\n */\ntypedef enum {\n    HTTP_READING_HEADERS  = 0,\n    HTTP_READING_BODY     = 1,\n    HTTP_PROCESSING       = 2,\n    HTTP_WRITING_RESPONSE = 3,\n    HTTP_CLOSING          = 4,\n} conn_http_state;\n```\nNow define the full per-connection HTTP context. This extends the connection state from Milestone 2 with HTTP-specific fields:\n```c\n#include <stdint.h>\n#include <stdbool.h>\n#include <sys/stat.h>\n#define READ_BUF_SIZE      16384   /* 16 KB: large enough for typical request headers */\n#define MAX_PATH_LEN       1024\n#define MAX_METHOD_LEN     8\n#define MAX_HEADER_VALUE   256\n#define STATIC_DIR         \"./public\"  /* serve files from this directory */\n#define IDLE_TIMEOUT_MS    30000       /* 30 seconds */\n/*\n * http_request - Parsed fields from one HTTP request.\n *\n * Populated incrementally as headers are parsed.\n * Reset to zero at the start of each new request (keep-alive reuse).\n *\n * Memory layout:\n *   method[8]          =   8 bytes\n *   path[1024]         = 1024 bytes\n *   content_length     =   8 bytes (uint64_t)\n *   body_received      =   8 bytes (uint64_t)\n *   keep_alive         =   1 byte  (bool)\n *   has_content_length =   1 byte  (bool)\n *   [6 bytes padding]\n *   Total: ~1056 bytes\n */\ntypedef struct {\n    char     method[MAX_METHOD_LEN];\n    char     path[MAX_PATH_LEN];\n    uint64_t content_length;\n    uint64_t body_received;\n    bool     keep_alive;\n    bool     has_content_length;\n} http_request;\n/*\n * http_conn - Complete per-connection HTTP state.\n *\n * This is the user_data pointer registered with reactor_register().\n * The reactor knows nothing about HTTP; it just calls our callback\n * with this pointer as the context.\n *\n * Memory layout (approximate, 64-bit):\n *   read_buf[16384]    = 16384 bytes  (incoming byte accumulator)\n *   wbuf               =    24 bytes  (write_buf from M2)\n *   req                =  1056 bytes  (parsed HTTP request)\n *   read_len           =     4 bytes  (bytes used in read_buf)\n *   fd                 =     4 bytes\n *   timer_id           =     4 bytes\n *   state              =     4 bytes  (conn_http_state enum)\n *   [4 bytes padding]\n *   reactor_ref        =     8 bytes  (pointer back to reactor)\n *   Total: ~17488 bytes per connection\n *\n * At 10,000 connections: ~171 MB resident. The read_buf is the dominant\n * cost. If memory is tight, reduce READ_BUF_SIZE to 4096 and handle\n * header lines > 4096 bytes as an error (RFC 7230 allows servers to\n * reject excessively large headers).\n */\ntypedef struct {\n    char            read_buf[READ_BUF_SIZE];\n    write_buf       wbuf;\n    http_request    req;\n    uint32_t        read_len;       /* bytes of valid data in read_buf */\n    int             fd;\n    int             timer_id;       /* reactor timer handle, -1 if none */\n    conn_http_state state;\n    reactor        *reactor_ref;\n} http_conn;\n```\n> **Why a pointer back to the reactor?** Each `http_conn` needs to call `reactor_defer`, `reactor_set_timeout`, and `reactor_deregister` when it processes events. In Milestone 3, your callbacks received the reactor as a separate argument in some designs. Storing it directly in the connection state avoids threading the reactor pointer through every function call. This is idiomatic in C event-driven codeâ€”connection objects hold a reference to their owning event loop.\n---\n## The Incremental HTTP Parser\nThe parser's contract is simple: given a byte buffer of length N, return either a parsed request (complete) or `PARSE_INCOMPLETE` (need more bytes). Internally, it's a state machine that scans the buffer once, character by character, tracking which parsing sub-state it's in.\nFor this milestone, implement a header-only parser for GET requests. The HTTP body parsing for POST/PUT requests follows the same pattern but is left as an extension exercise.\n```c\n/*\n * parse_result - What the parser returns after examining the buffer.\n */\ntypedef enum {\n    PARSE_COMPLETE   =  0,  /* full request parsed; req is populated */\n    PARSE_INCOMPLETE = -1,  /* need more data */\n    PARSE_ERROR      = -2,  /* malformed request; close connection */\n} parse_result;\n/*\n * find_header_end - Scan buffer for the \\r\\n\\r\\n sequence marking end of headers.\n *\n * Returns the byte offset AFTER the \\r\\n\\r\\n, or -1 if not found.\n *\n * Implementation uses a simple scan. Production parsers (picohttpparser)\n * use SIMD to scan 16 bytes at a time with SSE2 _mm_cmpeq_epi8 â€” scanning\n * for '\\r' across 16 bytes in 2 cycles instead of 16. For this milestone,\n * the naive scan is correct and measurable.\n *\n * Cache note: buf is in L1 cache (just read from the socket). Sequential\n * scan is prefetch-friendly â€” the hardware prefetcher loads upcoming cache\n * lines before we need them.\n */\nstatic int find_header_end(const char *buf, uint32_t len) {\n    /* Need at least 4 bytes for \\r\\n\\r\\n */\n    if (len < 4) return -1;\n    for (uint32_t i = 0; i <= len - 4; i++) {\n        if (buf[i]   == '\\r' && buf[i+1] == '\\n' &&\n            buf[i+2] == '\\r' && buf[i+3] == '\\n') {\n            return (int)(i + 4);\n        }\n    }\n    return -1;\n}\n/*\n * parse_request_line - Extract method and path from \"METHOD /path HTTP/1.1\".\n *\n * Returns 0 on success, -1 on malformed request.\n * line is NOT null-terminated; line_len is its length.\n */\nstatic int parse_request_line(const char *line, int line_len, http_request *req) {\n    /* Find first space (end of method) */\n    int method_end = -1;\n    for (int i = 0; i < line_len; i++) {\n        if (line[i] == ' ') { method_end = i; break; }\n    }\n    if (method_end <= 0 || method_end >= MAX_METHOD_LEN) return -1;\n    memcpy(req->method, line, method_end);\n    req->method[method_end] = '\\0';\n    /* Find second space (end of path) */\n    int path_start = method_end + 1;\n    int path_end   = -1;\n    for (int i = path_start; i < line_len; i++) {\n        if (line[i] == ' ') { path_end = i; break; }\n    }\n    if (path_end <= path_start) return -1;\n    int path_len = path_end - path_start;\n    if (path_len >= MAX_PATH_LEN) return -1;\n    memcpy(req->path, line + path_start, path_len);\n    req->path[path_len] = '\\0';\n    return 0;\n}\n/*\n * parse_header_field - Process one \"Name: Value\\r\\n\" header line.\n *\n * We only extract the fields we care about: Content-Length and Connection.\n * Unknown headers are silently ignored â€” correct per RFC 7230.\n */\nstatic void parse_header_field(const char *line, int line_len, http_request *req) {\n    /* Find the colon separator */\n    int colon = -1;\n    for (int i = 0; i < line_len; i++) {\n        if (line[i] == ':') { colon = i; break; }\n    }\n    if (colon <= 0) return;\n    /* Skip whitespace after colon */\n    int val_start = colon + 1;\n    while (val_start < line_len && line[val_start] == ' ') val_start++;\n    int val_len = line_len - val_start;\n    if (val_len <= 0) return;\n    /* Case-insensitive header name comparison */\n    if (colon == 14 && strncasecmp(line, \"Content-Length\", 14) == 0) {\n        char tmp[32] = {0};\n        int  copy    = val_len < 31 ? val_len : 31;\n        memcpy(tmp, line + val_start, copy);\n        req->content_length     = (uint64_t)strtoull(tmp, NULL, 10);\n        req->has_content_length = true;\n    } else if (colon == 10 && strncasecmp(line, \"Connection\", 10) == 0) {\n        /* Check for \"close\" value */\n        if (val_len >= 5 && strncasecmp(line + val_start, \"close\", 5) == 0) {\n            req->keep_alive = false;\n        }\n    }\n}\n/*\n * http_parse_headers - Attempt to parse complete HTTP headers from buf.\n *\n * CALLING CONVENTION:\n *   Call after every read(). If PARSE_INCOMPLETE, return to the event loop\n *   and wait for more data. If PARSE_COMPLETE, buf[0..header_end] has been\n *   consumed; remaining bytes (body or start of next request) begin at\n *   buf[header_end].\n *\n * Returns: PARSE_COMPLETE, PARSE_INCOMPLETE, or PARSE_ERROR.\n * On PARSE_COMPLETE, *header_end_out is set to the byte offset after \\r\\n\\r\\n.\n */\nparse_result http_parse_headers(const char *buf, uint32_t len,\n                                http_request *req, int *header_end_out) {\n    int hdr_end = find_header_end(buf, len);\n    if (hdr_end < 0) {\n        /* Haven't seen \\r\\n\\r\\n yet */\n        if (len >= READ_BUF_SIZE) {\n            /* Buffer full, no end found â€” headers too large */\n            return PARSE_ERROR;\n        }\n        return PARSE_INCOMPLETE;\n    }\n    /* Default: keep-alive for HTTP/1.1 (RFC 7230 Â§6.3) */\n    req->keep_alive         = true;\n    req->has_content_length = false;\n    req->content_length     = 0;\n    req->body_received      = 0;\n    /* Parse line by line. Lines are separated by \\r\\n. */\n    const char *pos     = buf;\n    const char *hdr_end_ptr = buf + hdr_end;\n    bool        first   = true;\n    while (pos < hdr_end_ptr) {\n        /* Find end of this line */\n        const char *line_end = pos;\n        while (line_end + 1 < hdr_end_ptr &&\n               !(line_end[0] == '\\r' && line_end[1] == '\\n')) {\n            line_end++;\n        }\n        int line_len = (int)(line_end - pos);\n        if (first) {\n            if (parse_request_line(pos, line_len, req) != 0) {\n                return PARSE_ERROR;\n            }\n            first = false;\n        } else if (line_len > 0) {\n            parse_header_field(pos, line_len, req);\n        }\n        pos = line_end + 2;  /* skip \\r\\n */\n    }\n    *header_end_out = hdr_end;\n    return PARSE_COMPLETE;\n}\n```\n> **Why iterate byte-by-byte instead of using `strstr`?** `strstr` would find `\\r\\n\\r\\n`, but it requires null-terminated input, and your read buffer may contain binary data in the body. More importantly, `strstr` on a large buffer scans from the beginning every call. Since you're accumulating bytes across multiple reads, you'd rescan already-checked bytes on every invocation. A production optimization: remember the parse position between reads (store `parse_offset` in `http_conn`) and start scanning from there. For this milestone, rescanning from zero is correct; the optimization is straightforward once the basic structure works.\n---\n## Handling the Read Event: Accumulate, Parse, Dispatch\nThis is the read callback registered with the reactor for every client fd. It's the integration point where the event loop, the parser, and the state machine meet:\n```c\n#include \"reactor.h\"\n#include <errno.h>\n#include <unistd.h>\n#include <string.h>\n#include <stdio.h>\n#include <stdlib.h>\n/* Forward declarations */\nstatic void http_process_request(http_conn *conn);\nstatic void http_conn_close_deferred(reactor *r, void *user_data);\nstatic void http_conn_reset_for_keepalive(http_conn *conn);\n/*\n * http_on_readable - Called by reactor when REACTOR_READABLE fires.\n *\n * This function embodies the incremental parsing loop:\n *   1. Read all available data into the accumulation buffer.\n *   2. After each read, attempt to parse.\n *   3. If parse completes: transition state, process request.\n *   4. If parse incomplete: return to event loop (wait for more data).\n *   5. Handle the ET discipline: read until EAGAIN.\n *\n * NOTE: This server registers with EPOLLIN | EPOLLET for efficiency.\n * The drain-until-EAGAIN loop is therefore mandatory here (Milestone 1).\n */\nstatic void http_on_readable(int fd, uint32_t events, void *user_data) {\n    http_conn *conn = (http_conn *)user_data;\n    reactor   *r    = conn->reactor_ref;\n    /* Error or hangup: schedule cleanup and return */\n    if (events & (REACTOR_ERROR | REACTOR_HANGUP)) {\n        reactor_defer(r, http_conn_close_deferred, conn);\n        return;\n    }\n    /* Only accept reads in the READING_HEADERS or READING_BODY states */\n    if (conn->state != HTTP_READING_HEADERS && conn->state != HTTP_READING_BODY) {\n        /* Unexpected read during PROCESSING or WRITING â€” possible race.\n         * Ignore: the write path will close the connection when done. */\n        return;\n    }\n    /* ET mode: drain until EAGAIN */\n    for (;;) {\n        /* How much space is left in the read buffer? */\n        uint32_t space = READ_BUF_SIZE - conn->read_len;\n        if (space == 0) {\n            /* Buffer full without completing parse â€” headers too large */\n            reactor_defer(r, http_conn_close_deferred, conn);\n            return;\n        }\n        ssize_t n = read(fd, conn->read_buf + conn->read_len, space);\n        if (n > 0) {\n            conn->read_len += (uint32_t)n;\n            /* Reset idle timer: we received data */\n            if (conn->timer_id >= 0) {\n                reactor_cancel_timer(r, conn->timer_id);\n            }\n            conn->timer_id = reactor_set_timeout(r, IDLE_TIMEOUT_MS,\n                                                  http_idle_timeout_cb, conn);\n            /* Attempt to parse after every read â€” don't wait for EAGAIN */\n            if (conn->state == HTTP_READING_HEADERS) {\n                int header_end = 0;\n                parse_result pr = http_parse_headers(conn->read_buf,\n                                                     conn->read_len,\n                                                     &conn->req,\n                                                     &header_end);\n                if (pr == PARSE_ERROR) {\n                    /* Malformed request: send 400, then close */\n                    http_send_error(conn, 400, \"Bad Request\");\n                    conn->state = HTTP_CLOSING;\n                    return;\n                }\n                if (pr == PARSE_COMPLETE) {\n                    /* Headers done. Do we have a body? */\n                    if (conn->req.has_content_length && conn->req.content_length > 0) {\n                        /* Shift remaining bytes (body start) to front of buffer */\n                        uint32_t remaining = conn->read_len - (uint32_t)header_end;\n                        if (remaining > 0) {\n                            memmove(conn->read_buf,\n                                    conn->read_buf + header_end,\n                                    remaining);\n                        }\n                        conn->read_len = remaining;\n                        conn->req.body_received = remaining;\n                        conn->state = HTTP_READING_BODY;\n                        /* Fall through to body reading below */\n                    } else {\n                        /* No body: process immediately */\n                        conn->read_len = 0;\n                        conn->state    = HTTP_PROCESSING;\n                        http_process_request(conn);\n                        /* After processing, we may be back in READING_HEADERS\n                         * (keep-alive) or CLOSING. If writing started, the\n                         * EPOLLOUT path (from M2) handles the rest. */\n                        if (conn->state == HTTP_CLOSING) return;\n                        /* Continue drain loop for pipelining */\n                    }\n                }\n                /* PARSE_INCOMPLETE: continue reading */\n            }\n            if (conn->state == HTTP_READING_BODY) {\n                uint64_t needed = conn->req.content_length - conn->req.body_received;\n                /* We only buffer up to READ_BUF_SIZE of the body.\n                 * For large bodies, a production server would stream to disk. */\n                if (conn->req.body_received >= conn->req.content_length) {\n                    conn->state = HTTP_PROCESSING;\n                    http_process_request(conn);\n                    if (conn->state == HTTP_CLOSING) return;\n                } else {\n                    (void)needed; /* still accumulating */\n                }\n            }\n        } else if (n == 0) {\n            /* EOF: peer closed the connection */\n            reactor_defer(r, http_conn_close_deferred, conn);\n            return;\n        } else {\n            /* n == -1 */\n            if (errno == EAGAIN || errno == EWOULDBLOCK) {\n                break;  /* buffer fully drained â€” exit ET read loop */\n            }\n            /* Real socket error */\n            reactor_defer(r, http_conn_close_deferred, conn);\n            return;\n        }\n    }\n}\n```\n\n![Complete Request Lifecycle: Accept to Response to Close](./diagrams/diag-m4-full-request-lifecycle-trace.svg)\n\nThe critical insight in `http_on_readable`: `http_parse_headers` is called inside the read loop, after every successful `read()`. This is the incremental designâ€”don't wait for EAGAIN to try parsing. The moment you have more data, try. If headers are complete, process immediately without waiting for the next event. If they're not complete, the loop continues reading (or exits on EAGAIN, and the reactor will re-notify when more data arrives).\nThe `memmove` after parsing headers deserves attention. If your 16 KB read buffer received 512 bytes of headers followed by the first 128 bytes of a POST body, `header_end` points to byte 512. The body bytes (128 bytes) need to be at the *front* of the buffer for subsequent reads to append correctly. `memmove` slides them there. This is O(body_received) bytes copiedâ€”small for this use case, but worth noting for large streaming bodies where you'd want a ring buffer or linked list of chunks.\n---\n## Processing the Request and Serving Static Files\n```c\n#include <fcntl.h>\n#include <sys/stat.h>\n#include <sys/sendfile.h>\n/*\n * get_content_type - Map file extension to MIME type string.\n * Returns \"application/octet-stream\" for unknown extensions.\n */\nstatic const char *get_content_type(const char *path) {\n    const char *dot = strrchr(path, '.');\n    if (!dot) return \"application/octet-stream\";\n    if (strcmp(dot, \".html\") == 0 || strcmp(dot, \".htm\") == 0)\n        return \"text/html; charset=utf-8\";\n    if (strcmp(dot, \".css\")  == 0) return \"text/css\";\n    if (strcmp(dot, \".js\")   == 0) return \"application/javascript\";\n    if (strcmp(dot, \".json\") == 0) return \"application/json\";\n    if (strcmp(dot, \".png\")  == 0) return \"image/png\";\n    if (strcmp(dot, \".jpg\")  == 0 || strcmp(dot, \".jpeg\") == 0)\n        return \"image/jpeg\";\n    if (strcmp(dot, \".ico\")  == 0) return \"image/x-icon\";\n    if (strcmp(dot, \".txt\")  == 0) return \"text/plain; charset=utf-8\";\n    return \"application/octet-stream\";\n}\n/*\n * build_safe_path - Combine STATIC_DIR with the request path, rejecting\n * path traversal attacks (/../ sequences).\n *\n * Returns 0 on success (out_path populated), -1 if path is unsafe.\n *\n * Security note: Without this check, a request for\n *   GET /../../../etc/passwd HTTP/1.1\n * would serve the system password file. Never skip this.\n */\nstatic int build_safe_path(const char *req_path, char *out_path, int out_len) {\n    /* Reject any path containing \"..\" after normalization */\n    if (strstr(req_path, \"..\") != NULL) return -1;\n    /* Reject paths not starting with '/' */\n    if (req_path[0] != '/') return -1;\n    /* Combine static dir + request path */\n    int n = snprintf(out_path, out_len, \"%s%s\", STATIC_DIR, req_path);\n    if (n <= 0 || n >= out_len) return -1;\n    /* If path ends with '/', append index.html */\n    if (out_path[n - 1] == '/') {\n        int rem = out_len - n;\n        if (snprintf(out_path + n, rem, \"index.html\") >= rem) return -1;\n    }\n    return 0;\n}\n/*\n * http_send_error - Send a simple error response and queue for closing.\n *\n * Uses the write buffer from M2. Partial writes are handled by the\n * EPOLLOUT mechanism automatically.\n */\nstatic void http_send_error(http_conn *conn, int status, const char *reason) {\n    char buf[256];\n    int  n = snprintf(buf, sizeof(buf),\n                      \"HTTP/1.1 %d %s\\r\\n\"\n                      \"Content-Length: 0\\r\\n\"\n                      \"Connection: close\\r\\n\"\n                      \"\\r\\n\",\n                      status, reason);\n    if (n > 0) {\n        conn_write_buffered(conn->reactor_ref, conn, buf, (uint32_t)n);\n    }\n    conn->req.keep_alive = false;\n    conn->state = HTTP_CLOSING;\n}\n/*\n * http_process_request - Act on a fully-parsed HTTP request.\n *\n * This function is called from http_on_readable after parse completes.\n * It builds the response and writes it via the buffered write path from M2.\n * After this returns, the connection is either in WRITING_RESPONSE or CLOSING.\n */\nstatic void http_process_request(http_conn *conn) {\n    conn->state = HTTP_WRITING_RESPONSE;\n    /* Only handle GET and HEAD for this static file server */\n    bool is_head = (strcmp(conn->req.method, \"HEAD\") == 0);\n    if (strcmp(conn->req.method, \"GET\") != 0 && !is_head) {\n        http_send_error(conn, 405, \"Method Not Allowed\");\n        return;\n    }\n    /* Resolve the file path */\n    char file_path[MAX_PATH_LEN + sizeof(STATIC_DIR) + 16];\n    if (build_safe_path(conn->req.path, file_path, sizeof(file_path)) != 0) {\n        http_send_error(conn, 400, \"Bad Request\");\n        return;\n    }\n    /* Stat the file to get its size and verify it exists */\n    struct stat st;\n    if (stat(file_path, &st) != 0 || !S_ISREG(st.st_mode)) {\n        http_send_error(conn, 404, \"Not Found\");\n        return;\n    }\n    off_t file_size = st.st_size;\n    const char *content_type = get_content_type(file_path);\n    const char *conn_header  = conn->req.keep_alive\n                               ? \"keep-alive\" : \"close\";\n    /* Build response headers */\n    char headers[512];\n    int  hdr_len = snprintf(headers, sizeof(headers),\n                            \"HTTP/1.1 200 OK\\r\\n\"\n                            \"Content-Type: %s\\r\\n\"\n                            \"Content-Length: %lld\\r\\n\"\n                            \"Connection: %s\\r\\n\"\n                            \"\\r\\n\",\n                            content_type,\n                            (long long)file_size,\n                            conn_header);\n    if (hdr_len <= 0 || hdr_len >= (int)sizeof(headers)) {\n        http_send_error(conn, 500, \"Internal Server Error\");\n        return;\n    }\n    /* Write headers via M2 write buffer */\n    if (conn_write_buffered(conn->reactor_ref, conn,\n                             headers, (uint32_t)hdr_len) != 0) {\n        reactor_defer(conn->reactor_ref, http_conn_close_deferred, conn);\n        return;\n    }\n    if (is_head) {\n        /* HEAD: only headers, no body */\n        http_finalize_response(conn);\n        return;\n    }\n    /* Read file and write body. For small files, read into a buffer.\n     * For large files, see the sendfile() optimization in the\n     * Knowledge Cascade section. */\n    int file_fd = open(file_path, O_RDONLY | O_CLOEXEC);\n    if (file_fd < 0) {\n        /* Headers already sent; can't send 500 now. Close connection. */\n        reactor_defer(conn->reactor_ref, http_conn_close_deferred, conn);\n        return;\n    }\n    char file_buf[65536];  /* 64 KB read chunks */\n    off_t sent = 0;\n    while (sent < file_size) {\n        ssize_t n = read(file_fd, file_buf, sizeof(file_buf));\n        if (n <= 0) break;  /* file read error or unexpected EOF */\n        if (conn_write_buffered(conn->reactor_ref, conn,\n                                 file_buf, (uint32_t)n) != 0) {\n            close(file_fd);\n            reactor_defer(conn->reactor_ref, http_conn_close_deferred, conn);\n            return;\n        }\n        sent += n;\n    }\n    close(file_fd);\n    http_finalize_response(conn);\n}\n/*\n * http_finalize_response - Transition state after response is queued.\n *\n * If keep-alive: reset to READING_HEADERS for the next request.\n * If Connection: close: go to CLOSING, which triggers close after flush.\n */\nstatic void http_finalize_response(http_conn *conn) {\n    if (conn->req.keep_alive) {\n        /* Reuse connection: reset state machine for next request */\n        http_conn_reset_for_keepalive(conn);\n    } else {\n        conn->state = HTTP_CLOSING;\n        /* The write path (conn_flush from M2) will close the fd after the\n         * write buffer drains. We communicate this via the CLOSING state. */\n    }\n}\n```\n---\n## HTTP/1.1 Keep-Alive: The State Machine's Cycle\nKeep-alive is HTTP's connection reuse mechanism. Instead of TCP teardown and re-establishment for every request (which costs one full round-trip for the handshake plus TIME_WAIT overhead), the same TCP connection carries multiple request-response cycles sequentially.\n\n![HTTP Keep-Alive: Connection Reuse Timeline](./diagrams/diag-m4-keepalive-connection-reuse.svg)\n\n> **ðŸ”‘ Foundation: HTTP/1.1 keep-alive and Content-Length**\n>\n> **1. What it IS**\n> HTTP/1.1 defaults to keep-alive connections: the server keeps the TCP connection open after sending a response, and the client can send another request on the same connection. The critical constraint is framing: without `Content-Length` (or `Transfer-Encoding: chunked`), the client has no way to know where one response ends and the next begins in the TCP byte stream. `Content-Length` tells the client exactly how many bytes to read for the body, so it knows when the response is complete and the next request can begin.\n>\n> **2. Why you need it right now**\n> Keep-alive is not optional at C10K scale. Without it, every request requires a new TCP connection: 3-way handshake (~1 RTT), kernel allocates socket state, TIME_WAIT after close (~60 seconds holding the port pair). At 10,000 requests/second, that's 10,000 new connections per second and 600,000 connections in TIME_WAIT simultaneouslyâ€”your server exhausts its file descriptor limit in seconds. With keep-alive, the same 10,000 TCP connections carry all 10,000 requests/second indefinitely.\n>\n> **3. Key Insight: The Framing Contract**\n> HTTP/1.1's persistent connections work only because of strict framing. When your server sends `Content-Length: 1234`, you're making a contract: the response body is exactly 1,234 bytes, no more, no less. If you send 1,233 bytes and close the body, the client will wait forever for the 1,234th byte. If you send 1,235 bytes, the extra byte will be interpreted as the start of the next HTTP responseâ€”parse error. `Content-Length` is not metadata; it's the protocol's framing mechanism.\nResetting the connection for keep-alive means clearing all request-specific state while preserving connection-level infrastructure (the fd, the write buffer, the reactor registration, the idle timer):\n```c\n/*\n * http_conn_reset_for_keepalive - Reset parser state for next request.\n *\n * Called after a response is fully sent on a keep-alive connection.\n * MUST reset: read buffer, parsed request fields, state machine.\n * MUST preserve: fd, wbuf, reactor_ref, timer_id.\n *\n * This is the state transition that makes keep-alive work.\n * Without it, the read buffer retains old request bytes and the parser\n * incorrectly appends new request bytes to old ones.\n */\nstatic void http_conn_reset_for_keepalive(http_conn *conn) {\n    conn->read_len = 0;\n    conn->state    = HTTP_READING_HEADERS;\n    memset(&conn->req, 0, sizeof(conn->req));\n    /* The write buffer (conn->wbuf) is preserved â€” may have pending data.\n     * The idle timer is already reset on each read; we don't reset it here\n     * to avoid double-arming. */\n}\n```\nThe write side needs to be aware of the CLOSING state. When `conn_flush` fully drains the write buffer for a CLOSING connection, instead of just deregistering EPOLLOUT, it should close the connection:\n```c\n/*\n * http_on_writable - Called by reactor when REACTOR_WRITABLE fires.\n *\n * Flushes the write buffer. If the buffer empties:\n *   - CLOSING state: close the connection (deregister EPOLLOUT then close fd)\n *   - Other states: deregister EPOLLOUT (already handled in conn_flush from M2)\n */\nstatic void http_on_writable(int fd, uint32_t events, void *user_data) {\n    http_conn *conn = (http_conn *)user_data;\n    reactor   *r    = conn->reactor_ref;\n    (void)fd; (void)events;\n    /* Flush the write buffer (uses M2's conn_flush logic) */\n    int flush_result = conn_flush_http(r, conn);\n    if (flush_result != 0) {\n        /* Write error */\n        reactor_defer(r, http_conn_close_deferred, conn);\n        return;\n    }\n    /* If write buffer is now empty and we're in CLOSING state, close */\n    if (wbuf_is_empty(&conn->wbuf) && conn->state == HTTP_CLOSING) {\n        reactor_defer(r, http_conn_close_deferred, conn);\n    }\n}\n```\n\n![HTTP Response Write Path: Reactor Integration](./diagrams/diag-m4-write-integration-backpressure.svg)\n\n---\n## Connection Lifecycle and Resource Cleanup\nEvery exit pathâ€”normal close after `Connection: close`, idle timeout, read error, write error, parse errorâ€”must free the same set of resources in the same order. Missing any one resource is a leak; closing in the wrong order causes use-after-free.\n\n![Resource Cleanup: Every Exit Path Must Free Everything](./diagrams/diag-m4-resource-cleanup-all-paths.svg)\n\n```c\n/*\n * http_conn_close - Fully tear down one HTTP connection.\n *\n * MUST be called as a deferred task (via reactor_defer) when inside\n * a callback, NEVER called directly from within an I/O handler.\n * Reason: the reactor's dispatch loop may have more events for this fd\n * in the current batch; direct close causes use-after-free (M3 explains this).\n *\n * Cleanup order (MANDATORY):\n *   1. Check active flag â€” prevent double-free\n *   2. Cancel idle timer â€” prevent timer firing after fd close\n *   3. Deregister from reactor â€” prevent events on closed fd\n *   4. Free write buffer heap memory â€” prevent memory leak\n *   5. close(fd) â€” release file descriptor (kernel cleans up TCP state)\n *   6. free(conn) â€” release the conn struct itself\n */\nstatic void http_conn_close_deferred(reactor *r, void *user_data) {\n    http_conn *conn = (http_conn *)user_data;\n    /* Guard against double-close (timer + I/O error firing simultaneously) */\n    if (conn->fd < 0) return;\n    /* 2. Cancel idle timer */\n    if (conn->timer_id >= 0) {\n        reactor_cancel_timer(r, conn->timer_id);\n        conn->timer_id = -1;\n    }\n    /* 3. Deregister from reactor (triggers epoll_ctl DEL) */\n    reactor_deregister(r, conn->fd);\n    /* 4. Free write buffer */\n    wbuf_free(&conn->wbuf);\n    /* 5. Close the file descriptor */\n    close(conn->fd);\n    conn->fd = -1;\n    /* 6. Free the connection struct */\n    free(conn);\n}\n/*\n * http_idle_timeout_cb - Called by reactor when idle timer expires.\n *\n * A connection that hasn't sent data for IDLE_TIMEOUT_MS is closed.\n * This defends against:\n *   - Slow loris: clients that send partial headers slowly\n *   - Zombie connections: TCP connections where the client crashed\n *   - Resource exhaustion: fd accumulation from idle keep-alive connections\n */\nstatic void http_idle_timeout_cb(reactor *r, void *user_data) {\n    http_conn *conn = (http_conn *)user_data;\n    conn->timer_id  = -1;  /* timer has fired; don't try to cancel it */\n    /* Defer the close to ensure we're not in the middle of I/O dispatch */\n    reactor_defer(r, http_conn_close_deferred, conn);\n}\n```\n> **Why `conn->fd = -1` as the guard instead of a boolean?** Using the fd itself as the \"alive\" indicator eliminates one field. A valid fd is always â‰¥ 0 (0, 1, 2 are stdin/stdout/stderr; sockets start at 3 or higher). Setting `conn->fd = -1` is unambiguous \"this connection is dead,\" and the guard `if (conn->fd < 0) return` catches all double-close attempts. This pattern appears throughout production C codeâ€”libuv marks closed handles with `UV__HANDLE_CLOSING`, NGINX sets `c->fd = -1` on close.\n---\n## Wiring It All Together: The Accept Path\n```c\n/*\n * http_accept_cb - Reactor callback for the listening socket.\n *\n * Accepts all pending connections (ET discipline: drain until EAGAIN).\n * Allocates http_conn, registers with reactor, sets idle timer.\n */\nstatic void http_accept_cb(int listen_fd, uint32_t events, void *user_data) {\n    reactor *r = (reactor *)user_data;\n    (void)events;\n    for (;;) {\n        int fd = accept4(listen_fd, NULL, NULL, SOCK_NONBLOCK | SOCK_CLOEXEC);\n        if (fd == -1) {\n            if (errno == EAGAIN || errno == EWOULDBLOCK) break;\n            perror(\"accept4\");\n            break;\n        }\n        http_conn *conn = calloc(1, sizeof(http_conn));\n        if (!conn) {\n            fprintf(stderr, \"OOM: dropping connection fd=%d\\n\", fd);\n            close(fd);\n            continue;\n        }\n        conn->fd          = fd;\n        conn->timer_id    = -1;\n        conn->state       = HTTP_READING_HEADERS;\n        conn->reactor_ref = r;\n        wbuf_init(&conn->wbuf);\n        memset(&conn->req, 0, sizeof(conn->req));\n        /* Register with reactor for read events, ET mode */\n        if (reactor_register(r, fd, REACTOR_READABLE,\n                             http_on_readable, conn) != 0) {\n            perror(\"reactor_register\");\n            free(conn);\n            close(fd);\n            continue;\n        }\n        /* Set initial idle timeout */\n        conn->timer_id = reactor_set_timeout(r, IDLE_TIMEOUT_MS,\n                                              http_idle_timeout_cb, conn);\n    }\n}\nint main(void) {\n    reactor *r = reactor_create();\n    if (!r) { perror(\"reactor_create\"); return 1; }\n    int listen_fd = create_listening_socket();  /* from M1 */\n    if (listen_fd < 0) { reactor_destroy(r); return 1; }\n    /* Register listening socket */\n    if (reactor_register(r, listen_fd, REACTOR_READABLE,\n                         http_accept_cb, r) != 0) {\n        perror(\"reactor_register listen\");\n        close(listen_fd);\n        reactor_destroy(r);\n        return 1;\n    }\n    printf(\"HTTP server on port 8080, serving files from %s\\n\", STATIC_DIR);\n    printf(\"ulimit -n: check with 'ulimit -n' â€” must be > 10000 for C10K\\n\");\n    reactor_run(r);\n    close(listen_fd);\n    reactor_destroy(r);\n    return 0;\n}\n```\n---\n## Preparing for C10K: System Configuration\nBefore benchmarking, the operating system itself needs configuration. A stock Linux system limits file descriptors to 1,024 per processâ€”you'll hit this wall at connection 1,025. These limits exist to protect against runaway processes; override them deliberately:\n```bash\n# Check current limits\nulimit -n           # soft limit (typically 1024)\nulimit -Hn          # hard limit (typically 1048576 on modern systems)\n# Raise soft limit to 65536 for this session\nulimit -n 65536\n# Permanent increase: add to /etc/security/limits.conf\n# *    soft    nofile    65536\n# *    hard    nofile    65536\n# Kernel-level maximum (requires root)\nsysctl -w fs.file-max=200000\n# TCP tuning for high connection counts\nsysctl -w net.core.somaxconn=65535          # listen() backlog\nsysctl -w net.ipv4.tcp_max_syn_backlog=65535\nsysctl -w net.core.netdev_max_backlog=5000\nsysctl -w net.ipv4.tcp_tw_reuse=1           # reuse TIME_WAIT sockets\nsysctl -w net.ipv4.ip_local_port_range=\"1024 65535\"  # client port range\n# Verify your server's actual fd limit\ncat /proc/$(pgrep http_server)/limits | grep 'open files'\n```\n> **`net.core.somaxconn`**: This controls the maximum length of the kernel's queue of fully-established TCP connections waiting for `accept()`. If your server can't call `accept()` fast enough (e.g., if it's doing expensive work), this queue fills. When full, new connection attempts are silently dropped. Set it high (65535) and ensure your accept loop drains it quicklyâ€”which your ET accept loop does.\n---\n## Benchmarking: Verifying C10K\n\n![C10K Benchmark Setup and Expected Results](./diagrams/diag-m4-c10k-benchmark-architecture.svg)\n\n```bash\n# Install wrk (HTTP benchmark tool with Lua scripting support)\napt-get install wrk  # or build from source: github.com/wg/wrk\n# Create a static file to serve\nmkdir -p public\ndd if=/dev/urandom bs=1024 count=1 | base64 > public/test.html\n# Creates a ~1.3 KB HTML file (base64 encoding expands binary)\n# Compile with optimizations\ngcc -O2 -Wall -Wextra -o http_server http_server.c\n./http_server &\n# Basic benchmark: 100 connections, 12 threads, 10 seconds\nwrk -t12 -c100 -d10s http://localhost:8080/test.html\n# C10K test: 10,000 connections, 12 threads, 30 seconds\nwrk -t12 -c10000 -d30s http://localhost:8080/test.html\n# Expected output at C10K:\n# Running 30s test @ http://localhost:8080/test.html\n#   12 threads and 10000 connections\n#   Thread Stats   Avg      Stdev     Max   +/- Stdev\n#     Latency     2.14ms   18.73ms 521.41ms  99.33%\n#     Req/Sec     8.23k     2.14k   15.89k   70.00%\n#   2,468,231 requests in 30.10s, 3.38GB read\n# Requests/sec: 82,000\n# Latency (p99): < 100ms â† the target\n# Measure latency percentiles explicitly\nwrk -t12 -c10000 -d30s --latency http://localhost:8080/test.html\n```\nIf your p99 latency exceeds 100ms, these are the usual culprits:\n```bash\n# Check for file descriptor exhaustion\ncat /proc/$(pgrep http_server)/fd | wc -l   # current open fds\nss -s                                         # socket statistics\n# Check for CPU bottleneck (should be < 100% for single-threaded)\ntop -p $(pgrep http_server)\n# Check for kernel TCP queue drops (should be 0)\nnetstat -s | grep -i 'drop\\|overflow\\|fail'\n# Profile hot paths with perf\nperf stat -p $(pgrep http_server) -- sleep 10\nperf top -p $(pgrep http_server)\n```\nThe most common performance cliff at C10K: the Linux kernel's TCP accept backlog filled because the accept loop ran too slowly. Increase `net.core.somaxconn` and verify with `ss -lnt` (look at the Recv-Q column for the listening socket; it should stay near 0).\n---\n## The Slow Loris: Understanding the Attack You've Already Defended Against\n\n![Slow Loris Attack and Defense Mechanisms](./diagrams/diag-m4-slow-loris-attack-defense.svg)\n\nNow that you've built an incremental HTTP parser, you can understand the **slow loris attack** at a mechanistic levelâ€”not just as a description, but as a consequence of the exact code you wrote.\nYour parser accumulates bytes in `read_buf` until `find_header_end` finds `\\r\\n\\r\\n`. The parsed request's state machine stays in `HTTP_READING_HEADERS` until that happens. The connection holds `sizeof(http_conn)` â‰ˆ 17 KB of memory throughout.\nA slow loris client sends one byte of an HTTP request every 25 seconds. Your parser never finds `\\r\\n\\r\\n`. The connection stays open, consuming memory, with its idle timer reset each time the byte arrives. Against a server without idle timeouts, a single slow loris client with 1,000 connections can hold 17 MB of server memory indefinitely, and each of those connections consumes a file descriptorâ€”eventually exhausting the fd limit and making the server unable to accept legitimate connections.\nYour defense is already in place: `IDLE_TIMEOUT_MS = 30000`. A connection that sends one byte every 25 seconds will reset the timer each time, but a connection that sends nothing for 30 seconds will be closed. Against a more sophisticated slow loris that sends exactly one byte every 29 seconds, you'd add a secondary defense: a maximum time-to-first-complete-request (separate from idle timeout), which limits how long the header accumulation state can last regardless of activity.\n```c\n/* Secondary defense: maximum header accumulation time */\n#define MAX_HEADER_TIME_MS  60000  /* 60 seconds maximum to send complete headers */\n/* In http_accept_cb, set TWO timers: */\nconn->idle_timer_id    = reactor_set_timeout(r, IDLE_TIMEOUT_MS, http_idle_timeout_cb, conn);\nconn->header_timer_id  = reactor_set_timeout(r, MAX_HEADER_TIME_MS, http_header_timeout_cb, conn);\n/* Cancel header_timer_id in http_process_request once headers complete */\n```\n---\n## The Three-Level View: One HTTP Request\nLet's trace a complete HTTP GET request from the moment the NIC receives the TCP segment to the moment your `http_process_request` is called.\n**Level 3 â€” Hardware**: A TCP segment carrying `GET /test.html HTTP/1.1\\r\\nHost: bench\\r\\n\\r\\n` arrives at the NIC. The NIC's DMA engine writes the payload into a kernel ring buffer (the NIC's RX ring) without CPU involvement. The NIC signals the CPU via an interrupt (or the kernel polls with NAPI to reduce interrupt overhead at high packet rates). The hardware interrupt fires.\n**Level 2 â€” OS/Kernel**: The interrupt handler runs in interrupt context (non-preemptible, cannot sleep). It dequeues the packet from the NIC's RX ring, runs it through the network stack (`net/ipv4/tcp_input.c`): TCP checksum verification, sequence number validation, segment reassembly if fragmented. Reassembled data is placed into the socket's receive buffer (`sk->sk_receive_queue`). The socket's readiness callback firesâ€”`sock_def_readable`â€”which wakes the epoll subsystem. The `epitem` for this fd moves from the wait queue to `rdllist`. At some point, your process (sleeping in `epoll_wait`) is scheduled by the kernel's CFS (Completely Fair Scheduler). The kernel copies the ready event from `rdllist` into your user-space `events[]` array via `copy_to_user`. `epoll_wait` returns.\n**Level 1 â€” Application**: Your `reactor_run` loop reads `n_ready = 1`. It retrieves `fd_handler *h = events[0].data.ptr`. It calls `h->callback(fd, REACTOR_READABLE, h->user_data)`. That's `http_on_readable`. Inside, `read(fd, conn->read_buf + conn->read_len, space)` copies bytes from kernel socket buffer to user space (another `copy_to_user` in reverseâ€”`copy_to_user` from kernel's perspective, data flows from kernel to your process). `http_parse_headers` scans the buffer, finds `\\r\\n\\r\\n`, populates `conn->req`. `http_process_request` opens `/public/test.html`, reads it, writes headers and body to `conn->wbuf`. On the next `write()` call, bytes flow from `conn->wbuf` back into the kernel's socket send buffer. The TCP stack segments them, queues DMA descriptors to the NIC's TX ring, and the NIC sends them on the wire.\nTotal latency from packet arrival to response queued for sending: roughly **50â€“200 Âµs** on a modern server at low load. The dominant costs are the interrupt handling and scheduling latency (~10â€“30 Âµs), the two `memcpy` operations (kernelâ†’receive buffer and receive bufferâ†’socket send buffer, each ~1â€“5 Âµs for KB-sized payloads), and the file `read()` call (~5â€“20 Âµs for a cached file from page cache).\n---\n## Hardware Soul: What Limits Your Throughput\nAt 10,000 concurrent connections with a 1.3 KB response file, what are the hardware bottlenecks?\n**Memory bandwidth**: Each request involves reading ~17 KB of `http_conn` state (cold connections cache-miss) plus the file data from page cache. At 80,000 requests/second and 17 KB per connection access, that's 1.36 GB/s of memory readsâ€”well within a modern CPU's 40â€“80 GB/s memory bandwidth. Memory is not the bottleneck here.\n**Cache pressure**: Your 10,000 active connections occupy 10,000 Ã— 17 KB = 170 MB of heap memory. L3 cache is typically 8â€“32 MB. Most `http_conn` structures are cold in cache; accessing one for the first time costs an L3 miss (~40 cycles). Under heavy load where the same connections are active repeatedly, the working set shrinks to recently-active connections and the cache hit rate improves. The per-connection state size is therefore a real performance dialâ€”halving it (8 KB instead of 16 KB for the read buffer) approximately doubles the number of \"warm\" connections that fit in L3.\n**System call overhead**: Each request involves `epoll_wait` (1 syscall), `read` (1 syscall), `stat` (1 syscall), `open` (1 syscall), `read` (file, possibly multiple syscalls), `write` (1+ syscalls). At 80,000 req/s, that's roughly 480,000 syscalls/second. Each syscall costs ~200 ns (context switch to kernel and back). At 480K syscalls/s: 96 ms of CPU time per second just in syscall overheadâ€”about 10% of one CPU core. This is measurable and motivates `sendfile()` (eliminates the read+write pair for static files) and io_uring (eliminates the per-syscall context switch overhead entirely).\n**Branch prediction**: The parser's `find_header_end` scan has a branch (the `\\r\\n\\r\\n` check) that's almost always not-taken until the very end of the headers. The branch predictor learns this quickly. The state machine transitions (`conn->state == HTTP_READING_HEADERS`) are nearly always predictable because connections spend much more time reading than transitioning.\n---\n## Knowledge Cascade: Five Connections to Carry Forward\n### 1. Protocol Buffers and gRPC Framing (Cross-Domain: Distributed Systems)\nYour incremental `\\r\\n\\r\\n` search is one specific solution to the **message framing problem**: given a byte stream, how do you know where one message ends and the next begins? HTTP headers use a text delimiter. Protocol Buffers over gRPC use **length-prefixed framing**: a 5-byte prefix (1 byte for compression flag, 4 bytes for message length in big-endian) precedes each message. The receiver must accumulate bytes until it has the 5-byte header, parse the length, then accumulate exactly that many more bytes.\nThe gRPC framing layer faces identical incremental parsing challenges: what if only 3 bytes of the 5-byte prefix have arrived? The receiver must buffer and wait for the remaining 2 bytes before it knows the message length. The state machine looks exactly like yoursâ€”`READING_FRAME_HEADER`, `READING_FRAME_BODY`, `PROCESSING`â€”with the same \"accumulate in a buffer, parse after each read, handle incomplete state\" discipline.\nThis is why gRPC requires HTTP/2 (not HTTP/1.1): HTTP/2's binary framing natively separates the transport layer from the RPC layer, making the framing problem explicit and well-specified. HTTP/1.1's text headers required every gRPC implementation to re-solve incremental parsing.\n### 2. Database Wire Protocols (Cross-Domain: Databases)\nPostgreSQL's wire protocol, MySQL's packet protocol, and Redis's RESP (REdis Serialization Protocol) all face the same incremental parsing problem you just solved. Redis's `processInlineBuffer` and `processMultibulkBuffer` functions in `networking.c` are direct analogs to your `http_parse_headers`. They accumulate bytes in `c->querybuf`, scan for command terminators (`\\r\\n` for inline, the RESP `*` bulk count prefix for multibulk), and return to the event loop when incomplete. Redis's `readQueryFromClient` is structurally identical to your `http_on_readable`.\nThe reason these protocols are state-machine-based is not incidentalâ€”it's a consequence of being built on top of the same TCP byte stream model you're working with. Any protocol that expects to run over a reliable byte-stream transport must solve incremental framing. This is one of the deepest patterns in distributed systems engineering.\n### 3. Zero-Copy I/O with `sendfile()`\nYour static file serving implementation reads the file into a user-space buffer, then writes that buffer to the socket. The data traverses memory twice:\n1. Kernel page cache â†’ user-space buffer (`read()`)\n2. User-space buffer â†’ kernel socket send buffer (`write()`)\nThe CPU touches every byte twice. For a 1 MB file at 10,000 requests/second, that's 20 GB/s of memory bandwidth wasted on unnecessary copies.\n`sendfile(out_fd, in_fd, offset, count)` is the Linux syscall that eliminates both copies. The kernel transfers data directly from the page cache to the socket send bufferâ€”no user-space involvement, no `malloc`, no buffer. The data never touches user space at all:\n```c\n/*\n * Zero-copy file serving with sendfile(2).\n *\n * sendfile moves data between two kernel-managed regions without\n * copying through user space. CPU usage for file serving drops\n * significantly; kernel NIC drivers may use DMA directly from\n * the page cache to the NIC's TX ring (hardware scatter-gather).\n *\n * Limitation: sendfile doesn't work with non-blocking sockets\n * cleanly â€” it may return EAGAIN if the socket buffer is full,\n * requiring the same EPOLLOUT + retry pattern as regular writes.\n */\nstatic int serve_file_sendfile(http_conn *conn, int file_fd, off_t file_size) {\n    off_t offset = 0;\n    while (offset < file_size) {\n        ssize_t sent = sendfile(conn->fd, file_fd, &offset, file_size - offset);\n        if (sent > 0) {\n            /* offset is updated by sendfile automatically */\n            continue;\n        }\n        if (sent == -1 && (errno == EAGAIN || errno == EWOULDBLOCK)) {\n            /* Socket buffer full. To do this correctly with the reactor,\n             * we'd need to store the file_fd and offset in conn state,\n             * register EPOLLOUT, and resume on EPOLLOUT firing.\n             * This is a meaningful extension exercise. */\n            return -1;\n        }\n        return -1;  /* error */\n    }\n    return 0;\n}\n```\nFor a complete production implementation, `sendfile` with the reactor requires storing the in-progress file transfer state (`file_fd`, `offset`, `remaining`) in `http_conn`, resuming on `EPOLLOUT`. `io_uring`'s `IORING_OP_SPLICE` does the same thing with the proactor modelâ€”submit the splice, get a completion when it's done, no EPOLLOUT management needed.\n### 4. HTTP/1.1 Head-of-Line Blocking and the Path to HTTP/2\nHTTP/1.1 with keep-alive serializes requests on a connection: request 2 must wait for response 1 to fully send before the client sends request 2. (HTTP pipelining, which lets clients send request 2 before receiving response 1, was standardized but rarely implemented correctly and almost never enabled in practice.) This is **head-of-line blocking**: a large, slow response to request 1 blocks all subsequent requests on that connection.\nHTTP/2 solves this with **stream multiplexing**: multiple requests are interleaved as numbered streams on a single connection. The server can send partial response 1, then partial response 2, then more of response 1â€”interleaved. A slow response to request 1 no longer blocks request 2.\nBut notice what that requires: the HTTP/2 framing layer must label each frame with its stream ID, and the receiver must reassemble frames into their respective streams. This is a much more complex state machine than the one you builtâ€”instead of one per-connection state machine, you need one per-stream state machine, multiplexed over one TCP connection. The incremental parsing challenge multiplies: you're not just accumulating headers across reads, you're demultiplexing frames across reads and reassembling per-stream state.\nBuilding HTTP/1.1's state machine gives you direct intuition for what HTTP/2 adds and why it's more complex. Head-of-line blocking is the exact limitation your `http_finalize_response` â†’ `HTTP_READING_HEADERS` cycle creates.\n### 5. The Slow Loris at Protocol Level\nUnderstanding slow loris reveals a deeper principle: **every protocol that accumulates state before processing is vulnerable to resource exhaustion attacks**. Your HTTP parser accumulates `http_conn` memory for the duration of header parsing. A slow loris exploits this accumulation window.\nThe general defense patternâ€”idle timeouts, maximum accumulation size, maximum accumulation timeâ€”applies everywhere:\n- PostgreSQL: `client_connection_check_interval`, `statement_timeout`\n- Redis: `timeout` configuration for idle clients\n- gRPC: `keepalive_timeout`, `max_connection_idle`\n- NGINX: `client_header_timeout`, `client_body_timeout`\nThese aren't configuration knobs added as afterthoughts. They're the engineering response to the exact resource accumulation pattern you've implemented. Every production protocol server has them. Now you know why.\n---\n## Pitfall Reference: The Six Ways This Breaks\n**Pitfall 1: Expecting complete headers in a single `read()` call**\n*Symptom*: Works perfectly on localhost, fails intermittently in production or under wrk load test. Requests over ~1400 bytes (MTU) fail at the 95th percentile.\n*Fix*: Always accumulate into a buffer and call the parser after each `read()`. Never assume `read()` returns complete headers.\n**Pitfall 2: Write buffer growing unboundedly for slow clients**\n*Symptom*: Server RSS grows steadily under load; eventually OOM-killed or exhausts heap.\n*Fix*: Check `wbuf_append` return value; if -1 (buffer exceeded `WRITE_BUF_MAX`), close the connection immediately. Log when this happensâ€”it indicates slow clients or network issues.\n**Pitfall 3: Keep-alive without resetting the read buffer**\n*Symptom*: Second request on a keep-alive connection fails to parse or gets garbage data mixed in.\n*Fix*: `http_conn_reset_for_keepalive` must zero `read_len` and `memset` the `req` struct. Do not skip either step.\n**Pitfall 4: Path traversal vulnerability**\n*Symptom*: `GET /../../../etc/passwd` serves `/etc/passwd`. Server leaks arbitrary files.\n*Fix*: `build_safe_path` must reject any path containing `..`. Apply this check before any file system access.\n**Pitfall 5: Closing connection directly from within a callback**\n*Symptom*: Occasional segfault or data sent to wrong client after high-churn periods.\n*Fix*: Always use `reactor_defer(r, http_conn_close_deferred, conn)`. Never call `close(conn->fd)` directly from within `http_on_readable` or `http_on_writable`. This is the core lesson from Milestone 3's zombie flag mechanism.\n**Pitfall 6: Not benchmarking with real file descriptors**\n*Symptom*: Server appears healthy in initial testing; crashes or times out when wrk uses 10,000 connections.\n*Fix*: Run `ulimit -n 65536` before starting the server. Add `assert(fd < MAX_FDS)` in the accept callback. Monitor `cat /proc/PID/limits` during benchmark.\n---\n<!-- END_MS -->\n\n\n\n\n# TDD\n\nA bottom-up implementation journey that transforms raw Linux syscalls into a production-grade HTTP/1.1 server capable of 10K+ concurrent connections. Each milestone builds a verifiable artifactâ€”echo server, timer-driven reaper, reactor library, benchmarked HTTP serverâ€”while revealing why naive approaches fail under load. The architecture mirrors NGINX, Redis, and Node.js's libuv at the structural level, making every design decision legible through the lens of hardware constraints: cache line behavior, TLB pressure, branch prediction, and DMA-driven NIC I/O.\n\n\n\n<!-- TDD_MOD_ID: build-event-loop-m1 -->\n# MODULE CHARTER: epoll Basics: Level-Triggered and Edge-Triggered\n\nThis module establishes the foundational I/O multiplexing layer for the entire server architecture. It focuses on the transition from blocking, thread-per-connection models to a single-threaded event loop using the Linux `epoll` facility. The primary objective is to implement a robust echo server that correctly handles both Level-Triggered (LT) and Edge-Triggered (ET) semantics. This module does NOT implement write buffering, timers, or application-layer protocols (HTTP); those are deferred to subsequent milestones. It enforces the invariant that all monitored file descriptors must be non-blocking and that the ET loop must drain the kernel receive buffer to `EAGAIN` to prevent data-loss deadlocks.\n\n# FILE STRUCTURE\n\n1. `reactor_core.h`: Common definitions, constants, and the per-connection state structure.\n2. `reactor_core.c`: Core utilities for `epoll` manipulation and non-blocking configuration.\n3. `echo_server.c`: Main entry point containing the LT and ET loop implementations and the socket acceptance logic.\n4. `Makefile`: Build instructions with `-O2` and `-Wall -Wextra` flags.\n\n# COMPLETE DATA MODEL\n\n### `conn_state_t` (Per-Connection State)\nThe server maintains a global array of `conn_state_t` structures, indexed by the file descriptor (FD) integer value. This provides $O(1)$ lookup and avoids the overhead of a hash map.\n\n| Field | Type | Offset (64-bit) | Size | Purpose |\n| :--- | :--- | :--- | :--- | :--- |\n| `read_buf` | `char[4096]` | 0x0000 | 4096 | Accumulates raw bytes from `read()` calls. Matches page size. |\n| `read_len` | `uint32_t` | 0x1000 | 4 | Number of active bytes in `read_buf`. |\n| `fd` | `int` | 0x1004 | 4 | The underlying file descriptor. |\n| `is_active` | `bool` | 0x1008 | 1 | Flag indicating if this slot is currently in use. |\n| `padding` | `uint8_t[7]` | 0x1009 | 7 | Alignment padding to maintain 64-bit boundaries. |\n| **Total Size** | | | **4112 bytes** | |\n\n**Memory & Cache Analysis:**\n- **Cache Alignment:** The `read_buf` starts at offset 0, ensuring the first chunk of data aligns with L1 cache lines (64 bytes).\n- **Resident Set Size (RSS):** For 10,000 connections, this array consumes ~41 MB. Because the array is allocated globally, the kernel uses demand-paging; memory is only physically mapped when a specific FD index is touched.\n- **Cache Locality:** When the event loop receives a batch of ready FDs, it accesses the `conn_state_t` array. If FDs are assigned sequentially by the kernel, these accesses exhibit high spatial locality.\n\n\n![Thread-per-Connection vs Single-Thread epoll: Stack Memory and Context Switch Cost](./diagrams/tdd-diag-1.svg)\n\n\n# INTERFACE CONTRACTS\n\n### 1. `int set_nonblocking(int fd)`\n- **Purpose**: Configures an FD for non-blocking I/O.\n- **Arguments**: `fd` (The target file descriptor).\n- **Operation**: Calls `fcntl(fd, F_GETFL)` to retrieve current flags, then `fcntl(fd, F_SETFL, flags | O_NONBLOCK)`.\n- **Return**: `0` on success, `-1` on error (sets `errno`).\n- **Invariant**: Must never clear existing flags (e.g., `O_APPEND`).\n\n### 2. `int reactor_add(int epoll_fd, int fd, uint32_t events)`\n- **Purpose**: Registers a new FD into the kernel interest list.\n- **Arguments**: `epoll_fd` (The epoll instance), `fd` (The target FD), `events` (Bitmask like `EPOLLIN | EPOLLET`).\n- **Return**: `0` on success, `-1` on error.\n- **Side Effect**: Populates `struct epoll_event.data.fd` for retrieval during `epoll_wait`.\n\n### 3. `void conn_init(int fd)`\n- **Purpose**: Initializes the `conn_state_t` entry in the global array.\n- **Return**: None.\n- **Constraint**: Must be called immediately after `accept4()` succeeds.\n\n### 4. `void conn_close(int epoll_fd, int fd)`\n- **Purpose**: Cleans up resources for a terminating connection.\n- **Operation**: Removes FD from epoll via `EPOLL_CTL_DEL`, calls `close(fd)`, and marks `is_active = false`.\n- **Constraint**: Must handle cases where FD might have already been closed.\n\n# ALGORITHM SPECIFICATION\n\n### Level-Triggered (LT) Loop Logic\n1. Call `epoll_wait(epoll_fd, events, MAX_EVENTS, -1)`.\n2. For each ready event:\n    a. If `fd == listen_fd`, call `accept4(listen_fd, ...)` once.\n    b. If `ev & EPOLLIN`, call `read(fd, buf, 4096)`.\n    c. If `read > 0`, immediately call `write(fd, buf, read)`.\n    d. If `read == 0` or `read < 0` (and not `EAGAIN`), call `conn_close`.\n3. **Note**: In LT mode, the kernel re-notifies if data remains in the socket buffer. A single `read()` call per iteration is functional but less efficient than a loop.\n\n### Edge-Triggered (ET) Loop Logic\n1. Call `epoll_wait(epoll_fd, events, MAX_EVENTS, -1)`.\n2. For each ready event:\n    a. If `fd == listen_fd`, **LOOP** `accept4` until it returns `-1` with `errno == EAGAIN`.\n    b. If `ev & EPOLLIN`:\n        i. **LOOP** `read(fd, buf, 4096)`:\n            - If `read > 0`: `write(fd, buf, read)`.\n            - If `read == 0`: `conn_close` and `break` loop.\n            - If `read < 0`:\n                - If `errno == EAGAIN` or `EWOULDBLOCK`: **Break loop** (buffer drained).\n                - Otherwise: `conn_close` and `break` loop.\n3. **Invariant**: Failure to drain to `EAGAIN` in ET mode will result in a connection stall if the client stops sending data but the server hasn't finished reading the previous burst.\n\n\n![epoll Syscall Sequence: epoll_create1 â†’ epoll_ctl ADD â†’ epoll_wait â†’ epoll_ctl DEL](./diagrams/tdd-diag-2.svg)\n\n\n# HARDWARE SOUL: SYSCALLS AND PIPELINES\n\n### 1. The Cost of `epoll_wait`\nWhen `epoll_wait` is called, the CPU transitions from Ring 3 (User) to Ring 0 (Kernel).\n- **TLB Pressure**: The kernel must access its internal `eventpoll` data structures. Modern CPUs use the PCID (Process-Context Identifier) to avoid flushing the TLB, but the context switch still incurs a ~200ns overhead.\n- **The Ready List**: Linux maintains a doubly-linked list (`rdllist`) of ready FDs. `epoll_wait` simply copies the contents of this list to the user-supplied `events[]` array. This is $O(k)$ where $k$ is the number of ready FDs, making it highly scalable.\n\n### 2. Branch Prediction in the ET Loop\nThe `while(1)` loop in ET mode contains a branch: `if (n < 0 && (errno == EAGAIN || errno == EWOULDBLOCK))`.\n- **Prediction**: During high-throughput bursts, this branch is predicted \"not taken\" by the CPU's Branch Target Buffer (BTB) because most `read()` calls return data.\n- **Misprediction Cost**: When the buffer finally empties, the CPU mispredicts the `EAGAIN` exit. This costs ~15-20 cycles. However, this is significantly cheaper than the overhead of a redundant `epoll_wait` call that LT would require to discover the same state.\n\n### 3. SIMD Opportunities\nWhile not implemented in M1, the `read_buf` is sized at 4KB (64 cache lines). This prepares the memory layout for future vectorization (e.g., using AVX-512 to scan for protocol delimiters) by ensuring the buffer is large enough and potentially aligned to 64-byte boundaries.\n\n# ERROR HANDLING MATRIX\n\n| Error | Detected By | Recovery Action | User-Visible? |\n| :--- | :--- | :--- | :--- |\n| `EAGAIN` / `EWOULDBLOCK` | `read()` / `write()` | Stop loop, return to `epoll_wait`. This is the \"normal\" path for non-blocking. | No |\n| `ECONNRESET` | `read()` / `write()` | Call `conn_close()`. Connection was forcibly closed by peer. | No |\n| `EMFILE` | `accept4()` | Log \"Out of FDs\". Stop accepting connections temporarily. | No (Server log only) |\n| `EINTR` | `epoll_wait()` | `continue` the main loop immediately. | No |\n| `EBADF` | `epoll_ctl()` | Internal logic error. Log error and abort or skip connection. | No |\n\n# IMPLEMENTATION SEQUENCE\n\n### Phase 1: Socket & Non-blocking Helpers (1.5 Hours)\n- Implement `set_nonblocking`.\n- Implement `create_listening_socket` (socket, bind, listen).\n- Use `SO_REUSEADDR` to avoid `TIME_WAIT` rebind failures.\n- **Checkpoint**: Compile a small tool that opens a socket, sets it non-blocking, and verifies with `fcntl(F_GETFL)`.\n\n### Phase 2: LT Event Loop (3 Hours)\n- Implement `conn_state_t` array management.\n- Implement `epoll_create1(EPOLL_CLOEXEC)`.\n- Implement the LT loop: single `accept`, single `read`/`write`.\n- **Checkpoint**: Run server. Connect with `nc localhost 8080`. Verify echo works. Use `strace` to confirm `epoll_wait` returns for every chunk of data.\n\n### Phase 3: ET Event Loop & Drain (3 Hours)\n- Add `EPOLLET` to the `epoll_ctl` registration.\n- Implement the \"Drain until EAGAIN\" loops for both `accept` and `read`.\n- Implement the CLI switch (e.g., `./server --mode=et`).\n- **Checkpoint**: Use a Python script to send 10KB of data in one burst. Verify that in ET mode, one `epoll_wait` wakeup triggers multiple `read()` calls until `EAGAIN`.\n\n# TEST SPECIFICATION\n\n### 1. Functional Echo Test (Happy Path)\n- **Input**: `echo \"Hello\" | nc -q 1 localhost 8080`\n- **Output**: Server logs \"Read 6 bytes\", client receives \"Hello\".\n- **Success Criteria**: Data received matches data sent.\n\n### 2. The ET \"Stall\" Test (Edge Case)\n- **Input**: Server in ET mode. Force the `read()` call to only read 2 bytes then return to `epoll_wait` (manual code hack). Send \"LongString\".\n- **Failure**: Client hangs; server never reads the rest of the string.\n- **Fix**: Re-enable the loop-until-EAGAIN.\n- **Success Criteria**: Server reads the entire string in one event trigger.\n\n### 3. Thundering Herd / Burst Accept\n- **Input**: Use `ab -n 100 -c 10 http://localhost:8080/` (even though not HTTP, the TCP handshake will trigger accepts).\n- **Success Criteria**: All 100 connections accepted; no `ECONNREFUSED`.\n\n# PERFORMANCE TARGETS\n\n| Operation | Target | Measurement Method |\n| :--- | :--- | :--- |\n| Connection Latency | < 500Î¼s | `ping` local port vs `ping` loopback overhead |\n| Syscall Ratio | 1:1 `epoll_wait` to Read (LT) | `strace -c` |\n| Throughput | 100k+ ops/sec | `tcp-echo-bench` or custom script |\n| Memory Footprint | ~45MB RSS (10k conns) | `ps -o rss` |\n\n# CONCURRENCY SPECIFICATION\n\n- **Model**: Single-threaded Reactor.\n- **Thread Safety**: None required.\n- **Re-entrancy**: The `conn_close` function must be re-entrant safe (or idempotent) in case multiple events (e.g., `EPOLLIN` and `EPOLLHUP`) trigger in the same batch for the same FD.\n\n```c\n/* Pseudocode for the ET read loop */\nvoid handle_read_et(int fd) {\n    conn_state_t *state = &global_connections[fd];\n    while (1) {\n        ssize_t n = read(fd, state->read_buf, 4096);\n        if (n < 0) {\n            if (errno == EAGAIN || errno == EWOULDBLOCK) break; // Drained\n            conn_close(epoll_fd, fd); break; // Error\n        }\n        if (n == 0) { conn_close(epoll_fd, fd); break; } // EOF\n        write(fd, state->read_buf, n); // Echo\n    }\n}\n```\n<!-- END_TDD_MOD -->\n\n\n<!-- TDD_MOD_ID: build-event-loop-m2 -->\n# MODULE CHARTER: Write Buffering and Timer Management\n\nThis module extends the basic `epoll` event loop from Milestone 1 to handle two critical real-world constraints: asynchronous write backpressure and connection lifecycle management. In high-concurrency environments, a `write()` call may return `EAGAIN` if the kernel's socket send buffer is full; this module implements a per-connection dynamic write queue and manages the `EPOLLOUT` lifecycle to flush data only when the socket becomes writable, preventing both data loss and CPU-spinning busy loops. Additionally, it integrates a high-performance min-heap timer system to reap idle connections, utilizing the `epoll_wait` timeout parameter to create a precision tick-less event loop. This module does not yet abstract the reactor API but provides the internal logic necessary for the protocol-aware server in M4.\n\n# FILE STRUCTURE\n\n1. `write_buffer.h`: Definitions for the dynamic write queue.\n2. `write_buffer.c`: Implementation of append, consume, and compaction logic.\n3. `timer_heap.h`: Min-heap structures and priority queue logic.\n4. `timer_heap.c`: Heap sift-up/down, insertion, and cancellation.\n5. `reactor_core.h`: Updated `conn_state_t` and global context.\n6. `main.c`: Updated event loop with write-flush logic and timer integration.\n7. `Makefile`: Build script with updated object dependencies.\n\n# COMPLETE DATA MODEL\n\n### `write_buf_t` (Per-Connection Output Queue)\nLocated within each `conn_state_t`. Manages bytes that cannot be sent immediately.\n\n| Field | Type | Offset | Size | Purpose |\n| :--- | :--- | :--- | :--- | :--- |\n| `data` | `char*` | 0x00 | 8 | Heap-allocated buffer for unsent bytes. |\n| `len` | `uint32_t` | 0x08 | 4 | Current number of buffered bytes. |\n| `cap` | `uint32_t` | 0x0C | 4 | Total allocated capacity of `data`. |\n| `offset` | `uint32_t` | 0x10 | 4 | Index of the first unsent byte (drain point). |\n| `padding` | `uint8_t[4]` | 0x14 | 4 | Padding for 8-byte alignment of the next struct. |\n| **Total** | | | **24 bytes** | |\n\n### `timer_entry_t` (Heap Node)\nRepresents a scheduled timeout.\n\n| Field | Type | Offset | Size | Purpose |\n| :--- | :--- | :--- | :--- | :--- |\n| `expiry_ms` | `uint64_t` | 0x00 | 8 | Absolute monotonic time (ms) when timer fires. |\n| `fd` | `int` | 0x08 | 4 | The FD associated with this timer. |\n| `padding` | `uint8_t[4]` | 0x0C | 4 | Alignment. |\n| **Total** | | | **16 bytes** | |\n\n### `conn_state_t` (Updated)\nThe per-connection state is expanded to track write interest and timer positions.\n\n| Field | Type | Offset | Size | Purpose |\n| :--- | :--- | :--- | :--- | :--- |\n| `read_buf` | `char[4096]` | 0x0000 | 4096 | Milestone 1 Read Buffer. |\n| `wbuf` | `write_buf_t` | 0x1000 | 24 | The write queue defined above. |\n| `read_len` | `uint32_t` | 0x1018 | 4 | Current read count. |\n| `fd` | `int` | 0x101C | 4 | File descriptor. |\n| `epollout_armed` | `bool` | 0x1020 | 1 | Guard: is `EPOLLOUT` registered in the kernel? |\n| `is_active` | `bool` | 0x1021 | 1 | Liveness flag. |\n| `timer_idx` | `int` | 0x1024 | 4 | Current index in `timer_heap[]` (for O(1) cancel). |\n| `timer_expiry` | `uint64_t` | 0x1028 | 8 | Absolute expiry time. |\n| **Total** | | | **~4152 bytes** | |\n\n\n![write_buf Struct: Byte-Level Memory Layout and Compaction Mechanics](./diagrams/tdd-diag-8.svg)\n\n\n# INTERFACE CONTRACTS\n\n### 1. `int wbuf_append(write_buf_t *wb, const char *src, uint32_t n)`\n- **Invariants**: `wb->len + n` must not exceed `WRITE_BUF_MAX` (256KB).\n- **Behavior**: If `wb->offset` is large (e.g., > `cap/2`), perform `memmove` to compact data to the front. If `cap` is insufficient, double `cap` via `realloc`.\n- **Errors**: Return `-1` on OOM or buffer overflow (indicates slow client).\n\n### 2. `int conn_write(int epoll_fd, int fd, const char *src, uint32_t n)`\n- **Constraints**: Must attempt a direct `write()` first if `wbuf` is empty.\n- **Backpressure**: If `write()` returns `EAGAIN`, call `wbuf_append()` and use `epoll_ctl(MOD)` to add `EPOLLOUT`.\n- **State Management**: Update `epollout_armed` to `true`.\n\n### 3. `int conn_flush(int epoll_fd, int fd)`\n- **Constraints**: Triggered by `EPOLLOUT`.\n- **Behavior**: Write as much of `wbuf` as possible. Update `wb->offset` and `wb->len`.\n- **Termination**: If `wbuf` becomes empty, use `epoll_ctl(MOD)` to remove `EPOLLOUT`. Update `epollout_armed` to `false`.\n\n### 4. `void timer_set(int fd, uint64_t ms_from_now)`\n- **Logic**: If `conn->timer_idx != -1`, update existing node and sift. Otherwise, append to heap and `sift_up`.\n- **Complexity**: $O(\\log N)$.\n\n### 5. `int timer_next_ms()`\n- **Logic**: Peek `timer_heap[0]`. Calculate `expiry - now()`.\n- **Returns**: Milliseconds for `epoll_wait` timeout, or `-1` if heap empty.\n\n# ALGORITHM SPECIFICATION\n\n### Write Buffer Compaction and Growth\nTo maintain $O(1)$ amortized performance and avoid memory fragmentation:\n1. **Compaction**: When `wbuf->offset > wbuf->cap / 2`, move `wbuf->data + wbuf->offset` to `wbuf->data` using `memmove`. Reset `offset = 0`. This prevents the \"creeping offset\" that leads to unnecessary allocations.\n2. **Growth**: If `n > free_space`, `new_cap = max(cap * 2, len + n)`. Caps at `WRITE_BUF_MAX`.\n\n### Min-Heap Sift-Down (Deletion/Update)\nUsed when the root timer expires or an arbitrary timer is cancelled via `timer_idx`.\n1. Replace the target node with the last node in the heap.\n2. Update the `timer_idx` in the `conn_state_t` of the moved node.\n3. Compare the moved node with its children.\n4. If larger than the smallest child, swap and repeat.\n5. If smaller than the parent (relevant for arbitrary cancel), call `sift_up`.\n\n{{DIAGRAM:tdd-diag-9}}\n\n# ERROR HANDLING MATRIX\n\n| Error | Detected By | Recovery Action | User-Visible? |\n| :--- | :--- | :--- | :--- |\n| `WRITE_BUF_MAX` Hit | `wbuf_append` | Close connection immediately (slow loris defense). | No |\n| `realloc` Fail | `wbuf_append` | Close connection (OOM handling). | No |\n| `EPOLLOUT` spin | `epoll_wait` | If `wbuf_is_empty` but `EPOLLOUT` fires, disarm immediately. | No |\n| Backward Clock | `now_ms` | Use `CLOCK_MONOTONIC` to ensure time never flows backward. | No |\n| Heap Overflow | `timer_set` | Log error; close oldest connection to make room. | No |\n\n# IMPLEMENTATION SEQUENCE\n\n### Phase 1: The Byte Queue (2 Hours)\n- Implement `write_buf_t` lifecycle.\n- **Compaction logic**: Crucial to prevent `realloc` on every write.\n- **Checkpoint**: Unit test `wbuf_append` and `wbuf_consume` with a sequence of partial writes. Verify that `offset` resets and memory doesn't leak.\n\n### Phase 2: EPOLLOUT Lifecycle (2 Hours)\n- Modify `handle_read` to use `conn_write`.\n- Implement `conn_flush` to be called when `events[i].events & EPOLLOUT`.\n- **Crucial Invariant**: `epoll_ctl(MOD)` must be called to *remove* `EPOLLOUT` when the queue is empty, or `epoll_wait` will return immediately in a tight loop.\n- **Checkpoint**: Run server with a simulated slow client (`trickle -d 1`). Verify CPU remains at 0% while the server is waiting for the client to drain its buffer.\n\n### Phase 3: Monotonic Timing & Heap (3 Hours)\n- Implement `now_ms()` using `clock_gettime(CLOCK_MONOTONIC, ...)`.\n- Implement binary min-heap: `sift_up`, `sift_down`.\n- **FD Mapping**: Ensure `timer_heap[i].fd` allows you to update `connections[fd].timer_idx`.\n- **Checkpoint**: Insert 1000 random timers. Extract them one by one. Verify they are returned in strictly increasing chronological order.\n\n### Phase 4: Integrated Event Loop (2 Hours)\n- Calculate `epoll_wait` timeout using `timer_next_ms()`.\n- Call `timer_process_expired()` after `epoll_wait` returns.\n- **Re-entrancy**: If a timer expires and closes an FD, ensure subsequent I/O events for that FD in the same `epoll_wait` batch are ignored.\n- **Checkpoint**: Set `IDLE_TIMEOUT` to 5s. Connect with `nc`. Wait 6s. Verify server closes the connection automatically.\n\n# TEST SPECIFICATION\n\n### 1. The Slow Reader Test (Backpressure)\n- **Setup**: Start server. Use a python script to connect, send a request, but `recv()` only 1 byte per second.\n- **Execution**: Server should eventually trigger `EAGAIN` on `write()`, arm `EPOLLOUT`, and buffer bytes.\n- **Success**: Server memory stays bounded by `WRITE_BUF_MAX`. Connection is closed if buffer exceeds limit.\n\n### 2. The Busy Loop Test (Deregistration)\n- **Setup**: High-speed client sending many requests.\n- **Execution**: Monitor CPU usage with `top`.\n- **Success**: CPU usage drops to 0.0% when all responses are sent, even if connections remain open.\n\n### 3. Timer Stress Test\n- **Setup**: 10,000 connections. Set random idle timeouts between 1s and 10s.\n- **Success**: Connections are closed precisely at their expiry times (+/- 10ms jitter). Heap property remains valid throughout.\n\n# PERFORMANCE TARGETS\n\n| Operation | Target | Measurement Method |\n| :--- | :--- | :--- |\n| Timer Insert | < 1Î¼s | Micro-benchmark 10k inserts |\n| Syscall Overhead | 0 `epoll_ctl` calls if buffer not full | `strace -e epoll_ctl` |\n| Memory Overhead | < 1MB for Timer Heap (64k nodes) | `sizeof(timer_entry_t) * 65536` |\n| Clock Resolution | 1ms | `epoll_wait` timeout granularity |\n\n# SOUL SECTION: HARDWARE & KERNEL INTERACTIONS\n\n### 1. vDSO and `clock_gettime`\nWe use `CLOCK_MONOTONIC`. On modern Linux, this syscall is mapped into the process address space via **vDSO (virtual Dynamic Shared Object)**. This allows the process to read the hardware TSC (Time Stamp Counter) directly without a full context switch to the kernel. This reduces `now_ms()` cost from ~200ns to ~30ns.\n\n### 2. Cache Line Alignment of Heap Nodes\nThe `timer_entry_t` is 16 bytes. A standard 64-byte cache line holds exactly 4 nodes. \n- During `sift_up`, we access parent nodes at index `(i-1)/2`.\n- Because the heap is a complete binary tree, the top 3 levels (indices 0-6) fit in **two cache lines**. \n- This ensures that for almost every timer operation, the \"hot\" part of the priority queue is already in the L1/L2 cache.\n\n### 3. Write Buffer Compaction vs. Page Faults\nWe use `memmove` for compaction. For small `len`, this is a pure L1/L2 cache operation. However, we avoid `realloc` as much as possible because `realloc` might trigger the `mmap` syscall for large buffers, leading to page faults and TLB shootdowns across the CPU cores. The doubling strategy ensures we only pay the \"allocation tax\" $O(\\log N)$ times.\n\n### 4. TCP Send Buffer vs. `EPOLLOUT`\nThe kernel's `SO_SNDBUF` determines when `write()` returns `EAGAIN`. By default, this is tuned by the kernel (see `tcp_wmem`). When our `conn_flush` runs, the kernel initiates a DMA transfer from the kernel buffer to the NIC. Only after the NIC signals completion (or the TCP window opens) does the kernel free space and trigger `EPOLLOUT`. Our server effectively \"waits on the NIC\" without blocking the CPU.\n\n```c\n/* Implementation Detail: The Timer Heap Swap */\nstatic void heap_swap(int i, int j) {\n    timer_entry_t tmp = timer_heap[i];\n    timer_heap[i] = timer_heap[j];\n    timer_heap[j] = tmp;\n    \n    /* MANDATORY: Keep the FD -> Heap Index map in sync */\n    connections[timer_heap[i].fd].timer_idx = i;\n    connections[timer_heap[j].fd].timer_idx = j;\n}\n\n/* Implementation Detail: Write Backpressure Logic */\nint conn_write(int epoll_fd, int fd, const char *data, uint32_t n) {\n    conn_state_t *c = &connections[fd];\n    \n    // 1. If buffer already has data, we must append to maintain order\n    if (c->wbuf.len > 0) {\n        return wbuf_append(&c->wbuf, data, n);\n    }\n    \n    // 2. Fast path: try to send directly\n    ssize_t sent = write(fd, data, n);\n    if (sent < 0) {\n        if (errno == EAGAIN || errno == EWOULDBLOCK) {\n            sent = 0; // Prepare to buffer all\n        } else {\n            return -1; // Real error\n        }\n    }\n    \n    // 3. Buffer remaining\n    if ((uint32_t)sent < n) {\n        wbuf_append(&c->wbuf, data + sent, n - sent);\n        \n        // 4. Arm EPOLLOUT if not already armed\n        if (!c->epollout_armed) {\n            struct epoll_event ev;\n            ev.events = EPOLLIN | EPOLLOUT | EPOLLET;\n            ev.data.fd = fd;\n            epoll_ctl(epoll_fd, EPOLL_CTL_MOD, fd, &ev);\n            c->epollout_armed = true;\n        }\n    }\n    return 0;\n}\n```\n<!-- END_TDD_MOD -->\n\n\n<!-- TDD_MOD_ID: build-event-loop-m3 -->\n# MODULE CHARTER: Reactor API and Callback Dispatch\n\nThis module decouples application logic from the underlying Linux `epoll` primitives by implementing the Reactor Pattern. It provides a clean, callback-based interface for I/O multiplexing, timer management, and deferred task execution. A primary objective is the elimination of \"use-after-free\" and \"file descriptor reuse\" bugs through a **zombie flag** mechanism and a **deferred modification queue**, ensuring that modifying the interest set during event dispatch does not corrupt the active event batch. This module does NOT implement any high-level protocols (like HTTP or Redis RESP); it serves as a pure infrastructure layer. Invariants include: (1) no direct `epoll_ctl` calls during dispatch, (2) guaranteed execution of deferred tasks after all I/O events in a tick, and (3) O(1) handler lookup via a fixed-size registration table.\n\n# FILE STRUCTURE\n\nThe implementation follows a strict separation between public API and internal implementation details.\n\n1. `reactor.h`: Public interface definitions, constants, and function signatures.\n2. `reactor_internal.h`: Internal structure definitions (opaque to users), heap logic, and queue types.\n3. `reactor.c`: Core implementation of the dispatch loop and event management.\n4. `Makefile`: Build instructions ensuring `-fPIC` (if building as library) and `-O2`.\n\n# COMPLETE DATA MODEL\n\n### 1. `reactor_t` (The Engine)\nHidden from the user via an opaque pointer. It encapsulates the kernel state and the user-space dispatch metadata.\n\n| Field | Type | Offset | Size | Purpose |\n| :--- | :--- | :--- | :--- | :--- |\n| `epoll_fd` | `int` | 0x00 | 4 | The kernel epoll instance. |\n| `is_running` | `bool` | 0x04 | 1 | Controls the main loop execution. |\n| `is_dispatching` | `bool` | 0x05 | 1 | Mutex-equivalent: true while iterating `epoll_wait` results. |\n| `padding` | `uint8_t[2]` | 0x06 | 2 | Align subsequent pointer to 8 bytes. |\n| `handlers` | `fd_handler_t*` | 0x08 | 8 | Array of 65,536 handlers (1.5 MB total). |\n| `timer_heap` | `timer_node_t*` | 0x10 | 8 | Min-heap array for scheduled timeouts. |\n| `mod_queue` | `deferred_mod_t*` | 0x18 | 8 | Queue for `epoll_ctl` ops generated during dispatch. |\n| `task_queue` | `deferred_task_t*` | 0x20 | 8 | Post-dispatch callback queue. |\n| `timer_count` | `uint32_t` | 0x28 | 4 | Current number of active timers. |\n| `mod_count` | `uint32_t` | 0x2C | 4 | Current size of `mod_queue`. |\n| `task_count` | `uint32_t` | 0x30 | 4 | Current size of `task_queue`. |\n\n### 2. `fd_handler_t` (Registration Metadata)\nEach entry in the `handlers` array tracks the application's intent for a specific file descriptor.\n\n| Field | Type | Offset | Size | Purpose |\n| :--- | :--- | :--- | :--- | :--- |\n| `callback` | `io_cb_fn` | 0x00 | 8 | Function pointer to execute on event. |\n| `user_data` | `void*` | 0x08 | 8 | Opaque context passed to the callback. |\n| `events` | `uint32_t` | 0x10 | 4 | Bitmask of `REACTOR_READABLE`, etc. |\n| `is_registered` | `bool` | 0x14 | 1 | Is this FD currently in the epoll set? |\n| `is_zombie` | `bool` | 0x15 | 1 | Marked for deletion during current dispatch? |\n| `padding` | `uint8_t[2]` | 0x16 | 2 | Padding to 24-byte struct size. |\n\n**Memory & Cache Analysis:**\nThe `handlers` array is $65,536 \\times 24 \\text{ bytes} \\approx 1.5 \\text{ MB}$. In high-concurrency scenarios, the \"working set\" of active handlers fits into the L3 cache. Using `epoll_event.data.ptr` to point directly to these structs eliminates an array-index multiplication per event.\n\n\n![Reactor Module Architecture: All Structs, Typedefs, and Public API Functions](./diagrams/tdd-diag-17.svg)\n\n\n# INTERFACE CONTRACTS\n\n### 1. `int reactor_register(reactor_t *r, int fd, uint32_t events, io_cb_fn cb, void *ud)`\n- **Input**: `events` as a bitmask (e.g., `REACTOR_READABLE | REACTOR_WRITABLE`).\n- **Safety**: If `r->is_dispatching` is true, it MUST NOT call `epoll_ctl` immediately. It must append to `r->mod_queue`.\n- **Logic**: If `handlers[fd].is_registered` is true, perform `EPOLL_CTL_MOD`. Otherwise, `EPOLL_CTL_ADD`.\n- **Return**: 0 on success, -1 on invalid FD or registration failure.\n\n### 2. `void reactor_deregister(reactor_t *r, int fd)`\n- **Safety**: If `r->is_dispatching` is true, set `handlers[fd].is_zombie = true` and append `MOD_DEL` to `r->mod_queue`.\n- **Logic**: Prevents subsequent events in the same batch from firing for a closed FD.\n\n### 3. `void reactor_defer(reactor_t *r, task_fn fn, void *ud)`\n- **Behavior**: Appends to `r->task_queue`.\n- **Execution**: Guaranteed to run after the I/O dispatch loop finishes but before the next `epoll_wait`.\n\n### 4. `int reactor_run(reactor_t *r)`\n- **Behavior**: Enters a `while(r->is_running)` loop.\n- **Tick Order**: \n    1. Calculate `epoll_wait` timeout from min-heap.\n    2. Execute expired timers.\n    3. `epoll_wait` for I/O events.\n    4. Set `is_dispatching = true`, iterate results, skip zombies.\n    5. Set `is_dispatching = false`, process `mod_queue`.\n    6. Process `task_queue` (snapshot current size to handle re-entrant defers).\n\n\n![fd_handler Struct: Byte-Level Memory Layout and Registration Table Size](./diagrams/tdd-diag-18.svg)\n\n\n# ALGORITHM SPECIFICATION\n\n### 1. The \"Zombie\" Guard (Event Skipping)\nDuring `epoll_wait`, the kernel returns $N$ events. If callback for event $i$ calls `reactor_deregister(fd_j)`, and event $k$ (where $k > i$) also involves `fd_j`:\n1. `reactor_deregister` sets `handlers[fd_j].is_zombie = true`.\n2. When the loop reaches index $k$, it checks `if (handlers[fd].is_zombie) continue;`.\n3. This prevents dispatching to an FD that was just closed/removed, avoiding the FD reuse race where `fd_j` might already be reassigned to a new connection.\n\n### 2. Drift-Free Interval Timers\nWhen an interval timer (repeating) fires:\n1. `next_expiry = previous_expiry + interval_ms`.\n2. Do NOT use `now() + interval_ms`, as the time taken to execute the callback would cause the timer to \"drift\" forward with every tick.\n3. If `next_expiry < now()` (due to extreme system lag), catch up by increments of `interval_ms`.\n\n### 3. Deferred Modification Application\nAfter `is_dispatching` is set to `false`:\n1. Iterate `r->mod_queue`.\n2. For `MOD_DEL`: `epoll_ctl(r->epoll_fd, EPOLL_CTL_DEL, mod->fd, NULL)`. Set `is_registered = false` and `is_zombie = false`.\n3. For `MOD_ADD/MOD`: Convert `REACTOR_*` flags to `EPOLL*` flags and call `epoll_ctl`.\n\n\n![Use-After-Free Scenario: fd Reuse Within One epoll_wait Batch](./diagrams/tdd-diag-19.svg)\n\n\n# ERROR HANDLING MATRIX\n\n| Error | Detected By | Recovery Action | User-Visible? |\n| :--- | :--- | :--- | :--- |\n| `reactor_register` during dispatch | `is_dispatching` check | Queue to `mod_queue`. Always succeeds unless queue is full. | No |\n| `epoll_ctl(MOD)` returns `ENOENT` | `reactor_apply_mod` | FD was likely removed out-of-band. Convert to `EPOLL_CTL_ADD` or log and ignore. | No |\n| `realloc` failure for queues | `enqueue_mod` | Hard fail: log \"OOM\" and abort server. Memory is critical for event safety. | Yes (log) |\n| `EINTR` in `epoll_wait` | `reactor_run` | `continue` the loop immediately. | No |\n| `EAGAIN` in `accept` | App callback | Return to reactor. Reactor will notify on next connection. | No |\n\n# IMPLEMENTATION SEQUENCE\n\n### Phase 1: Core Lifecycle & Registry (2 Hours)\n- Implement `reactor_create` / `reactor_destroy`.\n- Implement `handlers[65536]` fixed-size array initialization.\n- Implement `reactor_register` / `reactor_deregister` (outside-dispatch versions first).\n- **Checkpoint**: Test adding an FD to epoll, verifying `epoll_ctl` is called, and removing it.\n\n### Phase 2: The Safe Dispatch Loop (3 Hours)\n- Implement `reactor_run`.\n- Use `events[i].data.ptr` to store `&handlers[fd]`.\n- Implement the `is_dispatching` flag.\n- Add `is_zombie` checks and the `mod_queue`.\n- **Checkpoint**: Register two FDs. Inside FD1's callback, deregister FD2. Verify FD2's callback never fires even if data was available.\n\n### Phase 3: Post-Dispatch Tasks (1.5 Hours)\n- Implement `reactor_defer`.\n- Implement the \"generation snapshot\" logic for `task_queue` to handle tasks that schedule further tasks.\n- **Checkpoint**: Defer a function from within an I/O callback. Verify it runs *after* the I/O loop finishes.\n\n### Phase 4: Integrated Timer API (2.5 Hours)\n- Wrap Milestone 2's heap logic into `reactor_set_timeout` and `reactor_set_interval`.\n- Ensure `timer_process_timers` is called at the top of every reactor tick.\n- Implement the drift-free interval re-arming.\n- **Checkpoint**: Set a 100ms interval timer. Verify it fires 10 times in 1000ms +/- jitter.\n\n# TEST SPECIFICATION\n\n### 1. Re-entrancy Test (The FD Reuse Race)\n- **Scenario**: Callback for FD 5 calls `reactor_deregister(5)` then `accept4()` which happens to return FD 5. It then calls `reactor_register(5, ..., new_cb, new_ud)`.\n- **Happy Path**: The new registration clears the zombie flag. The reactor should NOT fire the old callback for FD 5 if it was already in the ready list.\n- **Failure**: Old callback fires with new user data, causing a crash.\n\n### 2. Deferred Task Order\n- **Scenario**: In a single tick, three events fire. Event 1 and 3 call `reactor_defer`.\n- **Verification**: Ensure both tasks run after Event 3, in the order they were deferred.\n\n### 3. Timer Cancellation inside I/O\n- **Scenario**: I/O callback for FD 10 receives a \"QUIT\" command and calls `reactor_cancel_timer` for its own idle timer.\n- **Verification**: Verify the heap is updated correctly and the timer never fires.\n\n# PERFORMANCE TARGETS\n\n| Operation | Target | Measurement Method |\n| :--- | :--- | :--- |\n| Handler Dispatch | < 50ns | CPU cycles from `epoll_wait` return to callback entry. |\n| Memory Overhead | 1.5MB fixed | `sizeof(fd_handler_t) * 65536` |\n| Queue Allocation | 0 on steady state | Use fixed-capacity queues with growth only on bursts. |\n| Loop Jitter | < 1ms | Latency between timer expiry and callback firing. |\n\n# SOUL SECTION: HARDWARE SOUL\n\n### 1. Pointer Dispatch vs. Integer Lookup\nWe store `data.ptr = &handlers[fd]` in the `epoll_event`. \n- **The Hardware View**: When the kernel returns events, the CPU reads the `data.ptr` memory address. Since this address points directly to the `fd_handler_t` struct, we avoid the `shl` (shift left) and `add` instructions required to calculate `base_address + (index * 24)`. \n- **Cycles Saved**: ~3-5 cycles per event. At 1,000,000 events/sec, this saves ~5 million cycles/sec, keeping the L1 cache pipeline tighter.\n\n### 2. The Zombie Branch\n`if (h->is_zombie) continue;`\n- **Branch Prediction**: 99.9% of the time, this is false. The CPU's **Branch Target Buffer (BTB)** will mark this as \"not taken.\" The check becomes effectively free (0 cycles) as the CPU speculatively executes the callback invocation.\n- **Cache Locality**: Since we just fetched the handler via `data.ptr`, the `is_zombie` byte is already in the L1d cache.\n\n### 3. Tick-less Efficiency\nBy calculating `timeout = next_timer - now`, the reactor is **tick-less**. \n- **Power Consumption**: The CPU stays in a deep sleep state (C-state) via the kernel `HLT` instruction until the exact millisecond a timer or I/O arrives. \n- **Context Switches**: Zero unnecessary wakeups. The system only context switches when work is actually pending.\n\n# STATE MACHINE: REACTOR LIFECYCLE\n\n| State | Transition Event | Allowed Actions |\n| :--- | :--- | :--- |\n| **INIT** | `reactor_create()` | Register fds, set timers. |\n| **POLLING** | `epoll_wait()` | Kernel-level wait. No user code. |\n| **DISPATCHING** | `epoll_wait` returns | `register`/`deregister` (queued), `defer`. |\n| **MOD_APPLY** | Dispatch loop ends | `epoll_ctl` batching. |\n| **TASK_RUN** | Mod apply ends | Run application-level deferred tasks. |\n| **STOPPED** | `reactor_stop()` | `reactor_destroy()` cleanup. |\n\n```c\n/* Pseudocode: reactor_run core logic */\nvoid reactor_run(reactor_t *r) {\n    while (r->is_running) {\n        int timeout = timer_heap_get_next_timeout(r->timer_heap);\n        int n_ready = epoll_wait(r->epoll_fd, r->event_batch, MAX_EVENTS, timeout);\n        \n        // 1. Timers first\n        timer_heap_process_expired(r, now_ms());\n        \n        // 2. I/O Dispatch\n        r->is_dispatching = true;\n        for (int i = 0; i < n_ready; i++) {\n            fd_handler_t *h = (fd_handler_t*)r->event_batch[i].data.ptr;\n            if (h->is_zombie || !h->is_registered) continue;\n            \n            uint32_t r_events = map_epoll_to_reactor(r->event_batch[i].events);\n            h->callback(fd_from_ptr(r, h), r_events, h->user_data);\n        }\n        r->is_dispatching = false;\n        \n        // 3. Mod Queue\n        process_mod_queue(r);\n        \n        // 4. Defer Queue (Snapshot-based)\n        process_defer_queue(r);\n    }\n}\n```\n<!-- END_TDD_MOD -->\n\n\n<!-- TDD_MOD_ID: build-event-loop-m4 -->\n# MODULE CHARTER: HTTP Server on Event Loop\n\nThis module implements a high-performance HTTP/1.1 static file server atop the Milestone 3 Reactor API. Its primary objective is to manage the transformation of raw TCP byte streams into structured HTTP requests and responses while maintaining the C10K concurrency target. The implementation must handle the \"Streaming Fragmentation\" reality of TCP, where HTTP headers and bodies may arrive across multiple `read()` calls or be multiplexed within a single read (pipelining). \n\nKey responsibilities include:\n1.  **Incremental Parsing**: A non-blocking state machine that accumulates bytes and pauses until delimiters (`\\r\\n\\r\\n`) are found.\n2.  **Connection State Lifecycle**: Managing transitions between `READING_HEADERS`, `READING_BODY`, `PROCESSING`, `WRITING`, and `KEEP_ALIVE`.\n3.  **Resource Safety**: Enforcing path-traversal defenses to prevent unauthorized file access and implementing canonical deferred cleanup to avoid use-after-free conditions.\n4.  **Performance Integration**: Utilizing the M2 write-buffer for backpressure and M2 timers for idle-connection reaping.\n\nThis module does NOT implement HTTP/2, TLS/SSL, POST body processing beyond length tracking, or dynamic CGI-like execution.\n\n# FILE STRUCTURE\n\nThe implementation follows a modular structure, building on the previously established `reactor` and `write_buffer` components.\n\n1.  `http_server.h`: Protocol constants, MIME types, and public server initialization.\n2.  `http_parser.c`: The incremental state machine and header extraction logic.\n3.  `http_core.c`: Request dispatch, file I/O integration, and response generation.\n4.  `http_connection.c`: Lifecycle management (init, reset, deferred close).\n5.  `main.c`: Entry point, reactor initialization, and signal handling.\n6.  `Makefile`: Updated to include all objects with `-O3` and `-march=native` for performance.\n\n# COMPLETE DATA MODEL\n\n### 1. `http_state_t` (Lifecycle Enum)\nDefines the current phase of the HTTP transaction.\n\n| Value | Name | Description |\n| :--- | :--- | :--- |\n| 0 | `HTTP_STATE_READING_HEADERS` | Accumulating bytes in `read_buf` searching for `\\r\\n\\r\\n`. |\n| 1 | `HTTP_STATE_READING_BODY` | Headers done; waiting for `Content-Length` bytes to arrive. |\n| 2 | `HTTP_STATE_PROCESSING` | Request fully received; resolving file path and generating headers. |\n| 3 | `HTTP_STATE_WRITING_RESPONSE` | Data is being flushed from the M2 `write_buf`. |\n| 4 | `HTTP_STATE_CLOSING` | Final flush in progress; connection will close once `write_buf` is empty. |\n\n### 2. `http_request_t` (Parsed Metadata)\nStores the result of the incremental parser. Reset every request in keep-alive cycles.\n\n| Field | Type | Size | Purpose |\n| :--- | :--- | :--- | :--- |\n| `method` | `char[10]` | 10 | \"GET\", \"HEAD\", etc. |\n| `path` | `char[1024]` | 1024 | URL path (e.g., \"/index.html\"). |\n| `content_length` | `size_t` | 8 | From `Content-Length` header. |\n| `body_received` | `size_t` | 8 | Bytes of body currently in `read_buf`. |\n| `keep_alive` | `bool` | 1 | True if `Connection: keep-alive` (or default 1.1). |\n| `is_complete` | `bool` | 1 | Internal parser flag. |\n\n### 3. `http_conn_t` (The Connection Context)\nThe \"Heart\" of the server. This struct is passed as `user_data` to all reactor callbacks.\n\n| Field | Type | Offset | Size | Purpose |\n| :--- | :--- | :--- | :--- | :--- |\n| `read_buf` | `char[16384]` | 0x00 | 16384 | Large buffer to catch fragmented headers. |\n| `wbuf` | `write_buf_t` | 0x4000 | 24 | M2 Write Buffer for backpressure. |\n| `req` | `http_request_t` | 0x4018 | ~1060 | Parsed request metadata. |\n| `fd` | `int` | 0x443C | 4 | Client socket descriptor. |\n| `state` | `http_state_t`| 0x4440 | 4 | Current lifecycle state. |\n| `read_pos` | `uint32_t` | 0x4444 | 4 | Current fill level of `read_buf`. |\n| `timer_id` | `int` | 0x4448 | 4 | Reactor timer handle for idle timeout. |\n| `reactor` | `reactor_t*` | 0x4450 | 8 | Reference back to owning reactor. |\n| **Total Size** | | | **~17.5 KB** | |\n\n**Memory Analysis:** At 10,000 connections, this requires ~175 MB of resident memory. The 16 KB `read_buf` is sized to accommodate most production HTTP header sets (typical limit 8-16 KB).\n\n\n![http_conn Struct: Byte-Level Memory Layout with Field Groups and Cache Line Boundaries](./diagrams/tdd-diag-26.svg)\n\n\n# INTERFACE CONTRACTS\n\n### 1. `parse_result_t http_parse_incremental(http_conn_t *conn)`\n- **Behavior**: Scans `conn->read_buf` from `0` to `conn->read_pos`.\n- **Delimiters**: Looks for `\\r\\n\\r\\n`.\n- **Incremental logic**: If not found, returns `PARSE_AGAIN`. If found, parses the first line and headers into `conn->req` and returns `PARSE_OK`.\n- **Edge Case**: If `read_pos == sizeof(read_buf)` and no delimiter found, returns `PARSE_LIMIT_EXCEEDED`.\n\n### 2. `int http_build_response(http_conn_t *conn)`\n- **Safety**: Calls `build_safe_path()` to sanitize `req->path`.\n- **I/O**: Uses `stat()` to get file size and `open()` for reading.\n- **Generation**: Writes HTTP/1.1 status, `Content-Type`, `Content-Length`, and `Connection` headers to `conn->wbuf`.\n- **Body**: Reads file chunks into `conn->wbuf` using `wbuf_append`.\n\n### 3. `void http_conn_close_deferred(reactor_t *r, void *arg)`\n- **Contract**: The ONLY valid way to close an HTTP connection.\n- **Cleanup**: Cancels timers, deregisters from reactor, frees `wbuf` heap memory, closes `fd`, and finally `free(conn)`.\n- **Rationale**: Must be called via `reactor_defer` to ensure the reactor's current event batch processing is complete.\n\n# ALGORITHM SPECIFICATION\n\n### 1. Incremental Read & Shift Algorithm\nWhen `REACTOR_READABLE` fires:\n1.  **Read**: `n = read(fd, read_buf + read_pos, space)`.\n2.  **Parse**: Call `http_parse_incremental`.\n3.  **Shift**: If headers are complete but part of a body (or next request) was read:\n    - `body_start = header_end_offset`.\n    - `remaining = read_pos - body_start`.\n    - `memmove(read_buf, read_buf + body_start, remaining)`.\n    - `read_pos = remaining`.\n4.  **State Change**: Transition to `HTTP_STATE_PROCESSING`.\n\n### 2. Path Sanitization (Defense-in-Depth)\n`int build_safe_path(const char *input, char *output)`\n1.  Prepend `STATIC_ROOT`.\n2.  Check for `..` substrings. If found, REJECT (400 Bad Request).\n3.  Check for `//` or internal `\\0`.\n4.  If path ends in `/`, append `index.html`.\n5.  Verify result is within `MAX_PATH`.\n\n### 3. Keep-Alive Cycle Logic\n1.  After response is fully appended to `wbuf`:\n2.  If `req->keep_alive` is true:\n    - Call `http_reset_connection(conn)`.\n    - Set `state = HTTP_STATE_READING_HEADERS`.\n    - Do NOT close FD. Reset idle timer to `now + 30s`.\n3.  If `keep_alive` is false:\n    - Set `state = HTTP_STATE_CLOSING`.\n    - Write logic will close after last byte leaves `wbuf`.\n\n\n![Per-Connection HTTP State Machine: All States, Valid Transitions, and Illegal Transitions](./diagrams/tdd-diag-27.svg)\n\n\n# ERROR HANDLING MATRIX\n\n| Error | Detected By | Recovery Action | User-Visible? |\n| :--- | :--- | :--- | :--- |\n| `PARSE_LIMIT_EXCEEDED` | `http_parse` | Send `413 Payload Too Large`, defer close. | Yes (413) |\n| Path Traversal (`..`) | `build_safe_path` | Send `400 Bad Request`, defer close. | Yes (400) |\n| File Not Found | `stat()` | Send `404 Not Found`, keep-alive reset. | Yes (404) |\n| `wbuf` Full | `wbuf_append` | Defer close immediately (Slow Loris defense). | No |\n| `open()` fails (after headers) | `http_process` | Defer close immediately (Broken Pipe). | No |\n| Idle Timeout | Reactor Timer | `reactor_defer(http_conn_close_deferred)`. | No |\n\n# IMPLEMENTATION SEQUENCE\n\n### Phase 1: Data Structures & Handlers (2 Hours)\n- Define `http_conn_t` and `http_request_t`.\n- Implement `http_accept_cb` to allocate `http_conn_t` and register with reactor.\n- **Checkpoint**: Server accepts connections, allocates memory, and assigns an idle timer. Verify via `valgrind` that memory is freed on manual close.\n\n### Phase 2: Incremental Parser (3 Hours)\n- Implement `find_header_end` (\\r\\n\\r\\n).\n- Implement `parse_request_line` and `parse_header_field`.\n- Integrate into `http_on_readable` with the `memmove` shift logic.\n- **Checkpoint**: Use `telnet` to send headers one character at a time. Verify the parser only triggers `PARSE_OK` after the final `\\r\\n\\r\\n`.\n\n### Phase 3: Response Generation & File I/O (3 Hours)\n- Implement `build_safe_path`.\n- Implement `http_process_request` with `stat` and `Content-Type` mapping.\n- Hook into M2 `conn_write_buffered`.\n- **Checkpoint**: `curl http://localhost:8080/index.html` successfully retrieves a file from the `public/` directory.\n\n### Phase 4: Lifecycle & Keep-Alive (2 Hours)\n- Implement `http_reset_connection`.\n- Handle `Connection: close` vs `keep-alive`.\n- Implement `http_conn_close_deferred` and ensure all error paths use it.\n- **Checkpoint**: `ab -k` (keep-alive) shows multiple requests handled over a single TCP connection.\n\n### Phase 5: Tuning & Benchmarking (2 Hours)\n- Set `ulimit -n 65535`.\n- Run `wrk -c 10000`.\n- Profile with `perf top` to identify hotspots (usually `find_header_end` or `memmove`).\n- **Checkpoint**: p99 latency < 100ms under 10k concurrent load.\n\n# TEST SPECIFICATION\n\n### 1. Fragmentation Stress Test\n- **Tool**: Custom python script.\n- **Action**: Send `GET /index.html HTT`, sleep 100ms, send `P/1.1\\r\\nHost: loc`, sleep 100ms, send `alhost\\r\\n\\r\\n`.\n- **Expected**: Server correctly parses and responds after the final chunk.\n\n### 2. Security: Path Traversal\n- **Input**: `GET /../../../../etc/passwd HTTP/1.1`\n- **Expected**: `400 Bad Request` or `404 Not Found` (depending on root configuration), but NEVER the content of `passwd`.\n\n### 3. C10K Load Test\n- **Tool**: `wrk -t12 -c10000 -d30s http://localhost:8080/test.html`\n- **Success Criteria**: 0 socket errors, 0 timeouts, p99 < 100ms.\n\n# PERFORMANCE TARGETS\n\n| Operation | Target | Measurement Method |\n| :--- | :--- | :--- |\n| Header Parsing | < 10Î¼s per req | `perf` probe on `http_parse_incremental` |\n| Memory Per Connection | ~17.5 KB | `ps -o rss` / total_conns |\n| Throughput | 50,000+ RPS | `wrk` on localhost |\n| Max Conns | 10,000+ | `netstat -an | grep ESTABLISHED | wc -l` |\n\n# HARDWARE SOUL: PERFORMANCE INSIGHTS\n\n### 1. Sequential Access & Prefetching\nThe `find_header_end` function performs a linear scan of `read_buf`. \n- **The Hardware View**: Modern CPU prefetchers detect this linear read pattern (stride of 1). By the time the code is checking byte $N$, the hardware has already loaded bytes $N+64$ and $N+128$ into the L1 cache. \n- **Optimization**: To keep the pipeline full, we avoid complex branching inside the loop.\n\n### 2. `memmove` and Cache Pressure\nWhen we shift body bytes to the front of the `read_buf`, we use `memmove`. \n- **Effect**: This touches the memory twice (read then write). \n- **Mitigation**: By keeping `READ_BUF_SIZE` at 16 KB, we ensure the entire buffer fits in the L1 Data Cache (typically 32-64 KB). This makes the shift operation nearly as fast as register-to-register moves.\n\n### 3. Syscall Batching (The \"Amortization\")\nIn the `http_accept_cb` and `http_on_readable`, we use **ET (Edge-Triggered)** mode with a loop until `EAGAIN`.\n- **Benefit**: This minimizes the number of `epoll_wait` entries/exits. If 100 packets arrive for 100 different FDs, `epoll_wait` returns them all in one array. We process all 100 in user-space before context-switching back to the kernel. This amortizes the ~200ns syscall cost across 100 requests.\n\n### 4. `sendfile(2)` (Optional Milestone)\nWhile the standard implementation uses `read/write`, a \"Hardware Soul\" optimization is `sendfile`. \n- **Zero-Copy**: It transfers data from the kernel Page Cache directly to the Socket Buffer without ever entering user-space memory. This eliminates two `memcpy` operations and reduces CPU usage by ~30% for large static files.\n\n```c\n/* Canonical Deferred Close implementation */\nvoid http_conn_close_deferred(reactor_t *r, void *arg) {\n    http_conn_t *conn = (http_conn_t *)arg;\n    if (conn->fd == -1) return; // Guard against double close\n\n    // 1. Stop all reactor interest\n    if (conn->timer_id != -1) {\n        reactor_cancel_timer(r, conn->timer_id);\n    }\n    reactor_deregister(r, conn->fd);\n\n    // 2. Resource Release\n    wbuf_free(&conn->wbuf);\n    close(conn->fd);\n    \n    // 3. Final Memory Release\n    int old_fd = conn->fd;\n    conn->fd = -1; // Mark as dead\n    free(conn);\n    \n    printf(\"DEBUG: Cleaned up connection on fd %d\\n\", old_fd);\n}\n```\n<!-- END_TDD_MOD -->\n\n\n# Project Structure: Event Loop with epoll\n\n## Directory Tree\n\n```text\nevent-loop-epoll/\nâ”œâ”€â”€ include/                 # Header files (API & Internals)\nâ”‚   â”œâ”€â”€ reactor.h           # Public Reactor API (M3: Callback definitions)\nâ”‚   â”œâ”€â”€ reactor_internal.h  # Reactor private structs (M3: fd_handler, mod_queue)\nâ”‚   â”œâ”€â”€ write_buffer.h      # Write queue & compaction logic (M2)\nâ”‚   â”œâ”€â”€ timer_heap.h        # Min-heap & timing definitions (M2)\nâ”‚   â””â”€â”€ http_server.h       # HTTP constants, MIME types, & states (M4)\nâ”œâ”€â”€ src/                    # Implementation files\nâ”‚   â”œâ”€â”€ reactor.c           # Core epoll loop & dispatch logic (M1, M3)\nâ”‚   â”œâ”€â”€ write_buffer.c      # Dynamic buffer management (M2: Backpressure)\nâ”‚   â”œâ”€â”€ timer_heap.c        # Min-heap sift operations (M2: Idle timeouts)\nâ”‚   â”œâ”€â”€ http_parser.c       # Incremental state machine (M4: \\r\\n\\r\\n scanner)\nâ”‚   â”œâ”€â”€ http_core.c         # File I/O & HTTP response generation (M4)\nâ”‚   â”œâ”€â”€ http_connection.c   # Connection lifecycle & deferred cleanup (M4)\nâ”‚   â””â”€â”€ main.c              # Application entry & server initialization (M4)\nâ”œâ”€â”€ public/                 # Static assets for HTTP server (M4)\nâ”‚   â””â”€â”€ index.html          # Default landing page for C10K testing\nâ”œâ”€â”€ Makefile                # Build system (M1-M4: -O3, -march=native)\nâ”œâ”€â”€ README.md               # Project overview and sysctl tuning guide\nâ””â”€â”€ .gitignore              # Ignores build artifacts (http_server, *.o)\n```\n\n## Creation Order\n\n1.  **Foundational I/O** (M1)\n    *   Create `Makefile` with basic flags (`-Wall -Wextra -O2`).\n    *   Implement `set_nonblocking` and `create_listening_socket` in a temporary `echo_server.c`.\n    *   Build the raw `epoll_wait` loop to verify Level-Triggered (LT) vs Edge-Triggered (ET) behavior.\n\n2.  **Reliability Layer** (M2)\n    *   Implement `src/write_buffer.c` and `src/timer_heap.c`.\n    *   Integrate `wbuf_append` into the write path to handle `EAGAIN`.\n    *   Integrate `timer_next_ms()` into the `epoll_wait` timeout to handle idle connections.\n\n3.  **The Reactor Library** (M3)\n    *   Refactor the raw loop into `include/reactor.h` and `src/reactor.c`.\n    *   Implement the `is_dispatching` flag and `mod_queue` to prevent FD reuse races.\n    *   Implement `reactor_defer()` to handle safe, post-dispatch cleanup.\n\n4.  **Protocol Implementation** (M4)\n    *   Implement `src/http_parser.c` with the `memmove` incremental shift logic.\n    *   Implement `src/http_core.c` including the `build_safe_path` security check.\n    *   Set up `src/http_connection.c` for keep-alive state resets.\n\n5.  **Optimization & Load Testing** (M4)\n    *   Finalize `src/main.c` with signal handling.\n    *   Tune `Makefile` with `-O3 -march=native`.\n    *   Apply `sysctl` kernel tweaks for C10K and run `wrk` benchmarks.\n\n## File Count Summary\n*   **Total Source Files**: 7 (.c)\n*   **Total Header Files**: 5 (.h)\n*   **Total Directories**: 3\n*   **Estimated Lines of Code**: ~1,800 LOC\n*   **Build Artifacts**: `http_server` (executable), `*.o` (object files)\n"}