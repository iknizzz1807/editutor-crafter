{"html":"<h1 id=\"build-your-own-git-design-document\">Build Your Own Git: Design Document</h1>\n<h2 id=\"overview\">Overview</h2>\n<p>This system implements a version control system that uses content-addressable storage and a directed acyclic graph to track file changes over time. The key architectural challenge is designing an immutable object store where every piece of content is identified by its cryptographic hash, enabling efficient deduplication and integrity verification.</p>\n<blockquote>\n<p>This guide is meant to help you understand the big picture before diving into each milestone. Refer back to it whenever you need context on how components connect.</p>\n</blockquote>\n<h2 id=\"context-and-problem-statement\">Context and Problem Statement</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section establishes the foundational concepts underlying all milestones</p>\n</blockquote>\n<h3 id=\"mental-model-the-digital-filing-cabinet\">Mental Model: The Digital Filing Cabinet</h3>\n<p>Imagine you have a magical filing cabinet for all your documents. This isn&#39;t an ordinary filing cabinet—it has three extraordinary properties that make it perfect for managing the evolution of your work over time.</p>\n<p>First, the filing cabinet <strong>never loses anything</strong>. Every version of every document you&#39;ve ever stored remains perfectly preserved, accessible whenever you need it. You can ask to see the draft of your thesis from six months ago, or the version of your code from last Tuesday, and the cabinet instantly produces an exact copy. Nothing ever gets overwritten or accidentally deleted.</p>\n<p>Second, the filing cabinet is <strong>impossibly organized</strong>. Instead of using arbitrary folder names or date-based filing systems that might conflict or become confusing, it uses a perfect organizational scheme: every document gets filed based on a mathematical fingerprint of its exact contents. Two identical documents, even if created years apart, automatically go to the same location. This means there&#39;s never any duplication—the cabinet stores each unique piece of content exactly once, no matter how many times you reference it.</p>\n<p>Third, the filing cabinet <strong>remembers the relationships</strong> between documents. When you file a new version of your thesis that incorporates feedback, the cabinet automatically records that this new version is based on the previous draft. It builds a complete family tree of how your documents evolved, branched into different versions, and merged back together. You can trace the lineage of any document back to its origins and understand exactly how it came to be.</p>\n<p>This magical filing cabinet is precisely what Git provides for software development. The <strong>content-addressable storage</strong> system acts as the perfect organizational scheme, using cryptographic hashes to ensure every piece of content has a unique, deterministic location. The <strong>immutable object store</strong> guarantees that once something is filed, it never disappears or changes. The <strong>directed acyclic graph</strong> of commits preserves the complete evolutionary history of your project, showing how each version builds upon previous work.</p>\n<p>Unlike physical filing cabinets where you might run out of space or struggle to find documents, Git&#39;s digital filing cabinet scales effortlessly. The mathematical properties of the hash-based organization ensure that even projects with millions of files and decades of history remain fast and reliable. The distributed nature means every developer gets their own complete copy of this magical cabinet, yet all copies can synchronize and share their contents seamlessly.</p>\n<blockquote>\n<p>The fundamental insight that makes Git possible is that <strong>content identity can be derived from content itself</strong>. Instead of assigning arbitrary names or numbers to track different versions, Git computes a cryptographic fingerprint of each piece of content. This fingerprint serves as both the identity and the storage location, creating a self-organizing system that eliminates duplication and ensures integrity.</p>\n</blockquote>\n<h3 id=\"existing-version-control-approaches\">Existing Version Control Approaches</h3>\n<p>The challenge of tracking changes to files over time has been approached in several fundamentally different ways throughout the history of software development. Each approach represents different trade-offs between simplicity, functionality, and complexity. Understanding these approaches illuminates why Git&#39;s content-addressable architecture emerged as the dominant solution for modern software development.</p>\n<h4 id=\"simple-file-based-approaches\">Simple File-Based Approaches</h4>\n<p>The most basic approach to version control involves manual copying and timestamping. Developers create copies of their entire project directory with names like <code>project-v1.0</code>, <code>project-v1.1-backup</code>, <code>project-final</code>, <code>project-final-REALLY-FINAL</code>. This approach is intuitive and requires no special tools, but it quickly becomes unworkable.</p>\n<p>The fundamental problems with file copying are storage inefficiency and coordination impossibility. Each complete copy of the project consumes full disk space, even when changes affect only a few files. A project with 1000 files that undergoes 100 versions consumes space equivalent to 100,000 files, even if most files never changed. More critically, there&#39;s no systematic way to understand what changed between versions, merge contributions from multiple developers, or recover from mistakes. Finding specific changes requires manual comparison of directory trees, a process that becomes prohibitively expensive as project size grows.</p>\n<p>Some developers attempt to solve the comparison problem by maintaining change logs—text files that document what modified in each version. However, these logs are manually maintained and inevitably drift out of sync with actual changes. The change logs themselves become another file that needs version control, creating a recursive problem. Additionally, manual change tracking is error-prone and time-consuming, reducing developer productivity and introducing opportunities for human error.</p>\n<h4 id=\"centralized-version-control-systems\">Centralized Version Control Systems</h4>\n<p>Centralized systems like Subversion (SVN) and Concurrent Versions System (CVS) emerged to solve the coordination and storage problems of manual file copying. These systems introduce a central server that stores the complete history of the project and coordinates access among multiple developers.</p>\n<p>In the centralized model, the server maintains a linear sequence of numbered revisions. Each revision represents a snapshot of the entire project at a specific point in time. Developers work with local working copies that contain only the current version of files. When they want to make changes, they update their working copy to the latest revision from the server, make modifications locally, and commit changes back to the server. The server automatically assigns sequential revision numbers and stores the differences between consecutive revisions.</p>\n<table>\n<thead>\n<tr>\n<th>Aspect</th>\n<th>Centralized VCS Behavior</th>\n<th>Advantages</th>\n<th>Disadvantages</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Storage Model</strong></td>\n<td>Server stores complete history, clients have working copies only</td>\n<td>Efficient network usage, simple mental model</td>\n<td>Single point of failure, requires network access</td>\n</tr>\n<tr>\n<td><strong>Branching</strong></td>\n<td>Branches are server-side directories, expensive to create</td>\n<td>Clear branch visualization in repository structure</td>\n<td>Branch creation requires server round-trip, discourages experimentation</td>\n</tr>\n<tr>\n<td><strong>Merging</strong></td>\n<td>Server coordinates all merges, maintains linear history when possible</td>\n<td>Simplified conflict resolution workflow</td>\n<td>Complex merges block other developers, limited merge strategies</td>\n</tr>\n<tr>\n<td><strong>Network Dependency</strong></td>\n<td>Most operations require server communication</td>\n<td>Always synchronized with team, simplified backup</td>\n<td>Offline work impossible, network latency affects productivity</td>\n</tr>\n<tr>\n<td><strong>Access Control</strong></td>\n<td>Server enforces permissions per-directory or per-file</td>\n<td>Fine-grained security control, audit trails</td>\n<td>Administrative overhead, inflexible workflows</td>\n</tr>\n</tbody></table>\n<p>The centralized approach works well for small teams with reliable network connectivity and relatively simple branching needs. The linear revision numbering makes it easy to reference specific versions, and the central server provides a clear authoritative source of truth. However, centralized systems impose significant limitations on developer workflows and introduce architectural brittleness.</p>\n<h4 id=\"distributed-version-control-systems\">Distributed Version Control Systems</h4>\n<p>Distributed systems like Git, Mercurial, and Bazaar eliminate the central server bottleneck by giving every developer a complete copy of the project history. This architectural shift enables fundamentally new workflows while solving many limitations of centralized systems.</p>\n<p>In the distributed model, every working copy is actually a complete repository containing the full history of the project. Developers can create branches, make commits, and view history entirely locally without network access. Synchronization between repositories happens through explicit push and pull operations that exchange sets of commits. There&#39;s no inherent hierarchy—any repository can serve as a coordination point, and different teams can use different topologies (centralized, peer-to-peer, hierarchical) based on their needs.</p>\n<table>\n<thead>\n<tr>\n<th>Aspect</th>\n<th>Distributed VCS Behavior</th>\n<th>Advantages</th>\n<th>Disadvantages</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Storage Model</strong></td>\n<td>Every clone contains complete history</td>\n<td>Full offline capability, no single point of failure</td>\n<td>Larger initial clone size, complex synchronization</td>\n</tr>\n<tr>\n<td><strong>Branching</strong></td>\n<td>Branches are lightweight local references</td>\n<td>Instant branch creation, encourages experimentation</td>\n<td>Branch proliferation can become confusing</td>\n</tr>\n<tr>\n<td><strong>Merging</strong></td>\n<td>Advanced three-way merge algorithms with multiple strategies</td>\n<td>Sophisticated conflict resolution, non-linear history support</td>\n<td>Steeper learning curve, potential for complex merge conflicts</td>\n</tr>\n<tr>\n<td><strong>Network Independence</strong></td>\n<td>All operations work offline, sync when convenient</td>\n<td>Flexible workflows, works with unreliable connectivity</td>\n<td>Potential for repositories to diverge significantly</td>\n</tr>\n<tr>\n<td><strong>Collaboration Models</strong></td>\n<td>Supports multiple coordination topologies</td>\n<td>Adaptable to different team structures and policies</td>\n<td>Requires explicit coordination protocols</td>\n</tr>\n</tbody></table>\n<p>The distributed approach excels in scenarios with complex branching needs, unreliable network connectivity, or large teams with diverse collaboration patterns. The complete local history enables powerful operations like bisecting to find bug introductions, sophisticated blame tracking, and experimental branching without coordination overhead.</p>\n<h4 id=\"git39s-content-addressable-innovation\">Git&#39;s Content-Addressable Innovation</h4>\n<p>Git&#39;s specific innovation within the distributed model is the use of content-addressable storage based on cryptographic hashing. While other distributed systems like Mercurial use similar overall architectures, Git&#39;s object model provides unique advantages for integrity, deduplication, and performance.</p>\n<p>Every piece of content in Git—whether file contents, directory structures, or commit metadata—is stored as an object identified by the SHA-1 hash of its contents. This creates several powerful properties that distinguish Git from other approaches:</p>\n<p><strong>Automatic deduplication</strong> occurs because identical content always produces identical hashes. If the same file appears in multiple commits or branches, Git stores it only once. This makes branching extremely lightweight compared to systems that copy files or store differences.</p>\n<p><strong>Cryptographic integrity verification</strong> happens automatically because any corruption changes the hash. Git can detect repository corruption immediately when accessing objects, providing stronger integrity guarantees than systems relying on file system integrity alone.</p>\n<p><strong>Distributed consistency</strong> emerges naturally because content hashes are identical across all repositories. Two developers who independently create identical commits will generate identical commit hashes, simplifying synchronization and conflict detection.</p>\n<p><strong>Immutable history</strong> is enforced by the hash chain structure. Because each commit&#39;s hash includes the hashes of its parent commits, changing any historical commit would require recomputing all subsequent hashes, making tampering easily detectable.</p>\n<blockquote>\n<p><strong>Decision: Content-Addressable Object Storage</strong></p>\n<ul>\n<li><strong>Context</strong>: Version control systems need to store file contents, directory structures, and metadata efficiently while ensuring integrity and enabling distributed synchronization</li>\n<li><strong>Options Considered</strong>: Sequential revision numbers (CVS/SVN), content-based addressing (Git), hybrid approaches (Mercurial)</li>\n<li><strong>Decision</strong>: Use SHA-1 hashes of content as both object identity and storage location</li>\n<li><strong>Rationale</strong>: Content-addressable storage provides automatic deduplication, cryptographic integrity, distributed consistency, and immutable history with minimal overhead</li>\n<li><strong>Consequences</strong>: Enables lightweight branching, efficient storage, strong integrity guarantees, but requires understanding of hash-based addressing and occasional hash collisions</li>\n</ul>\n</blockquote>\n<p>The trade-offs of Git&#39;s approach become apparent in specific scenarios. The content-addressable model requires understanding of hash-based addressing, which has a steeper learning curve than sequential revision numbers. The complete history in every clone means initial repository size is larger than centralized systems. Complex branching and merging capabilities can lead to confusing repository states if not managed carefully.</p>\n<p>However, for software development workflows involving frequent branching, distributed teams, or long-lived feature development, Git&#39;s advantages typically outweigh these costs. The ability to work completely offline while maintaining full version control capabilities, combined with the lightweight nature of Git&#39;s branching model, has made it the standard choice for most modern software projects.</p>\n<h4 id=\"summary-of-architectural-trade-offs\">Summary of Architectural Trade-offs</h4>\n<table>\n<thead>\n<tr>\n<th>Approach</th>\n<th>Storage Efficiency</th>\n<th>Branching Cost</th>\n<th>Network Dependency</th>\n<th>Learning Curve</th>\n<th>Best Use Cases</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>File Copying</strong></td>\n<td>Very Poor</td>\n<td>Manual only</td>\n<td>None</td>\n<td>Minimal</td>\n<td>Single developer, tiny projects</td>\n</tr>\n<tr>\n<td><strong>Centralized</strong></td>\n<td>Good</td>\n<td>Medium-High</td>\n<td>Required for most operations</td>\n<td>Low-Medium</td>\n<td>Small teams, simple workflows</td>\n</tr>\n<tr>\n<td><strong>Distributed</strong></td>\n<td>Excellent</td>\n<td>Very Low</td>\n<td>Optional</td>\n<td>Medium-High</td>\n<td>Complex projects, distributed teams</td>\n</tr>\n<tr>\n<td><strong>Git Specifically</strong></td>\n<td>Excellent</td>\n<td>Minimal</td>\n<td>Optional</td>\n<td>High</td>\n<td>Software development, open source</td>\n</tr>\n</tbody></table>\n<p>The evolution from manual copying through centralized systems to distributed version control reflects the growing complexity of software development projects and the need for more sophisticated collaboration models. Git&#39;s content-addressable approach represents the current state of the art, providing the flexibility and power needed for modern software development while maintaining the performance and reliability required for large-scale projects.</p>\n<p>Understanding these different approaches helps explain why Git is architected the way it is, and why certain design decisions that might seem complex in isolation actually solve fundamental problems that simpler approaches cannot address. The content-addressable object store that we will implement represents decades of evolution in version control system design, distilled into an elegant and powerful architecture.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The following implementation guidance provides concrete technical recommendations for building the foundational components described in this section. This guidance targets Python development and establishes the coding patterns we&#39;ll use throughout the project.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Hashing</strong></td>\n<td><code>hashlib.sha1()</code> from standard library</td>\n<td><code>cryptography</code> library with hash verification</td>\n</tr>\n<tr>\n<td><strong>Compression</strong></td>\n<td><code>zlib</code> module from standard library</td>\n<td><code>lzma</code> for better compression ratios</td>\n</tr>\n<tr>\n<td><strong>File I/O</strong></td>\n<td><code>pathlib.Path</code> with context managers</td>\n<td><code>os.scandir()</code> for high-performance directory traversal</td>\n</tr>\n<tr>\n<td><strong>Binary Data</strong></td>\n<td><code>bytes</code> and <code>struct.pack/unpack</code></td>\n<td><code>ctypes</code> for complex binary structures</td>\n</tr>\n<tr>\n<td><strong>Command Line</strong></td>\n<td><code>argparse</code> for basic CLI</td>\n<td><code>click</code> for advanced command interfaces</td>\n</tr>\n<tr>\n<td><strong>Testing</strong></td>\n<td><code>unittest</code> from standard library</td>\n<td><code>pytest</code> with fixtures and parametrization</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-project-structure\">Recommended Project Structure</h4>\n<p>Organize your Git implementation to mirror the architectural components and support iterative development across the eight milestones:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>git-implementation/\n├── mygit/                          # Main package\n│   ├── __init__.py                 # Package initialization\n│   ├── cli.py                      # Command-line interface entry point\n│   ├── repository.py               # Repository class and initialization\n│   ├── objects/                    # Object store implementation\n│   │   ├── __init__.py\n│   │   ├── blob.py                 # Blob object handling\n│   │   ├── tree.py                 # Tree object handling\n│   │   ├── commit.py               # Commit object handling\n│   │   └── store.py                # Object storage backend\n│   ├── index/                      # Staging area implementation\n│   │   ├── __init__.py\n│   │   ├── index.py                # Index file format and operations\n│   │   └── status.py               # Working directory status calculation\n│   ├── refs/                       # Reference management\n│   │   ├── __init__.py\n│   │   ├── head.py                 # HEAD reference handling\n│   │   └── branches.py             # Branch creation and management\n│   ├── diff/                       # Diff algorithm implementation\n│   │   ├── __init__.py\n│   │   ├── myers.py                # Myers diff algorithm\n│   │   └── unified.py              # Unified diff output format\n│   ├── merge/                      # Merge implementation\n│   │   ├── __init__.py\n│   │   ├── three_way.py            # Three-way merge algorithm\n│   │   └── conflicts.py            # Conflict detection and marking\n│   └── utils/                      # Shared utilities\n│       ├── __init__.py\n│       ├── hash.py                 # Hash computation helpers\n│       └── paths.py                # Path manipulation utilities\n├── tests/                          # Test suite\n│   ├── __init__.py\n│   ├── test_objects.py             # Object store tests\n│   ├── test_index.py               # Index operation tests\n│   ├── test_refs.py                # Reference management tests\n│   ├── test_diff.py                # Diff algorithm tests\n│   ├── test_merge.py               # Merge algorithm tests\n│   └── integration/                # Integration tests\n│       ├── __init__.py\n│       └── test_workflows.py       # End-to-end workflow tests\n├── examples/                       # Example repositories and scripts\n│   └── sample_repo/                # Test repository for development\n└── docs/                          # Documentation\n    └── milestones/                 # Milestone-specific documentation</code></pre></div>\n\n<h4 id=\"core-infrastructure-components\">Core Infrastructure Components</h4>\n<p>Before implementing Git-specific logic, establish these foundational utilities that will be used throughout the project:</p>\n<p><strong>Hash Computation Utility (utils/hash.py):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> hashlib</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#79B8FF\"> bytes</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> compute_sha1</span><span style=\"color:#E1E4E8\">(content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Compute SHA-1 hash of content and return as 40-character hex string.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        content: Raw bytes to hash</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        40-character lowercase hex digest</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Example:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        >>> </span><span style=\"color:#9ECBFF\">compute_sha1(b\"hello world\")</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        '2aae6c35c94fcfb415dbe95f408b9ce91ee846ed'</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    hasher </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> hashlib.sha1()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    hasher.update(content)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> hasher.hexdigest()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> compute_object_hash</span><span style=\"color:#E1E4E8\">(object_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Compute Git object hash including type and size header.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Git objects are hashed as: \"{type} {size}</span><span style=\"color:#79B8FF\">\\0</span><span style=\"color:#9ECBFF\">{content}\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        object_type: Git object type (\"blob\", \"tree\", \"commit\")</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        content: Raw object content</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        40-character hex hash that matches git hash-object</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    header </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">object_type</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#79B8FF\"> {len</span><span style=\"color:#E1E4E8\">(content)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">.encode(</span><span style=\"color:#9ECBFF\">'ascii'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    full_content </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> header </span><span style=\"color:#F97583\">+</span><span style=\"color:#F97583\"> b</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\0</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#F97583\"> +</span><span style=\"color:#E1E4E8\"> content</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> compute_sha1(full_content)</span></span></code></pre></div>\n\n<p><strong>Path Utilities (utils/paths.py):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> os</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> find_git_directory</span><span style=\"color:#E1E4E8\">(start_path: Path </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> Optional[Path]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Find .git directory by walking up the directory tree.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        start_path: Directory to start search from (default: current directory)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Path to .git directory, or None if not found</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> start_path </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        start_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Path.cwd()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    current </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> start_path.resolve()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    while</span><span style=\"color:#E1E4E8\"> current </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> current.parent:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        git_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> current </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> '.git'</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> git_dir.is_dir():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> git_dir</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        current </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> current.parent</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> ensure_directory_exists</span><span style=\"color:#E1E4E8\">(path: Path) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Create directory and all parent directories if they don't exist.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    path.mkdir(</span><span style=\"color:#FFAB70\">parents</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">exist_ok</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> object_path_from_hash</span><span style=\"color:#E1E4E8\">(git_dir: Path, object_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Path:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Convert object hash to file system path in .git/objects.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Git stores objects as .git/objects/xx/yyyyyyyy where xx is first 2 hex chars.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        git_dir: Path to .git directory</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        object_hash: 40-character hex hash</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Path where object should be stored</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Example:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        >>> </span><span style=\"color:#9ECBFF\">object_path_from_hash(Path('.git'), 'abc123...')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Path('.git/objects/ab/c123...')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> 'objects'</span><span style=\"color:#F97583\"> /</span><span style=\"color:#E1E4E8\"> object_hash[:</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> object_hash[</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">:]</span></span></code></pre></div>\n\n<p><strong>Repository Class Skeleton (repository.py):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .utils.paths </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> find_git_directory, ensure_directory_exists</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> Repository</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Represents a Git repository and provides access to its components.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    The Repository class serves as the main entry point for all Git operations,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    coordinating between the object store, index, references, and working directory.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, path: Path </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Initialize repository object.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            path: Path to repository root (default: find from current directory)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.git_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> find_git_directory(path)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.git_dir </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Not a git repository\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.work_tree </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.git_dir.parent</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">classmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> init</span><span style=\"color:#E1E4E8\">(cls, path: Path </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#9ECBFF\">'Repository'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Initialize a new Git repository.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            path: Directory to initialize (default: current directory)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Repository object for the newly created repository</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> path </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Path.cwd()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        git_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> path </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> '.git'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if .git already exists and handle appropriately</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Create .git directory structure (objects, refs, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Create initial HEAD file pointing to refs/heads/master</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Create config file with repository format version</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Set appropriate permissions on .git directory</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> cls</span><span style=\"color:#E1E4E8\">(path)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> object_exists</span><span style=\"color:#E1E4E8\">(self, object_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Check if object with given hash exists in object store.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Implement object existence check</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> read_object</span><span style=\"color:#E1E4E8\">(self, object_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Read and decompress object from object store.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Tuple of (object_type, content)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Implement object reading with decompression</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> write_object</span><span style=\"color:#E1E4E8\">(self, object_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Write object to object store with compression.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            SHA-1 hash of the stored object</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Implement object writing with compression</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"development-workflow-setup\">Development Workflow Setup</h4>\n<p><strong>Environment Configuration:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># requirements.txt</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">pytest</span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\">7.0</span><span style=\"color:#E1E4E8\">.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">pytest</span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\">cov</span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\">4.0</span><span style=\"color:#E1E4E8\">.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">black</span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\">22.0</span><span style=\"color:#E1E4E8\">.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">mypy</span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\">1.0</span><span style=\"color:#E1E4E8\">.0</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># .gitignore for your implementation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">__pycache__</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">.pyc</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">.pyo</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">.pyd</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">.Python</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">build</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">develop</span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\">eggs</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">dist</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">downloads</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">eggs</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">.eggs</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">lib</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">lib64</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">parts</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">sdist</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">var</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">wheels</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">.egg</span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\">info</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">.installed.cfg</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">.egg</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">.pytest_cache</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">.coverage</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">htmlcov</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">.mypy_cache</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">examples</span><span style=\"color:#F97583\">/*/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">test_repos</span><span style=\"color:#F97583\">/</span></span></code></pre></div>\n\n<h4 id=\"milestone-1-checkpoint-repository-initialization\">Milestone 1 Checkpoint: Repository Initialization</h4>\n<p>After implementing the repository initialization logic, verify your implementation with these tests:</p>\n<p><strong>Manual Verification Steps:</strong></p>\n<ol>\n<li>Run <code>python -m mygit init</code> in an empty directory</li>\n<li>Verify <code>.git</code> directory exists with mode 755: <code>ls -la | grep .git</code></li>\n<li>Check directory structure: <code>find .git -type d | sort</code></li>\n<li>Verify HEAD contents: <code>cat .git/HEAD</code> should show <code>ref: refs/heads/master</code></li>\n<li>Test error handling: run <code>mygit init</code> again, should warn about existing repository</li>\n</ol>\n<p><strong>Expected Directory Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>.git/\n├── objects/\n│   ├── info/\n│   └── pack/\n├── refs/\n│   ├── heads/\n│   └── tags/\n├── HEAD\n└── config</code></pre></div>\n\n<p><strong>Unit Test Template:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> test_repository_initialization</span><span style=\"color:#E1E4E8\">(tmp_path):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Test that repository initialization creates correct structure.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Initialize repository</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    repo </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Repository.init(tmp_path)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Verify .git directory exists</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    assert</span><span style=\"color:#E1E4E8\"> (tmp_path </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> '.git'</span><span style=\"color:#E1E4E8\">).is_dir()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Verify required subdirectories</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    required_dirs </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span><span style=\"color:#9ECBFF\">'.git/objects'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'.git/refs/heads'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'.git/refs/tags'</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> dir_path </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> required_dirs:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        assert</span><span style=\"color:#E1E4E8\"> (tmp_path </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> dir_path).is_dir()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Verify HEAD file contents</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    head_content </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (tmp_path </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> '.git/HEAD'</span><span style=\"color:#E1E4E8\">).read_text().strip()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    assert</span><span style=\"color:#E1E4E8\"> head_content </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> 'ref: refs/heads/master'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Verify repository can be reopened</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    repo2 </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Repository(tmp_path)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    assert</span><span style=\"color:#E1E4E8\"> repo2.git_dir </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> tmp_path </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> '.git'</span></span></code></pre></div>\n\n<h4 id=\"common-development-pitfalls\">Common Development Pitfalls</h4>\n<p>⚠️ <strong>Pitfall: Binary vs Text File Handling</strong>\nGit objects contain binary data (especially the null bytes in object headers), but many file operations default to text mode. Always open object files in binary mode (<code>&#39;rb&#39;</code>, <code>&#39;wb&#39;</code>) and use <code>bytes</code> objects for all content handling.</p>\n<p>⚠️ <strong>Pitfall: Platform Path Differences</strong>\nGit uses forward slashes for paths internally, but your implementation runs on different operating systems. Use <code>pathlib.Path</code> for all path manipulation and normalize paths when storing them in Git objects.</p>\n<p>⚠️ <strong>Pitfall: Hash Encoding Confusion</strong>\nSHA-1 hashes appear in three forms: binary (20 bytes), hex string (40 chars), and hex bytes (40 bytes). Be explicit about which format you&#39;re using and convert consistently using <code>.digest()</code>, <code>.hexdigest()</code>, and <code>.encode()</code>.</p>\n<p>⚠️ <strong>Pitfall: Directory Creation Race Conditions</strong>\nWhen multiple Git operations run simultaneously, directory creation can fail if another process creates the directory first. Use <code>mkdir(parents=True, exist_ok=True)</code> to handle this gracefully.</p>\n<h4 id=\"language-specific-hints-for-python\">Language-Specific Hints for Python</h4>\n<p><strong>File I/O Patterns:</strong></p>\n<ul>\n<li>Use <code>with open(path, &#39;rb&#39;) as f:</code> for all object file operations</li>\n<li>Use <code>Path.read_bytes()</code> and <code>Path.write_bytes()</code> for simple file operations</li>\n<li>Use <code>os.makedirs(path, exist_ok=True)</code> for directory creation</li>\n</ul>\n<p><strong>Binary Data Handling:</strong></p>\n<ul>\n<li>Use <code>struct.pack()</code> and <code>struct.unpack()</code> for binary index format</li>\n<li>Use <code>bytes.join()</code> for concatenating binary data</li>\n<li>Use <code>.encode(&#39;utf-8&#39;)</code> and <code>.decode(&#39;utf-8&#39;)</code> for string/bytes conversion</li>\n</ul>\n<p><strong>Error Handling:</strong></p>\n<ul>\n<li>Catch <code>FileNotFoundError</code> for missing objects and references</li>\n<li>Catch <code>OSError</code> for file system permission issues</li>\n<li>Use custom exception classes like <code>ObjectNotFoundError</code> for Git-specific errors</li>\n</ul>\n<p>This implementation foundation provides the scaffolding needed for all eight milestones. The modular structure allows you to implement components incrementally while maintaining clean separation of concerns. The utility functions handle cross-cutting concerns like hashing and path manipulation consistently across the entire codebase.</p>\n<h2 id=\"goals-and-non-goals\">Goals and Non-Goals</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section establishes the scope and boundaries for all eight milestones, from repository initialization through three-way merging</p>\n</blockquote>\n<p>Building a complete Git implementation requires making deliberate choices about what to include and what to exclude. Git itself has evolved over nearly two decades and includes hundreds of commands, optimization strategies, and edge case handling that would overwhelm any learning project. Our implementation focuses on the core mechanisms that make Git fundamentally different from other version control systems: content-addressable storage, immutable object graphs, and distributed merge capabilities.</p>\n<p>The key insight driving our scope decisions is that Git&#39;s power comes from a small set of elegant primitives that compose to create sophisticated behaviors. By implementing these primitives correctly, we gain deep understanding of how modern version control systems work at their foundation. Advanced features like remote synchronization, pack file compression, and complex merge strategies are all built on top of these same primitives.</p>\n<h3 id=\"functional-goals\">Functional Goals</h3>\n<p>Our Git implementation will support eight core operations that demonstrate the fundamental principles of content-addressable version control. These operations form a complete workflow from repository creation through collaborative development scenarios.</p>\n<p><strong>Repository Lifecycle Management:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Operation</th>\n<th>Command</th>\n<th>Purpose</th>\n<th>Key Learning</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Repository Initialization</td>\n<td><code>Repository.init()</code></td>\n<td>Create <code>.git</code> directory structure with proper permissions and default configuration</td>\n<td>Understanding Git&#39;s on-disk layout and reference system initialization</td>\n</tr>\n<tr>\n<td>Repository Discovery</td>\n<td><code>find_git_directory()</code></td>\n<td>Locate the nearest <code>.git</code> directory by traversing parent directories</td>\n<td>How Git commands work from any subdirectory within a repository</td>\n</tr>\n</tbody></table>\n<p>The repository lifecycle operations establish the workspace where all other Git operations occur. Repository initialization demonstrates how Git creates its internal data structures, while repository discovery shows how Git maintains context across the entire project directory tree.</p>\n<p><strong>Content Storage and Retrieval:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Operation</th>\n<th>Command</th>\n<th>Purpose</th>\n<th>Key Learning</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Blob Storage</td>\n<td><code>hash-object</code></td>\n<td>Compute SHA-1 hash and store file contents as compressed blob objects</td>\n<td>Content-addressable storage principles and object deduplication</td>\n</tr>\n<tr>\n<td>Object Retrieval</td>\n<td><code>cat-file</code></td>\n<td>Decompress and display stored objects by their hash</td>\n<td>How immutable objects enable reliable content addressing</td>\n</tr>\n<tr>\n<td>Tree Creation</td>\n<td><code>write-tree</code></td>\n<td>Build tree objects representing directory structure from staged files</td>\n<td>Hierarchical directory representation using object references</td>\n</tr>\n<tr>\n<td>Tree Inspection</td>\n<td><code>ls-tree</code></td>\n<td>Display tree object contents showing file modes, types, and hashes</td>\n<td>Understanding how Git tracks file metadata and permissions</td>\n</tr>\n</tbody></table>\n<p>Content operations form the foundation of Git&#39;s storage model. These operations demonstrate how Git transforms the familiar file system metaphor into an immutable, cryptographically-verified object store. The progression from individual file storage (blobs) to directory structure representation (trees) shows how Git builds complex data from simple primitives.</p>\n<p><strong>History and Version Management:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Operation</th>\n<th>Command</th>\n<th>Purpose</th>\n<th>Key Learning</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Commit Creation</td>\n<td><code>commit-tree</code></td>\n<td>Create commit objects linking trees with metadata and parent pointers</td>\n<td>How immutable history is built through directed acyclic graph structure</td>\n</tr>\n<tr>\n<td>History Traversal</td>\n<td>Navigate parent commit chains</td>\n<td>Follow commit links to reconstruct project history</td>\n<td>Understanding Git&#39;s approach to temporal relationships between versions</td>\n</tr>\n</tbody></table>\n<p>History management operations demonstrate how Git creates tamper-evident project timelines. Unlike systems that store differences between versions, Git stores complete snapshots linked by cryptographic hashes, making history manipulation detectable and enabling powerful analysis capabilities.</p>\n<p><strong>Branch and Reference Management:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Operation</th>\n<th>Command</th>\n<th>Purpose</th>\n<th>Key Learning</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Branch Creation</td>\n<td>Create files in <code>.git/refs/heads/</code></td>\n<td>Associate human-readable names with commit hashes</td>\n<td>How Git provides convenient aliases for navigating object graph</td>\n</tr>\n<tr>\n<td>Branch Switching</td>\n<td>Update <code>HEAD</code> reference</td>\n<td>Change working directory context to different branch tip</td>\n<td>Understanding symbolic references and detached HEAD states</td>\n</tr>\n<tr>\n<td>Reference Resolution</td>\n<td>Resolve symbolic and direct references</td>\n<td>Convert branch names to specific commit hashes</td>\n<td>How Git maintains consistency between human naming and content addressing</td>\n</tr>\n</tbody></table>\n<p>Reference operations bridge the gap between Git&#39;s cryptographic object model and human workflow needs. These operations show how Git maintains the benefits of content-addressable storage while providing familiar branch-based development patterns.</p>\n<p><strong>Staging and Workflow Management:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Operation</th>\n<th>Command</th>\n<th>Purpose</th>\n<th>Key Learning</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>File Staging</td>\n<td><code>add</code></td>\n<td>Move files from working directory to staging area with blob creation</td>\n<td>Understanding Git&#39;s three-tree architecture and incremental commit preparation</td>\n</tr>\n<tr>\n<td>Status Calculation</td>\n<td><code>status</code></td>\n<td>Compare working directory, index, and HEAD to show modification states</td>\n<td>How Git efficiently detects changes across multiple contexts</td>\n</tr>\n<tr>\n<td>Index Management</td>\n<td>Binary <code>.git/index</code> file operations</td>\n<td>Maintain sorted list of staged files with metadata caching</td>\n<td>Git&#39;s approach to performance optimization through cached file information</td>\n</tr>\n</tbody></table>\n<p>Staging operations demonstrate Git&#39;s unique three-stage workflow that separates file modification, commit preparation, and history recording. This separation enables precise control over what changes enter the permanent record and supports complex development workflows.</p>\n<p><strong>Change Analysis and Comparison:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Operation</th>\n<th>Command</th>\n<th>Purpose</th>\n<th>Key Learning</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Difference Calculation</td>\n<td><code>diff</code></td>\n<td>Compute line-by-line changes between file versions using Myers algorithm</td>\n<td>Understanding how version control systems analyze and present textual changes</td>\n</tr>\n<tr>\n<td>Unified Diff Output</td>\n<td>Generate standard diff format</td>\n<td>Present changes in human-readable format with context lines and hunk headers</td>\n<td>Industry-standard approaches to change visualization</td>\n</tr>\n</tbody></table>\n<p>Difference calculation operations reveal how Git analyzes changes between versions. Understanding diff algorithms provides insight into how all version control systems approach the fundamental problem of change detection and presentation.</p>\n<p><strong>Collaborative Development Support:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Operation</th>\n<th>Command</th>\n<th>Purpose</th>\n<th>Key Learning</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Three-Way Merge</td>\n<td><code>merge</code></td>\n<td>Combine changes from two branches using common ancestor as merge base</td>\n<td>Understanding Git&#39;s approach to collaborative development and conflict resolution</td>\n</tr>\n<tr>\n<td>Merge Base Calculation</td>\n<td>Find lowest common ancestor</td>\n<td>Identify the optimal point for comparing divergent development lines</td>\n<td>Graph algorithms applied to version control history</td>\n</tr>\n<tr>\n<td>Conflict Detection</td>\n<td>Identify overlapping changes</td>\n<td>Recognize when automatic merging is impossible and manual resolution is required</td>\n<td>How version control systems handle ambiguous merge scenarios</td>\n</tr>\n</tbody></table>\n<p>Merge operations demonstrate Git&#39;s most sophisticated collaborative features. Three-way merging shows how distributed version control systems enable independent development while maintaining the ability to recombine work systematically.</p>\n<blockquote>\n<p><strong>Design Insight</strong>: These eight operation categories form a complete development workflow while teaching the core principles that make Git unique: content addressing, immutable history, three-tree architecture, and systematic merge handling. Each operation builds on primitives established in previous operations, creating a natural learning progression.</p>\n</blockquote>\n<h3 id=\"explicit-non-goals\">Explicit Non-Goals</h3>\n<p>Our implementation deliberately excludes advanced Git features that, while important for production use, would distract from learning the core principles. These exclusions allow us to focus on fundamental concepts without getting lost in optimization details or edge case handling.</p>\n<p><strong>Remote Repository Operations:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Excluded Feature</th>\n<th>Rationale</th>\n<th>Learning Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>clone</code>, <code>fetch</code>, <code>push</code>, <code>pull</code></td>\n<td>Remote operations require network protocols, authentication, and synchronization strategies</td>\n<td>These are applications of local Git primitives rather than fundamental storage concepts</td>\n</tr>\n<tr>\n<td>SSH/HTTPS transport protocols</td>\n<td>Protocol implementation involves security, networking, and error handling unrelated to version control</td>\n<td>Understanding local operations provides foundation for later network protocol study</td>\n</tr>\n<tr>\n<td>Remote reference tracking</td>\n<td>Tracking multiple remote repositories adds complexity without teaching core storage principles</td>\n<td>Local branch operations demonstrate the same reference management concepts</td>\n</tr>\n</tbody></table>\n<p>Remote operations, while essential for collaborative development, are fundamentally applications of the local operations we do implement. Understanding how Git stores and manipulates objects locally provides the foundation needed to later understand how those same objects are synchronized across repositories.</p>\n<p><strong>Performance Optimizations:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Excluded Feature</th>\n<th>Rationale</th>\n<th>Learning Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Pack files and delta compression</td>\n<td>Pack files are storage optimizations that obscure the object model during learning</td>\n<td>Understanding individual object storage first makes pack file optimizations more meaningful later</td>\n</tr>\n<tr>\n<td>Index version 2+ extensions</td>\n<td>Newer index formats add performance features without changing fundamental staging concepts</td>\n<td>Learning basic index operations provides foundation for understanding extensions</td>\n</tr>\n<tr>\n<td>Parallel object processing</td>\n<td>Concurrency optimizations complicate core algorithm understanding</td>\n<td>Sequential implementations are easier to debug and understand during learning</td>\n</tr>\n<tr>\n<td>Memory-mapped file access</td>\n<td>Low-level optimizations distract from high-level version control concepts</td>\n<td>Standard file I/O demonstrates the same concepts with clearer code</td>\n</tr>\n</tbody></table>\n<p>Performance optimizations, while crucial for large repositories, often obscure the underlying algorithms during initial learning. Our implementation prioritizes clarity and correctness over performance, making the fundamental concepts more accessible.</p>\n<blockquote>\n<p><strong>Critical Exclusion Rationale</strong>: Pack files deserve special mention as they represent one of Git&#39;s most important optimizations. However, pack files are essentially a compression layer over the object model we do implement. Learning individual object storage first provides the conceptual foundation needed to understand why pack files exist and how they work.</p>\n</blockquote>\n<p><strong>Advanced Merge and Conflict Resolution:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Excluded Feature</th>\n<th>Rationale</th>\n<th>Learning Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Octopus merges (more than two parents)</td>\n<td>Multiple parent merges are rare and don&#39;t teach additional concepts beyond two-parent merging</td>\n<td>Two-parent merges demonstrate all the fundamental merge base and conflict resolution concepts</td>\n</tr>\n<tr>\n<td>Rename detection during merge</td>\n<td>Rename tracking requires sophisticated file similarity algorithms</td>\n<td>File-level merging demonstrates core three-way merge concepts without algorithmic complexity</td>\n</tr>\n<tr>\n<td>Advanced merge strategies (<code>subtree</code>, <code>ours</code>, <code>theirs</code>)</td>\n<td>Alternative merge strategies are specialized tools for specific workflows</td>\n<td>Standard recursive three-way merge teaches the fundamental merge principles</td>\n</tr>\n<tr>\n<td>Interactive conflict resolution</td>\n<td>User interface concerns distract from merge algorithm understanding</td>\n<td>Conflict marker generation demonstrates conflict detection principles</td>\n</tr>\n</tbody></table>\n<p>Advanced merge features solve specific workflow problems but don&#39;t teach additional fundamental concepts beyond three-way merging with conflict detection. Our implementation covers the core merge principles that underlie all of Git&#39;s merge strategies.</p>\n<p><strong>Extended Object Model Features:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Excluded Feature</th>\n<th>Rationale</th>\n<th>Learning Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Annotated tags</td>\n<td>Tags are references with additional metadata, not fundamental object types</td>\n<td>Basic reference handling demonstrates the same storage and retrieval concepts</td>\n</tr>\n<tr>\n<td>Signed commits and tags</td>\n<td>Cryptographic signatures are security features independent of version control concepts</td>\n<td>Object integrity through SHA-1 hashing demonstrates core verification principles</td>\n</tr>\n<tr>\n<td>Git attributes and filters</td>\n<td>Content filtering is a layer above the object model</td>\n<td>Understanding basic object storage provides foundation for filter comprehension</td>\n</tr>\n<tr>\n<td>Submodules</td>\n<td>Submodules are repository composition features built on basic Git operations</td>\n<td>Core repository operations demonstrate the primitives submodules use</td>\n</tr>\n</tbody></table>\n<p>Extended object model features are important for production workflows but are built using the same storage primitives we do implement. Understanding blob, tree, and commit objects provides the foundation for understanding how these extensions work.</p>\n<p><strong>File System and Platform Features:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Excluded Feature</th>\n<th>Rationale</th>\n<th>Learning Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Symbolic link handling</td>\n<td>Platform-specific file system features add complexity without teaching version control concepts</td>\n<td>Regular file handling demonstrates core content tracking principles</td>\n</tr>\n<tr>\n<td>File permission preservation</td>\n<td>File metadata tracking is important but secondary to content versioning concepts</td>\n<td>Basic mode bits demonstrate metadata handling without platform complexity</td>\n</tr>\n<tr>\n<td>Large file support (LFS)</td>\n<td>Large files require external storage systems beyond Git&#39;s scope</td>\n<td>Understanding regular file storage shows why large file extensions exist</td>\n</tr>\n<tr>\n<td>Cross-platform line ending handling</td>\n<td>Text file normalization is important but orthogonal to version control storage</td>\n<td>Binary content handling demonstrates core storage without text processing complexity</td>\n</tr>\n</tbody></table>\n<p>File system integration features solve important practical problems but don&#39;t teach the fundamental version control concepts that make Git unique. Our implementation focuses on the storage and merge algorithms that form Git&#39;s conceptual core.</p>\n<p><strong>Configuration and User Interface:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Excluded Feature</th>\n<th>Rationale</th>\n<th>Learning Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Global and local configuration files</td>\n<td>Configuration management is important but separate from core version control algorithms</td>\n<td>Hardcoded defaults allow focus on storage and merge logic</td>\n</tr>\n<tr>\n<td>Command-line argument parsing</td>\n<td>User interface concerns distract from algorithmic understanding</td>\n<td>Direct function calls demonstrate algorithm behavior more clearly</td>\n</tr>\n<tr>\n<td>Error message localization</td>\n<td>User experience features don&#39;t teach version control concepts</td>\n<td>Simple error messages focus attention on understanding failure modes</td>\n</tr>\n<tr>\n<td>Interactive staging (<code>add -p</code>)</td>\n<td>User interface features for workflow convenience</td>\n<td>Basic staging demonstrates the fundamental three-tree architecture</td>\n</tr>\n</tbody></table>\n<p>Configuration and interface features improve user experience but don&#39;t teach the fundamental algorithms that make version control systems work. Our implementation uses direct function calls and simple interfaces to keep focus on the core concepts.</p>\n<blockquote>\n<p><strong>Architecture Decision: Scope Boundary Principle</strong></p>\n<ul>\n<li><strong>Context</strong>: Git includes hundreds of features accumulated over decades of development, making complete implementation impractical for learning</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>Implement minimal subset (init, add, commit only)</li>\n<li>Implement core workflow with basic collaboration (our choice)</li>\n<li>Attempt complete Git compatibility</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Implement complete local workflow plus basic three-way merging</li>\n<li><strong>Rationale</strong>: This scope teaches all fundamental Git concepts (content addressing, immutable history, three-tree architecture, collaborative merging) without overwhelming complexity. Each operation builds naturally on previous ones, creating clear learning progression.</li>\n<li><strong>Consequences</strong>: Learners understand Git&#39;s conceptual foundation and can later study advanced features with solid grounding. Implementation remains manageable while covering realistic development workflows.</li>\n</ul>\n</blockquote>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>Building a Git implementation requires careful technology choices and project organization to manage complexity while maintaining focus on core learning objectives. The following recommendations balance educational value with practical implementation concerns.</p>\n<p><strong>A. Technology Recommendations:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>SHA-1 Hashing</td>\n<td><code>hashlib.sha1()</code> built-in library</td>\n<td>Custom SHA-1 implementation for deeper understanding</td>\n</tr>\n<tr>\n<td>File Compression</td>\n<td><code>zlib</code> standard library for object compression</td>\n<td>Custom compression algorithms</td>\n</tr>\n<tr>\n<td>Binary Parsing</td>\n<td><code>struct</code> module for index file format</td>\n<td>Custom binary serialization framework</td>\n</tr>\n<tr>\n<td>File System Operations</td>\n<td><code>pathlib.Path</code> for cross-platform path handling</td>\n<td>Direct <code>os</code> module calls with manual path construction</td>\n</tr>\n<tr>\n<td>Diff Algorithm</td>\n<td>Myers algorithm implementation from scratch</td>\n<td>External diff library (<code>difflib</code> for validation)</td>\n</tr>\n<tr>\n<td>Command Interface</td>\n<td>Direct function calls for simplicity</td>\n<td>Full command-line parser (<code>argparse</code>)</td>\n</tr>\n</tbody></table>\n<p>The simple options provide clear, focused implementations that highlight the core concepts without unnecessary complexity. Advanced options are available for learners who want deeper understanding of specific components.</p>\n<p><strong>B. Recommended File Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>build-your-own-git/\n├── git/\n│   ├── __init__.py\n│   ├── repository.py          # Repository class and initialization\n│   ├── objects/\n│   │   ├── __init__.py\n│   │   ├── blob.py           # Blob object handling\n│   │   ├── tree.py           # Tree object creation and parsing\n│   │   ├── commit.py         # Commit object operations\n│   │   └── store.py          # Object store implementation\n│   ├── refs/\n│   │   ├── __init__.py\n│   │   ├── reference.py      # Reference resolution and management\n│   │   └── symbolic.py       # HEAD and symbolic reference handling\n│   ├── index/\n│   │   ├── __init__.py\n│   │   ├── staging.py        # Add and remove operations\n│   │   └── status.py         # Status calculation\n│   ├── diff/\n│   │   ├── __init__.py\n│   │   ├── myers.py          # Myers diff algorithm\n│   │   └── unified.py        # Unified diff output formatting\n│   └── merge/\n│       ├── __init__.py\n│       ├── three_way.py      # Three-way merge implementation\n│       └── conflicts.py      # Conflict detection and marking\n├── tests/\n│   ├── test_repository.py\n│   ├── test_objects.py\n│   ├── test_refs.py\n│   ├── test_index.py\n│   ├── test_diff.py\n│   └── test_merge.py\n├── examples/\n│   ├── basic_workflow.py     # Demonstrates typical Git workflow\n│   └── merge_scenario.py     # Shows merge and conflict resolution\n└── README.md</code></pre></div>\n\n<p>This structure separates concerns logically while keeping related functionality together. Each major component lives in its own module with clear dependencies between layers.</p>\n<p><strong>C. Infrastructure Starter Code:</strong></p>\n<p><strong>Repository Discovery and Initialization</strong> (Complete implementation):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># git/repository.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> os</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> Repository</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Represents a Git repository with working directory and git directory.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, git_dir: Path, work_tree: Path):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.git_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_dir</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.work_tree </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> work_tree</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">classmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> init</span><span style=\"color:#E1E4E8\">(cls, path: Path) -> </span><span style=\"color:#9ECBFF\">'Repository'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Initialize a new Git repository at the given path.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        git_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> path </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> '.git'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Create directory structure</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        git_dir.mkdir(</span><span style=\"color:#FFAB70\">exist_ok</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        (git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> 'objects'</span><span style=\"color:#E1E4E8\">).mkdir(</span><span style=\"color:#FFAB70\">exist_ok</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        (git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> 'refs'</span><span style=\"color:#F97583\"> /</span><span style=\"color:#9ECBFF\"> 'heads'</span><span style=\"color:#E1E4E8\">).mkdir(</span><span style=\"color:#FFAB70\">parents</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">exist_ok</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        (git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> 'refs'</span><span style=\"color:#F97583\"> /</span><span style=\"color:#9ECBFF\"> 'tags'</span><span style=\"color:#E1E4E8\">).mkdir(</span><span style=\"color:#FFAB70\">exist_ok</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Create HEAD file pointing to default branch</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        head_file </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> 'HEAD'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        head_file.write_text(</span><span style=\"color:#9ECBFF\">'ref: refs/heads/master</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Create basic config</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        config_file </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> 'config'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        config_content </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"\"\"[core]</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    repositoryformatversion = 0</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    filemode = true</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    bare = false</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        config_file.write_text(config_content)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> cls</span><span style=\"color:#E1E4E8\">(git_dir, path)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> object_path_from_hash</span><span style=\"color:#E1E4E8\">(self, object_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Path:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Convert SHA-1 hash to object file path.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> 'objects'</span><span style=\"color:#F97583\"> /</span><span style=\"color:#E1E4E8\"> object_hash[:</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> object_hash[</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">:]</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> find_git_directory</span><span style=\"color:#E1E4E8\">(start_path: Path) -> Optional[Path]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Find .git directory by walking up the directory tree.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    current </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> start_path.resolve()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    while</span><span style=\"color:#E1E4E8\"> current </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> current.parent:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        git_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> current </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> '.git'</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> git_dir.is_dir():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> git_dir</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        current </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> current.parent</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> None</span></span></code></pre></div>\n\n<p><strong>SHA-1 and Object Hashing Utilities</strong> (Complete implementation):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># git/objects/store.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> hashlib</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> zlib</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Constants</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">SHA1_HEX_LENGTH</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 40</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">OBJECT_HEADER_FORMAT</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> '</span><span style=\"color:#79B8FF\">{type}</span><span style=\"color:#79B8FF\"> {size}\\0{content}</span><span style=\"color:#9ECBFF\">'</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> compute_sha1</span><span style=\"color:#E1E4E8\">(content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Compute SHA-1 hash of raw bytes, returning hex string.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> hashlib.sha1(content).hexdigest()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> compute_object_hash</span><span style=\"color:#E1E4E8\">(object_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Compute Git object hash with proper header.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    header </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">object_type</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#79B8FF\"> {len</span><span style=\"color:#E1E4E8\">(content)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">.encode() </span><span style=\"color:#F97583\">+</span><span style=\"color:#F97583\"> b</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\0</span><span style=\"color:#9ECBFF\">'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    full_content </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> header </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> content</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> compute_sha1(full_content)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> store_object</span><span style=\"color:#E1E4E8\">(git_dir: Path, object_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Store a Git object and return its hash.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    object_hash </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> compute_object_hash(object_type, content)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Create object file path</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    obj_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> 'objects'</span><span style=\"color:#F97583\"> /</span><span style=\"color:#E1E4E8\"> object_hash[:</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    obj_dir.mkdir(</span><span style=\"color:#FFAB70\">exist_ok</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    obj_file </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> obj_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> object_hash[</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">:]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Write compressed object</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    header </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">object_type</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#79B8FF\"> {len</span><span style=\"color:#E1E4E8\">(content)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">.encode() </span><span style=\"color:#F97583\">+</span><span style=\"color:#F97583\"> b</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\0</span><span style=\"color:#9ECBFF\">'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    full_content </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> header </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> content</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    compressed </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> zlib.compress(full_content)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    obj_file.write_bytes(compressed)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> object_hash</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> load_object</span><span style=\"color:#E1E4E8\">(git_dir: Path, object_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Load and decompress a Git object, returning (type, content).\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    obj_file </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> 'objects'</span><span style=\"color:#F97583\"> /</span><span style=\"color:#E1E4E8\"> object_hash[:</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> object_hash[</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">:]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> obj_file.exists():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Object </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">object_hash</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> not found\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Read and decompress</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    compressed </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> obj_file.read_bytes()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    decompressed </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> zlib.decompress(compressed)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Parse header</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    null_index </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> decompressed.find(</span><span style=\"color:#F97583\">b</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\0</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    header </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> decompressed[:null_index].decode()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    content </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> decompressed[null_index </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">:]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    object_type, size_str </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> header.split(</span><span style=\"color:#9ECBFF\">' '</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    expected_size </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> int</span><span style=\"color:#E1E4E8\">(size_str)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(content) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> expected_size:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Object </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">object_hash</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> has incorrect size\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> object_type, content</span></span></code></pre></div>\n\n<p><strong>D. Core Logic Skeleton Code:</strong></p>\n<p><strong>Blob Operations</strong> (signatures with detailed TODOs):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># git/objects/blob.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> hash_object</span><span style=\"color:#E1E4E8\">(file_path: Path, git_dir: Path) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Hash a file and store it as a blob object.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns the SHA-1 hash of the stored blob.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Read file content as bytes (handle both text and binary files)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Use store_object() with object_type='blob' and file content</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return the computed hash</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: Git treats all files as binary data, don't decode as text</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> cat_file_blob</span><span style=\"color:#E1E4E8\">(object_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, git_dir: Path) -> </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Retrieve and return blob content by hash.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Use load_object() to get object type and content</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Verify object_type is 'blob', raise error if not</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return the raw content bytes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: This is the reverse of hash_object - just extract content</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span></code></pre></div>\n\n<p><strong>Tree Operations</strong> (signatures with detailed TODOs):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># git/objects/tree.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Tuple</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">TreeEntry </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]  </span><span style=\"color:#6A737D\"># (mode, name, hash)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> create_tree_from_index</span><span style=\"color:#E1E4E8\">(index_entries: List[</span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">], git_dir: Path) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Create tree object from staged index entries.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns the hash of the created tree object.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Sort index entries by name (Git requires lexicographic order)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: For each entry, format as: mode + ' ' + name + '\\0' + binary_hash</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Handle subdirectories by recursively creating tree objects</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Use store_object() with object_type='tree' and formatted content</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return the computed tree hash</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: Binary hash is bytes.fromhex(hash_string) - not the hex string!</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> parse_tree_object</span><span style=\"color:#E1E4E8\">(tree_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, git_dir: Path) -> List[TreeEntry]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Parse tree object and return list of (mode, name, hash) entries.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Use load_object() to get tree content</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Parse binary tree format: mode + ' ' + name + '\\0' + 20_byte_hash</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Convert each entry to (mode, name, hex_hash) tuple</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return sorted list of entries</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: Use content.find(b'\\0') to locate null bytes between name and hash</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> ls_tree</span><span style=\"color:#E1E4E8\">(tree_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, git_dir: Path) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Display tree contents in human-readable format.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Use parse_tree_object() to get entries</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: For each entry, determine object type (blob vs tree) from mode</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Print in format: mode object_type hash name</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Mode 40000 = tree, 100644 = regular file, 100755 = executable</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: You can also load each referenced object to verify its type</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span></code></pre></div>\n\n<p><strong>E. Language-Specific Hints:</strong></p>\n<p><strong>Python-Specific Implementation Tips:</strong></p>\n<ul>\n<li>Use <code>pathlib.Path</code> consistently for all file system operations - it handles cross-platform path differences automatically</li>\n<li>The <code>hashlib.sha1()</code> function requires bytes input, not strings - use <code>.encode()</code> for text content</li>\n<li>For binary file operations, always use <code>&#39;rb&#39;</code> and <code>&#39;wb&#39;</code> modes to avoid text encoding issues</li>\n<li>Use <code>struct.pack()</code> and <code>struct.unpack()</code> for binary data formats like the index file</li>\n<li>The <code>zlib.compress()</code> and <code>zlib.decompress()</code> functions handle Git&#39;s object compression transparently</li>\n<li>Use <code>os.stat()</code> to get file modification times and permissions for index entries</li>\n<li>Handle both relative and absolute paths using <code>Path.resolve()</code> to avoid confusion</li>\n</ul>\n<p><strong>Common Python Pitfalls:</strong></p>\n<p>⚠️ <strong>Pitfall: String vs Bytes Confusion</strong>\nMany Git formats use binary data, but Python 3 distinguishes strings (Unicode) from bytes. Always use bytes for:</p>\n<ul>\n<li>File content when hashing</li>\n<li>SHA-1 hash computation  </li>\n<li>Compressed object storage</li>\n<li>Binary parts of index file format</li>\n</ul>\n<p>Use strings only for:</p>\n<ul>\n<li>Hash values in hex format</li>\n<li>File paths and names</li>\n<li>Text content when displaying to user</li>\n</ul>\n<p>⚠️ <strong>Pitfall: Path Handling</strong>\nDon&#39;t use string concatenation for file paths - use <code>Path</code> objects:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Wrong: path + '/' + filename</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Right: path / filename</span></span></code></pre></div>\n\n<p>The <code>Path</code> class handles platform differences and prevents common path-related bugs.</p>\n<p><strong>F. Milestone Checkpoints:</strong></p>\n<p>After implementing each milestone, verify functionality with these specific tests:</p>\n<p><strong>Milestone 1-2 Checkpoint (Repository + Blob Objects):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test repository initialization</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">repo </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Repository.init(Path(</span><span style=\"color:#9ECBFF\">'./test-repo'</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">assert</span><span style=\"color:#E1E4E8\"> (repo.git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> 'objects'</span><span style=\"color:#E1E4E8\">).exists()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">assert</span><span style=\"color:#E1E4E8\"> (repo.git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> 'HEAD'</span><span style=\"color:#E1E4E8\">).read_text().strip() </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> 'ref: refs/heads/master'</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test blob storage and retrieval  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">test_content </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> b</span><span style=\"color:#9ECBFF\">\"Hello, Git!\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">blob_hash </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> hash_object_from_content(test_content, repo.git_dir)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">retrieved </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> cat_file_blob(blob_hash, repo.git_dir)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">assert</span><span style=\"color:#E1E4E8\"> retrieved </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> test_content</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"✓ Blob hash: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">blob_hash</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p>Expected output: 40-character hex hash that matches running <code>echo &quot;Hello, Git!&quot; | git hash-object --stdin</code> in real Git.</p>\n<p><strong>Milestone 3-4 Checkpoint (Trees + Commits):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Create a simple tree and commit</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">entries </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    {</span><span style=\"color:#9ECBFF\">'mode'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'100644'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'name'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'README.md'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'hash'</span><span style=\"color:#E1E4E8\">: readme_blob_hash},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    {</span><span style=\"color:#9ECBFF\">'mode'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'100644'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'name'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'main.py'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'hash'</span><span style=\"color:#E1E4E8\">: main_blob_hash}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">tree_hash </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> create_tree_from_entries(entries, repo.git_dir)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">commit_hash </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> create_commit(tree_hash, [], </span><span style=\"color:#9ECBFF\">\"Initial commit\"</span><span style=\"color:#E1E4E8\">, repo.git_dir)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Verify tree parsing</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">tree_entries </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> parse_tree_object(tree_hash, repo.git_dir)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">assert</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(tree_entries) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 2</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"✓ Tree: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">tree_hash</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"✓ Commit: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">commit_hash</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p><strong>G. Debugging Tips:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Hash mismatch with real Git</td>\n<td>Incorrect object format or missing null bytes</td>\n<td>Compare hex dump of your object vs Git&#39;s object</td>\n<td>Check header format: <code>{type} {size}\\0{content}</code></td>\n</tr>\n<tr>\n<td>&quot;Object not found&quot; errors</td>\n<td>Wrong path calculation or hash format</td>\n<td>Print object file paths and verify they exist</td>\n<td>Ensure hash[:2] directory exists before creating file</td>\n</tr>\n<tr>\n<td>Compression errors</td>\n<td>Storing uncompressed data or wrong compression level</td>\n<td>Try decompressing stored objects manually</td>\n<td>Use <code>zlib.compress()</code> with default settings</td>\n</tr>\n<tr>\n<td>Index corruption</td>\n<td>Incorrect binary format or endianness</td>\n<td>Hex dump the index file and compare to spec</td>\n<td>Use <code>struct.pack(&#39;&gt;I&#39;, value)</code> for big-endian integers</td>\n</tr>\n<tr>\n<td>Tree parsing failures</td>\n<td>Binary hash vs hex hash confusion</td>\n<td>Check if hash storage is 20 bytes or 40 chars</td>\n<td>Store binary: <code>bytes.fromhex(hash_string)</code></td>\n</tr>\n<tr>\n<td>Merge infinite loops</td>\n<td>Cycle in commit graph or incorrect parent following</td>\n<td>Trace parent chain manually and look for cycles</td>\n<td>Add visited set to prevent infinite recursion</td>\n</tr>\n</tbody></table>\n<p>The most common debugging approach is comparing your implementation&#39;s output with real Git using identical input. Git&#39;s object format is precisely specified, so byte-for-byte comparison reveals implementation errors quickly.</p>\n<h2 id=\"high-level-architecture\">High-Level Architecture</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section provides the architectural foundation for all milestones, with particular emphasis on Milestone 1 (Repository Initialization) and the component separation needed for Milestones 2-8</p>\n</blockquote>\n<p>The architecture of our Git implementation follows a clean separation of concerns across four distinct layers, each with well-defined responsibilities and interfaces. Understanding this architectural foundation is crucial because Git&#39;s power emerges from the elegant interaction between these components, particularly how they all coordinate through the content-addressable object store.</p>\n<p><img src=\"/api/project/build-git/architecture-doc/asset?path=diagrams%2Fsystem-architecture.svg\" alt=\"Git System Architecture\"></p>\n<h3 id=\"system-components\">System Components</h3>\n<p>The Git system architecture consists of four primary components that work together to provide version control functionality. Each component has distinct responsibilities and maintains its own data structures, but they interact through well-defined interfaces to create a cohesive system.</p>\n<h4 id=\"object-store-the-immutable-foundation\">Object Store: The Immutable Foundation</h4>\n<p>The <strong>Object Store</strong> serves as the foundational layer of our Git implementation, providing content-addressable storage for all repository data. Think of it as a digital warehouse where every item has a unique barcode derived from its contents - you can store something once and retrieve it forever using that barcode, with mathematical certainty that the contents haven&#39;t changed.</p>\n<p>The Object Store manages three critical responsibilities: storing Git objects with SHA-1 hash-based addressing, providing immutable content retrieval, and maintaining data integrity through cryptographic verification. Every piece of content that enters Git - whether it&#39;s a file, directory structure, or commit metadata - gets processed through this layer and becomes permanently addressable by its hash.</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Responsibility</th>\n<th>Data Managed</th>\n<th>Interface Methods</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Object Store</td>\n<td>Content-addressable storage</td>\n<td>Blobs, trees, commits</td>\n<td><code>store_object()</code>, <code>retrieve_object()</code>, <code>object_exists()</code>, <code>list_objects()</code></td>\n</tr>\n<tr>\n<td>Index</td>\n<td>Staging area management</td>\n<td>File metadata and hashes</td>\n<td><code>add_file()</code>, <code>remove_file()</code>, <code>get_status()</code>, <code>write_tree()</code></td>\n</tr>\n<tr>\n<td>References</td>\n<td>Branch and tag management</td>\n<td>Commit pointers</td>\n<td><code>create_branch()</code>, <code>update_ref()</code>, <code>resolve_ref()</code>, <code>list_refs()</code></td>\n</tr>\n<tr>\n<td>Working Directory</td>\n<td>File system interface</td>\n<td>Current project files</td>\n<td><code>checkout_files()</code>, <code>scan_changes()</code>, <code>apply_diff()</code></td>\n</tr>\n</tbody></table>\n<p>The Object Store&#39;s design centers around three core data structures that represent different types of content. <strong>Blob objects</strong> store file content as immutable byte sequences, with each blob identified by the SHA-1 hash of its contents. <strong>Tree objects</strong> represent directory structures, containing sorted lists of file and subdirectory entries with their corresponding hashes. <strong>Commit objects</strong> capture project snapshots, linking to a tree hash and containing metadata about the change.</p>\n<blockquote>\n<p><strong>Key Insight</strong>: The Object Store&#39;s immutability is what enables Git&#39;s powerful features. Because objects never change once stored, operations like branching, merging, and history traversal become safe and efficient. Multiple branches can share the same objects without fear of interference.</p>\n</blockquote>\n<p><strong>Object Store Data Structures:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Object Type</th>\n<th>Header Format</th>\n<th>Content Structure</th>\n<th>Key Properties</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Blob</td>\n<td><code>blob {size}\\0</code></td>\n<td>Raw file bytes</td>\n<td>Content-addressed, immutable</td>\n</tr>\n<tr>\n<td>Tree</td>\n<td><code>tree {size}\\0</code></td>\n<td>Sorted entries: <code>{mode} {name}\\0{hash}</code></td>\n<td>Directory representation</td>\n</tr>\n<tr>\n<td>Commit</td>\n<td><code>commit {size}\\0</code></td>\n<td>Tree hash, parents, author, message</td>\n<td>Links project snapshots</td>\n</tr>\n</tbody></table>\n<p>The Object Store implements a simple but effective storage algorithm. When storing an object, it first computes the SHA-1 hash of the complete object (header plus content), then compresses the object using zlib compression, and finally stores the compressed data at a file system path derived from the hash. The path structure uses the first two hexadecimal characters of the hash as a directory name, with the remaining 38 characters as the filename.</p>\n<h4 id=\"index-the-staging-area-bridge\">Index: The Staging Area Bridge</h4>\n<p>The <strong>Index</strong> acts as an intermediate layer between the working directory and the object store, implementing Git&#39;s distinctive staging area concept. Picture it as a photographer&#39;s contact sheet - a place where you arrange and review your shots before committing to the final print. The Index allows developers to incrementally prepare commits by selectively staging changes.</p>\n<p>The Index maintains a binary file at <code>.git/index</code> that contains metadata about staged files, including their object hashes, file system timestamps, and permission modes. This metadata enables Git to quickly detect when files have been modified since they were last staged, without needing to re-hash file contents on every status check.</p>\n<p><strong>Index Entry Structure:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Size</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Create Time</td>\n<td>8 bytes</td>\n<td>uint64</td>\n<td>File creation timestamp</td>\n</tr>\n<tr>\n<td>Modify Time</td>\n<td>8 bytes</td>\n<td>uint64</td>\n<td>File modification timestamp</td>\n</tr>\n<tr>\n<td>Device ID</td>\n<td>4 bytes</td>\n<td>uint32</td>\n<td>File system device identifier</td>\n</tr>\n<tr>\n<td>Inode</td>\n<td>4 bytes</td>\n<td>uint32</td>\n<td>File system inode number</td>\n</tr>\n<tr>\n<td>Mode</td>\n<td>4 bytes</td>\n<td>uint32</td>\n<td>File permissions and type</td>\n</tr>\n<tr>\n<td>UID</td>\n<td>4 bytes</td>\n<td>uint32</td>\n<td>Owner user identifier</td>\n</tr>\n<tr>\n<td>GID</td>\n<td>4 bytes</td>\n<td>uint32</td>\n<td>Owner group identifier</td>\n</tr>\n<tr>\n<td>File Size</td>\n<td>4 bytes</td>\n<td>uint32</td>\n<td>Size of file in bytes</td>\n</tr>\n<tr>\n<td>SHA-1 Hash</td>\n<td>20 bytes</td>\n<td>bytes</td>\n<td>Object hash of file contents</td>\n</tr>\n<tr>\n<td>Flags</td>\n<td>2 bytes</td>\n<td>uint16</td>\n<td>Name length and stage flags</td>\n</tr>\n<tr>\n<td>Path Name</td>\n<td>Variable</td>\n<td>UTF-8 string</td>\n<td>Relative path from repository root</td>\n</tr>\n</tbody></table>\n<p>The Index enables the three-way status calculation that shows users what changes are staged, unstaged, or untracked. It compares file timestamps and sizes between the working directory, index, and HEAD commit to efficiently determine file states without expensive hash computations for unchanged files.</p>\n<h4 id=\"references-the-human-readable-navigation-system\">References: The Human-Readable Navigation System</h4>\n<p>The <strong>References</strong> component provides human-readable names for commits, implementing Git&#39;s branch and tag system. Think of references as bookmarks in a vast library - instead of memorizing long SHA-1 hashes, you can use meaningful names like &quot;main&quot; or &quot;feature-login&quot; to navigate your project&#39;s history.</p>\n<p>References are stored as simple text files in the <code>.git/refs</code> directory hierarchy. Branch references live in <code>.git/refs/heads/</code>, tag references in <code>.git/refs/tags/</code>, and remote references in <code>.git/refs/remotes/</code>. Each reference file contains a single line with either a commit hash (direct reference) or a reference to another reference (symbolic reference).</p>\n<p><strong>Reference Types:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Reference Type</th>\n<th>Storage Location</th>\n<th>Content Format</th>\n<th>Example</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Branch</td>\n<td><code>.git/refs/heads/{name}</code></td>\n<td>SHA-1 hash</td>\n<td><code>a1b2c3d4e5f6...</code></td>\n</tr>\n<tr>\n<td>Tag</td>\n<td><code>.git/refs/tags/{name}</code></td>\n<td>SHA-1 hash or tag object</td>\n<td><code>a1b2c3d4e5f6...</code></td>\n</tr>\n<tr>\n<td>HEAD</td>\n<td><code>.git/HEAD</code></td>\n<td>Symbolic or direct ref</td>\n<td><code>ref: refs/heads/main</code></td>\n</tr>\n<tr>\n<td>Detached HEAD</td>\n<td><code>.git/HEAD</code></td>\n<td>Direct SHA-1 hash</td>\n<td><code>a1b2c3d4e5f6...</code></td>\n</tr>\n</tbody></table>\n<p>The HEAD reference deserves special attention as it tracks the current branch or commit. In normal operation, HEAD contains a symbolic reference like <code>ref: refs/heads/main</code>, indicating that commits should advance the main branch. In detached HEAD state, HEAD contains a direct commit hash, meaning commits won&#39;t advance any branch.</p>\n<blockquote>\n<p><strong>Design Decision</strong>: References use the file system as their storage layer rather than the object store. This allows atomic updates through file system operations and makes references easily readable by external tools, while keeping them separate from the immutable object history.</p>\n</blockquote>\n<h4 id=\"working-directory-the-user-interface-layer\">Working Directory: The User Interface Layer</h4>\n<p>The <strong>Working Directory</strong> represents the file system view of your project, containing the actual files that users edit and build. It serves as the interface between Git&#39;s internal data structures and the user&#39;s development workflow. The Working Directory component is responsible for checking out files from the object store, detecting changes, and applying updates from commits.</p>\n<p>The Working Directory maintains no persistent state of its own - it&#39;s purely a projection of some commit&#39;s tree structure onto the file system. However, it provides crucial functionality for detecting modifications, handling file permissions, and managing the checkout process when switching between branches or commits.</p>\n<p><strong>Working Directory Operations:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Operation</th>\n<th>Input</th>\n<th>Output</th>\n<th>Side Effects</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Checkout</td>\n<td>Tree hash</td>\n<td>File system changes</td>\n<td>Updates working files</td>\n</tr>\n<tr>\n<td>Scan Changes</td>\n<td>File paths</td>\n<td>Modified file list</td>\n<td>None</td>\n</tr>\n<tr>\n<td>Apply Diff</td>\n<td>Diff patches</td>\n<td>File modifications</td>\n<td>Updates working files</td>\n</tr>\n<tr>\n<td>Clean</td>\n<td>None</td>\n<td>Status report</td>\n<td>Removes untracked files</td>\n</tr>\n</tbody></table>\n<p>The Working Directory implements change detection through file system metadata comparison. By comparing modification times, file sizes, and inode numbers against the Index&#39;s cached values, it can quickly identify potentially modified files. Only files that appear changed need to be re-hashed to determine if their content actually differs.</p>\n<h3 id=\"recommended-file-structure\">Recommended File Structure</h3>\n<p>Organizing the codebase to mirror the architectural layers makes the system easier to understand, test, and maintain. Each component should have its own module with clear boundaries and minimal dependencies. The following structure separates concerns while enabling the necessary interactions between components.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>git_implementation/\n├── core/\n│   ├── __init__.py              # Core package exports\n│   ├── repository.py            # Repository class and initialization\n│   ├── hash_utils.py            # SHA-1 computation utilities\n│   └── constants.py             # Shared constants and formats\n├── objects/\n│   ├── __init__.py              # Object store package\n│   ├── store.py                 # Object storage and retrieval\n│   ├── blob.py                  # Blob object implementation\n│   ├── tree.py                  # Tree object implementation\n│   ├── commit.py                # Commit object implementation\n│   └── serialization.py         # Object serialization/parsing\n├── index/\n│   ├── __init__.py              # Index package\n│   ├── staging.py               # Index file management\n│   ├── status.py                # Status calculation logic\n│   └── binary_format.py         # Index binary format handling\n├── refs/\n│   ├── __init__.py              # References package\n│   ├── manager.py               # Reference CRUD operations\n│   ├── symbolic.py              # Symbolic reference handling\n│   └── head.py                  # HEAD reference management\n├── working_dir/\n│   ├── __init__.py              # Working directory package\n│   ├── checkout.py              # File checkout operations\n│   ├── scanner.py               # Change detection\n│   └── filesystem.py           # File system utilities\n├── algorithms/\n│   ├── __init__.py              # Algorithms package\n│   ├── diff.py                  # Myers diff implementation\n│   ├── merge.py                 # Three-way merge logic\n│   └── merge_base.py            # Common ancestor calculation\n├── commands/\n│   ├── __init__.py              # Commands package\n│   ├── init.py                  # git init implementation\n│   ├── add.py                   # git add implementation\n│   ├── commit.py                # git commit implementation\n│   ├── branch.py                # git branch implementation\n│   ├── merge.py                 # git merge implementation\n│   └── status.py                # git status implementation\n├── tests/\n│   ├── test_objects/            # Object store tests\n│   ├── test_index/              # Index tests\n│   ├── test_refs/               # References tests\n│   ├── test_algorithms/         # Algorithm tests\n│   └── integration/             # End-to-end tests\n└── main.py                      # CLI entry point</code></pre></div>\n\n<p>This structure provides several important benefits for learners and maintainers. The separation between <code>objects/</code>, <code>index/</code>, <code>refs/</code>, and <code>working_dir/</code> mirrors the architectural components, making it easy to understand where functionality belongs. The <code>algorithms/</code> package isolates complex logic like diff and merge, which can be tested independently. The <code>commands/</code> package provides a clean CLI interface without mixing user interaction with core logic.</p>\n<p><strong>Module Dependencies and Interfaces:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Module</th>\n<th>Direct Dependencies</th>\n<th>Key Interfaces</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>core/</code></td>\n<td>None</td>\n<td><code>Repository</code>, <code>compute_sha1()</code></td>\n</tr>\n<tr>\n<td><code>objects/</code></td>\n<td><code>core/</code></td>\n<td><code>ObjectStore</code>, object type classes</td>\n</tr>\n<tr>\n<td><code>index/</code></td>\n<td><code>core/</code>, <code>objects/</code></td>\n<td><code>Index</code>, <code>IndexEntry</code></td>\n</tr>\n<tr>\n<td><code>refs/</code></td>\n<td><code>core/</code></td>\n<td><code>ReferenceManager</code>, <code>HEAD</code></td>\n</tr>\n<tr>\n<td><code>working_dir/</code></td>\n<td><code>core/</code>, <code>objects/</code></td>\n<td><code>WorkingDirectory</code>, <code>FileScanner</code></td>\n</tr>\n<tr>\n<td><code>algorithms/</code></td>\n<td><code>objects/</code>, <code>index/</code></td>\n<td><code>diff()</code>, <code>merge()</code>, <code>find_merge_base()</code></td>\n</tr>\n<tr>\n<td><code>commands/</code></td>\n<td>All others</td>\n<td>Command implementations</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Architecture Decision Record: Component Isolation</strong></p>\n<ul>\n<li><strong>Context</strong>: Git operations involve complex interactions between object storage, indexing, and file system operations. Poor separation leads to tangled dependencies and difficult testing.</li>\n<li><strong>Options Considered</strong>: Monolithic design, layered architecture, component-based architecture</li>\n<li><strong>Decision</strong>: Component-based architecture with clear interface boundaries</li>\n<li><strong>Rationale</strong>: Each component can be developed and tested independently, interfaces prevent tight coupling, and the design mirrors Git&#39;s actual architecture making it easier to understand</li>\n<li><strong>Consequences</strong>: Enables parallel development of components, requires more upfront design but pays dividends in maintainability, makes debugging easier by isolating failures to specific components</li>\n</ul>\n</blockquote>\n<p>The <code>tests/</code> directory structure mirrors the main codebase, enabling focused testing of each component. Integration tests verify that components work together correctly, while unit tests ensure each component meets its individual contracts. This testing structure supports the milestone-based development approach by allowing verification of each component as it&#39;s built.</p>\n<p><strong>Common Pitfalls in Architecture Organization:</strong></p>\n<p>⚠️ <strong>Pitfall: Circular Dependencies</strong>\nMany learners create circular imports between components, such as the Index importing from References while References import from Index. This happens when components try to directly access each other&#39;s internals rather than going through well-defined interfaces. The fix is to pass dependencies as parameters and use dependency injection rather than direct imports between peer components.</p>\n<p>⚠️ <strong>Pitfall: Mixing CLI Logic with Core Logic</strong>\nAnother common mistake is embedding command-line parsing, user interaction, and error formatting inside the core Git logic. This makes the core components impossible to test and reuse. Keep all user interface concerns in the <code>commands/</code> package, and ensure core components only raise exceptions with structured data that the CLI layer can format appropriately.</p>\n<p>⚠️ <strong>Pitfall: Putting Everything in the Repository Class</strong>\nBeginners often make the <code>Repository</code> class a &quot;god object&quot; that contains all Git functionality. This creates a massive class that&#39;s difficult to test and understand. Instead, the <code>Repository</code> class should be a lightweight coordinator that holds references to the component instances and provides convenience methods that delegate to the appropriate components.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The architectural components should be implemented with clear separation of concerns and well-defined interfaces. This guidance provides the foundational code structure and implementation patterns needed to build each component correctly.</p>\n<p><strong>Technology Recommendations:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Object Storage</td>\n<td>File system + zlib</td>\n<td>LevelDB or SQLite</td>\n</tr>\n<tr>\n<td>Index Format</td>\n<td>Binary struct packing</td>\n<td>Protocol Buffers</td>\n</tr>\n<tr>\n<td>Hash Computation</td>\n<td>hashlib.sha1()</td>\n<td>Custom SHA-1 implementation</td>\n</tr>\n<tr>\n<td>File System Operations</td>\n<td>pathlib.Path</td>\n<td>os.path with error handling</td>\n</tr>\n<tr>\n<td>Compression</td>\n<td>zlib standard library</td>\n<td>LZ4 or custom compression</td>\n</tr>\n</tbody></table>\n<p><strong>Core Infrastructure Code:</strong></p>\n<p>The following provides complete, working implementations of the foundational utilities that all components depend on:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># core/constants.py - Shared constants across all components</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">SHA1_HEX_LENGTH</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 40</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">SHA1_BINARY_LENGTH</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 20</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">OBJECT_HEADER_FORMAT</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"</span><span style=\"color:#79B8FF\">{type}</span><span style=\"color:#79B8FF\"> {size}\\0{content}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Git object types</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">BLOB_TYPE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"blob\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">TREE_TYPE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"tree\"</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">COMMIT_TYPE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"commit\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Index constants</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">INDEX_VERSION</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 2</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">INDEX_HEADER_SIZE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 12</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">INDEX_ENTRY_MIN_SIZE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 62</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># File modes (octal values stored as integers)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">FILE_MODE_REGULAR</span><span style=\"color:#F97583\"> =</span><span style=\"color:#F97583\"> 0o</span><span style=\"color:#79B8FF\">100644</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">FILE_MODE_EXECUTABLE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#F97583\"> 0o</span><span style=\"color:#79B8FF\">100755</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">FILE_MODE_TREE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#F97583\"> 0o</span><span style=\"color:#79B8FF\">040000</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">FILE_MODE_SYMLINK</span><span style=\"color:#F97583\"> =</span><span style=\"color:#F97583\"> 0o</span><span style=\"color:#79B8FF\">120000</span></span></code></pre></div>\n\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># core/hash_utils.py - Complete hash computation utilities</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> hashlib</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#79B8FF\"> bytes</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> compute_sha1</span><span style=\"color:#E1E4E8\">(content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Compute SHA-1 hash of raw bytes, returning hex digest.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    hasher </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> hashlib.sha1()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    hasher.update(content)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> hasher.hexdigest()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> compute_object_hash</span><span style=\"color:#E1E4E8\">(object_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Compute Git object hash including type header.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    header </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">object_type</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#79B8FF\"> {len</span><span style=\"color:#E1E4E8\">(content)</span><span style=\"color:#79B8FF\">}\\0</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">.encode(</span><span style=\"color:#9ECBFF\">'ascii'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    full_content </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> header </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> content</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> compute_sha1(full_content)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> hash_to_path_components</span><span style=\"color:#E1E4E8\">(object_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Convert hash to directory and filename components.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(object_hash) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> SHA1_HEX_LENGTH</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Invalid hash length: </span><span style=\"color:#79B8FF\">{len</span><span style=\"color:#E1E4E8\">(object_hash)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> object_hash[:</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">], object_hash[</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">:]</span></span></code></pre></div>\n\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># core/repository.py - Repository initialization and discovery</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> os</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> Repository</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Represents a Git repository with its working tree and git directory.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, work_tree: Path, git_dir: Path):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.work_tree </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> work_tree.resolve()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.git_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_dir.resolve()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">classmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> init</span><span style=\"color:#E1E4E8\">(cls, path: Path) -> </span><span style=\"color:#9ECBFF\">'Repository'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Initialize a new Git repository at the given path.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create the target directory if it doesn't exist</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Create .git subdirectory structure</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Initialize .git/objects with subdirectories  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Initialize .git/refs/heads and .git/refs/tags directories</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Create initial HEAD file pointing to refs/heads/master</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Create basic config file with repository settings</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Set appropriate permissions on .git directory (0755)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Return Repository instance with work_tree=path and git_dir=path/.git</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> object_path_from_hash</span><span style=\"color:#E1E4E8\">(self, object_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Path:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Convert object hash to file system path.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        dir_name, file_name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> hash_to_path_components(object_hash)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"objects\"</span><span style=\"color:#F97583\"> /</span><span style=\"color:#E1E4E8\"> dir_name </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> file_name</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> find_git_directory</span><span style=\"color:#E1E4E8\">(start_path: Path) -> Optional[Path]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Locate .git directory by walking up the directory tree.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    current </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> start_path.resolve()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    while</span><span style=\"color:#E1E4E8\"> current </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> current.parent:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        git_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> current </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \".git\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> git_dir.is_dir():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> git_dir</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        current </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> current.parent</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> None</span></span></code></pre></div>\n\n<p><strong>Component Interface Skeletons:</strong></p>\n<p>Each major component should implement these interfaces. The skeletons provide method signatures and detailed TODO comments that map to the architectural responsibilities:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># objects/store.py - Object store component skeleton</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> zlib</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional, </span><span style=\"color:#79B8FF\">bytes</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ObjectStore</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Content-addressable storage for Git objects.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, git_dir: Path):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.objects_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"objects\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> store_object</span><span style=\"color:#E1E4E8\">(self, object_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Store an object and return its hash.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Compute object hash using compute_object_hash()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check if object already exists using object_exists()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Create header with format \"{type} {size}\\0\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Combine header and content into full object</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Compress full object using zlib.compress()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Determine storage path using hash_to_path_components()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Create parent directory if it doesn't exist</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Write compressed data to object file atomically</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 9: Set file permissions to 0444 (read-only)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Return the computed hash</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> retrieve_object</span><span style=\"color:#E1E4E8\">(self, object_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Retrieve object content and type by hash.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate hash format and length</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Construct object file path</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Check if object file exists, raise error if not</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Read and decompress object file using zlib.decompress()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Parse header to extract type and size</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Validate content size matches header</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Return tuple of (object_type, content)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> object_exists</span><span style=\"color:#E1E4E8\">(self, object_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Check if object exists in store.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check if object file exists at computed path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>File Structure Creation:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Directory structure creation helper</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> create_git_directory_structure</span><span style=\"color:#E1E4E8\">(git_dir: Path) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Create complete .git directory structure.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    directories_to_create </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        git_dir,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"objects\"</span><span style=\"color:#F97583\"> /</span><span style=\"color:#9ECBFF\"> \"info\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"objects\"</span><span style=\"color:#F97583\"> /</span><span style=\"color:#9ECBFF\"> \"pack\"</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"refs\"</span><span style=\"color:#F97583\"> /</span><span style=\"color:#9ECBFF\"> \"heads\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"refs\"</span><span style=\"color:#F97583\"> /</span><span style=\"color:#9ECBFF\"> \"tags\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"hooks\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> directory </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> directories_to_create:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        directory.mkdir(</span><span style=\"color:#FFAB70\">parents</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">exist_ok</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Set directory permissions to 0755</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        directory.chmod(</span><span style=\"color:#F97583\">0o</span><span style=\"color:#79B8FF\">755</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Create initial HEAD file</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    head_file </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"HEAD\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    head_file.write_text(</span><span style=\"color:#9ECBFF\">\"ref: refs/heads/master</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Create basic config</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    config_file </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"config\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    config_content </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"\"\"[core]</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    repositoryformatversion = 0</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    filemode = true</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    bare = false</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    logallrefupdates = true</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    config_file.write_text(config_content)</span></span></code></pre></div>\n\n<p><strong>Milestone Checkpoints:</strong></p>\n<p>After implementing the basic architecture:</p>\n<ol>\n<li><strong>Repository Initialization Test</strong>: Run <code>Repository.init(Path(&quot;test_repo&quot;))</code> and verify the directory structure:</li>\n</ol>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">   find</span><span style=\"color:#9ECBFF\"> test_repo/.git</span><span style=\"color:#79B8FF\"> -type</span><span style=\"color:#9ECBFF\"> d</span><span style=\"color:#F97583\"> |</span><span style=\"color:#B392F0\"> sort</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">   # Should show: .git, .git/hooks, .git/objects, .git/objects/info, </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">   # .git/objects/pack, .git/refs, .git/refs/heads, .git/refs/tags</span></span></code></pre></div>\n\n<ol start=\"2\">\n<li><strong>Object Store Test</strong>: Store and retrieve a simple blob:</li>\n</ol>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#E1E4E8\">   store </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ObjectStore(Path(</span><span style=\"color:#9ECBFF\">\"test_repo/.git\"</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">   hash1 </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> store.store_object(</span><span style=\"color:#9ECBFF\">\"blob\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">b</span><span style=\"color:#9ECBFF\">\"hello world\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">   obj_type, content </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> store.retrieve_object(hash1) </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">   assert</span><span style=\"color:#E1E4E8\"> obj_type </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> \"blob\"</span><span style=\"color:#F97583\"> and</span><span style=\"color:#E1E4E8\"> content </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> b</span><span style=\"color:#9ECBFF\">\"hello world\"</span></span></code></pre></div>\n\n<ol start=\"3\">\n<li><strong>Component Independence Test</strong>: Each component should be importable and testable in isolation without requiring the others to be fully implemented.</li>\n</ol>\n<p><strong>Debugging Tips:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>&quot;Object not found&quot; errors</td>\n<td>Incorrect path computation</td>\n<td>Print the computed path and check if file exists</td>\n<td>Verify hash_to_path_components() logic</td>\n</tr>\n<tr>\n<td>Permission denied on .git</td>\n<td>Wrong directory permissions</td>\n<td>Check with <code>ls -la .git</code></td>\n<td>Set permissions to 0755 on directories</td>\n</tr>\n<tr>\n<td>Hash mismatches</td>\n<td>Header format incorrect</td>\n<td>Print the raw content being hashed</td>\n<td>Ensure null byte between size and content</td>\n</tr>\n<tr>\n<td>Import errors between components</td>\n<td>Circular dependencies</td>\n<td>Draw dependency graph</td>\n<td>Move shared code to core/, use dependency injection</td>\n</tr>\n</tbody></table>\n<h2 id=\"data-model\">Data Model</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section establishes the data model foundations for Milestone 2 (Object Storage - Blobs), Milestone 3 (Tree Objects), and Milestone 4 (Commit Objects), while providing the conceptual framework for all remaining milestones</p>\n</blockquote>\n<p>The data model forms the heart of Git&#39;s architecture, defining how content is structured, stored, and interconnected within the content-addressable object store. Understanding this model is crucial because every Git operation—from storing a single file to merging complex histories—ultimately manipulates these three fundamental object types and their relationships.</p>\n<p><img src=\"/api/project/build-git/architecture-doc/asset?path=diagrams%2Fobject-model.svg\" alt=\"Git Object Model\"></p>\n<h3 id=\"mental-model-the-universal-content-graph\">Mental Model: The Universal Content Graph</h3>\n<p>Think of Git&#39;s data model as a universal content graph, similar to how Wikipedia represents knowledge. In Wikipedia, articles (like commits) reference other articles and media files (like trees and blobs), creating an interconnected web of information where each piece of content has a unique, permanent address. Just as Wikipedia&#39;s internal links remain valid even when articles are moved or renamed, Git&#39;s objects reference each other through immutable cryptographic addresses that never change.</p>\n<p>The key insight is that Git doesn&#39;t store files and directories the way your operating system does—it stores a graph of content relationships. A commit doesn&#39;t &quot;contain&quot; files; it points to a tree that describes the project structure at that moment in time. That tree doesn&#39;t &quot;contain&quot; files either; it points to blobs that hold the actual content. This indirection enables powerful features: two commits can share the same tree (identical project states), multiple trees can reference the same blob (duplicate files), and the entire history forms a graph where content is automatically deduplicated.</p>\n<p>Consider how this differs from traditional file storage. When you copy a directory, the operating system duplicates all the files. When Git stores multiple commits with identical files, those files exist only once in the object store, referenced by their content hash. This is why Git repositories remain compact despite having complete project history.</p>\n<h3 id=\"git-object-types\">Git Object Types</h3>\n<p>Git&#39;s object model consists of exactly three object types, each serving a specific purpose in representing project content and history. Every object follows the same fundamental structure: a header containing the object type and size, followed by the raw content, with the entire object identified by the SHA-1 hash of this formatted data.</p>\n<blockquote>\n<p><strong>Design Insight:</strong> The three-object model strikes an optimal balance between simplicity and expressiveness. Blobs handle raw content, trees handle directory structure, and commits handle history and metadata. This minimal set can represent arbitrarily complex projects and histories while maintaining Git&#39;s core properties of immutability and content-addressable storage.</p>\n</blockquote>\n<h4 id=\"object-storage-format\">Object Storage Format</h4>\n<p>Every Git object follows a consistent storage format that enables content-addressable lookup and integrity verification. This uniformity allows the object store to handle all three object types through a single storage and retrieval mechanism.</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Format</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Object Header</td>\n<td><code>{type} {size}\\0</code></td>\n<td>Object type string, space, decimal byte count, null terminator</td>\n</tr>\n<tr>\n<td>Object Content</td>\n<td><code>{raw_content}</code></td>\n<td>Type-specific content in binary or text format</td>\n</tr>\n<tr>\n<td>Storage Format</td>\n<td><code>compress(header + content)</code></td>\n<td>Zlib-compressed complete object</td>\n</tr>\n<tr>\n<td>Hash Calculation</td>\n<td><code>sha1(header + content)</code></td>\n<td>SHA-1 of uncompressed object</td>\n</tr>\n<tr>\n<td>File Path</td>\n<td><code>.git/objects/{hash[0:2]}/{hash[2:40]}</code></td>\n<td>First 2 hash chars as directory, remaining 38 as filename</td>\n</tr>\n</tbody></table>\n<p>The hash calculation is performed on the complete uncompressed object (header + content), but the stored file contains the zlib-compressed version. This separation enables efficient storage while maintaining cryptographic integrity verification.</p>\n<blockquote>\n<p><strong>Architecture Decision: Object Header Format</strong></p>\n<ul>\n<li><strong>Context</strong>: Need a way to store different object types in a unified storage system while enabling type identification and content verification</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>Store type as separate metadata file</li>\n<li>Use file extensions to indicate type</li>\n<li>Embed type and size in object content header</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Embed <code>{type} {size}\\0</code> header in each object&#39;s content</li>\n<li><strong>Rationale</strong>: Self-describing objects eliminate metadata synchronization issues, size enables integrity verification, null terminator provides clear binary boundary</li>\n<li><strong>Consequences</strong>: Every object is self-contained and verifiable, but adds small storage overhead for the header</li>\n</ul>\n</blockquote>\n<h4 id=\"blob-objects\">Blob Objects</h4>\n<p>Blob objects store raw file content without any metadata such as filename, permissions, or timestamps. They represent the pure content of files at specific points in time, enabling content deduplication across the entire repository history.</p>\n<table>\n<thead>\n<tr>\n<th>Property</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Purpose</td>\n<td>Store raw file content without filesystem metadata</td>\n</tr>\n<tr>\n<td>Content Format</td>\n<td>Exact byte sequence from the original file</td>\n</tr>\n<tr>\n<td>Deduplication</td>\n<td>Files with identical content share the same blob object</td>\n</tr>\n<tr>\n<td>Size Limits</td>\n<td>Practically unlimited, though performance degrades for very large files</td>\n</tr>\n<tr>\n<td>Binary Handling</td>\n<td>All content treated as binary; no line-ending or encoding conversions</td>\n</tr>\n</tbody></table>\n<p><strong>Blob Object Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Header: &quot;blob {content_length}\\0&quot;\nContent: {raw_file_bytes}</code></pre></div>\n\n<p>The blob hash depends only on content, never on filename or location. This means moving a file without changing its content creates no new objects—the tree changes but the blob remains identical. Similarly, if multiple files in the project have identical content, they share a single blob object.</p>\n<p><strong>Content Handling Considerations:</strong></p>\n<p>Blob objects preserve file content exactly as it exists in the working directory, making no assumptions about text encoding, line endings, or binary formats. This byte-for-byte preservation ensures perfect fidelity when checking out files, but requires careful handling of cross-platform differences at higher levels of the system.</p>\n<table>\n<thead>\n<tr>\n<th>Scenario</th>\n<th>Blob Behavior</th>\n<th>Implications</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Text files with CRLF line endings</td>\n<td>Stored exactly as provided</td>\n<td>Cross-platform checkouts may differ</td>\n</tr>\n<tr>\n<td>Binary files</td>\n<td>Stored as-is with no interpretation</td>\n<td>Perfect preservation of executable and media files</td>\n</tr>\n<tr>\n<td>Empty files</td>\n<td>Creates blob with zero-length content</td>\n<td>Empty files still consume one object in the store</td>\n</tr>\n<tr>\n<td>Large files</td>\n<td>Stored completely in single blob</td>\n<td>No automatic chunking; entire file must fit in memory</td>\n</tr>\n</tbody></table>\n<h4 id=\"tree-objects\">Tree Objects</h4>\n<p>Tree objects represent directory structure at specific points in time, storing sorted lists of files and subdirectories with their associated permissions and object hashes. They provide the hierarchical organization that transforms flat blob storage into recognizable project structure.</p>\n<p><strong>Tree Object Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Header: &quot;tree {content_length}\\0&quot;\nContent: {sorted_tree_entries}</code></pre></div>\n\n<p>Each tree entry follows a specific binary format that packs directory information efficiently while maintaining sort order for consistent hashing:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Format</th>\n<th>Size</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Mode</td>\n<td>ASCII decimal string</td>\n<td>Variable</td>\n<td>Unix file mode (permissions and type)</td>\n</tr>\n<tr>\n<td>Space</td>\n<td>ASCII space character</td>\n<td>1 byte</td>\n<td>Separator between mode and name</td>\n</tr>\n<tr>\n<td>Name</td>\n<td>UTF-8 string</td>\n<td>Variable</td>\n<td>Filename or directory name</td>\n</tr>\n<tr>\n<td>Null Terminator</td>\n<td><code>\\0</code> byte</td>\n<td>1 byte</td>\n<td>Separator between name and hash</td>\n</tr>\n<tr>\n<td>Object Hash</td>\n<td>Raw SHA-1 bytes</td>\n<td>20 bytes</td>\n<td>Binary object hash (not hex-encoded)</td>\n</tr>\n</tbody></table>\n<p><strong>Tree Entry Format:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>{mode} {name}\\0{20_byte_hash}</code></pre></div>\n\n<p>The mode field encodes both file permissions and type information using Unix conventions. Understanding these modes is crucial for preserving file system semantics across different platforms.</p>\n<table>\n<thead>\n<tr>\n<th>Mode</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>100644</code></td>\n<td>Regular file</td>\n<td>Normal file with read/write permissions</td>\n</tr>\n<tr>\n<td><code>100755</code></td>\n<td>Executable file</td>\n<td>File with execute permissions</td>\n</tr>\n<tr>\n<td><code>040000</code></td>\n<td>Directory</td>\n<td>Subdirectory (points to another tree object)</td>\n</tr>\n<tr>\n<td><code>120000</code></td>\n<td>Symbolic link</td>\n<td>Symlink (blob contains link target path)</td>\n</tr>\n<tr>\n<td><code>160000</code></td>\n<td>Git submodule</td>\n<td>Reference to another Git repository</td>\n</tr>\n</tbody></table>\n<p><strong>Sorting Requirements:</strong></p>\n<p>Tree entries must be sorted to ensure consistent hashing across different systems and Git implementations. The sort order treats directory names specially to maintain proper tree structure:</p>\n<ol>\n<li><strong>Primary sort</strong>: Lexicographic order by entry name</li>\n<li><strong>Directory handling</strong>: Directories are sorted as if their names ended with <code>/</code></li>\n<li><strong>Case sensitivity</strong>: Sorting is case-sensitive using byte values</li>\n<li><strong>Locale independence</strong>: Sorting uses binary comparison, not locale-specific rules</li>\n</ol>\n<p>This sorting ensures that the same directory structure always produces the same tree hash, regardless of the order in which files were added to the index.</p>\n<p><strong>Nested Directory Representation:</strong></p>\n<p>Trees handle directory hierarchies through recursive object references. Each subdirectory becomes a separate tree object, referenced by its hash from the parent tree. This creates a tree-of-trees structure that mirrors the directory hierarchy.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>project/\n├── README.md          → blob abc123... (referenced from root tree)\n├── src/               → tree def456... (referenced from root tree)\n│   ├── main.py        → blob ghi789... (referenced from src tree)\n│   └── utils.py       → blob jkl012... (referenced from src tree)\n└── tests/             → tree mno345... (referenced from root tree)\n    └── test_main.py   → blob pqr678... (referenced from tests tree)</code></pre></div>\n\n<p>This structure enables efficient sharing of subtrees between commits. If only <code>README.md</code> changes between commits, the <code>src/</code> and <code>tests/</code> tree objects remain identical and are reused.</p>\n<h4 id=\"commit-objects\">Commit Objects</h4>\n<p>Commit objects capture complete project snapshots along with metadata about when, why, and by whom changes were made. They form the backbone of Git&#39;s history tracking by linking project states into a directed acyclic graph.</p>\n<p><strong>Commit Object Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Header: &quot;commit {content_length}\\0&quot;\nContent: {commit_fields}</code></pre></div>\n\n<p>Commit content consists of structured text fields that provide complete context for each project snapshot:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Format</th>\n<th>Required</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>tree</td>\n<td><code>tree {hash}</code></td>\n<td>Yes</td>\n<td>SHA-1 hash of root tree object</td>\n</tr>\n<tr>\n<td>parent</td>\n<td><code>parent {hash}</code></td>\n<td>No</td>\n<td>SHA-1 hash of parent commit (0 or more)</td>\n</tr>\n<tr>\n<td>author</td>\n<td><code>author {name} &lt;{email}&gt; {timestamp} {timezone}</code></td>\n<td>Yes</td>\n<td>Who created the changes</td>\n</tr>\n<tr>\n<td>committer</td>\n<td><code>committer {name} &lt;{email}&gt; {timestamp} {timezone}</code></td>\n<td>Yes</td>\n<td>Who committed the changes</td>\n</tr>\n<tr>\n<td>blank line</td>\n<td><code>\\n</code></td>\n<td>Yes</td>\n<td>Separates metadata from message</td>\n</tr>\n<tr>\n<td>message</td>\n<td>Free-form text</td>\n<td>Yes</td>\n<td>Commit message (can span multiple lines)</td>\n</tr>\n</tbody></table>\n<p><strong>Example Commit Object Content:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>tree 4b825dc642cb6eb9a060e54bf8d69288fbee4904\nparent 3a1b2c3d4e5f6789abcd0123456789abcdef0123\nauthor John Doe &lt;john@example.com&gt; 1609459200 +0000\ncommitter John Doe &lt;john@example.com&gt; 1609459200 +0000\n\nInitial commit with basic project structure\n\nAdded README.md and basic source code layout</code></pre></div>\n\n<p><strong>Timestamp Format:</strong></p>\n<p>Git stores timestamps as Unix epoch seconds followed by timezone offset. This format enables precise temporal ordering while preserving timezone information for distributed development.</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Format</th>\n<th>Example</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Unix Timestamp</td>\n<td>Decimal seconds since epoch</td>\n<td><code>1609459200</code></td>\n<td>UTC seconds since January 1, 1970</td>\n</tr>\n<tr>\n<td>Timezone Offset</td>\n<td><code>±HHMM</code> format</td>\n<td><code>+0000</code>, <code>-0500</code></td>\n<td>Offset from UTC in hours and minutes</td>\n</tr>\n<tr>\n<td>Complete Format</td>\n<td><code>{timestamp} {offset}</code></td>\n<td><code>1609459200 +0000</code></td>\n<td>Combined timestamp and timezone</td>\n</tr>\n</tbody></table>\n<p>The timezone preservation allows Git to maintain exact temporal context even when commits are created in different timezones, which is crucial for distributed teams.</p>\n<p><strong>Author vs Committer:</strong></p>\n<p>Git distinguishes between the person who authored changes and the person who committed them to the repository. This distinction supports workflows where patches are created by one person and applied by another.</p>\n<table>\n<thead>\n<tr>\n<th>Role</th>\n<th>When Different</th>\n<th>Example Scenario</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Author</td>\n<td>Original creator of changes</td>\n<td>Developer writes patch</td>\n</tr>\n<tr>\n<td>Committer</td>\n<td>Person who applies changes</td>\n<td>Maintainer applies patch to repository</td>\n</tr>\n<tr>\n<td>Same Person</td>\n<td>Direct commits</td>\n<td>Developer commits own work directly</td>\n</tr>\n<tr>\n<td>Automated Systems</td>\n<td>CI/CD commits</td>\n<td>Build system commits generated changes</td>\n</tr>\n</tbody></table>\n<p><strong>Parent References and History Graph:</strong></p>\n<p>Commits link to their predecessors through parent references, creating the history graph that represents project evolution over time. The number of parents determines the commit type:</p>\n<table>\n<thead>\n<tr>\n<th>Parent Count</th>\n<th>Commit Type</th>\n<th>Description</th>\n<th>Graph Implications</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>0</td>\n<td>Initial commit</td>\n<td>First commit in repository</td>\n<td>Root node of history graph</td>\n</tr>\n<tr>\n<td>1</td>\n<td>Normal commit</td>\n<td>Regular development progress</td>\n<td>Linear history segment</td>\n</tr>\n<tr>\n<td>2+</td>\n<td>Merge commit</td>\n<td>Integration of multiple branches</td>\n<td>Graph convergence point</td>\n</tr>\n</tbody></table>\n<p>Multiple parents enable Git to represent complex development histories where feature branches are merged back into main development lines. Each parent hash creates an edge in the commit graph, allowing Git to traverse history in multiple directions.</p>\n<h3 id=\"object-relationships\">Object Relationships</h3>\n<p>The power of Git&#39;s data model emerges from how objects reference each other to form a complete content-addressable graph. These relationships enable efficient storage, robust history tracking, and powerful operations like merging and rebasing.</p>\n<h4 id=\"content-addressable-references\">Content-Addressable References</h4>\n<p>All object references in Git use SHA-1 hashes as addresses, creating a content-addressable system where references are derived from the content they point to. This approach provides several critical properties:</p>\n<table>\n<thead>\n<tr>\n<th>Property</th>\n<th>Description</th>\n<th>Benefits</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Immutability</td>\n<td>Object content cannot change without changing its hash</td>\n<td>History integrity and tamper detection</td>\n</tr>\n<tr>\n<td>Deduplication</td>\n<td>Identical content shares the same hash and storage</td>\n<td>Efficient storage utilization</td>\n</tr>\n<tr>\n<td>Verification</td>\n<td>Hash validates content integrity</td>\n<td>Corruption detection and data consistency</td>\n</tr>\n<tr>\n<td>Location Independence</td>\n<td>Hash works regardless of storage location</td>\n<td>Distributed repository synchronization</td>\n</tr>\n</tbody></table>\n<p>When a commit references a tree, it references the exact content state represented by that tree&#39;s hash. If any file changes, the blob hash changes, which changes the tree hash, which changes the commit hash. This cascade ensures that commit hashes uniquely identify complete project states.</p>\n<h4 id=\"the-complete-reference-graph\">The Complete Reference Graph</h4>\n<p>Git objects form a directed acyclic graph (DAG) where commits point to trees, trees point to blobs and other trees, and commits point to parent commits. Understanding this graph structure is essential for implementing Git operations correctly.</p>\n<p><strong>Reference Flow:</strong></p>\n<ol>\n<li><strong>Commit → Tree</strong>: Each commit references exactly one root tree representing the complete project state</li>\n<li><strong>Tree → Blob/Tree</strong>: Each tree entry references either a blob (file) or another tree (subdirectory)</li>\n<li><strong>Commit → Commit</strong>: Each commit references zero or more parent commits, forming the history graph</li>\n<li><strong>No Circular References</strong>: The graph is acyclic—objects never reference themselves directly or indirectly</li>\n</ol>\n<p><strong>Graph Properties:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Property</th>\n<th>Description</th>\n<th>Implementation Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Directed</td>\n<td>References flow from commits toward content</td>\n<td>History traversal has natural direction</td>\n</tr>\n<tr>\n<td>Acyclic</td>\n<td>No reference cycles exist</td>\n<td>Graph algorithms terminate reliably</td>\n</tr>\n<tr>\n<td>Multi-rooted</td>\n<td>Multiple commits can exist without common ancestors</td>\n<td>Supports repository merging</td>\n</tr>\n<tr>\n<td>Immutable</td>\n<td>Objects never change after creation</td>\n<td>Safe concurrent access without locking</td>\n</tr>\n</tbody></table>\n<h4 id=\"shared-object-references\">Shared Object References</h4>\n<p>One of Git&#39;s most elegant features is automatic content sharing through hash-based references. When multiple objects need to reference identical content, they naturally share the same hash and storage location.</p>\n<p><strong>Blob Sharing Scenarios:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Scenario</th>\n<th>Sharing Mechanism</th>\n<th>Storage Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Duplicate files</td>\n<td>Same content produces identical blob hashes</td>\n<td>Single blob stored regardless of file count</td>\n</tr>\n<tr>\n<td>File copies</td>\n<td>Copying doesn&#39;t change content, shares blob</td>\n<td>Zero storage cost for file copies</td>\n</tr>\n<tr>\n<td>Partial file duplication</td>\n<td>Different files share blob only if completely identical</td>\n<td>No automatic deduplication for similar files</td>\n</tr>\n</tbody></table>\n<p><strong>Tree Sharing Scenarios:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Scenario</th>\n<th>Sharing Mechanism</th>\n<th>Storage Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Unchanged subdirectories</td>\n<td>Same tree structure produces identical hash</td>\n<td>Subtrees shared across commits</td>\n</tr>\n<tr>\n<td>Branch merging</td>\n<td>Common directory states share tree objects</td>\n<td>Efficient merge representation</td>\n</tr>\n<tr>\n<td>File renames within directory</td>\n<td>Tree content unchanged, shares existing tree</td>\n<td>Renames are metadata-only changes</td>\n</tr>\n</tbody></table>\n<p><strong>Commit Graph Sharing:</strong></p>\n<p>Commits share parent references to build the history graph, but the sharing goes deeper. When branches diverge from a common point, they share all ancestor commits, creating efficient representation of parallel development.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>A ← B ← C ← D    (main branch)\n     ↖ E ← F     (feature branch)</code></pre></div>\n\n<p>In this example:</p>\n<ul>\n<li>Commits A and B are shared by both branches</li>\n<li>Commits C,D belong only to main</li>\n<li>Commits E,F belong only to feature</li>\n<li>Storage cost is 6 commits, not 8 (no duplication of A,B)</li>\n</ul>\n<h4 id=\"reference-resolution-and-traversal\">Reference Resolution and Traversal</h4>\n<p>Understanding how to navigate the object graph is crucial for implementing Git operations. Different operations require different traversal patterns through the reference relationships.</p>\n<p><strong>Common Traversal Patterns:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Operation</th>\n<th>Traversal Pattern</th>\n<th>Object Types Accessed</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Checkout</td>\n<td>Commit → Tree → Blobs</td>\n<td>All three types for complete project reconstruction</td>\n</tr>\n<tr>\n<td>Log</td>\n<td>Commit → Parent Commits</td>\n<td>Commits only for history traversal</td>\n</tr>\n<tr>\n<td>Diff</td>\n<td>Commit → Tree, Compare Trees → Blobs</td>\n<td>Commits and trees for comparison, blobs for content diff</td>\n</tr>\n<tr>\n<td>Status</td>\n<td>Working Directory ↔ Index ↔ HEAD</td>\n<td>Trees and blobs for three-way comparison</td>\n</tr>\n</tbody></table>\n<p><strong>Graph Traversal Algorithms:</strong></p>\n<p>Different Git operations require different graph traversal strategies to efficiently access the required objects:</p>\n<table>\n<thead>\n<tr>\n<th>Algorithm</th>\n<th>Use Case</th>\n<th>Traversal Order</th>\n<th>Termination Condition</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Breadth-First Search</td>\n<td>Finding merge base</td>\n<td>Level-by-level commit traversal</td>\n<td>Common ancestor found</td>\n</tr>\n<tr>\n<td>Depth-First Search</td>\n<td>Complete history traversal</td>\n<td>Follow parent chains deeply</td>\n<td>No more parents</td>\n</tr>\n<tr>\n<td>Topological Sort</td>\n<td>Chronological history</td>\n<td>Respect parent-child relationships</td>\n<td>All commits processed</td>\n</tr>\n<tr>\n<td>Tree Recursion</td>\n<td>File system operations</td>\n<td>Directory-first or file-first</td>\n<td>All tree entries processed</td>\n</tr>\n</tbody></table>\n<h4 id=\"object-storage-efficiency\">Object Storage Efficiency</h4>\n<p>The reference relationships enable significant storage efficiencies that make Git practical for large repositories with long histories. Understanding these efficiencies helps appreciate why Git&#39;s approach scales well.</p>\n<p><strong>Deduplication Through References:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Content Type</th>\n<th>Deduplication Level</th>\n<th>Efficiency Gain</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Identical files</td>\n<td>Complete blob sharing</td>\n<td>Near-zero cost for duplicates</td>\n</tr>\n<tr>\n<td>Unchanged directories</td>\n<td>Complete tree sharing</td>\n<td>Subtree reuse across commits</td>\n</tr>\n<tr>\n<td>Common history</td>\n<td>Shared commit ancestors</td>\n<td>Linear growth with unique changes</td>\n</tr>\n<tr>\n<td>Branch points</td>\n<td>Shared parent references</td>\n<td>Efficient parallel development</td>\n</tr>\n</tbody></table>\n<p><strong>Storage Growth Patterns:</strong></p>\n<p>Understanding how repository size grows helps design efficient operations and predict storage requirements:</p>\n<table>\n<thead>\n<tr>\n<th>Change Type</th>\n<th>New Objects Created</th>\n<th>Storage Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Edit single file</td>\n<td>1 blob, 1+ trees, 1 commit</td>\n<td>Proportional to directory depth</td>\n</tr>\n<tr>\n<td>Add new file</td>\n<td>1 blob, 1+ trees, 1 commit</td>\n<td>Same as file edit</td>\n</tr>\n<tr>\n<td>Rename file</td>\n<td>0 blobs, 1+ trees, 1 commit</td>\n<td>Metadata-only change</td>\n</tr>\n<tr>\n<td>Copy file</td>\n<td>0 blobs, 1+ trees, 1 commit</td>\n<td>Blob reuse makes copies free</td>\n</tr>\n</tbody></table>\n<p>This efficiency model explains why Git can maintain complete history with reasonable storage costs—most changes affect only a small portion of the total project content, and unchanged content is automatically shared.</p>\n<h3 id=\"common-pitfalls\">Common Pitfalls</h3>\n<p>⚠️ <strong>Pitfall: Hash Encoding in Tree Objects</strong>\nTree objects store SHA-1 hashes as raw 20-byte binary data, not as 40-character hex strings. This is a frequent source of errors when implementing tree parsing and creation. Using hex encoding doubles the storage size and produces incorrect hash values. Always convert hex hashes to binary using <code>bytes.fromhex()</code> before storing in tree objects, and convert back to hex using <code>.hex()</code> when displaying or comparing hashes.</p>\n<p>⚠️ <strong>Pitfall: Incorrect Object Header Format</strong>\nThe object header must use the exact format <code>{type} {size}\\0{content}</code> with a space between type and size, and a null byte (not newline) after the size. Using incorrect separators or missing the null terminator results in hash mismatches with standard Git. The size must be the decimal byte count of the content portion only, not including the header itself.</p>\n<p>⚠️ <strong>Pitfall: Tree Entry Sorting</strong>\nTree entries must be sorted lexicographically with directories treated as if their names end with <code>/</code>. Incorrect sorting produces different tree hashes for identical directory contents. Use byte-level comparison, not locale-specific string sorting. The sort must be stable and consistent across all platforms to ensure repository compatibility.</p>\n<p>⚠️ <strong>Pitfall: Binary vs Text Content Handling</strong>\nAlways treat object content as binary data, even for text files. Using text mode file operations can corrupt binary content through line-ending conversion or encoding transformations. Open files in binary mode (<code>&#39;rb&#39;</code>, <code>&#39;wb&#39;</code>) and handle encoding explicitly when needed for display purposes.</p>\n<p>⚠️ <strong>Pitfall: Timestamp Format Confusion</strong>\nGit timestamps use Unix epoch seconds with timezone offsets, not local time representations. The format is <code>{seconds_since_epoch} {±HHMM}</code>, where the timezone offset is hours and minutes from UTC. Using local time or incorrect timezone formats breaks chronological ordering and compatibility with standard Git.</p>\n<p>⚠️ <strong>Pitfall: Parent Hash Storage</strong>\nCommit objects can have zero, one, or multiple parent lines, but each parent must be stored as a separate <code>parent {hash}</code> line, not as multiple hashes on a single line. Initial commits have no parent lines, merge commits have multiple parent lines. The order of parent lines affects merge commit interpretation.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Hash Computation</td>\n<td><code>hashlib.sha1()</code> from standard library</td>\n<td>Custom SHA-1 implementation for learning</td>\n</tr>\n<tr>\n<td>Binary Data Handling</td>\n<td><code>bytes</code> type with <code>struct.pack()/unpack()</code></td>\n<td>Custom binary serialization classes</td>\n</tr>\n<tr>\n<td>Object Storage</td>\n<td>Direct file I/O with <code>pathlib.Path</code></td>\n<td>Abstract storage interface supporting multiple backends</td>\n</tr>\n<tr>\n<td>Content Compression</td>\n<td><code>zlib.compress()/decompress()</code> from standard library</td>\n<td>Stream-based compression for large objects</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>git-implementation/\n├── core/\n│   ├── __init__.py\n│   ├── objects.py              ← Object model (this implementation)\n│   │   ├── class GitObject     ← Base object interface\n│   │   ├── class BlobObject    ← Blob implementation\n│   │   ├── class TreeObject    ← Tree implementation  \n│   │   └── class CommitObject  ← Commit implementation\n│   ├── hash_utils.py           ← SHA-1 and object hashing utilities\n│   └── storage.py              ← Object store interface\n├── tests/\n│   ├── test_objects.py         ← Object model tests\n│   └── fixtures/               ← Test data files\n└── examples/\n    └── object_examples.py      ← Usage examples</code></pre></div>\n\n<p>This structure separates the core object model from storage concerns, making it easier to test object creation and parsing independently from file system operations.</p>\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p><strong>Hash Utilities (<code>core/hash_utils.py</code>):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> hashlib</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> zlib</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#79B8FF\"> bytes</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Complete utility functions for object hashing and storage format</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> compute_sha1</span><span style=\"color:#E1E4E8\">(content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Compute SHA-1 hash of raw bytes, returning hex string.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> hashlib.sha1(content).hexdigest()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> compute_object_hash</span><span style=\"color:#E1E4E8\">(object_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Compute Git object hash with proper header format.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    header </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">object_type</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#79B8FF\"> {len</span><span style=\"color:#E1E4E8\">(content)</span><span style=\"color:#79B8FF\">}\\0</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">.encode(</span><span style=\"color:#9ECBFF\">'utf-8'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    full_content </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> header </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> content</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> compute_sha1(full_content)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> format_object_for_storage</span><span style=\"color:#E1E4E8\">(object_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Format object with header and compress for storage.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    header </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">object_type</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#79B8FF\"> {len</span><span style=\"color:#E1E4E8\">(content)</span><span style=\"color:#79B8FF\">}\\0</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">.encode(</span><span style=\"color:#9ECBFF\">'utf-8'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    full_content </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> header </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> content</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> zlib.compress(full_content)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> parse_stored_object</span><span style=\"color:#E1E4E8\">(compressed_data: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Decompress and parse stored object, returning (type, content).\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    decompressed </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> zlib.decompress(compressed_data)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Find null terminator separating header from content</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    null_pos </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> decompressed.find(</span><span style=\"color:#F97583\">b</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\0</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> null_pos </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Invalid object format: no null terminator\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    header </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> decompressed[:null_pos].decode(</span><span style=\"color:#9ECBFF\">'utf-8'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    content </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> decompressed[null_pos </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">:]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Parse header: \"type size\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    header_parts </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> header.split(</span><span style=\"color:#9ECBFF\">' '</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(header_parts) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Invalid header format: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">header</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    object_type, size_str </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> header_parts</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    expected_size </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> int</span><span style=\"color:#E1E4E8\">(size_str)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(content) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> expected_size:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Content size mismatch: expected </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">expected_size</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">, got </span><span style=\"color:#79B8FF\">{len</span><span style=\"color:#E1E4E8\">(content)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> object_type, content</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Constants for object types</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">BLOB_TYPE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"blob\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">TREE_TYPE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"tree\"</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">COMMIT_TYPE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"commit\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">SHA1_HEX_LENGTH</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 40</span></span></code></pre></div>\n\n<p><strong>Object Storage Interface (<code>core/storage.py</code>):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> os</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional, </span><span style=\"color:#79B8FF\">tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .hash_utils </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> format_object_for_storage, parse_stored_object</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ObjectStore</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Handles content-addressable object storage and retrieval.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, objects_dir: Path):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.objects_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> objects_dir</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Ensure objects directory exists</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.objects_dir.mkdir(</span><span style=\"color:#FFAB70\">parents</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">exist_ok</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> object_path_from_hash</span><span style=\"color:#E1E4E8\">(self, object_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Path:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Convert hash to file system path: .git/objects/xx/yy...\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(object_hash) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> SHA1_HEX_LENGTH</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Invalid hash length: </span><span style=\"color:#79B8FF\">{len</span><span style=\"color:#E1E4E8\">(object_hash)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        dir_name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> object_hash[:</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        file_name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> object_hash[</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">:]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.objects_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> dir_name </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> file_name</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> store_object</span><span style=\"color:#E1E4E8\">(self, object_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Store object in content-addressable store, return hash.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Format and compress object</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        compressed_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> format_object_for_storage(object_type, content)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Compute hash for lookup</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        object_hash </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> compute_object_hash(object_type, content)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Determine storage path</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        object_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.object_path_from_hash(object_hash)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Create directory if needed</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        object_path.parent.mkdir(</span><span style=\"color:#FFAB70\">exist_ok</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Write compressed object (only if not already exists)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> object_path.exists():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            object_path.write_bytes(compressed_data)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> object_hash</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> retrieve_object</span><span style=\"color:#E1E4E8\">(self, object_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Retrieve object content and type by hash.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        object_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.object_path_from_hash(object_hash)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> object_path.exists():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> FileNotFoundError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Object </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">object_hash</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> not found\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        compressed_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> object_path.read_bytes()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> parse_stored_object(compressed_data)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> object_exists</span><span style=\"color:#E1E4E8\">(self, object_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Check if object exists in store.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.object_path_from_hash(object_hash).exists()</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeleton-code\">Core Logic Skeleton Code</h4>\n<p><strong>Object Model Base Classes (<code>core/objects.py</code>):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> abc </span><span style=\"color:#F97583\">import</span><span style=\"color:#79B8FF\"> ABC</span><span style=\"color:#E1E4E8\">, abstractmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#79B8FF\"> bytes</span><span style=\"color:#E1E4E8\">, List, Optional, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> struct</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Type aliases for clarity</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">TreeEntry </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]  </span><span style=\"color:#6A737D\"># (mode, name, hash)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> GitObject</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">ABC</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Base class for all Git objects.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.content </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> content</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">property</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @abstractmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> object_type</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Return the Git object type string.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @abstractmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> serialize</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Serialize object content for storage.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">classmethod</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @abstractmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> deserialize</span><span style=\"color:#E1E4E8\">(cls, content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#9ECBFF\">'GitObject'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Create object from stored content.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> compute_hash</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Compute SHA-1 hash of this object.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> compute_object_hash(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.object_type, </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.serialize())</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> BlobObject</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">GitObject</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Git blob object for file content storage.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">(content)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">property</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> object_type</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> BLOB_TYPE</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> serialize</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Serialize blob content - content is stored as-is.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Return the raw content bytes without modification</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Blobs store file content exactly as it exists</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: self.content already contains the file bytes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">classmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> deserialize</span><span style=\"color:#E1E4E8\">(cls, content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#9ECBFF\">'BlobObject'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Create blob from stored content.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create new BlobObject with the provided content</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Blob deserialization is trivial - content is stored as-is</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Simply pass content to constructor</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TreeObject</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">GitObject</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Git tree object for directory structure.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, entries: List[TreeEntry]):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.entries </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> entries</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Sort entries to ensure consistent hashing</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._sort_entries()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._serialize_entries())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">property</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> object_type</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> TREE_TYPE</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _sort_entries</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Sort tree entries according to Git rules.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Sort entries lexicographically by name</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Treat directories as if their names end with '/'</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Use byte-level comparison, not locale-specific sorting</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: key=lambda entry: entry[1] + ('/' if entry[0] == '40000' else '')</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _serialize_entries</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Serialize tree entries to binary format.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: For each entry, format as: {mode} {name}\\0{20-byte-hash}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Mode is ASCII string, name is UTF-8, hash is binary</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Convert hex hash to 20-byte binary using bytes.fromhex()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Concatenate all entries into single bytes object</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use bytes.fromhex() to convert hash from hex to binary</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> serialize</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Serialize tree content.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.content</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">classmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> deserialize</span><span style=\"color:#E1E4E8\">(cls, content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#9ECBFF\">'TreeObject'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Create tree from stored binary content.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        entries </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        pos </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        while</span><span style=\"color:#E1E4E8\"> pos </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(content):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Find space character separating mode from name</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Extract mode as ASCII string</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Find null terminator separating name from hash</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Extract name as UTF-8 string</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Extract next 20 bytes as binary hash</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Convert binary hash to hex string for storage</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Add (mode, name, hex_hash) tuple to entries list</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Advance pos to next entry</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Hint: Use content.find() to locate separators</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> cls</span><span style=\"color:#E1E4E8\">(entries)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> add_entry</span><span style=\"color:#E1E4E8\">(self, mode: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, object_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Add entry to tree and re-sort.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Add new entry tuple to self.entries</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Re-sort entries to maintain Git ordering</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Re-serialize content to update self.content</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Call self._sort_entries() and update self.content</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> CommitObject</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">GitObject</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Git commit object for project snapshots.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, tree_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, parent_hashes: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 author: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, committer: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 author_timestamp: Optional[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 committer_timestamp: Optional[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 timezone: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"+0000\"</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.tree_hash </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> tree_hash</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.parent_hashes </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> parent_hashes</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.author </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> author</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.committer </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> committer</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.message </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> message</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.author_timestamp </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> author_timestamp </span><span style=\"color:#F97583\">or</span><span style=\"color:#79B8FF\"> int</span><span style=\"color:#E1E4E8\">(time.time())</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.committer_timestamp </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> committer_timestamp </span><span style=\"color:#F97583\">or</span><span style=\"color:#79B8FF\"> int</span><span style=\"color:#E1E4E8\">(time.time())</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.timezone </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> timezone</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._serialize_commit())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">property</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> object_type</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> COMMIT_TYPE</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _format_person_line</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, timestamp: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, timezone: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Format author/committer line with timestamp.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Format as: {name} {timestamp} {timezone}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: timestamp is Unix epoch seconds as decimal string</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: timezone is ±HHMM format (e.g., +0000, -0500)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: f\"{name} {timestamp} {timezone}\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _serialize_commit</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Serialize commit to text format.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        lines </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Add tree line: \"tree {hash}\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Add parent lines: \"parent {hash}\" for each parent</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Add author line with formatted timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Add committer line with formatted timestamp  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Add blank line separator</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Add commit message (can be multiple lines)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Join all lines with \\n and encode to UTF-8 bytes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use self._format_person_line() for author/committer</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> serialize</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Serialize commit content.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.content</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">classmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> deserialize</span><span style=\"color:#E1E4E8\">(cls, content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#9ECBFF\">'CommitObject'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Create commit from stored text content.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        text </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> content.decode(</span><span style=\"color:#9ECBFF\">'utf-8'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        lines </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> text.split(</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Parse tree hash from first line</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Parse parent hashes from any \"parent\" lines</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Parse author line and extract name, timestamp, timezone</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Parse committer line and extract name, timestamp, timezone</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Find blank line separating metadata from message</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Extract message as remaining lines after blank line</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Create CommitObject with parsed data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use startswith() to identify line types</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p><strong>After Implementing Blob Objects:</strong></p>\n<ul>\n<li>Create a test file: <code>echo &quot;Hello, Git!&quot; &gt; test.txt</code></li>\n<li>Your implementation should compute the same hash as: <code>git hash-object test.txt</code></li>\n<li>Expected hash: <code>d95f3ad14dee633a758d2e331151e950dd13e4ed</code></li>\n<li>Verify blob content retrieval matches original file exactly</li>\n</ul>\n<p><strong>After Implementing Tree Objects:</strong></p>\n<ul>\n<li>Create a simple directory structure with a few files</li>\n<li>Your tree serialization should produce consistent hashes for identical directory contents</li>\n<li>Test tree entry sorting by creating files in different orders</li>\n<li>Verify nested directories create separate tree objects</li>\n</ul>\n<p><strong>After Implementing Commit Objects:</strong></p>\n<ul>\n<li>Create a commit object with known tree hash and timestamp</li>\n<li>Compare your commit hash with Git&#39;s output for the same tree/parent/message</li>\n<li>Test merge commit with multiple parents</li>\n<li>Verify author/committer timestamp parsing and formatting</li>\n</ul>\n<h4 id=\"debugging-tips\">Debugging Tips</h4>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Hash mismatch with Git</td>\n<td>Incorrect object header format</td>\n<td>Compare byte-by-byte with <code>git cat-file -p</code></td>\n<td>Check header format: <code>{type} {size}\\0{content}</code></td>\n</tr>\n<tr>\n<td>Tree parsing errors</td>\n<td>Binary hash vs hex confusion</td>\n<td>Print hash lengths (should be 20 bytes in tree)</td>\n<td>Use <code>bytes.fromhex()</code> when storing, <code>.hex()</code> when displaying</td>\n</tr>\n<tr>\n<td>Commit timestamp issues</td>\n<td>Wrong timezone format</td>\n<td>Compare with <code>git log --pretty=fuller</code></td>\n<td>Use <code>{timestamp} ±HHMM</code> format</td>\n</tr>\n<tr>\n<td>Object corruption</td>\n<td>Text mode file operations</td>\n<td>Check if binary files are corrupted</td>\n<td>Always use binary mode for file I/O</td>\n</tr>\n<tr>\n<td>Tree entry order wrong</td>\n<td>Incorrect sorting algorithm</td>\n<td>Compare sorted entries with <code>git ls-tree</code></td>\n<td>Sort lexicographically with directory special case</td>\n</tr>\n</tbody></table>\n<h2 id=\"object-store-design\">Object Store Design</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section provides the storage engine foundation for Milestone 2 (Object Storage - Blobs), Milestone 3 (Tree Objects), and Milestone 4 (Commit Objects), establishing the content-addressable storage patterns used throughout all subsequent milestones</p>\n</blockquote>\n<p><img src=\"/api/project/build-git/architecture-doc/asset?path=diagrams%2Fobject-storage-layout.svg\" alt=\"Object Store File Layout\"></p>\n<h3 id=\"mental-model-the-universal-library\">Mental Model: The Universal Library</h3>\n<p>Imagine a vast, magical library where books are never filed by title or author, but instead by their exact content. Every book receives a unique fingerprint derived from every word, punctuation mark, and space within its pages. This fingerprint becomes the book&#39;s permanent address on the shelf. If you know the fingerprint, you can instantly locate any book. If two people write identical books independently, they receive the same fingerprint and occupy the same shelf space—the library automatically deduplicates content.</p>\n<p>This is <strong>content-addressable storage</strong>, the revolutionary concept at Git&#39;s core. Unlike traditional file systems that assign arbitrary names and locations to files, Git computes a cryptographic fingerprint (SHA-1 hash) of each piece of content and uses that fingerprint as both the content&#39;s identifier and storage location. This approach provides several powerful properties that make distributed version control possible.</p>\n<p>The fingerprint is deterministic—the same content always produces the same hash, regardless of when or where it&#39;s computed. This enables perfect deduplication: storing the same file in multiple commits or branches requires no additional space. The fingerprint is also tamper-evident: changing even a single bit of content produces a completely different hash, making corruption or malicious modification immediately detectable.</p>\n<p>In Git&#39;s universal library, every piece of content becomes an <strong>immutable object</strong>. Once stored, objects never change—they can only be referenced by their hash. This immutability enables Git&#39;s powerful branching and merging capabilities: you never lose data by creating branches or switching between them, because every version of every file remains permanently accessible through its unique fingerprint.</p>\n<p>The object store serves as the foundation layer for all Git operations. When you stage a file, Git computes its hash and stores it as a blob object. When you commit changes, Git creates tree objects that organize these blobs into directory structures, then creates a commit object that points to the root tree. Every object is stored once and referenced by its SHA-1 hash throughout the repository.</p>\n<h3 id=\"storage-algorithm\">Storage Algorithm</h3>\n<p>The object storage process transforms arbitrary content into an immutable, verifiable object within Git&#39;s content-addressable store. This multi-step algorithm ensures consistency, integrity, and efficient retrieval across all Git operations.</p>\n<p><strong>Step 1: Object Header Construction</strong></p>\n<p>Git wraps every piece of content with a standardized header before computing its hash. The header follows the format <code>{type} {size}\\0{content}</code> where type is one of <code>blob</code>, <code>tree</code>, or <code>commit</code>, size is the decimal byte count of the raw content, and a null byte separates the header from content. This header serves multiple purposes: it prevents hash collisions between different object types containing identical content, enables type verification during retrieval, and provides size information for memory allocation and corruption detection.</p>\n<p>For a text file containing &quot;Hello, World!&quot; (13 bytes), the complete object becomes <code>blob 13\\0Hello, World!</code> where <code>\\0</code> represents the null byte separator. This formatted object, not just the original content, becomes the input for hash calculation.</p>\n<p><strong>Step 2: SHA-1 Hash Computation</strong></p>\n<p>Git computes the SHA-1 cryptographic hash of the complete formatted object (header plus content) to generate a 160-bit digest, represented as a 40-character hexadecimal string. This hash serves as the object&#39;s immutable identifier throughout its lifetime. The SHA-1 algorithm ensures that identical content produces identical hashes deterministically, while any content modification results in a completely different hash.</p>\n<p>The hash computation must be precise and consistent across all Git implementations. Python&#39;s <code>hashlib.sha1()</code> function provides the standard implementation, accepting the complete object bytes and returning the hexadecimal digest. This hash becomes the object&#39;s permanent name within the repository—it can never be changed without detecting the modification.</p>\n<p><strong>Step 3: Content Compression</strong></p>\n<p>Git compresses every object using the zlib compression algorithm before storage. This compression occurs after hash computation, ensuring the hash reflects the actual content while storage benefits from size reduction. The zlib algorithm typically achieves significant compression ratios for text-based content like source code, documentation, and configuration files commonly stored in version control.</p>\n<p>The compression level balances storage space against compression time. Git uses zlib&#39;s default compression level (6 on a scale of 0-9), providing good compression ratios without excessive CPU overhead during write operations. The compressed data becomes the actual bytes written to the file system.</p>\n<p><strong>Step 4: File System Path Generation</strong></p>\n<p>Git derives the storage path from the object&#39;s SHA-1 hash using a two-level directory structure. The first two hexadecimal characters become the directory name within <code>.git/objects/</code>, while the remaining 38 characters become the filename. This sharding approach distributes objects across multiple directories, preventing performance degradation from storing thousands of files in a single directory.</p>\n<p>For hash <code>a1b2c3d4e5f6789...</code>, the storage path becomes <code>.git/objects/a1/b2c3d4e5f6789...</code>. The directory <code>a1</code> must exist before writing the object file. Most file systems handle directories with hundreds of files efficiently, making this two-level approach sufficient for most repositories.</p>\n<p><strong>Step 5: Atomic File Writing</strong></p>\n<p>Git writes objects atomically to prevent corruption from interrupted operations or concurrent access. The atomic write process creates a temporary file with a unique name in the target directory, writes the compressed object content, ensures data reaches persistent storage through <code>fsync()</code>, then atomically renames the temporary file to the final object name.</p>\n<p>This atomic operation ensures that object files are either completely present and valid or completely absent—partially written objects cannot exist. If a write operation fails at any point, the temporary file can be safely removed without affecting existing repository state.</p>\n<p>The following table details the complete object storage algorithm:</p>\n<table>\n<thead>\n<tr>\n<th>Step</th>\n<th>Operation</th>\n<th>Input</th>\n<th>Output</th>\n<th>Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>Header Construction</td>\n<td><code>(type, content)</code></td>\n<td><code>formatted_object</code></td>\n<td>Standardize object format</td>\n</tr>\n<tr>\n<td>2</td>\n<td>Hash Computation</td>\n<td><code>formatted_object</code></td>\n<td><code>sha1_hash</code></td>\n<td>Generate unique identifier</td>\n</tr>\n<tr>\n<td>3</td>\n<td>Compression</td>\n<td><code>formatted_object</code></td>\n<td><code>compressed_data</code></td>\n<td>Reduce storage space</td>\n</tr>\n<tr>\n<td>4</td>\n<td>Path Generation</td>\n<td><code>sha1_hash</code></td>\n<td><code>file_path</code></td>\n<td>Determine storage location</td>\n</tr>\n<tr>\n<td>5</td>\n<td>Atomic Write</td>\n<td><code>(file_path, compressed_data)</code></td>\n<td><code>stored_object</code></td>\n<td>Persist object safely</td>\n</tr>\n</tbody></table>\n<h3 id=\"retrieval-and-verification\">Retrieval and Verification</h3>\n<p>Object retrieval reverses the storage process, locating objects by their SHA-1 hash and reconstructing the original content with integrity verification. This process must handle missing objects gracefully and detect corruption reliably.</p>\n<p><strong>Hash-to-Path Resolution</strong></p>\n<p>The retrieval process begins by converting the 40-character SHA-1 hash into a file system path using the same sharding logic as storage. The first two characters specify the subdirectory within <code>.git/objects/</code>, and the remaining 38 characters identify the object file. The complete path becomes <code>.git/objects/XX/YYYYYY...</code> where XX and YYYY represent the hash prefix and suffix respectively.</p>\n<p>Before attempting to read the object file, the retrieval system should verify that both the subdirectory and object file exist. Missing subdirectories indicate the object has never been stored, while missing object files within existing subdirectories may indicate corruption or incomplete write operations.</p>\n<p><strong>Decompression and Parsing</strong></p>\n<p>Once located, the object file contains zlib-compressed data that must be decompressed to recover the original formatted object. The decompression operation may fail if the file is corrupted or truncated, requiring appropriate error handling to report repository corruption.</p>\n<p>After successful decompression, the formatted object must be parsed to separate the header from content. The parser locates the null byte separator, extracts the type and size information from the header, then validates that the declared size matches the actual content length. This validation detects various corruption scenarios including truncated objects and header modification.</p>\n<p><strong>Content Verification</strong></p>\n<p>The most critical aspect of object retrieval is verifying that the retrieved content matches its claimed identity. Git recomputes the SHA-1 hash of the decompressed, formatted object and compares it to the hash used for retrieval. Any mismatch indicates corruption and must be treated as a fatal error.</p>\n<p>This verification step provides Git&#39;s fundamental integrity guarantee: if an object can be retrieved successfully, its content is guaranteed to be identical to when it was stored. This property enables distributed collaboration without central authority—every participant can independently verify the integrity of shared history.</p>\n<p>The following table outlines the complete retrieval and verification process:</p>\n<table>\n<thead>\n<tr>\n<th>Operation</th>\n<th>Input</th>\n<th>Process</th>\n<th>Output</th>\n<th>Error Conditions</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Path Resolution</td>\n<td><code>sha1_hash</code></td>\n<td>Split hash into directory/file components</td>\n<td><code>file_path</code></td>\n<td>Invalid hash format</td>\n</tr>\n<tr>\n<td>File Reading</td>\n<td><code>file_path</code></td>\n<td>Read compressed bytes from file system</td>\n<td><code>compressed_data</code></td>\n<td>File not found, permission denied</td>\n</tr>\n<tr>\n<td>Decompression</td>\n<td><code>compressed_data</code></td>\n<td>zlib decompression</td>\n<td><code>formatted_object</code></td>\n<td>Corruption, truncation</td>\n</tr>\n<tr>\n<td>Header Parsing</td>\n<td><code>formatted_object</code></td>\n<td>Extract type, size, content</td>\n<td><code>(type, size, content)</code></td>\n<td>Invalid format, size mismatch</td>\n</tr>\n<tr>\n<td>Hash Verification</td>\n<td><code>formatted_object</code></td>\n<td>Recompute SHA-1, compare to expected</td>\n<td><code>verified_content</code></td>\n<td>Hash mismatch (corruption)</td>\n</tr>\n</tbody></table>\n<p><strong>Error Recovery Strategies</strong></p>\n<p>When object retrieval fails, Git provides several diagnostic capabilities to help identify the root cause. Missing object files typically indicate incomplete repository clones or damaged file systems. Decompression failures suggest file corruption or storage hardware issues. Hash verification failures represent the most serious corruption type, indicating that stored content differs from its claimed identity.</p>\n<p>For missing objects, Git can attempt to retrieve them from alternate object databases (alternates mechanism) or remote repositories. For corrupted objects, no automatic recovery is possible—the object must be restored from backup or reconstructed from other repository copies.</p>\n<h3 id=\"architecture-decision-records\">Architecture Decision Records</h3>\n<p>The object store design involves several critical architecture decisions that fundamentally shape Git&#39;s behavior, performance characteristics, and security properties. Each decision represents careful consideration of trade-offs between competing requirements.</p>\n<blockquote>\n<p><strong>Decision: SHA-1 Hash Algorithm Selection</strong></p>\n<ul>\n<li><strong>Context</strong>: Git requires a cryptographic hash function to generate unique, tamper-evident identifiers for all stored content. The hash function must provide strong collision resistance, fast computation, and consistent cross-platform behavior.</li>\n<li><strong>Options Considered</strong>: MD5 (fast but cryptographically broken), SHA-1 (established but showing weaknesses), SHA-256 (stronger but larger hashes)</li>\n<li><strong>Decision</strong>: SHA-1 for initial implementation, with migration path to SHA-256</li>\n<li><strong>Rationale</strong>: SHA-1 provides adequate collision resistance for version control use cases while maintaining compatibility with existing Git repositories. The 160-bit hash size balances security with storage efficiency. Although theoretical weaknesses exist, practical collision attacks remain extremely difficult and detectable.</li>\n<li><strong>Consequences</strong>: Enables compatibility with existing Git tools and repositories. Provides strong integrity guarantees for typical use cases. May require migration to SHA-256 in future for enhanced security as collision attacks become more practical.</li>\n</ul>\n</blockquote>\n<p>The following table compares the hash algorithm options:</p>\n<table>\n<thead>\n<tr>\n<th>Algorithm</th>\n<th>Digest Size</th>\n<th>Performance</th>\n<th>Collision Resistance</th>\n<th>Compatibility</th>\n<th>Chosen</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>MD5</td>\n<td>128 bits</td>\n<td>Fastest</td>\n<td>Broken</td>\n<td>Legacy only</td>\n<td>❌</td>\n</tr>\n<tr>\n<td>SHA-1</td>\n<td>160 bits</td>\n<td>Fast</td>\n<td>Weakening</td>\n<td>Full Git compatibility</td>\n<td>✅</td>\n</tr>\n<tr>\n<td>SHA-256</td>\n<td>256 bits</td>\n<td>Slower</td>\n<td>Strong</td>\n<td>Limited Git support</td>\n<td>Future</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Two-Level Directory Structure</strong></p>\n<ul>\n<li><strong>Context</strong>: Storing thousands of objects in a single directory causes severe performance degradation on most file systems. The storage structure must distribute objects efficiently while maintaining simple hash-to-path mapping.</li>\n<li><strong>Options Considered</strong>: Single flat directory (simple but slow), two-level sharding (balanced), three-level sharding (complex but scalable)</li>\n<li><strong>Decision</strong>: Two-level directory structure using first two hex characters as directory name</li>\n<li><strong>Rationale</strong>: Provides 256 possible subdirectories, distributing objects evenly across directories. Most repositories contain fewer than 10,000 objects per subdirectory, maintaining good file system performance. Simple mapping algorithm enables fast path computation.</li>\n<li><strong>Consequences</strong>: Excellent performance for repositories of all practical sizes. Simple implementation with minimal complexity overhead. Requires directory pre-creation but provides efficient object distribution.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Structure</th>\n<th>Directories</th>\n<th>Objects per Dir</th>\n<th>Lookup Speed</th>\n<th>Implementation</th>\n<th>Chosen</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Flat</td>\n<td>1</td>\n<td>Unlimited</td>\n<td>Very slow</td>\n<td>Trivial</td>\n<td>❌</td>\n</tr>\n<tr>\n<td>Two-level</td>\n<td>256</td>\n<td>~400 (typical)</td>\n<td>Fast</td>\n<td>Simple</td>\n<td>✅</td>\n</tr>\n<tr>\n<td>Three-level</td>\n<td>4,096</td>\n<td>~25 (typical)</td>\n<td>Fastest</td>\n<td>Complex</td>\n<td>❌</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: zlib Compression Algorithm</strong></p>\n<ul>\n<li><strong>Context</strong>: Version control repositories often contain repetitive text content that compresses well. Compression reduces storage requirements but adds CPU overhead for every object operation.</li>\n<li><strong>Options Considered</strong>: No compression (fast but large), gzip/zlib (balanced), specialized algorithms (complex)</li>\n<li><strong>Decision</strong>: zlib compression with default level (6)</li>\n<li><strong>Rationale</strong>: zlib provides excellent compression ratios for typical source code content while maintaining fast compression/decompression speed. Wide platform availability and mature implementations reduce compatibility risks. Default compression level balances space savings with CPU cost.</li>\n<li><strong>Consequences</strong>: Significant storage space reduction (often 50-80% for text content). Minimal performance impact on modern systems. Universal compatibility across platforms and programming languages.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Algorithm</th>\n<th>Compression Ratio</th>\n<th>Speed</th>\n<th>Availability</th>\n<th>Complexity</th>\n<th>Chosen</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>None</td>\n<td>0%</td>\n<td>Fastest</td>\n<td>Universal</td>\n<td>Minimal</td>\n<td>❌</td>\n</tr>\n<tr>\n<td>zlib (level 6)</td>\n<td>60-80%</td>\n<td>Fast</td>\n<td>Universal</td>\n<td>Low</td>\n<td>✅</td>\n</tr>\n<tr>\n<td>LZMA</td>\n<td>70-85%</td>\n<td>Slow</td>\n<td>Limited</td>\n<td>High</td>\n<td>❌</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Immutable Object Model</strong></p>\n<ul>\n<li><strong>Context</strong>: Version control systems must preserve historical content while enabling efficient storage and reliable integrity verification. Objects could be mutable (updateable) or immutable (write-once).</li>\n<li><strong>Options Considered</strong>: Mutable objects with versioning, immutable objects with content-addressing, hybrid approach with mutable metadata</li>\n<li><strong>Decision</strong>: Fully immutable objects identified by content hash</li>\n<li><strong>Rationale</strong>: Immutability provides strong integrity guarantees—content cannot be modified without detection. Content-addressing enables automatic deduplication and efficient comparison operations. Simplifies concurrent access by eliminating modification conflicts.</li>\n<li><strong>Consequences</strong>: Perfect integrity preservation for historical data. Automatic deduplication across branches and repositories. Simplified concurrency model. Storage growth over time as objects accumulate, requiring periodic cleanup.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>Integrity</th>\n<th>Deduplication</th>\n<th>Concurrency</th>\n<th>Storage Growth</th>\n<th>Chosen</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Mutable</td>\n<td>Moderate</td>\n<td>Manual</td>\n<td>Complex locking</td>\n<td>Controlled</td>\n<td>❌</td>\n</tr>\n<tr>\n<td>Immutable</td>\n<td>Perfect</td>\n<td>Automatic</td>\n<td>Lock-free reads</td>\n<td>Unbounded</td>\n<td>✅</td>\n</tr>\n<tr>\n<td>Hybrid</td>\n<td>Variable</td>\n<td>Partial</td>\n<td>Mixed complexity</td>\n<td>Moderate</td>\n<td>❌</td>\n</tr>\n</tbody></table>\n<h3 id=\"common-pitfalls\">Common Pitfalls</h3>\n<p>Building a content-addressable object store presents several subtle challenges that frequently trip up implementers. Understanding these pitfalls and their solutions is crucial for creating a reliable Git implementation.</p>\n<p>⚠️ <strong>Pitfall: Including Hash in Header During Hash Computation</strong></p>\n<p>Many implementers mistakenly include the object&#39;s SHA-1 hash within the object header when computing the hash, creating an impossible circular dependency. The hash cannot be computed until the complete object is formed, but the object cannot be complete if it includes its own hash.</p>\n<p>Git&#39;s object format includes only the object type and content size in the header, never the hash itself. The hash is computed from the complete formatted object (<code>{type} {size}\\0{content}</code>) and then used separately as the object&#39;s identifier and storage path. The hash never becomes part of the stored object content.</p>\n<p>To avoid this pitfall, ensure your hash computation function receives the complete formatted object without any hash reference, computes the SHA-1 digest, then uses that digest for storage path generation and object identification.</p>\n<p>⚠️ <strong>Pitfall: Hash Computation on Content Only (Excluding Header)</strong></p>\n<p>Some implementations compute the SHA-1 hash using only the raw content bytes, ignoring the type and size header. This approach fails to match Git&#39;s hash computation and can lead to hash collisions between different object types containing identical content.</p>\n<p>Git always computes hashes on the complete formatted object including the header. A blob containing &quot;tree abc&quot; and a tree containing the same bytes produce different hashes because their headers differ (<code>blob 8\\0tree abc</code> vs <code>tree 8\\0tree abc</code>). This separation prevents type confusion attacks and ensures object type integrity.</p>\n<p>Verify your hash computation includes the complete object header by testing with Git&#39;s <code>hash-object</code> command and comparing results. Your implementation must produce identical hashes for identical input.</p>\n<p>⚠️ <strong>Pitfall: Compressing Content Before Hash Computation</strong></p>\n<p>The sequence of hash computation and compression operations is critical but often confused. Computing the hash of compressed content instead of the original formatted object produces incorrect hashes that don&#39;t match Git&#39;s expectations.</p>\n<p>Git&#39;s algorithm always follows this sequence: format object with header, compute SHA-1 hash of formatted object, compress formatted object, store compressed data. The hash reflects the uncompressed content, while storage benefits from compression. This approach allows hash computation without decompression during future retrieval operations.</p>\n<p>Ensure your storage function computes the hash first, stores the hash for later use, then compresses the same formatted object for file system storage.</p>\n<p>⚠️ <strong>Pitfall: Incorrect Directory Creation Permissions</strong></p>\n<p>Object directories within <code>.git/objects/</code> require specific permissions to function correctly across different operating systems and deployment scenarios. Using default directory permissions can cause access failures in shared repository environments.</p>\n<p>Git creates object directories with 0755 permissions (owner read/write/execute, group and other read/execute), ensuring they remain accessible to the repository owner while allowing read access for other authorized users. Execute permission on directories is required for file access within the directory.</p>\n<p>Set directory permissions explicitly using your platform&#39;s appropriate mechanism (<code>os.mkdir(path, 0o755)</code> in Python) rather than relying on default umask behavior.</p>\n<p>⚠️ <strong>Pitfall: Non-Atomic Object Writing</strong></p>\n<p>Writing object files directly to their final location creates a race condition where other processes might read partially written objects, leading to corruption errors. This is particularly problematic during concurrent Git operations or system crashes during writes.</p>\n<p>Git ensures atomicity by writing to temporary files first, then atomically renaming them to the final object name. This approach guarantees that object files are either completely absent or completely valid—partially written objects cannot exist.</p>\n<p>Implement atomic writes using a temporary filename (such as appending <code>.tmp</code> plus process ID), write complete content to the temporary file, sync to disk, then rename to the final object filename.</p>\n<p>⚠️ <strong>Pitfall: Missing fsync() for Durability</strong></p>\n<p>Object files must be durably written to persistent storage before being considered successfully stored. Without explicit synchronization, object data may remain in file system buffers and be lost during system crashes, leading to repository corruption.</p>\n<p>After writing the complete object file, call <code>fsync()</code> (or platform equivalent) to ensure data reaches persistent storage before proceeding. This operation may significantly impact write performance but is essential for repository integrity.</p>\n<p>Include explicit sync operations in your atomic write sequence: write to temporary file, sync temporary file, rename to final name, sync parent directory to ensure directory entry is persistent.</p>\n<p>⚠️ <strong>Pitfall: Inadequate Error Handling During Retrieval</strong></p>\n<p>Object retrieval involves multiple failure modes that require different handling strategies. Treating all retrieval failures identically can mask serious corruption issues or provide misleading error messages to users.</p>\n<p>Distinguish between expected failures (missing objects that haven&#39;t been stored) and unexpected failures (corruption, permission issues, file system errors). Missing objects should be handled gracefully with appropriate user feedback, while corruption should be treated as fatal errors requiring user intervention.</p>\n<p>Implement comprehensive error categorization that identifies the specific failure mode and provides appropriate recovery suggestions for each case.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The object store implementation requires careful attention to file system operations, cryptographic hashing, and data integrity verification. This section provides complete infrastructure code and skeletal implementations for the core learning objectives.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Hashing</td>\n<td><code>hashlib.sha1()</code> (built-in)</td>\n<td><code>cryptography</code> library for future SHA-256</td>\n</tr>\n<tr>\n<td>Compression</td>\n<td><code>zlib</code> module (built-in)</td>\n<td><code>python-lzo</code> for better performance</td>\n</tr>\n<tr>\n<td>File Operations</td>\n<td><code>pathlib.Path</code> + <code>open()</code></td>\n<td><code>os.open()</code> with explicit flags</td>\n</tr>\n<tr>\n<td>Atomic Writes</td>\n<td><code>tempfile</code> + <code>os.rename()</code></td>\n<td>Platform-specific atomic operations</td>\n</tr>\n<tr>\n<td>Directory Creation</td>\n<td><code>os.makedirs()</code></td>\n<td><code>os.mkdir()</code> with explicit permission handling</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>git-implementation/\n  src/\n    git_core/\n      __init__.py\n      objects/                  ← Object store implementation\n        __init__.py\n        store.py               ← ObjectStore class (core learning)\n        types.py               ← GitObject base classes\n        hash.py                ← Hashing utilities (infrastructure)\n        compression.py         ← Compression utilities (infrastructure)\n      repository.py            ← Repository class\n      exceptions.py            ← Git-specific exceptions\n  tests/\n    test_objects/\n      test_store.py            ← Object store tests\n      test_hash.py             ← Hash computation tests\n    fixtures/                  ← Test data files</code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p><strong>Hash Computation Utilities</strong> (<code>src/git_core/objects/hash.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Hash computation utilities for Git objects.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Provides SHA-1 computation with Git's object header format.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> hashlib</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Tuple</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">SHA1_HEX_LENGTH</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 40</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">OBJECT_HEADER_FORMAT</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"</span><span style=\"color:#79B8FF\">{type}</span><span style=\"color:#79B8FF\"> {size}\\0{content}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> compute_sha1</span><span style=\"color:#E1E4E8\">(content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Compute SHA-1 hash of raw bytes, returning hex digest.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> hashlib.sha1(content).hexdigest()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> format_git_object</span><span style=\"color:#E1E4E8\">(object_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Format content with Git object header: '{type} {size}</span><span style=\"color:#79B8FF\">\\\\</span><span style=\"color:#9ECBFF\">0{content}'\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    header </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">object_type</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#79B8FF\"> {len</span><span style=\"color:#E1E4E8\">(content)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> header.encode(</span><span style=\"color:#9ECBFF\">'utf-8'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">+</span><span style=\"color:#F97583\"> b</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\0</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#F97583\"> +</span><span style=\"color:#E1E4E8\"> content</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> compute_object_hash</span><span style=\"color:#E1E4E8\">(object_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Compute Git object hash including type/size header.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    formatted_object </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> format_git_object(object_type, content)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> compute_sha1(formatted_object)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> parse_git_object</span><span style=\"color:#E1E4E8\">(formatted_object: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> Tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Parse formatted Git object, returning (type, size, content).\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    null_index </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> formatted_object.find(</span><span style=\"color:#F97583\">b</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\0</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> null_index </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Invalid Git object: missing null separator\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    header </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> formatted_object[:null_index].decode(</span><span style=\"color:#9ECBFF\">'utf-8'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    content </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> formatted_object[null_index </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">:]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        object_type, size_str </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> header.split(</span><span style=\"color:#9ECBFF\">' '</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        declared_size </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> int</span><span style=\"color:#E1E4E8\">(size_str)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    except</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Invalid Git object header: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">header</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(content) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> declared_size:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Content size mismatch: declared </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">declared_size</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">, actual </span><span style=\"color:#79B8FF\">{len</span><span style=\"color:#E1E4E8\">(content)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> object_type, declared_size, content</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> validate_sha1_hash</span><span style=\"color:#E1E4E8\">(hash_str: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Validate SHA-1 hash format (40 hex characters).\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">len</span><span style=\"color:#E1E4E8\">(hash_str) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> SHA1_HEX_LENGTH</span><span style=\"color:#F97583\"> and</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            all</span><span style=\"color:#E1E4E8\">(c </span><span style=\"color:#F97583\">in</span><span style=\"color:#9ECBFF\"> '0123456789abcdef'</span><span style=\"color:#F97583\"> for</span><span style=\"color:#E1E4E8\"> c </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> hash_str.lower()))</span></span></code></pre></div>\n\n<p><strong>Compression Utilities</strong> (<code>src/git_core/objects/compression.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Compression utilities for Git object storage.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Handles zlib compression/decompression with error handling.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> zlib</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#79B8FF\"> bytes</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">DEFAULT_COMPRESSION_LEVEL</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 6</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> compress_object</span><span style=\"color:#E1E4E8\">(data: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">, level: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> DEFAULT_COMPRESSION_LEVEL</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Compress data using zlib with specified compression level.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> zlib.compress(data, level)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    except</span><span style=\"color:#E1E4E8\"> zlib.error </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Compression failed: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> decompress_object</span><span style=\"color:#E1E4E8\">(compressed_data: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Decompress zlib-compressed data.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> zlib.decompress(compressed_data)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    except</span><span style=\"color:#E1E4E8\"> zlib.error </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Decompression failed: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p><strong>Git Object Types</strong> (<code>src/git_core/objects/types.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Git object type definitions and base classes.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> abc </span><span style=\"color:#F97583\">import</span><span style=\"color:#79B8FF\"> ABC</span><span style=\"color:#E1E4E8\">, abstractmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#79B8FF\"> bytes</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">BLOB_TYPE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"blob\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">TREE_TYPE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"tree\"</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">COMMIT_TYPE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"commit\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> GitObject</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">ABC</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Base class for all Git objects (blob, tree, commit).\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.content </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> content</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">property</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @abstractmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> object_type</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Return the Git object type string.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> compute_hash</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Compute the SHA-1 hash of this object.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        from</span><span style=\"color:#E1E4E8\"> .hash </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> compute_object_hash</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> compute_object_hash(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.object_type, </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.content)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> BlobObject</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">GitObject</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Git blob object representing file content.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">property</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> object_type</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> BLOB_TYPE</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TreeObject</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">GitObject</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Git tree object representing directory structure.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">property</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> object_type</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> TREE_TYPE</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> CommitObject</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">GitObject</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Git commit object representing a project snapshot.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">property</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> object_type</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> COMMIT_TYPE</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeleton-code\">Core Logic Skeleton Code</h4>\n<p><strong>Object Store Implementation</strong> (<code>src/git_core/objects/store.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Git object store implementation.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Core content-addressable storage for Git objects.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> os</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> tempfile</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional, Tuple, </span><span style=\"color:#79B8FF\">bytes</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .hash </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> compute_object_hash, parse_git_object, validate_sha1_hash, format_git_object</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .compression </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> compress_object, decompress_object</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ObjectStore</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Content-addressable storage for Git objects.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, objects_dir: Path):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.objects_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> objects_dir</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._ensure_objects_directory()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _ensure_objects_directory</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Create .git/objects directory structure if it doesn't exist.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create objects_dir with 0o755 permissions if it doesn't exist</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Create info/ and pack/ subdirectories for Git compatibility</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use os.makedirs() with exist_ok=True</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> object_path_from_hash</span><span style=\"color:#E1E4E8\">(self, object_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Path:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Convert SHA-1 hash to file system path in objects directory.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate hash format using validate_sha1_hash()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Split hash into directory (first 2 chars) and filename (remaining 38)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return Path to .git/objects/XX/YYYYYYYY...</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: hash[:2] gives first 2 characters, hash[2:] gives remainder</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> store_object</span><span style=\"color:#E1E4E8\">(self, object_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Store object in content-addressable store, return SHA-1 hash.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Format object with header using format_git_object()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Compute SHA-1 hash of formatted object</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Compress formatted object using compress_object()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Generate storage path from hash using object_path_from_hash()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Create parent directory if it doesn't exist (with 0o755 permissions)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Write compressed data atomically using _write_object_file()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Return computed SHA-1 hash</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Atomic write prevents corruption from interrupted operations</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> retrieve_object</span><span style=\"color:#E1E4E8\">(self, object_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Retrieve object by hash, return (object_type, content).\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate hash format</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Generate file path from hash</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Check if object file exists, raise exception if missing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Read compressed data from file</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Decompress data using decompress_object()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Parse object header using parse_git_object()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Verify integrity by recomputing hash and comparing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Return (object_type, content) tuple</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Hash verification detects corruption</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> object_exists</span><span style=\"color:#E1E4E8\">(self, object_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Check if object exists in store without reading content.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate hash format</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Generate file path from hash</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return whether file exists using Path.exists()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: This is more efficient than retrieve_object() for existence checks</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _write_object_file</span><span style=\"color:#E1E4E8\">(self, file_path: Path, compressed_data: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Atomically write compressed object data to file.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create temporary file in same directory as target</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Write compressed_data to temporary file</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Sync temporary file to disk (fsync)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Atomically rename temporary file to final path</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Handle any errors by cleaning up temporary file</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use tempfile.NamedTemporaryFile() with delete=False</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: os.rename() is atomic on most platforms</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _create_object_directory</span><span style=\"color:#E1E4E8\">(self, directory_path: Path) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Create object subdirectory with correct permissions.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create directory if it doesn't exist</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Set permissions to 0o755</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Handle race condition if directory is created concurrently</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use os.makedirs() with exist_ok=True</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"language-specific-hints\">Language-Specific Hints</h4>\n<p><strong>Python-Specific Implementation Details:</strong></p>\n<ul>\n<li>Use <code>pathlib.Path</code> for all file system operations—it provides cross-platform path handling and convenient methods like <code>.exists()</code> and <code>.mkdir()</code></li>\n<li>The <code>os.rename()</code> function provides atomic file renaming on POSIX systems, but use <code>shutil.move()</code> on Windows for cross-platform compatibility</li>\n<li>Use <code>tempfile.NamedTemporaryFile(delete=False)</code> to create temporary files that persist after closing, enabling atomic rename operations</li>\n<li>Call <code>file.flush()</code> followed by <code>os.fsync(file.fileno())</code> to ensure data reaches persistent storage</li>\n<li>Use <code>os.makedirs(path, mode=0o755, exist_ok=True)</code> to create directories with specific permissions while handling concurrent creation</li>\n</ul>\n<p><strong>Error Handling Patterns:</strong></p>\n<ul>\n<li>Distinguish between <code>FileNotFoundError</code> (missing object) and <code>PermissionError</code> (access issue) when reading objects</li>\n<li>Catch <code>zlib.error</code> during compression/decompression and convert to more descriptive exceptions</li>\n<li>Use try/finally blocks around temporary file operations to ensure cleanup on failure</li>\n<li>Validate input parameters (hash format, object type) before performing expensive operations</li>\n</ul>\n<h4 id=\"milestone-checkpoint\">Milestone Checkpoint</h4>\n<p>After implementing the object store, verify functionality with these tests:</p>\n<p><strong>Basic Storage and Retrieval:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/test_objects/test_store.py::test_store_blob</span><span style=\"color:#79B8FF\"> -v</span></span></code></pre></div>\n<p>Expected behavior: Store a simple text blob, retrieve it, verify content matches exactly.</p>\n<p><strong>Hash Computation Verification:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Compare with Git's hash-object command</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#9ECBFF\"> \"Hello, World!\"</span><span style=\"color:#F97583\"> |</span><span style=\"color:#B392F0\"> git</span><span style=\"color:#9ECBFF\"> hash-object</span><span style=\"color:#79B8FF\"> --stdin</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Your implementation should produce: 8ab686eafeb1f44702738c8b0f24f2567c36da6d</span></span></code></pre></div>\n\n<p><strong>Directory Structure Validation:</strong>\nAfter storing an object with hash <code>8ab686eafeb1f44702738c8b0f24f2567c36da6d</code>, verify:</p>\n<ul>\n<li>Directory <code>.git/objects/8a/</code> exists with 0755 permissions  </li>\n<li>File <code>.git/objects/8a/b686eafeb1f44702738c8b0f24f2567c36da6d</code> contains compressed data</li>\n<li>File can be decompressed to recover original formatted object</li>\n</ul>\n<p><strong>Integrity Verification:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">store = ObjectStore(Path('.git/objects'))</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">hash1 = store.store_object('blob', b'test content')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">hash2 = store.store_object('blob', b'test content')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">assert hash1 == hash2  # Same content produces same hash</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span></code></pre></div>\n\n<p><strong>Signs of Problems:</strong></p>\n<ul>\n<li>Hash mismatches indicate incorrect header formatting or hash computation sequence</li>\n<li>Permission errors suggest incorrect directory creation or file permissions</li>\n<li>Decompression failures indicate compression/decompression sequence problems</li>\n<li>Missing files after storage suggest atomic write implementation issues</li>\n</ul>\n<h2 id=\"index-and-staging-area\">Index and Staging Area</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section is crucial for Milestone 6 (Index/Staging Area) and provides the foundation for Milestone 7 (Diff Algorithm) and Milestone 8 (Merge) which rely heavily on index operations and status calculations</p>\n</blockquote>\n<h3 id=\"mental-model-the-photography-dark-room\">Mental Model: The Photography Dark Room</h3>\n<p>Think of Git&#39;s staging area as a traditional photographer&#39;s darkroom where film is developed into photographs. In the days of film photography, taking a picture was just the beginning of a multi-stage process. After shooting a roll of film, the photographer would bring it into the darkroom to develop the negatives, examine each shot under a red light, choose which ones to print, make adjustments to exposure and contrast, and only then commit to creating the final prints.</p>\n<p>The staging area works exactly like this darkroom process. Your <strong>working directory</strong> is like your camera - you can take as many shots as you want, modify files, experiment with changes, but nothing is permanent yet. The <strong>staging area</strong> (also called the index) is your darkroom where you carefully review each change, decide which modifications should be included in your next commit, and prepare them for final development. The <strong>repository</strong> is like your photo album - once you commit (develop and print), those changes become part of your permanent project history.</p>\n<p>Just as a photographer might take dozens of shots but only print their best work, you might make changes to many files in your working directory but selectively stage only specific changes for each commit. This selective staging allows you to craft meaningful, focused commits rather than dumping all your work-in-progress changes into the repository at once.</p>\n<p>The key insight is that the staging area gives you a <strong>preparation and review step</strong> before committing to permanent history. You can stage a file, make more changes to it, stage those additional changes, or even unstage files if you decide they&#39;re not ready. This three-stage workflow (working directory → staging area → repository) is what makes Git so powerful for maintaining clean, logical project history.</p>\n<h3 id=\"index-binary-format\">Index Binary Format</h3>\n<p>The Git index is stored as a binary file at <code>.git/index</code> and serves as the implementation of the staging area. Unlike most Git internal files which are human-readable text, the index uses a compact binary format for performance reasons - Git needs to quickly read, write, and search through potentially thousands of file entries during common operations like <code>git status</code> and <code>git add</code>.</p>\n<p>The index file follows a strict binary layout that begins with a fixed header, followed by a sorted array of file entries, and concludes with a SHA-1 checksum of the entire file content. This format enables Git to efficiently detect when files have been modified by comparing cached metadata against the current file system state.</p>\n<p><strong>Index File Header Structure:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Size (bytes)</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Signature</td>\n<td>4</td>\n<td>char[4]</td>\n<td>Always &quot;DIRC&quot; (directory cache)</td>\n</tr>\n<tr>\n<td>Version</td>\n<td>4</td>\n<td>uint32</td>\n<td>Format version number (we use version 2)</td>\n</tr>\n<tr>\n<td>Entry Count</td>\n<td>4</td>\n<td>uint32</td>\n<td>Number of index entries that follow</td>\n</tr>\n</tbody></table>\n<p>The header&#39;s 12-byte fixed size allows Git to quickly determine how many entries to expect when parsing the file. The &quot;DIRC&quot; signature serves as both a magic number for file type identification and a corruption detection mechanism - if these bytes are corrupted, Git immediately knows the index is invalid.</p>\n<p><strong>Index Entry Structure:</strong></p>\n<p>Each index entry represents a single staged file and contains both the file&#39;s content hash and cached file system metadata. This dual information allows Git to quickly determine whether a file has been modified since it was last staged, without having to re-read and hash the entire file content.</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Size (bytes)</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>ctime seconds</td>\n<td>4</td>\n<td>uint32</td>\n<td>File creation time (seconds since Unix epoch)</td>\n</tr>\n<tr>\n<td>ctime nanoseconds</td>\n<td>4</td>\n<td>uint32</td>\n<td>File creation time fractional seconds</td>\n</tr>\n<tr>\n<td>mtime seconds</td>\n<td>4</td>\n<td>uint32</td>\n<td>File modification time (seconds since Unix epoch)</td>\n</tr>\n<tr>\n<td>mtime nanoseconds</td>\n<td>4</td>\n<td>uint32</td>\n<td>File modification time fractional seconds</td>\n</tr>\n<tr>\n<td>Device ID</td>\n<td>4</td>\n<td>uint32</td>\n<td>Device ID containing the file</td>\n</tr>\n<tr>\n<td>Inode</td>\n<td>4</td>\n<td>uint32</td>\n<td>File system inode number</td>\n</tr>\n<tr>\n<td>Mode</td>\n<td>4</td>\n<td>uint32</td>\n<td>File mode and permissions (0o100644 for regular files)</td>\n</tr>\n<tr>\n<td>UID</td>\n<td>4</td>\n<td>uint32</td>\n<td>User ID of file owner</td>\n</tr>\n<tr>\n<td>GID</td>\n<td>4</td>\n<td>uint32</td>\n<td>Group ID of file owner</td>\n</tr>\n<tr>\n<td>File Size</td>\n<td>4</td>\n<td>uint32</td>\n<td>Size of file content in bytes</td>\n</tr>\n<tr>\n<td>SHA-1 Hash</td>\n<td>20</td>\n<td>char[20]</td>\n<td>Object hash of staged file content (binary, not hex)</td>\n</tr>\n<tr>\n<td>Flags</td>\n<td>2</td>\n<td>uint16</td>\n<td>Status flags including name length</td>\n</tr>\n<tr>\n<td>Path Name</td>\n<td>variable</td>\n<td>char[]</td>\n<td>File path relative to repository root</td>\n</tr>\n<tr>\n<td>Padding</td>\n<td>0-3</td>\n<td>char[]</td>\n<td>NUL bytes to align entry to 4-byte boundary</td>\n</tr>\n</tbody></table>\n<p>The extensive metadata caching in each entry enables Git&#39;s famous performance. When you run <code>git status</code>, Git can quickly scan through the index entries and compare the cached timestamps and file sizes against the current working directory. Only files whose metadata has changed need to be re-read and hashed to determine if their content has actually been modified.</p>\n<blockquote>\n<p><strong>Critical Implementation Detail</strong>: The SHA-1 hash is stored as 20 binary bytes, not as 40 hexadecimal characters. This is a common source of bugs - you must convert between binary and hex representations when reading/writing the index versus displaying hashes to users.</p>\n</blockquote>\n<p><strong>Index Entry Sorting and Padding:</strong></p>\n<p>Index entries must be stored in <strong>lexicographic order</strong> by their path name. This sorting enables Git to use binary search when looking up specific files and ensures consistent behavior across different implementations. The sorting is performed on the raw byte values of the UTF-8 encoded path strings.</p>\n<p>Each entry&#39;s total size must be a multiple of 4 bytes for memory alignment performance. After the variable-length path name, NUL padding bytes are added to reach the next 4-byte boundary. The entry size calculation is: <code>62 + path_length + padding_to_4_byte_boundary</code>.</p>\n<p><strong>Index Checksum:</strong></p>\n<p>The index file concludes with a 20-byte SHA-1 checksum of all preceding content. This checksum serves multiple purposes:</p>\n<ol>\n<li><strong>Corruption Detection</strong>: Git can verify the index hasn&#39;t been corrupted by disk errors or incomplete writes</li>\n<li><strong>Concurrent Access Safety</strong>: Multiple Git processes can detect when another process has modified the index</li>\n<li><strong>Atomic Updates</strong>: Git writes to a temporary file then renames it, ensuring the index is never in a partially-written state</li>\n</ol>\n<p>The checksum is calculated over the entire file content except for the checksum bytes themselves.</p>\n<blockquote>\n<p><strong>Decision: Binary Format vs Text Format</strong></p>\n<ul>\n<li><strong>Context</strong>: The staging area needs to store metadata for potentially thousands of files and be read/written frequently during common Git operations</li>\n<li><strong>Options Considered</strong>: <ul>\n<li>Text format (similar to .gitignore): Human readable, easy to debug, simple to parse</li>\n<li>Binary format: Compact storage, faster parsing, fixed-width fields enable efficient seeking</li>\n<li>Hybrid approach: Text metadata with binary hashes</li>\n</ul>\n</li>\n<li><strong>Decision</strong>: Binary format with fixed-width header and entries</li>\n<li><strong>Rationale</strong>: Performance is critical for the staging area since it&#39;s accessed by almost every Git command. Binary format provides 3-5x faster parsing and 2x smaller file size compared to text alternatives. The complexity cost is justified by the performance benefits for large repositories.</li>\n<li><strong>Consequences</strong>: More complex to implement and debug, but enables Git&#39;s famous speed even in repositories with thousands of files</li>\n</ul>\n</blockquote>\n<h3 id=\"add-and-remove-operations\">Add and Remove Operations</h3>\n<p>The core staging area operations are adding files (staging changes) and removing files (unstaging changes). These operations maintain the index&#39;s binary format and sorted ordering while updating both the object store and the cached metadata.</p>\n<p><strong>Add Operation Algorithm:</strong></p>\n<p>The <code>git add</code> operation stages a file&#39;s current content and metadata into the index. This involves both storing the file content as a blob object and creating or updating the corresponding index entry.</p>\n<ol>\n<li><p><strong>Read File Content</strong>: Read the complete file content from the working directory. Handle binary files correctly by reading raw bytes without text encoding assumptions.</p>\n</li>\n<li><p><strong>Create Blob Object</strong>: Compute the SHA-1 hash of the blob object using the <code>compute_object_hash</code> function with <code>BLOB_TYPE</code>. Store the compressed object in the object store using <code>store_object</code>.</p>\n</li>\n<li><p><strong>Gather File Metadata</strong>: Use file system calls to collect the complete stat information including modification time, file size, inode number, device ID, permissions, and owner IDs. This metadata enables fast change detection later.</p>\n</li>\n<li><p><strong>Load Current Index</strong>: Read and parse the existing <code>.git/index</code> file if it exists. If the repository has no staged files yet, start with an empty index structure.</p>\n</li>\n<li><p><strong>Update or Insert Entry</strong>: Search for an existing entry with the same path name. If found, update its hash and metadata. If not found, create a new entry. The binary hash must be converted from the 40-character hex representation to 20 binary bytes.</p>\n</li>\n<li><p><strong>Maintain Sort Order</strong>: Keep all index entries sorted lexicographically by path name. Insert new entries in the correct position or re-sort after updates.</p>\n</li>\n<li><p><strong>Write Updated Index</strong>: Serialize the complete index structure back to binary format, calculate the SHA-1 checksum of the content, append the checksum, and atomically write to <code>.git/index</code> using a temporary file and rename operation.</p>\n</li>\n</ol>\n<p><strong>Add Operation Data Flow:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Input</th>\n<th>Processing</th>\n<th>Output</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Working Directory</td>\n<td>File path</td>\n<td>Read file content and stat metadata</td>\n<td>Raw bytes + file stats</td>\n</tr>\n<tr>\n<td>Object Store</td>\n<td>File content</td>\n<td>Hash, compress, store as blob</td>\n<td>Object hash</td>\n</tr>\n<tr>\n<td>Index</td>\n<td>Path + hash + stats</td>\n<td>Update entry, maintain sort order</td>\n<td>Updated index</td>\n</tr>\n<tr>\n<td>File System</td>\n<td>Binary index data</td>\n<td>Atomic write with checksum</td>\n<td>Persistent .git/index</td>\n</tr>\n</tbody></table>\n<p><strong>Remove Operation Algorithm:</strong></p>\n<p>The <code>git rm --cached</code> operation (unstaging) removes a file from the index without affecting the working directory. This is distinct from <code>git rm</code> which removes both the index entry and the working directory file.</p>\n<ol>\n<li><p><strong>Load Current Index</strong>: Read and parse the existing <code>.git/index</code> file. If the index doesn&#39;t exist or is empty, the remove operation is a no-op.</p>\n</li>\n<li><p><strong>Find Target Entry</strong>: Search through the sorted index entries for the specified path name. Since entries are sorted, this can use binary search for efficiency in large repositories.</p>\n</li>\n<li><p><strong>Remove Entry</strong>: Delete the matching entry from the index entry list. This does not affect the blob object in the object store (other commits might reference it).</p>\n</li>\n<li><p><strong>Update Entry Count</strong>: Decrement the entry count in the index header to reflect the removal.</p>\n</li>\n<li><p><strong>Write Updated Index</strong>: Serialize the modified index structure back to binary format and write it atomically. The checksum will change since the content has changed.</p>\n</li>\n</ol>\n<p>⚠️ <strong>Pitfall: Object Store Cleanup</strong>\nMany implementations mistakenly delete the blob object when removing an index entry. This is incorrect - the object store is append-only and blob objects should never be deleted during normal operations. Other commits in the repository history might reference the same blob hash. Git&#39;s garbage collection process handles cleanup of unreferenced objects separately.</p>\n<p><strong>Handling File Modifications:</strong></p>\n<p>When a file is modified after being staged, Git needs to handle the scenario where the working directory version differs from the staged version. The add operation naturally handles this case:</p>\n<ol>\n<li>The new file content gets a different SHA-1 hash than the previously staged version</li>\n<li>The old blob object remains in the object store (it might be referenced by previous commits)</li>\n<li>The new blob object is stored alongside the old one</li>\n<li>The index entry is updated with the new hash and current metadata</li>\n</ol>\n<p>This design means that staging a file multiple times creates multiple blob objects, but this is acceptable because content-addressable storage ensures identical content is never duplicated (same content always produces the same hash).</p>\n<p><strong>Index Locking and Concurrency:</strong></p>\n<p>Multiple Git commands might attempt to read or write the index simultaneously. Git uses a file-based locking mechanism to prevent corruption:</p>\n<ol>\n<li>Before writing the index, Git creates a <code>.git/index.lock</code> file</li>\n<li>The actual index updates are written to this lock file</li>\n<li>When the update is complete, the lock file is atomically renamed to <code>.git/index</code></li>\n<li>Other Git processes that find an existing lock file wait or abort with an error</li>\n</ol>\n<p>This locking protocol ensures that the index is never in a partially-written state and that concurrent operations don&#39;t corrupt each other&#39;s changes.</p>\n<p><strong>Status Tracking for Modified Files:</strong></p>\n<p>The cached metadata in index entries enables efficient change detection. When determining if a file has been modified since staging:</p>\n<ol>\n<li><p><strong>Fast Path</strong>: Compare cached mtime and file size against current values. If both match, the file is likely unchanged (skip expensive content hashing).</p>\n</li>\n<li><p><strong>Slow Path</strong>: If metadata differs, read the file content, compute its SHA-1 hash, and compare against the staged hash. This definitively determines if content has changed.</p>\n</li>\n<li><p><strong>Race Condition Handling</strong>: If a file is modified during the status check, the metadata comparison might give inconsistent results. Git handles this by re-checking files whose metadata changed during processing.</p>\n</li>\n</ol>\n<p>This two-level approach makes <code>git status</code> extremely fast even in large repositories, since most files are unchanged and can be verified using only metadata comparison.</p>\n<p><img src=\"/api/project/build-git/architecture-doc/asset?path=diagrams%2Fcommit-creation-flow.svg\" alt=\"Commit Creation Sequence\"></p>\n<h3 id=\"status-calculation\">Status Calculation</h3>\n<p>Git status determines the state of every file by performing a <strong>three-way comparison</strong> between the working directory, the staging area (index), and the current commit (HEAD). This comparison categorizes each file into one of several states that inform the user what changes are staged, what changes are unstaged, and what files are untracked.</p>\n<p>Understanding status calculation is crucial because it forms the foundation for diff algorithms and merge operations. The status calculation must be both comprehensive (finding all relevant files) and efficient (fast enough for interactive use).</p>\n<p><strong>Three-Way Comparison Overview:</strong></p>\n<p>The status algorithm compares three different views of the project&#39;s files:</p>\n<ol>\n<li><strong>HEAD Commit</strong>: The files and content from the current branch&#39;s most recent commit</li>\n<li><strong>Index (Staging Area)</strong>: The files that have been staged for the next commit  </li>\n<li><strong>Working Directory</strong>: The current files in the file system</li>\n</ol>\n<p>By comparing these three states pairwise, Git can determine exactly what changes have been made and what actions the user might want to take next.</p>\n<p><strong>File State Categories:</strong></p>\n<table>\n<thead>\n<tr>\n<th>State</th>\n<th>Working Directory</th>\n<th>Index</th>\n<th>HEAD</th>\n<th>User Action Needed</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Untracked</td>\n<td>Present</td>\n<td>Absent</td>\n<td>Absent</td>\n<td><code>git add</code> to begin tracking</td>\n</tr>\n<tr>\n<td>Added</td>\n<td>Present</td>\n<td>Present</td>\n<td>Absent</td>\n<td><code>git commit</code> to confirm addition</td>\n</tr>\n<tr>\n<td>Modified</td>\n<td>Modified</td>\n<td>Original</td>\n<td>Original</td>\n<td><code>git add</code> to stage changes</td>\n</tr>\n<tr>\n<td>Staged</td>\n<td>Modified</td>\n<td>Modified</td>\n<td>Original</td>\n<td><code>git commit</code> to confirm changes</td>\n</tr>\n<tr>\n<td>Deleted</td>\n<td>Absent</td>\n<td>Original</td>\n<td>Present</td>\n<td><code>git add</code> to stage deletion</td>\n</tr>\n<tr>\n<td>Renamed</td>\n<td>New location</td>\n<td>New location</td>\n<td>Old location</td>\n<td><code>git commit</code> to confirm rename</td>\n</tr>\n<tr>\n<td>Conflicted</td>\n<td>Conflicted</td>\n<td>Multiple stages</td>\n<td>Original</td>\n<td>Resolve conflicts manually</td>\n</tr>\n</tbody></table>\n<p><strong>Status Calculation Algorithm:</strong></p>\n<p>The status calculation follows a systematic approach to ensure no files are missed and all states are correctly identified:</p>\n<ol>\n<li><p><strong>Collect File Sets</strong>: Gather the complete set of file paths from all three sources:</p>\n<ul>\n<li>Parse the HEAD commit tree to get all tracked files</li>\n<li>Read the index to get all staged files  </li>\n<li>Scan the working directory for all present files (respecting .gitignore rules)</li>\n</ul>\n</li>\n<li><p><strong>Create Union of Paths</strong>: Combine all file paths from the three sources into a single sorted set. This ensures every file that exists in any state gets examined.</p>\n</li>\n<li><p><strong>Three-Way Comparison</strong>: For each file path, determine its presence and content in each of the three states:</p>\n<ul>\n<li>HEAD state: File hash from the commit tree (if present)</li>\n<li>Index state: File hash from the index entry (if present)</li>\n<li>Working directory state: Computed hash of current file content (if present)</li>\n</ul>\n</li>\n<li><p><strong>Apply Classification Rules</strong>: Use the three-state comparison to classify each file according to the state table above.</p>\n</li>\n<li><p><strong>Handle Special Cases</strong>: Process renames, ignored files, and submodule states according to Git&#39;s specific rules.</p>\n</li>\n</ol>\n<p><strong>Detailed State Classification:</strong></p>\n<p><strong>Untracked Files:</strong>\nFiles present in the working directory but absent from both the index and HEAD commit. These represent new files that haven&#39;t been added to version control yet.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Working Directory: file.txt (content: &quot;hello&quot;)\nIndex: (absent)\nHEAD: (absent)\nStatus: Untracked</code></pre></div>\n\n<p><strong>Added Files (Staged for Addition):</strong>\nFiles that have been staged but don&#39;t exist in the HEAD commit. These will be new files in the next commit.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Working Directory: new-file.txt (hash: abc123)\nIndex: new-file.txt (hash: abc123) \nHEAD: (absent)\nStatus: Added</code></pre></div>\n\n<p><strong>Modified Files (Unstaged Changes):</strong>\nFiles where the working directory content differs from what&#39;s staged in the index. The index matches HEAD, but the working directory has newer changes.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Working Directory: file.txt (hash: def456)\nIndex: file.txt (hash: abc123)\nHEAD: file.txt (hash: abc123)\nStatus: Modified (unstaged)</code></pre></div>\n\n<p><strong>Staged Files (Staged Changes):</strong>\nFiles where the index content differs from HEAD, indicating changes that are ready to be committed.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Working Directory: file.txt (hash: def456)\nIndex: file.txt (hash: def456)\nHEAD: file.txt (hash: abc123)\nStatus: Modified (staged)</code></pre></div>\n\n<p><strong>Deleted Files:</strong>\nFiles that exist in HEAD or the index but are missing from the working directory.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Working Directory: (absent)\nIndex: file.txt (hash: abc123)\nHEAD: file.txt (hash: abc123)\nStatus: Deleted (unstaged)</code></pre></div>\n\n<p><strong>Both Modified (Conflicted State):</strong>\nFiles that have different content in all three states, indicating both staged and unstaged changes exist simultaneously.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Working Directory: file.txt (hash: ghi789)\nIndex: file.txt (hash: def456)  \nHEAD: file.txt (hash: abc123)\nStatus: Modified (both staged and unstaged)</code></pre></div>\n\n<p><strong>Optimization Strategies:</strong></p>\n<p>Status calculation can be expensive in large repositories, so several optimization techniques are crucial:</p>\n<p><strong>Metadata-Based Change Detection:</strong>\nUse the cached stat information in index entries to avoid re-reading file content. If a file&#39;s mtime and size haven&#39;t changed since it was staged, assume its content hasn&#39;t changed either.</p>\n<p><strong>Parallel Processing:</strong>\nProcess different subtrees of the repository concurrently. Since file hashing is CPU-intensive, parallelizing across multiple files can significantly speed up status calculation.</p>\n<p><strong>Incremental Updates:</strong>\nCache status results and only re-examine files whose metadata indicates they might have changed. This is particularly effective for interactive tools that repeatedly call status.</p>\n<p><strong>Ignore File Processing:</strong>\nEfficiently skip untracked files that match .gitignore patterns without examining their content. This prevents status calculation from becoming slow in directories with many generated files.</p>\n<blockquote>\n<p><strong>Decision: Three-Way vs Pair-Wise Comparison</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to determine file states for status display and as input to merge algorithms</li>\n<li><strong>Options Considered</strong>: <ul>\n<li>Pair-wise comparisons: Compare working dir vs index, then index vs HEAD separately</li>\n<li>Three-way comparison: Examine all three states simultaneously for each file</li>\n<li>Lazy evaluation: Only compute states for files the user specifically requests</li>\n</ul>\n</li>\n<li><strong>Decision</strong>: Three-way comparison with optimization shortcuts</li>\n<li><strong>Rationale</strong>: Three-way comparison provides complete information needed for merge operations and enables more accurate status reporting (can detect &quot;both modified&quot; states). Pair-wise approaches miss important state combinations and require multiple passes through file sets.</li>\n<li><strong>Consequences</strong>: More complex algorithm but provides comprehensive status information needed by advanced Git operations like merge and rebase</li>\n</ul>\n</blockquote>\n<p><strong>Common Status Calculation Pitfalls:</strong></p>\n<p>⚠️ <strong>Pitfall: Ignoring File System Case Sensitivity</strong>\nOn case-insensitive file systems (macOS, Windows), files named <code>File.txt</code> and <code>file.txt</code> are the same file system object but different Git objects. Status calculation must handle this correctly by using the file system&#39;s canonical casing for working directory files while preserving the exact casing stored in Git objects.</p>\n<p>⚠️ <strong>Pitfall: Race Conditions During Status Calculation</strong>\nFiles can be modified while status is being calculated, leading to inconsistent results. The algorithm must handle cases where file metadata changes between when the file list is built and when individual files are examined.</p>\n<p>⚠️ <strong>Pitfall: Memory Usage with Large Repositories</strong>\nLoading all file paths into memory simultaneously can consume excessive memory in repositories with hundreds of thousands of files. Streaming approaches that process files incrementally are necessary for very large repositories.</p>\n<p>⚠️ <strong>Pitfall: Inefficient Untracked File Detection</strong>\nScanning the entire working directory tree for untracked files can be extremely slow. The algorithm must respect .gitignore rules early to avoid examining large directories full of generated files (like <code>node_modules</code> or build outputs).</p>\n<p><img src=\"/api/project/build-git/architecture-doc/asset?path=diagrams%2Findex-format.svg\" alt=\"Index File Structure\"></p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The index implementation requires careful handling of binary data formats and efficient file system operations. This guidance provides complete infrastructure code for the non-core components and skeleton code for the core learning objectives.</p>\n<p><strong>Technology Recommendations:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Binary Parsing</td>\n<td><code>struct</code> module with format strings</td>\n<td><code>ctypes</code> or <code>numpy</code> for performance</td>\n</tr>\n<tr>\n<td>File I/O</td>\n<td>Standard <code>open()</code> with binary mode</td>\n<td><code>mmap</code> for large index files</td>\n</tr>\n<tr>\n<td>Sorting</td>\n<td>Built-in <code>sorted()</code> function</td>\n<td>Custom sorting with locale awareness</td>\n</tr>\n<tr>\n<td>Concurrency</td>\n<td>File locking with <code>fcntl</code> (Unix)</td>\n<td>Cross-platform locking library</td>\n</tr>\n<tr>\n<td>Status Display</td>\n<td>Simple print statements</td>\n<td>Rich terminal formatting with colors</td>\n</tr>\n</tbody></table>\n<p><strong>Recommended File Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>project-root/\n  git/\n    __init__.py\n    repository.py           ← Repository class\n    objects.py              ← Object store (from previous milestones)\n    index.py                ← Index implementation (THIS COMPONENT)\n      IndexEntry            ← Individual file entry\n      Index                 ← Main index operations\n      StatusCalculator      ← Three-way comparison logic\n    references.py           ← Branch/HEAD management (next milestone)\n    commands/\n      add.py                ← git add command\n      status.py             ← git status command\n      commit.py             ← git commit command\n    utils/\n      binary_parser.py      ← Binary format helpers (infrastructure)\n      file_utils.py         ← File system utilities (infrastructure)\n  tests/\n    test_index.py           ← Index unit tests\n    test_status.py          ← Status calculation tests</code></pre></div>\n\n<p><strong>Infrastructure: Binary Parser Utilities</strong></p>\n<p>This complete utility module handles the low-level binary format parsing, so you can focus on the higher-level index logic:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># utils/binary_parser.py - COMPLETE INFRASTRUCTURE CODE</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> struct</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> hashlib</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Tuple, List, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> BinaryReader</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Helper for reading structured binary data from Git files.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, data: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> data</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.offset </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> read_bytes</span><span style=\"color:#E1E4E8\">(self, count: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Read exactly count bytes and advance position.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.offset </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> count </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.data):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Not enough data: need </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">count</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">, have </span><span style=\"color:#79B8FF\">{len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.data) </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.offset</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        result </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.data[</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.offset:</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.offset </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> count]</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.offset </span><span style=\"color:#F97583\">+=</span><span style=\"color:#E1E4E8\"> count</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> result</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> read_uint32</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Read big-endian 32-bit unsigned integer.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> struct.unpack(</span><span style=\"color:#9ECBFF\">\">I\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.read_bytes(</span><span style=\"color:#79B8FF\">4</span><span style=\"color:#E1E4E8\">))[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> read_uint16</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Read big-endian 16-bit unsigned integer.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> struct.unpack(</span><span style=\"color:#9ECBFF\">\">H\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.read_bytes(</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">))[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> read_cstring</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Read null-terminated string.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        start </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.offset</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        while</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.offset </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.data) </span><span style=\"color:#F97583\">and</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.data[</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.offset] </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.offset </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.offset </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.data):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Unterminated string\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        result </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.data[start:</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.offset].decode(</span><span style=\"color:#9ECBFF\">'utf-8'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.offset </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#6A737D\">  # Skip null terminator</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> result</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> align_to_4_bytes</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Advance to next 4-byte boundary.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        while</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.offset </span><span style=\"color:#F97583\">%</span><span style=\"color:#79B8FF\"> 4</span><span style=\"color:#F97583\"> !=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.offset </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> BinaryWriter</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Helper for writing structured binary data to Git files.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.data </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> bytearray</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> write_bytes</span><span style=\"color:#E1E4E8\">(self, data: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Write raw bytes.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.data.extend(data)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> write_uint32</span><span style=\"color:#E1E4E8\">(self, value: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Write big-endian 32-bit unsigned integer.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.data.extend(struct.pack(</span><span style=\"color:#9ECBFF\">\">I\"</span><span style=\"color:#E1E4E8\">, value))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> write_uint16</span><span style=\"color:#E1E4E8\">(self, value: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Write big-endian 16-bit unsigned integer.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.data.extend(struct.pack(</span><span style=\"color:#9ECBFF\">\">H\"</span><span style=\"color:#E1E4E8\">, value))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> write_cstring</span><span style=\"color:#E1E4E8\">(self, text: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Write null-terminated UTF-8 string.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.data.extend(text.encode(</span><span style=\"color:#9ECBFF\">'utf-8'</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.data.append(</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> pad_to_4_bytes</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Pad with null bytes to next 4-byte boundary.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        while</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.data) </span><span style=\"color:#F97583\">%</span><span style=\"color:#79B8FF\"> 4</span><span style=\"color:#F97583\"> !=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.data.append(</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_data</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get the complete binary data.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> bytes</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.data)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> compute_sha1</span><span style=\"color:#E1E4E8\">(data: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Compute SHA-1 hash and return as hex string.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> hashlib.sha1(data).hexdigest()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> verify_checksum</span><span style=\"color:#E1E4E8\">(data: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Verify that the last 20 bytes are SHA-1 of the rest.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(data) </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 20</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    content </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> data[:</span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\">20</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    expected_checksum </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> data[</span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\">20</span><span style=\"color:#E1E4E8\">:]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    actual_checksum </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> hashlib.sha1(content).digest()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> expected_checksum </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> actual_checksum</span></span></code></pre></div>\n\n<p><strong>Infrastructure: File System Utilities</strong></p>\n<p>Complete utility functions for safe file operations and metadata handling:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># utils/file_utils.py - COMPLETE INFRASTRUCTURE CODE</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> os</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> stat</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> tempfile</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, Any, Optional</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> get_file_metadata</span><span style=\"color:#E1E4E8\">(file_path: Path) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Get complete file metadata for index storage.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        st </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> file_path.stat()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'ctime_sec'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">(st.st_ctime),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'ctime_nsec'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">((st.st_ctime </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> int</span><span style=\"color:#E1E4E8\">(st.st_ctime)) </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 1_000_000_000</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'mtime_sec'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">(st.st_mtime),  </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'mtime_nsec'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">((st.st_mtime </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> int</span><span style=\"color:#E1E4E8\">(st.st_mtime)) </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 1_000_000_000</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'device'</span><span style=\"color:#E1E4E8\">: st.st_dev,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'inode'</span><span style=\"color:#E1E4E8\">: st.st_ino,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'mode'</span><span style=\"color:#E1E4E8\">: st.st_mode,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'uid'</span><span style=\"color:#E1E4E8\">: st.st_uid,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'gid'</span><span style=\"color:#E1E4E8\">: st.st_gid,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'size'</span><span style=\"color:#E1E4E8\">: st.st_size,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    except</span><span style=\"color:#79B8FF\"> OSError</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> is_file_modified</span><span style=\"color:#E1E4E8\">(file_path: Path, cached_mtime_sec: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, cached_size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Fast check if file might be modified using cached metadata.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        st </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> file_path.stat()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">(st.st_mtime) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> cached_mtime_sec </span><span style=\"color:#F97583\">or</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                st.st_size </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> cached_size)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    except</span><span style=\"color:#79B8FF\"> OSError</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> True</span><span style=\"color:#6A737D\">  # File missing/inaccessible = modified</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> atomic_write_file</span><span style=\"color:#E1E4E8\">(file_path: Path, content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Write file atomically using temp file + rename.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    temp_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> file_path.with_suffix(file_path.suffix </span><span style=\"color:#F97583\">+</span><span style=\"color:#9ECBFF\"> '.tmp'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> open</span><span style=\"color:#E1E4E8\">(temp_path, </span><span style=\"color:#9ECBFF\">'wb'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> f:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            f.write(content)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            f.flush()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            os.fsync(f.fileno())  </span><span style=\"color:#6A737D\"># Ensure written to disk</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        temp_path.rename(file_path)  </span><span style=\"color:#6A737D\"># Atomic on most filesystems</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    except</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> temp_path.exists():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            temp_path.unlink()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> scan_directory</span><span style=\"color:#E1E4E8\">(dir_path: Path, ignore_patterns: Optional[</span><span style=\"color:#79B8FF\">set</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> List[Path]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Recursively scan directory for all files, respecting ignore patterns.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> ignore_patterns </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ignore_patterns </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span><span style=\"color:#9ECBFF\">'.git'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'__pycache__'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'.pyc'</span><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    files </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> root, dirs, filenames </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> os.walk(dir_path):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Remove ignored directories to prevent os.walk from entering them</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            dirs[:] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [d </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> d </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> dirs </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> d </span><span style=\"color:#F97583\">not</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> ignore_patterns]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            for</span><span style=\"color:#E1E4E8\"> filename </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> filenames:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> filename </span><span style=\"color:#F97583\">not</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> ignore_patterns:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    file_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Path(root) </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> filename</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    files.append(file_path.relative_to(dir_path))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    except</span><span style=\"color:#79B8FF\"> OSError</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span><span style=\"color:#6A737D\">  # Directory inaccessible</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> sorted</span><span style=\"color:#E1E4E8\">(files)</span></span></code></pre></div>\n\n<p><strong>Core Logic: Index Entry Structure</strong></p>\n<p>Here&#39;s the skeleton for the core IndexEntry class that you need to implement:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># index.py - CORE LOGIC SKELETON</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional, List, Dict, Set</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .utils.binary_parser </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> BinaryReader, BinaryWriter, compute_sha1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .utils.file_utils </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> get_file_metadata, atomic_write_file</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">INDEX_VERSION</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 2</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">FILE_MODE_REGULAR</span><span style=\"color:#F97583\"> =</span><span style=\"color:#F97583\"> 0o</span><span style=\"color:#79B8FF\">100644</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> IndexEntry</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Represents a single file entry in the Git index.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # File metadata (cached for fast change detection)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ctime_sec: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ctime_nsec: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    mtime_sec: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    mtime_nsec: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    device: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    inode: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    mode: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    uid: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    gid: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    size: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Git object information</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    object_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#6A737D\">  # 40-character hex SHA-1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    flags: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#6A737D\">        # Status flags and path length</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#6A737D\">         # Relative path from repository root</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">classmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> from_file</span><span style=\"color:#E1E4E8\">(cls, file_path: Path, object_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, repo_root: Path) -> </span><span style=\"color:#9ECBFF\">'IndexEntry'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Create index entry from working directory file.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Get file metadata using get_file_metadata()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Calculate relative path from repo_root</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Set flags (path length in lower 12 bits, others zero)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return IndexEntry with all fields populated</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: flags = min(len(relative_path), 0xfff)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> serialize</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Serialize entry to binary format for index file.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        writer </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> BinaryWriter()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Write all metadata fields as uint32 (10 fields total)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Write SHA-1 hash as 20 binary bytes (convert from hex)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Write flags as uint16</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Write path as null-terminated string</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Pad to 4-byte boundary</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Order: ctime_sec, ctime_nsec, mtime_sec, mtime_nsec, device, </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #        inode, mode, uid, gid, size, hash_bytes, flags, path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">classmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> deserialize</span><span style=\"color:#E1E4E8\">(cls, reader: BinaryReader) -> </span><span style=\"color:#9ECBFF\">'IndexEntry'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Deserialize entry from binary format.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Read all metadata fields as uint32 (10 fields)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Read SHA-1 hash as 20 binary bytes, convert to hex</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Read flags as uint16</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Read path as null-terminated string</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Align reader to 4-byte boundary</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return IndexEntry instance</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>Core Logic: Index Class</strong></p>\n<p>The main Index class that manages the complete staging area:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> Index</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Git staging area implementation with binary format support.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, git_dir: Path):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.git_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_dir</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.index_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> 'index'</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.entries: List[IndexEntry] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> load</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Load index from .git/index file.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.index_path.exists():</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.entries </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> open</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.index_path, </span><span style=\"color:#9ECBFF\">'rb'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> f:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> f.read()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Verify checksum using verify_checksum()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Create BinaryReader with content (excluding checksum)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Read and verify header (signature \"DIRC\", version 2)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Read entry count</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Read each entry using IndexEntry.deserialize()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Store entries in self.entries list</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Content for checksum is data[:-20], checksum is data[-20:]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> save</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Save index to .git/index file with atomic write.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        writer </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> BinaryWriter()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Write header (signature, version, entry count)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Sort entries by path name</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Write each entry using entry.serialize()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Calculate SHA-1 checksum of all content</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Append checksum as 20 binary bytes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Write atomically using atomic_write_file()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> add_file</span><span style=\"color:#E1E4E8\">(self, file_path: Path, repo_root: Path, object_store):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Stage a file by adding it to the index.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Read file content from working directory</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Store file content as blob object using object_store.store_object()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Create IndexEntry from file and object hash</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Remove any existing entry with same path</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Insert new entry maintaining sort order</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use bisect module for efficient sorted insertion</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> remove_file</span><span style=\"color:#E1E4E8\">(self, file_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Remove file from index (unstage).\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Find entry with matching path</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Remove entry from self.entries list</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Don't modify object store (objects are immutable)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_entry</span><span style=\"color:#E1E4E8\">(self, file_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Optional[IndexEntry]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get index entry for specified path.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Search through entries for matching path</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Return entry if found, None otherwise</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Since entries are sorted, can use binary search</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_all_paths</span><span style=\"color:#E1E4E8\">(self) -> Set[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get set of all paths in the index.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> {entry.path </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> entry </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.entries}</span></span></code></pre></div>\n\n<p><strong>Core Logic: Status Calculator</strong></p>\n<p>The three-way comparison engine:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> StatusCalculator</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Calculates file status using three-way comparison.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, repo_root: Path, git_dir: Path):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.repo_root </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> repo_root</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.git_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_dir</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> calculate_status</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Perform three-way comparison and return file statuses.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Load index and get all staged file paths</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Get HEAD commit and extract all tracked file paths/hashes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Scan working directory for all present files</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Create union of all file paths from three sources</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: For each path, determine state in all three locations</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Apply classification rules to determine status</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Return dict mapping file paths to status strings</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _get_head_files</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get files and hashes from HEAD commit.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Read HEAD reference to get current commit hash</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Load commit object and get root tree hash</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Recursively walk tree objects to get all file paths/hashes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return dict mapping paths to object hashes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _get_working_files</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get files and hashes from working directory.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Scan working directory for all files</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: For each file, compute what its blob hash would be</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Skip ignored files (.gitignore rules)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return dict mapping paths to computed hashes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _classify_file_status</span><span style=\"color:#E1E4E8\">(self, path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, wd_hash: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                             index_hash: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">], head_hash: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Classify single file status based on three-way comparison.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Handle untracked case (wd present, index and head absent)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Handle added case (wd and index present, head absent)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Handle modified cases (various combinations)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Handle deleted cases (wd absent, index/head present)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Handle staged cases (index differs from head)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return appropriate status string</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>Milestone Checkpoint:</strong></p>\n<p>After implementing the index system, verify your implementation with these tests:</p>\n<ol>\n<li><strong>Basic Add Operation</strong>:</li>\n</ol>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#79B8FF\">   echo</span><span style=\"color:#9ECBFF\"> \"hello world\"</span><span style=\"color:#F97583\"> ></span><span style=\"color:#9ECBFF\"> test.txt</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">   python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> git.commands.add</span><span style=\"color:#9ECBFF\"> test.txt</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">   # Should create .git/index file and store blob object</span></span></code></pre></div>\n\n<ol start=\"2\">\n<li><strong>Index File Format</strong>:</li>\n</ol>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">   hexdump</span><span style=\"color:#79B8FF\"> -C</span><span style=\"color:#9ECBFF\"> .git/index</span><span style=\"color:#F97583\"> |</span><span style=\"color:#B392F0\"> head</span><span style=\"color:#79B8FF\"> -5</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">   # Should show \"DIRC\" signature, version 2, entry count</span></span></code></pre></div>\n\n<ol start=\"3\">\n<li><strong>Status Calculation</strong>:</li>\n</ol>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">   python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> git.commands.status</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">   # Should show test.txt as \"new file\" (added)</span></span></code></pre></div>\n\n<ol start=\"4\">\n<li><strong>Index Persistence</strong>:</li>\n</ol>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">   # Run status twice - should be fast second time (metadata caching)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">   time</span><span style=\"color:#E1E4E8\"> python -m git.commands.status</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">   time</span><span style=\"color:#E1E4E8\"> python -m git.commands.status</span></span></code></pre></div>\n\n<p><strong>Debugging Tips:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>Diagnosis</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Index file corrupted</td>\n<td>Wrong binary format</td>\n<td><code>hexdump -C .git/index</code></td>\n<td>Check field sizes and byte order</td>\n</tr>\n<tr>\n<td>Status shows all files modified</td>\n<td>Metadata caching broken</td>\n<td>Compare cached vs actual mtime/size</td>\n<td>Fix stat field extraction</td>\n</tr>\n<tr>\n<td>Add operation fails</td>\n<td>Path encoding issues</td>\n<td>Check for non-ASCII characters</td>\n<td>Use UTF-8 encoding consistently</td>\n</tr>\n<tr>\n<td>Performance poor on large repos</td>\n<td>Not using metadata optimization</td>\n<td>Profile status calculation</td>\n<td>Implement fast-path metadata checks</td>\n</tr>\n</tbody></table>\n<h2 id=\"references-and-branch-management\">References and Branch Management</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section is essential for Milestone 5 (References and Branches) and provides the foundation for branch-based operations in Milestone 7 (Diff Algorithm) and Milestone 8 (Merge)</p>\n</blockquote>\n<p>The reference system forms the human-readable layer of Git&#39;s architecture, sitting above the cryptographic hash-based object store to provide meaningful names for commits and manage the current project state. While Git&#39;s underlying storage operates entirely through SHA-1 hashes, users need intuitive names like &quot;main&quot;, &quot;feature-branch&quot;, or &quot;v1.2.3&quot; to navigate their project history effectively. The reference system bridges this gap by maintaining a mapping from human-readable names to commit hashes, while also tracking the current branch state through the special HEAD reference.</p>\n<h3 id=\"mental-model-bookmarks-in-history\">Mental Model: Bookmarks in History</h3>\n<p>Think of Git references as <strong>bookmarks in a vast historical library</strong>. Imagine you&#39;re researching in a library where every book represents a commit, and books are shelved by their unique catalog number (the SHA-1 hash). Without bookmarks, you&#39;d need to remember cryptic 40-character numbers like &quot;a1b2c3d4e5f6...&quot; to find the books you care about.</p>\n<p>Git references are like labeled bookmarks you can place anywhere in this library:</p>\n<ul>\n<li><strong>Branch references</strong> are moveable bookmarks that automatically advance to new books as you add them to a series</li>\n<li><strong>Tag references</strong> are permanent bookmarks that never move, marking important milestones</li>\n<li><strong>HEAD</strong> is your special &quot;you are here&quot; bookmark that shows which book you&#39;re currently reading</li>\n</ul>\n<p>When you create a new branch called &quot;feature-login&quot;, you&#39;re essentially placing a bookmark labeled &quot;feature-login&quot; at the current book (commit). As you write new chapters (make new commits), that bookmark automatically moves forward to always point to your latest work. Meanwhile, other bookmarks like &quot;main&quot; stay put unless you explicitly move them.</p>\n<p>The HEAD reference is particularly special—it&#39;s like having a &quot;current location&quot; bookmark that can either:</p>\n<ul>\n<li>Point to one of your labeled bookmarks (when you&#39;re &quot;on a branch&quot;)</li>\n<li>Point directly to a specific book (when you have a &quot;detached HEAD&quot;)</li>\n</ul>\n<p>This system allows you to navigate through your project&#39;s history using memorable names instead of memorizing long hash strings, while Git maintains the cryptographic integrity of the underlying object store.</p>\n<h3 id=\"symbolic-vs-direct-references\">Symbolic vs Direct References</h3>\n<p>Git&#39;s reference system supports two fundamentally different types of references that serve distinct purposes in branch management and navigation. Understanding this distinction is crucial for implementing proper branch switching and detached HEAD state handling.</p>\n<p><strong>Direct references</strong> store a raw commit SHA-1 hash and point directly to a commit object in the object store. These references contain exactly 40 hexadecimal characters followed by a newline, with no additional formatting or indirection. When Git needs to resolve a direct reference, it simply reads the hash value and uses it to look up the commit object.</p>\n<p><strong>Symbolic references</strong> store a reference to another reference, creating a level of indirection in the resolution process. The most important symbolic reference is HEAD, which typically contains content like <code>ref: refs/heads/main\\n</code> instead of a raw hash. When Git resolves a symbolic reference, it first reads the reference name, then follows that reference to find the actual commit hash.</p>\n<p>The HEAD reference demonstrates why this distinction matters for branch management. When you&#39;re working on a branch, HEAD contains a symbolic reference pointing to the current branch (e.g., <code>ref: refs/heads/feature-branch</code>). This means that when you make a new commit, Git updates the branch reference file, and HEAD automatically points to the new commit through the symbolic link. This is how Git knows to advance the current branch when you commit.</p>\n<p>However, when you check out a specific commit hash (creating a detached HEAD state), HEAD becomes a direct reference containing the raw commit SHA-1. In this state, making new commits doesn&#39;t update any branch—the commits exist but aren&#39;t reachable through any branch name.</p>\n<table>\n<thead>\n<tr>\n<th>Reference Type</th>\n<th>Content Format</th>\n<th>Resolution Process</th>\n<th>Use Case</th>\n<th>Example Content</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Direct</td>\n<td>Raw SHA-1 hash + newline</td>\n<td>Single lookup in object store</td>\n<td>Branch tips, tags, detached HEAD</td>\n<td><code>a1b2c3d4e5f6789...</code></td>\n</tr>\n<tr>\n<td>Symbolic</td>\n<td><code>ref: </code> + reference path + newline</td>\n<td>Two-step: resolve target ref, then lookup</td>\n<td>HEAD pointing to current branch</td>\n<td><code>ref: refs/heads/main</code></td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Design Principle</strong>: The symbolic reference mechanism enables Git&#39;s branch semantics. Without symbolic references, there would be no concept of &quot;being on a branch&quot;—you would always be in a detached state, and commits wouldn&#39;t automatically advance any branch pointer.</p>\n</blockquote>\n<p><strong>Reference Resolution Algorithm</strong></p>\n<p>The process of resolving any reference to its final commit hash follows these steps:</p>\n<ol>\n<li><strong>Read the reference file</strong> from the appropriate location (<code>.git/HEAD</code>, <code>.git/refs/heads/branchname</code>, etc.)</li>\n<li><strong>Check the content format</strong> by examining the first few bytes for the <code>ref: </code> prefix</li>\n<li><strong>For symbolic references</strong>: Extract the target reference path, then recursively resolve that reference</li>\n<li><strong>For direct references</strong>: Validate the SHA-1 format (40 hex characters) and return the hash</li>\n<li><strong>Verify the target commit exists</strong> in the object store before considering resolution successful</li>\n</ol>\n<p>This resolution process can chain multiple symbolic references, though in practice Git repositories rarely have chains longer than two levels (HEAD → branch → commit).</p>\n<blockquote>\n<p><strong>Decision: Single-Level Symbolic Reference Implementation</strong></p>\n<ul>\n<li><strong>Context</strong>: While Git supports arbitrary symbolic reference chains, most real-world usage involves only HEAD pointing to branches</li>\n<li><strong>Options Considered</strong>: Full recursive resolution vs single-level resolution vs direct references only</li>\n<li><strong>Decision</strong>: Implement single-level symbolic reference resolution (HEAD → branch → commit)</li>\n<li><strong>Rationale</strong>: Covers 99% of real Git usage while keeping implementation simple and reducing infinite loop risk</li>\n<li><strong>Consequences</strong>: Enables proper branch semantics and detached HEAD handling without complex recursion logic</li>\n</ul>\n</blockquote>\n<h3 id=\"branch-creation-and-switching\">Branch Creation and Switching</h3>\n<p>Branch management operations form the core of Git&#39;s workflow, allowing developers to create parallel lines of development and switch between them safely. The implementation must handle three primary operations: creating new branches, switching between existing branches, and managing the transition between attached and detached HEAD states.</p>\n<p><strong>Branch Creation Process</strong></p>\n<p>Creating a new branch involves establishing a new reference that points to a specific commit, typically the current HEAD commit. The process requires careful coordination between the reference system and the working directory to maintain repository consistency.</p>\n<p>The branch creation algorithm proceeds through these steps:</p>\n<ol>\n<li><strong>Resolve the target commit hash</strong> from the specified starting point (HEAD by default, or a specific commit/branch name)</li>\n<li><strong>Validate the target commit exists</strong> in the object store to prevent creating branches that point to non-existent commits</li>\n<li><strong>Check for branch name conflicts</strong> by verifying no file exists at <code>.git/refs/heads/branch-name</code></li>\n<li><strong>Create the branch reference file</strong> at <code>.git/refs/heads/branch-name</code> containing the target commit hash</li>\n<li><strong>Optionally switch to the new branch</strong> by updating HEAD to point to the new branch reference</li>\n</ol>\n<p>Branch names must follow Git&#39;s reference naming rules to avoid conflicts with the file system and Git&#39;s internal operations. Valid branch names cannot contain spaces, control characters, or special sequences like <code>..</code> that could interfere with reference resolution.</p>\n<table>\n<thead>\n<tr>\n<th>Branch Creation Input</th>\n<th>Target Commit Resolution</th>\n<th>Result</th>\n<th>Example</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>git branch feature</code></td>\n<td>Current HEAD commit</td>\n<td>New branch at HEAD</td>\n<td><code>refs/heads/feature</code> → <code>abc123...</code></td>\n</tr>\n<tr>\n<td><code>git branch hotfix main</code></td>\n<td>Tip of main branch</td>\n<td>New branch at main&#39;s tip</td>\n<td><code>refs/heads/hotfix</code> → <code>def456...</code></td>\n</tr>\n<tr>\n<td><code>git branch release abc123</code></td>\n<td>Specific commit hash</td>\n<td>New branch at that commit</td>\n<td><code>refs/heads/release</code> → <code>abc123...</code></td>\n</tr>\n</tbody></table>\n<p><strong>Branch Switching Algorithm</strong></p>\n<p>Switching branches requires updating both HEAD and the working directory to reflect the target branch&#39;s state. This operation is one of the most complex in Git because it must handle file system changes while maintaining data safety.</p>\n<p>The branch switching process involves several critical steps:</p>\n<ol>\n<li><strong>Resolve the target branch reference</strong> to get the target commit hash, handling both local branches and commit hashes</li>\n<li><strong>Check working directory status</strong> to detect uncommitted changes that might be lost during the switch</li>\n<li><strong>Load the target commit&#39;s tree object</strong> to determine what files should exist in the working directory</li>\n<li><strong>Calculate working directory changes</strong> by comparing current files with the target tree structure</li>\n<li><strong>Apply file system changes</strong> by creating, modifying, or deleting files to match the target tree</li>\n<li><strong>Update HEAD reference</strong> to point to the target branch (symbolic) or commit (direct)</li>\n<li><strong>Update the index</strong> to reflect the new working directory state if necessary</li>\n</ol>\n<p>The most critical aspect of branch switching is handling uncommitted changes safely. Git uses a three-way comparison between the current HEAD, target commit, and working directory to determine if changes can be preserved or if they would be lost.</p>\n<p><strong>Working Directory Update Strategy</strong></p>\n<p>When switching branches, Git must transform the working directory from one tree state to another while preserving user work where possible. This involves analyzing each file in both trees and applying the appropriate changes.</p>\n<table>\n<thead>\n<tr>\n<th>Current File State</th>\n<th>Target File State</th>\n<th>Action Required</th>\n<th>Conflict Potential</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Exists, clean</td>\n<td>Exists, different content</td>\n<td>Overwrite with target</td>\n<td>None</td>\n</tr>\n<tr>\n<td>Exists, modified</td>\n<td>Exists, different content</td>\n<td>Check for conflicts</td>\n<td>High - may lose changes</td>\n</tr>\n<tr>\n<td>Exists, clean</td>\n<td>Does not exist</td>\n<td>Delete file</td>\n<td>None</td>\n</tr>\n<tr>\n<td>Exists, modified</td>\n<td>Does not exist</td>\n<td>Refuse switch or force delete</td>\n<td>High - would lose changes</td>\n</tr>\n<tr>\n<td>Does not exist</td>\n<td>Exists</td>\n<td>Create with target content</td>\n<td>Low - check for untracked conflicts</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Safety Principle</strong>: Git should never silently lose user data. Branch switching must either preserve all changes or explicitly warn the user about potential data loss and require confirmation.</p>\n</blockquote>\n<p><strong>Detached HEAD State Management</strong></p>\n<p>The detached HEAD state occurs when HEAD points directly to a commit hash rather than to a branch reference. This state is essential for examining historical commits, building releases from specific points, or creating experimental commits that aren&#39;t part of any branch.</p>\n<p>Entering detached HEAD state happens in several scenarios:</p>\n<ol>\n<li><strong>Explicit commit checkout</strong>: <code>git checkout abc123</code> where <code>abc123</code> is a commit hash</li>\n<li><strong>Tag checkout</strong>: <code>git checkout v1.2.3</code> where the tag points to a commit rather than a branch</li>\n<li><strong>Historical navigation</strong>: <code>git checkout HEAD~3</code> to examine a previous commit</li>\n</ol>\n<p>The implementation must handle the transition between attached and detached states carefully, updating HEAD&#39;s content format and providing clear user feedback about the state change.</p>\n<p><strong>Detached HEAD State Transitions</strong></p>\n<p><img src=\"/api/project/build-git/architecture-doc/asset?path=diagrams%2Freference-states.svg\" alt=\"Reference State Machine\"></p>\n<p>The state machine shows the valid transitions between different HEAD states and the operations that trigger them. Each state has different implications for commit behavior and branch advancement.</p>\n<table>\n<thead>\n<tr>\n<th>Current State</th>\n<th>Operation</th>\n<th>Next State</th>\n<th>HEAD Content</th>\n<th>Branch Update Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>On branch <code>main</code></td>\n<td><code>checkout feature-branch</code></td>\n<td>On branch <code>feature-branch</code></td>\n<td><code>ref: refs/heads/feature-branch</code></td>\n<td>Commits advance feature-branch</td>\n</tr>\n<tr>\n<td>On branch <code>main</code></td>\n<td><code>checkout abc123</code></td>\n<td>Detached HEAD</td>\n<td><code>abc123...</code></td>\n<td>Commits create orphan history</td>\n</tr>\n<tr>\n<td>Detached HEAD</td>\n<td><code>checkout main</code></td>\n<td>On branch <code>main</code></td>\n<td><code>ref: refs/heads/main</code></td>\n<td>Commits advance main branch</td>\n</tr>\n<tr>\n<td>Detached HEAD</td>\n<td>Create new branch from HEAD</td>\n<td>On new branch</td>\n<td><code>ref: refs/heads/new-branch</code></td>\n<td>Commits advance new-branch</td>\n</tr>\n</tbody></table>\n<p><strong>Reference File Management</strong></p>\n<p>The reference system stores all branch and tag information as plain text files within the <code>.git/refs/</code> directory tree. This simple approach makes Git repositories inspectable and debuggable with standard file system tools while providing atomic updates through file system operations.</p>\n<p>The directory structure organizes references by type and namespace:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>.git/\n  HEAD                    ← current branch pointer (symbolic ref)\n  refs/\n    heads/               ← local branches\n      main               ← contains commit hash for main branch\n      feature-login      ← contains commit hash for feature-login branch\n      hotfix/security    ← branches can have path separators\n    remotes/             ← remote-tracking branches (future extension)\n      origin/main        ← tracks remote main branch\n    tags/                ← tag references\n      v1.0.0            ← contains commit hash for v1.0.0 tag</code></pre></div>\n\n<p>Each reference file contains a single line of text: either a raw SHA-1 hash (for direct references) or a symbolic reference in the format <code>ref: refs/heads/branch-name</code>. The newline character at the end is significant and must be preserved for compatibility with Git&#39;s reference parsing.</p>\n<p><strong>Atomic Reference Updates</strong></p>\n<p>Reference updates must be atomic to prevent repository corruption during concurrent operations or system failures. The implementation uses the standard technique of writing to a temporary file and then atomically renaming it to the target location.</p>\n<p>The atomic update process follows these steps:</p>\n<ol>\n<li><strong>Generate a unique temporary filename</strong> in the same directory as the target reference file</li>\n<li><strong>Write the new reference content</strong> to the temporary file, including the required newline character</li>\n<li><strong>Sync the temporary file</strong> to ensure the data is written to stable storage</li>\n<li><strong>Atomically rename</strong> the temporary file to the final reference filename</li>\n<li><strong>Clean up</strong> any temporary files on failure to avoid leaving debris in the repository</li>\n</ol>\n<p>This approach ensures that reference files are never in an inconsistent state—they either contain the old value or the new value, never partial writes or corrupted data.</p>\n<blockquote>\n<p><strong>Decision: Plain Text Reference Files</strong></p>\n<ul>\n<li><strong>Context</strong>: Git needs to store mappings from branch names to commit hashes with atomic updates and human readability</li>\n<li><strong>Options Considered</strong>: Plain text files vs binary packed format vs embedded database</li>\n<li><strong>Decision</strong>: Use plain text files in .git/refs/ directory structure</li>\n<li><strong>Rationale</strong>: Simple implementation, atomic updates via file system, human-readable for debugging, compatible with Git tooling</li>\n<li><strong>Consequences</strong>: Slightly slower than packed refs for repositories with thousands of branches, but much simpler and more reliable</li>\n</ul>\n</blockquote>\n<p><strong>Branch Name Validation</strong></p>\n<p>Branch names must follow specific rules to avoid conflicts with Git&#39;s internal operations and file system limitations. The validation process ensures that branch names can be safely used as file names and don&#39;t interfere with Git&#39;s reference resolution algorithms.</p>\n<p>Invalid branch name patterns include:</p>\n<ul>\n<li><strong>Control characters</strong>: ASCII control characters (0x00-0x1f) that might interfere with text processing</li>\n<li><strong>Path separators</strong>: While <code>/</code> is allowed within branch names, <code>.</code> and <code>..</code> are prohibited to prevent directory traversal</li>\n<li><strong>Special sequences</strong>: Patterns like <code>@{</code> that Git uses for reference specifications</li>\n<li><strong>Reserved names</strong>: Names that conflict with Git&#39;s internal references or common conventions</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>Pattern</th>\n<th>Valid?</th>\n<th>Reason</th>\n<th>Example</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>feature-login</code></td>\n<td>✓</td>\n<td>Alphanumeric with hyphens</td>\n<td>Standard branch name</td>\n</tr>\n<tr>\n<td><code>hotfix/security</code></td>\n<td>✓</td>\n<td>Slash creates namespace</td>\n<td>Organized branch structure</td>\n</tr>\n<tr>\n<td><code>release-1.0</code></td>\n<td>✓</td>\n<td>Alphanumeric with dash and dot</td>\n<td>Version branch naming</td>\n</tr>\n<tr>\n<td><code>.hidden</code></td>\n<td>✗</td>\n<td>Leading dot reserved</td>\n<td>Could conflict with Git internals</td>\n</tr>\n<tr>\n<td><code>branch..name</code></td>\n<td>✗</td>\n<td>Double dot reserved</td>\n<td>Conflicts with revision syntax</td>\n</tr>\n<tr>\n<td><code>branch name</code></td>\n<td>✗</td>\n<td>Spaces cause parsing issues</td>\n<td>Would break command line tools</td>\n</tr>\n</tbody></table>\n<p><strong>Common Pitfalls</strong></p>\n<p>⚠️ <strong>Pitfall: Forgetting to Update Working Directory During Branch Switch</strong></p>\n<p>Many implementations correctly update HEAD but forget to modify the working directory files to match the target branch&#39;s tree. This leaves the repository in an inconsistent state where HEAD points to one commit but the working directory contains files from another commit.</p>\n<p>The symptoms include: files appearing modified immediately after a branch switch, confusion about which branch&#39;s changes are visible, and potential data loss when users assume they&#39;re working on a different branch than their files represent.</p>\n<p><strong>Fix</strong>: Always implement the complete branch switching algorithm that updates both HEAD and working directory atomically, or fail the entire operation if working directory updates cannot be completed safely.</p>\n<p>⚠️ <strong>Pitfall: Creating Branches Without Validating Target Commits</strong></p>\n<p>Creating a branch reference that points to a non-existent commit hash creates a broken branch that cannot be checked out or used for any operations. This commonly happens when implementing branch creation from user-specified commit hashes without verifying the commits exist.</p>\n<p>The symptoms include: branches that appear in branch listings but cannot be checked out, error messages about missing objects when trying to use the branch, and confusion about whether commits were lost or never existed.</p>\n<p><strong>Fix</strong>: Always validate that the target commit exists in the object store before creating any reference that points to it. Use the <code>object_exists()</code> function to verify commit availability.</p>\n<p>⚠️ <strong>Pitfall: Race Conditions in Reference Updates</strong></p>\n<p>Writing reference files without atomic updates can lead to corruption when multiple Git processes run simultaneously or when system failures occur during writes. This creates partially-written reference files containing truncated hashes or mixed content.</p>\n<p>The symptoms include: references containing partial SHA-1 hashes, &quot;not a valid object name&quot; errors when resolving references, and repository corruption that requires manual repair.</p>\n<p><strong>Fix</strong>: Always use atomic file updates with temporary files and rename operations. Never write directly to reference files in-place.</p>\n<p>⚠️ <strong>Pitfall: Incorrect HEAD Format for Symbolic References</strong></p>\n<p>The HEAD file format for symbolic references is strict: <code>ref: refs/heads/branch-name\\n</code> with exactly one space after the colon, no extra whitespace, and a single trailing newline. Deviating from this format breaks reference resolution.</p>\n<p>Common mistakes include: missing the space after the colon (<code>ref:refs/heads/main</code>), adding extra spaces or tabs, omitting the trailing newline, or using Windows line endings (<code>\\r\\n</code>) instead of Unix line endings.</p>\n<p><strong>Fix</strong>: Use string constants for the symbolic reference format and validate the exact format when reading symbolic references. Always use binary file writing to control line endings precisely.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The reference management system requires careful attention to file system operations and atomic updates. This implementation provides a robust foundation for branch operations while maintaining compatibility with Git&#39;s reference format.</p>\n<p><strong>Technology Recommendations</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>File Operations</td>\n<td><code>pathlib.Path</code> with text read/write</td>\n<td><code>pathlib.Path</code> with atomic writes and file locking</td>\n</tr>\n<tr>\n<td>Reference Resolution</td>\n<td>Recursive function with depth limit</td>\n<td>State machine with cycle detection</td>\n</tr>\n<tr>\n<td>Branch Validation</td>\n<td>Regular expression patterns</td>\n<td>Full Git reference name validation</td>\n</tr>\n<tr>\n<td>Concurrent Access</td>\n<td>File system atomic operations</td>\n<td>Advisory file locking with timeouts</td>\n</tr>\n</tbody></table>\n<p><strong>Recommended File Structure</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#E1E4E8\">project</span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\">root</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">  git_implementation</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    core</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      repository.py          ← Repository </span><span style=\"color:#F97583\">class</span><span style=\"color:#F97583\"> with</span><span style=\"color:#E1E4E8\"> reference methods</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      reference_manager.py   ← ReferenceManager implementation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      object_store.py       ← ObjectStore </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> commit validation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    utils</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      file_operations.py    ← Atomic </span><span style=\"color:#FFAB70\">file</span><span style=\"color:#E1E4E8\"> write utilities</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      validation.py         ← Branch name validation functions</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    tests</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      test_references.py    ← Reference system tests</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      test_branches.py      ← Branch operation tests</span></span></code></pre></div>\n\n<p><strong>Infrastructure Starter Code</strong></p>\n<p>Here&#39;s a complete atomic file operations utility that handles the low-level file system operations needed for safe reference updates:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Atomic file operations for safe repository updates.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Provides utilities for writing files atomically to prevent corruption.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> os</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> tempfile</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Union</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> atomic_write_file</span><span style=\"color:#E1E4E8\">(file_path: Path, content: Union[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">]) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Write content to a file atomically using temporary file and rename.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        file_path: Target file path to write</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        content: Content to write (str or bytes)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Raises:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        OSError: If file operations fail</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        UnicodeEncodeError: If string content cannot be encoded as UTF-8</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Ensure parent directory exists</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    file_path.parent.mkdir(</span><span style=\"color:#FFAB70\">parents</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">exist_ok</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Create temporary file in same directory for atomic rename</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    temp_fd, temp_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> tempfile.mkstemp(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        dir</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">file_path.parent,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        prefix</span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\".tmp_</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">file_path.name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">_\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        suffix</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\".tmp\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#E1E4E8\"> os.fdopen(temp_fd, </span><span style=\"color:#9ECBFF\">'wb'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> temp_file:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(content, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                temp_file.write(content.encode(</span><span style=\"color:#9ECBFF\">'utf-8'</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                temp_file.write(content)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Force write to disk before rename</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            temp_file.flush()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            os.fsync(temp_file.fileno())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Atomic rename to final location</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        os.rename(temp_path, file_path)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Clean up temp file on any error</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            os.unlink(temp_path)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> OSError</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span><span style=\"color:#6A737D\">  # Temp file already gone</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> read_reference_file</span><span style=\"color:#E1E4E8\">(ref_path: Path) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Read a Git reference file and return its content.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        ref_path: Path to reference file</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Reference content with trailing whitespace stripped</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Raises:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        FileNotFoundError: If reference file doesn't exist</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        UnicodeDecodeError: If file contains invalid UTF-8</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> open</span><span style=\"color:#E1E4E8\">(ref_path, </span><span style=\"color:#9ECBFF\">'r'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">encoding</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">'utf-8'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> f:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> f.read().rstrip(</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\n\\r</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    except</span><span style=\"color:#79B8FF\"> FileNotFoundError</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> FileNotFoundError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Reference not found: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">ref_path</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> ensure_git_directory_structure</span><span style=\"color:#E1E4E8\">(git_dir: Path) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Create the basic .git directory structure needed for references.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        git_dir: Path to .git directory</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    directories </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"refs\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"refs\"</span><span style=\"color:#F97583\"> /</span><span style=\"color:#9ECBFF\"> \"heads\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"refs\"</span><span style=\"color:#F97583\"> /</span><span style=\"color:#9ECBFF\"> \"tags\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"refs\"</span><span style=\"color:#F97583\"> /</span><span style=\"color:#9ECBFF\"> \"remotes\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> directory </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> directories:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        directory.mkdir(</span><span style=\"color:#FFAB70\">parents</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">exist_ok</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p><strong>Branch Name Validation Utilities</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Git reference name validation following Git's naming rules.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> re</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Git reference name validation patterns</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">INVALID_REF_CHARS</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> re.compile(</span><span style=\"color:#F97583\">r</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">[</span><span style=\"color:#85E89D;font-weight:bold\">\\x00</span><span style=\"color:#79B8FF\">-</span><span style=\"color:#85E89D;font-weight:bold\">\\x1f\\x7f</span><span style=\"color:#79B8FF\">~^:</span><span style=\"color:#85E89D;font-weight:bold\">\\\\\\*\\?</span><span style=\"color:#79B8FF\">]</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">INVALID_REF_SEQUENCES</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> [</span><span style=\"color:#9ECBFF\">'.'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'..'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'@{'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'//'</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">RESERVED_REF_NAMES</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> {</span><span style=\"color:#9ECBFF\">'HEAD'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'ORIG_HEAD'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'FETCH_HEAD'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'MERGE_HEAD'</span><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> validate_branch_name</span><span style=\"color:#E1E4E8\">(name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Validate a branch name against Git's reference naming rules.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        name: Proposed branch name</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        List of validation error messages (empty if valid)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    errors </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> name:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        errors.append(</span><span style=\"color:#9ECBFF\">\"Branch name cannot be empty\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> errors</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> name </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> RESERVED_REF_NAMES</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        errors.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"'</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">' is a reserved reference name\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> name.startswith(</span><span style=\"color:#9ECBFF\">'.'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">or</span><span style=\"color:#E1E4E8\"> name.endswith(</span><span style=\"color:#9ECBFF\">'.'</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        errors.append(</span><span style=\"color:#9ECBFF\">\"Branch name cannot start or end with '.'\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> name.startswith(</span><span style=\"color:#9ECBFF\">'/'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">or</span><span style=\"color:#E1E4E8\"> name.endswith(</span><span style=\"color:#9ECBFF\">'/'</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        errors.append(</span><span style=\"color:#9ECBFF\">\"Branch name cannot start or end with '/'\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#79B8FF\"> INVALID_REF_CHARS</span><span style=\"color:#E1E4E8\">.search(name):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        errors.append(</span><span style=\"color:#9ECBFF\">\"Branch name contains invalid characters\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> sequence </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> INVALID_REF_SEQUENCES</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> sequence </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> name:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            errors.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Branch name cannot contain '</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">sequence</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">'\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> errors</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> is_valid_branch_name</span><span style=\"color:#E1E4E8\">(name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Check if a branch name is valid.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(validate_branch_name(name)) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span></span></code></pre></div>\n\n<p><strong>Core Logic Skeleton Code</strong></p>\n<p>Here&#39;s the main <code>ReferenceManager</code> class structure with detailed TODO comments for implementation:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Git reference management system handling branches, HEAD, and symbolic references.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional, Dict, Set</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> hashlib</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ReferenceManager</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Manages Git references including branches, HEAD, and symbolic references.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, git_dir: Path):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.git_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_dir</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.refs_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"refs\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.heads_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.refs_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"heads\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.tags_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.refs_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"tags\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.head_file </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"HEAD\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> resolve_reference</span><span style=\"color:#E1E4E8\">(self, ref_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Resolve a reference name to its target commit hash.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Handles both direct references (containing commit hashes) and</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        symbolic references (containing 'ref: path/to/other/ref').</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            ref_name: Reference to resolve (e.g., 'HEAD', 'main', 'refs/heads/feature')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Commit SHA-1 hash if reference exists and resolves, None otherwise</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Handle special case of 'HEAD' - read from self.head_file</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: If ref_name doesn't start with 'refs/', try 'refs/heads/' + ref_name</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Construct full path to reference file</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Check if reference file exists, return None if not</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Read reference file content using read_reference_file()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Check if content starts with 'ref: ' (symbolic reference)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: For symbolic refs: extract target path and recursively resolve</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: For direct refs: validate SHA-1 format and return hash</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 9: Add recursion depth limit to prevent infinite loops</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use validate_sha1_hash() to check hash format</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> create_branch</span><span style=\"color:#E1E4E8\">(self, branch_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, target_commit: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Create a new branch pointing to the specified commit.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            branch_name: Name for the new branch</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            target_commit: SHA-1 hash of commit to point to</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            True if branch was created successfully, False otherwise</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate branch name using validate_branch_name()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Verify target_commit exists in object store using object_exists()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Check if branch already exists (refs/heads/branch_name file exists)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Create branch reference file with atomic_write_file()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Write target_commit hash + '\\n' to the branch file</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return success/failure status</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Branch file path is self.heads_dir / branch_name</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> switch_branch</span><span style=\"color:#E1E4E8\">(self, branch_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Switch to an existing branch by updating HEAD.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        This is a simplified version that only updates references without</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        modifying the working directory or index.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            branch_name: Name of branch to switch to</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            True if switch was successful, False otherwise</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Verify target branch exists using branch_exists()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Create symbolic reference content: f\"ref: refs/heads/{branch_name}\\n\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Write symbolic reference to HEAD file using atomic_write_file()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return success status</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Note: Full implementation would also update working directory</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> checkout_commit</span><span style=\"color:#E1E4E8\">(self, commit_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Enter detached HEAD state by pointing HEAD directly to a commit.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            commit_hash: SHA-1 hash of commit to check out</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            True if checkout was successful, False otherwise</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate commit_hash format using validate_sha1_hash()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Verify commit exists in object store using object_exists()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Write commit hash + '\\n' directly to HEAD file (direct reference)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return success status</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Note: This creates detached HEAD state</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_current_branch</span><span style=\"color:#E1E4E8\">(self) -> Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Get the name of the current branch, if HEAD points to a branch.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Branch name if on a branch, None if in detached HEAD state</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Read HEAD file content</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check if content starts with 'ref: refs/heads/'</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Extract branch name from symbolic reference</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return branch name or None for detached HEAD</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> list_branches</span><span style=\"color:#E1E4E8\">(self) -> Set[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        List all local branches in the repository.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Set of branch names</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if refs/heads directory exists</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Iterate through all files in refs/heads directory</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Use glob or iterdir to find all branch files</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Extract branch names (relative paths from refs/heads/)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return set of branch names</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use Path.iterdir() and handle subdirectories for namespaced branches</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> delete_branch</span><span style=\"color:#E1E4E8\">(self, branch_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, force: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> False</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Delete a branch reference.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            branch_name: Name of branch to delete</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            force: If True, delete even if it's the current branch</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            True if deletion was successful, False otherwise</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if branch exists</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: If not force, verify branch is not current branch</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Remove branch reference file using Path.unlink()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Handle FileNotFoundError gracefully</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return success status</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> branch_exists</span><span style=\"color:#E1E4E8\">(self, branch_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Check if a branch exists.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check if refs/heads/branch_name file exists</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> is_detached_head</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Check if HEAD is in detached state (points to commit, not branch).\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Read HEAD file content</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Return True if content is a SHA-1 hash, False if symbolic ref</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> validate_sha1_hash</span><span style=\"color:#E1E4E8\">(hash_str: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Validate that a string is a valid SHA-1 hash.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(hash_str) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 40</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        int</span><span style=\"color:#E1E4E8\">(hash_str, </span><span style=\"color:#79B8FF\">16</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    except</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> False</span></span></code></pre></div>\n\n<p><strong>Language-Specific Hints</strong></p>\n<ul>\n<li>Use <code>pathlib.Path</code> for all file system operations - it handles path joining and OS differences automatically</li>\n<li>Python&#39;s <code>tempfile.mkstemp()</code> creates temporary files securely with proper permissions</li>\n<li>Always use <code>&#39;utf-8&#39;</code> encoding when reading/writing text files to ensure compatibility</li>\n<li>Use <code>os.fsync()</code> after writing critical files like references to ensure data reaches disk</li>\n<li>The <code>rstrip(&#39;\\n\\r&#39;)</code> method handles both Unix and Windows line endings when reading files</li>\n<li>Use <code>Path.mkdir(parents=True, exist_ok=True)</code> to create directory trees safely</li>\n</ul>\n<p><strong>Milestone Checkpoint</strong></p>\n<p>After implementing the reference management system, verify these behaviors:</p>\n<ol>\n<li><strong>Branch Creation</strong>: Create a branch with <code>create_branch(&#39;feature&#39;, &#39;commit_hash&#39;)</code> and verify the file <code>refs/heads/feature</code> contains the commit hash</li>\n<li><strong>Branch Listing</strong>: Call <code>list_branches()</code> and verify it returns all branch names from the file system</li>\n<li><strong>HEAD Management</strong>: Switch branches and verify HEAD content changes between symbolic and direct references</li>\n<li><strong>Reference Resolution</strong>: Test resolving &#39;HEAD&#39;, branch names, and full reference paths</li>\n<li><strong>Detached HEAD</strong>: Checkout a commit hash and verify <code>is_detached_head()</code> returns True</li>\n</ol>\n<p>Expected file system state after creating branch &#39;feature&#39;:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>.git/\n  HEAD                     ← contains &quot;ref: refs/heads/main\\n&quot;\n  refs/heads/\n    main                   ← contains commit hash\n    feature                ← contains same or different commit hash</code></pre></div>\n\n<p><strong>Debugging Tips</strong></p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Branch appears in listing but cannot be resolved</td>\n<td>Invalid commit hash in branch file</td>\n<td>Check file contents with <code>cat .git/refs/heads/branch</code></td>\n<td>Recreate branch with valid commit hash</td>\n</tr>\n<tr>\n<td>HEAD resolution fails after branch switch</td>\n<td>Incorrect symbolic reference format</td>\n<td>Check HEAD file format: should be <code>ref: refs/heads/branch\\n</code></td>\n<td>Rewrite HEAD with correct format</td>\n</tr>\n<tr>\n<td>Branch creation succeeds but branch disappears</td>\n<td>Missing newline in reference file</td>\n<td>Check file ends with <code>\\n</code> character</td>\n<td>Always append <code>\\n</code> to reference content</td>\n</tr>\n<tr>\n<td>Permission denied when updating references</td>\n<td>Incorrect file permissions on .git directory</td>\n<td>Check <code>.git</code> directory is writable</td>\n<td>Set proper permissions with <code>chmod</code></td>\n</tr>\n<tr>\n<td>Reference resolution enters infinite loop</td>\n<td>Circular symbolic reference</td>\n<td>Trace reference chain manually</td>\n<td>Add recursion depth limit to resolution</td>\n</tr>\n</tbody></table>\n<h2 id=\"diff-algorithm-implementation\">Diff Algorithm Implementation</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section is critical for Milestone 7 (Diff Algorithm) and provides the foundation for conflict detection in Milestone 8 (Three-Way Merge). The diff algorithm serves as the core comparison engine for status calculation in Milestone 6 (Index/Staging Area).</p>\n</blockquote>\n<p>The diff algorithm forms the analytical heart of any version control system. While Git&#39;s object store provides immutable content storage and the index manages staging, the diff algorithm answers the fundamental question: &quot;What changed between two versions of a file or project?&quot; This capability underpins virtually every Git operation that involves comparison - from <code>git status</code> showing modified files to <code>git merge</code> detecting conflicts between branches.</p>\n<p>The challenge of implementing diff extends beyond simple file comparison. A naive approach of comparing files byte-by-byte would only tell us whether files are identical or different, but not what specifically changed. Users need to see exactly which lines were added, removed, or modified, preferably in a format that highlights the minimal set of changes required to transform one version into another. This is where sophisticated diff algorithms like Myers&#39; algorithm excel, finding the shortest edit script between two sequences while producing human-readable output.</p>\n<p>Our diff implementation must handle several complex scenarios: comparing files with vastly different line counts, detecting when entire sections have moved, handling binary files gracefully, and producing output that follows industry-standard unified diff format. The algorithm must also be efficient enough to handle large files without consuming excessive memory or computation time.</p>\n<h3 id=\"mental-model-document-comparison\">Mental Model: Document Comparison</h3>\n<p>Think of the diff algorithm as an expert editor comparing two drafts of the same manuscript. When an author submits a revised chapter, the editor doesn&#39;t simply declare &quot;these are different&quot; - instead, they meticulously identify each change: &quot;In paragraph 3, you added a new sentence about character motivation. In paragraph 7, you removed the description of the sunset. In paragraph 12, you changed &#39;walked&#39; to &#39;strode&#39;.&quot;</p>\n<p>This editor has developed a systematic approach over years of experience. They don&#39;t just scan randomly - they find the longest unchanged passages first (these serve as anchor points), then focus their attention on the gaps between these passages where changes must have occurred. When they find a section that appears in both drafts but in different locations, they recognize it as moved content rather than a deletion followed by an addition.</p>\n<p>The editor also knows that their goal isn&#39;t just accuracy, but usefulness. They present changes in a format that makes it easy for the author to understand what happened: showing a few lines of unchanged context around each change, grouping nearby changes together, and using clear markers to indicate additions and deletions. This is exactly how Myers&#39; diff algorithm works - it finds the minimal set of changes between two text sequences and presents them in a format optimized for human comprehension.</p>\n<p>The key insight is that effective diff algorithms don&#39;t just identify differences - they find the <strong>optimal</strong> set of differences that minimizes cognitive load for the person reviewing the changes. This requires sophisticated algorithms that can distinguish between genuine changes and coincidental similarities, while producing output that tells a coherent story about how one version evolved into another.</p>\n<h3 id=\"myers-diff-algorithm\">Myers Diff Algorithm</h3>\n<p>The Myers diff algorithm, developed by Eugene Myers in 1986, represents the gold standard for computing differences between two sequences. Unlike simpler approaches that might miss optimal solutions, Myers&#39; algorithm is guaranteed to find the shortest edit script - the minimal sequence of insertions and deletions needed to transform one file into another. This optimality is crucial for producing readable diffs that don&#39;t overwhelm users with unnecessary noise.</p>\n<p>The algorithm operates on a fundamental insight about the structure of edit problems. When comparing two sequences A and B, we can visualize the problem as finding a path through a two-dimensional grid where the x-axis represents positions in sequence A and the y-axis represents positions in sequence B. Each cell (i,j) in this grid represents the state where we&#39;ve processed i elements from sequence A and j elements from sequence B.</p>\n<p>From any cell in this grid, we have three possible moves: move right (delete an element from A), move down (insert an element from B), or move diagonally (elements match, no edit required). Our goal is to find the path from the top-left corner (0,0) to the bottom-right corner (len(A), len(B)) that requires the fewest non-diagonal moves. Each non-diagonal move corresponds to an edit operation, so minimizing these moves gives us the shortest edit script.</p>\n<p>The brilliance of Myers&#39; algorithm lies in how it explores this space efficiently. Rather than examining every possible path (which would be exponential), it uses a technique called &quot;edit distance computation with greedy matching.&quot; The algorithm processes the comparison in phases, where each phase considers all possible paths that require exactly k edit operations. Within each phase, it greedily extends paths as far as possible using diagonal moves (matching elements), which cost nothing.</p>\n<p>Here&#39;s how the algorithm proceeds step by step:</p>\n<ol>\n<li><p><strong>Initialize the exploration</strong>: Create a data structure to track the furthest position reachable along each diagonal for a given number of edits. A diagonal d represents positions where (x - y = d). We track V[d] = x, the furthest x-coordinate reached on diagonal d.</p>\n</li>\n<li><p><strong>Iterative deepening by edit distance</strong>: For each possible edit distance k from 0 to the maximum possible (len(A) + len(B)), explore all paths that require exactly k edits. This ensures we find the optimal solution as soon as one exists.</p>\n</li>\n<li><p><strong>Diagonal exploration</strong>: For each diagonal d that could be reached with k edits, calculate the furthest point reachable. We can reach diagonal d either by moving right from diagonal d-1 (deletion) or by moving down from diagonal d+1 (insertion). Choose the option that gets us furthest along diagonal d.</p>\n</li>\n<li><p><strong>Greedy extension</strong>: Once we&#39;ve determined our starting position on diagonal d, extend as far as possible using diagonal moves (matching elements). This is the &quot;greedy&quot; part - we take all free matches we can get.</p>\n</li>\n<li><p><strong>Termination check</strong>: After exploring all diagonals for edit distance k, check if any path has reached the target position (len(A), len(B)). If so, we&#39;ve found the optimal solution with k edits.</p>\n</li>\n<li><p><strong>Backtracking for edit script</strong>: Once we&#39;ve found the optimal edit distance, we need to reconstruct the actual sequence of edits. This requires backtracking through our exploration data to find which moves led to the optimal path.</p>\n</li>\n</ol>\n<p>The algorithm&#39;s time complexity is O((M+N)D) where M and N are the lengths of the sequences and D is the length of the shortest edit script. In practice, this performs much better than the theoretical worst case because D is typically much smaller than M+N for most real-world comparisons.</p>\n<table>\n<thead>\n<tr>\n<th>Algorithm Phase</th>\n<th>Purpose</th>\n<th>Data Structure</th>\n<th>Time Complexity</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Forward Pass</td>\n<td>Find minimum edit distance</td>\n<td>V array tracking furthest x per diagonal</td>\n<td>O((M+N)D)</td>\n</tr>\n<tr>\n<td>Greedy Extension</td>\n<td>Maximize diagonal moves within each step</td>\n<td>Direct sequence comparison</td>\n<td>O(matching characters)</td>\n</tr>\n<tr>\n<td>Backtrack Pass</td>\n<td>Reconstruct edit sequence</td>\n<td>Trace through V snapshots</td>\n<td>O(D)</td>\n</tr>\n<tr>\n<td>Edit Script Generation</td>\n<td>Convert path to insert/delete operations</td>\n<td>List of edit commands</td>\n<td>O(D)</td>\n</tr>\n</tbody></table>\n<p>The implementation requires careful handling of several edge cases and optimizations:</p>\n<p><strong>Diagonal indexing</strong>: Since diagonals can have negative indices (when y &gt; x), we need to offset our array indices appropriately. The diagonal d=x-y ranges from -N to M, so we use V[d+N] to ensure non-negative array indices.</p>\n<p><strong>Memory optimization</strong>: The basic algorithm stores the entire V array for each edit distance k, which can consume significant memory for large files. Advanced implementations use techniques like &quot;linear space refinement&quot; to reduce memory usage by recomputing portions of the search space as needed.</p>\n<p><strong>Snake detection</strong>: A &quot;snake&quot; in Myers&#39; terminology is a sequence of diagonal moves (matching elements). The algorithm spends most of its time detecting and following these snakes, so optimizing this inner loop is crucial for performance.</p>\n<p><strong>Boundary conditions</strong>: Special care is needed when exploring diagonals at the edges of the search space, where we might only be able to reach a diagonal from one direction rather than both.</p>\n<blockquote>\n<p><strong>Key Insight</strong>: Myers&#39; algorithm&#39;s efficiency comes from recognizing that most file changes are localized. By greedily consuming matching content (diagonal moves) whenever possible, the algorithm quickly navigates through unchanged regions and focuses computational effort on the areas where real differences exist.</p>\n</blockquote>\n<h4 id=\"architecture-decision-records\">Architecture Decision Records</h4>\n<blockquote>\n<p><strong>Decision: Myers Algorithm vs. Patience Diff</strong></p>\n<ul>\n<li><strong>Context</strong>: Multiple diff algorithms exist with different trade-offs in quality and performance. Myers finds shortest edit distance, while Patience diff often produces more intuitive results for code with moved functions.</li>\n<li><strong>Options Considered</strong>: Myers&#39; algorithm (shortest edit script), Patience diff (unique line anchoring), Hunt-McIlroy algorithm (classic LCS-based)</li>\n<li><strong>Decision</strong>: Implement Myers&#39; algorithm as the primary diff engine</li>\n<li><strong>Rationale</strong>: Myers provides optimal edit distance with reasonable performance, matches Git&#39;s internal implementation for compatibility, and has well-understood complexity characteristics. Patience diff can be added later as an alternative strategy.</li>\n<li><strong>Consequences</strong>: Optimal diff output for most cases, some counterintuitive results when functions are moved (can be addressed with post-processing), compatible with existing Git tooling expectations.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Algorithm Option</th>\n<th>Pros</th>\n<th>Cons</th>\n<th>Performance</th>\n<th>Quality</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Myers&#39; Algorithm</td>\n<td>Optimal edit distance, well-studied, Git-compatible</td>\n<td>May miss intuitive moves</td>\n<td>O((M+N)D)</td>\n<td>Mathematically optimal</td>\n</tr>\n<tr>\n<td>Patience Diff</td>\n<td>Better handling of moved code blocks</td>\n<td>More complex, may not be shortest</td>\n<td>O(N log N) typical</td>\n<td>More intuitive for code</td>\n</tr>\n<tr>\n<td>Hunt-McIlroy</td>\n<td>Simple LCS-based approach</td>\n<td>Not optimized for text</td>\n<td>O(MN) worst case</td>\n<td>Basic but functional</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Line-based vs. Character-based Comparison</strong></p>\n<ul>\n<li><strong>Context</strong>: Diff algorithms can operate at different granularities - comparing entire lines, individual characters, or words. Each choice affects both performance and output usefulness.</li>\n<li><strong>Options Considered</strong>: Character-level diff (finest granularity), word-level diff (balanced approach), line-level diff (Git standard)</li>\n<li><strong>Decision</strong>: Implement line-based comparison as primary mode with character-level available for within-line changes</li>\n<li><strong>Rationale</strong>: Line-based comparison matches user expectations for code review, provides good performance for large files, and aligns with Git&#39;s standard behavior. Character-level can be used for highlighting intra-line changes.</li>\n<li><strong>Consequences</strong>: Fast comparison of large files, familiar output format, may miss some fine-grained changes within lines (addressed by intra-line diff post-processing).</li>\n</ul>\n</blockquote>\n<blockquote>\n<p><strong>Decision: In-memory vs. Streaming Comparison</strong></p>\n<ul>\n<li><strong>Context</strong>: Large files may not fit in memory, requiring either streaming algorithms or memory-mapped file access. This affects both memory usage and algorithm complexity.</li>\n<li><strong>Options Considered</strong>: Full in-memory comparison, streaming with limited lookahead, memory-mapped file access</li>\n<li><strong>Decision</strong>: Use in-memory comparison with fallback to &quot;binary file&quot; detection for very large files</li>\n<li><strong>Rationale</strong>: Most source code files are small enough for in-memory processing, simplifies algorithm implementation, and provides better performance for typical use cases. Binary file detection prevents memory exhaustion on large files.</li>\n<li><strong>Consequences</strong>: Excellent performance for typical source files, may not handle very large text files optimally, requires size-based heuristics to detect problematic files.</li>\n</ul>\n</blockquote>\n<h3 id=\"unified-diff-output-format\">Unified Diff Output Format</h3>\n<p>The unified diff format represents the industry standard for presenting file differences in a human-readable form. Developed as an improvement over the older &quot;context diff&quot; format, unified diff consolidates additions and deletions into single hunks, making it easier to understand what changed while providing sufficient context for applying patches accurately.</p>\n<p>Understanding unified diff format is crucial because it serves as the common language between different version control systems, patch utilities, and code review tools. When you see a GitHub pull request, apply a patch with <code>git apply</code>, or review changes in your IDE, you&#39;re likely looking at some variation of unified diff output.</p>\n<p>The format consists of several distinct components, each serving a specific purpose in conveying change information:</p>\n<p><strong>File headers</strong> identify the files being compared and provide metadata about the comparison. The traditional unified diff header includes the original filename prefixed with <code>---</code> and the new filename prefixed with <code>+++</code>. These lines may include timestamps or revision identifiers, though Git typically uses commit hashes or symbolic names like &quot;HEAD&quot; instead of timestamps.</p>\n<p><strong>Hunk headers</strong> mark the beginning of each contiguous block of changes. A hunk header appears as <code>@@ -start,count +start,count @@</code> where the first pair describes the line range in the original file and the second pair describes the corresponding range in the new file. The counts indicate how many lines from each file are included in this hunk, including both changed and context lines.</p>\n<p><strong>Context lines</strong> provide unchanged content around modifications to help readers understand where changes occurred. These lines begin with a space character and appear exactly as they exist in both files. The standard is to include three lines of context before and after each change, though this is configurable.</p>\n<p><strong>Deletion lines</strong> show content that was removed from the original file. These lines begin with a <code>-</code> character followed by the content that was deleted. Multiple consecutive deletion lines indicate a block of content that was removed.</p>\n<p><strong>Addition lines</strong> show content that was added in the new file. These lines begin with a <code>+</code> character followed by the new content. When deletion and addition lines appear together, they typically represent content that was modified rather than purely removed and added.</p>\n<p>Here&#39;s the detailed structure of unified diff output:</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Format</th>\n<th>Example</th>\n<th>Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>File Header (original)</td>\n<td><code>--- filename</code></td>\n<td><code>--- a/src/main.py</code></td>\n<td>Identifies source file</td>\n</tr>\n<tr>\n<td>File Header (new)</td>\n<td><code>+++ filename</code></td>\n<td><code>+++ b/src/main.py</code></td>\n<td>Identifies target file</td>\n</tr>\n<tr>\n<td>Hunk Header</td>\n<td><code>@@ -start,count +start,count @@</code></td>\n<td><code>@@ -15,7 +15,8 @@</code></td>\n<td>Defines change location and scope</td>\n</tr>\n<tr>\n<td>Context Line</td>\n<td><code> content</code></td>\n<td><code> def process_data():</code></td>\n<td>Shows unchanged content for reference</td>\n</tr>\n<tr>\n<td>Deletion Line</td>\n<td><code>-content</code></td>\n<td><code>- return None</code></td>\n<td>Shows content removed from original</td>\n</tr>\n<tr>\n<td>Addition Line</td>\n<td><code>+content</code></td>\n<td><code>+ return process_result()</code></td>\n<td>Shows content added in new version</td>\n</tr>\n<tr>\n<td>No newline marker</td>\n<td><code>\\ No newline at end of file</code></td>\n<td><code>\\ No newline at end of file</code></td>\n<td>Indicates file doesn&#39;t end with newline</td>\n</tr>\n</tbody></table>\n<p>The algorithm for generating unified diff output operates in several phases:</p>\n<ol>\n<li><p><strong>Edit script processing</strong>: Convert the Myers algorithm output (a sequence of insert/delete operations) into a list of change regions. Consecutive operations of the same type can be grouped together for efficiency.</p>\n</li>\n<li><p><strong>Context calculation</strong>: For each change region, determine the appropriate context lines to include. This requires reading the unchanged content before and after each change, typically 3 lines in each direction.</p>\n</li>\n<li><p><strong>Hunk consolidation</strong>: Merge nearby change regions into single hunks when their context areas overlap. This prevents repetitive context lines and produces more readable output.</p>\n</li>\n<li><p><strong>Line number calculation</strong>: Track line numbers in both the original and new files as we process changes. This information is needed for the hunk headers and must account for how previous changes affect subsequent line numbering.</p>\n</li>\n<li><p><strong>Output formatting</strong>: Generate the actual diff text with proper prefixes, ensuring that each line type is correctly marked and that the overall format follows the unified diff specification.</p>\n</li>\n</ol>\n<p>The implementation must handle several special cases that commonly occur in real-world file comparisons:</p>\n<p><strong>Files with no final newline</strong>: When a file doesn&#39;t end with a newline character, the unified diff format includes a special marker <code>\\ No newline at end of file</code> after the affected line. This distinction is important because adding or removing a final newline is a meaningful change in many contexts.</p>\n<p><strong>Empty files</strong>: Comparing to or from empty files requires special handling in the hunk headers. An empty file is represented with line numbers <code>0,0</code>, and the hunk header must reflect this appropriately.</p>\n<p><strong>Large change regions</strong>: When an entire file has been rewritten, generating a diff with every line marked as deleted and added may not be useful. Some implementations detect this case and either display a summary message or fall back to binary file handling.</p>\n<p><strong>Binary file detection</strong>: The unified diff format is designed for text files. When binary content is detected (through null bytes or other heuristics), the output should indicate that the files differ without attempting to show the actual differences.</p>\n<p><strong>Tab vs. space handling</strong>: Unified diff output should preserve the exact whitespace from the original files, including tabs and spaces. However, some display contexts may render these differently, so care must be taken to maintain fidelity.</p>\n<blockquote>\n<p><strong>Implementation Note</strong>: Generating clean unified diff output requires careful attention to line ending handling. Mixed line endings (LF vs. CRLF) within the same file can produce confusing output if not normalized consistently.</p>\n</blockquote>\n<h4 id=\"common-pitfalls\">Common Pitfalls</h4>\n<p>⚠️ <strong>Pitfall: Incorrect Line Number Tracking</strong>\nA frequent mistake is failing to properly track line numbers as changes are processed. The line numbers in hunk headers must reflect the position in the original and new files respectively, accounting for how previous insertions and deletions shift subsequent positions. This is especially tricky when multiple hunks are generated for the same file comparison.</p>\n<p><strong>Why it&#39;s wrong</strong>: Incorrect line numbers make the diff output unusable for patch applications and confuse users trying to locate changes in their editors.</p>\n<p><strong>How to fix</strong>: Maintain separate line counters for the original and new files, updating them as each edit operation is processed. Validate line numbers by ensuring they align with the actual content being compared.</p>\n<p>⚠️ <strong>Pitfall: Context Line Boundary Errors</strong>\nWhen extracting context lines around changes, implementations often fail to handle file boundaries correctly. Requesting 3 lines of context before a change that occurs at line 2 should gracefully handle the fact that only 1 context line is available.</p>\n<p><strong>Why it&#39;s wrong</strong>: Attempting to access lines before the beginning or after the end of a file will cause array bounds exceptions or produce incorrect context.</p>\n<p><strong>How to fix</strong>: Always clamp context line ranges to the actual file boundaries using <code>max(0, start_line - context)</code> and <code>min(file_length, end_line + context)</code> when calculating context regions.</p>\n<p>⚠️ <strong>Pitfall: Inefficient String Building</strong>\nGenerating unified diff output often involves concatenating many small strings (line prefixes, content, newlines). Using simple string concatenation in a loop can result in O(n²) performance due to string immutability in many languages.</p>\n<p><strong>Why it&#39;s wrong</strong>: Large files or files with many changes will experience severe performance degradation, making the diff operation unusably slow.</p>\n<p><strong>How to fix</strong>: Use a string builder or array-based approach that can efficiently accumulate output. Build each hunk separately and then combine them, rather than building the entire output character by character.</p>\n<p>⚠️ <strong>Pitfall: Inconsistent Newline Handling</strong>\nText files may use different newline conventions (LF on Unix, CRLF on Windows, or even mixed). If the diff algorithm doesn&#39;t handle these consistently, it may report spurious changes where only line endings differ.</p>\n<p><strong>Why it&#39;s wrong</strong>: Users will see confusing diffs where every line appears to have changed, even when only line endings are different.</p>\n<p><strong>How to fix</strong>: Implement a consistent newline normalization strategy, either by converting all content to a standard format before comparison or by making the line-splitting logic aware of different newline conventions.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The diff algorithm implementation requires careful coordination between the core Myers algorithm, output formatting, and integration with Git&#39;s object model. The following guidance provides both complete infrastructure and skeleton implementations to help you build a robust diff system.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Line Splitting</td>\n<td><code>str.splitlines()</code> with keepends=True</td>\n<td>Custom line iterator with encoding detection</td>\n</tr>\n<tr>\n<td>Output Building</td>\n<td>List accumulation with <code>&#39;&#39;.join()</code></td>\n<td><code>io.StringIO</code> for memory-efficient streaming</td>\n</tr>\n<tr>\n<td>File Comparison</td>\n<td>Full file reading with <code>Path.read_text()</code></td>\n<td>Memory-mapped files with <code>mmap</code> module</td>\n</tr>\n<tr>\n<td>Binary Detection</td>\n<td>Check for null bytes in first 1024 chars</td>\n<td>Use <code>chardet</code> library for encoding confidence</td>\n</tr>\n<tr>\n<td>Performance Profiling</td>\n<td>Simple timing with <code>time.perf_counter()</code></td>\n<td><code>cProfile</code> with line-by-line analysis</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>project-root/\n├── src/\n│   ├── diff/\n│   │   ├── __init__.py           ← Public diff API\n│   │   ├── myers.py              ← Myers algorithm implementation\n│   │   ├── unified.py            ← Unified diff formatting\n│   │   ├── types.py              ← Diff data structures\n│   │   └── utils.py              ← File reading utilities\n│   ├── objects/\n│   │   └── retrieval.py          ← Object content access\n│   └── repository.py             ← Main Repository class\n├── tests/\n│   ├── diff/\n│   │   ├── test_myers.py         ← Myers algorithm tests\n│   │   ├── test_unified.py       ← Output format tests\n│   │   └── fixtures/             ← Test file pairs\n│   └── integration/\n│       └── test_git_compatibility.py  ← Compare with real Git\n└── examples/\n    └── diff_demo.py              ← Usage examples</code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p><strong>File: <code>src/diff/types.py</code></strong> - Complete data structures for diff operations:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"Data structures for diff algorithm implementation.\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Tuple, Optional, Union</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> EditType</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Types of edit operations in a diff.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    INSERT</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"insert\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    DELETE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"delete\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    MATCH</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"match\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">frozen</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> Edit</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"A single edit operation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    type</span><span style=\"color:#E1E4E8\">: EditType</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    old_line: Optional[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">]  </span><span style=\"color:#6A737D\"># Line number in original file (None for inserts)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    new_line: Optional[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">]  </span><span style=\"color:#6A737D\"># Line number in new file (None for deletes)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    content: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#6A737D\">             # The actual line content</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">frozen</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DiffHunk</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"A contiguous block of changes with context.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    old_start: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#6A737D\">           # Starting line in original file</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    old_count: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#6A737D\">           # Number of lines from original file</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    new_start: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#6A737D\">           # Starting line in new file  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    new_count: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#6A737D\">           # Number of lines from new file</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    lines: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]         </span><span style=\"color:#6A737D\"># Formatted diff lines (with +/- prefixes)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">frozen</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> FileDiff</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Complete diff result for a single file comparison.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    old_path: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]   </span><span style=\"color:#6A737D\"># Original file path (None for new file)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    new_path: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]   </span><span style=\"color:#6A737D\"># New file path (None for deleted file)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    is_binary: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#6A737D\">          # True if files contain binary data</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    hunks: List[DiffHunk]    </span><span style=\"color:#6A737D\"># List of change hunks</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DiffStats</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Statistics about a diff operation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.files_changed </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.insertions </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.deletions </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.binary_files </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> add_file_diff</span><span style=\"color:#E1E4E8\">(self, file_diff: FileDiff) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Update statistics with results from a file diff.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.files_changed </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> file_diff.is_binary:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.binary_files </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> hunk </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> file_diff.hunks:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            for</span><span style=\"color:#E1E4E8\"> line </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> hunk.lines:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> line.startswith(</span><span style=\"color:#9ECBFF\">'+'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">and</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> line.startswith(</span><span style=\"color:#9ECBFF\">'+++'</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                    self</span><span style=\"color:#E1E4E8\">.insertions </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                elif</span><span style=\"color:#E1E4E8\"> line.startswith(</span><span style=\"color:#9ECBFF\">'-'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">and</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> line.startswith(</span><span style=\"color:#9ECBFF\">'---'</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                    self</span><span style=\"color:#E1E4E8\">.deletions </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __str__</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate summary string like Git's diff --stat output.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        parts </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.files_changed</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> file(s) changed\"</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.insertions:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            parts.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.insertions</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> insertion(s)\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.deletions:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            parts.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.deletions</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> deletion(s)\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> \", \"</span><span style=\"color:#E1E4E8\">.join(parts)</span></span></code></pre></div>\n\n<p><strong>File: <code>src/diff/utils.py</code></strong> - Complete utilities for file handling:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"Utilities for file reading and binary detection.\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> os</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Optional, Tuple</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> is_binary_content</span><span style=\"color:#E1E4E8\">(content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Detect if content appears to be binary data.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> content:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Check for null bytes (strong binary indicator)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> b</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\x00</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> content[:</span><span style=\"color:#79B8FF\">1024</span><span style=\"color:#E1E4E8\">]:  </span><span style=\"color:#6A737D\"># Check first 1KB</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Check for high ratio of non-printable characters</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    printable_chars </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> sum</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#F97583\"> for</span><span style=\"color:#E1E4E8\"> b </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> content[:</span><span style=\"color:#79B8FF\">1024</span><span style=\"color:#E1E4E8\">] </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                         if</span><span style=\"color:#79B8FF\"> 32</span><span style=\"color:#F97583\"> &#x3C;=</span><span style=\"color:#E1E4E8\"> b </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 126</span><span style=\"color:#F97583\"> or</span><span style=\"color:#E1E4E8\"> b </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">9</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">13</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(content[:</span><span style=\"color:#79B8FF\">1024</span><span style=\"color:#E1E4E8\">]) </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        printable_ratio </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> printable_chars </span><span style=\"color:#F97583\">/</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(content[:</span><span style=\"color:#79B8FF\">1024</span><span style=\"color:#E1E4E8\">])</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> printable_ratio </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 0.75</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> read_file_lines</span><span style=\"color:#E1E4E8\">(file_path: Path) -> Tuple[List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">], </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Read file and return lines with binary detection.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Tuple of (lines, is_binary) where lines are empty if binary.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Read as binary first for detection</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> open</span><span style=\"color:#E1E4E8\">(file_path, </span><span style=\"color:#9ECBFF\">'rb'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> f:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            content </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> f.read()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> is_binary_content(content):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> [], </span><span style=\"color:#79B8FF\">True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Convert to text and split into lines</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            text_content </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> content.decode(</span><span style=\"color:#9ECBFF\">'utf-8'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> UnicodeDecodeError</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                text_content </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> content.decode(</span><span style=\"color:#9ECBFF\">'latin1'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            except</span><span style=\"color:#79B8FF\"> UnicodeDecodeError</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#E1E4E8\"> [], </span><span style=\"color:#79B8FF\">True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Split lines but keep line endings for accurate diff</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        lines </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> text_content.splitlines(</span><span style=\"color:#FFAB70\">keepends</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> lines, </span><span style=\"color:#79B8FF\">False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    except</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">IOError</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">OSError</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> [], </span><span style=\"color:#79B8FF\">True</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> safe_file_size</span><span style=\"color:#E1E4E8\">(file_path: Path) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Get file size safely, returning 0 if file doesn't exist.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> file_path.stat().st_size</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    except</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">OSError</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">IOError</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> normalize_path</span><span style=\"color:#E1E4E8\">(path: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]) -> Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Normalize file path for display in diff headers.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> path </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Convert to forward slashes for consistency</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    normalized </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> str</span><span style=\"color:#E1E4E8\">(Path(path)).replace(os.sep, </span><span style=\"color:#9ECBFF\">'/'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Add a/ or b/ prefix if not already present (Git convention)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> normalized.startswith((</span><span style=\"color:#9ECBFF\">'a/'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'b/'</span><span style=\"color:#E1E4E8\">)):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"a/</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">normalized</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> normalized</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeleton-code\">Core Logic Skeleton Code</h4>\n<p><strong>File: <code>src/diff/myers.py</code></strong> - Myers algorithm implementation skeleton:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"Myers diff algorithm implementation.\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Dict, Tuple, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .types </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Edit, EditType</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> MyersDiff</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Implementation of Myers' O(ND) diff algorithm.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, old_lines: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">], new_lines: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.old_lines </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> old_lines</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.new_lines </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> new_lines</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.M </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(old_lines)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.N </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(new_lines)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> compute_diff</span><span style=\"color:#E1E4E8\">(self) -> List[Edit]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Compute the shortest edit script using Myers algorithm.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            List of Edit operations to transform old_lines into new_lines.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Handle edge cases (empty files)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.M </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return all insertions</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.N </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return all deletions</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Find the shortest edit script length</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        edit_distance </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._find_shortest_edit_distance()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Backtrack to reconstruct the actual edit sequence</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._backtrack_edit_script(edit_distance)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _find_shortest_edit_distance</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Find the length of the shortest edit script.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            The minimum number of insertions + deletions needed.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Myers algorithm uses a V array to track furthest reaching paths</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # V[d] = furthest x coordinate reached on diagonal d</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Diagonal d represents positions where x - y = d</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        max_d </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.M </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.N</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        v </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}  </span><span style=\"color:#6A737D\"># V array: diagonal -> furthest x position</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Initialize V[1] = 0 (starting position)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: For each possible edit distance from 0 to max_d:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> d </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(max_d </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: For each diagonal that could be reached with d edits:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            for</span><span style=\"color:#E1E4E8\"> k </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\">d, d </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Determine starting x position on diagonal k</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # Can reach diagonal k from k-1 (move right/delete) or k+1 (move down/insert)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> k </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#E1E4E8\">d </span><span style=\"color:#F97583\">or</span><span style=\"color:#E1E4E8\"> (k </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> d </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> v.get(k</span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> v.get(k</span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Move down from diagonal k+1 (insert from new)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    x </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> v.get(k</span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Move right from diagonal k-1 (delete from old)  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    x </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> v.get(k</span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Calculate y position from x and diagonal</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                y </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> x </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> k</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 9: Extend diagonally while elements match (greedy)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                while</span><span style=\"color:#E1E4E8\"> (x </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.M </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> y </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.N </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                       self</span><span style=\"color:#E1E4E8\">.old_lines[x] </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.new_lines[y]):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Advance both x and y</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 10: Store furthest position reached on this diagonal</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                v[k] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> x</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 11: Check if we've reached the target position</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> x </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.M </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> y </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.N:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    return</span><span style=\"color:#E1E4E8\"> d</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Should never reach here for valid inputs</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> max_d</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _backtrack_edit_script</span><span style=\"color:#E1E4E8\">(self, edit_distance: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> List[Edit]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Reconstruct the edit script by backtracking through the search.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            edit_distance: The optimal edit distance found</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            List of Edit operations in forward order.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 12: Re-run the forward search but save V arrays for each step</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        v_history </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._compute_v_history(edit_distance)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 13: Start from the end position and work backwards</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        x, y </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.M, </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.N</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        edits </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 14: For each edit distance from max down to 0:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> d </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(edit_distance, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            v </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> v_history[d]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            v_prev </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> v_history[d</span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 15: Find which diagonal we're on</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            k </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> x </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> y</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 16: Determine how we reached this position</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Check if we came from diagonal k-1 (right move) or k+1 (down move)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> k </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#E1E4E8\">d </span><span style=\"color:#F97583\">or</span><span style=\"color:#E1E4E8\"> (k </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> d </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> v_prev.get(k</span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> v_prev.get(k</span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: We moved down (insertion)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                prev_k </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> k </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: We moved right (deletion)  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                prev_k </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> k </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 17: Calculate previous position</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            prev_x </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> v_prev[prev_k]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            prev_y </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> prev_x </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> prev_k</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 18: Add diagonal moves (matches) first</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            while</span><span style=\"color:#E1E4E8\"> x </span><span style=\"color:#F97583\">></span><span style=\"color:#E1E4E8\"> prev_x </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> y </span><span style=\"color:#F97583\">></span><span style=\"color:#E1E4E8\"> prev_y:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Add MATCH edit for diagonal moves</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                x </span><span style=\"color:#F97583\">-=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                y </span><span style=\"color:#F97583\">-=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # edits.insert(0, Edit(EditType.MATCH, x, y, self.old_lines[x]))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 19: Add the actual edit operation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> x </span><span style=\"color:#F97583\">></span><span style=\"color:#E1E4E8\"> prev_x:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Deletion (moved right)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                x </span><span style=\"color:#F97583\">-=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # edits.insert(0, Edit(EditType.DELETE, x, None, self.old_lines[x]))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            elif</span><span style=\"color:#E1E4E8\"> y </span><span style=\"color:#F97583\">></span><span style=\"color:#E1E4E8\"> prev_y:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Insertion (moved down)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                y </span><span style=\"color:#F97583\">-=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # edits.insert(0, Edit(EditType.INSERT, None, y, self.new_lines[y]))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> edits</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _compute_v_history</span><span style=\"color:#E1E4E8\">(self, max_d: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, Dict[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Recompute the V arrays and store history for backtracking.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 20: This is similar to _find_shortest_edit_distance but saves all V arrays</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Return dict where v_history[d] = V array after processing edit distance d</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>File: <code>src/diff/unified.py</code></strong> - Unified diff formatting skeleton:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"Unified diff output formatting.\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .types </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Edit, EditType, FileDiff, DiffHunk</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> UnifiedDiffFormatter</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Formats diff results as unified diff output.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, context_lines: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 3</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.context_lines </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> context_lines</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> format_file_diff</span><span style=\"color:#E1E4E8\">(self, file_diff: FileDiff) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Format a complete file diff in unified format.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            file_diff: The diff result to format</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Unified diff string ready for display.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> file_diff.is_binary:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._format_binary_diff(file_diff)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        lines </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Add file headers (--- and +++ lines)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> file_diff.old_path:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Add \"--- a/path\" line</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Add \"--- /dev/null\" for new files</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> file_diff.new_path:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Add \"+++ b/path\" line  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Add \"+++ /dev/null\" for deleted files</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Add each hunk with its header</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> hunk </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> file_diff.hunks:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Add hunk header like \"@@ -15,7 +15,8 @@\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            hunk_header </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"@@ -</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">hunk.old_start</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">,</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">hunk.old_count</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> +</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">hunk.new_start</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">,</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">hunk.new_count</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> @@\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            lines.append(hunk_header)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Add all hunk lines (already formatted with +/- prefixes)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            lines.extend(hunk.lines)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> '</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">.join(lines) </span><span style=\"color:#F97583\">+</span><span style=\"color:#9ECBFF\"> '</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> lines </span><span style=\"color:#F97583\">else</span><span style=\"color:#9ECBFF\"> \"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> edits_to_hunks</span><span style=\"color:#E1E4E8\">(self, edits: List[Edit], old_lines: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                      new_lines: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]) -> List[DiffHunk]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Convert edit sequence to unified diff hunks with context.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            edits: Sequence of edit operations</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            old_lines: Original file lines</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            new_lines: New file lines</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            List of DiffHunk objects with context lines added.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> edits:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Group edits into change regions</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        change_regions </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._group_edits_into_regions(edits)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Add context around each region  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        hunks </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> region </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> change_regions:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            hunk </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._create_hunk_with_context(region, old_lines, new_lines)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            hunks.append(hunk)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Merge overlapping hunks</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._merge_adjacent_hunks(hunks, old_lines, new_lines)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _group_edits_into_regions</span><span style=\"color:#E1E4E8\">(self, edits: List[Edit]) -> List[List[Edit]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Group consecutive edits into change regions.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Separate MATCH edits from INSERT/DELETE edits</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Group consecutive non-MATCH edits together</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Return list of edit groups representing distinct change areas</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _create_hunk_with_context</span><span style=\"color:#E1E4E8\">(self, region_edits: List[Edit], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                old_lines: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">], new_lines: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]) -> DiffHunk:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Create a single hunk with context lines around the changes.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 9: Find the line range covered by this region</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        min_old_line </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> min</span><span style=\"color:#E1E4E8\">((e.old_line </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> e </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> region_edits </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> e.old_line </span><span style=\"color:#F97583\">is</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">), </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        max_old_line </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> max</span><span style=\"color:#E1E4E8\">((e.old_line </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> e </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> region_edits </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> e.old_line </span><span style=\"color:#F97583\">is</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">), </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 10: Calculate context boundaries</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        context_start_old </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> max</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, min_old_line </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.context_lines)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        context_end_old </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> min</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">len</span><span style=\"color:#E1E4E8\">(old_lines), max_old_line </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.context_lines </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 11: Build the hunk lines with proper prefixes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        hunk_lines </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 12: Add leading context</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(context_start_old, min_old_line):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Add context line with space prefix</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 13: Add the actual changes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> edit </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> region_edits:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> edit.type </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EditType.</span><span style=\"color:#79B8FF\">DELETE</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Add line with - prefix</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                pass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            elif</span><span style=\"color:#E1E4E8\"> edit.type </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EditType.</span><span style=\"color:#79B8FF\">INSERT</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Add line with + prefix</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                pass</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # MATCH edits within a change region become context</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 14: Add trailing context</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(max_old_line </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">, context_end_old):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Add context line with space prefix</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 15: Calculate hunk header numbers</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        old_start </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> context_start_old </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#6A737D\">  # 1-based line numbers</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        old_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> context_end_old </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> context_start_old</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate new_start and new_count similarly</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> DiffHunk(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            old_start</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">old_start,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            old_count</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">old_count, </span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            new_start</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,  </span><span style=\"color:#6A737D\"># </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate this</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            new_count</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,  </span><span style=\"color:#6A737D\"># </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate this</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            lines</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">hunk_lines</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _merge_adjacent_hunks</span><span style=\"color:#E1E4E8\">(self, hunks: List[DiffHunk], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                            old_lines: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">], new_lines: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]) -> List[DiffHunk]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Merge hunks whose context regions overlap.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 16: Check each pair of consecutive hunks</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 17: If context regions overlap, merge them into single hunk</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 18: Recalculate line counts after merging</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _format_binary_diff</span><span style=\"color:#E1E4E8\">(self, file_diff: FileDiff) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Format a binary file diff message.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        old_name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> file_diff.old_path </span><span style=\"color:#F97583\">or</span><span style=\"color:#9ECBFF\"> \"/dev/null\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        new_name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> file_diff.new_path </span><span style=\"color:#F97583\">or</span><span style=\"color:#9ECBFF\"> \"/dev/null\"</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"--- </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">old_name</span><span style=\"color:#79B8FF\">}\\n</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                f</span><span style=\"color:#9ECBFF\">\"+++ </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">new_name</span><span style=\"color:#79B8FF\">}\\n</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                f</span><span style=\"color:#9ECBFF\">\"Binary files </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">old_name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> and </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">new_name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> differ</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p>After implementing the diff algorithm, verify your implementation with these specific tests:</p>\n<p><strong>Basic Functionality Test:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Create test files</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#79B8FF\"> -e</span><span style=\"color:#9ECBFF\"> \"line1\\nline2\\nline3\"</span><span style=\"color:#F97583\"> ></span><span style=\"color:#9ECBFF\"> old.txt</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#79B8FF\"> -e</span><span style=\"color:#9ECBFF\"> \"line1\\nmodified\\nline3\\nnew line\"</span><span style=\"color:#F97583\"> ></span><span style=\"color:#9ECBFF\"> new.txt</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Your diff should output:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># --- old.txt</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># +++ new.txt  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># @@ -1,3 +1,4 @@</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">#  line1</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># -line2</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># +modified</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">#  line3</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># +new line</span></span></code></pre></div>\n\n<p><strong>Empty File Test:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">touch</span><span style=\"color:#9ECBFF\"> empty.txt</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#9ECBFF\"> \"content\"</span><span style=\"color:#F97583\"> ></span><span style=\"color:#9ECBFF\"> nonempty.txt</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Diff from empty should show all additions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Diff to empty should show all deletions</span></span></code></pre></div>\n\n<p><strong>Binary File Test:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Create a binary file (contains null bytes)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">printf</span><span style=\"color:#9ECBFF\"> \"binary\\x00data\"</span><span style=\"color:#F97583\"> ></span><span style=\"color:#9ECBFF\"> binary.dat</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#9ECBFF\"> \"text content\"</span><span style=\"color:#F97583\"> ></span><span style=\"color:#9ECBFF\"> text.txt</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Should output: \"Binary files binary.dat and text.txt differ\"</span></span></code></pre></div>\n\n<p><strong>Performance Test:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Generate large text files (1000+ lines)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Diff should complete within reasonable time (&#x3C; 1 second for 1000 lines)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Memory usage should remain reasonable (&#x3C; 100MB for typical files)</span></span></code></pre></div>\n\n<p><strong>Git Compatibility Test:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Compare your diff output with Git's output for same files</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">git</span><span style=\"color:#9ECBFF\"> diff</span><span style=\"color:#79B8FF\"> --no-index</span><span style=\"color:#9ECBFF\"> old.txt</span><span style=\"color:#9ECBFF\"> new.txt</span><span style=\"color:#F97583\"> ></span><span style=\"color:#9ECBFF\"> git_output.diff</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">your_git</span><span style=\"color:#9ECBFF\"> diff</span><span style=\"color:#9ECBFF\"> old.txt</span><span style=\"color:#9ECBFF\"> new.txt</span><span style=\"color:#F97583\"> ></span><span style=\"color:#9ECBFF\"> your_output.diff</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Outputs should be functionally equivalent (may differ in header details)</span></span></code></pre></div>\n\n<h4 id=\"language-specific-hints\">Language-Specific Hints</h4>\n<p><strong>Python Performance Tips:</strong></p>\n<ul>\n<li>Use <code>str.splitlines(keepends=True)</code> to preserve line ending information</li>\n<li>Build diff output using lists and <code>&#39;&#39;.join()</code> rather than string concatenation</li>\n<li>Consider <code>collections.defaultdict(int)</code> for the V array in Myers algorithm</li>\n<li>Use <code>enumerate()</code> when you need both index and value during iteration</li>\n</ul>\n<p><strong>Memory Management:</strong></p>\n<ul>\n<li>For very large files, consider implementing a streaming version that processes chunks</li>\n<li>The Myers algorithm V array can grow large - consider the linear space refinement for huge diffs</li>\n<li>Use generators where possible to avoid loading entire diff output into memory</li>\n</ul>\n<p><strong>Error Handling:</strong></p>\n<ul>\n<li>Wrap file I/O operations in try/except blocks for graceful error handling</li>\n<li>Detect and handle different text encodings (UTF-8, Latin1, etc.)</li>\n<li>Provide meaningful error messages when files cannot be read or compared</li>\n</ul>\n<p><strong>Testing Strategy:</strong></p>\n<ul>\n<li>Create a comprehensive test suite with edge cases (empty files, binary files, identical files)</li>\n<li>Include performance tests with large files to catch algorithmic issues</li>\n<li>Test against Git&#39;s output for compatibility verification</li>\n<li>Use property-based testing to generate random file pairs for robustness testing</li>\n</ul>\n<h2 id=\"three-way-merge-implementation\">Three-Way Merge Implementation</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section is the culmination of Milestone 8 (Three-way Merge), building upon all previous milestones. The merge algorithm requires the object storage (Milestone 2-4), references (Milestone 5), index management (Milestone 6), and diff algorithms (Milestone 7) to function correctly.</p>\n</blockquote>\n<h3 id=\"mental-model-collaborative-document-editing\">Mental Model: Collaborative Document Editing</h3>\n<p>Think of three-way merging like collaborative document editing in the pre-digital era. Imagine you and a colleague both receive copies of the same research paper draft on Monday morning. You each spend the week making independent edits - you focus on improving the introduction and methodology, while your colleague refines the conclusion and adds new references. On Friday, you need to combine both sets of changes into a single, improved document.</p>\n<p>The naive approach would be to simply compare your final version with your colleague&#39;s final version. However, this creates confusion - if the same paragraph appears differently in both versions, you have no way to know whether both of you changed it (creating a conflict) or only one person modified it while the other left it unchanged. The solution is to keep the original Monday morning version as a reference point.</p>\n<p>With the original document as your <strong>merge base</strong>, you can now perform a three-way comparison. For each paragraph, you examine three versions: the original (base), your version (branch A), and your colleague&#39;s version (branch B). If only you changed a paragraph, your changes win. If only your colleague changed it, their changes win. If neither of you touched it, it stays the same. But if both of you modified the same paragraph, you have a genuine conflict that requires manual resolution - perhaps you need to sit down together and decide how to combine both improvements.</p>\n<p>This is exactly how Git&#39;s three-way merge works. The <strong>merge base</strong> is the common ancestor commit - the last point where both branches shared the same history. By comparing each file&#39;s content across all three versions (base, branch A, branch B), Git can automatically resolve most changes and only flag genuine conflicts where both branches modified the same lines.</p>\n<p>The power of this approach is that it preserves the intent of both sets of changes. If you deleted a paragraph that your colleague left unchanged, the merge knows you intentionally removed it and won&#39;t restore it. If you both added different content at the same location, the merge knows this requires human judgment to resolve properly.</p>\n<h3 id=\"finding-the-merge-base\">Finding the Merge Base</h3>\n<p>The merge base calculation is a graph traversal problem that finds the <strong>lowest common ancestor</strong> (LCA) between two commits in Git&#39;s directed acyclic graph. This ancestor represents the most recent point in history where both branches shared the same state, making it the ideal reference point for three-way comparison.</p>\n<p><img src=\"/api/project/build-git/architecture-doc/asset?path=diagrams%2Fmerge-base-algorithm.svg\" alt=\"Merge Base Algorithm\"></p>\n<p>The algorithm uses a breadth-first search approach that explores the commit history backwards from both branch tips simultaneously. The key insight is that Git&#39;s commit graph forms a DAG where each commit points to its parent(s), creating paths back through history. The merge base is the commit that appears in both traversal paths with the shortest distance from either starting point.</p>\n<p><img src=\"/api/project/build-git/architecture-doc/asset?path=diagrams%2Fthree-way-merge.svg\" alt=\"Three-Way Merge Process\"></p>\n<p><strong>Merge Base Discovery Algorithm:</strong></p>\n<ol>\n<li><p><strong>Initialize Search State</strong>: Create two sets to track visited commits - one for each branch being merged. Initialize two queues with the starting commit hashes from both branches. This dual-queue approach ensures we explore both histories simultaneously and can detect when they intersect.</p>\n</li>\n<li><p><strong>Parallel Breadth-First Traversal</strong>: While both queues contain commits, dequeue one commit from each queue in alternating fashion. This alternating approach ensures we explore both histories at roughly the same depth, increasing the likelihood of finding the nearest common ancestor quickly rather than exploring one branch much deeper than the other.</p>\n</li>\n<li><p><strong>Intersection Detection</strong>: For each dequeued commit, check if it already exists in the opposite branch&#39;s visited set. If a commit from branch A&#39;s queue appears in branch B&#39;s visited set, we&#39;ve found a common ancestor. Record this commit as a potential merge base candidate.</p>\n</li>\n<li><p><strong>Parent Expansion</strong>: Load the commit object for the current commit and extract its parent commit hashes. Add each parent to the current branch&#39;s queue for future exploration. Mark the current commit as visited in the current branch&#39;s set to avoid revisiting it later.</p>\n</li>\n<li><p><strong>Multiple Ancestor Resolution</strong>: Continue the search even after finding the first common ancestor, as there might be multiple common ancestors at the same depth level. In Git&#39;s history, merge commits can create situations where two branches have multiple equally-valid common ancestors.</p>\n</li>\n<li><p><strong>Best Candidate Selection</strong>: Among all discovered common ancestors, select the one with the shortest path distance from either branch tip. This represents the most recent common state and provides the most meaningful base for comparison.</p>\n</li>\n</ol>\n<p>The algorithm handles several edge cases that commonly occur in Git repositories:</p>\n<table>\n<thead>\n<tr>\n<th>Edge Case</th>\n<th>Detection Method</th>\n<th>Resolution Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>No Common Ancestor</td>\n<td>Both queues become empty without intersection</td>\n<td>Return null - branches have completely separate histories</td>\n</tr>\n<tr>\n<td>Self-Merge Attempt</td>\n<td>Source and target commits are identical</td>\n<td>Return the commit itself as the merge base</td>\n</tr>\n<tr>\n<td>Fast-Forward Scenario</td>\n<td>Target commit appears in source&#39;s ancestry</td>\n<td>Return target commit - no merge needed, just update reference</td>\n</tr>\n<tr>\n<td>Multiple Merge Bases</td>\n<td>Several ancestors found at same depth</td>\n<td>Select the one with shortest path to either tip</td>\n</tr>\n<tr>\n<td>Octopus Merge History</td>\n<td>Commits with more than two parents</td>\n<td>Treat each parent equally in the traversal</td>\n</tr>\n</tbody></table>\n<p><strong>Performance Considerations:</strong></p>\n<p>The merge base calculation can become expensive in repositories with deep history or complex branching patterns. The algorithm&#39;s time complexity is O(N) where N is the number of commits that must be examined before finding the common ancestor. In the worst case, this could require traversing most of the repository&#39;s history.</p>\n<p>To optimize performance, the implementation can employ several strategies:</p>\n<ul>\n<li><strong>Early Termination</strong>: Stop the search immediately upon finding the first common ancestor if the repository structure guarantees a unique merge base</li>\n<li><strong>Commit Metadata Caching</strong>: Cache commit parent relationships to avoid repeated object loading during traversal</li>\n<li><strong>Generation Numbers</strong>: Use Git&#39;s commit-graph generation numbers (if available) to guide the search toward likely intersection points</li>\n<li><strong>Path Limiting</strong>: In repositories with known branching patterns, limit the search depth to reasonable bounds</li>\n</ul>\n<blockquote>\n<p><strong>Critical Insight</strong>: The merge base calculation is not just an optimization - it&#39;s fundamental to Git&#39;s ability to understand the intent behind changes. Without the correct merge base, Git cannot distinguish between deliberate deletions and independent additions, leading to incorrect automatic merges or false conflict detection.</p>\n</blockquote>\n<h3 id=\"three-way-merge-algorithm\">Three-Way Merge Algorithm</h3>\n<p>The three-way merge algorithm performs a line-by-line comparison between three versions of each file: the merge base (common ancestor), the current branch (ours), and the branch being merged (theirs). This comparison determines which changes can be automatically applied and which require manual conflict resolution.</p>\n<p>The algorithm operates on the principle of <strong>change attribution</strong> - understanding which branch introduced each modification relative to the common base. A change is considered safe to apply automatically if only one branch modified a particular region of the file. Conflicts arise when both branches made different changes to the same lines.</p>\n<p><strong>File-Level Merge Process:</strong></p>\n<p>The merge algorithm begins by identifying all files that exist in any of the three versions (base, ours, theirs). For each file, it determines the merge scenario based on which versions contain the file:</p>\n<table>\n<thead>\n<tr>\n<th>Base Exists</th>\n<th>Ours Exists</th>\n<th>Theirs Exists</th>\n<th>Scenario</th>\n<th>Action</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Yes</td>\n<td>Yes</td>\n<td>Yes</td>\n<td>Modified in branches</td>\n<td>Perform three-way content merge</td>\n</tr>\n<tr>\n<td>Yes</td>\n<td>Yes</td>\n<td>No</td>\n<td>Deleted in theirs</td>\n<td>Check if ours modified; conflict if yes</td>\n</tr>\n<tr>\n<td>Yes</td>\n<td>No</td>\n<td>Yes</td>\n<td>Deleted in ours</td>\n<td>Check if theirs modified; conflict if yes</td>\n</tr>\n<tr>\n<td>Yes</td>\n<td>No</td>\n<td>No</td>\n<td>Deleted in both</td>\n<td>Remove file (agreement)</td>\n</tr>\n<tr>\n<td>No</td>\n<td>Yes</td>\n<td>Yes</td>\n<td>Added in both</td>\n<td>Compare content; conflict if different</td>\n</tr>\n<tr>\n<td>No</td>\n<td>Yes</td>\n<td>No</td>\n<td>Added in ours</td>\n<td>Keep ours version</td>\n</tr>\n<tr>\n<td>No</td>\n<td>No</td>\n<td>Yes</td>\n<td>Added in theirs</td>\n<td>Keep theirs version</td>\n</tr>\n<tr>\n<td>No</td>\n<td>No</td>\n<td>No</td>\n<td>Impossible</td>\n<td>Error condition</td>\n</tr>\n</tbody></table>\n<p><strong>Line-Level Merge Logic:</strong></p>\n<p>For files requiring content merging, the algorithm processes each line using three-way comparison logic. The merge result depends on which branches modified each line relative to the base:</p>\n<ol>\n<li><p><strong>Unchanged in All Versions</strong>: If a line appears identically in base, ours, and theirs, include it unchanged in the merge result. This represents content that neither branch chose to modify.</p>\n</li>\n<li><p><strong>Modified in Ours Only</strong>: If a line differs between base and ours but matches between base and theirs, apply the change from ours. This represents an intentional modification made only on the current branch.</p>\n</li>\n<li><p><strong>Modified in Theirs Only</strong>: If a line differs between base and theirs but matches between base and ours, apply the change from theirs. This represents an intentional modification made only on the incoming branch.</p>\n</li>\n<li><p><strong>Modified Identically</strong>: If both branches made the same change to a line (ours and theirs match each other but differ from base), include the shared change. This represents convergent evolution or cherry-picked changes.</p>\n</li>\n<li><p><strong>Modified Differently</strong>: If base, ours, and theirs all differ from each other, mark this as a conflict requiring manual resolution. The automated merge cannot determine which change takes precedence.</p>\n</li>\n</ol>\n<p><strong>Region-Based Conflict Detection:</strong></p>\n<p>The merge algorithm groups consecutive conflicting lines into conflict regions to provide meaningful context for resolution. Rather than marking individual lines as conflicts, it identifies blocks of related changes that should be resolved together:</p>\n<ol>\n<li><p><strong>Conflict Region Identification</strong>: Scan the line-by-line comparison results to find sequences of consecutive conflicts or near-conflicts (within a configurable context window).</p>\n</li>\n<li><p><strong>Context Expansion</strong>: Extend each conflict region to include surrounding unchanged lines for context. This helps developers understand the broader scope of conflicting changes.</p>\n</li>\n<li><p><strong>Region Consolidation</strong>: Merge adjacent conflict regions if they&#39;re separated by only a few unchanged lines. This prevents fragmented conflicts that would be difficult to resolve coherently.</p>\n</li>\n<li><p><strong>Boundary Refinement</strong>: Adjust conflict region boundaries to align with logical boundaries (function definitions, paragraph breaks) when possible, making the conflicts more intuitive to resolve.</p>\n</li>\n</ol>\n<p><strong>Merge Result Generation:</strong></p>\n<p>The algorithm produces a merged file containing three types of content:</p>\n<ul>\n<li><strong>Clean Lines</strong>: Lines where the three-way comparison produced an unambiguous result, included directly in the output</li>\n<li><strong>Conflict Markers</strong>: Special marker lines that delimit regions requiring manual resolution</li>\n<li><strong>Conflict Content</strong>: The competing versions from both branches, clearly labeled for comparison</li>\n</ul>\n<p>The merge algorithm maintains metadata about the merge process for reporting and debugging:</p>\n<table>\n<thead>\n<tr>\n<th>Metadata Field</th>\n<th>Purpose</th>\n<th>Example Value</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Files Modified</td>\n<td>Count of files requiring changes</td>\n<td>12</td>\n</tr>\n<tr>\n<td>Auto-Merged Files</td>\n<td>Files merged without conflicts</td>\n<td>8</td>\n</tr>\n<tr>\n<td>Conflicted Files</td>\n<td>Files requiring manual resolution</td>\n<td>4</td>\n</tr>\n<tr>\n<td>Lines Added</td>\n<td>Total lines added from both branches</td>\n<td>156</td>\n</tr>\n<tr>\n<td>Lines Removed</td>\n<td>Total lines removed from both branches</td>\n<td>89</td>\n</tr>\n<tr>\n<td>Conflict Regions</td>\n<td>Number of distinct conflict areas</td>\n<td>7</td>\n</tr>\n</tbody></table>\n<p><strong>Error Handling and Recovery:</strong></p>\n<p>The merge algorithm must handle various error conditions gracefully:</p>\n<ul>\n<li><strong>Missing Objects</strong>: If any required blob, tree, or commit object is missing from the object store, abort the merge with a clear error message indicating which object is unavailable.</li>\n<li><strong>Binary File Conflicts</strong>: When both branches modify a binary file differently, mark the entire file as conflicted rather than attempting line-based merging.</li>\n<li><strong>Permission Conflicts</strong>: If file modes differ between branches (executable vs non-executable), include mode information in conflict markers.</li>\n<li><strong>Symlink Conflicts</strong>: Handle symbolic links specially, as their target paths may conflict even when the content appears similar.</li>\n</ul>\n<blockquote>\n<p><strong>Design Principle</strong>: The three-way merge algorithm prioritizes correctness over convenience. When in doubt, it prefers to flag potential conflicts for manual review rather than making incorrect automatic decisions that could lose work or introduce bugs.</p>\n</blockquote>\n<h3 id=\"conflict-detection-and-marking\">Conflict Detection and Marking</h3>\n<p>Conflict detection is the process of identifying regions where both branches made incompatible changes to the same content, requiring human judgment to resolve. The conflict marking system provides a structured format that allows developers to understand the competing changes and make informed decisions about the final content.</p>\n<p>Git uses a <strong>conflict marker format</strong> that clearly delineates the boundaries of each conflict and identifies which branch contributed each version of the conflicted content. This format has become an industry standard, recognized by merge tools, IDEs, and diff viewers.</p>\n<p><strong>Conflict Marker Structure:</strong></p>\n<p>When a conflict is detected, the merge algorithm inserts special marker lines into the file content to create a <strong>conflict block</strong>. Each conflict block follows a consistent structure:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD (or branch name)\n[Content from the current branch]\n=======\n[Content from the branch being merged]\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; branch-name (or commit hash)</code></pre></div>\n\n<p>The conflict markers serve specific purposes:</p>\n<ul>\n<li><strong>Opening Marker</strong> (<code>&lt;&lt;&lt;&lt;&lt;&lt;&lt;</code>): Indicates the start of a conflict region and identifies the current branch (usually &quot;HEAD&quot; or the branch name)</li>\n<li><strong>Separator</strong> (<code>=======</code>): Divides the two competing versions of the conflicted content</li>\n<li><strong>Closing Marker</strong> (<code>&gt;&gt;&gt;&gt;&gt;&gt;&gt;</code>): Indicates the end of the conflict region and identifies the incoming branch or commit</li>\n<li><strong>Content Sections</strong>: The actual competing content from each branch, preserved exactly as it appears in each version</li>\n</ul>\n<p><strong>Advanced Conflict Scenarios:</strong></p>\n<p>Beyond simple line-level conflicts, the merge algorithm must handle several complex scenarios:</p>\n<table>\n<thead>\n<tr>\n<th>Conflict Type</th>\n<th>Description</th>\n<th>Example Scenario</th>\n<th>Resolution Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Add/Add Conflict</td>\n<td>Both branches added different content at same location</td>\n<td>New function added with different implementations</td>\n<td>Present both versions with clear branch labels</td>\n</tr>\n<tr>\n<td>Delete/Modify Conflict</td>\n<td>One branch deleted content, other modified it</td>\n<td>Function removed vs function refactored</td>\n<td>Show deletion intent vs modification intent</td>\n</tr>\n<tr>\n<td>Mode Conflict</td>\n<td>File permissions differ between branches</td>\n<td>File made executable on one branch only</td>\n<td>Include mode information in conflict markers</td>\n</tr>\n<tr>\n<td>Rename Conflict</td>\n<td>Same file renamed differently on each branch</td>\n<td>README.txt → README.md vs README.txt → readme.txt</td>\n<td>Create conflict for filename choice</td>\n</tr>\n<tr>\n<td>Binary Conflict</td>\n<td>Binary files modified differently</td>\n<td>Image files updated independently</td>\n<td>Mark entire file as binary conflict</td>\n</tr>\n</tbody></table>\n<p><strong>Context-Aware Conflict Boundaries:</strong></p>\n<p>The merge algorithm attempts to create meaningful conflict boundaries that align with logical content structure. Rather than starting and ending conflicts at arbitrary line boundaries, it analyzes the content to find natural breakpoints:</p>\n<ol>\n<li><p><strong>Function Boundaries</strong>: For source code, attempt to align conflict regions with function or method boundaries, including the complete function signature and closing brace.</p>\n</li>\n<li><p><strong>Paragraph Boundaries</strong>: For text content, extend conflicts to complete paragraphs or sentences when possible, avoiding mid-sentence breaks that would be confusing to resolve.</p>\n</li>\n<li><p><strong>Indentation Consistency</strong>: Maintain consistent indentation levels within conflict regions, ensuring that the conflicted code remains syntactically valid for each branch&#39;s version.</p>\n</li>\n<li><p><strong>Comment Preservation</strong>: Include related comments and documentation within conflict regions so that developers have full context for understanding the intent behind each change.</p>\n</li>\n</ol>\n<p><strong>Conflict Metadata and Reporting:</strong></p>\n<p>The merge system maintains detailed metadata about each conflict to support resolution tools and provide useful feedback to developers:</p>\n<table>\n<thead>\n<tr>\n<th>Conflict Property</th>\n<th>Description</th>\n<th>Usage</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>File Path</td>\n<td>Relative path of the conflicted file</td>\n<td>Reporting and tool integration</td>\n</tr>\n<tr>\n<td>Line Range</td>\n<td>Start and end line numbers of the conflict</td>\n<td>IDE navigation and highlighting</td>\n</tr>\n<tr>\n<td>Conflict Type</td>\n<td>Category of conflict (content, mode, rename)</td>\n<td>Specialized resolution workflows</td>\n</tr>\n<tr>\n<td>Base Content</td>\n<td>Content from the merge base version</td>\n<td>Three-way merge tools</td>\n</tr>\n<tr>\n<td>Branch Labels</td>\n<td>Names of the conflicting branches</td>\n<td>User interface display</td>\n</tr>\n<tr>\n<td>Complexity Score</td>\n<td>Estimated difficulty of resolution</td>\n<td>Prioritizing resolution effort</td>\n</tr>\n</tbody></table>\n<p><strong>Conflict Resolution Workflow:</strong></p>\n<p>The conflict marking system supports both manual and tool-assisted resolution workflows:</p>\n<ol>\n<li><p><strong>Manual Resolution</strong>: Developers can edit the conflicted file directly, removing the conflict markers and combining the content as appropriate. The merge system validates that all markers are removed before allowing the merge to complete.</p>\n</li>\n<li><p><strong>Merge Tool Integration</strong>: External merge tools can parse the conflict markers to present a three-way view (base, ours, theirs) and generate the resolved content automatically when the user makes selections.</p>\n</li>\n<li><p><strong>Partial Resolution</strong>: Large conflicts can be resolved incrementally by addressing individual conflict blocks while leaving others for later resolution.</p>\n</li>\n<li><p><strong>Resolution Validation</strong>: The system checks that resolved files contain no remaining conflict markers and that the content compiles or validates according to project standards.</p>\n</li>\n</ol>\n<p><strong>Binary File Conflict Handling:</strong></p>\n<p>Binary files require special conflict handling since line-based merging is not applicable:</p>\n<ol>\n<li><p><strong>Binary Detection</strong>: Use heuristics to identify binary content (null bytes, high ratio of non-printable characters, or file extension patterns).</p>\n</li>\n<li><p><strong>Whole-File Conflicts</strong>: Mark the entire file as conflicted rather than attempting to merge portions of binary content.</p>\n</li>\n<li><p><strong>Version Selection</strong>: Provide mechanisms for users to select which branch&#39;s version of the binary file should be used in the final merge.</p>\n</li>\n<li><p><strong>External Tool Integration</strong>: Support launching specialized merge tools for specific binary file types (image editors, document processors).</p>\n</li>\n</ol>\n<p><strong>Performance Optimization for Large Conflicts:</strong></p>\n<p>In files with extensive conflicts, the merge algorithm employs optimization strategies to maintain reasonable performance:</p>\n<ul>\n<li><strong>Streaming Processing</strong>: Process large files in chunks rather than loading entire content into memory</li>\n<li><strong>Conflict Batching</strong>: Group small adjacent conflicts to reduce the total number of conflict regions</li>\n<li><strong>Early Termination</strong>: Stop processing files that exceed conflict thresholds and mark them for manual resolution</li>\n<li><strong>Memory Management</strong>: Use efficient data structures to minimize memory usage during conflict detection</li>\n</ul>\n<blockquote>\n<p><strong>Critical Success Factor</strong>: Effective conflict marking must balance completeness with usability. Too little context makes conflicts difficult to resolve, while too much context overwhelms developers with irrelevant information. The optimal approach provides just enough surrounding content to understand the intent of each change while keeping conflict regions focused on the actual disagreement.</p>\n</blockquote>\n<p><strong>Common Pitfalls in Conflict Detection:</strong></p>\n<p>⚠️ <strong>Pitfall: Inconsistent Line Ending Handling</strong>\nDifferent operating systems use different line ending conventions (LF vs CRLF). If the merge algorithm doesn&#39;t normalize line endings before comparison, it may generate false conflicts where the only difference is the line terminator. Always normalize line endings to a consistent format (typically LF) before performing three-way comparison.</p>\n<p>⚠️ <strong>Pitfall: Whitespace-Only Conflicts</strong>\nChanges that only affect whitespace (spaces vs tabs, trailing spaces) can create conflicts that are difficult to visualize and resolve. Implement configurable whitespace handling that can either ignore whitespace differences or normalize them according to project standards.</p>\n<p>⚠️ <strong>Pitfall: Incomplete Conflict Markers</strong>\nIf the merge process is interrupted (by system crash, user cancellation, or error), partially written conflict markers can corrupt the file. Always write conflict markers atomically - either the complete conflict block exists or none of it does. Use temporary files and atomic moves to ensure consistency.</p>\n<p>⚠️ <strong>Pitfall: Nested Conflict Markers</strong>\nIf one of the branches being merged already contains conflict markers from a previous merge, the new merge can create nested or malformed conflict structures. Detect existing conflict markers before merging and either resolve them first or use alternative marker styles to avoid confusion.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The three-way merge implementation requires sophisticated algorithms for graph traversal, content comparison, and conflict resolution. This section provides concrete implementation patterns and complete working code for the supporting infrastructure.</p>\n<p><strong>A. Technology Recommendations:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Graph Traversal</td>\n<td>Collections.deque with manual BFS</td>\n<td>NetworkX for complex graph algorithms</td>\n</tr>\n<tr>\n<td>Line Processing</td>\n<td>Built-in file.readlines()</td>\n<td>Memory-mapped files for large content</td>\n</tr>\n<tr>\n<td>Diff Algorithm</td>\n<td>Simple longest common subsequence</td>\n<td>Myers algorithm from previous section</td>\n</tr>\n<tr>\n<td>Conflict Output</td>\n<td>String concatenation with markers</td>\n<td>Template-based conflict formatting</td>\n</tr>\n<tr>\n<td>Binary Detection</td>\n<td>Check for null bytes in first 1024 bytes</td>\n<td>Use python-magic library for MIME type detection</td>\n</tr>\n</tbody></table>\n<p><strong>B. File Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>src/git/\n  merge/\n    __init__.py                 ← Public merge API\n    merge_base.py              ← Merge base calculation algorithms\n    three_way_merge.py         ← Core three-way merge logic\n    conflict_detection.py     ← Conflict marking and resolution\n    merge_result.py           ← Data structures for merge results\n    test/\n      test_merge_base.py       ← Merge base algorithm tests\n      test_three_way_merge.py  ← Three-way merge tests\n      test_conflict_resolution.py ← Conflict handling tests\n  objects/\n    object_store.py           ← Required for commit traversal\n  refs/\n    reference_manager.py      ← Required for branch resolution</code></pre></div>\n\n<p><strong>C. Infrastructure Code - Merge Base Calculator:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> collections </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> deque</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional, Set, Dict, List, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> MergeBaseCalculator</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Finds the lowest common ancestor between two commits using BFS traversal.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, object_store):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.object_store </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> object_store</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> find_merge_base</span><span style=\"color:#E1E4E8\">(self, commit_a: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, commit_b: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Find the merge base (lowest common ancestor) between two commits.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            commit_a: SHA-1 hash of first commit</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            commit_b: SHA-1 hash of second commit</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            SHA-1 hash of merge base commit, or None if no common ancestor</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Handle trivial cases</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> commit_a </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> commit_b:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> commit_a</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Initialize dual BFS queues and visited sets</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        queue_a </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> deque([commit_a])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        queue_b </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> deque([commit_b])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        visited_a </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {commit_a}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        visited_b </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {commit_b}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Track distances for selecting best candidate</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        distances </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {commit_a: </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, commit_b: </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        candidates </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Alternating BFS traversal</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        while</span><span style=\"color:#E1E4E8\"> queue_a </span><span style=\"color:#F97583\">or</span><span style=\"color:#E1E4E8\"> queue_b:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Process one commit from each queue per iteration</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> queue_a:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                current </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> queue_a.popleft()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> current </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> visited_b:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    candidates.append((current, distances[current]))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                    self</span><span style=\"color:#E1E4E8\">._expand_parents(current, queue_a, visited_a, distances)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> queue_b:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                current </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> queue_b.popleft()  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> current </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> visited_a:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    candidates.append((current, distances[current]))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                    self</span><span style=\"color:#E1E4E8\">._expand_parents(current, queue_b, visited_b, distances)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Early termination if we found candidates</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> candidates:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                break</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Return the candidate with shortest distance</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> candidates:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> min</span><span style=\"color:#E1E4E8\">(candidates, </span><span style=\"color:#FFAB70\">key</span><span style=\"color:#F97583\">=lambda</span><span style=\"color:#E1E4E8\"> x: x[</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">])[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _expand_parents</span><span style=\"color:#E1E4E8\">(self, commit_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, queue: deque, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                       visited: Set[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">], distances: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">]):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Add commit's parents to the search queue.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            commit_obj </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.object_store.retrieve_object(commit_hash)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> commit_obj[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">!=</span><span style=\"color:#9ECBFF\"> 'commit'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Parse commit object to extract parent hashes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            content </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> commit_obj[</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">].decode(</span><span style=\"color:#9ECBFF\">'utf-8'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            current_distance </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> distances[commit_hash]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            for</span><span style=\"color:#E1E4E8\"> line </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> content.split(</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> line.startswith(</span><span style=\"color:#9ECBFF\">'parent '</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    parent_hash </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> line[</span><span style=\"color:#79B8FF\">7</span><span style=\"color:#E1E4E8\">:].strip()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    if</span><span style=\"color:#E1E4E8\"> parent_hash </span><span style=\"color:#F97583\">not</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> visited:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        visited.add(parent_hash)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        queue.append(parent_hash)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        distances[parent_hash] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> current_distance </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                elif</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> line.startswith(</span><span style=\"color:#9ECBFF\">'parent'</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                    # Stop at first non-parent line</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    break</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Skip commits we can't read</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span></code></pre></div>\n\n<p><strong>D. Core Logic Skeleton - Three-Way Merge:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Optional, Dict, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> MergeStatus</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    CLEAN</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"clean\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    CONFLICTED</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"conflicted\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ConflictType</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    CONTENT</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"content\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    ADD_ADD</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"add_add\"</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    DELETE_MODIFY</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"delete_modify\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    MODE_CHANGE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"mode_change\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ConflictRegion</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    start_line: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    end_line: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    conflict_type: ConflictType</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ours_content: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    theirs_content: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    base_content: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> MergeResult</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    status: MergeStatus</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    merged_content: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    conflicts: List[ConflictRegion]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    files_changed: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    lines_added: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    lines_deleted: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ThreeWayMerge</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Performs three-way merging with automatic conflict detection.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, object_store, diff_algorithm):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.object_store </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> object_store</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.diff_algorithm </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> diff_algorithm</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> merge_commits</span><span style=\"color:#E1E4E8\">(self, base_commit: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, our_commit: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                     their_commit: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, MergeResult]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Merge two commits using three-way algorithm.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Dictionary mapping file paths to their merge results</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Extract tree objects from all three commits</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Build file lists from each tree (recursively for subdirectories)  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Identify all unique file paths across the three trees</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: For each file path, determine the merge scenario (see file-level table above)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Call merge_file_content for files requiring content merging</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Handle add/add conflicts by comparing content hashes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Handle delete/modify conflicts by checking if deleted file was modified</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Aggregate results and return file path -> MergeResult mapping</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> merge_file_content</span><span style=\"color:#E1E4E8\">(self, base_content: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, our_content: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                          their_content: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, file_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> MergeResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Perform line-by-line three-way merge of file content.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            base_content: Content from merge base commit</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            our_content: Content from current branch  </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            their_content: Content from branch being merged</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            file_path: Path for error reporting</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            MergeResult with merged content or conflicts</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Split each content version into lines (handle different line endings)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Run diff algorithm between base->ours and base->theirs</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Create line mapping showing which lines changed in each branch</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Iterate through lines applying three-way merge logic:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #         - Unchanged in both: keep base version  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #         - Changed in ours only: apply our change</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #         - Changed in theirs only: apply their change</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #         - Changed identically: keep the shared change</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #         - Changed differently: mark as conflict</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Group consecutive conflicts into regions with context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Generate conflict markers for unresolved regions  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Return MergeResult with final content and conflict metadata</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _detect_conflicts</span><span style=\"color:#E1E4E8\">(self, base_lines: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">], our_lines: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">],</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                         their_lines: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]) -> List[ConflictRegion]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Identify regions where both branches made incompatible changes.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            List of conflict regions requiring manual resolution</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Use Myers diff to find edit scripts for base->ours and base->theirs</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Build change maps showing which lines were modified in each branch</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Find overlapping changes where both branches modified same line ranges</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Classify conflict types (content, add/add, delete/modify)  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Group adjacent conflicts with context lines</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Create ConflictRegion objects with all necessary metadata</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _generate_conflict_markers</span><span style=\"color:#E1E4E8\">(self, conflict: ConflictRegion, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                  our_branch: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, their_branch: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Generate standard Git conflict markers for a conflict region.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            List of lines with conflict markers inserted</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create opening marker with our branch name: \"&#x3C;&#x3C;&#x3C;&#x3C;&#x3C;&#x3C;&#x3C; {our_branch}\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Add all lines from our version of the conflict</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Add separator marker: \"=======\"  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Add all lines from their version of the conflict</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Add closing marker with their branch name: \">>>>>>> {their_branch}\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return complete conflict block as list of lines</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _is_binary_content</span><span style=\"color:#E1E4E8\">(self, content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Check if content appears to be binary data.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(content) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Check first 1024 bytes for null bytes or high ratio of non-printable chars</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        sample </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> content[:</span><span style=\"color:#79B8FF\">1024</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> b</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\x00</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> sample:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        printable_chars </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> sum</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#F97583\"> for</span><span style=\"color:#E1E4E8\"> byte </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> sample </span><span style=\"color:#F97583\">if</span><span style=\"color:#79B8FF\"> 32</span><span style=\"color:#F97583\"> &#x3C;=</span><span style=\"color:#E1E4E8\"> byte </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 126</span><span style=\"color:#F97583\"> or</span><span style=\"color:#E1E4E8\"> byte </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> [</span><span style=\"color:#79B8FF\">9</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">13</span><span style=\"color:#E1E4E8\">])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ratio </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> printable_chars </span><span style=\"color:#F97583\">/</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(sample) </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> sample </span><span style=\"color:#F97583\">else</span><span style=\"color:#79B8FF\"> 1.0</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> ratio </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 0.75</span></span></code></pre></div>\n\n<p><strong>E. Language-Specific Implementation Hints:</strong></p>\n<ul>\n<li><strong>Graph Traversal</strong>: Use <code>collections.deque</code> for BFS queues - it has O(1) append/popleft operations compared to O(n) for lists</li>\n<li><strong>String Processing</strong>: Use <code>str.splitlines(keepends=True)</code> to preserve line ending information during merge</li>\n<li><strong>Memory Management</strong>: For large files, consider using generators or streaming processing rather than loading entire content</li>\n<li><strong>Path Handling</strong>: Use <code>pathlib.Path</code> consistently and call <code>.resolve()</code> to handle symbolic links properly</li>\n<li><strong>Error Handling</strong>: Catch <code>KeyError</code> when looking up objects that might not exist, and <code>UnicodeDecodeError</code> when processing potentially binary content</li>\n</ul>\n<p><strong>F. Milestone Checkpoint:</strong></p>\n<p>After implementing three-way merge:</p>\n<ol>\n<li><strong>Test Basic Merge</strong>: Create two branches that modify different files, merge should complete cleanly</li>\n<li><strong>Test Conflict Detection</strong>: Create branches that modify the same lines, verify conflict markers appear</li>\n<li><strong>Test Merge Base</strong>: Verify merge base calculation finds correct common ancestor</li>\n<li><strong>Integration Test</strong>: Run <code>python -m git merge branch-name</code> and compare results with real Git</li>\n</ol>\n<p>Expected behavior:</p>\n<ul>\n<li>Clean merges complete without user intervention  </li>\n<li>Conflicted files contain properly formatted conflict markers</li>\n<li>Merge commit has two parent references</li>\n<li>Working directory contains merged content</li>\n</ul>\n<p><strong>G. Debugging Tips:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>Diagnosis</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>&quot;No merge base found&quot;</td>\n<td>Branches have separate histories</td>\n<td>Check commit ancestry with log</td>\n<td>Verify both branches descend from same root</td>\n</tr>\n<tr>\n<td>Merge creates wrong conflicts</td>\n<td>Incorrect diff algorithm</td>\n<td>Compare diff output with Git&#39;s</td>\n<td>Debug Myers algorithm implementation</td>\n</tr>\n<tr>\n<td>Missing conflict markers</td>\n<td>Binary file detected incorrectly</td>\n<td>Check file content detection</td>\n<td>Adjust binary detection thresholds</td>\n</tr>\n<tr>\n<td>Malformed conflict output</td>\n<td>Line ending inconsistencies</td>\n<td>Check line splitting logic</td>\n<td>Normalize line endings before processing</td>\n</tr>\n</tbody></table>\n<h2 id=\"component-interactions-and-data-flow\">Component Interactions and Data Flow</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section synthesizes all eight milestones, showing how components interact during complex operations. It&#39;s particularly crucial for understanding the complete workflows in Milestone 6 (Index/Staging Area), Milestone 7 (Diff Algorithm), and Milestone 8 (Three-Way Merge), while demonstrating how earlier milestones (Object Storage, References, Tree Objects, Commit Objects) integrate into cohesive operations.</p>\n</blockquote>\n<h3 id=\"mental-model-the-assembly-line-factory\">Mental Model: The Assembly Line Factory</h3>\n<p>Think of Git operations as an assembly line factory where raw materials (your file changes) flow through different stations, getting processed and transformed at each stage. The <strong>working directory</strong> is your raw materials warehouse, the <strong>staging area</strong> is the quality control station where you inspect and prepare items for production, the <strong>object store</strong> is the permanent inventory warehouse, and <strong>references</strong> are the catalog system that helps you find finished products later.</p>\n<p>Just as a factory has standard workflows—receiving materials, quality control, assembly, packaging, and shipping—Git has standard data flows for its core operations. A simple product might visit only a few stations (like storing a single file), while a complex product (like merging two feature branches) requires coordination across all stations with multiple quality checks and decision points.</p>\n<p>The beauty of this assembly line design is that each station has a single, well-defined responsibility, but the stations can be combined in different sequences to handle everything from simple file storage to complex multi-branch merges. Understanding these workflows is essential because they reveal how Git maintains consistency and enables powerful features like atomic commits and conflict-free parallel development.</p>\n<p><img src=\"/api/project/build-git/architecture-doc/asset?path=diagrams%2Fsystem-architecture.svg\" alt=\"Git System Architecture\"></p>\n<h3 id=\"commit-creation-data-flow\">Commit Creation Data Flow</h3>\n<p>The commit creation process represents Git&#39;s most fundamental workflow, transforming scattered file changes in your working directory into an immutable entry in the project&#39;s permanent history. This operation demonstrates the elegant coordination between all four major components: the working directory provides the raw changes, the staging area curates which changes to include, the object store provides permanent storage with deduplication, and the reference system updates to point to the new history state.</p>\n<h4 id=\"stage-1-file-staging-git-add\">Stage 1: File Staging (git add)</h4>\n<p>The staging process begins when a developer runs the equivalent of <code>git add</code>, which moves changes from the working directory into the staging area. This operation involves complex coordination between the <code>WorkingDirectory</code>, <code>Index</code>, and <code>ObjectStore</code> components to ensure that file content is preserved exactly while metadata is captured for change detection.</p>\n<p>The staging workflow follows these detailed steps:</p>\n<ol>\n<li>The <code>WorkingDirectory</code> component scans the specified file path and reads the complete file content into memory, handling both text and binary files uniformly as byte streams</li>\n<li>The system computes the SHA-1 hash of the file content using the blob object format: <code>blob {size}\\0{content}</code>, which ensures that identical file contents always produce identical hashes regardless of filename or location</li>\n<li>The <code>ObjectStore</code> checks whether an object with this hash already exists in the <code>.git/objects</code> directory, leveraging Git&#39;s content-addressable storage to avoid storing duplicate content</li>\n<li>If the object doesn&#39;t exist, the system compresses the full blob object using zlib compression and stores it at the path <code>.git/objects/xx/yy...</code> where <code>xx</code> is the first two hex characters of the SHA-1 hash</li>\n<li>The <code>Index</code> creates a new <code>IndexEntry</code> containing the file&#39;s complete metadata: modification times (<code>mtime_sec</code>, <code>mtime_nsec</code>), file size (<code>size</code>), file mode (<code>mode</code>), device and inode numbers for change detection, and the computed object hash</li>\n<li>The new entry replaces any existing entry for the same file path in the index&#39;s sorted entry list, maintaining the index&#39;s alphabetical ordering requirement</li>\n<li>The modified index is written atomically to <code>.git/index</code> using a temporary file and rename operation to ensure consistency even if the process is interrupted</li>\n</ol>\n<p>This staging process creates a critical checkpoint where the file&#39;s content is permanently preserved in the object store, while the index maintains a snapshot of the working directory state at staging time.</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Responsibility</th>\n<th>Data Input</th>\n<th>Data Output</th>\n<th>Side Effects</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>WorkingDirectory</code></td>\n<td>File content reading</td>\n<td>File path</td>\n<td>Raw file bytes</td>\n<td>None (read-only)</td>\n</tr>\n<tr>\n<td><code>ObjectStore</code></td>\n<td>Content preservation</td>\n<td>Blob object data</td>\n<td>Object hash</td>\n<td>Creates compressed object file</td>\n</tr>\n<tr>\n<td><code>Index</code></td>\n<td>Change tracking</td>\n<td>File metadata + hash</td>\n<td>Updated entry list</td>\n<td>Modifies .git/index file</td>\n</tr>\n</tbody></table>\n<h4 id=\"stage-2-tree-construction-git-write-tree\">Stage 2: Tree Construction (git write-tree)</h4>\n<p>Tree construction transforms the flat list of staged files into Git&#39;s hierarchical tree structure, which mirrors the directory organization while enabling efficient storage and comparison of project states. This process requires the <code>Index</code> to coordinate with the <code>ObjectStore</code> to build a nested tree structure where each directory becomes a tree object containing references to its files (as blobs) and subdirectories (as subtrees).</p>\n<p>The tree construction algorithm proceeds recursively through the directory hierarchy:</p>\n<ol>\n<li>The <code>Index</code> groups all staged entries by their parent directory path, creating a hierarchical structure that mirrors the working directory organization</li>\n<li>For each directory level, starting from the deepest subdirectories and working upward, the system creates a tree object containing sorted entries</li>\n<li>Each tree entry consists of the file mode (e.g., <code>100644</code> for regular files, <code>040000</code> for subdirectories), the filename or directory name, and the 20-byte binary SHA-1 hash of the referenced object</li>\n<li>Subdirectories are processed first to obtain their tree hashes, which are then referenced by their parent directories, creating a bottom-up construction process</li>\n<li>The tree entries are sorted according to Git&#39;s specific sorting rules: directories sort as if they have a trailing slash, ensuring consistent tree hashes regardless of entry insertion order</li>\n<li>Each tree object is formatted as <code>tree {size}\\0{entry1}{entry2}...{entryN}</code> where each entry is the binary concatenation of mode, space, name, null byte, and 20-byte hash</li>\n<li>The formatted tree object is hashed, compressed, and stored in the object store using the same content-addressable storage mechanism as blob objects</li>\n<li>The process continues up the directory hierarchy until a single root tree hash represents the entire project structure</li>\n</ol>\n<p>This tree construction process creates an immutable snapshot of the project&#39;s directory structure, where identical directory contents always produce identical tree hashes, enabling efficient comparison and storage.</p>\n<table>\n<thead>\n<tr>\n<th>Directory Level</th>\n<th>Input Data</th>\n<th>Processing</th>\n<th>Output</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Leaf directories</td>\n<td>File entries from index</td>\n<td>Sort + format tree object</td>\n<td>Tree hash</td>\n</tr>\n<tr>\n<td>Intermediate directories</td>\n<td>File entries + subtree hashes</td>\n<td>Sort + format tree object</td>\n<td>Tree hash</td>\n</tr>\n<tr>\n<td>Root directory</td>\n<td>All entries + subtree hashes</td>\n<td>Sort + format tree object</td>\n<td>Root tree hash</td>\n</tr>\n</tbody></table>\n<h4 id=\"stage-3-commit-creation-git-commit\">Stage 3: Commit Creation (git commit)</h4>\n<p>Commit creation represents the culmination of the staging process, where the prepared tree object is wrapped with metadata to create a permanent, immutable entry in the project&#39;s history. This operation involves the <code>ObjectStore</code> for content storage and the <code>ReferenceManager</code> for updating the current branch pointer, creating an atomic transition from one project state to another.</p>\n<p>The commit creation process follows these precise steps:</p>\n<ol>\n<li>The system retrieves the root tree hash from the tree construction phase, which represents the complete project state being committed</li>\n<li>The <code>ReferenceManager</code> resolves the current HEAD reference to determine the parent commit hash, handling both normal branch situations and detached HEAD states</li>\n<li>The system collects commit metadata including author information (name, email, timestamp with timezone), committer information (typically identical to author), and the commit message provided by the user</li>\n<li>A commit object is constructed with the format: <code>commit {size}\\0tree {tree_hash}\\nparent {parent_hash}\\nauthor {author_line}\\ncommitter {committer_line}\\n\\n{commit_message}</code></li>\n<li>The formatted commit object is hashed using SHA-1, compressed with zlib, and stored in the object store using the same content-addressable mechanism as other Git objects</li>\n<li>The <code>ReferenceManager</code> atomically updates the current branch reference (or HEAD in detached state) to point to the new commit hash, using a temporary file and rename operation for consistency</li>\n<li>If the repository tracks a reflog, the reference change is logged with the commit hash, previous hash, author information, and commit message for audit purposes</li>\n</ol>\n<p>This commit creation process establishes an immutable link in the project&#39;s history chain, where the new commit references both the project state (via the tree hash) and the previous history (via the parent hash), creating Git&#39;s characteristic directed acyclic graph structure.</p>\n<blockquote>\n<p>The critical insight in commit creation is that the tree hash captures <em>what</em> changed while the parent hash captures <em>when</em> it changed relative to other commits. This dual referencing system enables Git to efficiently answer both &quot;what was the project state at this point?&quot; and &quot;how did we get to this state?&quot; questions.</p>\n</blockquote>\n<p><img src=\"/api/project/build-git/architecture-doc/asset?path=diagrams%2Fcommit-creation-flow.svg\" alt=\"Commit Creation Sequence\"></p>\n<h4 id=\"data-flow-summary-for-commit-creation\">Data Flow Summary for Commit Creation</h4>\n<p>The complete commit creation flow demonstrates how Git&#39;s four-layer architecture enables atomic, consistent operations even when dealing with hundreds or thousands of files. Each component has a single responsibility, but they coordinate through well-defined interfaces to ensure that the working directory, index, and object store remain synchronized.</p>\n<table>\n<thead>\n<tr>\n<th>Operation Phase</th>\n<th>Primary Component</th>\n<th>Secondary Components</th>\n<th>Critical Data</th>\n<th>Failure Recovery</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>File staging</td>\n<td><code>Index</code></td>\n<td><code>WorkingDirectory</code>, <code>ObjectStore</code></td>\n<td>File content + metadata</td>\n<td>Partial index can be rebuilt from objects</td>\n</tr>\n<tr>\n<td>Tree construction</td>\n<td><code>ObjectStore</code></td>\n<td><code>Index</code></td>\n<td>Directory structure + hashes</td>\n<td>Trees can be reconstructed from index</td>\n</tr>\n<tr>\n<td>Commit creation</td>\n<td><code>ReferenceManager</code></td>\n<td><code>ObjectStore</code></td>\n<td>Parent hash + tree hash</td>\n<td>Reference can be reset to previous state</td>\n</tr>\n<tr>\n<td>Reference update</td>\n<td><code>ReferenceManager</code></td>\n<td>None</td>\n<td>New commit hash</td>\n<td>Atomic file operations prevent corruption</td>\n</tr>\n</tbody></table>\n<h3 id=\"branch-merge-data-flow\">Branch Merge Data Flow</h3>\n<p>Branch merging represents Git&#39;s most complex operation, requiring coordination across all system components to combine changes from two independent lines of development while detecting and managing conflicts. Unlike the linear flow of commit creation, merge operations involve bidirectional data flow, backtracking algorithms, and conditional logic based on the discovered merge state.</p>\n<h4 id=\"mental-model-the-document-reconciliation-process\">Mental Model: The Document Reconciliation Process</h4>\n<p>Think of branch merging like two editors working independently on the same document. Each editor starts with the same original version (the merge base), makes their own changes, and then you need to create a final version that includes both sets of changes. Sometimes their edits don&#39;t overlap (easy merge), sometimes they edit different parts of the same paragraph (automatic merge), and sometimes they change the same sentence in conflicting ways (manual merge required).</p>\n<p>Git&#39;s three-way merge algorithm automates this reconciliation process by comparing three versions: the original document (merge base), editor A&#39;s version (our branch), and editor B&#39;s version (their branch). By understanding what each editor changed relative to the original, Git can intelligently combine non-conflicting changes and flag areas where human judgment is needed.</p>\n<h4 id=\"stage-1-merge-base-discovery\">Stage 1: Merge Base Discovery</h4>\n<p>Merge base discovery involves traversing the commit history graph to find the most recent common ancestor between two branches. This operation requires the <code>ObjectStore</code> to retrieve commit objects and performs a graph search algorithm to identify the point where the branches diverged, which serves as the reference point for three-way comparison.</p>\n<p>The merge base discovery algorithm uses a breadth-first search approach with distance tracking:</p>\n<ol>\n<li>The <code>MergeBaseCalculator</code> initializes two parallel breadth-first searches, one starting from each branch tip, maintaining separate visited sets and distance tracking for each search path</li>\n<li>Each iteration expands one level of parent commits from both starting points, retrieving commit objects from the <code>ObjectStore</code> and parsing their parent references</li>\n<li>The algorithm tracks the minimum distance from each starting commit to every discovered ancestor commit, enabling it to identify the lowest common ancestor when paths converge</li>\n<li>When a commit is discovered from both search paths, it represents a potential merge base, but the algorithm continues until it has explored all commits at the current distance level to ensure optimality</li>\n<li>Among all discovered common ancestors, the algorithm selects the one with the minimum combined distance from both branch tips, which represents the most recent common ancestor</li>\n<li>Special cases are handled including: merge commits with multiple parents (both parents are added to the search queue), initial commits with no parents (search terminates at repository root), and branches with no common history (rare but possible in repositories with multiple root commits)</li>\n<li>The algorithm returns the SHA-1 hash of the identified merge base commit, or signals an error if no common ancestry exists between the branches</li>\n</ol>\n<p>This merge base discovery creates the foundation for three-way comparison by establishing the &quot;original document&quot; against which both branches&#39; changes will be evaluated.</p>\n<table>\n<thead>\n<tr>\n<th>Search Phase</th>\n<th>Data Structure</th>\n<th>Content</th>\n<th>Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Initialization</td>\n<td><code>visited_a: Set[str]</code></td>\n<td>Branch A&#39;s starting commit</td>\n<td>Track explored commits from branch A</td>\n</tr>\n<tr>\n<td>Initialization</td>\n<td><code>visited_b: Set[str]</code></td>\n<td>Branch B&#39;s starting commit</td>\n<td>Track explored commits from branch B</td>\n</tr>\n<tr>\n<td>Expansion</td>\n<td><code>distances_a: Dict[str, int]</code></td>\n<td>Commit hash → distance mapping</td>\n<td>Find shortest path from branch A</td>\n</tr>\n<tr>\n<td>Expansion</td>\n<td><code>distances_b: Dict[str, int]</code></td>\n<td>Commit hash → distance mapping</td>\n<td>Find shortest path from branch B</td>\n</tr>\n<tr>\n<td>Convergence</td>\n<td><code>common_ancestors: Set[str]</code></td>\n<td>Intersection of visited sets</td>\n<td>Identify potential merge bases</td>\n</tr>\n<tr>\n<td>Selection</td>\n<td><code>merge_base: str</code></td>\n<td>Optimal common ancestor hash</td>\n<td>Reference point for three-way merge</td>\n</tr>\n</tbody></table>\n<h4 id=\"stage-2-three-way-file-comparison\">Stage 2: Three-Way File Comparison</h4>\n<p>Three-way file comparison forms the heart of Git&#39;s merge algorithm, analyzing each file that exists in any of the three versions (merge base, our branch, their branch) to determine whether changes can be automatically combined or require manual conflict resolution. This process requires the <code>ObjectStore</code> to retrieve file content and the <code>MyersDiff</code> algorithm to compute precise change locations.</p>\n<p>The three-way comparison process analyzes each file through multiple decision paths:</p>\n<ol>\n<li>The <code>ThreeWayMerge</code> component enumerates all unique file paths that exist in any of the three commits (merge base, ours, theirs), creating a comprehensive list of files that require analysis</li>\n<li>For each file path, the system retrieves the file content from all three versions where the file exists, handling cases where the file was added, deleted, or modified in different branches</li>\n<li>The Myers diff algorithm computes two separate edit scripts: one from the merge base to our version, and another from the merge base to their version, identifying exactly which lines were added, deleted, or modified</li>\n<li>The system analyzes the two edit scripts to categorize the merge scenario: clean merge (non-overlapping changes), conflict (overlapping changes), or various edge cases like add/add conflicts where both branches created the same file path</li>\n<li>For clean merges, the algorithm applies both sets of changes to the merge base content, creating a unified result that incorporates modifications from both branches</li>\n<li>For conflicts, the system identifies the specific line ranges where changes overlap and generates conflict markers that preserve both versions for manual resolution</li>\n<li>Binary files receive special handling since line-by-line merging is not applicable; binary conflicts always require manual resolution by choosing one version or the other</li>\n<li>The result for each file is classified into one of several categories: cleanly merged content, conflicted content with markers, binary conflict requiring resolution, or deletion/modification conflicts</li>\n</ol>\n<p>This three-way analysis produces a complete understanding of how the two branches diverged and where human intervention is required to complete the merge.</p>\n<table>\n<thead>\n<tr>\n<th>File State</th>\n<th>Base Version</th>\n<th>Our Version</th>\n<th>Their Version</th>\n<th>Merge Result</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Unchanged</td>\n<td>Exists</td>\n<td>Identical</td>\n<td>Identical</td>\n<td>Use any version</td>\n</tr>\n<tr>\n<td>Modified by us only</td>\n<td>Exists</td>\n<td>Modified</td>\n<td>Identical</td>\n<td>Use our version</td>\n</tr>\n<tr>\n<td>Modified by them only</td>\n<td>Exists</td>\n<td>Identical</td>\n<td>Modified</td>\n<td>Use their version</td>\n</tr>\n<tr>\n<td>Modified by both (clean)</td>\n<td>Exists</td>\n<td>Modified</td>\n<td>Modified</td>\n<td>Merge both changes</td>\n</tr>\n<tr>\n<td>Modified by both (conflict)</td>\n<td>Exists</td>\n<td>Modified</td>\n<td>Modified</td>\n<td>Insert conflict markers</td>\n</tr>\n<tr>\n<td>Added by us only</td>\n<td>None</td>\n<td>Exists</td>\n<td>None</td>\n<td>Use our version</td>\n</tr>\n<tr>\n<td>Added by them only</td>\n<td>None</td>\n<td>None</td>\n<td>Exists</td>\n<td>Use their version</td>\n</tr>\n<tr>\n<td>Added by both (same content)</td>\n<td>None</td>\n<td>Exists</td>\n<td>Exists</td>\n<td>Use either version</td>\n</tr>\n<tr>\n<td>Added by both (different)</td>\n<td>None</td>\n<td>Exists</td>\n<td>Exists</td>\n<td>Insert conflict markers</td>\n</tr>\n<tr>\n<td>Deleted by us only</td>\n<td>Exists</td>\n<td>None</td>\n<td>Identical</td>\n<td>Delete file</td>\n</tr>\n<tr>\n<td>Deleted by them only</td>\n<td>Exists</td>\n<td>Identical</td>\n<td>None</td>\n<td>Delete file</td>\n</tr>\n<tr>\n<td>Deleted by both</td>\n<td>Exists</td>\n<td>None</td>\n<td>None</td>\n<td>Delete file</td>\n</tr>\n<tr>\n<td>Delete/modify conflict</td>\n<td>Exists</td>\n<td>None</td>\n<td>Modified</td>\n<td>Conflict requiring resolution</td>\n</tr>\n</tbody></table>\n<h4 id=\"stage-3-conflict-resolution-and-merge-commit-creation\">Stage 3: Conflict Resolution and Merge Commit Creation</h4>\n<p>When conflicts are detected during three-way comparison, the system must create a partially merged state that preserves both versions for manual resolution, then provide mechanisms for completing the merge once conflicts are resolved. This process involves the <code>Index</code>, <code>WorkingDirectory</code>, and <code>ReferenceManager</code> components working together to maintain merge state across multiple user interactions.</p>\n<p>The conflict resolution workflow manages the complex state transitions required for interactive merging:</p>\n<ol>\n<li>The <code>ThreeWayMerge</code> component writes conflicted files to the working directory with Git&#39;s standard conflict markers: <code>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</code> delimiting our changes, <code>=======</code> separating the versions, and <code>&gt;&gt;&gt;&gt;&gt;&gt;&gt; {branch_name}</code> delimiting their changes</li>\n<li>The <code>Index</code> is updated to record the merge state by storing index entries for all three versions of conflicted files (stage 1 for merge base, stage 2 for our version, stage 3 for their version), while cleanly merged files are stored as normal stage 0 entries</li>\n<li>A <code>.git/MERGE_HEAD</code> file is created containing the SHA-1 hash of the branch being merged, which signals to other Git operations that a merge is in progress and prevents certain operations that could corrupt the merge state</li>\n<li>The user manually resolves conflicts by editing the working directory files to remove conflict markers and create the desired merged content, typically using text editors or specialized merge tools</li>\n<li>The user stages their resolution using the equivalent of <code>git add</code>, which removes the multi-stage index entries for each resolved file and replaces them with a single stage 0 entry containing the resolved content</li>\n<li>Once all conflicts are resolved (indicated by no remaining multi-stage index entries), the user can complete the merge by creating a merge commit</li>\n<li>The merge commit creation process follows the same object creation steps as regular commits, but includes two parent hashes: the current branch tip and the merged branch tip, creating Git&#39;s characteristic merge topology</li>\n<li>Upon successful merge commit creation, the <code>.git/MERGE_HEAD</code> file is removed, the current branch reference is updated to point to the new merge commit, and the merge state is cleared</li>\n</ol>\n<p>This conflict resolution process maintains complete safety by preserving all original content while providing clear indicators of what requires manual attention.</p>\n<blockquote>\n<p>The critical design insight for merge conflict handling is that Git never loses information during conflicts. The original versions from both branches are preserved in the index at different stages, the conflict markers clearly delineate the choices, and the user&#39;s resolution becomes part of the permanent history. This enables confident merging even in complex scenarios because you can always recover the original versions if needed.</p>\n</blockquote>\n<h4 id=\"stage-4-merge-state-management\">Stage 4: Merge State Management</h4>\n<p>Managing merge state involves tracking the progress of a multi-step merge operation across multiple user interactions, ensuring that partial merge states are preserved consistently and that the system can detect incomplete merges to prevent data loss. This requires coordination between the <code>Index</code>, <code>ReferenceManager</code>, and file system to maintain merge metadata.</p>\n<p>The merge state management system handles several complex scenarios:</p>\n<ol>\n<li><strong>In-progress merge detection</strong>: The presence of <code>.git/MERGE_HEAD</code> signals that a merge is in progress, causing status commands to display merge information and preventing operations like starting new merges or switching branches that could lose merge state</li>\n<li><strong>Multi-stage index management</strong>: Conflicted files are stored with stage numbers (1 = merge base, 2 = ours, 3 = theirs) in the index, while resolved files use stage 0, enabling precise tracking of which conflicts remain unresolved</li>\n<li><strong>Partial resolution handling</strong>: Users can resolve conflicts incrementally, staging some files while leaving others conflicted, with the system maintaining accurate state for each file independently</li>\n<li><strong>Merge abort capability</strong>: The system can restore the pre-merge state by resetting the working directory and index to the original branch tip and removing merge metadata files</li>\n<li><strong>Merge commit validation</strong>: Before allowing merge commit creation, the system verifies that no multi-stage index entries remain, ensuring that all conflicts have been explicitly resolved</li>\n<li><strong>Reference safety</strong>: During merge operations, the current branch reference is not updated until the merge commit is successfully created, maintaining a consistent rollback point</li>\n<li><strong>Working directory synchronization</strong>: The system ensures that working directory file contents match the user&#39;s intended resolutions and that no uncommitted changes would be lost during merge completion</li>\n</ol>\n<p>This comprehensive state management enables safe, incremental conflict resolution while maintaining system consistency throughout the merge process.</p>\n<table>\n<thead>\n<tr>\n<th>Merge State</th>\n<th>Index Entries</th>\n<th>Working Directory</th>\n<th>Metadata Files</th>\n<th>User Actions Available</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Clean merge</td>\n<td>Stage 0 only</td>\n<td>Merged content</td>\n<td>None</td>\n<td>Commit merge immediately</td>\n</tr>\n<tr>\n<td>Conflicts present</td>\n<td>Multi-stage entries</td>\n<td>Conflict markers</td>\n<td><code>.git/MERGE_HEAD</code></td>\n<td>Resolve conflicts, stage files</td>\n</tr>\n<tr>\n<td>Partially resolved</td>\n<td>Mixed stage entries</td>\n<td>Some resolved, some conflicted</td>\n<td><code>.git/MERGE_HEAD</code></td>\n<td>Continue resolving, stage files</td>\n</tr>\n<tr>\n<td>Fully resolved</td>\n<td>Stage 0 only</td>\n<td>All resolved</td>\n<td><code>.git/MERGE_HEAD</code></td>\n<td>Commit merge</td>\n</tr>\n<tr>\n<td>Aborted merge</td>\n<td>Original state</td>\n<td>Original state</td>\n<td>None</td>\n<td>Normal operations</td>\n</tr>\n</tbody></table>\n<h3 id=\"common-pitfalls-in-component-interactions\">Common Pitfalls in Component Interactions</h3>\n<p>Understanding the complex data flows in Git operations helps identify common mistakes that can lead to inconsistent repository states or data loss. These pitfalls often occur at the boundaries between components where assumptions about data consistency or operation atomicity may not hold.</p>\n<p>⚠️ <strong>Pitfall: Non-atomic Index Updates</strong></p>\n<p>Many implementers update the index entry by entry during staging operations, which can leave the repository in an inconsistent state if the process is interrupted. For example, partially updating the index during a large <code>git add</code> operation could result in some files being staged while others remain in an unknown state. The index file could become corrupted if the process crashes while writing, since the checksum at the end of the file would not match the partial content. Always use atomic writes with temporary files and rename operations, and ensure that the index checksum is computed over the complete final state before writing.</p>\n<p>⚠️ <strong>Pitfall: Incorrect Object Hash Computation</strong></p>\n<p>A common mistake is computing object hashes over just the content bytes rather than the complete object format including the type header and size. This leads to hash mismatches where your implementation generates different hashes than real Git for identical content. The hash must be computed over the complete format: <code>{type} {size}\\0{content}</code> where the null byte is critical and often forgotten. Additionally, ensure that the size is the byte count of the raw content, not the formatted object, and that binary content is handled without text encoding conversions.</p>\n<p>⚠️ <strong>Pitfall: Merge Base Calculation Errors</strong></p>\n<p>Merge base discovery can fail in repositories with complex branching topologies, particularly when dealing with merge commits that have multiple parents or when branches have been created and deleted repeatedly. A common error is implementing a simple &quot;first common ancestor&quot; algorithm rather than finding the <em>lowest</em> common ancestor, which can result in merge bases that are too far back in history. This leads to unnecessarily complex merges with spurious conflicts. Always implement breadth-first search with proper distance tracking, and handle edge cases like octopus merges and orphan branches.</p>\n<p>⚠️ <strong>Pitfall: Conflict Marker Generation</strong></p>\n<p>When generating conflict markers during merge operations, many implementations fail to properly escape or handle edge cases in the conflict content itself. If the conflicted content already contains lines that look like conflict markers (e.g., lines starting with <code>&lt;&lt;&lt;&lt;&lt;&lt;&lt;</code>), the generated markers can become ambiguous or confusing. Additionally, failing to include proper branch names or commit identifiers in the conflict markers makes it difficult for users to understand which version is which. Always validate that generated markers are unambiguous and include sufficient context for resolution.</p>\n<p>⚠️ <strong>Pitfall: Reference Update Race Conditions</strong></p>\n<p>In systems where multiple processes might access the repository simultaneously, updating references without proper locking can lead to lost commits or corrupted branch states. For example, if two processes attempt to commit to the same branch simultaneously, one commit might be lost if both read the same parent hash but only the last write succeeds. While single-user scenarios are common during learning, understanding the race conditions helps build more robust implementations. Use file locking or atomic operations for reference updates, and consider implementing basic conflict detection for concurrent access.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>This section provides concrete implementation support for building the component interactions and data flows described above. The code focuses on orchestrating the individual components built in previous milestones into cohesive, complex operations.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n<th>Notes</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Flow orchestration</td>\n<td>Simple function calls</td>\n<td>Command pattern with undo</td>\n<td>Commands enable better error recovery</td>\n</tr>\n<tr>\n<td>State management</td>\n<td>Direct attribute access</td>\n<td>State machine pattern</td>\n<td>State machines prevent invalid transitions</td>\n</tr>\n<tr>\n<td>Error handling</td>\n<td>Exception bubbling</td>\n<td>Result/Option types</td>\n<td>Explicit error handling improves debugging</td>\n</tr>\n<tr>\n<td>Concurrency</td>\n<td>Sequential operations</td>\n<td>Lock-free algorithms</td>\n<td>Start simple, optimize later if needed</td>\n</tr>\n<tr>\n<td>Progress tracking</td>\n<td>Print statements</td>\n<td>Observer pattern with events</td>\n<td>Useful for long-running merge operations</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<p>The component interaction code should coordinate the individual components built in previous milestones:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>src/\n  git/\n    commands/\n      add.py              ← Implements staging workflow\n      commit.py           ← Implements commit creation workflow  \n      merge.py            ← Implements merge workflow\n      status.py           ← Implements status calculation workflow\n    workflows/\n      commit_workflow.py  ← Complete commit creation orchestration\n      merge_workflow.py   ← Complete merge orchestration\n    core/                 ← Individual components from previous milestones\n      object_store.py     ← From Milestone 2-4\n      index.py           ← From Milestone 6\n      references.py      ← From Milestone 5\n      diff.py           ← From Milestone 7\n      merge.py          ← From Milestone 8</code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p>Complete workflow orchestration helpers that coordinate the individual components:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Workflow orchestration utilities for complex Git operations.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Provides high-level coordination between individual components.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional, Tuple, Set</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> WorkflowError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">Exception</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Base exception for workflow orchestration errors.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> WorkflowStatus</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Status of a multi-step workflow operation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    SUCCESS</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"success\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    PARTIAL</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"partial\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    CONFLICT</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"conflict\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    ERROR</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"error\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> WorkflowResult</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Result of a workflow operation with detailed status information.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    status: WorkflowStatus</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    message: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    files_changed: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    conflicts: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    warnings: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __post_init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.conflicts </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.conflicts </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.warnings </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.warnings </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ProgressReporter</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Simple progress reporting for long-running operations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, total_items: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.total_items </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> total_items</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.completed_items </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.current_operation </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> start_operation</span><span style=\"color:#E1E4E8\">(self, operation: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, total: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Start a new operation with optional total item count.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.current_operation </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> operation</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.completed_items </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> total </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.total_items </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> total</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Starting: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">operation</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> update_progress</span><span style=\"color:#E1E4E8\">(self, items_completed: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Update progress by specified number of items.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.completed_items </span><span style=\"color:#F97583\">+=</span><span style=\"color:#E1E4E8\"> items_completed</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.total_items </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            percentage </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.completed_items </span><span style=\"color:#F97583\">/</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.total_items) </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 100</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Progress: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">percentage</span><span style=\"color:#F97583\">:.1f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">% (</span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.completed_items</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">/</span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.total_items</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">) </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">message</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Progress: </span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.completed_items</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> items completed </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">message</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> finish_operation</span><span style=\"color:#E1E4E8\">(self, success: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Mark current operation as finished.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        status </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"completed\"</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> success </span><span style=\"color:#F97583\">else</span><span style=\"color:#9ECBFF\"> \"failed\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Finished: </span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.current_operation</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> - </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">status</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> validate_repository_state</span><span style=\"color:#E1E4E8\">(git_dir: Path) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Validate that repository is in a consistent state for operations.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns list of validation errors, empty list if valid.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    errors </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Check basic repository structure</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> git_dir.exists():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        errors.append(</span><span style=\"color:#9ECBFF\">\"Git directory does not exist\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> errors</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    objects_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"objects\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> objects_dir.exists():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        errors.append(</span><span style=\"color:#9ECBFF\">\"Objects directory missing\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    refs_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"refs\"</span><span style=\"color:#F97583\"> /</span><span style=\"color:#9ECBFF\"> \"heads\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> refs_dir.exists():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        errors.append(</span><span style=\"color:#9ECBFF\">\"References directory missing\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    head_file </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"HEAD\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> head_file.exists():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        errors.append(</span><span style=\"color:#9ECBFF\">\"HEAD reference missing\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Check for corrupted index</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    index_file </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"index\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> index_file.exists():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Attempt to read index header to validate format</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            with</span><span style=\"color:#79B8FF\"> open</span><span style=\"color:#E1E4E8\">(index_file, </span><span style=\"color:#9ECBFF\">'rb'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> f:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                signature </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> f.read(</span><span style=\"color:#79B8FF\">4</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> signature </span><span style=\"color:#F97583\">!=</span><span style=\"color:#F97583\"> b</span><span style=\"color:#9ECBFF\">'DIRC'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    errors.append(</span><span style=\"color:#9ECBFF\">\"Index file corrupted - invalid signature\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            errors.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Index file unreadable: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> errors</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> atomic_workflow_operation</span><span style=\"color:#E1E4E8\">(operation_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, operation_func, cleanup_func</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Decorator for atomic workflow operations with automatic cleanup on failure.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    If operation fails, cleanup_func is called to restore previous state.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> decorator</span><span style=\"color:#E1E4E8\">(func):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        def</span><span style=\"color:#B392F0\"> wrapper</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">args, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Starting atomic operation: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">operation_name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                result </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> operation_func(</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">args, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Atomic operation completed: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">operation_name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#E1E4E8\"> result</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Atomic operation failed: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">operation_name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> - </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> cleanup_func:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        cleanup_func(</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">args, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Cleanup completed for: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">operation_name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> cleanup_error:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Cleanup failed for </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">operation_name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">cleanup_error</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                raise</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> wrapper</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> decorator</span></span></code></pre></div>\n\n<h4 id=\"commit-creation-workflow-implementation\">Commit Creation Workflow Implementation</h4>\n<p>Complete orchestration for the commit creation process:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Commit creation workflow implementation.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Orchestrates staging, tree building, and commit creation.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Optional, Set</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .workflows.base </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> WorkflowResult, WorkflowStatus, ProgressReporter</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> CommitWorkflow</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Orchestrates the complete commit creation process.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, repository, object_store, index, references):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.repository </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> repository</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.object_store </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> object_store</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.index </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> index</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.references </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> references</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.progress </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ProgressReporter()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> stage_files</span><span style=\"color:#E1E4E8\">(self, file_paths: List[Path]) -> WorkflowResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Stage multiple files for commit.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Coordinates WorkingDirectory -> ObjectStore -> Index flow.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate that all file paths exist in working directory</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: For each file, read content and compute blob hash</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Store blob object in object store (with deduplication check)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Create IndexEntry with file metadata and object hash</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Add IndexEntry to index, replacing any existing entry</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Save updated index atomically to .git/index</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use ProgressReporter to show staging progress for large numbers of files</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Collect any files that couldn't be staged and include in warnings</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> build_tree_from_index</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Build tree object hierarchy from current index state.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns root tree hash representing complete project state.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Group index entries by directory path (recursive grouping)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Start with deepest subdirectories, build tree objects bottom-up</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: For each directory level, create sorted list of tree entries</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Format tree entries as: mode + \" \" + name + \"\\0\" + 20-byte hash</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Create tree object with format: \"tree {size}\\0{entries}\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Store tree object in object store and get its hash</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Continue up directory hierarchy until root tree is built</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Directories sort as if they have trailing \"/\" for Git compatibility</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Tree entries must be sorted for deterministic tree hashes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> create_commit</span><span style=\"color:#E1E4E8\">(self, tree_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, parent_hashes: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Create commit object linking tree to history.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns commit hash for the new commit.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Get current HEAD reference to determine parent commit</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Format author and committer lines with timestamp and timezone</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Build commit content: tree line, parent lines, author, committer, blank line, message</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Create commit object with format: \"commit {size}\\0{content}\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Store commit object in object store and get its hash</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Update current branch reference to point to new commit</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Clear any merge state files if this completes a merge</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Handle both normal commits (1 parent) and merge commits (2+ parents)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use atomic reference update to prevent corruption</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> execute_commit</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, stage_all: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> False</span><span style=\"color:#E1E4E8\">) -> WorkflowResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Execute complete commit workflow: stage files, build tree, create commit.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        This is the high-level orchestration function.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.progress.start_operation(</span><span style=\"color:#9ECBFF\">\"Creating commit\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: If stage_all=True, stage all modified files in working directory</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Validate that index contains at least one staged change</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Build tree object from current index state</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Create commit object with tree hash and commit message</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Update HEAD reference to point to new commit</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return WorkflowResult with success status and commit details</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Hint: Use progress.update_progress() to show workflow steps</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Hint: Return appropriate error status if any step fails</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Hint: Include commit hash and files changed count in result</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.progress.finish_operation(</span><span style=\"color:#FFAB70\">success</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> WorkflowResult(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                status</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">WorkflowStatus.</span><span style=\"color:#79B8FF\">ERROR</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                message</span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Commit failed: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span></code></pre></div>\n\n<h4 id=\"merge-workflow-implementation\">Merge Workflow Implementation</h4>\n<p>Complete orchestration for the merge process:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Merge workflow implementation.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Orchestrates merge base discovery, three-way merge, and conflict resolution.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .workflows.base </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> WorkflowResult, WorkflowStatus, ProgressReporter</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> MergeWorkflow</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Orchestrates the complete branch merge process.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, repository, object_store, index, references, merge_algorithm):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.repository </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> repository</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.object_store </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> object_store</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.index </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> index</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.references </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> references</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.merge_algorithm </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> merge_algorithm</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.progress </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ProgressReporter()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> discover_merge_base</span><span style=\"color:#E1E4E8\">(self, our_commit: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, their_commit: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Find lowest common ancestor between two commits.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Uses breadth-first search with distance tracking.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Initialize BFS queues for both commits with distance 0</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Track visited commits and distances from each starting point  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Expand one level at a time, adding parent commits to queues</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: When commit appears in both visited sets, it's a common ancestor</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Continue until all commits at current distance level are processed</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return common ancestor with minimum combined distance</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Handle edge cases: no common ancestor, identical commits</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use object_store.retrieve_object() to get commit objects</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Parse commit objects to extract parent hashes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Return None if branches have no common history</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> analyze_merge_conflicts</span><span style=\"color:#E1E4E8\">(self, base_commit: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, our_commit: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, their_commit: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Analyze all files in three commits to categorize merge requirements.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns dict mapping file paths to merge status.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Get tree objects for all three commits</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Extract all unique file paths from all three trees</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: For each file path, determine what happened in each branch</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Categorize each file: clean merge, conflict, add/add, delete/modify, etc.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return mapping of file_path -> merge_status</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use tree traversal to find all files in each commit</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Handle cases where file exists in some commits but not others</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Status values: \"clean\", \"conflict\", \"add_add\", \"delete_modify\", etc.</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> execute_three_way_merge</span><span style=\"color:#E1E4E8\">(self, base_commit: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, our_commit: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, their_commit: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> WorkflowResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Perform three-way merge of two branches.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Handles both clean merges and conflicts.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.progress.start_operation(</span><span style=\"color:#9ECBFF\">\"Merging branches\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Analyze all files to categorize merge requirements</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: For each file, perform appropriate merge operation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Write cleanly merged files to working directory</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Write conflicted files with conflict markers to working directory</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Update index with appropriate stage entries (0 for clean, 1/2/3 for conflicts)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Create .git/MERGE_HEAD file with their commit hash</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Return result indicating clean merge or conflicts requiring resolution</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Hint: Use progress reporting for large merges</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Hint: Collect conflict file paths for result reporting</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Hint: Handle binary files (always conflict, no line-level merge)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.progress.finish_operation(</span><span style=\"color:#FFAB70\">success</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> WorkflowResult(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                status</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">WorkflowStatus.</span><span style=\"color:#79B8FF\">ERROR</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                message</span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Merge failed: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> resolve_conflicts_and_commit</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> WorkflowResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Complete merge after manual conflict resolution.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Creates merge commit with two parents.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Verify that no multi-stage index entries remain (all conflicts resolved)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Build tree from resolved index state</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Get both parent commits: current HEAD and MERGE_HEAD</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Create merge commit with both parent hashes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Update HEAD reference to new merge commit</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Remove .git/MERGE_HEAD file to clear merge state</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Return success result with merge commit details</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Generate default merge message if none provided</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Validate that working directory matches index (no unstaged changes)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Merge commits have exactly two parent lines in commit object</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p>After implementing the component interactions, verify the complete workflows:</p>\n<p><strong>Commit Creation Verification:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Initialize test repository</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> git.init</span><span style=\"color:#9ECBFF\"> test_repo</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">cd</span><span style=\"color:#9ECBFF\"> test_repo</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Create and stage multiple files</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#9ECBFF\"> \"Content A\"</span><span style=\"color:#F97583\"> ></span><span style=\"color:#9ECBFF\"> file_a.txt</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#9ECBFF\"> \"Content B\"</span><span style=\"color:#F97583\"> ></span><span style=\"color:#9ECBFF\"> file_b.txt</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">mkdir</span><span style=\"color:#9ECBFF\"> subdir</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#9ECBFF\"> \"Content C\"</span><span style=\"color:#F97583\"> ></span><span style=\"color:#9ECBFF\"> subdir/file_c.txt</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> git.add</span><span style=\"color:#9ECBFF\"> file_a.txt</span><span style=\"color:#9ECBFF\"> file_b.txt</span><span style=\"color:#9ECBFF\"> subdir/file_c.txt</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> git.commit</span><span style=\"color:#9ECBFF\"> \"Initial commit with multiple files\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Verify objects were created correctly</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> git.log</span><span style=\"color:#79B8FF\"> --oneline</span><span style=\"color:#6A737D\">  # Should show commit</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> git.ls-tree</span><span style=\"color:#9ECBFF\"> HEAD</span><span style=\"color:#6A737D\">   # Should show tree structure</span></span></code></pre></div>\n\n<p><strong>Expected output:</strong> Commit creation should produce consistent tree and commit hashes, with working directory, index, and object store all synchronized.</p>\n<p><strong>Merge Workflow Verification:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Create two branches with diverging changes</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> git.checkout</span><span style=\"color:#79B8FF\"> -b</span><span style=\"color:#9ECBFF\"> feature</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#9ECBFF\"> \"Feature change\"</span><span style=\"color:#F97583\"> >></span><span style=\"color:#9ECBFF\"> file_a.txt</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> git.add</span><span style=\"color:#9ECBFF\"> file_a.txt</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> git.commit</span><span style=\"color:#9ECBFF\"> \"Feature commit\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> git.checkout</span><span style=\"color:#9ECBFF\"> main</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#9ECBFF\"> \"Main change\"</span><span style=\"color:#F97583\"> >></span><span style=\"color:#9ECBFF\"> file_b.txt</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> git.add</span><span style=\"color:#9ECBFF\"> file_b.txt</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> git.commit</span><span style=\"color:#9ECBFF\"> \"Main commit\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Attempt merge - should be clean</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> git.merge</span><span style=\"color:#9ECBFF\"> feature</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Verify merge commit was created</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> git.log</span><span style=\"color:#79B8FF\"> --graph</span><span style=\"color:#79B8FF\"> --oneline</span><span style=\"color:#6A737D\">  # Should show merge topology</span></span></code></pre></div>\n\n<p><strong>Expected behavior:</strong> Clean merge should complete automatically, conflicting merge should leave conflict markers and require manual resolution.</p>\n<h2 id=\"error-handling-and-edge-cases\">Error Handling and Edge Cases</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section applies to all eight milestones but is particularly critical for Milestone 6 (Index/Staging Area), Milestone 7 (Diff Algorithm), and Milestone 8 (Three-Way Merge). Robust error handling becomes essential as operations grow more complex and involve multiple components interacting.</p>\n</blockquote>\n<h3 id=\"mental-model-the-digital-safety-net\">Mental Model: The Digital Safety Net</h3>\n<p>Think of error handling in a version control system like the safety systems in a modern airplane. Just as aircraft have multiple redundant systems, automatic failure detection, and clear emergency procedures that pilots practice extensively, a robust Git implementation needs layered protection against data corruption, clear detection of problems, and well-defined recovery workflows that users can follow confidently.</p>\n<p>When turbulence hits an aircraft, the autopilot doesn&#39;t just crash—it has protocols for every conceivable failure mode. Similarly, when your Git implementation encounters corrupted objects, interrupted merges, or concurrent access conflicts, it should degrade gracefully, preserve data integrity above all else, and provide clear guidance for recovery.</p>\n<p>The critical insight is that version control systems are <strong>data custodians</strong>—they hold irreplaceable project history. Like a bank vault, the system must be paranoid about data integrity and conservative about operations that could cause loss. This means validating everything, assuming hardware can fail at any moment, and always providing a path back to a known good state.</p>\n<h3 id=\"repository-corruption-handling\">Repository Corruption Handling</h3>\n<p>Repository corruption represents the most serious class of failures in version control systems. Unlike application crashes that lose only current work, corruption can destroy historical data that may be impossible to recreate. Our error handling strategy must prioritize <strong>early detection</strong>, <strong>damage isolation</strong>, and <strong>graceful recovery</strong> while maintaining data integrity above all other concerns.</p>\n<h4 id=\"corruption-detection-strategies\">Corruption Detection Strategies</h4>\n<p>The foundation of corruption handling lies in comprehensive validation that occurs at multiple layers throughout the system. Rather than trusting that data remains intact, we implement verification at every access point to catch corruption as early as possible.</p>\n<p><strong>Object Integrity Verification</strong> forms the first line of defense. Every time we retrieve an object from the content-addressable store, we must verify that its content still produces the expected SHA-1 hash. This catches both storage corruption and programming bugs that might corrupt objects in memory.</p>\n<table>\n<thead>\n<tr>\n<th>Validation Point</th>\n<th>Check Performed</th>\n<th>Frequency</th>\n<th>Action on Failure</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Object Retrieval</td>\n<td>SHA-1 verification</td>\n<td>Every access</td>\n<td>Return corruption error</td>\n</tr>\n<tr>\n<td>Object Storage</td>\n<td>Hash before/after compression</td>\n<td>Every write</td>\n<td>Abort operation</td>\n</tr>\n<tr>\n<td>Index Loading</td>\n<td>Checksum verification</td>\n<td>On index read</td>\n<td>Rebuild from working tree</td>\n</tr>\n<tr>\n<td>Reference Resolution</td>\n<td>SHA-1 format validation</td>\n<td>Every resolution</td>\n<td>Report invalid reference</td>\n</tr>\n<tr>\n<td>Tree Traversal</td>\n<td>Entry format validation</td>\n<td>During traversal</td>\n<td>Stop at corrupted tree</td>\n</tr>\n<tr>\n<td>Commit Parsing</td>\n<td>Header format validation</td>\n<td>During log operations</td>\n<td>Mark commit as corrupted</td>\n</tr>\n</tbody></table>\n<p><strong>Repository Structure Validation</strong> ensures that the fundamental directory structure and required files remain intact. This validation should occur during repository initialization and can be triggered explicitly by user commands.</p>\n<p>The validation algorithm proceeds systematically through repository components:</p>\n<ol>\n<li>Verify that the git directory exists and has appropriate permissions (0755)</li>\n<li>Check that required subdirectories exist: objects, refs, refs/heads, refs/tags</li>\n<li>Validate that the HEAD file exists and contains either a valid symbolic reference or commit hash</li>\n<li>Scan the objects directory to ensure the two-character subdirectory structure is intact</li>\n<li>Verify that no objects have been corrupted by spot-checking a sample of stored objects</li>\n<li>Validate reference files to ensure they contain properly formatted commit hashes or symbolic references</li>\n<li>Check the index file format and checksum if present</li>\n</ol>\n<p><strong>Cross-Reference Consistency</strong> validates that references between objects remain valid. A commit might reference a tree that no longer exists, or a tree might reference a blob that has been corrupted. These consistency checks require traversing object relationships and validating each link.</p>\n<h4 id=\"corruption-recovery-strategies\">Corruption Recovery Strategies</h4>\n<p>Recovery from corruption depends heavily on the extent and location of the damage. Our recovery strategy follows a <strong>progressive escalation</strong> approach, starting with minimal intervention and escalating to more drastic measures only when necessary.</p>\n<blockquote>\n<p><strong>Decision: Corruption Recovery Hierarchy</strong></p>\n<ul>\n<li><strong>Context</strong>: When corruption is detected, we need a systematic approach to recovery that minimizes data loss while restoring repository functionality</li>\n<li><strong>Options Considered</strong>: <ul>\n<li>Immediate full repository rebuild from working directory</li>\n<li>Attempt to repair specific corrupted components</li>\n<li>Progressive recovery starting with least invasive repairs</li>\n</ul>\n</li>\n<li><strong>Decision</strong>: Implement progressive recovery hierarchy starting with object-level repairs</li>\n<li><strong>Rationale</strong>: Maximizes data preservation while providing clear escalation path; users retain control over recovery process</li>\n<li><strong>Consequences</strong>: More complex recovery logic but better preservation of historical data and user confidence</li>\n</ul>\n</blockquote>\n<p><strong>Level 1: Object-Level Recovery</strong> addresses corruption in individual objects while preserving the broader repository structure. When object retrieval fails due to hash mismatch or decompression errors, the system should attempt to recover the object from alternative sources.</p>\n<table>\n<thead>\n<tr>\n<th>Recovery Method</th>\n<th>Source</th>\n<th>Applicability</th>\n<th>Success Rate</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Re-read from disk</td>\n<td>Same object file</td>\n<td>Transient I/O errors</td>\n<td>High</td>\n</tr>\n<tr>\n<td>Rebuild from working tree</td>\n<td>Current file content</td>\n<td>Blob objects only</td>\n<td>Medium</td>\n</tr>\n<tr>\n<td>Reconstruct from index</td>\n<td>Staged content</td>\n<td>Recently staged files</td>\n<td>Medium</td>\n</tr>\n<tr>\n<td>Import from backup</td>\n<td>External copy</td>\n<td>Any object type</td>\n<td>Variable</td>\n</tr>\n</tbody></table>\n<p><strong>Level 2: Reference Recovery</strong> handles corruption in the reference system, including damaged HEAD files, missing branch references, or invalid symbolic references. Reference recovery is generally safer than object recovery since references can be reconstructed from known commit hashes.</p>\n<p>The reference recovery process involves:</p>\n<ol>\n<li>Scan the objects directory to identify all available commit objects</li>\n<li>Parse each commit to extract author, timestamp, and message information</li>\n<li>Present a list of recent commits to the user for branch recreation</li>\n<li>Allow the user to select which commits should become branch heads</li>\n<li>Recreate the branch references pointing to the selected commits</li>\n<li>Reset HEAD to point to the user&#39;s preferred default branch</li>\n</ol>\n<p><strong>Level 3: Index Reconstruction</strong> rebuilds the staging area when the index file becomes corrupted or inconsistent. Since the index represents only the current staging state, it can be safely reconstructed from the working directory without losing historical data.</p>\n<p><strong>Level 4: Repository Rebuild</strong> represents the most drastic recovery option, essentially reinitializing the repository while preserving as much history as possible. This approach salvages individual objects and reconstructs the repository structure around them.</p>\n<h4 id=\"validation-error-types-and-responses\">Validation Error Types and Responses</h4>\n<p>Different types of corruption require specialized detection and response strategies. Our implementation must recognize each category and apply appropriate recovery measures.</p>\n<table>\n<thead>\n<tr>\n<th>Error Type</th>\n<th>Detection Method</th>\n<th>Immediate Response</th>\n<th>Recovery Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>SHA-1 Mismatch</td>\n<td>Hash verification</td>\n<td>Block object access</td>\n<td>Re-read or rebuild object</td>\n</tr>\n<tr>\n<td>Compression Failure</td>\n<td>Zlib decompression</td>\n<td>Return read error</td>\n<td>Attempt raw file recovery</td>\n</tr>\n<tr>\n<td>Malformed Object</td>\n<td>Header parsing</td>\n<td>Parsing exception</td>\n<td>Reconstruct from metadata</td>\n</tr>\n<tr>\n<td>Missing Object</td>\n<td>File system access</td>\n<td>File not found</td>\n<td>Search for alternatives</td>\n</tr>\n<tr>\n<td>Invalid Reference</td>\n<td>Reference resolution</td>\n<td>Format validation</td>\n<td>Reset to valid commit</td>\n</tr>\n<tr>\n<td>Corrupt Index</td>\n<td>Checksum verification</td>\n<td>Index load failure</td>\n<td>Rebuild from working tree</td>\n</tr>\n<tr>\n<td>Permission Errors</td>\n<td>File system operations</td>\n<td>Access denied</td>\n<td>Report and suggest fixes</td>\n</tr>\n</tbody></table>\n<p>⚠️ <strong>Pitfall: Silent Corruption</strong>\nMany corruption scenarios don&#39;t immediately cause obvious failures. A single bit flip in an object file might not be detected until that specific object is accessed, potentially weeks later. Always implement comprehensive validation rather than assuming storage is reliable. Check SHA-1 hashes on every object read, not just during explicit verification commands.</p>\n<h3 id=\"merge-conflict-resolution\">Merge Conflict Resolution</h3>\n<p>Merge conflicts represent a normal part of collaborative development, but the complexity of conflict resolution can overwhelm users if not handled gracefully. Our conflict resolution system must provide <strong>clear conflict presentation</strong>, <strong>intuitive resolution workflows</strong>, and <strong>safe mechanisms</strong> for completing interrupted merges.</p>\n<h4 id=\"conflict-detection-and-classification\">Conflict Detection and Classification</h4>\n<p>Effective conflict resolution begins with precise conflict detection that categorizes conflicts by type and complexity. This classification helps users understand what they&#39;re dealing with and choose appropriate resolution strategies.</p>\n<p><strong>Content Conflicts</strong> occur when both branches modify the same lines of a file. These represent the classic merge conflict scenario where automated merging cannot determine which changes should take precedence.</p>\n<p>The conflict detection algorithm compares changes from both branches against their common ancestor:</p>\n<ol>\n<li>Identify all lines that were modified in the &quot;ours&quot; branch relative to the merge base</li>\n<li>Identify all lines that were modified in the &quot;theirs&quot; branch relative to the merge base</li>\n<li>Find overlapping regions where both branches modified the same line numbers</li>\n<li>For each overlap, determine if the changes are identical (auto-resolve) or conflicting (require manual resolution)</li>\n<li>Generate conflict markers for regions that require manual resolution</li>\n</ol>\n<p><strong>Structural Conflicts</strong> arise from changes to file organization rather than content. These conflicts require different resolution strategies than simple content conflicts.</p>\n<table>\n<thead>\n<tr>\n<th>Conflict Type</th>\n<th>Scenario</th>\n<th>Detection Method</th>\n<th>Resolution Options</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Add/Add</td>\n<td>Both branches add file with same name</td>\n<td>Path collision during merge</td>\n<td>Keep one, keep both with rename, manual merge</td>\n</tr>\n<tr>\n<td>Delete/Modify</td>\n<td>One branch deletes, other modifies</td>\n<td>Missing file during content merge</td>\n<td>Keep modification, confirm deletion</td>\n</tr>\n<tr>\n<td>Mode Change</td>\n<td>Different permission changes</td>\n<td>File mode comparison</td>\n<td>Choose one mode or manual decision</td>\n</tr>\n<tr>\n<td>Rename/Rename</td>\n<td>Both branches rename same file</td>\n<td>Path tracking during merge</td>\n<td>Choose one name or create new name</td>\n</tr>\n<tr>\n<td>Directory/File</td>\n<td>Directory becomes file or vice versa</td>\n<td>Path type validation</td>\n<td>Manual resolution required</td>\n</tr>\n</tbody></table>\n<p><strong>Binary File Conflicts</strong> require special handling since line-based merging doesn&#39;t apply to binary content. The system must detect binary files and present appropriate resolution options.</p>\n<h4 id=\"conflict-marker-generation\">Conflict Marker Generation</h4>\n<p>When conflicts cannot be resolved automatically, the system must generate clear, standardized conflict markers that help users understand what happened and how to proceed. The conflict marker format follows Git&#39;s established conventions to maintain familiarity for users.</p>\n<p>The standard conflict marker structure includes:</p>\n<ol>\n<li>Opening marker (<code>&lt;&lt;&lt;&lt;&lt;&lt;&lt;</code>) followed by branch identifier for &quot;ours&quot; changes</li>\n<li>The conflicting content from the &quot;ours&quot; branch</li>\n<li>Separator marker (<code>=======</code>) dividing the conflicting versions</li>\n<li>The conflicting content from the &quot;theirs&quot; branch  </li>\n<li>Closing marker (<code>&gt;&gt;&gt;&gt;&gt;&gt;&gt;</code>) followed by branch identifier for &quot;theirs&quot; changes</li>\n</ol>\n<p>For three-way conflicts where the merge base content differs from both branches, an additional marker (<code>|||||||</code>) introduces the original content between the ours section and the separator.</p>\n<blockquote>\n<p>The key insight for effective conflict markers is that they must tell a story. Users need to understand not just what the conflicting content is, but where it came from, why it conflicts, and what their options are for resolution. Clear branch identifiers and optional base content provide this context.</p>\n</blockquote>\n<h4 id=\"conflict-resolution-workflows\">Conflict Resolution Workflows</h4>\n<p>Successful conflict resolution requires well-defined workflows that guide users through the resolution process without overwhelming them. The workflow design must accommodate both novice and experienced users while maintaining safety throughout the process.</p>\n<p><strong>Interactive Resolution Workflow</strong> provides step-by-step guidance for users who prefer structured assistance:</p>\n<ol>\n<li>Present a summary of all conflicts found, categorized by type and file</li>\n<li>For each conflicted file, display the conflict in context with surrounding unchanged lines</li>\n<li>Offer resolution options: edit manually, choose ours, choose theirs, or skip for now</li>\n<li>After each resolution, validate that conflict markers have been properly removed</li>\n<li>Allow users to test their resolution by running builds or tests before finalizing</li>\n<li>Provide a final review showing all resolved conflicts before completing the merge</li>\n</ol>\n<p><strong>Batch Resolution Workflow</strong> supports experienced users who want to resolve multiple conflicts efficiently:</p>\n<ol>\n<li>Generate a conflict summary report showing all conflicts and their types</li>\n<li>Allow pattern-based resolution for similar conflicts (e.g., &quot;choose ours for all .config files&quot;)</li>\n<li>Provide bulk editing capabilities for systematic conflict resolution</li>\n<li>Validate that all conflicts have been addressed before allowing merge completion</li>\n</ol>\n<p><strong>Tool Integration Workflow</strong> supports external merge tools by providing standardized interfaces:</p>\n<ol>\n<li>Generate temporary files containing base, ours, and theirs versions for each conflict</li>\n<li>Launch the configured merge tool with appropriate file arguments</li>\n<li>Wait for the tool to complete and validate the merged result</li>\n<li>Import the resolved content back into the working directory</li>\n<li>Continue with the next conflict or complete the merge process</li>\n</ol>\n<h4 id=\"interrupted-merge-recovery\">Interrupted Merge Recovery</h4>\n<p>Merge operations can be interrupted by system crashes, user cancellation, or external factors. The system must maintain enough state information to allow users to resume or abort interrupted merges safely.</p>\n<p><strong>Merge State Tracking</strong> records the current merge operation&#39;s progress and context in the git directory. This state information enables recovery after interruption.</p>\n<table>\n<thead>\n<tr>\n<th>State File</th>\n<th>Content</th>\n<th>Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>MERGE_HEAD</td>\n<td>Target commit hash</td>\n<td>Identifies what we&#39;re merging</td>\n</tr>\n<tr>\n<td>MERGE_MODE</td>\n<td>Merge type and options</td>\n<td>Records merge algorithm settings</td>\n</tr>\n<tr>\n<td>MERGE_MSG</td>\n<td>Proposed commit message</td>\n<td>Preserves user&#39;s merge message</td>\n</tr>\n<tr>\n<td>MERGE_PROGRESS</td>\n<td>Resolved/remaining files</td>\n<td>Tracks completion status</td>\n</tr>\n</tbody></table>\n<p><strong>Recovery Options</strong> provide users with clear paths forward when they encounter an interrupted merge:</p>\n<ol>\n<li><strong>Continue Merge</strong>: Resume the merge process after resolving remaining conflicts</li>\n<li><strong>Abort Merge</strong>: Return to the pre-merge state, discarding all merge progress</li>\n<li><strong>Reset Merge</strong>: Restart the merge from the beginning with fresh conflict resolution</li>\n</ol>\n<p>The continue workflow validates that all conflicts have been resolved before proceeding:</p>\n<ol>\n<li>Scan all files mentioned in MERGE_PROGRESS for remaining conflict markers</li>\n<li>Verify that the working directory contains no unexpected changes</li>\n<li>Build the final merge tree from resolved content</li>\n<li>Create the merge commit with both parent commits recorded</li>\n<li>Update the current branch reference and clean up merge state files</li>\n</ol>\n<p>The abort workflow ensures complete restoration to the pre-merge state:</p>\n<ol>\n<li>Read the original HEAD commit from the merge state files</li>\n<li>Reset the working directory to match the original commit tree</li>\n<li>Clear the index of any merge-related staged content</li>\n<li>Remove all merge state files to indicate normal (non-merge) state</li>\n<li>Display a summary of what was discarded for user confirmation</li>\n</ol>\n<p>⚠️ <strong>Pitfall: Partial Conflict Resolution</strong>\nUsers often resolve some conflicts and then forget to complete the merge, leaving the repository in an intermediate state. Always check for incomplete merges during status operations and provide clear guidance. Store enough state to distinguish between &quot;merge in progress with remaining conflicts&quot; and &quot;merge ready to complete&quot; scenarios.</p>\n<h3 id=\"concurrent-access-patterns\">Concurrent Access Patterns</h3>\n<p>Modern development workflows often involve multiple processes accessing the same repository simultaneously. Build systems, IDE integrations, backup tools, and multiple Git commands can all attempt repository operations concurrently. Our implementation must handle these scenarios gracefully without corrupting data or creating inconsistent states.</p>\n<h4 id=\"file-system-level-concurrency\">File System Level Concurrency</h4>\n<p>The fundamental challenge of concurrent access lies in the shared file system that underlies Git&#39;s storage model. Multiple processes writing to the same files or directories can create race conditions, partial updates, and corruption scenarios that are difficult to diagnose and recover from.</p>\n<p><strong>Atomic Operations Strategy</strong> ensures that file operations either complete entirely or fail entirely, preventing partial updates that could leave the repository in an inconsistent state.</p>\n<table>\n<thead>\n<tr>\n<th>Operation Type</th>\n<th>Atomicity Mechanism</th>\n<th>Failure Handling</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Object Storage</td>\n<td>Write to temp file, rename</td>\n<td>Remove temp file on failure</td>\n</tr>\n<tr>\n<td>Reference Updates</td>\n<td>Write to temp file, rename</td>\n<td>Restore original reference</td>\n</tr>\n<tr>\n<td>Index Updates</td>\n<td>Write complete index to temp, rename</td>\n<td>Restore backup index</td>\n</tr>\n<tr>\n<td>Branch Creation</td>\n<td>Atomic file creation with O_EXCL</td>\n<td>Report if branch exists</td>\n</tr>\n<tr>\n<td>Lock Acquisition</td>\n<td>Create lock file with O_EXCL</td>\n<td>Wait or fail immediately</td>\n</tr>\n</tbody></table>\n<p>The atomic write pattern forms the foundation of safe concurrent access:</p>\n<ol>\n<li>Generate a unique temporary filename in the same directory as the target file</li>\n<li>Write the complete content to the temporary file</li>\n<li>Sync the temporary file to ensure data reaches persistent storage</li>\n<li>Atomically rename the temporary file to the final filename</li>\n<li>If any step fails, remove the temporary file and report the error</li>\n</ol>\n<p><strong>Locking Protocols</strong> prevent multiple processes from modifying the same repository components simultaneously. Our locking strategy balances safety with performance, using fine-grained locks where possible to minimize contention.</p>\n<p>The repository uses several categories of locks:</p>\n<ul>\n<li><strong>Reference Locks</strong>: Protect individual branch and tag references during updates</li>\n<li><strong>Index Lock</strong>: Prevents concurrent modification of the staging area</li>\n<li><strong>Object Store Locks</strong>: Protect against concurrent writes to the same object (rare but possible)</li>\n<li><strong>Merge State Locks</strong>: Prevent multiple merge operations from running simultaneously</li>\n</ul>\n<p>Lock acquisition follows a consistent protocol to avoid deadlocks:</p>\n<ol>\n<li>Determine all required locks for the operation in a predetermined order</li>\n<li>Attempt to acquire each lock in sequence with appropriate timeouts</li>\n<li>If any lock acquisition fails, release all previously acquired locks</li>\n<li>Either retry with backoff or report the failure to the user</li>\n<li>Upon successful completion, release all locks in reverse order</li>\n</ol>\n<p><strong>Lock File Implementation</strong> uses the file system&#39;s atomic file creation semantics to implement advisory locks. This approach works across different operating systems and doesn&#39;t require specialized locking primitives.</p>\n<p>Lock file creation process:</p>\n<ol>\n<li>Generate lock filename by appending <code>.lock</code> to the protected resource name</li>\n<li>Attempt to create the lock file with exclusive access (O_CREAT | O_EXCL)</li>\n<li>If creation succeeds, write lock metadata (process ID, operation type, timestamp)</li>\n<li>If creation fails because the file exists, another process holds the lock</li>\n<li>To release the lock, simply remove the lock file</li>\n</ol>\n<h4 id=\"process-coordination-patterns\">Process Coordination Patterns</h4>\n<p>Beyond basic file locking, certain operations require coordination between processes to ensure consistent behavior and avoid conflicts that locks alone cannot prevent.</p>\n<p><strong>Read-Write Coordination</strong> allows multiple readers to access repository data simultaneously while ensuring that write operations have exclusive access when needed. This pattern is particularly important for long-running operations like large merges or history traversals.</p>\n<table>\n<thead>\n<tr>\n<th>Access Pattern</th>\n<th>Lock Type</th>\n<th>Concurrency Level</th>\n<th>Use Cases</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Multiple Readers</td>\n<td>Shared read access</td>\n<td>High concurrency</td>\n<td>Status, log, diff operations</td>\n</tr>\n<tr>\n<td>Single Writer</td>\n<td>Exclusive write access</td>\n<td>No concurrency</td>\n<td>Commit, merge, rebase operations</td>\n</tr>\n<tr>\n<td>Reader-Writer</td>\n<td>Upgrade from read to write</td>\n<td>Medium concurrency</td>\n<td>Add operations that become commits</td>\n</tr>\n</tbody></table>\n<p><strong>Operation Serialization</strong> ensures that certain operations complete in a consistent order even when initiated simultaneously. This is particularly important for operations that depend on the current repository state.</p>\n<p>The serialization mechanism works through operation queuing:</p>\n<ol>\n<li>Operations that require serialization acquire a queue position lock</li>\n<li>Each operation writes its intent and dependencies to a coordination file</li>\n<li>Operations check their dependencies before proceeding with actual work</li>\n<li>Upon completion, operations signal their completion and wake waiting operations</li>\n<li>The coordination file is cleaned up when no operations remain pending</li>\n</ol>\n<p><strong>Graceful Degradation Strategies</strong> allow the system to continue operating even when some concurrent access patterns fail. Rather than failing completely, the system falls back to safer but potentially slower operation modes.</p>\n<table>\n<thead>\n<tr>\n<th>Failure Scenario</th>\n<th>Degradation Strategy</th>\n<th>Performance Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Lock timeout</td>\n<td>Prompt user to retry or wait</td>\n<td>User intervention required</td>\n</tr>\n<tr>\n<td>File contention</td>\n<td>Retry with exponential backoff</td>\n<td>Increased operation latency</td>\n</tr>\n<tr>\n<td>Coordination failure</td>\n<td>Fall back to exclusive locking</td>\n<td>Reduced concurrency</td>\n</tr>\n<tr>\n<td>Resource exhaustion</td>\n<td>Queue operations sequentially</td>\n<td>Serialized execution</td>\n</tr>\n</tbody></table>\n<h4 id=\"error-recovery-in-concurrent-scenarios\">Error Recovery in Concurrent Scenarios</h4>\n<p>Concurrent access introduces additional failure modes that don&#39;t occur in single-process scenarios. These failures often involve partial state updates, timing-dependent races, and complex interactions between multiple operations.</p>\n<p><strong>Orphaned Lock Detection</strong> identifies and recovers from situations where locks are left behind by crashed or killed processes. Without proper cleanup, these orphaned locks can permanently block repository access.</p>\n<p>The orphaned lock detection algorithm:</p>\n<ol>\n<li>When lock acquisition fails, examine the existing lock file contents</li>\n<li>Extract the process ID and timestamp from the lock metadata</li>\n<li>Check if the process ID still exists and is running the expected operation</li>\n<li>If the process is gone or running a different operation, consider the lock orphaned</li>\n<li>Verify that sufficient time has passed since lock creation to avoid false positives</li>\n<li>Remove the orphaned lock and proceed with the operation</li>\n</ol>\n<p><strong>Partial Operation Recovery</strong> handles scenarios where an operation begins but cannot complete due to concurrent access conflicts. The system must be able to detect these partial states and either complete the operation or roll back to a consistent state.</p>\n<p>Partial operation scenarios include:</p>\n<ul>\n<li>Reference updates that write the new value but fail to remove backup files</li>\n<li>Index updates that complete partially before lock contention forces abandonment</li>\n<li>Object store operations that create objects but fail to update references</li>\n<li>Merge operations that resolve some conflicts but encounter locking issues</li>\n</ul>\n<p>The recovery strategy involves state validation and corrective action:</p>\n<ol>\n<li>During repository initialization, scan for signs of incomplete operations</li>\n<li>For each incomplete operation type, determine if completion is safe</li>\n<li>If completion is safe and beneficial, finish the operation automatically</li>\n<li>If completion is risky or impossible, roll back to the previous consistent state</li>\n<li>Log the recovery action for user awareness and debugging</li>\n</ol>\n<p><strong>Deadlock Prevention</strong> ensures that multiple processes cannot create circular waiting conditions that would permanently block progress. While file-based locking reduces deadlock risk compared to more complex locking primitives, careful lock ordering prevents the remaining deadlock scenarios.</p>\n<p>The deadlock prevention protocol establishes a global ordering for all repository locks:</p>\n<ol>\n<li>Object store locks (ordered by object hash)</li>\n<li>Index lock</li>\n<li>Reference locks (ordered alphabetically by reference name)</li>\n<li>Merge state locks</li>\n</ol>\n<p>All operations must acquire locks in this predetermined order and release them in reverse order. Operations that cannot acquire all needed locks within the timeout period must release all locks and retry to avoid deadlock scenarios.</p>\n<p>⚠️ <strong>Pitfall: Lock File Cleanup</strong>\nLock files can accumulate over time if processes crash or are killed forcefully. Always implement cleanup logic that runs during normal operations to detect and remove orphaned locks. However, be very conservative about timing—removing a lock that&#39;s actually held by a slow operation can cause corruption.</p>\n<p>⚠️ <strong>Pitfall: Cross-Platform File Locking</strong>\nFile locking semantics vary across operating systems, particularly between Windows and Unix-like systems. Test your locking implementation thoroughly on all target platforms, and consider using advisory locks rather than mandatory locks for better portability and recovery options.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Error Types</td>\n<td>Python exceptions with custom hierarchy</td>\n<td>Structured error enums with detailed context</td>\n</tr>\n<tr>\n<td>Logging</td>\n<td>Python logging module with file handlers</td>\n<td>Structured logging with correlation IDs</td>\n</tr>\n<tr>\n<td>File Locking</td>\n<td>fcntl-based advisory locks (Unix)</td>\n<td>Cross-platform locking with timeout</td>\n</tr>\n<tr>\n<td>Validation</td>\n<td>Manual checks with custom validators</td>\n<td>Schema-based validation with automatic checking</td>\n</tr>\n<tr>\n<td>Recovery</td>\n<td>Interactive prompts with user choice</td>\n<td>Automated recovery with safety checks</td>\n</tr>\n<tr>\n<td>Concurrency</td>\n<td>Process-level coordination with lock files</td>\n<td>Thread-safe operations with proper synchronization</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>project-root/\n  src/\n    git_impl/\n      errors/\n        __init__.py              ← error hierarchy and base classes\n        corruption.py            ← repository corruption errors\n        merge.py                 ← merge conflict and resolution errors  \n        concurrency.py           ← concurrent access errors\n      validation/\n        __init__.py              ← validation framework\n        repository.py            ← repository structure validation\n        objects.py               ← object integrity validation\n        references.py            ← reference consistency validation\n      recovery/\n        __init__.py              ← recovery orchestration\n        corruption.py            ← corruption detection and repair\n        merge.py                 ← merge conflict resolution workflows\n        locks.py                 ← lock management and cleanup\n      concurrency/\n        __init__.py              ← concurrency coordination\n        locks.py                 ← file-based locking implementation\n        coordination.py          ← process coordination patterns</code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p><strong>Error Hierarchy Implementation:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Git error hierarchy for comprehensive error handling and recovery.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> GitError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">Exception</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Base exception for all Git-related errors.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, error_code: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">, recoverable: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">(message)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.message </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> message</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.error_code </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> error_code</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.recoverable </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> recoverable</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.timestamp </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> CorruptionError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">GitError</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Raised when repository corruption is detected.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, component: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, details: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, corruption_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        message </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"Corruption detected in </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">component</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">details</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">(message, </span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"CORRUPT_</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">corruption_type</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">recoverable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.component </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> component</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.corruption_type </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> corruption_type</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.details </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> details</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> MergeConflictError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">GitError</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Raised when merge conflicts require manual resolution.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, conflicted_files: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">], conflict_count: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        message </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"Merge conflicts in </span><span style=\"color:#79B8FF\">{len</span><span style=\"color:#E1E4E8\">(conflicted_files)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> files (</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">conflict_count</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> regions)\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">(message, </span><span style=\"color:#9ECBFF\">\"MERGE_CONFLICT\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">recoverable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.conflicted_files </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> conflicted_files</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.conflict_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> conflict_count</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ConcurrencyError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">GitError</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Raised when concurrent access prevents operation completion.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, resource: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, operation: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, retry_possible: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        message </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"Concurrent access conflict on </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">resource</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> during </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">operation</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">(message, </span><span style=\"color:#9ECBFF\">\"CONCURRENCY_CONFLICT\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">recoverable</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">retry_possible)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.resource </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> resource</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.operation </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> operation</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.retry_possible </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> retry_possible</span></span></code></pre></div>\n\n<p><strong>File Lock Manager:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Cross-platform file locking for safe concurrent repository access.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> os</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> fcntl</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> contextlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> contextmanager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> FileLock</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Advisory file lock for coordinating repository access.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, lock_path: Path, timeout: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 30.0</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.lock_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> lock_path</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.timeout </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> timeout</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.lock_fd: Optional[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.acquired </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> acquire</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Acquire the lock, waiting up to timeout seconds.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        start_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        while</span><span style=\"color:#E1E4E8\"> time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.timeout:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # Create lock file exclusively</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">.lock_fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> os.open(</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                    self</span><span style=\"color:#E1E4E8\">.lock_path, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    os.</span><span style=\"color:#79B8FF\">O_CREAT</span><span style=\"color:#F97583\"> |</span><span style=\"color:#E1E4E8\"> os.</span><span style=\"color:#79B8FF\">O_EXCL</span><span style=\"color:#F97583\"> |</span><span style=\"color:#E1E4E8\"> os.</span><span style=\"color:#79B8FF\">O_WRONLY</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    0o</span><span style=\"color:#79B8FF\">644</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # Write lock metadata</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                lock_info </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"pid=</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">os.getpid()</span><span style=\"color:#79B8FF\">}\\n</span><span style=\"color:#9ECBFF\">time=</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">time.time()</span><span style=\"color:#79B8FF\">}\\n</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                os.write(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.lock_fd, lock_info.encode())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                os.fsync(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.lock_fd)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">.acquired </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            except</span><span style=\"color:#79B8FF\"> OSError</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> e.errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> errno.</span><span style=\"color:#79B8FF\">EEXIST</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                    # Lock file exists, check if it's orphaned</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._check_orphaned_lock():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                        continue</span><span style=\"color:#6A737D\">  # Try again after cleanup</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    time.sleep(</span><span style=\"color:#79B8FF\">0.1</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Wait briefly before retry</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    raise</span><span style=\"color:#E1E4E8\"> ConcurrencyError(</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.lock_path), </span><span style=\"color:#9ECBFF\">\"lock_acquire\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> release</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Release the lock if currently held.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.acquired </span><span style=\"color:#F97583\">and</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.lock_fd </span><span style=\"color:#F97583\">is</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            os.close(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.lock_fd)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.lock_path.unlink(</span><span style=\"color:#FFAB70\">missing_ok</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.acquired </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.lock_fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@contextmanager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> repository_lock</span><span style=\"color:#E1E4E8\">(git_dir: Path, operation: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Context manager for repository-wide locking.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    lock_file </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">operation</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">.lock\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> FileLock(lock_file)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> lock.acquire():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#E1E4E8\"> ConcurrencyError(</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(lock_file), operation)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        yield</span><span style=\"color:#E1E4E8\"> lock</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    finally</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        lock.release()</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeletons\">Core Logic Skeletons</h4>\n<p><strong>Repository Validation Framework:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> validate_repository_state</span><span style=\"color:#E1E4E8\">(git_dir: Path) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Comprehensive repository validation returning list of issues found.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        List of validation error messages, empty if repository is valid</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    errors </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate basic directory structure exists and has correct permissions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Check: .git directory, objects/, refs/, refs/heads/, refs/tags/</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Verify: Directory permissions are 0755, accessible to current user</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Validate HEAD file exists and contains valid reference</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Check: HEAD file exists and is readable</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Verify: Content is either valid SHA-1 or symbolic reference format</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Validate object store integrity</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Scan: All objects in .git/objects directory structure</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Verify: Each object file can be read, decompressed, and SHA-1 verified</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Validate reference consistency</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Check: All reference files contain valid SHA-1 hashes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Verify: Referenced commits exist in object store</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Validate index file if present</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Check: Index file format and checksum</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Verify: All referenced objects exist</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> errors</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> recover_corrupted_object</span><span style=\"color:#E1E4E8\">(object_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, object_store, working_dir: Path) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Attempt to recover a corrupted object from alternative sources.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        True if recovery succeeded, False otherwise</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Try re-reading object from disk (handle transient I/O errors)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Use: Multiple read attempts with delays between attempts</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: For blob objects, attempt rebuild from working directory</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Check: If file exists in working directory with matching path</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Verify: Recompute hash and store if it matches expected hash</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Check if object exists in index for recent staging</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Load: Current index entries</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Match: Object hash to staged files for potential recovery</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Log recovery attempt results for debugging</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Record: What recovery methods were tried and their outcomes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> False</span></span></code></pre></div>\n\n<p><strong>Merge Conflict Resolution:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> resolve_merge_conflicts</span><span style=\"color:#E1E4E8\">(conflicted_files: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">], merge_info: Dict) -> WorkflowResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Interactive merge conflict resolution workflow.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        conflicted_files: List of files containing merge conflicts</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        merge_info: Information about the merge operation (branches, commits)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        WorkflowResult indicating resolution status and remaining conflicts</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    resolved_files </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    remaining_conflicts </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Present conflict summary to user</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Display: Number of conflicts, affected files, conflict types</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Offer: Resolution options (interactive, tool-based, manual)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: For each conflicted file, detect conflict markers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Scan: File content for &#x3C;&#x3C;&#x3C;&#x3C;&#x3C;&#x3C;&#x3C; ======= >>>>>>> patterns</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Parse: Conflict regions and extract ours/theirs/base content</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Offer resolution strategies for each conflict</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Options: Keep ours, keep theirs, manual edit, launch merge tool</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Validate: Ensure all conflict markers are removed after resolution</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Track resolution progress and allow resumption</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Save: Resolution state to allow interruption and continuation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Update: MERGE_PROGRESS file with completed resolutions</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Validate complete resolution before allowing merge completion</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Check: No remaining conflict markers in any resolved files</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Verify: All conflicted files have been addressed</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> WorkflowResult(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        status</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">WorkflowStatus.</span><span style=\"color:#79B8FF\">SUCCESS</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        message</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"All conflicts resolved\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        files_changed</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">len</span><span style=\"color:#E1E4E8\">(resolved_files),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        conflicts</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">remaining_conflicts</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    )</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> generate_conflict_markers</span><span style=\"color:#E1E4E8\">(conflict: ConflictRegion, our_branch: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, their_branch: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Generate standard Git conflict markers for a conflict region.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Formatted conflict markers with content from both sides</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Format opening marker with our branch identifier</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Format: \"&#x3C;&#x3C;&#x3C;&#x3C;&#x3C;&#x3C;&#x3C; {our_branch}\" or \"&#x3C;&#x3C;&#x3C;&#x3C;&#x3C;&#x3C;&#x3C; HEAD\" for detached state</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Add our content with proper line endings</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Include: All lines from our version of the conflict region</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Add separator marker</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Insert: \"=======\" line to separate our content from theirs</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Add their content with branch identifier</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Include: All lines from their version</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Format: \">>>>>>> {their_branch}\" closing marker</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Optionally include base content for three-way conflicts</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Insert: \"||||||| merged common ancestors\" section if base differs</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#9ECBFF\"> \"\"</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p><strong>After implementing corruption detection:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test repository validation</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> git_impl.validation.repository</span><span style=\"color:#9ECBFF\"> /path/to/repo</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected output: List of validation results</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Should detect: Missing directories, corrupted objects, invalid references</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Should report: Specific error locations and types</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test object corruption recovery</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#9ECBFF\"> \"test content\"</span><span style=\"color:#F97583\"> ></span><span style=\"color:#9ECBFF\"> test.txt</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> git_impl</span><span style=\"color:#9ECBFF\"> add</span><span style=\"color:#9ECBFF\"> test.txt</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Manually corrupt the blob object file</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> git_impl.recovery.corruption</span><span style=\"color:#79B8FF\"> --scan</span><span style=\"color:#79B8FF\"> --fix</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected behavior: Detection of corrupted object, attempt recovery from working tree</span></span></code></pre></div>\n\n<p><strong>After implementing merge conflict resolution:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Create merge conflict scenario</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">git</span><span style=\"color:#9ECBFF\"> checkout</span><span style=\"color:#79B8FF\"> -b</span><span style=\"color:#9ECBFF\"> feature</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#9ECBFF\"> \"feature change\"</span><span style=\"color:#F97583\"> >></span><span style=\"color:#9ECBFF\"> file.txt</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">git</span><span style=\"color:#9ECBFF\"> add</span><span style=\"color:#9ECBFF\"> file.txt</span><span style=\"color:#E1E4E8\"> &#x26;&#x26; </span><span style=\"color:#B392F0\">git</span><span style=\"color:#9ECBFF\"> commit</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> \"feature\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">git</span><span style=\"color:#9ECBFF\"> checkout</span><span style=\"color:#9ECBFF\"> main</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#9ECBFF\"> \"main change\"</span><span style=\"color:#F97583\"> >></span><span style=\"color:#9ECBFF\"> file.txt</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">git</span><span style=\"color:#9ECBFF\"> add</span><span style=\"color:#9ECBFF\"> file.txt</span><span style=\"color:#E1E4E8\"> &#x26;&#x26; </span><span style=\"color:#B392F0\">git</span><span style=\"color:#9ECBFF\"> commit</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> \"main\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> git_impl.merge</span><span style=\"color:#9ECBFF\"> feature</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected output: Conflict detection, interactive resolution prompt</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Should create: Conflict markers in file.txt</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Should provide: Resolution options and validation</span></span></code></pre></div>\n\n<h4 id=\"debugging-tips\">Debugging Tips</h4>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>Diagnosis</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>&quot;Object not found&quot; errors</td>\n<td>Corrupted object store</td>\n<td>Check .git/objects structure</td>\n<td>Run repository validation</td>\n</tr>\n<tr>\n<td>Merge hangs indefinitely</td>\n<td>Deadlock in file locking</td>\n<td>Check for orphaned lock files</td>\n<td>Remove old .lock files</td>\n</tr>\n<tr>\n<td>&quot;Repository corrupt&quot; on startup</td>\n<td>Interrupted operation</td>\n<td>Check for partial state files</td>\n<td>Run corruption recovery</td>\n</tr>\n<tr>\n<td>Conflicts not detected properly</td>\n<td>Three-way merge base error</td>\n<td>Verify merge base calculation</td>\n<td>Check commit history integrity</td>\n</tr>\n<tr>\n<td>Lock timeout errors</td>\n<td>High concurrent access</td>\n<td>Monitor lock file creation/deletion</td>\n<td>Increase timeout or serialize operations</td>\n</tr>\n<tr>\n<td>Index corruption after crash</td>\n<td>Non-atomic index write</td>\n<td>Check index file permissions and size</td>\n<td>Rebuild index from working tree</td>\n</tr>\n</tbody></table>\n<h2 id=\"testing-strategy-and-milestone-checkpoints\">Testing Strategy and Milestone Checkpoints</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section provides comprehensive testing approaches for all eight milestones, with specific verification steps for each milestone and integration testing strategies to ensure compatibility with real Git.</p>\n</blockquote>\n<h3 id=\"mental-model-the-quality-assurance-laboratory\">Mental Model: The Quality Assurance Laboratory</h3>\n<p>Think of testing your Git implementation like running a quality assurance laboratory for a manufacturing process. Each milestone represents a critical component that must pass rigorous inspection before moving to the next stage. Just as a car manufacturer tests each subsystem (engine, brakes, transmission) individually before assembling the complete vehicle, we must verify each Git component works correctly in isolation before testing the integrated system.</p>\n<p>The testing laboratory has multiple inspection stations. <strong>Unit testing</strong> is like checking individual parts under a microscope - ensuring each bolt meets specifications. <strong>Integration testing</strong> is like testing how parts work together - does the engine properly connect to the transmission? <strong>Compatibility testing</strong> is like verifying your car can drive on the same roads as other vehicles - does your Git produce the same results as the official Git implementation?</p>\n<p>The most crucial aspect of this testing laboratory is the <strong>golden standard comparison</strong>. Just as manufacturers compare their products against industry standards, we compare our Git implementation against the official Git behavior. Every hash, every file format, every command output must match exactly. This isn&#39;t just about correctness - it&#39;s about ensuring users can seamlessly switch between your implementation and official Git without any surprises.</p>\n<h3 id=\"milestone-verification-steps\">Milestone Verification Steps</h3>\n<p>Each milestone builds upon previous ones, creating a dependency chain that requires careful validation. The verification approach uses both <strong>black-box testing</strong> (testing external behavior) and <strong>white-box testing</strong> (verifying internal state). The key insight is that Git&#39;s deterministic nature means identical inputs should always produce identical outputs, making automated verification straightforward.</p>\n<h4 id=\"milestone-1-repository-initialization-verification\">Milestone 1: Repository Initialization Verification</h4>\n<p>Repository initialization is the foundation - if the directory structure is incorrect, all subsequent operations will fail mysteriously. The verification process must check both the presence and exact contents of each required file and directory.</p>\n<table>\n<thead>\n<tr>\n<th>Verification Step</th>\n<th>Command</th>\n<th>Expected Result</th>\n<th>Validation Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Directory Structure Creation</td>\n<td><code>ls -la .git/</code></td>\n<td>Shows objects/, refs/, HEAD with correct permissions</td>\n<td>Directory existence and permissions check</td>\n</tr>\n<tr>\n<td>Objects Directory Layout</td>\n<td><code>ls -la .git/objects/</code></td>\n<td>Empty directory with proper subdirectory structure</td>\n<td>Subdirectory count and permissions</td>\n</tr>\n<tr>\n<td>References Directory</td>\n<td><code>ls -la .git/refs/</code></td>\n<td>Contains heads/ and tags/ subdirectories</td>\n<td>Directory structure validation</td>\n</tr>\n<tr>\n<td>HEAD File Content</td>\n<td><code>cat .git/HEAD</code></td>\n<td>Exactly &quot;ref: refs/heads/master\\n&quot;</td>\n<td>String comparison with newline</td>\n</tr>\n<tr>\n<td>Git Recognition</td>\n<td><code>git status</code> (using official Git)</td>\n<td>Recognizes as valid Git repository</td>\n<td>Official Git compatibility test</td>\n</tr>\n</tbody></table>\n<p>The most critical validation is ensuring the HEAD file contains the exact string format. Many implementations fail because they forget the newline character or use incorrect reference syntax.</p>\n<p><strong>Detailed Verification Procedure:</strong></p>\n<ol>\n<li><p><strong>Structure Validation</strong>: Use <code>find .git -type d</code> to list all directories and compare against the expected structure. The output should include <code>.git/objects/</code>, <code>.git/refs/</code>, <code>.git/refs/heads/</code>, <code>.git/refs/tags/</code>, and <code>.git/hooks/</code>.</p>\n</li>\n<li><p><strong>Permissions Check</strong>: Verify directory permissions using <code>stat -c &#39;%a&#39; .git/</code> - should return <code>755</code> for proper read/write/execute permissions.</p>\n</li>\n<li><p><strong>HEAD Content Validation</strong>: Read the HEAD file byte-by-byte and compare against the expected content. The file must contain exactly 21 bytes: &quot;ref: refs/heads/master&quot; followed by a newline character (0x0A).</p>\n</li>\n<li><p><strong>Official Git Compatibility</strong>: Run <code>git rev-parse --git-dir</code> using official Git - it should return <code>.git</code> without errors, confirming the repository structure is valid.</p>\n</li>\n<li><p><strong>Empty Repository State</strong>: Verify <code>git log</code> returns &quot;fatal: your current branch &#39;master&#39; does not have any commits yet&quot; - this confirms the repository is properly initialized but empty.</p>\n</li>\n</ol>\n<h4 id=\"milestone-2-object-storage-blobs-verification\">Milestone 2: Object Storage (Blobs) Verification</h4>\n<p>Blob storage is the foundation of Git&#39;s content-addressable system. Every aspect must match official Git exactly - hash computation, compression, file paths, and retrieval. The verification process focuses on round-trip consistency and hash determinism.</p>\n<table>\n<thead>\n<tr>\n<th>Verification Step</th>\n<th>Test Input</th>\n<th>Expected Hash</th>\n<th>Validation Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Empty File Hash</td>\n<td><code>&quot;&quot;</code> (empty string)</td>\n<td><code>e69de29bb2d1d6434b8b29ae775ad8c2e48c5391</code></td>\n<td>Hash comparison with official Git</td>\n</tr>\n<tr>\n<td>Simple Text Hash</td>\n<td><code>&quot;hello world&quot;</code></td>\n<td><code>95d09f2b10159347eece71399a7e2e907ea3df4f</code></td>\n<td>Hash comparison with official Git</td>\n</tr>\n<tr>\n<td>Binary Content Hash</td>\n<td>Random 1KB binary data</td>\n<td>Must match <code>git hash-object</code> output</td>\n<td>Binary content handling test</td>\n</tr>\n<tr>\n<td>Large File Hash</td>\n<td>10MB text file</td>\n<td>Must match official Git hash</td>\n<td>Performance and correctness test</td>\n</tr>\n<tr>\n<td>Round-trip Consistency</td>\n<td>Any content</td>\n<td><code>cat-file</code> output matches original input</td>\n<td>Storage and retrieval verification</td>\n</tr>\n</tbody></table>\n<p>The hash computation must implement the exact Git algorithm: <code>SHA1(&quot;blob &quot; + content_length + &quot;\\0&quot; + content)</code>. Many implementations fail by forgetting the space after &quot;blob&quot; or using incorrect size formatting.</p>\n<p><strong>Detailed Verification Procedure:</strong></p>\n<ol>\n<li><p><strong>Hash Algorithm Verification</strong>: Create a test file with known content and verify your hash matches official Git exactly. Use <code>echo -n &quot;test content&quot; | git hash-object --stdin</code> as the reference.</p>\n</li>\n<li><p><strong>File Path Generation</strong>: Verify your implementation creates the correct object path. For hash <code>abc123...</code>, the file should be stored at <code>.git/objects/ab/c123...</code> with the first two characters forming the directory name.</p>\n</li>\n<li><p><strong>Compression Verification</strong>: Decompress stored objects manually using Python&#39;s zlib and verify the content matches the expected format: <code>blob {size}\\0{content}</code>.</p>\n</li>\n<li><p><strong>Binary Content Handling</strong>: Test with files containing null bytes, non-UTF8 content, and various binary formats. Git treats all content as binary internally.</p>\n</li>\n<li><p><strong>Performance Baseline</strong>: Measure hash computation and storage time for various file sizes. Your implementation should handle files up to several megabytes without excessive memory usage.</p>\n</li>\n</ol>\n<p><strong>Cross-Implementation Testing</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Create test file</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#9ECBFF\"> \"test content\"</span><span style=\"color:#F97583\"> ></span><span style=\"color:#9ECBFF\"> test.txt</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Hash with your implementation</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">./your-git</span><span style=\"color:#9ECBFF\"> hash-object</span><span style=\"color:#9ECBFF\"> test.txt</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Hash with official Git</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">git</span><span style=\"color:#9ECBFF\"> hash-object</span><span style=\"color:#9ECBFF\"> test.txt</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Both should produce identical output</span></span></code></pre></div>\n\n<h4 id=\"milestone-3-tree-objects-verification\">Milestone 3: Tree Objects Verification</h4>\n<p>Tree objects represent directory structures and must maintain exact sorting and binary format compatibility with official Git. The verification focuses on directory traversal, entry sorting, and nested tree creation.</p>\n<table>\n<thead>\n<tr>\n<th>Verification Step</th>\n<th>Test Scenario</th>\n<th>Expected Behavior</th>\n<th>Validation Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Single File Tree</td>\n<td>Directory with one file</td>\n<td>Tree with single blob entry</td>\n<td>Tree content comparison</td>\n</tr>\n<tr>\n<td>Sorted Entries</td>\n<td>Files: z.txt, a.txt, m.txt</td>\n<td>Tree entries sorted alphabetically</td>\n<td>Entry order verification</td>\n</tr>\n<tr>\n<td>Nested Directories</td>\n<td>Subdirectory with files</td>\n<td>Parent tree references child tree</td>\n<td>Tree hierarchy validation</td>\n</tr>\n<tr>\n<td>Mixed Content Types</td>\n<td>Files and subdirectories</td>\n<td>Correct mode values (100644, 040000)</td>\n<td>Mode field verification</td>\n</tr>\n<tr>\n<td>Empty Directory Handling</td>\n<td>Empty subdirectory</td>\n<td>Directory not included in tree</td>\n<td>Git&#39;s empty directory behavior</td>\n</tr>\n</tbody></table>\n<p>Tree objects use a specific binary format where each entry is: <code>{mode} {name}\\0{20-byte-hash}</code>. The mode values are crucial - regular files use <code>100644</code>, executable files use <code>100755</code>, and directories use <code>040000</code>.</p>\n<p><strong>Detailed Verification Procedure:</strong></p>\n<ol>\n<li><p><strong>Entry Sorting Verification</strong>: Create a directory with files named in non-alphabetical order. Verify your tree object lists entries in exact alphabetical order, matching <code>git ls-tree</code> output.</p>\n</li>\n<li><p><strong>Binary Format Validation</strong>: Extract a tree object and verify the binary format byte-by-byte. Each entry should be null-terminated, followed by exactly 20 bytes of binary hash data.</p>\n</li>\n<li><p><strong>Mode Value Accuracy</strong>: Test files with different permissions and verify the mode values match Git&#39;s behavior. Use <code>git ls-tree -l</code> to see detailed mode information.</p>\n</li>\n<li><p><strong>Nested Tree Verification</strong>: Create a directory structure with subdirectories and verify your implementation creates the correct tree hierarchy. Each subdirectory should become a separate tree object referenced by its parent.</p>\n</li>\n<li><p><strong>Hash Consistency</strong>: Build the same directory structure twice and verify identical tree hashes are produced. Tree building must be deterministic.</p>\n</li>\n</ol>\n<h4 id=\"milestone-4-commit-objects-verification\">Milestone 4: Commit Objects Verification</h4>\n<p>Commit objects tie together trees, parents, and metadata to form Git&#39;s history graph. Verification must ensure exact format compatibility and proper parent linking.</p>\n<table>\n<thead>\n<tr>\n<th>Verification Step</th>\n<th>Test Case</th>\n<th>Expected Format</th>\n<th>Validation Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Initial Commit</td>\n<td>Commit with no parents</td>\n<td>No parent field in commit object</td>\n<td>Commit format verification</td>\n</tr>\n<tr>\n<td>Parent Linking</td>\n<td>Commit with one parent</td>\n<td>Single parent line with hash</td>\n<td>Parent reference validation</td>\n</tr>\n<tr>\n<td>Merge Commit</td>\n<td>Commit with two parents</td>\n<td>Multiple parent lines</td>\n<td>Multi-parent commit handling</td>\n</tr>\n<tr>\n<td>Author/Committer Data</td>\n<td>Different author and committer</td>\n<td>Separate author/committer lines with timestamps</td>\n<td>Metadata format verification</td>\n</tr>\n<tr>\n<td>Message Handling</td>\n<td>Multi-line commit message</td>\n<td>Message separated by blank line</td>\n<td>Message format validation</td>\n</tr>\n</tbody></table>\n<p>Commit objects follow a strict text format with specific field ordering and timestamp formatting. The timestamp format is Unix epoch seconds followed by timezone offset (e.g., <code>1609459200 +0000</code>).</p>\n<p><strong>Detailed Verification Procedure:</strong></p>\n<ol>\n<li><p><strong>Commit Format Validation</strong>: Create commits and verify the object format matches <code>git cat-file commit &lt;hash&gt;</code> exactly. Field order is: tree, parent(s), author, committer, blank line, message.</p>\n</li>\n<li><p><strong>Timestamp Format</strong>: Verify timestamps use Unix epoch format with timezone. Compare your output with <code>git log --format=fuller</code> to ensure exact match.</p>\n</li>\n<li><p><strong>Parent Chain Verification</strong>: Create multiple commits and verify the parent relationships form a proper chain. Each commit should reference its predecessor correctly.</p>\n</li>\n<li><p><strong>Character Encoding</strong>: Test commits with non-ASCII characters in messages and author names. Git uses UTF-8 encoding internally.</p>\n</li>\n<li><p><strong>Empty Message Handling</strong>: Test commits with empty messages and verify they&#39;re handled correctly (Git allows empty messages).</p>\n</li>\n</ol>\n<h4 id=\"milestone-5-references-and-branches-verification\">Milestone 5: References and Branches Verification</h4>\n<p>References provide human-readable names for commits and must handle both symbolic and direct references correctly. The verification focuses on file-based storage and HEAD state management.</p>\n<table>\n<thead>\n<tr>\n<th>Verification Step</th>\n<th>Test Operation</th>\n<th>Expected Outcome</th>\n<th>Validation Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Branch Creation</td>\n<td>Create branch &quot;feature&quot;</td>\n<td>File <code>.git/refs/heads/feature</code> contains commit hash</td>\n<td>File content verification</td>\n</tr>\n<tr>\n<td>HEAD Update</td>\n<td>Switch to branch</td>\n<td>HEAD contains <code>ref: refs/heads/feature</code></td>\n<td>Symbolic reference validation</td>\n</tr>\n<tr>\n<td>Detached HEAD</td>\n<td>Checkout specific commit</td>\n<td>HEAD contains raw commit hash</td>\n<td>Direct reference handling</td>\n</tr>\n<tr>\n<td>Branch Deletion</td>\n<td>Delete branch</td>\n<td>Reference file removed</td>\n<td>File system state check</td>\n</tr>\n<tr>\n<td>Invalid Names</td>\n<td>Create branch with invalid characters</td>\n<td>Operation fails with clear error</td>\n<td>Error handling validation</td>\n</tr>\n</tbody></table>\n<p>Reference files are plain text containing either a commit hash (direct reference) or a symbolic reference in the format <code>ref: refs/heads/branch-name</code>.</p>\n<p><strong>Detailed Verification Procedure:</strong></p>\n<ol>\n<li><p><strong>Reference File Format</strong>: Create branches and verify the reference files contain exactly 41 characters - 40 hex digits for the hash plus a newline character.</p>\n</li>\n<li><p><strong>Symbolic Reference Handling</strong>: Switch branches and verify HEAD is updated to point to the correct branch reference, not the commit hash directly.</p>\n</li>\n<li><p><strong>Detached HEAD State</strong>: Checkout a specific commit and verify HEAD contains the raw hash. Test that subsequent commits update HEAD directly rather than through a branch.</p>\n</li>\n<li><p><strong>Branch Namespace</strong>: Test branch names with slashes (e.g., <code>feature/login</code>) and verify the directory structure is created correctly under <code>.git/refs/heads/</code>.</p>\n</li>\n<li><p><strong>Concurrent Access</strong>: Test rapid branch creation/deletion to ensure file operations are atomic and don&#39;t leave partially written files.</p>\n</li>\n</ol>\n<h4 id=\"milestone-6-index-staging-area-verification\">Milestone 6: Index (Staging Area) Verification</h4>\n<p>The index is Git&#39;s most complex binary format, requiring exact compatibility for field layouts, checksums, and metadata handling. Verification must cover all aspects of the binary format specification.</p>\n<table>\n<thead>\n<tr>\n<th>Verification Step</th>\n<th>Test Scenario</th>\n<th>Expected Behavior</th>\n<th>Validation Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>File Staging</td>\n<td>Add single file</td>\n<td>Index entry with correct metadata</td>\n<td>Binary format parsing</td>\n</tr>\n<tr>\n<td>Multiple Files</td>\n<td>Stage several files</td>\n<td>Entries sorted by path</td>\n<td>Entry ordering validation</td>\n</tr>\n<tr>\n<td>File Modification</td>\n<td>Modify staged file</td>\n<td>Status shows modified state</td>\n<td>Three-way comparison accuracy</td>\n</tr>\n<tr>\n<td>Index Checksum</td>\n<td>Any index operation</td>\n<td>Valid SHA-1 checksum at file end</td>\n<td>Checksum verification</td>\n</tr>\n<tr>\n<td>Metadata Accuracy</td>\n<td>Stage file with specific timestamps</td>\n<td>Index preserves exact metadata</td>\n<td>Metadata comparison</td>\n</tr>\n</tbody></table>\n<p>The index binary format includes a 12-byte header, variable-length entries, and a 20-byte SHA-1 checksum. Each entry contains extensive file metadata for change detection.</p>\n<p><strong>Detailed Verification Procedure:</strong></p>\n<ol>\n<li><p><strong>Binary Format Compliance</strong>: Parse index files created by official Git and verify your implementation can read them correctly. Also verify official Git can read your index files.</p>\n</li>\n<li><p><strong>Checksum Validation</strong>: Verify the SHA-1 checksum at the end of index files. Any corruption should be detected when loading the index.</p>\n</li>\n<li><p><strong>Metadata Preservation</strong>: Stage files and verify all metadata (timestamps, file size, permissions, device/inode numbers) is stored and retrieved accurately.</p>\n</li>\n<li><p><strong>Path Sorting</strong>: Stage files with various path names and verify they&#39;re stored in correct sort order. The sorting algorithm affects index format compatibility.</p>\n</li>\n<li><p><strong>Partial Updates</strong>: Test staging individual files multiple times and verify the index is updated correctly without corrupting other entries.</p>\n</li>\n</ol>\n<h4 id=\"milestone-7-diff-algorithm-verification\">Milestone 7: Diff Algorithm Verification</h4>\n<p>The Myers diff algorithm must produce output that matches Git&#39;s diff format exactly, including context lines, hunk headers, and binary file detection.</p>\n<table>\n<thead>\n<tr>\n<th>Verification Step</th>\n<th>Test Case</th>\n<th>Expected Output</th>\n<th>Validation Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Simple Addition</td>\n<td>Add lines to file</td>\n<td>Unified diff with + markers</td>\n<td>Output format comparison</td>\n</tr>\n<tr>\n<td>Line Deletion</td>\n<td>Remove lines from file</td>\n<td>Unified diff with - markers</td>\n<td>Deletion marking accuracy</td>\n</tr>\n<tr>\n<td>Line Modification</td>\n<td>Change existing lines</td>\n<td>Shows as deletion + addition</td>\n<td>Edit sequence accuracy</td>\n</tr>\n<tr>\n<td>Context Lines</td>\n<td>Large file changes</td>\n<td>Correct @@ hunk headers with line numbers</td>\n<td>Hunk formatting validation</td>\n</tr>\n<tr>\n<td>Binary Files</td>\n<td>Binary file changes</td>\n<td>&quot;Binary files differ&quot; message</td>\n<td>Binary detection accuracy</td>\n</tr>\n</tbody></table>\n<p>The unified diff format includes specific hunk headers with old and new line number ranges, plus context lines around changes.</p>\n<p><strong>Detailed Verification Procedure:</strong></p>\n<ol>\n<li><p><strong>Algorithm Correctness</strong>: Test the Myers algorithm against known inputs with verified shortest edit scripts. The algorithm must find optimal solutions.</p>\n</li>\n<li><p><strong>Unified Format Compliance</strong>: Compare your diff output with <code>git diff</code> for identical files. Header format, line prefixes, and hunk boundaries must match exactly.</p>\n</li>\n<li><p><strong>Binary Detection</strong>: Test various file types (images, executables, text with null bytes) and verify binary detection matches Git&#39;s heuristics.</p>\n</li>\n<li><p><strong>Large File Performance</strong>: Test diff performance with large files (thousands of lines) and verify the algorithm completes in reasonable time.</p>\n</li>\n<li><p><strong>Edge Cases</strong>: Test empty files, single-line files, files with only whitespace changes, and files with no final newline.</p>\n</li>\n</ol>\n<h4 id=\"milestone-8-three-way-merge-verification\">Milestone 8: Three-Way Merge Verification</h4>\n<p>Three-way merge is the most complex operation, requiring correct merge base calculation, conflict detection, and merge commit creation. Verification must cover all merge scenarios.</p>\n<table>\n<thead>\n<tr>\n<th>Verification Step</th>\n<th>Test Scenario</th>\n<th>Expected Result</th>\n<th>Validation Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Fast-Forward Merge</td>\n<td>One branch is ancestor of other</td>\n<td>Branch pointer update only</td>\n<td>Merge strategy detection</td>\n</tr>\n<tr>\n<td>Clean Merge</td>\n<td>Non-overlapping changes</td>\n<td>Automatic merge completion</td>\n<td>Conflict-free merging</td>\n</tr>\n<tr>\n<td>Content Conflict</td>\n<td>Overlapping line changes</td>\n<td>Conflict markers in file</td>\n<td>Conflict detection accuracy</td>\n</tr>\n<tr>\n<td>Merge Base Calculation</td>\n<td>Complex branch history</td>\n<td>Correct common ancestor</td>\n<td>Graph traversal validation</td>\n</tr>\n<tr>\n<td>Merge Commit Creation</td>\n<td>Successful merge</td>\n<td>Commit with two parents</td>\n<td>Multi-parent commit handling</td>\n</tr>\n</tbody></table>\n<p>The merge algorithm must handle various conflict types and produce standard conflict markers compatible with Git&#39;s format.</p>\n<p><strong>Detailed Verification Procedure:</strong></p>\n<ol>\n<li><p><strong>Merge Base Accuracy</strong>: Create complex branch histories and verify merge base calculation matches <code>git merge-base</code> output exactly.</p>\n</li>\n<li><p><strong>Conflict Marker Format</strong>: Create conflicting changes and verify conflict markers match Git&#39;s format exactly, including branch name labels.</p>\n</li>\n<li><p><strong>Three-Way Algorithm</strong>: Test merge scenarios where base, ours, and theirs all differ, ensuring the algorithm correctly identifies conflicting vs. non-conflicting regions.</p>\n</li>\n<li><p><strong>File-Level Conflicts</strong>: Test scenarios where files are added, deleted, or modified in conflicting ways across branches.</p>\n</li>\n<li><p><strong>Performance Testing</strong>: Test merge performance with large files and many conflicts to ensure the algorithm scales reasonably.</p>\n</li>\n</ol>\n<h3 id=\"integration-testing-approach\">Integration Testing Approach</h3>\n<p>Integration testing verifies that your Git implementation behaves identically to official Git across complete workflows. The approach uses <strong>comparative testing</strong> where every operation is performed with both implementations and results are compared.</p>\n<h4 id=\"golden-standard-testing-framework\">Golden Standard Testing Framework</h4>\n<p>The golden standard approach treats official Git as the authoritative reference. Every test scenario is executed with both your implementation and official Git, with results compared byte-for-byte where applicable.</p>\n<table>\n<thead>\n<tr>\n<th>Testing Layer</th>\n<th>Scope</th>\n<th>Comparison Method</th>\n<th>Failure Handling</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Object Compatibility</td>\n<td>Individual objects</td>\n<td>Hash and content comparison</td>\n<td>Object format debugging</td>\n</tr>\n<tr>\n<td>Repository State</td>\n<td>Complete repository state</td>\n<td>File system diff of .git directory</td>\n<td>State reconstruction analysis</td>\n</tr>\n<tr>\n<td>Command Output</td>\n<td>User-visible output</td>\n<td>String comparison with normalization</td>\n<td>Output format adjustment</td>\n</tr>\n<tr>\n<td>File Content</td>\n<td>Working directory files</td>\n<td>Byte-by-byte comparison</td>\n<td>Content merge verification</td>\n</tr>\n<tr>\n<td>Performance Baseline</td>\n<td>Operation timing</td>\n<td>Relative performance comparison</td>\n<td>Performance regression detection</td>\n</tr>\n</tbody></table>\n<p>The framework must handle <strong>environment differences</strong> that don&#39;t indicate implementation bugs. For example, timestamps will differ between test runs, so they must be normalized or ignored during comparison.</p>\n<h4 id=\"test-scenario-categories\">Test Scenario Categories</h4>\n<p><strong>Basic Workflow Testing</strong> covers the fundamental Git operations that users perform daily. These scenarios must work flawlessly as they form the foundation of version control workflows.</p>\n<ol>\n<li><p><strong>Repository Lifecycle</strong>: Initialize repository, add files, create commits, view history. This tests the basic object creation and storage pipeline.</p>\n</li>\n<li><p><strong>Branch Operations</strong>: Create branches, switch branches, merge branches. This tests the reference management and merge algorithms.</p>\n</li>\n<li><p><strong>Staging Operations</strong>: Stage files, unstage files, partial staging. This tests the index management and status calculation.</p>\n</li>\n<li><p><strong>History Navigation</strong>: Checkout previous commits, view diffs between versions. This tests object retrieval and diff algorithms.</p>\n</li>\n<li><p><strong>Merge Scenarios</strong>: Fast-forward merges, three-way merges, conflict resolution. This tests the most complex algorithms in your implementation.</p>\n</li>\n</ol>\n<p><strong>Edge Case Testing</strong> covers unusual but valid Git operations that might expose implementation bugs or missing functionality.</p>\n<table>\n<thead>\n<tr>\n<th>Edge Case Category</th>\n<th>Test Scenarios</th>\n<th>Common Failure Points</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Empty Content</td>\n<td>Empty files, empty directories, empty commits</td>\n<td>Null pointer handling, zero-length content</td>\n</tr>\n<tr>\n<td>Large Content</td>\n<td>Large files, many files, deep directory trees</td>\n<td>Memory usage, performance degradation</td>\n</tr>\n<tr>\n<td>Special Characters</td>\n<td>Unicode filenames, binary content, line endings</td>\n<td>Character encoding, binary detection</td>\n</tr>\n<tr>\n<td>Concurrent Operations</td>\n<td>Multiple processes modifying repository</td>\n<td>File locking, atomic operations</td>\n</tr>\n<tr>\n<td>Corrupted State</td>\n<td>Missing objects, invalid references, corrupted index</td>\n<td>Error detection, graceful degradation</td>\n</tr>\n</tbody></table>\n<p><strong>Cross-Platform Testing</strong> ensures your implementation works consistently across different operating systems and file systems.</p>\n<ul>\n<li><p><strong>File System Differences</strong>: Test on case-sensitive and case-insensitive file systems. Some Git operations behave differently based on file system capabilities.</p>\n</li>\n<li><p><strong>Path Separator Handling</strong>: Verify path normalization works correctly on Windows (backslashes) and Unix (forward slashes).</p>\n</li>\n<li><p><strong>Permission Model Differences</strong>: Test file permissions and executable bit handling across platforms where permission models differ.</p>\n</li>\n<li><p><strong>Line Ending Handling</strong>: Test files with different line ending conventions (LF, CRLF, mixed) to ensure consistent behavior.</p>\n</li>\n</ul>\n<h4 id=\"automated-compatibility-verification\">Automated Compatibility Verification</h4>\n<p>The compatibility verification system runs automated test suites that compare your implementation against official Git across hundreds of scenarios. The system must handle the inherent non-determinism in some Git operations (like timestamps) while catching genuine compatibility issues.</p>\n<p><strong>Test Data Generation</strong> creates comprehensive test scenarios programmatically rather than maintaining large test fixtures. This ensures broad coverage without overwhelming the test suite with data.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Test Repository Generator:\n1. Generate random file content with various characteristics\n2. Create random directory structures with different depths\n3. Simulate realistic commit histories with merges and branches\n4. Create conflict scenarios with overlapping changes\n5. Generate edge cases (empty files, binary content, special names)</code></pre></div>\n\n<p><strong>Result Comparison Engine</strong> handles the complex task of comparing Git repository states while accounting for acceptable differences.</p>\n<table>\n<thead>\n<tr>\n<th>Comparison Aspect</th>\n<th>Exact Match Required</th>\n<th>Acceptable Differences</th>\n<th>Normalization Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Object Hashes</td>\n<td>Yes</td>\n<td>None</td>\n<td>Direct string comparison</td>\n</tr>\n<tr>\n<td>Object Content</td>\n<td>Yes</td>\n<td>None</td>\n<td>Byte-by-byte comparison</td>\n</tr>\n<tr>\n<td>Reference Values</td>\n<td>Yes</td>\n<td>None</td>\n<td>Hash comparison</td>\n</tr>\n<tr>\n<td>File Timestamps</td>\n<td>No</td>\n<td>Any difference</td>\n<td>Ignore during comparison</td>\n</tr>\n<tr>\n<td>Commit Timestamps</td>\n<td>No</td>\n<td>Any difference</td>\n<td>Normalize to fixed value</td>\n</tr>\n<tr>\n<td>Author Information</td>\n<td>Yes</td>\n<td>None</td>\n<td>String comparison</td>\n</tr>\n<tr>\n<td>File Permissions</td>\n<td>Yes</td>\n<td>None</td>\n<td>Octal comparison</td>\n</tr>\n</tbody></table>\n<p><strong>Regression Testing</strong> maintains a suite of previously passing tests to ensure new changes don&#39;t break existing functionality. The regression suite includes both successful operations and expected failures.</p>\n<h4 id=\"performance-and-scalability-testing\">Performance and Scalability Testing</h4>\n<p>Performance testing ensures your Git implementation scales reasonably with repository size and complexity. While exact performance parity with official Git isn&#39;t required, your implementation should handle realistic workloads without excessive resource consumption.</p>\n<p><strong>Scalability Test Scenarios:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Scale Factor</th>\n<th>Repository Size</th>\n<th>File Count</th>\n<th>Commit History</th>\n<th>Expected Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Small</td>\n<td>&lt; 10MB</td>\n<td>&lt; 100 files</td>\n<td>&lt; 50 commits</td>\n<td>Sub-second operations</td>\n</tr>\n<tr>\n<td>Medium</td>\n<td>10-100MB</td>\n<td>100-1000 files</td>\n<td>50-500 commits</td>\n<td>Operations complete in seconds</td>\n</tr>\n<tr>\n<td>Large</td>\n<td>100MB-1GB</td>\n<td>1000-10000 files</td>\n<td>500-5000 commits</td>\n<td>Operations complete in minutes</td>\n</tr>\n<tr>\n<td>Stress Test</td>\n<td>&gt; 1GB</td>\n<td>&gt; 10000 files</td>\n<td>&gt; 5000 commits</td>\n<td>Graceful degradation, no crashes</td>\n</tr>\n</tbody></table>\n<p><strong>Memory Usage Monitoring</strong> ensures your implementation doesn&#39;t have memory leaks or excessive memory consumption during normal operations.</p>\n<p><strong>Performance Regression Detection</strong> compares operation timing across implementation versions to catch performance regressions early.</p>\n<h3 id=\"common-testing-pitfalls\">Common Testing Pitfalls</h3>\n<p>Understanding common testing mistakes helps avoid frustration and ensures your testing efforts are effective. These pitfalls are based on frequent issues encountered when building Git implementations.</p>\n<p>⚠️ <strong>Pitfall: Ignoring Byte-Level Compatibility</strong></p>\n<p>Many implementers focus on functional correctness while ignoring exact byte-level compatibility with Git&#39;s formats. This leads to repositories that work with your implementation but fail when accessed by official Git.</p>\n<p><strong>Why it&#39;s problematic</strong>: Git&#39;s binary formats (index file, pack files, object formats) have specific layouts that must be followed exactly. Even single-byte differences can cause incompatibility.</p>\n<p><strong>How to avoid</strong>: Always test round-trip compatibility - create objects with your implementation and verify official Git can read them, and vice versa. Use hex dumps to compare binary formats byte-by-byte when debugging.</p>\n<p>⚠️ <strong>Pitfall: Testing Only Happy Paths</strong></p>\n<p>Focusing testing on successful operations while ignoring error conditions and edge cases leads to implementations that fail unexpectedly in real-world usage.</p>\n<p><strong>Why it&#39;s problematic</strong>: Real Git repositories encounter corrupted files, network failures, concurrent access, and unusual content. Your implementation must handle these gracefully.</p>\n<p><strong>How to avoid</strong>: Dedicate significant testing effort to error conditions. Test with corrupted objects, missing files, invalid references, and concurrent operations. Verify error messages are helpful and recovery is possible.</p>\n<p>⚠️ <strong>Pitfall: Timestamp and Environment Dependencies</strong></p>\n<p>Writing tests that depend on specific timestamps, user information, or system configuration makes tests brittle and difficult to reproduce across different environments.</p>\n<p><strong>Why it&#39;s problematic</strong>: Tests fail randomly based on when they&#39;re run or what system they&#39;re run on, making it difficult to distinguish real bugs from environmental issues.</p>\n<p><strong>How to avoid</strong>: Use fixed timestamps and author information in tests. Normalize or ignore environment-specific data when comparing results. Use dependency injection to control environmental factors.</p>\n<p>⚠️ <strong>Pitfall: Insufficient Cross-Platform Testing</strong></p>\n<p>Testing only on one operating system misses compatibility issues that arise from file system differences, path handling, and permission models.</p>\n<p><strong>Why it&#39;s problematic</strong>: Git repositories are often shared across different operating systems. Incompatibilities can corrupt repositories or cause data loss.</p>\n<p><strong>How to avoid</strong>: Test on multiple platforms, especially Windows and Linux. Pay special attention to path separators, case sensitivity, and file permissions. Use continuous integration to automate cross-platform testing.</p>\n<p>⚠️ <strong>Pitfall: Missing Performance Reality Checks</strong></p>\n<p>Implementing algorithms without testing performance on realistic data sizes leads to implementations that work on small test cases but become unusable on real repositories.</p>\n<p><strong>Why it&#39;s problematic</strong>: Algorithms with poor complexity (like O(n²) diff algorithms) work fine on small test files but become unusably slow on large files or repositories.</p>\n<p><strong>How to avoid</strong>: Include performance tests with realistic data sizes in your test suite. Set reasonable performance expectations and fail tests that exceed them. Profile your implementation to identify bottlenecks.</p>\n<h3 id=\"integration-with-development-workflow\">Integration with Development Workflow</h3>\n<p>The testing strategy must integrate seamlessly with the development workflow to provide rapid feedback and prevent regressions. The approach uses multiple testing layers triggered at different points in the development process.</p>\n<p><strong>Pre-commit Testing</strong> runs quickly during development to catch obvious bugs before they&#39;re committed to version control.</p>\n<p><strong>Continuous Integration Testing</strong> runs comprehensive test suites on every code change, including cross-platform and performance testing.</p>\n<p><strong>Release Testing</strong> performs exhaustive compatibility testing before releasing new versions, including testing against multiple Git versions and large real-world repositories.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The testing implementation requires careful attention to automation, reliability, and maintainability. The goal is creating a testing framework that provides confidence in your Git implementation while being practical to maintain and extend.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Testing Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Test Framework</td>\n<td>pytest with subprocess calls</td>\n<td>Custom test harness with Git process management</td>\n</tr>\n<tr>\n<td>Repository Setup</td>\n<td>Manual git init in test directories</td>\n<td>Programmatic repository generation with GitPython</td>\n</tr>\n<tr>\n<td>Result Comparison</td>\n<td>String comparison with basic normalization</td>\n<td>AST-based parsing and semantic comparison</td>\n</tr>\n<tr>\n<td>Performance Testing</td>\n<td>Manual timing with time.time()</td>\n<td>pytest-benchmark with statistical analysis</td>\n</tr>\n<tr>\n<td>Cross-Platform Testing</td>\n<td>Manual testing on multiple systems</td>\n<td>GitHub Actions matrix builds</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-testing-file-structure\">Recommended Testing File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>build-your-own-git/\n├── tests/\n│   ├── unit/                    # Unit tests for individual components\n│   │   ├── test_object_store.py\n│   │   ├── test_index.py\n│   │   ├── test_references.py\n│   │   └── test_diff_algorithm.py\n│   ├── integration/             # Integration tests comparing with official Git\n│   │   ├── test_basic_workflow.py\n│   │   ├── test_branch_operations.py\n│   │   ├── test_merge_scenarios.py\n│   │   └── test_compatibility.py\n│   ├── milestone/               # Milestone-specific verification tests\n│   │   ├── test_milestone_1.py  # Repository initialization\n│   │   ├── test_milestone_2.py  # Blob storage\n│   │   └── ...\n│   ├── fixtures/                # Test data and repository templates\n│   │   ├── sample_repos/\n│   │   ├── binary_files/\n│   │   └── conflict_scenarios/\n│   └── utils/                   # Testing utilities and helpers\n│       ├── git_comparison.py    # Compare with official Git\n│       ├── repo_generator.py    # Generate test repositories\n│       └── binary_parser.py     # Parse Git binary formats\n├── src/\n│   └── your_git/               # Your Git implementation\n└── conftest.py                 # pytest configuration and fixtures</code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p><strong>Git Comparison Utility</strong> provides a complete framework for comparing your implementation with official Git:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">#!/usr/bin/env python3</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Git Comparison Utility - Complete implementation for comparing custom Git with official Git.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">This utility handles environment normalization and result comparison.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> os</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> subprocess</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> tempfile</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> shutil</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional, Tuple, Any</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> hashlib</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> GitComparison</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Utility for comparing custom Git implementation with official Git.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, custom_git_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, official_git_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"git\"</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.custom_git </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> custom_git_path</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.official_git </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> official_git_path</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.test_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.comparison_results </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> setup_test_environment</span><span style=\"color:#E1E4E8\">(self) -> Path:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Create isolated test directory with proper Git environment.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.test_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Path(tempfile.mkdtemp(</span><span style=\"color:#FFAB70\">prefix</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"git_test_\"</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Set consistent Git environment</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        os.environ.update({</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'GIT_AUTHOR_NAME'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'Test Author'</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'GIT_AUTHOR_EMAIL'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'test@example.com'</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'GIT_COMMITTER_NAME'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'Test Committer'</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'GIT_COMMITTER_EMAIL'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'test@example.com'</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'GIT_AUTHOR_DATE'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'2021-01-01T12:00:00Z'</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'GIT_COMMITTER_DATE'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'2021-01-01T12:00:00Z'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        })</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.test_dir</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> cleanup_test_environment</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Remove test directory and reset environment.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.test_dir </span><span style=\"color:#F97583\">and</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.test_dir.exists():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            shutil.rmtree(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.test_dir)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.test_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> run_command</span><span style=\"color:#E1E4E8\">(self, git_binary: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, args: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">], cwd: Path) -> Tuple[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Run Git command and return exit code, stdout, stderr.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            result </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> subprocess.run(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                [git_binary] </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> args,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                cwd</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">cwd,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                capture_output</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                text</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                timeout</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">30</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> result.returncode, result.stdout, result.stderr</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#E1E4E8\"> subprocess.TimeoutExpired:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"Command timed out\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Command failed: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> normalize_output</span><span style=\"color:#E1E4E8\">(self, output: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, operation: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Normalize output for comparison, handling acceptable differences.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        lines </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> output.strip().split(</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        normalized_lines </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> line </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> lines:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Remove timestamp variations for certain operations</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> operation </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> [</span><span style=\"color:#9ECBFF\">'log'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'show'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">and</span><span style=\"color:#9ECBFF\"> 'Date:'</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> line:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                continue</span><span style=\"color:#6A737D\">  # Skip timestamp lines</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Normalize path separators</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            line </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> line.replace(</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\\\</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'/'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Remove trailing whitespace</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            line </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> line.rstrip()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            normalized_lines.append(line)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> '</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">.join(normalized_lines)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> compare_repository_state</span><span style=\"color:#E1E4E8\">(self, repo_path: Path) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Compare complete repository state between implementations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        state_comparison </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'objects_match'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'refs_match'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'index_match'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'differences'</span><span style=\"color:#E1E4E8\">: []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        git_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> repo_path </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> '.git'</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> git_dir.exists():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            state_comparison[</span><span style=\"color:#9ECBFF\">'differences'</span><span style=\"color:#E1E4E8\">].append(</span><span style=\"color:#9ECBFF\">\"No .git directory found\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> state_comparison</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Compare object store</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        objects_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> 'objects'</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> objects_dir.exists():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            for</span><span style=\"color:#E1E4E8\"> obj_dir </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> objects_dir.iterdir():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> obj_dir.is_dir() </span><span style=\"color:#F97583\">and</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(obj_dir.name) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    for</span><span style=\"color:#E1E4E8\"> obj_file </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> obj_dir.iterdir():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        obj_hash </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> obj_dir.name </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> obj_file.name</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                        # Verify object can be read by both implementations</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        custom_result </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.run_command(</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                            self</span><span style=\"color:#E1E4E8\">.custom_git, [</span><span style=\"color:#9ECBFF\">'cat-file'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'-p'</span><span style=\"color:#E1E4E8\">, obj_hash], repo_path</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        official_result </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.run_command(</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                            self</span><span style=\"color:#E1E4E8\">.official_git, [</span><span style=\"color:#9ECBFF\">'cat-file'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'-p'</span><span style=\"color:#E1E4E8\">, obj_hash], repo_path</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                        if</span><span style=\"color:#E1E4E8\"> custom_result[</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> official_result[</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                            state_comparison[</span><span style=\"color:#9ECBFF\">'objects_match'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                            state_comparison[</span><span style=\"color:#9ECBFF\">'differences'</span><span style=\"color:#E1E4E8\">].append(</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                                f</span><span style=\"color:#9ECBFF\">\"Object </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">obj_hash</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> content differs\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                            )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> state_comparison</span></span></code></pre></div>\n\n<p><strong>Repository Generator</strong> creates test repositories programmatically:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">#!/usr/bin/env python3</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Repository Generator - Creates test repositories with various characteristics.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> os</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> random</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> string</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Dict, Any</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> tempfile</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TestRepositoryGenerator</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Generate Git repositories for testing various scenarios.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, base_dir: Path):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.base_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> base_dir</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.base_dir.mkdir(</span><span style=\"color:#FFAB70\">exist_ok</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> create_simple_repository</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Path:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Create a simple repository with a few commits.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        repo_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.base_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> name</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        repo_path.mkdir(</span><span style=\"color:#FFAB70\">exist_ok</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Initialize repository</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        os.system(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"cd </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">repo_path</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> &#x26;&#x26; git init\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Create initial commit</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        (repo_path </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"README.md\"</span><span style=\"color:#E1E4E8\">).write_text(</span><span style=\"color:#9ECBFF\">\"# Test Repository</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        os.system(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"cd </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">repo_path</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> &#x26;&#x26; git add README.md &#x26;&#x26; git commit -m 'Initial commit'\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Create second commit</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        (repo_path </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"file1.txt\"</span><span style=\"color:#E1E4E8\">).write_text(</span><span style=\"color:#9ECBFF\">\"Content of file 1</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        os.system(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"cd </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">repo_path</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> &#x26;&#x26; git add file1.txt &#x26;&#x26; git commit -m 'Add file1'\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> repo_path</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> create_merge_scenario</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Path:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Create repository with merge scenario for testing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        repo_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.base_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> name</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        repo_path.mkdir(</span><span style=\"color:#FFAB70\">exist_ok</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        os.system(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"cd </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">repo_path</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> &#x26;&#x26; git init\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Create main branch commits</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        (repo_path </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"main.txt\"</span><span style=\"color:#E1E4E8\">).write_text(</span><span style=\"color:#9ECBFF\">\"Main branch content</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        os.system(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"cd </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">repo_path</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> &#x26;&#x26; git add main.txt &#x26;&#x26; git commit -m 'Main commit'\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Create feature branch</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        os.system(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"cd </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">repo_path</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> &#x26;&#x26; git checkout -b feature\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        (repo_path </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"feature.txt\"</span><span style=\"color:#E1E4E8\">).write_text(</span><span style=\"color:#9ECBFF\">\"Feature branch content</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        os.system(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"cd </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">repo_path</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> &#x26;&#x26; git add feature.txt &#x26;&#x26; git commit -m 'Feature commit'\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Return to main and create conflicting change</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        os.system(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"cd </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">repo_path</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> &#x26;&#x26; git checkout main\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        (repo_path </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"main.txt\"</span><span style=\"color:#E1E4E8\">).write_text(</span><span style=\"color:#9ECBFF\">\"Modified main branch content</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        os.system(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"cd </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">repo_path</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> &#x26;&#x26; git add main.txt &#x26;&#x26; git commit -m 'Main modification'\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> repo_path</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> generate_random_content</span><span style=\"color:#E1E4E8\">(self, size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, binary: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> False</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate random content for testing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> binary:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> bytes</span><span style=\"color:#E1E4E8\">(random.randint(</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">255</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> _ </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(size))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            chars </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> string.ascii_letters </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> string.digits </span><span style=\"color:#F97583\">+</span><span style=\"color:#9ECBFF\"> '</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#79B8FF\"> \\t</span><span style=\"color:#9ECBFF\">'</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#9ECBFF\"> ''</span><span style=\"color:#E1E4E8\">.join(random.choice(chars) </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> _ </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(size)).encode(</span><span style=\"color:#9ECBFF\">'utf-8'</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeleton-code\">Core Logic Skeleton Code</h4>\n<p><strong>Milestone Verification Test Template</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">#!/usr/bin/env python3</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Milestone Verification Template - Complete test structure for milestone validation.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> pytest</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> tempfile</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> subprocess</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Dict, Any</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> MilestoneVerifier</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Base class for milestone verification tests.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, git_implementation_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.git_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_implementation_path</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.test_repo </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> setup_test_repo</span><span style=\"color:#E1E4E8\">(self) -> Path:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Create temporary test repository.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create temporary directory for test repository</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Set consistent Git environment variables (author, committer, dates)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return path to test repository</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> cleanup_test_repo</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Clean up temporary test repository.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Remove temporary directory if it exists</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Reset environment variables if needed</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> run_git_command</span><span style=\"color:#E1E4E8\">(self, args: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]) -> tuple[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Run Git command with your implementation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Build command line with git_path and args</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Execute command in test repository directory</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return (exit_code, stdout, stderr) tuple</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Handle timeout and other execution errors</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> verify_file_exists</span><span style=\"color:#E1E4E8\">(self, file_path: Path, expected_content: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Verify file exists and optionally check content.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if file exists at expected path</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: If expected_content provided, read file and compare</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return True if verification passes, False otherwise</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> compare_with_official_git</span><span style=\"color:#E1E4E8\">(self, command: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Compare command output with official Git.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Run command with your implementation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Run same command with official Git</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Normalize outputs (remove timestamps, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return True if outputs match, False otherwise</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> Milestone1Verifier</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">MilestoneVerifier</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Verify Milestone 1: Repository Initialization.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_git_init</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test repository initialization creates correct structure.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Run 'init' command in test directory</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Verify .git directory exists with correct permissions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify .git/objects directory exists with subdirectories</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Verify .git/refs/heads directory exists</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Verify HEAD file exists with correct content</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Test official Git recognizes repository as valid</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_directory_structure</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Verify complete .git directory structure.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Initialize repository</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check all required directories exist: objects, refs, refs/heads, refs/tags</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Check directory permissions are correct (0755)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Verify no extra files or directories are created</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_head_file_format</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Verify HEAD file has exact correct format.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Initialize repository</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Read HEAD file content as bytes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify content is exactly \"ref: refs/heads/master\\n\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Verify file has exactly 21 bytes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"language-specific-testing-hints\">Language-Specific Testing Hints</h4>\n<p><strong>Python Testing Environment</strong>:</p>\n<ul>\n<li>Use <code>pytest</code> as the test framework for its excellent fixtures and parametrization</li>\n<li>Use <code>subprocess.run()</code> with <code>capture_output=True</code> for running Git commands</li>\n<li>Use <code>tempfile.TemporaryDirectory()</code> for isolated test environments</li>\n<li>Use <code>pathlib.Path</code> for cross-platform path handling</li>\n<li>Set <code>PYTHONPATH</code> to include your Git implementation directory</li>\n</ul>\n<p><strong>Test Data Management</strong>:</p>\n<ul>\n<li>Store binary test data as base64 strings in test files to avoid Git corruption</li>\n<li>Use <code>pytest.mark.parametrize</code> to run the same test with multiple inputs</li>\n<li>Create reusable fixtures for common repository states</li>\n<li>Use <code>pytest-xdist</code> for parallel test execution to speed up large test suites</li>\n</ul>\n<p><strong>Cross-Platform Considerations</strong>:</p>\n<ul>\n<li>Use <code>os.name</code> and <code>platform.system()</code> to detect platform-specific behavior</li>\n<li>Normalize path separators using <code>pathlib</code> or <code>os.path.normpath()</code></li>\n<li>Handle case sensitivity differences in file system operations</li>\n<li>Test file permissions carefully on Windows where the model differs from Unix</li>\n</ul>\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p>After implementing each milestone, run these specific verification commands to ensure correctness:</p>\n<p><strong>Milestone 1 Checkpoint</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test repository initialization</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> your_git.py</span><span style=\"color:#9ECBFF\"> init</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">ls</span><span style=\"color:#79B8FF\"> -la</span><span style=\"color:#9ECBFF\"> .git/</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">cat</span><span style=\"color:#9ECBFF\"> .git/HEAD</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">git</span><span style=\"color:#9ECBFF\"> status</span><span style=\"color:#6A737D\">  # Using official Git to verify structure</span></span></code></pre></div>\n\n<p><strong>Milestone 2 Checkpoint</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test blob storage and retrieval</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#9ECBFF\"> \"test content\"</span><span style=\"color:#F97583\"> |</span><span style=\"color:#B392F0\"> python</span><span style=\"color:#9ECBFF\"> your_git.py</span><span style=\"color:#9ECBFF\"> hash-object</span><span style=\"color:#79B8FF\"> --stdin</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> your_git.py</span><span style=\"color:#9ECBFF\"> cat-file</span><span style=\"color:#9ECBFF\"> blob</span><span style=\"color:#F97583\"> &#x3C;</span><span style=\"color:#9ECBFF\">has</span><span style=\"color:#E1E4E8\">h</span><span style=\"color:#F97583\">></span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Compare hash with: echo \"test content\" | git hash-object --stdin</span></span></code></pre></div>\n\n<p><strong>Milestone 3 Checkpoint</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test tree object creation</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">mkdir</span><span style=\"color:#9ECBFF\"> testdir</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#9ECBFF\"> \"file content\"</span><span style=\"color:#F97583\"> ></span><span style=\"color:#9ECBFF\"> testdir/file.txt</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> your_git.py</span><span style=\"color:#9ECBFF\"> write-tree</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> your_git.py</span><span style=\"color:#9ECBFF\"> ls-tree</span><span style=\"color:#F97583\"> &#x3C;</span><span style=\"color:#9ECBFF\">tree-has</span><span style=\"color:#E1E4E8\">h</span><span style=\"color:#F97583\">></span></span></code></pre></div>\n\n<p><strong>Milestone 4 Checkpoint</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test commit creation</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> your_git.py</span><span style=\"color:#9ECBFF\"> commit-tree</span><span style=\"color:#F97583\"> &#x3C;</span><span style=\"color:#9ECBFF\">tree-has</span><span style=\"color:#E1E4E8\">h</span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> \"Test commit\"</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> your_git.py</span><span style=\"color:#9ECBFF\"> cat-file</span><span style=\"color:#9ECBFF\"> commit</span><span style=\"color:#F97583\"> &#x3C;</span><span style=\"color:#9ECBFF\">commit-has</span><span style=\"color:#E1E4E8\">h</span><span style=\"color:#F97583\">></span></span></code></pre></div>\n\n<p><strong>Milestone 5 Checkpoint</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test branch operations</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> your_git.py</span><span style=\"color:#9ECBFF\"> branch</span><span style=\"color:#9ECBFF\"> feature</span><span style=\"color:#F97583\"> &#x3C;</span><span style=\"color:#9ECBFF\">commit-has</span><span style=\"color:#E1E4E8\">h</span><span style=\"color:#F97583\">></span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">cat</span><span style=\"color:#9ECBFF\"> .git/refs/heads/feature</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> your_git.py</span><span style=\"color:#9ECBFF\"> checkout</span><span style=\"color:#9ECBFF\"> feature</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">cat</span><span style=\"color:#9ECBFF\"> .git/HEAD</span></span></code></pre></div>\n\n<p><strong>Milestone 6 Checkpoint</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test staging operations</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#9ECBFF\"> \"new content\"</span><span style=\"color:#F97583\"> ></span><span style=\"color:#9ECBFF\"> newfile.txt</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> your_git.py</span><span style=\"color:#9ECBFF\"> add</span><span style=\"color:#9ECBFF\"> newfile.txt</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> your_git.py</span><span style=\"color:#9ECBFF\"> status</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">hexdump</span><span style=\"color:#79B8FF\"> -C</span><span style=\"color:#9ECBFF\"> .git/index</span><span style=\"color:#6A737D\">  # Verify binary format</span></span></code></pre></div>\n\n<p><strong>Milestone 7 Checkpoint</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test diff algorithm</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#79B8FF\"> -e</span><span style=\"color:#9ECBFF\"> \"line1\\nline2\\nline3\"</span><span style=\"color:#F97583\"> ></span><span style=\"color:#9ECBFF\"> file1.txt</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#79B8FF\"> -e</span><span style=\"color:#9ECBFF\"> \"line1\\nmodified\\nline3\"</span><span style=\"color:#F97583\"> ></span><span style=\"color:#9ECBFF\"> file2.txt</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> your_git.py</span><span style=\"color:#9ECBFF\"> diff</span><span style=\"color:#9ECBFF\"> file1.txt</span><span style=\"color:#9ECBFF\"> file2.txt</span></span></code></pre></div>\n\n<p><strong>Milestone 8 Checkpoint</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test merge operations</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> your_git.py</span><span style=\"color:#9ECBFF\"> merge</span><span style=\"color:#9ECBFF\"> feature</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> your_git.py</span><span style=\"color:#9ECBFF\"> status</span><span style=\"color:#6A737D\">  # Check for conflicts</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> your_git.py</span><span style=\"color:#9ECBFF\"> log</span><span style=\"color:#79B8FF\"> --oneline</span><span style=\"color:#6A737D\">  # Verify merge commit</span></span></code></pre></div>\n\n<h4 id=\"debugging-tips\">Debugging Tips</h4>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Hash mismatch with official Git</td>\n<td>Incorrect object header format</td>\n<td>Compare object content byte-by-byte</td>\n<td>Ensure exact &quot;blob {size}\\0{content}&quot; format</td>\n</tr>\n<tr>\n<td>&quot;Not a git repository&quot; error</td>\n<td>Missing or incorrect .git structure</td>\n<td>Check directory permissions and HEAD file</td>\n<td>Verify .git directory and all subdirectories exist</td>\n</tr>\n<tr>\n<td>Index corruption</td>\n<td>Binary format errors</td>\n<td>Parse index with hexdump -C</td>\n<td>Follow Git index format specification exactly</td>\n</tr>\n<tr>\n<td>Merge conflicts not detected</td>\n<td>Incorrect three-way comparison</td>\n<td>Trace merge algorithm with debug output</td>\n<td>Verify merge base calculation and line-by-line comparison</td>\n</tr>\n<tr>\n<td>Performance problems</td>\n<td>Inefficient algorithms</td>\n<td>Profile with cProfile</td>\n<td>Optimize hot paths, especially diff and merge algorithms</td>\n</tr>\n</tbody></table>\n<p>The testing strategy provides comprehensive coverage while remaining practical for development workflows. The key insight is that Git&#39;s deterministic nature makes automated testing straightforward - identical operations should always produce identical results, making regression detection reliable and comprehensive compatibility verification achievable.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The testing implementation provides the foundation for confident development and reliable milestone verification. The comprehensive approach ensures your Git implementation works correctly both in isolation and in comparison with official Git.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Testing Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Test Framework</td>\n<td>pytest with basic assertions</td>\n<td>pytest with custom plugins and fixtures</td>\n</tr>\n<tr>\n<td>Git Execution</td>\n<td>subprocess.run() with shell commands</td>\n<td>GitPython library for programmatic Git operations</td>\n</tr>\n<tr>\n<td>Binary Format Testing</td>\n<td>Manual hex dump comparison</td>\n<td>Custom binary format parsers and validators</td>\n</tr>\n<tr>\n<td>Performance Testing</td>\n<td>Basic timing with time.time()</td>\n<td>pytest-benchmark with statistical analysis</td>\n</tr>\n<tr>\n<td>Cross-Platform Testing</td>\n<td>Manual testing on available systems</td>\n<td>GitHub Actions matrix with multiple OS versions</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-testing-file-structure\">Recommended Testing File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>build-your-own-git/\n├── tests/\n│   ├── __init__.py\n│   ├── conftest.py                 # pytest configuration and shared fixtures\n│   ├── unit/                       # Unit tests for individual components\n│   │   ├── __init__.py\n│   │   ├── test_object_store.py    # ObjectStore class testing\n│   │   ├── test_index.py           # Index class testing\n│   │   ├── test_references.py      # ReferenceManager testing\n│   │   ├── test_diff_algorithm.py  # MyersDiff algorithm testing\n│   │   └── test_merge_algorithm.py # ThreeWayMerge testing\n│   ├── integration/                # Integration tests comparing with official Git\n│   │   ├── __init__.py\n│   │   ├── test_basic_workflow.py  # init, add, commit workflow\n│   │   ├── test_branch_operations.py # branch creation, switching, merging\n│   │   ├── test_merge_scenarios.py # various merge conflict scenarios\n│   │   └── test_compatibility.py   # comprehensive compatibility testing\n│   ├── milestone/                  # Milestone-specific verification tests\n│   │   ├── __init__.py\n│   │   ├── test_milestone_1.py     # Repository initialization verification\n│   │   ├── test_milestone_2.py     # Blob storage verification\n│   │   ├── test_milestone_3.py     # Tree objects verification\n│   │   ├── test_milestone_4.py     # Commit objects verification\n│   │   ├── test_milestone_5.py     # References and branches verification\n│   │   ├── test_milestone_6.py     # Index and staging verification\n│   │   ├── test_milestone_7.py     # Diff algorithm verification\n│   │   └── test_milestone_8.py     # Three-way merge verification\n│   ├── fixtures/                   # Test data and repository templates\n│   │   ├── sample_repos/           # Pre-built test repositories\n│   │   ├── binary_files/           # Binary test files for blob storage\n│   │   ├── conflict_scenarios/     # Merge conflict test cases\n│   │   └── large_files/            # Performance testing files\n│   └── utils/                      # Testing utilities and helpers\n│       ├── __init__.py\n│       ├── git_comparison.py       # Compare with official Git implementation\n│       ├── repo_generator.py       # Generate test repositories programmatically\n│       ├── binary_parser.py        # Parse and validate Git binary formats\n│       └── performance_monitor.py  # Monitor performance and memory usage\n├── src/\n│   └── your_git/                   # Your Git implementation modules\n│       ├── __init__.py\n│       ├── repository.py           # Repository class\n│       ├── object_store.py         # ObjectStore class\n│       ├── index.py                # Index class\n│       └── ...\n└── pytest.ini                     # pytest configuration file</code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p><strong>Complete Git Comparison Framework</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">#!/usr/bin/env python3</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Complete Git Comparison Framework for testing compatibility with official Git.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">This framework handles environment setup, command execution, and result comparison.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> os</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> sys</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> subprocess</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> tempfile</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> shutil</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional, Tuple, Any, Set</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> hashlib</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> re</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass, field</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ComparisonResult</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Results of comparing custom Git with official Git.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    IDENTICAL</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"identical\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    ACCEPTABLE_DIFFERENCE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"acceptable_difference\"</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    INCOMPATIBLE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"incompatible\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    ERROR</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"error\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> CommandResult</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Result of running a Git command.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    exit_code: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    stdout: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    stderr: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    execution_time: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    command: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ComparisonReport</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Report comparing two Git implementations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    command: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    custom_result: CommandResult</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    official_result: CommandResult</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    comparison_result: ComparisonResult</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    differences: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">list</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    notes: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">list</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> GitTestEnvironment</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Manages isolated Git testing environment with consistent configuration.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, custom_git_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, test_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.custom_git_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> custom_git_path</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.official_git_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> shutil.which(</span><span style=\"color:#9ECBFF\">\"git\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.test_name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> test_name</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.test_dir: Optional[Path] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.original_env </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.official_git_path:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> RuntimeError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Official Git not found in PATH\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __enter__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Set up test environment.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.test_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Path(tempfile.mkdtemp(</span><span style=\"color:#FFAB70\">prefix</span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"git_test_</span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.test_name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">_\"</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Save original environment</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.original_env </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            key: os.environ.get(key) </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> key </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> [</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'GIT_AUTHOR_NAME'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'GIT_AUTHOR_EMAIL'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'GIT_COMMITTER_NAME'</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'GIT_COMMITTER_EMAIL'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'GIT_AUTHOR_DATE'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'GIT_COMMITTER_DATE'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            ]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Set consistent Git environment for reproducible results</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        os.environ.update({</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'GIT_AUTHOR_NAME'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'Test Author'</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'GIT_AUTHOR_EMAIL'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'author@test.com'</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'GIT_COMMITTER_NAME'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'Test Committer'</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'GIT_COMMITTER_EMAIL'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'committer@test.com'</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'GIT_AUTHOR_DATE'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'1609459200 +0000'</span><span style=\"color:#E1E4E8\">,    </span><span style=\"color:#6A737D\"># 2021-01-01 00:00:00 UTC</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'GIT_COMMITTER_DATE'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'1609459200 +0000'</span><span style=\"color:#6A737D\">  # 2021-01-01 00:00:00 UTC</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        })</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __exit__</span><span style=\"color:#E1E4E8\">(self, exc_type, exc_val, exc_tb):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Clean up test environment.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.test_dir </span><span style=\"color:#F97583\">and</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.test_dir.exists():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            shutil.rmtree(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.test_dir)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Restore original environment</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> key, value </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.original_env.items():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> value </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                os.environ.pop(key, </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                os.environ[key] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> value</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> run_custom_git</span><span style=\"color:#E1E4E8\">(self, args: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">], cwd: Optional[Path] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> CommandResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Run command with custom Git implementation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._run_git_command(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.custom_git_path, args, cwd </span><span style=\"color:#F97583\">or</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.test_dir)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> run_official_git</span><span style=\"color:#E1E4E8\">(self, args: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">], cwd: Optional[Path] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> CommandResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Run command with official Git.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._run_git_command(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.official_git_path, args, cwd </span><span style=\"color:#F97583\">or</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.test_dir)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _run_git_command</span><span style=\"color:#E1E4E8\">(self, git_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, args: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">], cwd: Path) -> CommandResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Execute Git command and capture results.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        start_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            result </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> subprocess.run(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                [git_path] </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> args,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                cwd</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">cwd,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                capture_output</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                text</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                timeout</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">60</span><span style=\"color:#6A737D\">  # 60 second timeout for commands</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            execution_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> CommandResult(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                exit_code</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">result.returncode,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                stdout</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">result.stdout,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                stderr</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">result.stderr,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                execution_time</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">execution_time,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                command</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">[git_path] </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> args</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#E1E4E8\"> subprocess.TimeoutExpired:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> CommandResult(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                exit_code</span><span style=\"color:#F97583\">=-</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                stdout</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                stderr</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"Command timed out after 60 seconds\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                execution_time</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">60.0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                command</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">[git_path] </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> args</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> CommandResult(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                exit_code</span><span style=\"color:#F97583\">=-</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                stdout</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                stderr</span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Command execution failed: </span><span style=\"color:#79B8FF\">{str</span><span style=\"color:#E1E4E8\">(e)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                execution_time</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                command</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">[git_path] </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> args</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> GitCompatibilityTester</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Comprehensive Git compatibility testing framework.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, custom_git_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.custom_git_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> custom_git_path</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.comparison_reports: List[ComparisonReport] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Patterns for acceptable differences</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.timestamp_patterns </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            re.compile(</span><span style=\"color:#F97583\">r</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\d</span><span style=\"color:#F97583\">{10}</span><span style=\"color:#79B8FF\"> [+-]\\d</span><span style=\"color:#F97583\">{4}</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">),  </span><span style=\"color:#6A737D\"># Unix timestamp with timezone</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            re.compile(</span><span style=\"color:#F97583\">r</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\w</span><span style=\"color:#F97583\">{3}</span><span style=\"color:#79B8FF\"> \\w</span><span style=\"color:#F97583\">{3}</span><span style=\"color:#79B8FF\"> \\d</span><span style=\"color:#F97583\">{1,2}</span><span style=\"color:#79B8FF\"> \\d</span><span style=\"color:#F97583\">{2}</span><span style=\"color:#DBEDFF\">:</span><span style=\"color:#79B8FF\">\\d</span><span style=\"color:#F97583\">{2}</span><span style=\"color:#DBEDFF\">:</span><span style=\"color:#79B8FF\">\\d</span><span style=\"color:#F97583\">{2}</span><span style=\"color:#79B8FF\"> \\d</span><span style=\"color:#F97583\">{4}</span><span style=\"color:#79B8FF\"> [+-]\\d</span><span style=\"color:#F97583\">{4}</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">),  </span><span style=\"color:#6A737D\"># Date format</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.hash_pattern </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> re.compile(</span><span style=\"color:#F97583\">r</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">[0-9a-f]</span><span style=\"color:#F97583\">{40}</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># SHA-1 hashes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> compare_commands</span><span style=\"color:#E1E4E8\">(self, test_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, commands: List[List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]]) -> List[ComparisonReport]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Compare series of commands between implementations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        reports </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#E1E4E8\"> GitTestEnvironment(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.custom_git_path, test_name) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> env:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            for</span><span style=\"color:#E1E4E8\"> command </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> commands:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                custom_result </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> env.run_custom_git(command)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                official_result </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> env.run_official_git(command)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                report </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._compare_results(command, custom_result, official_result)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                reports.append(report)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">.comparison_reports.append(report)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> reports</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _compare_results</span><span style=\"color:#E1E4E8\">(self, command: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">], custom: CommandResult, official: CommandResult) -> ComparisonReport:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Compare results from custom and official Git.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        report </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ComparisonReport(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            command</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">command,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            custom_result</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">custom,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            official_result</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">official,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            comparison_result</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">ComparisonResult.</span><span style=\"color:#79B8FF\">ERROR</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            differences</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">[],</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            notes</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">[]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Check exit codes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> custom.exit_code </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> official.exit_code:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            report.differences.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Exit code differs: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">custom.exit_code</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> vs </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">official.exit_code</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            report.comparison_result </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ComparisonResult.</span><span style=\"color:#79B8FF\">INCOMPATIBLE</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> report</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Normalize outputs for comparison</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        custom_stdout_norm </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._normalize_output(custom.stdout)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        official_stdout_norm </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._normalize_output(official.stdout)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        custom_stderr_norm </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._normalize_output(custom.stderr)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        official_stderr_norm </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._normalize_output(official.stderr)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Compare normalized outputs</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        stdout_match </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> custom_stdout_norm </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> official_stdout_norm</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        stderr_acceptable </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._is_stderr_acceptable(custom_stderr_norm, official_stderr_norm)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> stdout_match </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> stderr_acceptable:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            report.comparison_result </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ComparisonResult.</span><span style=\"color:#79B8FF\">IDENTICAL</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._outputs_are_functionally_equivalent(custom_stdout_norm, official_stdout_norm):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            report.comparison_result </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ComparisonResult.</span><span style=\"color:#79B8FF\">ACCEPTABLE_DIFFERENCE</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            report.notes.append(</span><span style=\"color:#9ECBFF\">\"Outputs are functionally equivalent despite formatting differences\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            report.comparison_result </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ComparisonResult.</span><span style=\"color:#79B8FF\">INCOMPATIBLE</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> stdout_match:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                report.differences.append(</span><span style=\"color:#9ECBFF\">\"stdout differs\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> stderr_acceptable:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                report.differences.append(</span><span style=\"color:#9ECBFF\">\"stderr differs significantly\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> report</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _normalize_output</span><span style=\"color:#E1E4E8\">(self, output: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Normalize output for comparison by removing acceptable variations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> output:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#9ECBFF\"> \"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        lines </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> output.strip().split(</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        normalized_lines </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> line </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> lines:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Replace timestamps with placeholder</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            for</span><span style=\"color:#E1E4E8\"> pattern </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.timestamp_patterns:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                line </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> pattern.sub(</span><span style=\"color:#9ECBFF\">'[TIMESTAMP]'</span><span style=\"color:#E1E4E8\">, line)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Normalize path separators</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            line </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> line.replace(</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\\\</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'/'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Remove trailing whitespace</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            line </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> line.rstrip()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> line:  </span><span style=\"color:#6A737D\"># Skip empty lines</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                normalized_lines.append(line)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> '</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">.join(normalized_lines)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _is_stderr_acceptable</span><span style=\"color:#E1E4E8\">(self, custom_stderr: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, official_stderr: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Determine if stderr differences are acceptable.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Both empty is OK</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> custom_stderr </span><span style=\"color:#F97583\">and</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> official_stderr:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Different error messages might be OK if they convey the same information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # This is a simplified check - expand based on specific error message patterns</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> abs</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">len</span><span style=\"color:#E1E4E8\">(custom_stderr) </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(official_stderr)) </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 100</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _outputs_are_functionally_equivalent</span><span style=\"color:#E1E4E8\">(self, custom_output: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, official_output: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Check if outputs are functionally equivalent despite formatting differences.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Extract all SHA-1 hashes from both outputs</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        custom_hashes </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> set</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.hash_pattern.findall(custom_output))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        official_hashes </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> set</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.hash_pattern.findall(official_output))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # If hashes match, outputs are likely functionally equivalent</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> custom_hashes </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> official_hashes </span><span style=\"color:#F97583\">and</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(custom_hashes) </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> generate_compatibility_report</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate comprehensive compatibility report.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        total_tests </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.comparison_reports)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> total_tests </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> {</span><span style=\"color:#9ECBFF\">\"error\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"No tests run\"</span><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        results_summary </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> result_type </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> ComparisonResult:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            count </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> sum</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#F97583\"> for</span><span style=\"color:#E1E4E8\"> r </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.comparison_reports </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> r.comparison_result </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> result_type)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            results_summary[result_type.value] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"count\"</span><span style=\"color:#E1E4E8\">: count,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"percentage\"</span><span style=\"color:#E1E4E8\">: (count </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> total_tests) </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 100</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        failed_commands </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"command\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\" \"</span><span style=\"color:#E1E4E8\">.join(r.command),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"result\"</span><span style=\"color:#E1E4E8\">: r.comparison_result.value,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"differences\"</span><span style=\"color:#E1E4E8\">: r.differences,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"notes\"</span><span style=\"color:#E1E4E8\">: r.notes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            for</span><span style=\"color:#E1E4E8\"> r </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.comparison_reports</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> r.comparison_result </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> ComparisonResult.</span><span style=\"color:#79B8FF\">INCOMPATIBLE</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"total_tests\"</span><span style=\"color:#E1E4E8\">: total_tests,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"results_summary\"</span><span style=\"color:#E1E4E8\">: results_summary,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"compatibility_score\"</span><span style=\"color:#E1E4E8\">: results_summary.get(</span><span style=\"color:#9ECBFF\">\"identical\"</span><span style=\"color:#E1E4E8\">, {}).get(</span><span style=\"color:#9ECBFF\">\"percentage\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"failed_commands\"</span><span style=\"color:#E1E4E8\">: failed_commands,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"test_timestamp\"</span><span style=\"color:#E1E4E8\">: time.strftime(</span><span style=\"color:#9ECBFF\">\"%Y-%m-</span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#9ECBFF\"> %H:%M:%S UTC\"</span><span style=\"color:#E1E4E8\">, time.gmtime())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span></code></pre></div>\n\n<p><strong>Repository Test Data Generator</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">#!/usr/bin/env python3</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Repository Test Data Generator - Creates diverse test repositories for comprehensive testing.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> os</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> random</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> string</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> struct</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Dict, Any, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> tempfile</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> subprocess</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TestDataGenerator</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Generate test data and repositories for Git testing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, base_dir: Optional[Path] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.base_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> base_dir </span><span style=\"color:#F97583\">or</span><span style=\"color:#E1E4E8\"> Path(tempfile.mkdtemp(</span><span style=\"color:#FFAB70\">prefix</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"git_test_data_\"</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.base_dir.mkdir(</span><span style=\"color:#FFAB70\">exist_ok</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> generate_text_content</span><span style=\"color:#E1E4E8\">(self, lines: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10</span><span style=\"color:#E1E4E8\">, line_length: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 80</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate realistic text content for testing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        content_lines </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(lines):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Generate line with realistic word structure</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            line_content </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            current_length </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            while</span><span style=\"color:#E1E4E8\"> current_length </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> line_length </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> 10</span><span style=\"color:#E1E4E8\">:  </span><span style=\"color:#6A737D\"># Leave room for final word</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                word_length </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> random.randint(</span><span style=\"color:#79B8FF\">3</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">12</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                word </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> ''</span><span style=\"color:#E1E4E8\">.join(random.choice(string.ascii_letters) </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> _ </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(word_length))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> current_length </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> word_length </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#F97583\"> &#x3C;=</span><span style=\"color:#E1E4E8\"> line_length:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    line_content.append(word)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    current_length </span><span style=\"color:#F97583\">+=</span><span style=\"color:#E1E4E8\"> word_length </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    break</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            content_lines.append(</span><span style=\"color:#9ECBFF\">' '</span><span style=\"color:#E1E4E8\">.join(line_content))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> '</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">.join(content_lines) </span><span style=\"color:#F97583\">+</span><span style=\"color:#9ECBFF\"> '</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> generate_binary_content</span><span style=\"color:#E1E4E8\">(self, size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate binary content for testing blob storage.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Mix of various byte values including null bytes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        content </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> bytearray</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> _ </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(size):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Include null bytes and high-bit characters</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            content.append(random.randint(</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">255</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> bytes</span><span style=\"color:#E1E4E8\">(content)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> create_repository_with_history</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, commit_count: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10</span><span style=\"color:#E1E4E8\">) -> Path:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Create repository with specified number of commits.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        repo_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.base_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> name</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        repo_path.mkdir(</span><span style=\"color:#FFAB70\">exist_ok</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Initialize repository</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        subprocess.run([</span><span style=\"color:#9ECBFF\">'git'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'init'</span><span style=\"color:#E1E4E8\">], </span><span style=\"color:#FFAB70\">cwd</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">repo_path, </span><span style=\"color:#FFAB70\">check</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">capture_output</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Create commits with diverse content</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(commit_count):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Create or modify files</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # Initial commit with README</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                (repo_path </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> 'README.md'</span><span style=\"color:#E1E4E8\">).write_text(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">'# </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">name</span><span style=\"color:#79B8FF\">}\\n\\n</span><span style=\"color:#9ECBFF\">Test repository created for Git compatibility testing.</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                subprocess.run([</span><span style=\"color:#9ECBFF\">'git'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'add'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'README.md'</span><span style=\"color:#E1E4E8\">], </span><span style=\"color:#FFAB70\">cwd</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">repo_path, </span><span style=\"color:#FFAB70\">check</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                message </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> 'Initial commit'</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # Add new files or modify existing ones</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> random.choice([</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">]):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                    # Add new file</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    filename </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">'file_</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">i</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">.txt'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    content </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.generate_text_content(random.randint(</span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">50</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    (repo_path </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> filename).write_text(content)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    subprocess.run([</span><span style=\"color:#9ECBFF\">'git'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'add'</span><span style=\"color:#E1E4E8\">, filename], </span><span style=\"color:#FFAB70\">cwd</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">repo_path, </span><span style=\"color:#FFAB70\">check</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    message </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">'Add </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">filename</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">'</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                    # Modify existing file</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    existing_files </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [f </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> f </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> repo_path.iterdir() </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> f.suffix </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> '.txt'</span><span style=\"color:#F97583\"> or</span><span style=\"color:#E1E4E8\"> f.suffix </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> '.md'</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    if</span><span style=\"color:#E1E4E8\"> existing_files:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        target_file </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> random.choice(existing_files)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        content </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.generate_text_content(random.randint(</span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">50</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        target_file.write_text(content)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        subprocess.run([</span><span style=\"color:#9ECBFF\">'git'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'add'</span><span style=\"color:#E1E4E8\">, target_file.name], </span><span style=\"color:#FFAB70\">cwd</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">repo_path, </span><span style=\"color:#FFAB70\">check</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        message </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">'Modify </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">target_file.name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">'</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                        continue</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Create commit</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            subprocess.run([</span><span style=\"color:#9ECBFF\">'git'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'commit'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'-m'</span><span style=\"color:#E1E4E8\">, message], </span><span style=\"color:#FFAB70\">cwd</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">repo_path, </span><span style=\"color:#FFAB70\">check</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">capture_output</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> repo_path</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> create_merge_conflict_repository</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Path:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Create repository with merge conflict scenario.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        repo_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.base_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> name</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        repo_path.mkdir(</span><span style=\"color:#FFAB70\">exist_ok</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        subprocess.run([</span><span style=\"color:#9ECBFF\">'git'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'init'</span><span style=\"color:#E1E4E8\">], </span><span style=\"color:#FFAB70\">cwd</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">repo_path, </span><span style=\"color:#FFAB70\">check</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">capture_output</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Create initial commit</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        content </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"line 1</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">line 2</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">line 3</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">line 4</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">line 5</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        (repo_path </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> 'conflict.txt'</span><span style=\"color:#E1E4E8\">).write_text(content)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        subprocess.run([</span><span style=\"color:#9ECBFF\">'git'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'add'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'conflict.txt'</span><span style=\"color:#E1E4E8\">], </span><span style=\"color:#FFAB70\">cwd</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">repo_path, </span><span style=\"color:#FFAB70\">check</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        subprocess.run([</span><span style=\"color:#9ECBFF\">'git'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'commit'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'-m'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'Initial version'</span><span style=\"color:#E1E4E8\">], </span><span style=\"color:#FFAB70\">cwd</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">repo_path, </span><span style=\"color:#FFAB70\">check</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">capture_output</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Create feature branch</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        subprocess.run([</span><span style=\"color:#9ECBFF\">'git'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'checkout'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'-b'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'feature'</span><span style=\"color:#E1E4E8\">], </span><span style=\"color:#FFAB70\">cwd</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">repo_path, </span><span style=\"color:#FFAB70\">check</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">capture_output</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Modify file in feature branch</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        modified_content </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"line 1</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">modified line 2 (feature)</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">line 3</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">line 4</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">feature addition</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        (repo_path </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> 'conflict.txt'</span><span style=\"color:#E1E4E8\">).write_text(modified_content)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        subprocess.run([</span><span style=\"color:#9ECBFF\">'git'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'add'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'conflict.txt'</span><span style=\"color:#E1E4E8\">], </span><span style=\"color:#FFAB70\">cwd</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">repo_path, </span><span style=\"color:#FFAB70\">check</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        subprocess.run([</span><span style=\"color:#9ECBFF\">'git'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'commit'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'-m'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'Feature changes'</span><span style=\"color:#E1E4E8\">], </span><span style=\"color:#FFAB70\">cwd</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">repo_path, </span><span style=\"color:#FFAB70\">check</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">capture_output</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Switch back to main and make conflicting changes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        subprocess.run([</span><span style=\"color:#9ECBFF\">'git'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'checkout'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'main'</span><span style=\"color:#E1E4E8\">], </span><span style=\"color:#FFAB70\">cwd</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">repo_path, </span><span style=\"color:#FFAB70\">check</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">capture_output</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        conflicting_content </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"line 1</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">modified line 2 (main)</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">line 3</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">main modification</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">line 5</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        (repo_path </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> 'conflict.txt'</span><span style=\"color:#E1E4E8\">).write_text(conflicting_content)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        subprocess.run([</span><span style=\"color:#9ECBFF\">'git'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'add'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'conflict.txt'</span><span style=\"color:#E1E4E8\">], </span><span style=\"color:#FFAB70\">cwd</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">repo_path, </span><span style=\"color:#FFAB70\">check</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        subprocess.run([</span><span style=\"color:#9ECBFF\">'git'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'commit'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'-m'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'Main branch changes'</span><span style=\"color:#E1E4E8\">], </span><span style=\"color:#FFAB70\">cwd</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">repo_path, </span><span style=\"color:#FFAB70\">check</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">capture_output</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> repo_path</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeleton-code\">Core Logic Skeleton Code</h4>\n<p><strong>Milestone Verification Test Template</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">#!/usr/bin/env python3</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Milestone Verification Test Framework - Template for systematic milestone testing.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> pytest</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> tempfile</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> subprocess</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> hashlib</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Dict, Any, Optional, Tuple</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> MilestoneTestBase</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Base class providing common testing infrastructure for all milestones.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, git_implementation_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.git_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_implementation_path</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.test_repo: Optional[Path] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.original_cwd </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Path.cwd()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> setup_test_repo</span><span style=\"color:#E1E4E8\">(self, repo_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"test_repo\"</span><span style=\"color:#E1E4E8\">) -> Path:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Create isolated test repository environment.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create temporary directory for test repository</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Set consistent Git environment variables for reproducible results</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Change to test repository directory</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return path to test repository for use in tests</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use tempfile.mkdtemp() and os.environ for environment setup</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> cleanup_test_repo</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Clean up test repository and restore environment.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1:</span></span></code></pre></div>\n\n\n<h2 id=\"debugging-guide\">Debugging Guide</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section applies to all eight milestones but is particularly critical for complex operations in Milestone 6 (Index/Staging Area), Milestone 7 (Diff Algorithm), and Milestone 8 (Three-Way Merge) where multiple components interact and failure modes can be subtle.</p>\n</blockquote>\n<h3 id=\"mental-model-the-medical-diagnostic-process\">Mental Model: The Medical Diagnostic Process</h3>\n<p>Think of debugging a Git implementation like diagnosing a patient in a hospital. When someone comes to the emergency room saying &quot;I feel terrible,&quot; that&#39;s just the symptom—the real challenge is systematically working backward to find the root cause. A good doctor doesn&#39;t just treat the fever; they run tests to determine whether it&#39;s caused by an infection, an autoimmune disorder, or something else entirely.</p>\n<p>Similarly, when your Git implementation fails with &quot;object not found&quot; or &quot;merge conflicts detected incorrectly,&quot; these are symptoms of deeper issues in the object store, hashing logic, file I/O, or algorithm implementation. Just like medical diagnosis follows a systematic process—gather symptoms, form hypotheses, run tests, eliminate possibilities—debugging Git requires a methodical approach to trace problems back through the system&#39;s layers.</p>\n<p>The key insight is that Git&#39;s components form a dependency chain: merge algorithms depend on diff algorithms, diff algorithms depend on tree comparisons, tree comparisons depend on object retrieval, and object retrieval depends on correct hashing and storage. A failure in any lower layer manifests as confusing symptoms in higher layers, just like how a kidney problem might first show up as fatigue or swelling.</p>\n<p>This section provides the diagnostic tools and systematic approaches you need to isolate problems quickly and fix them at their source, rather than chasing symptoms through multiple system layers.</p>\n<h3 id=\"object-storage-issues\">Object Storage Issues</h3>\n<p>The object store is the foundation of Git&#39;s architecture, and problems here propagate throughout the entire system. Since every other operation depends on storing and retrieving objects correctly, object storage bugs often manifest as mysterious failures in seemingly unrelated components.</p>\n<h4 id=\"hash-mismatches-and-computation-errors\">Hash Mismatches and Computation Errors</h4>\n<p>Hash mismatches are among the most common and frustrating problems in Git implementation. When your computed hash doesn&#39;t match the expected value, it indicates a fundamental error in how you&#39;re constructing or processing object content.</p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Root Cause</th>\n<th>Diagnostic Steps</th>\n<th>Solution</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>compute_object_hash()</code> returns different hash than real Git</td>\n<td>Missing or incorrect null byte separator</td>\n<td>Print raw bytes before hashing, check for <code>\\0</code> at correct position</td>\n<td>Ensure format is exactly <code>{type} {size}\\0{content}</code></td>\n</tr>\n<tr>\n<td>Hash computation works for text but fails for binary files</td>\n<td>Line ending conversion corrupting binary data</td>\n<td>Check if file reading mode is binary vs text</td>\n<td>Always open files in binary mode (<code>&#39;rb&#39;</code>)</td>\n</tr>\n<tr>\n<td>Same content produces different hashes on different runs</td>\n<td>Including timestamp or metadata in hash calculation</td>\n<td>Log exactly what bytes are being hashed</td>\n<td>Only hash the canonical object format, not filesystem metadata</td>\n</tr>\n<tr>\n<td>Objects store but can&#39;t be retrieved</td>\n<td>Hash computed incorrectly during storage vs retrieval</td>\n<td>Compare hashes at storage time vs retrieval time</td>\n<td>Ensure identical hash computation algorithm in both paths</td>\n</tr>\n<tr>\n<td>Repository corruption errors when using stored objects</td>\n<td>Hash collision or truncated hash</td>\n<td>Validate hash is exactly 40 hex characters</td>\n<td>Check for off-by-one errors in string slicing</td>\n</tr>\n</tbody></table>\n<p>The most critical debugging technique for hash issues is to log the exact byte sequence being hashed. Hash functions are deterministic—if you get different outputs, your inputs are different, even if they look identical when printed as strings.</p>\n<p><strong>⚠️ Pitfall: Text Mode File Reading</strong>\nOne of the most subtle bugs occurs when reading files in text mode instead of binary mode. On Windows, text mode automatically converts <code>\\r\\n</code> to <code>\\n</code>, which changes the file&#39;s byte content and produces a different hash. Always use binary mode for all file operations, then handle line endings explicitly if needed.</p>\n<p><strong>⚠️ Pitfall: Unicode Encoding Issues</strong>\nWhen handling file paths or commit messages with non-ASCII characters, inconsistent encoding between storage and retrieval will cause hash mismatches. Git internally uses UTF-8 for all text content, but filesystem paths might use different encodings. Establish a consistent encoding strategy early and apply it everywhere.</p>\n<blockquote>\n<p><strong>Key Insight</strong>: Hash mismatches are never random—they indicate a systematic difference in how content is processed. The debugging approach should focus on isolating exactly where the byte streams diverge, typically by comparing hex dumps of the content at each processing stage.</p>\n</blockquote>\n<h4 id=\"compression-and-storage-problems\">Compression and Storage Problems</h4>\n<p>Git uses zlib compression for all stored objects, and compression-related bugs can cause object corruption, storage failures, or retrieval errors that are difficult to trace back to their source.</p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Root Cause</th>\n<th>Diagnostic Steps</th>\n<th>Solution</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>zlib.error: Error -3 while decompressing</code></td>\n<td>Stored object wasn&#39;t properly compressed</td>\n<td>Try decompressing stored file manually with Python zlib</td>\n<td>Ensure <code>zlib.compress()</code> before writing to disk</td>\n</tr>\n<tr>\n<td>Objects store successfully but retrieval returns corrupted content</td>\n<td>Partial write or filesystem buffering issue</td>\n<td>Check file size on disk vs expected compressed size</td>\n<td>Use <code>fsync()</code> or atomic writes to ensure complete storage</td>\n</tr>\n<tr>\n<td>Compression works for small files but fails for large ones</td>\n<td>Memory exhaustion or buffer overflow</td>\n<td>Monitor memory usage during compression</td>\n<td>Stream compression for files larger than available RAM</td>\n</tr>\n<tr>\n<td>Decompression succeeds but content doesn&#39;t match original</td>\n<td>Wrong compression level or algorithm variant</td>\n<td>Compare compression settings between storage/retrieval</td>\n<td>Use consistent <code>zlib.compress()</code> with default level</td>\n</tr>\n<tr>\n<td>Storage location exists but appears empty</td>\n<td>Race condition in concurrent access</td>\n<td>Check if multiple processes are accessing same object</td>\n<td>Implement file locking around object store operations</td>\n</tr>\n</tbody></table>\n<p>The key diagnostic tool for compression issues is to manually test compression and decompression outside your Git implementation. Python&#39;s <code>zlib</code> module makes this straightforward:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test compression/decompression manually</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> zlib</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">original </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> b</span><span style=\"color:#9ECBFF\">\"blob 5</span><span style=\"color:#79B8FF\">\\x00</span><span style=\"color:#9ECBFF\">hello\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">compressed </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> zlib.compress(original)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">decompressed </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> zlib.decompress(compressed)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">assert</span><span style=\"color:#E1E4E8\"> original </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> decompressed</span></span></code></pre></div>\n\n<p>If this test passes but your Git implementation fails, the problem is in your file I/O, not the compression logic.</p>\n<p><strong>⚠️ Pitfall: Forgetting to Compress Before Storage</strong>\nA common mistake is computing the hash correctly (from uncompressed content) but then storing the uncompressed content to disk. Git always stores compressed objects, so retrieval will fail when trying to decompress uncompressed data. The rule is: hash the uncompressed content, store the compressed content.</p>\n<p><strong>⚠️ Pitfall: Double Compression</strong>\nAnother subtle bug occurs when accidentally compressing already-compressed data. This typically happens when a higher-level function calls a lower-level storage function that also performs compression. The symptom is that stored objects become corrupted and can&#39;t be retrieved. Always maintain clear boundaries about which layer handles compression.</p>\n<h4 id=\"file-system-permissions-and-path-issues\">File System Permissions and Path Issues</h4>\n<p>Object storage relies heavily on filesystem operations, and permission or path-related problems can cause mysterious failures that are difficult to diagnose because error messages often don&#39;t clearly indicate the root cause.</p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Root Cause</th>\n<th>Diagnostic Steps</th>\n<th>Solution</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>PermissionError</code> when storing objects</td>\n<td><code>.git/objects</code> directory has wrong permissions</td>\n<td>Check directory permissions with <code>ls -la .git/objects</code></td>\n<td>Ensure <code>.git</code> hierarchy has appropriate read/write permissions</td>\n</tr>\n<tr>\n<td>Objects store but can&#39;t be found during retrieval</td>\n<td>Incorrect path construction from hash</td>\n<td>Print full file path during storage and retrieval</td>\n<td>Verify path format is <code>.git/objects/xx/yy...</code> with correct hash splitting</td>\n</tr>\n<tr>\n<td>Storage succeeds on some systems but fails on others</td>\n<td>Case sensitivity differences (Windows vs Linux)</td>\n<td>Test with hashes that differ only in case</td>\n<td>Ensure consistent case handling in hash-to-path conversion</td>\n</tr>\n<tr>\n<td>Intermittent storage failures</td>\n<td>Directory creation race condition</td>\n<td>Check if <code>.git/objects/xx/</code> directory exists before object creation</td>\n<td>Create intermediate directories atomically</td>\n</tr>\n<tr>\n<td>Storage works but repository appears empty to other tools</td>\n<td>Objects stored in wrong location relative to <code>.git</code></td>\n<td>Verify object paths relative to repository root</td>\n<td>Ensure <code>.git</code> directory detection is working correctly</td>\n</tr>\n</tbody></table>\n<p>The most effective diagnostic approach for path issues is to log the complete file paths being used and manually verify they match Git&#39;s expected structure. Use <code>find .git/objects -type f</code> to see what&#39;s actually stored and compare against your expectations.</p>\n<p><strong>⚠️ Pitfall: Relative vs Absolute Paths</strong>\nBe extremely careful about working directory context when constructing object paths. If your Git implementation changes working directories, relative paths to <code>.git/objects</code> can suddenly point to the wrong location. Always resolve to absolute paths early in your program and maintain them consistently.</p>\n<p><strong>⚠️ Pitfall: Directory Creation Timing</strong>\nThe <code>.git/objects/xx</code> subdirectories need to be created before storing objects. A common bug is assuming these directories exist, leading to storage failures for objects whose hash prefix hasn&#39;t been seen before. Always create the directory structure on demand during object storage.</p>\n<h3 id=\"merge-algorithm-debugging\">Merge Algorithm Debugging</h3>\n<p>Merge algorithms are among the most complex components in Git, involving multiple algorithms working together: finding merge bases, comparing file trees, detecting conflicts, and combining changes. Problems here often involve subtle edge cases in graph traversal, incorrect conflict detection, or malformed output.</p>\n<h4 id=\"conflict-detection-failures\">Conflict Detection Failures</h4>\n<p>Incorrect conflict detection is one of the most subtle categories of merge bugs because the symptoms often don&#39;t appear until the merge completes, and by then the root cause is buried in complex algorithm state.</p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Root Cause</th>\n<th>Diagnostic Steps</th>\n<th>Solution</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Changes merge cleanly that should conflict</td>\n<td>Incorrect base version used in three-way comparison</td>\n<td>Print base, ours, theirs content for conflicted regions</td>\n<td>Verify merge base calculation is finding correct common ancestor</td>\n</tr>\n<tr>\n<td>Conflicts detected where files merge cleanly</td>\n<td>Overly aggressive conflict detection algorithm</td>\n<td>Compare line-by-line diffs manually</td>\n<td>Check that identical changes in both branches aren&#39;t flagged as conflicts</td>\n</tr>\n<tr>\n<td>Conflict markers appear in wrong locations</td>\n<td>Line numbering bug in conflict region calculation</td>\n<td>Log start/end line numbers for each conflict region</td>\n<td>Ensure conflict boundaries account for previous insertions/deletions</td>\n</tr>\n<tr>\n<td>Some conflicts detected but others missed</td>\n<td>Incomplete coverage in conflict scanning</td>\n<td>Test with files that have multiple conflict regions</td>\n<td>Scan entire file, not just first conflict</td>\n</tr>\n<tr>\n<td>Binary files show text conflict markers</td>\n<td>Binary file detection failing</td>\n<td>Check <code>is_binary_content()</code> with problematic files</td>\n<td>Improve binary detection or handle binary conflicts differently</td>\n</tr>\n</tbody></table>\n<p>The key diagnostic technique for conflict detection is to manually perform the three-way comparison that your algorithm should be doing. Take the base version, your changes, and their changes, and determine by hand what the result should be. Then trace through your algorithm step-by-step to find where it diverges from the correct result.</p>\n<p><strong>⚠️ Pitfall: Off-by-One Line Numbering</strong>\nConflict detection algorithms typically work with zero-indexed line arrays, but conflict markers need to reference one-indexed line numbers for human readability. Mixing these conventions leads to conflicts appearing in the wrong locations or spanning incorrect ranges.</p>\n<p><strong>⚠️ Pitfall: Assuming Clean Three-Way Split</strong>\nReal merge conflicts are messier than textbook examples. A single file might have multiple conflict regions, conflicts might be adjacent (requiring marker consolidation), or one branch might delete lines while the other modifies them. Design your conflict detection to handle overlapping and adjacent conflicts gracefully.</p>\n<h4 id=\"infinite-loops-in-merge-base-calculation\">Infinite Loops in Merge Base Calculation</h4>\n<p>Finding the merge base requires graph traversal of the commit history, and bugs in the traversal algorithm can cause infinite loops, incorrect results, or performance problems that make merges unusable.</p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Root Cause</th>\n<th>Diagnostic Steps</th>\n<th>Solution</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Merge base calculation never terminates</td>\n<td>Not tracking visited commits in graph traversal</td>\n<td>Add logging to see which commits are being processed repeatedly</td>\n<td>Maintain <code>visited</code> set to prevent revisiting same commit</td>\n</tr>\n<tr>\n<td>Merge base returns wrong commit</td>\n<td>Breadth-first search implementation bug</td>\n<td>Manually trace commit graph and identify expected merge base</td>\n<td>Ensure BFS queue processes commits in chronological order</td>\n</tr>\n<tr>\n<td>Merge base works for simple cases but fails on complex history</td>\n<td>Algorithm doesn&#39;t handle merge commits properly</td>\n<td>Test with repository that has merge commits in history</td>\n<td>Ensure algorithm follows all parent links, not just first parent</td>\n</tr>\n<tr>\n<td>Performance degrades with large repositories</td>\n<td>Inefficient graph traversal or storage</td>\n<td>Profile memory and time usage during merge base calculation</td>\n<td>Use efficient data structures for visited set and processing queue</td>\n</tr>\n<tr>\n<td>Merge base calculation crashes on corrupted history</td>\n<td>Missing error handling for invalid parent references</td>\n<td>Check for commits that reference non-existent parents</td>\n<td>Validate parent commits exist before following references</td>\n</tr>\n</tbody></table>\n<p>The standard approach for debugging graph traversal is to visualize the commit graph manually (using <code>git log --graph --oneline</code>) and trace through your algorithm by hand to verify it produces the same result.</p>\n<p><strong>⚠️ Pitfall: Not Handling Multiple Merge Bases</strong>\nIn complex histories, two branches might have multiple common ancestors at the same distance. The merge base algorithm should return the most recent common ancestor, not just any common ancestor. This requires careful handling of the BFS termination condition.</p>\n<p><strong>⚠️ Pitfall: Stack Overflow on Deep History</strong>\nRecursive implementations of merge base calculation can overflow the call stack on repositories with very deep history. Use iterative algorithms with explicit queues or stacks to handle arbitrarily deep commit graphs.</p>\n<h4 id=\"corrupted-merge-states\">Corrupted Merge States</h4>\n<p>Merge operations involve multiple steps and temporary state, creating opportunities for corruption if the process is interrupted or if there are bugs in state management.</p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Root Cause</th>\n<th>Diagnostic Steps</th>\n<th>Solution</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Merge appears successful but working directory is corrupted</td>\n<td>Incomplete file updates during merge</td>\n<td>Check if all files in merge result were written to working directory</td>\n<td>Ensure atomic updates—write to temp files, then rename</td>\n</tr>\n<tr>\n<td>Merge conflicts resolved but commit creation fails</td>\n<td>Index not updated with merge resolution</td>\n<td>Check index contents after conflict resolution</td>\n<td>Update index entries for all resolved files before committing</td>\n</tr>\n<tr>\n<td>Merge process can&#39;t be resumed after interruption</td>\n<td>Missing or corrupted merge state files</td>\n<td>Look for <code>.git/MERGE_HEAD</code> and related state files</td>\n<td>Save merge state atomically and restore on resume</td>\n</tr>\n<tr>\n<td>Merged content loses changes from one branch</td>\n<td>Three-way merge algorithm bug</td>\n<td>Compare merge result against manual merge</td>\n<td>Debug three-way merge logic with simple test cases</td>\n</tr>\n<tr>\n<td>Merge completes but repository is in inconsistent state</td>\n<td>Transaction boundary not properly implemented</td>\n<td>Verify all merge operations succeed before updating references</td>\n<td>Implement rollback capability for failed merges</td>\n</tr>\n</tbody></table>\n<p>The most effective debugging approach for merge state corruption is to implement comprehensive state validation at each step of the merge process. Before proceeding from one step to the next, verify that all previous steps completed successfully and left the repository in a consistent state.</p>\n<p><strong>⚠️ Pitfall: Not Cleaning Up Merge State</strong>\nAfter a successful merge, temporary state files (like <code>.git/MERGE_HEAD</code>) must be cleaned up. Leaving these files around confuses subsequent operations and can cause Git tools to think a merge is still in progress.</p>\n<p><strong>⚠️ Pitfall: Race Conditions in Concurrent Access</strong>\nIf multiple processes try to perform merges simultaneously, or if a merge is interrupted and restarted, corrupted state can result. Implement proper locking around merge operations to prevent concurrent modifications.</p>\n<h3 id=\"debugging-tools-and-techniques\">Debugging Tools and Techniques</h3>\n<p>Effective Git debugging requires a systematic toolkit of techniques for inspecting internal state, validating data structures, and tracing execution flow. Unlike application debugging, Git debugging often involves understanding the interaction between your implementation and the filesystem, as well as validating that your data structures match Git&#39;s exact specifications.</p>\n<h4 id=\"inspecting-git-internals\">Inspecting Git Internals</h4>\n<p>The ability to inspect and validate Git&#39;s internal data structures is crucial for debugging, because many bugs manifest as subtle differences between your implementation&#39;s output and Git&#39;s expected formats.</p>\n<table>\n<thead>\n<tr>\n<th>Technique</th>\n<th>Purpose</th>\n<th>Implementation</th>\n<th>Usage Example</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Object content validation</td>\n<td>Verify stored objects match expected format</td>\n<td>Decompress <code>.git/objects/xx/yy...</code> files and examine raw content</td>\n<td>Check that blob headers are exactly <code>blob {size}\\0{content}</code></td>\n</tr>\n<tr>\n<td>Hash verification</td>\n<td>Confirm object hashes are computed correctly</td>\n<td>Recompute hash from stored content and compare to filename</td>\n<td>Detect corruption or computation bugs</td>\n</tr>\n<tr>\n<td>Index inspection</td>\n<td>Examine staging area contents and metadata</td>\n<td>Parse binary <code>.git/index</code> file and display entries</td>\n<td>Debug staging/unstaging operations</td>\n</tr>\n<tr>\n<td>Reference tracing</td>\n<td>Follow symbolic and direct references</td>\n<td>Read <code>.git/HEAD</code> and <code>.git/refs/heads/*</code> files</td>\n<td>Debug branch switching and reference updates</td>\n</tr>\n<tr>\n<td>Tree traversal validation</td>\n<td>Verify directory structure representation</td>\n<td>Recursively expand tree objects and compare to filesystem</td>\n<td>Debug tree building and directory representation</td>\n</tr>\n</tbody></table>\n<p>A comprehensive Git internals inspection tool should provide commands to examine each type of internal data structure. This tool becomes invaluable when your implementation produces different results than expected, because it lets you identify exactly where the differences occur.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> inspect_object</span><span style=\"color:#E1E4E8\">(object_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, git_dir: Path) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Comprehensive object inspection that validates format and content.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns detailed breakdown of object structure for debugging.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Implement object retrieval and format validation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Parse object header and extract type, size</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate content matches declared size</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: For tree objects, parse and validate entry format</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: For commit objects, parse and validate all fields</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return structured data for comparison with expected values</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span></code></pre></div>\n\n<p><strong>⚠️ Pitfall: Endianness in Binary Parsing</strong>\nWhen inspecting the binary index file or other Git data structures, be aware that multi-byte integers use network byte order (big-endian). Python&#39;s <code>struct</code> module requires explicit endianness specification (<code>&gt;I</code> for big-endian 32-bit integer).</p>\n<p><strong>⚠️ Pitfall: String Encoding in Object Content</strong>\nGit objects can contain both text (UTF-8) and binary content. When displaying object content for debugging, handle encoding errors gracefully and clearly distinguish between text and binary data to avoid corrupting the debugging output itself.</p>\n<h4 id=\"tracing-object-relationships\">Tracing Object Relationships</h4>\n<p>Git&#39;s object model forms a directed acyclic graph where commits point to trees, trees point to blobs and subtrees, and commits can have multiple parents. Bugs often involve incorrect relationships in this graph, so tracing these relationships is a crucial debugging technique.</p>\n<table>\n<thead>\n<tr>\n<th>Relationship Type</th>\n<th>Validation Method</th>\n<th>Common Issues</th>\n<th>Debugging Approach</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Commit → Tree</td>\n<td>Verify tree hash in commit object exists and is valid tree</td>\n<td>Commit references non-existent tree</td>\n<td>Trace tree creation during commit process</td>\n</tr>\n<tr>\n<td>Tree → Blob/Subtree</td>\n<td>Check all tree entries reference valid objects of correct type</td>\n<td>Tree entry points to blob but declares mode as directory</td>\n<td>Validate tree building algorithm</td>\n</tr>\n<tr>\n<td>Commit → Parent</td>\n<td>Ensure parent hashes reference valid commit objects</td>\n<td>Commit parent chain broken or circular</td>\n<td>Graph traversal to detect cycles</td>\n</tr>\n<tr>\n<td>Branch → Commit</td>\n<td>Verify branch reference points to valid commit</td>\n<td>Branch reference corrupted or points to non-commit object</td>\n<td>Check reference update logic</td>\n</tr>\n<tr>\n<td>Index → Blob</td>\n<td>Confirm staged files reference valid blob objects</td>\n<td>Index entry hash doesn&#39;t match stored blob</td>\n<td>Debug file staging process</td>\n</tr>\n</tbody></table>\n<p>The most effective relationship tracing involves building a complete graph of your repository&#39;s objects and validating that it matches expected Git invariants. This can reveal subtle bugs like commits that reference trees built incorrectly, or index entries that point to non-existent blobs.</p>\n<blockquote>\n<p><strong>Critical Debugging Insight</strong>: Object relationship bugs often cascade—a corrupted tree leads to a corrupted commit, which leads to a corrupted branch reference. Always trace problems back to their root cause in the dependency graph rather than fixing symptoms at higher levels.</p>\n</blockquote>\n<h4 id=\"validating-repository-consistency\">Validating Repository Consistency</h4>\n<p>A well-formed Git repository must satisfy numerous consistency invariants, and validating these invariants systematically can catch bugs that would otherwise be difficult to reproduce or diagnose.</p>\n<table>\n<thead>\n<tr>\n<th>Consistency Check</th>\n<th>Validation Rule</th>\n<th>Implementation</th>\n<th>Common Violations</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Object reachability</td>\n<td>All referenced objects exist and are accessible</td>\n<td>Graph traversal from all branch heads</td>\n<td>Dangling references, missing objects</td>\n</tr>\n<tr>\n<td>Hash integrity</td>\n<td>Stored object hash matches computed hash of content</td>\n<td>Recompute hash for every stored object</td>\n<td>Hash computation bugs, storage corruption</td>\n</tr>\n<tr>\n<td>Reference validity</td>\n<td>All references point to valid objects of expected type</td>\n<td>Validate reference targets</td>\n<td>References pointing to non-existent or wrong-type objects</td>\n</tr>\n<tr>\n<td>Index consistency</td>\n<td>All index entries reference valid blobs with correct metadata</td>\n<td>Compare index entries to actual blobs and filesystem</td>\n<td>Staged files don&#39;t match working directory or stored blobs</td>\n</tr>\n<tr>\n<td>Tree structure validity</td>\n<td>Tree objects properly represent directory hierarchy</td>\n<td>Validate tree entry formats and recursive structure</td>\n<td>Malformed tree entries, incorrect permissions</td>\n</tr>\n</tbody></table>\n<p>Implementing a comprehensive repository validation function provides a systematic way to detect corruption and verify that your implementation maintains Git&#39;s invariants correctly.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> validate_repository_consistency</span><span style=\"color:#E1E4E8\">(git_dir: Path) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Comprehensive repository validation that checks all Git invariants.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns list of consistency violations found.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    violations </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate all objects in .git/objects have correct hash</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check that all references point to valid objects</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Verify index entries reference existing blobs</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate tree objects have proper entry format</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check commit objects have valid parent references</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Ensure no circular references in commit history</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Verify working directory matches HEAD commit + index</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> violations</span></span></code></pre></div>\n\n<p><strong>⚠️ Pitfall: Performance of Full Validation</strong>\nRepository validation can be expensive for large repositories. Implement incremental validation that focuses on recently modified objects, and provide full validation as a separate diagnostic tool rather than running it automatically.</p>\n<p><strong>⚠️ Pitfall: Validation During Intermediate States</strong>\nSome Git operations go through intermediate states where the repository temporarily violates consistency rules. For example, during a merge, the working directory might not match any single commit. Design validation to account for these legitimate intermediate states.</p>\n<h4 id=\"debugging-workflow-integration\">Debugging Workflow Integration</h4>\n<p>Effective Git debugging requires integrating diagnostic capabilities into your normal development workflow, so that problems can be detected and diagnosed quickly rather than accumulating until they cause major failures.</p>\n<table>\n<thead>\n<tr>\n<th>Integration Point</th>\n<th>Diagnostic Capability</th>\n<th>Implementation Strategy</th>\n<th>Benefit</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Object storage</td>\n<td>Automatic hash verification</td>\n<td>Verify stored object can be retrieved and matches original</td>\n<td>Catch storage bugs immediately</td>\n</tr>\n<tr>\n<td>Commit creation</td>\n<td>Tree validation</td>\n<td>Ensure generated tree matches working directory structure</td>\n<td>Detect tree building bugs</td>\n</tr>\n<tr>\n<td>Merge operations</td>\n<td>State consistency checks</td>\n<td>Validate repository state at each merge step</td>\n<td>Prevent merge corruption</td>\n</tr>\n<tr>\n<td>Index operations</td>\n<td>Metadata validation</td>\n<td>Check that index metadata matches filesystem</td>\n<td>Catch staging bugs early</td>\n</tr>\n<tr>\n<td>Reference updates</td>\n<td>Atomicity verification</td>\n<td>Ensure reference updates are atomic and consistent</td>\n<td>Prevent reference corruption</td>\n</tr>\n</tbody></table>\n<p>The key insight is that debugging capabilities should be built into the core operations, not added as an afterthought. This allows problems to be detected at their source rather than discovered much later when their effects become visible.</p>\n<p><strong>⚠️ Pitfall: Debug Code Affecting Performance</strong>\nExtensive validation and logging can significantly impact performance. Design debug features to be easily disabled in production builds, or implement them as optional validation passes that can be enabled when problems are suspected.</p>\n<p><strong>⚠️ Pitfall: Debug Output Affecting Test Results</strong>\nWhen implementing diagnostic logging, ensure that debug output doesn&#39;t interfere with normal program output that tests might depend on. Use separate streams for debug output, or implement a logging system that can be configured to different levels of verbosity.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>Building effective debugging capabilities requires a systematic approach that integrates diagnostic tools into your Git implementation from the beginning. The debugging infrastructure should be designed to help you understand not just what went wrong, but why it went wrong and how to prevent similar issues in the future.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Logging</td>\n<td>Python&#39;s <code>logging</code> module with file handlers</td>\n<td>Structured logging with JSON output for analysis</td>\n</tr>\n<tr>\n<td>Validation</td>\n<td>Simple assertion-based checks</td>\n<td>Property-based testing with hypothesis</td>\n</tr>\n<tr>\n<td>Object inspection</td>\n<td>Manual hex dump utilities</td>\n<td>Custom binary parser with formatted output</td>\n</tr>\n<tr>\n<td>State debugging</td>\n<td>Print statements with manual formatting</td>\n<td>Interactive debugger integration with repository state</td>\n</tr>\n<tr>\n<td>Performance profiling</td>\n<td>Basic timing with <code>time.time()</code></td>\n<td>Full profiling with <code>cProfile</code> and memory tracking</td>\n</tr>\n</tbody></table>\n<h4 id=\"debugging-infrastructure-starter-code\">Debugging Infrastructure Starter Code</h4>\n<p>Here&#39;s a complete debugging infrastructure that provides comprehensive diagnostic capabilities for your Git implementation:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> hashlib</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> zlib</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> struct</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional, Any, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ValidationLevel</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    MINIMAL</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"minimal\"</span><span style=\"color:#6A737D\">      # Only critical invariants</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    STANDARD</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"standard\"</span><span style=\"color:#6A737D\">    # Common consistency checks  </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    COMPREHENSIVE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"comprehensive\"</span><span style=\"color:#6A737D\">  # Full repository validation</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ValidationResult</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    is_valid: </span><span style=\"color:#79B8FF\">bool</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    violations: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    warnings: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    validation_time: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> GitDebugger</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Comprehensive debugging and validation toolkit for Git implementations.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Provides object inspection, consistency checking, and diagnostic utilities.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, git_dir: Path):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.git_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_dir</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.objects_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"objects\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.refs_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"refs\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.index_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"index\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.head_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"HEAD\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Set up logging</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> logging.getLogger(</span><span style=\"color:#9ECBFF\">\"git_debugger\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        handler </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> logging.FileHandler(git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"debug.log\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        handler.setFormatter(logging.Formatter(</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            '</span><span style=\"color:#79B8FF\">%(asctime)s</span><span style=\"color:#9ECBFF\"> - </span><span style=\"color:#79B8FF\">%(levelname)s</span><span style=\"color:#9ECBFF\"> - </span><span style=\"color:#79B8FF\">%(message)s</span><span style=\"color:#9ECBFF\">'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ))</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.logger.addHandler(handler)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.logger.setLevel(logging.</span><span style=\"color:#79B8FF\">INFO</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> inspect_object</span><span style=\"color:#E1E4E8\">(self, object_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Comprehensive object inspection with format validation.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns detailed object structure for debugging.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            object_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._get_object_path(object_hash)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> object_path.exists():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#E1E4E8\"> {</span><span style=\"color:#9ECBFF\">\"error\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Object </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">object_hash</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> not found\"</span><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Read and decompress object</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            with</span><span style=\"color:#79B8FF\"> open</span><span style=\"color:#E1E4E8\">(object_path, </span><span style=\"color:#9ECBFF\">'rb'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> f:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                compressed_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> f.read()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                raw_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> zlib.decompress(compressed_data)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            except</span><span style=\"color:#E1E4E8\"> zlib.error </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#E1E4E8\"> {</span><span style=\"color:#9ECBFF\">\"error\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Decompression failed: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Parse header</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            null_pos </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> raw_data.find(</span><span style=\"color:#F97583\">b</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\0</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> null_pos </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#E1E4E8\"> {</span><span style=\"color:#9ECBFF\">\"error\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"Invalid object format: no null separator\"</span><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            header </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> raw_data[:null_pos].decode(</span><span style=\"color:#9ECBFF\">'utf-8'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            content </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> raw_data[null_pos </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">:]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Parse object type and size</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                obj_type, size_str </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> header.split(</span><span style=\"color:#9ECBFF\">' '</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                declared_size </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> int</span><span style=\"color:#E1E4E8\">(size_str)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            except</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#E1E4E8\"> {</span><span style=\"color:#9ECBFF\">\"error\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Invalid header format: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">header</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Validate size</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(content) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> declared_size:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    \"error\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Size mismatch: declared </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">declared_size</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">, actual </span><span style=\"color:#79B8FF\">{len</span><span style=\"color:#E1E4E8\">(content)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Verify hash</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            expected_hash </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> hashlib.sha1(raw_data).hexdigest()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> expected_hash </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> object_hash:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    \"error\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Hash mismatch: expected </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">object_hash</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">, computed </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">expected_hash</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            result </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"hash\"</span><span style=\"color:#E1E4E8\">: object_hash,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"type\"</span><span style=\"color:#E1E4E8\">: obj_type,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"size\"</span><span style=\"color:#E1E4E8\">: declared_size,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"content_preview\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._preview_content(content, obj_type),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"valid\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Type-specific parsing</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> obj_type </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> \"tree\"</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                result[</span><span style=\"color:#9ECBFF\">\"entries\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._parse_tree_entries(content)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            elif</span><span style=\"color:#E1E4E8\"> obj_type </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> \"commit\"</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                result[</span><span style=\"color:#9ECBFF\">\"commit_info\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._parse_commit_info(content)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> result</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> {</span><span style=\"color:#9ECBFF\">\"error\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Inspection failed: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_repository</span><span style=\"color:#E1E4E8\">(self, level: ValidationLevel </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ValidationLevel.</span><span style=\"color:#79B8FF\">STANDARD</span><span style=\"color:#E1E4E8\">) -> ValidationResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Comprehensive repository validation with configurable depth.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        start_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        violations </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        warnings </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> level </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> [ValidationLevel.</span><span style=\"color:#79B8FF\">STANDARD</span><span style=\"color:#E1E4E8\">, ValidationLevel.</span><span style=\"color:#79B8FF\">COMPREHENSIVE</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                violations.extend(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._validate_object_store())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                violations.extend(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._validate_references())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                violations.extend(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._validate_index())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> level </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> ValidationLevel.</span><span style=\"color:#79B8FF\">COMPREHENSIVE</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                violations.extend(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._validate_object_relationships())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                violations.extend(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._validate_working_directory())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                warnings.extend(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._check_performance_issues())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            validation_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            is_valid </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(violations) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> ValidationResult(is_valid, violations, warnings, validation_time)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            violations.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Validation failed with error: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> ValidationResult(</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">, violations, warnings, time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> trace_object_relationships</span><span style=\"color:#E1E4E8\">(self, start_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, max_depth: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Trace object relationships from a starting object (typically a commit).</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns graph structure showing all reachable objects.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        visited </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> set</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        relationships </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        queue </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [(start_hash, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        while</span><span style=\"color:#E1E4E8\"> queue </span><span style=\"color:#F97583\">and</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(visited) </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 1000</span><span style=\"color:#E1E4E8\">:  </span><span style=\"color:#6A737D\"># Safety limit</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            obj_hash, depth </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> queue.pop(</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> obj_hash </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> visited </span><span style=\"color:#F97583\">or</span><span style=\"color:#E1E4E8\"> depth </span><span style=\"color:#F97583\">></span><span style=\"color:#E1E4E8\"> max_depth:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                continue</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            visited.add(obj_hash)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            obj_info </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.inspect_object(obj_hash)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#9ECBFF\"> \"error\"</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> obj_info:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                relationships[obj_hash] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span><span style=\"color:#9ECBFF\">\"error\"</span><span style=\"color:#E1E4E8\">: obj_info[</span><span style=\"color:#9ECBFF\">\"error\"</span><span style=\"color:#E1E4E8\">], </span><span style=\"color:#9ECBFF\">\"depth\"</span><span style=\"color:#E1E4E8\">: depth}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                continue</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            relationships[obj_hash] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"type\"</span><span style=\"color:#E1E4E8\">: obj_info[</span><span style=\"color:#9ECBFF\">\"type\"</span><span style=\"color:#E1E4E8\">],</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"depth\"</span><span style=\"color:#E1E4E8\">: depth,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"references\"</span><span style=\"color:#E1E4E8\">: []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Find referenced objects</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> obj_info[</span><span style=\"color:#9ECBFF\">\"type\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> \"commit\"</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                commit_info </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> obj_info.get(</span><span style=\"color:#9ECBFF\">\"commit_info\"</span><span style=\"color:#E1E4E8\">, {})</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#9ECBFF\"> \"tree\"</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> commit_info:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    queue.append((commit_info[</span><span style=\"color:#9ECBFF\">\"tree\"</span><span style=\"color:#E1E4E8\">], depth </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    relationships[obj_hash][</span><span style=\"color:#9ECBFF\">\"references\"</span><span style=\"color:#E1E4E8\">].append(commit_info[</span><span style=\"color:#9ECBFF\">\"tree\"</span><span style=\"color:#E1E4E8\">])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                for</span><span style=\"color:#E1E4E8\"> parent </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> commit_info.get(</span><span style=\"color:#9ECBFF\">\"parents\"</span><span style=\"color:#E1E4E8\">, []):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    queue.append((parent, depth </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    relationships[obj_hash][</span><span style=\"color:#9ECBFF\">\"references\"</span><span style=\"color:#E1E4E8\">].append(parent)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            elif</span><span style=\"color:#E1E4E8\"> obj_info[</span><span style=\"color:#9ECBFF\">\"type\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> \"tree\"</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                for</span><span style=\"color:#E1E4E8\"> entry </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> obj_info.get(</span><span style=\"color:#9ECBFF\">\"entries\"</span><span style=\"color:#E1E4E8\">, []):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    entry_hash </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> entry.get(</span><span style=\"color:#9ECBFF\">\"hash\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    if</span><span style=\"color:#E1E4E8\"> entry_hash:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        queue.append((entry_hash, depth </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        relationships[obj_hash][</span><span style=\"color:#9ECBFF\">\"references\"</span><span style=\"color:#E1E4E8\">].append(entry_hash)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"start_object\"</span><span style=\"color:#E1E4E8\">: start_hash,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"total_objects\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">len</span><span style=\"color:#E1E4E8\">(relationships),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"max_depth_reached\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">max</span><span style=\"color:#E1E4E8\">(r.get(</span><span style=\"color:#9ECBFF\">\"depth\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> r </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> relationships.values()),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"relationships\"</span><span style=\"color:#E1E4E8\">: relationships</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> diagnose_merge_failure</span><span style=\"color:#E1E4E8\">(self, our_commit: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, their_commit: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Comprehensive merge failure diagnosis.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        diagnosis </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"our_commit\"</span><span style=\"color:#E1E4E8\">: our_commit,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"their_commit\"</span><span style=\"color:#E1E4E8\">: their_commit,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"issues\"</span><span style=\"color:#E1E4E8\">: [],</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"recommendations\"</span><span style=\"color:#E1E4E8\">: []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Validate input commits</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        our_info </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.inspect_object(our_commit)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        their_info </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.inspect_object(their_commit)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#9ECBFF\"> \"error\"</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> our_info:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            diagnosis[</span><span style=\"color:#9ECBFF\">\"issues\"</span><span style=\"color:#E1E4E8\">].append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Our commit invalid: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">our_info[</span><span style=\"color:#9ECBFF\">'error'</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#9ECBFF\"> \"error\"</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> their_info:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            diagnosis[</span><span style=\"color:#9ECBFF\">\"issues\"</span><span style=\"color:#E1E4E8\">].append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Their commit invalid: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">their_info[</span><span style=\"color:#9ECBFF\">'error'</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> diagnosis[</span><span style=\"color:#9ECBFF\">\"issues\"</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> diagnosis</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Try to find merge base</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            merge_base </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._find_merge_base_debug(our_commit, their_commit)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> merge_base:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                diagnosis[</span><span style=\"color:#9ECBFF\">\"merge_base\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> merge_base</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                base_info </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.inspect_object(merge_base)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#9ECBFF\"> \"error\"</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> base_info:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    diagnosis[</span><span style=\"color:#9ECBFF\">\"issues\"</span><span style=\"color:#E1E4E8\">].append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Merge base corrupted: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">base_info[</span><span style=\"color:#9ECBFF\">'error'</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                diagnosis[</span><span style=\"color:#9ECBFF\">\"issues\"</span><span style=\"color:#E1E4E8\">].append(</span><span style=\"color:#9ECBFF\">\"No common ancestor found\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                diagnosis[</span><span style=\"color:#9ECBFF\">\"recommendations\"</span><span style=\"color:#E1E4E8\">].append(</span><span style=\"color:#9ECBFF\">\"Check if commits are from same repository\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            diagnosis[</span><span style=\"color:#9ECBFF\">\"issues\"</span><span style=\"color:#E1E4E8\">].append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Merge base calculation failed: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Analyze tree differences</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            our_tree </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> our_info[</span><span style=\"color:#9ECBFF\">\"commit_info\"</span><span style=\"color:#E1E4E8\">][</span><span style=\"color:#9ECBFF\">\"tree\"</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            their_tree </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> their_info[</span><span style=\"color:#9ECBFF\">\"commit_info\"</span><span style=\"color:#E1E4E8\">][</span><span style=\"color:#9ECBFF\">\"tree\"</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            tree_diff </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._analyze_tree_differences(our_tree, their_tree)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            diagnosis[</span><span style=\"color:#9ECBFF\">\"tree_analysis\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> tree_diff</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> tree_diff[</span><span style=\"color:#9ECBFF\">\"binary_conflicts\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                diagnosis[</span><span style=\"color:#9ECBFF\">\"recommendations\"</span><span style=\"color:#E1E4E8\">].append(</span><span style=\"color:#9ECBFF\">\"Binary file conflicts require manual resolution\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> tree_diff[</span><span style=\"color:#9ECBFF\">\"large_files\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                diagnosis[</span><span style=\"color:#9ECBFF\">\"recommendations\"</span><span style=\"color:#E1E4E8\">].append(</span><span style=\"color:#9ECBFF\">\"Large file conflicts may cause performance issues\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            diagnosis[</span><span style=\"color:#9ECBFF\">\"issues\"</span><span style=\"color:#E1E4E8\">].append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Tree analysis failed: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> diagnosis</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Helper methods for internal functionality</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _get_object_path</span><span style=\"color:#E1E4E8\">(self, object_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Path:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Convert object hash to filesystem path.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.objects_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> object_hash[:</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> object_hash[</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">:]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _preview_content</span><span style=\"color:#E1E4E8\">(self, content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">, obj_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate human-readable content preview.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> obj_type </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> \"blob\"</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Try to decode as text, fall back to hex for binary</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                text </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> content.decode(</span><span style=\"color:#9ECBFF\">'utf-8'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(text) </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 200</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    return</span><span style=\"color:#E1E4E8\"> text[:</span><span style=\"color:#79B8FF\">200</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">+</span><span style=\"color:#9ECBFF\"> \"...\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#E1E4E8\"> text</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            except</span><span style=\"color:#79B8FF\"> UnicodeDecodeError</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"&#x3C;binary content, </span><span style=\"color:#79B8FF\">{len</span><span style=\"color:#E1E4E8\">(content)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> bytes>\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # For tree and commit objects, always try text first</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#E1E4E8\"> content.decode(</span><span style=\"color:#9ECBFF\">'utf-8'</span><span style=\"color:#E1E4E8\">)[:</span><span style=\"color:#79B8FF\">500</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            except</span><span style=\"color:#79B8FF\"> UnicodeDecodeError</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#E1E4E8\"> content.hex()[:</span><span style=\"color:#79B8FF\">100</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">+</span><span style=\"color:#9ECBFF\"> \"...\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _parse_tree_entries</span><span style=\"color:#E1E4E8\">(self, content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> List[Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Parse tree object entries for inspection.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        entries </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        offset </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        while</span><span style=\"color:#E1E4E8\"> offset </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(content):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Find null terminator for mode/name</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            null_pos </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> content.find(</span><span style=\"color:#F97583\">b</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\0</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">, offset)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> null_pos </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                break</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            mode_name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> content[offset:null_pos].decode(</span><span style=\"color:#9ECBFF\">'utf-8'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                mode, name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> mode_name.split(</span><span style=\"color:#9ECBFF\">' '</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            except</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                break</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Extract 20-byte hash</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> null_pos </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 21</span><span style=\"color:#F97583\"> ></span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(content):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                break</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            hash_bytes </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> content[null_pos </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">:null_pos </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 21</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            hash_hex </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> hash_bytes.hex()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            entries.append({</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"mode\"</span><span style=\"color:#E1E4E8\">: mode,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"name\"</span><span style=\"color:#E1E4E8\">: name,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"hash\"</span><span style=\"color:#E1E4E8\">: hash_hex</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            })</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            offset </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> null_pos </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 21</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> entries</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _parse_commit_info</span><span style=\"color:#E1E4E8\">(self, content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Parse commit object for inspection.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            text </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> content.decode(</span><span style=\"color:#9ECBFF\">'utf-8'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            lines </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> text.split(</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            info </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span><span style=\"color:#9ECBFF\">\"parents\"</span><span style=\"color:#E1E4E8\">: []}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            message_start </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            for</span><span style=\"color:#E1E4E8\"> i, line </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> enumerate</span><span style=\"color:#E1E4E8\">(lines):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> line.strip():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    message_start </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    break</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> line.startswith(</span><span style=\"color:#9ECBFF\">'tree '</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    info[</span><span style=\"color:#9ECBFF\">\"tree\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> line[</span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">:]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                elif</span><span style=\"color:#E1E4E8\"> line.startswith(</span><span style=\"color:#9ECBFF\">'parent '</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    info[</span><span style=\"color:#9ECBFF\">\"parents\"</span><span style=\"color:#E1E4E8\">].append(line[</span><span style=\"color:#79B8FF\">7</span><span style=\"color:#E1E4E8\">:])</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                elif</span><span style=\"color:#E1E4E8\"> line.startswith(</span><span style=\"color:#9ECBFF\">'author '</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    info[</span><span style=\"color:#9ECBFF\">\"author\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> line[</span><span style=\"color:#79B8FF\">7</span><span style=\"color:#E1E4E8\">:]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                elif</span><span style=\"color:#E1E4E8\"> line.startswith(</span><span style=\"color:#9ECBFF\">'committer '</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    info[</span><span style=\"color:#9ECBFF\">\"committer\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> line[</span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">:]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> message_start:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                info[</span><span style=\"color:#9ECBFF\">\"message\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> '</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">.join(lines[message_start:])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> info</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> UnicodeDecodeError</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> {</span><span style=\"color:#9ECBFF\">\"error\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"Commit content is not valid UTF-8\"</span><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _validate_object_store</span><span style=\"color:#E1E4E8\">(self) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate object store consistency.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        violations </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.objects_dir.exists():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            violations.append(</span><span style=\"color:#9ECBFF\">\"Objects directory missing\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> violations</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Check object files</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> obj_dir </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.objects_dir.iterdir():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> obj_dir.is_dir() </span><span style=\"color:#F97583\">or</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(obj_dir.name) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                continue</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            for</span><span style=\"color:#E1E4E8\"> obj_file </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> obj_dir.iterdir():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> obj_file.is_file():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    continue</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                full_hash </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> obj_dir.name </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> obj_file.name</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(full_hash) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 40</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    violations.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Invalid object filename: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">full_hash</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    continue</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # Validate object can be read and hash matches</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                obj_info </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.inspect_object(full_hash)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#9ECBFF\"> \"error\"</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> obj_info:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    violations.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Corrupted object </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">full_hash</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">obj_info[</span><span style=\"color:#9ECBFF\">'error'</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> violations</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _validate_references</span><span style=\"color:#E1E4E8\">(self) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate reference consistency.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        violations </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Check HEAD</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.head_path.exists():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            violations.append(</span><span style=\"color:#9ECBFF\">\"HEAD file missing\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                head_content </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.head_path.read_text().strip()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> head_content.startswith(</span><span style=\"color:#9ECBFF\">'ref: '</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    ref_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> head_content[</span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">:]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> ref_path.exists():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        violations.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"HEAD points to non-existent ref: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">head_content[</span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">:]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                elif</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(head_content) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 40</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                    # Direct hash - validate object exists</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._get_object_path(head_content).exists():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        violations.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"HEAD points to non-existent object: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">head_content</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    violations.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Invalid HEAD content: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">head_content</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                violations.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Cannot read HEAD: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> violations</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _validate_index</span><span style=\"color:#E1E4E8\">(self) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate index consistency.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        violations </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.index_path.exists():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> []  </span><span style=\"color:#6A737D\"># Index is optional</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            with</span><span style=\"color:#79B8FF\"> open</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.index_path, </span><span style=\"color:#9ECBFF\">'rb'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> f:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # Read index header</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                signature </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> f.read(</span><span style=\"color:#79B8FF\">4</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> signature </span><span style=\"color:#F97583\">!=</span><span style=\"color:#F97583\"> b</span><span style=\"color:#9ECBFF\">'DIRC'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    violations.append(</span><span style=\"color:#9ECBFF\">\"Invalid index signature\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    return</span><span style=\"color:#E1E4E8\"> violations</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                version </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> struct.unpack(</span><span style=\"color:#9ECBFF\">'>I'</span><span style=\"color:#E1E4E8\">, f.read(</span><span style=\"color:#79B8FF\">4</span><span style=\"color:#E1E4E8\">))[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> version </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    violations.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Unsupported index version: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">version</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    return</span><span style=\"color:#E1E4E8\"> violations</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                entry_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> struct.unpack(</span><span style=\"color:#9ECBFF\">'>I'</span><span style=\"color:#E1E4E8\">, f.read(</span><span style=\"color:#79B8FF\">4</span><span style=\"color:#E1E4E8\">))[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # Validate each entry references existing blob</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                for</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(entry_count):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        entry_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> f.read(</span><span style=\"color:#79B8FF\">62</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Fixed portion of entry</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                        if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(entry_data) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 62</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                            violations.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Truncated index entry </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">i</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                            break</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                        # Extract hash (20 bytes starting at offset 40)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        hash_bytes </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> entry_data[</span><span style=\"color:#79B8FF\">40</span><span style=\"color:#E1E4E8\">:</span><span style=\"color:#79B8FF\">60</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        hash_hex </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> hash_bytes.hex()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                        # Check if blob exists</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._get_object_path(hash_hex).exists():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                            violations.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Index entry </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">i</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> references non-existent blob: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">hash_hex</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                        # Skip variable-length path name</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        flags </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> struct.unpack(</span><span style=\"color:#9ECBFF\">'>H'</span><span style=\"color:#E1E4E8\">, entry_data[</span><span style=\"color:#79B8FF\">60</span><span style=\"color:#E1E4E8\">:</span><span style=\"color:#79B8FF\">62</span><span style=\"color:#E1E4E8\">])[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        name_length </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> flags </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#F97583\"> 0x</span><span style=\"color:#79B8FF\">fff</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        f.read(name_length)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                        # Skip padding</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        total_read </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 62</span><span style=\"color:#F97583\"> +</span><span style=\"color:#E1E4E8\"> name_length</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        padding </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">8</span><span style=\"color:#F97583\"> -</span><span style=\"color:#E1E4E8\"> (total_read </span><span style=\"color:#F97583\">%</span><span style=\"color:#79B8FF\"> 8</span><span style=\"color:#E1E4E8\">)) </span><span style=\"color:#F97583\">%</span><span style=\"color:#79B8FF\"> 8</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        f.read(padding)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        violations.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Error reading index entry </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">i</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                        break</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            violations.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Cannot read index: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> violations</span></span></code></pre></div>\n\n<p>This debugging infrastructure provides comprehensive diagnostic capabilities that will help you identify and resolve issues throughout your Git implementation development.</p>\n<h2 id=\"future-extensions\">Future Extensions</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section goes beyond the eight core milestones, exploring advanced Git features that could be added to extend the basic implementation. Understanding these extensions helps architects plan for scalability and provides a roadmap for evolving the system.</p>\n</blockquote>\n<p>Building a basic Git implementation teaches the fundamental concepts of distributed version control, but Git&#39;s true power comes from its advanced features that enable large-scale collaboration and efficient storage. This section explores two critical extensions that transform a working but basic Git implementation into a production-ready system: remote repository support for distributed collaboration and pack file optimization for efficient storage.</p>\n<h3 id=\"mental-model-the-local-shop-goes-global\">Mental Model: The Local Shop Goes Global</h3>\n<p>Think of our current Git implementation as a successful local bookstore. The store has excellent organization (object storage), efficient inventory management (index), clear categorization (references), and a good return policy (merge conflict resolution). Customers love shopping there, but they can only visit in person.</p>\n<p>Now imagine the bookstore wants to expand globally. They need two major capabilities: <strong>shipping and receiving</strong> (remote repository support) to exchange books with other locations, and <strong>warehouse optimization</strong> (pack files) to store thousands of books efficiently instead of keeping each book in its own individual box.</p>\n<p>Remote repository support is like building a shipping network - books (objects) need to be packaged, addressed, sent, received, unpacked, and integrated into the local inventory. Pack file optimization is like switching from individual book boxes to efficient warehouse shelving - instead of storing each book separately, related books are grouped together and compressed to save space.</p>\n<h3 id=\"remote-repository-support\">Remote Repository Support</h3>\n<p>Remote repository support transforms Git from a local version control system into a distributed collaboration platform. This extension adds the ability to synchronize changes with other repositories through push, pull, and fetch operations while maintaining the integrity of the content-addressable object store.</p>\n<h4 id=\"understanding-remote-operations\">Understanding Remote Operations</h4>\n<p>The fundamental challenge of remote repository support is <strong>object synchronization</strong> - determining which objects exist in each repository and transferring only the missing ones. Unlike simple file synchronization, Git&#39;s content-addressable storage enables sophisticated optimizations because identical content always has identical hashes regardless of repository location.</p>\n<p>Each remote operation follows a similar pattern: <strong>discovery, negotiation, transfer, and integration</strong>. The discovery phase determines what references (branches and tags) exist in each repository. The negotiation phase computes the minimal set of objects needed to bring repositories into sync. The transfer phase moves objects efficiently across the network. The integration phase updates local references and working directory to reflect the new state.</p>\n<blockquote>\n<p><strong>Key Insight</strong>: Remote operations are fundamentally about moving objects and updating references. The content-addressable nature of Git&#39;s object store makes this conceptually simple - if two repositories have the same object hash, they have identical content. The complexity lies in efficiently determining what needs to be transferred and handling reference conflicts.</p>\n</blockquote>\n<h4 id=\"remote-repository-data-model\">Remote Repository Data Model</h4>\n<p>The remote system extends our existing architecture with several new components that manage distributed state and network operations.</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Purpose</th>\n<th>Storage Location</th>\n<th>Key Responsibilities</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>RemoteRepository</code></td>\n<td>Represents connection to remote Git repository</td>\n<td><code>.git/config</code> file</td>\n<td>URL management, authentication, protocol selection</td>\n</tr>\n<tr>\n<td><code>RemoteReferenceStore</code></td>\n<td>Tracks remote branch and tag states</td>\n<td><code>.git/refs/remotes/</code></td>\n<td>Remote reference caching, tracking branch relationships</td>\n</tr>\n<tr>\n<td><code>TransferProtocol</code></td>\n<td>Handles network communication with remote repositories</td>\n<td>Memory/network</td>\n<td>Object discovery, negotiation, data transfer</td>\n</tr>\n<tr>\n<td><code>PackProtocol</code></td>\n<td>Efficient object transfer format for network operations</td>\n<td>Memory/temporary files</td>\n<td>Object bundling, progress reporting, error recovery</td>\n</tr>\n<tr>\n<td><code>RefSpec</code></td>\n<td>Maps local and remote reference names</td>\n<td><code>.git/config</code></td>\n<td>Branch mapping rules, push/fetch behavior configuration</td>\n</tr>\n</tbody></table>\n<h4 id=\"fetch-operation-architecture\">Fetch Operation Architecture</h4>\n<p>The <strong>fetch operation</strong> retrieves objects and references from a remote repository without modifying the local working directory or current branch. This is the foundation operation that pull builds upon.</p>\n<p>The fetch algorithm follows these detailed steps:</p>\n<ol>\n<li><p><strong>Remote Discovery</strong>: Connect to the remote repository and retrieve the complete list of references (branches and tags) with their current commit hashes. This uses Git&#39;s upload-pack protocol to get an advertisement of all available references.</p>\n</li>\n<li><p><strong>Reference Analysis</strong>: Compare remote references against local remote-tracking branches stored in <code>.git/refs/remotes/origin/</code> to determine which references have changed since the last fetch.</p>\n</li>\n<li><p><strong>Object Graph Walking</strong>: Starting from new or updated remote references, walk backward through the commit graph to identify all objects (commits, trees, blobs) that exist in the remote repository but are missing from the local object store.</p>\n</li>\n<li><p><strong>Want/Have Negotiation</strong>: Send the remote repository a list of object hashes we &quot;want&quot; (missing objects) and &quot;have&quot; (existing objects). The remote responds with the minimal set of objects needed to satisfy our wants without sending objects we already possess.</p>\n</li>\n<li><p><strong>Pack File Reception</strong>: Receive a compressed pack file containing all requested objects in dependency order. Objects are transmitted in a format that allows streaming processing without requiring the entire pack file in memory.</p>\n</li>\n<li><p><strong>Object Extraction</strong>: Decompress and validate each object from the pack file, then store it in the local object store using the standard <code>.git/objects/xx/yy...</code> directory structure.</p>\n</li>\n<li><p><strong>Reference Updates</strong>: Update remote-tracking branches in <code>.git/refs/remotes/origin/</code> to reflect the current state of the remote repository. These references show what the remote looked like at fetch time.</p>\n</li>\n<li><p><strong>Fast-Forward Analysis</strong>: For each local branch that tracks a remote branch, determine if the local branch can be fast-forwarded to match the remote state (when the local branch is a direct ancestor of the remote).</p>\n</li>\n</ol>\n<h4 id=\"push-operation-architecture\">Push Operation Architecture</h4>\n<p>The <strong>push operation</strong> sends local objects and reference updates to a remote repository, requiring careful handling of concurrent modifications and reference conflicts.</p>\n<p>Push is more complex than fetch because it modifies the remote repository state, which may conflict with concurrent changes from other users. The push algorithm implements these steps:</p>\n<ol>\n<li><p><strong>Pre-Push Validation</strong>: Verify that all local references being pushed point to valid commits in the local object store and that the user has appropriate permissions for the target remote repository.</p>\n</li>\n<li><p><strong>Remote Reference Check</strong>: Retrieve current remote references to detect if any branches being pushed have been modified by other users since the last fetch. This prevents accidentally overwriting concurrent work.</p>\n</li>\n<li><p><strong>Fast-Forward Verification</strong>: For each branch being pushed, verify that the push represents a fast-forward update (the remote branch is an ancestor of the local branch) unless force push is explicitly enabled.</p>\n</li>\n<li><p><strong>Object Dependency Analysis</strong>: Walk the commit graph from local branch tips back to the last known remote state, collecting all objects that need to be transmitted to the remote repository.</p>\n</li>\n<li><p><strong>Pack File Generation</strong>: Create a pack file containing all objects that exist locally but are missing from the remote repository. Objects are compressed and ordered to optimize transmission efficiency.</p>\n</li>\n<li><p><strong>Atomic Push Transaction</strong>: Send the pack file and reference updates to the remote repository as an atomic transaction. Either all references update successfully, or none do, preventing partial updates that could corrupt remote repository state.</p>\n</li>\n<li><p><strong>Reference Conflict Resolution</strong>: If remote references have changed during the push operation, abort the push and require the user to fetch latest changes and resolve conflicts locally before retrying.</p>\n</li>\n<li><p><strong>Success Confirmation</strong>: Receive confirmation from the remote repository that all objects were stored successfully and all references were updated atomically.</p>\n</li>\n</ol>\n<h4 id=\"remote-reference-management\">Remote Reference Management</h4>\n<p>Remote-tracking branches solve the problem of maintaining local knowledge about remote repository state without interfering with local development. These references use a separate namespace to avoid conflicts with local branches.</p>\n<table>\n<thead>\n<tr>\n<th>Reference Type</th>\n<th>Storage Location</th>\n<th>Format</th>\n<th>Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Local Branch</td>\n<td><code>.git/refs/heads/feature</code></td>\n<td><code>commit_hash</code></td>\n<td>Local development work</td>\n</tr>\n<tr>\n<td>Remote Branch</td>\n<td><code>.git/refs/remotes/origin/feature</code></td>\n<td><code>commit_hash</code></td>\n<td>Last known state of remote branch</td>\n</tr>\n<tr>\n<td>Tracking Relationship</td>\n<td><code>.git/config</code></td>\n<td><code>[branch &quot;feature&quot;] remote = origin merge = refs/heads/feature</code></td>\n<td>Links local and remote branches</td>\n</tr>\n</tbody></table>\n<p>The tracking relationship enables Git to provide helpful information about branch divergence - whether the local branch is ahead, behind, or has diverged from its remote counterpart.</p>\n<h4 id=\"pull-operation-as-fetch-merge\">Pull Operation as Fetch + Merge</h4>\n<p>The <strong>pull operation</strong> combines fetch with automatic merging, implementing the common workflow of retrieving remote changes and integrating them into the current local branch.</p>\n<p>Pull executes as two distinct phases:</p>\n<ol>\n<li><p><strong>Fetch Phase</strong>: Execute a complete fetch operation to retrieve all remote objects and update remote-tracking branches. This ensures local knowledge of remote state is current.</p>\n</li>\n<li><p><strong>Integration Phase</strong>: Merge the updated remote-tracking branch into the current local branch using the three-way merge algorithm implemented in Milestone 8. If conflicts arise, they are presented to the user for manual resolution.</p>\n</li>\n</ol>\n<p>The integration phase supports multiple strategies:</p>\n<ul>\n<li><strong>Merge Strategy</strong>: Create a merge commit that combines local and remote changes, preserving the parallel development history</li>\n<li><strong>Rebase Strategy</strong>: Replay local commits on top of the remote branch, creating a linear history without merge commits</li>\n<li><strong>Fast-Forward Strategy</strong>: If the local branch hasn&#39;t diverged, simply update the local branch pointer to match the remote</li>\n</ul>\n<blockquote>\n<p><strong>Decision: Pull Integration Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Pull operations need to integrate remote changes into local branches, but different projects prefer different history structures</li>\n<li><strong>Options Considered</strong>: Always merge, always rebase, configurable per repository, configurable per branch</li>\n<li><strong>Decision</strong>: Default to merge with configuration options for rebase and fast-forward-only modes</li>\n<li><strong>Rationale</strong>: Merge preserves complete history and is safest for beginners, while advanced users can configure alternative strategies per their workflow needs</li>\n<li><strong>Consequences</strong>: More complex pull implementation but supports both simple and advanced workflows without forcing a single approach</li>\n</ul>\n</blockquote>\n<h4 id=\"protocol-implementation-considerations\">Protocol Implementation Considerations</h4>\n<p>Git&#39;s network protocols have evolved to optimize performance and security for distributed collaboration. The modern protocol supports multiple transport layers and advanced features.</p>\n<table>\n<thead>\n<tr>\n<th>Protocol Feature</th>\n<th>HTTP(S) Transport</th>\n<th>SSH Transport</th>\n<th>Local Filesystem</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Authentication</td>\n<td>Username/password, tokens</td>\n<td>SSH keys, agents</td>\n<td>File permissions</td>\n</tr>\n<tr>\n<td>Encryption</td>\n<td>TLS</td>\n<td>SSH tunnel</td>\n<td>None needed</td>\n</tr>\n<tr>\n<td>Firewall Friendly</td>\n<td>Yes (port 80/443)</td>\n<td>No (port 22)</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>Performance</td>\n<td>Good</td>\n<td>Excellent</td>\n<td>Excellent</td>\n</tr>\n<tr>\n<td>Setup Complexity</td>\n<td>Medium</td>\n<td>High</td>\n<td>Low</td>\n</tr>\n</tbody></table>\n<p>The protocol implements several optimizations:</p>\n<ul>\n<li><strong>Multi-round Negotiation</strong>: Multiple rounds of want/have negotiation minimize transferred objects</li>\n<li><strong>Thin Packs</strong>: Pack files can reference objects assumed to exist in the destination repository</li>\n<li><strong>Progress Reporting</strong>: Long operations provide progress feedback for user experience</li>\n<li><strong>Resumable Transfers</strong>: Large transfers can resume after network interruptions</li>\n</ul>\n<h4 id=\"architecture-decision-records-for-remote-support\">Architecture Decision Records for Remote Support</h4>\n<blockquote>\n<p><strong>Decision: Remote Configuration Storage</strong></p>\n<ul>\n<li><strong>Context</strong>: Remote repository URLs, authentication, and mapping rules need persistent storage</li>\n<li><strong>Options Considered</strong>: Separate remote config file, embed in main .git/config, database storage</li>\n<li><strong>Decision</strong>: Extend existing .git/config file with [remote] and [branch] sections</li>\n<li><strong>Rationale</strong>: Maintains compatibility with existing Git configuration patterns, supports version control of configuration, enables per-repository customization</li>\n<li><strong>Consequences</strong>: Config file becomes more complex but remains human-readable and editable</li>\n</ul>\n</blockquote>\n<blockquote>\n<p><strong>Decision: Object Transfer Batching</strong></p>\n<ul>\n<li><strong>Context</strong>: Large repositories may have thousands of objects to transfer, requiring efficient batching</li>\n<li><strong>Options Considered</strong>: Transfer all objects in single batch, fixed-size batches, adaptive batching based on network conditions</li>\n<li><strong>Decision</strong>: Implement adaptive batching with fallback to smaller batches on network errors</li>\n<li><strong>Rationale</strong>: Optimizes for fast networks while providing resilience on unreliable connections</li>\n<li><strong>Consequences</strong>: More complex transfer logic but better user experience across different network conditions</li>\n</ul>\n</blockquote>\n<h3 id=\"pack-file-optimization\">Pack File Optimization</h3>\n<p>Pack files transform Git&#39;s storage efficiency by replacing individual compressed objects with highly optimized compressed bundles that use delta compression and cross-object deduplication.</p>\n<h4 id=\"understanding-the-storage-efficiency-problem\">Understanding the Storage Efficiency Problem</h4>\n<p>Our current object store implementation stores each blob, tree, and commit as an individual zlib-compressed file. While this provides excellent simplicity and reliability, it has significant storage inefficiencies for real-world repositories:</p>\n<ul>\n<li><strong>Similar Content Duplication</strong>: Multiple versions of the same file share most content but are stored completely separately. A single-line change to a large file results in two complete compressed copies.</li>\n<li><strong>Small Object Overhead</strong>: Each object requires a minimum file system block (typically 4KB), so a 100-byte commit object wastes ~3900 bytes of storage.</li>\n<li><strong>Directory Fragmentation</strong>: Thousands of small files in <code>.git/objects/</code> create file system performance problems and backup inefficiencies.</li>\n</ul>\n<p>Pack files solve these problems by implementing <strong>delta compression</strong> - storing one version of a file completely, then storing subsequent versions as compact diffs against the base version.</p>\n<h4 id=\"mental-model-the-efficient-warehouse\">Mental Model: The Efficient Warehouse</h4>\n<p>Think of our current object storage as a warehouse where every item, no matter how similar, gets its own labeled box. If you stock 50 different versions of the same book that only differ in minor edits, you need 50 complete boxes.</p>\n<p>Pack files are like an efficient warehouse manager who says: &quot;Let&#39;s keep one complete copy of the first edition, then for each subsequent edition, just store a note saying &#39;same as first edition but change page 247 paragraph 2&#39;.&quot; The warehouse still contains all versions, but uses dramatically less space.</p>\n<p>The warehouse manager also batches related items together - instead of individual boxes scattered throughout the warehouse, related items are grouped on the same shelf for efficient access.</p>\n<h4 id=\"pack-file-data-structure\">Pack File Data Structure</h4>\n<p>A pack file consists of a header, a series of packed objects, and an index for efficient random access. The structure optimizes for both storage efficiency and access performance.</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Size</th>\n<th>Purpose</th>\n<th>Format</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Pack Header</td>\n<td>12 bytes</td>\n<td>File format identification</td>\n<td><code>PACK</code> signature + version + object count</td>\n</tr>\n<tr>\n<td>Packed Objects</td>\n<td>Variable</td>\n<td>Compressed object data with delta chains</td>\n<td>Type + size + compressed data or delta instructions</td>\n</tr>\n<tr>\n<td>Pack Checksum</td>\n<td>20 bytes</td>\n<td>Data integrity verification</td>\n<td>SHA-1 hash of all preceding pack data</td>\n</tr>\n<tr>\n<td>Pack Index</td>\n<td>Separate file</td>\n<td>Fast object lookup by hash</td>\n<td>Sorted hash table with offset pointers</td>\n</tr>\n</tbody></table>\n<h4 id=\"delta-compression-algorithm\">Delta Compression Algorithm</h4>\n<p>Delta compression identifies similar objects and stores only the differences, achieving dramatic space savings for repositories with many similar files.</p>\n<p>The delta compression algorithm works as follows:</p>\n<ol>\n<li><p><strong>Base Object Selection</strong>: For each object being packed, identify potential base objects that share significant content. Heuristics prioritize objects with similar paths, sizes, and content signatures.</p>\n</li>\n<li><p><strong>Delta Generation</strong>: Create a delta script that transforms the base object into the target object. The delta consists of copy instructions (copy N bytes from offset X in base) and insert instructions (insert these literal bytes).</p>\n</li>\n<li><p><strong>Chain Length Management</strong>: Limit delta chains to prevent excessive decompression overhead. If Object C is a delta of Object B, which is a delta of Object A, accessing Object C requires decompressing A, then B, then C.</p>\n</li>\n<li><p><strong>Size Efficiency Verification</strong>: Only use delta compression when it actually saves space. Sometimes small files or completely different files are more efficient stored as complete objects.</p>\n</li>\n<li><p><strong>Access Pattern Optimization</strong>: Place frequently accessed objects (recent commits, popular branches) early in the pack file and avoid long delta chains for objects likely to be accessed frequently.</p>\n</li>\n</ol>\n<h4 id=\"pack-index-structure\">Pack Index Structure</h4>\n<p>The pack index enables efficient random access to objects within pack files without scanning the entire pack. The index uses a sophisticated multi-level structure optimized for both space and lookup performance.</p>\n<table>\n<thead>\n<tr>\n<th>Index Level</th>\n<th>Purpose</th>\n<th>Structure</th>\n<th>Access Time</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Hash Fanout Table</td>\n<td>First-level lookup by hash prefix</td>\n<td>256 entries (one per hash byte value)</td>\n<td>O(1)</td>\n</tr>\n<tr>\n<td>Object Hash Table</td>\n<td>Sorted list of all object hashes in pack</td>\n<td>20-byte SHA-1 hashes in sorted order</td>\n<td>O(log n)</td>\n</tr>\n<tr>\n<td>CRC Checksums</td>\n<td>Integrity verification for individual objects</td>\n<td>4-byte CRC per object</td>\n<td>O(1)</td>\n</tr>\n<tr>\n<td>Pack Offsets</td>\n<td>File positions of objects within pack file</td>\n<td>4 or 8-byte offsets depending on pack size</td>\n<td>O(1)</td>\n</tr>\n</tbody></table>\n<p>The index lookup algorithm:</p>\n<ol>\n<li>Use the first byte of the target object hash to index into the fanout table</li>\n<li>Binary search the hash table segment identified by the fanout table</li>\n<li>If hash is found, retrieve the corresponding pack offset</li>\n<li>Seek to that offset in the pack file and read the object data</li>\n<li>Verify object integrity using the stored CRC checksum</li>\n</ol>\n<h4 id=\"garbage-collection-and-pack-generation\">Garbage Collection and Pack Generation</h4>\n<p>Garbage collection transforms loose objects into efficient pack files and removes objects that are no longer reachable from any reference.</p>\n<p>The garbage collection process implements these phases:</p>\n<ol>\n<li><p><strong>Reachability Analysis</strong>: Starting from all references (branches, tags, HEAD), walk the complete object graph to identify all reachable objects. Any object not reachable from a reference is considered garbage.</p>\n</li>\n<li><p><strong>Pack Candidate Selection</strong>: Group objects into logical packs based on access patterns. Typically, recent objects accessed together are packed together, while historical objects form separate packs.</p>\n</li>\n<li><p><strong>Delta Base Selection</strong>: For each object, identify optimal delta bases using heuristics based on path similarity, size, and content. This is computationally expensive but critical for pack efficiency.</p>\n</li>\n<li><p><strong>Pack Generation</strong>: Create pack files with objects ordered to optimize delta compression and access patterns. Recent commits and trees are typically placed early in packs.</p>\n</li>\n<li><p><strong>Index Generation</strong>: Build pack index files that enable efficient random access to packed objects without decompressing the entire pack.</p>\n</li>\n<li><p><strong>Atomic Replacement</strong>: Atomically replace loose objects with pack files, ensuring repository integrity is maintained even if the process is interrupted.</p>\n</li>\n<li><p><strong>Cleanup</strong>: Remove loose objects that are now redundant with packed versions, and remove old pack files that have been superseded.</p>\n</li>\n</ol>\n<h4 id=\"integration-with-existing-object-store\">Integration with Existing Object Store</h4>\n<p>Pack file support extends our existing <code>ObjectStore</code> component without breaking existing functionality. The enhanced object store checks both loose objects and pack files when retrieving objects.</p>\n<table>\n<thead>\n<tr>\n<th>Operation</th>\n<th>Loose Objects</th>\n<th>Pack Files</th>\n<th>Combined Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Store Object</td>\n<td>Write to <code>.git/objects/xx/yy...</code></td>\n<td>N/A (packs are read-only after creation)</td>\n<td>New objects always stored loose initially</td>\n</tr>\n<tr>\n<td>Retrieve Object</td>\n<td>Check <code>.git/objects/</code> first</td>\n<td>Search pack indexes if not found loose</td>\n<td>Transparent to callers</td>\n</tr>\n<tr>\n<td>Object Exists</td>\n<td>Scan directory</td>\n<td>Search pack indexes</td>\n<td>Return true if found in either location</td>\n</tr>\n<tr>\n<td>List All Objects</td>\n<td>Directory traversal</td>\n<td>Parse all pack indexes</td>\n<td>Union of loose and packed objects</td>\n</tr>\n</tbody></table>\n<p>The object retrieval algorithm becomes:</p>\n<ol>\n<li>Check for loose object at <code>.git/objects/xx/yy...</code></li>\n<li>If found, decompress and return</li>\n<li>If not found, search all pack indexes for the object hash</li>\n<li>If found in pack, seek to pack offset and decompress object (following delta chain if necessary)</li>\n<li>If not found anywhere, return object not found error</li>\n</ol>\n<h4 id=\"architecture-decision-records-for-pack-files\">Architecture Decision Records for Pack Files</h4>\n<blockquote>\n<p><strong>Decision: Delta Chain Length Limits</strong></p>\n<ul>\n<li><strong>Context</strong>: Long delta chains save more space but increase access time for individual objects</li>\n<li><strong>Options Considered</strong>: No limit (maximum compression), fixed limit of 10, adaptive limit based on object access frequency</li>\n<li><strong>Decision</strong>: Implement fixed limit of 50 with shorter limits for frequently accessed objects</li>\n<li><strong>Rationale</strong>: Balances storage efficiency with access performance, prevents pathological cases where accessing one object requires decompressing hundreds of deltas</li>\n<li><strong>Consequences</strong>: Some compression efficiency is sacrificed for predictable access performance</li>\n</ul>\n</blockquote>\n<blockquote>\n<p><strong>Decision: Pack File Size Limits</strong></p>\n<ul>\n<li><strong>Context</strong>: Large pack files are more efficient but harder to transfer and backup</li>\n<li><strong>Options Considered</strong>: No size limit, 2GB limit (32-bit offset compatibility), 4GB limit, multiple size tiers</li>\n<li><strong>Decision</strong>: 2GB size limit with automatic pack splitting for larger repositories</li>\n<li><strong>Rationale</strong>: Maintains compatibility with systems that have 32-bit limitations while supporting large repositories through multiple packs</li>\n<li><strong>Consequences</strong>: More complex pack management but broader system compatibility</li>\n</ul>\n</blockquote>\n<h4 id=\"performance-impact-analysis\">Performance Impact Analysis</h4>\n<p>Pack file optimization provides dramatic improvements in storage efficiency and some operations, while slightly impacting others.</p>\n<table>\n<thead>\n<tr>\n<th>Operation</th>\n<th>Storage Impact</th>\n<th>Performance Impact</th>\n<th>Network Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Repository Size</td>\n<td>60-90% reduction typical</td>\n<td>N/A</td>\n<td>Faster clones and fetches</td>\n</tr>\n<tr>\n<td>Object Retrieval</td>\n<td>N/A</td>\n<td>Slightly slower (delta decompression)</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>Garbage Collection</td>\n<td>Enables cleanup of unreachable objects</td>\n<td>CPU intensive during pack generation</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>Backup/Transfer</td>\n<td>Much smaller repository size</td>\n<td>N/A</td>\n<td>Dramatically faster</td>\n</tr>\n</tbody></table>\n<p>The storage savings are particularly dramatic for repositories with:</p>\n<ul>\n<li>Many small commits (reduces per-object overhead)</li>\n<li>Large files with incremental changes (delta compression)</li>\n<li>Long history (more opportunities for similar content)</li>\n</ul>\n<p>Typical compression ratios:</p>\n<ul>\n<li><strong>Text-heavy repositories</strong>: 70-85% size reduction</li>\n<li><strong>Binary-heavy repositories</strong>: 30-60% size reduction  </li>\n<li><strong>Mixed repositories</strong>: 60-80% size reduction</li>\n</ul>\n<h3 id=\"integration-considerations\">Integration Considerations</h3>\n<p>Both remote repository support and pack file optimization integrate cleanly with the existing eight-milestone architecture without requiring fundamental changes to core components.</p>\n<h4 id=\"compatibility-with-existing-components\">Compatibility with Existing Components</h4>\n<p>The extensions maintain full compatibility with existing functionality:</p>\n<ul>\n<li><strong>Object Store</strong>: Enhanced to check both loose objects and pack files transparently</li>\n<li><strong>References</strong>: Remote-tracking branches use the same reference format as local branches</li>\n<li><strong>Index</strong>: Unchanged - staging area works identically with packed and loose objects</li>\n<li><strong>Merge Algorithm</strong>: Unchanged - operates on object content regardless of storage format</li>\n<li><strong>Diff Algorithm</strong>: Unchanged - compares object content regardless of storage location</li>\n</ul>\n<h4 id=\"migration-strategy\">Migration Strategy</h4>\n<p>Implementing these extensions follows a progressive enhancement approach:</p>\n<ol>\n<li><strong>Phase 1</strong>: Add remote repository configuration and basic fetch/push without pack file support</li>\n<li><strong>Phase 2</strong>: Implement pack file reading to support repositories that already contain pack files</li>\n<li><strong>Phase 3</strong>: Add pack file generation during garbage collection</li>\n<li><strong>Phase 4</strong>: Optimize remote operations to use pack protocol for efficient transfers</li>\n</ol>\n<p>This approach allows the system to evolve incrementally while maintaining full functionality at each stage.</p>\n<h3 id=\"common-pitfalls\">Common Pitfalls</h3>\n<p>⚠️ <strong>Pitfall: Ignoring Network Failure Recovery</strong>\nWhen implementing remote operations, developers often assume network operations will succeed. In reality, network transfers can fail at any point, leaving repositories in inconsistent states. Always implement atomic operations where either all references update successfully or none do. Use temporary files for pack reception and atomic rename operations for reference updates.</p>\n<p>⚠️ <strong>Pitfall: Delta Chain Performance Degradation</strong>\nLong delta chains can make individual object access extremely slow, especially for frequently accessed objects like recent commits. Implement delta chain length limits and prioritize recent/frequently accessed objects as delta bases rather than targets. Monitor access patterns and repack when performance degrades.</p>\n<p>⚠️ <strong>Pitfall: Pack Index Corruption Handling</strong>\nPack indexes can become corrupted, making objects inaccessible even though they exist in the pack file. Always verify pack index integrity on startup and implement index regeneration from pack files. Never trust index entries without verifying the corresponding pack file data.</p>\n<p>⚠️ <strong>Pitfall: Concurrent Access to Pack Files</strong>\nMultiple processes may try to read pack files simultaneously, or garbage collection may try to delete packs while they&#39;re being read. Implement proper file locking for pack operations and use atomic operations for pack replacement. Consider delayed deletion of old pack files to allow ongoing operations to complete.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The implementation of these advanced features requires careful attention to network protocols, binary file formats, and concurrent access patterns. The following guidance provides a foundation for building production-ready extensions.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>HTTP Transport</td>\n<td><code>urllib3</code> with basic auth</td>\n<td><code>requests</code> with session management and retry logic</td>\n</tr>\n<tr>\n<td>SSH Transport</td>\n<td><code>subprocess</code> calls to <code>ssh</code> command</td>\n<td><code>paramiko</code> library for pure Python SSH</td>\n</tr>\n<tr>\n<td>Pack File I/O</td>\n<td><code>struct</code> module for binary formats</td>\n<td><code>mmap</code> for efficient large file access</td>\n</tr>\n<tr>\n<td>Delta Compression</td>\n<td>Custom implementation following Git format</td>\n<td><code>python-delta</code> library if available</td>\n</tr>\n<tr>\n<td>Network Protocol</td>\n<td>Simple HTTP POST/GET</td>\n<td>Full Git smart HTTP protocol</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Remote repository support</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">remote</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    __init__</span><span style=\"color:#E1E4E8\">.py</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    protocols</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        __init__</span><span style=\"color:#E1E4E8\">.py</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        http_transport.py      </span><span style=\"color:#6A737D\"># HTTP/HTTPS transport implementation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ssh_transport.py       </span><span style=\"color:#6A737D\"># SSH transport implementation  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        local_transport.py     </span><span style=\"color:#6A737D\"># Local filesystem transport</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    operations</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        __init__</span><span style=\"color:#E1E4E8\">.py</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        fetch.py              </span><span style=\"color:#6A737D\"># Fetch operation implementation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        push.py               </span><span style=\"color:#6A737D\"># Push operation implementation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        pull.py               </span><span style=\"color:#6A737D\"># Pull operation (fetch + merge)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    config</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        __init__</span><span style=\"color:#E1E4E8\">.py</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        remote_config.py      </span><span style=\"color:#6A737D\"># Remote repository configuration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        refspec.py            </span><span style=\"color:#6A737D\"># Reference specification parsing</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Pack file support  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">pack</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    __init__</span><span style=\"color:#E1E4E8\">.py</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    pack_file.py             </span><span style=\"color:#6A737D\"># Pack file reading and writing</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    pack_index.py            </span><span style=\"color:#6A737D\"># Pack index management</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    delta.py                 </span><span style=\"color:#6A737D\"># Delta compression implementation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    garbage_collection.py    </span><span style=\"color:#6A737D\"># GC and pack generation</span></span></code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p>Here&#39;s complete infrastructure code for basic remote configuration management:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">#!/usr/bin/env python3</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Remote repository configuration management.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Complete implementation ready for use.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> configparser</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> urllib.parse </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> urlparse</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> RemoteConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Manages remote repository configuration in .git/config file.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, git_dir: Path):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.git_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_dir</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> git_dir </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"config\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> configparser.ConfigParser()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.config_path.exists():</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.config.read(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.config_path)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> add_remote</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, url: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, fetch_refspec: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Add a new remote repository configuration.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> fetch_refspec </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            fetch_refspec </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"+refs/heads/*:refs/remotes/</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">/*\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        section_name </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"remote </span><span style=\"color:#79B8FF\">\\\"{</span><span style=\"color:#E1E4E8\">name</span><span style=\"color:#79B8FF\">}\\\"</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config[section_name] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'url'</span><span style=\"color:#E1E4E8\">: url,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'fetch'</span><span style=\"color:#E1E4E8\">: fetch_refspec</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._save_config()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> remove_remote</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Remove a remote repository configuration.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        section_name </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"remote </span><span style=\"color:#79B8FF\">\\\"{</span><span style=\"color:#E1E4E8\">name</span><span style=\"color:#79B8FF\">}\\\"</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> section_name </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.config:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.config.remove_section(section_name)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._save_config()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_remote_url</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get URL for named remote.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        section_name </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"remote </span><span style=\"color:#79B8FF\">\\\"{</span><span style=\"color:#E1E4E8\">name</span><span style=\"color:#79B8FF\">}\\\"</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> section_name </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.config:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.config[section_name].get(</span><span style=\"color:#9ECBFF\">'url'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> list_remotes</span><span style=\"color:#E1E4E8\">(self) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"List all configured remote names.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        remotes </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> section </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.config.sections():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> section.startswith(</span><span style=\"color:#9ECBFF\">'remote \"'</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # Extract name from 'remote \"origin\"' format</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> section[</span><span style=\"color:#79B8FF\">8</span><span style=\"color:#E1E4E8\">:</span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">]  </span><span style=\"color:#6A737D\"># Remove 'remote \"' and '\"'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                remotes.append(name)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> remotes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_fetch_refspecs</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get fetch refspecs for named remote.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        section_name </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"remote </span><span style=\"color:#79B8FF\">\\\"{</span><span style=\"color:#E1E4E8\">name</span><span style=\"color:#79B8FF\">}\\\"</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> section_name </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.config:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            fetch_spec </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.config[section_name].get(</span><span style=\"color:#9ECBFF\">'fetch'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">''</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> [fetch_spec] </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> fetch_spec </span><span style=\"color:#F97583\">else</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _save_config</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Save configuration to .git/config file.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> open</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.config_path, </span><span style=\"color:#9ECBFF\">'w'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> f:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.config.write(f)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> RefSpec</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Parses and manages Git refspecs for push/fetch operations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, refspec: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.refspec </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> refspec</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.force </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> refspec.startswith(</span><span style=\"color:#9ECBFF\">'+'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        spec </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> refspec[</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">:] </span><span style=\"color:#F97583\">if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.force </span><span style=\"color:#F97583\">else</span><span style=\"color:#E1E4E8\"> refspec</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#9ECBFF\"> ':'</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> spec:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.source, </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.destination </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> spec.split(</span><span style=\"color:#9ECBFF\">':'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.source </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> spec</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.destination </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> spec</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> matches_ref</span><span style=\"color:#E1E4E8\">(self, ref: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Check if this refspec matches the given reference.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#9ECBFF\"> '*'</span><span style=\"color:#F97583\"> in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.source:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Handle wildcard matching</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            prefix </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.source[:</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.source.index(</span><span style=\"color:#9ECBFF\">'*'</span><span style=\"color:#E1E4E8\">)]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> ref.startswith(prefix)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> ref </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.source</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> transform_ref</span><span style=\"color:#E1E4E8\">(self, ref: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Transform source ref to destination using this refspec.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#9ECBFF\"> '*'</span><span style=\"color:#F97583\"> in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.source </span><span style=\"color:#F97583\">and</span><span style=\"color:#9ECBFF\"> '*'</span><span style=\"color:#F97583\"> in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.destination:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Handle wildcard transformation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            prefix </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.source[:</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.source.index(</span><span style=\"color:#9ECBFF\">'*'</span><span style=\"color:#E1E4E8\">)]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            suffix </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ref[</span><span style=\"color:#79B8FF\">len</span><span style=\"color:#E1E4E8\">(prefix):]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            dest_prefix </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.destination[:</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.destination.index(</span><span style=\"color:#9ECBFF\">'*'</span><span style=\"color:#E1E4E8\">)]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> dest_prefix </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> suffix</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.destination</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Network transport helper</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> HTTPTransport</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Simple HTTP transport for Git operations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, base_url: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.base_url </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> base_url.rstrip(</span><span style=\"color:#9ECBFF\">'/'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> discover_refs</span><span style=\"color:#E1E4E8\">(self, service: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> List[Tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Discover available references on remote repository.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        import</span><span style=\"color:#E1E4E8\"> urllib.request</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        url </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.base_url</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">/info/refs?service=</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">service</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            with</span><span style=\"color:#E1E4E8\"> urllib.request.urlopen(url) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> response:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # Parse Git's advertisement format</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                refs </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                for</span><span style=\"color:#E1E4E8\"> line </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> response:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    line </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> line.decode(</span><span style=\"color:#9ECBFF\">'utf-8'</span><span style=\"color:#E1E4E8\">).strip()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    if</span><span style=\"color:#E1E4E8\"> line </span><span style=\"color:#F97583\">and</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> line.startswith(</span><span style=\"color:#9ECBFF\">'#'</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        parts </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> line.split(</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\t</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                        if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(parts) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                            hash_val, ref_name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> parts</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                            refs.append((ref_name, hash_val))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#E1E4E8\"> refs</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Failed to discover refs: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> []</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeleton-code\">Core Logic Skeleton Code</h4>\n<p>Here are the skeleton implementations for the main remote operations:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">#!/usr/bin/env python3</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Core remote operations - fetch, push, pull.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Skeletons for learner implementation.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional, Set, Tuple</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> FetchOperation</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Implements git fetch operation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, repository, object_store, reference_manager, remote_config):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.repository </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> repository</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.object_store </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> object_store</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.reference_manager </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> reference_manager</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.remote_config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> remote_config</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> fetch</span><span style=\"color:#E1E4E8\">(self, remote_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, refspecs: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Fetch objects and references from remote repository.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns mapping of updated references to their new commit hashes.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Get remote URL from configuration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Discover available references on remote repository  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Determine which references need updating based on refspecs</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Calculate missing objects using want/have negotiation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Request pack file containing missing objects from remote</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Receive and validate pack file from remote</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Extract objects from pack file and store in object store</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Update remote-tracking references in .git/refs/remotes/</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 9: Return mapping of updated references</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use _discover_remote_refs(), _negotiate_objects(), _receive_pack()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _discover_remote_refs</span><span style=\"color:#E1E4E8\">(self, remote_url: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> List[Tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Discover what references exist on the remote repository.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Connect to remote repository using appropriate transport</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Send upload-pack request to get reference advertisement</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Parse response to extract (ref_name, commit_hash) pairs</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return list of available references</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Different transports (HTTP, SSH, local) have different protocols</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _negotiate_objects</span><span style=\"color:#E1E4E8\">(self, remote_refs: List[Tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]]) -> Set[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Determine which objects need to be fetched from remote.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Identify commit hashes we want (from remote refs we're fetching)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Walk local object store to identify commit hashes we have</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Send want/have lists to remote repository</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Receive response indicating which objects will be sent</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return set of object hashes that will be transferred</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: This minimizes network transfer by avoiding duplicate objects</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _receive_pack</span><span style=\"color:#E1E4E8\">(self, expected_objects: Set[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]) -> Path:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Receive pack file containing requested objects.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Receive pack file header with object count</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Stream pack file data to temporary file</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Validate pack file checksum</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Verify pack contains expected objects</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return path to temporary pack file</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Pack files can be large - stream to disk, don't buffer in memory</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> PushOperation</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Implements git push operation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, repository, object_store, reference_manager, remote_config):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.repository </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> repository</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.object_store </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> object_store</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.reference_manager </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> reference_manager</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.remote_config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> remote_config</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> push</span><span style=\"color:#E1E4E8\">(self, remote_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, refspecs: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">], force: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> False</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Push local references and objects to remote repository.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns mapping of pushed references to their commit hashes.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Get remote URL and discover current remote references</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Validate push refspecs and check for conflicts</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify fast-forward requirement unless force=True</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Calculate objects that need to be sent to remote</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Generate pack file containing required objects</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Send pack file and reference updates atomically</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Verify remote accepted all updates successfully</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Update local remote-tracking references</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 9: Return mapping of successfully pushed references</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Push must be atomic - either all refs update or none do</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _verify_fast_forward</span><span style=\"color:#E1E4E8\">(self, local_ref: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, remote_ref: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, force: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Verify that push represents a fast-forward update.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Get commit hash for local reference</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Get commit hash for remote reference  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: If force=True, allow any update</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Check if remote commit is ancestor of local commit</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return True only if update is fast-forward or forced</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use commit graph traversal to check ancestry</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _generate_pack_file</span><span style=\"color:#E1E4E8\">(self, required_objects: Set[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]) -> Path:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate pack file containing objects to send to remote.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create temporary pack file</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Write pack header with object count</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Write each object in dependency order (commits, trees, blobs)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Apply delta compression where beneficial</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Write pack file checksum</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return path to completed pack file</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Objects must be ordered so dependencies come before referents</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Pack file skeleton implementation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> PackFile</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Reads and writes Git pack files.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, pack_path: Path):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.pack_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> pack_path</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.index_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> pack_path.with_suffix(</span><span style=\"color:#9ECBFF\">'.idx'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> read_object</span><span style=\"color:#E1E4E8\">(self, object_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Optional[Tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Read an object from this pack file.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Look up object hash in pack index to get offset</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Seek to offset in pack file</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Read object header (type and size)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: If object is delta, resolve delta chain</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Decompress object content</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return (object_type, content) tuple</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Delta objects require recursive resolution</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _resolve_delta_chain</span><span style=\"color:#E1E4E8\">(self, offset: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Resolve delta chain to get final object content.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Read delta object at given offset</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Identify base object (by offset or hash)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Recursively resolve base object content</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Apply delta instructions to base content</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return final reconstructed content</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Delta chains can be deep - avoid stack overflow</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p>After implementing remote repository support:</p>\n<p><strong>Checkpoint 1: Basic Remote Configuration</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test remote configuration</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from remote.config.remote_config import RemoteConfig</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from pathlib import Path</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">config = RemoteConfig(Path('.git'))</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">config.add_remote('origin', 'https://github.com/user/repo.git')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">print('Remotes:', config.list_remotes())</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">print('Origin URL:', config.get_remote_url('origin'))</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected: Shows 'origin' in remote list with correct URL</span></span></code></pre></div>\n\n<p><strong>Checkpoint 2: Reference Discovery</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test remote reference discovery</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from remote.operations.fetch import FetchOperation</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\"># Should connect to remote and list available branches/tags</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\"># Expected: List of (ref_name, commit_hash) pairs</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span></code></pre></div>\n\n<p>After implementing pack file support:</p>\n<p><strong>Checkpoint 3: Pack File Reading</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Create a pack file and verify reading</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from pack.pack_file import PackFile</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\"># Should be able to read existing pack files</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\"># Expected: Successfully retrieve objects from pack</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span></code></pre></div>\n\n<p><strong>Checkpoint 4: Repository Size Comparison</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Compare repository size before/after packing</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">du</span><span style=\"color:#79B8FF\"> -sh</span><span style=\"color:#9ECBFF\"> .git/objects</span><span style=\"color:#6A737D\">  # Before packing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Run garbage collection with pack generation</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">du</span><span style=\"color:#79B8FF\"> -sh</span><span style=\"color:#9ECBFF\"> .git/objects</span><span style=\"color:#6A737D\">  # After packing - should be much smaller</span></span></code></pre></div>\n\n<h4 id=\"debugging-tips-for-remote-operations\">Debugging Tips for Remote Operations</h4>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Fetch hangs forever</td>\n<td>Network timeout or incorrect URL</td>\n<td>Check network connectivity, verify URL format</td>\n<td>Add timeout handling, validate URLs</td>\n</tr>\n<tr>\n<td>Objects missing after fetch</td>\n<td>Pack file corruption or incomplete transfer</td>\n<td>Verify pack file checksum, check object count</td>\n<td>Re-fetch with integrity verification</td>\n</tr>\n<tr>\n<td>Push rejected</td>\n<td>Non-fast-forward update or permissions</td>\n<td>Check if remote branch has new commits</td>\n<td>Fetch first, merge conflicts, then push</td>\n</tr>\n<tr>\n<td>Pack files not found</td>\n<td>Index corruption or missing pack files</td>\n<td>List <code>.git/objects/pack/</code> directory contents</td>\n<td>Regenerate pack indexes or re-clone</td>\n</tr>\n</tbody></table>\n<h4 id=\"performance-monitoring\">Performance Monitoring</h4>\n<p>Track key metrics when implementing these extensions:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> RemoteOperationMetrics</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Track performance metrics for remote operations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.objects_transferred </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.bytes_transferred </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.operation_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0.0</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.network_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0.0</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.compression_ratio </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> log_fetch_completed</span><span style=\"color:#E1E4E8\">(self, objects: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, bytes_total: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, duration: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Log successful fetch operation metrics.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Fetch completed: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">objects</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> objects, </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">bytes_total</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> bytes, </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">duration</span><span style=\"color:#F97583\">:.2f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">s\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Transfer rate: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">bytes_total </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> duration </span><span style=\"color:#F97583\">/</span><span style=\"color:#79B8FF\"> 1024</span><span style=\"color:#F97583\">:.1f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> KB/s\"</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p>These extensions transform the basic Git implementation into a system capable of handling real-world distributed development workflows and large-scale repositories efficiently.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Remote Transport</td>\n<td><code>urllib3</code> with basic HTTP</td>\n<td><code>requests</code> with session pooling and retry logic</td>\n</tr>\n<tr>\n<td>Pack File I/O</td>\n<td><code>struct</code> module for binary parsing</td>\n<td><code>mmap</code> for efficient large file access</td>\n</tr>\n<tr>\n<td>Delta Compression</td>\n<td>Basic diff implementation</td>\n<td>Optimized Myers algorithm with binary search</td>\n</tr>\n<tr>\n<td>Network Protocol</td>\n<td>Simple request/response</td>\n<td>Full Git smart protocol with capability negotiation</td>\n</tr>\n<tr>\n<td>Concurrency</td>\n<td>Sequential operations</td>\n<td><code>asyncio</code> for concurrent fetch/push operations</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Extensions to existing structure</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">extensions</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    remote</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        __init__</span><span style=\"color:#E1E4E8\">.py</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        transport</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            __init__</span><span style=\"color:#E1E4E8\">.py</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            http_transport.py      </span><span style=\"color:#6A737D\"># HTTP/HTTPS protocol implementation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            ssh_transport.py       </span><span style=\"color:#6A737D\"># SSH protocol implementation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            protocol.py            </span><span style=\"color:#6A737D\"># Git wire protocol parsing</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        operations</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            __init__</span><span style=\"color:#E1E4E8\">.py</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            fetch.py              </span><span style=\"color:#6A737D\"># Fetch operation with negotiation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            push.py               </span><span style=\"color:#6A737D\"># Push with conflict detection</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            pull.py               </span><span style=\"color:#6A737D\"># Pull as fetch + merge</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        config</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            __init__</span><span style=\"color:#E1E4E8\">.py</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            remote_manager.py     </span><span style=\"color:#6A737D\"># Remote repository management</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            refspec_parser.py     </span><span style=\"color:#6A737D\"># Reference specification handling</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    pack</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        __init__</span><span style=\"color:#E1E4E8\">.py</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        pack_reader.py           </span><span style=\"color:#6A737D\"># Read existing pack files</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        pack_writer.py           </span><span style=\"color:#6A737D\"># Create new pack files</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        pack_index.py            </span><span style=\"color:#6A737D\"># Pack index management</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        delta_compression.py     </span><span style=\"color:#6A737D\"># Delta encoding/decoding</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        garbage_collector.py     </span><span style=\"color:#6A737D\"># Pack generation and cleanup</span></span></code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p>Complete network transport implementation:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">#!/usr/bin/env python3</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Git HTTP transport implementation.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Production-ready code for network operations.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> urllib.request</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> urllib.parse</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> GitHTTPTransport</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Handles Git smart HTTP protocol operations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, base_url: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, username: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">, password: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.base_url </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> base_url.rstrip(</span><span style=\"color:#9ECBFF\">'/'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.username </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> username</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.password </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> password</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._setup_auth()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _setup_auth</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Configure HTTP authentication if credentials provided.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.username </span><span style=\"color:#F97583\">and</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.password:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            password_mgr </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> urllib.request.HTTPPasswordMgrWithDefaultRealm()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            password_mgr.add_password(</span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.base_url, </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.username, </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.password)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            auth_handler </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> urllib.request.HTTPBasicAuthHandler(password_mgr)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            opener </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> urllib.request.build_opener(auth_handler)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            urllib.request.install_opener(opener)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> discover_refs</span><span style=\"color:#E1E4E8\">(self, service: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> List[Tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Discover available references on remote repository.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Service should be 'git-upload-pack' for fetch or 'git-receive-pack' for push.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        url </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.base_url</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">/info/refs?service=</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">service</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            request </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> urllib.request.Request(url)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            request.add_header(</span><span style=\"color:#9ECBFF\">'User-Agent'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'git/2.0 (custom-implementation)'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            with</span><span style=\"color:#E1E4E8\"> urllib.request.urlopen(request, </span><span style=\"color:#FFAB70\">timeout</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">30</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> response:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # Parse Git smart HTTP protocol response</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                refs </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                lines </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> response.read().decode(</span><span style=\"color:#9ECBFF\">'utf-8'</span><span style=\"color:#E1E4E8\">).splitlines()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # Skip protocol header lines</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                for</span><span style=\"color:#E1E4E8\"> line </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> lines:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    if</span><span style=\"color:#E1E4E8\"> line.startswith(</span><span style=\"color:#9ECBFF\">'#'</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                        continue</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    if</span><span style=\"color:#9ECBFF\"> '</span><span style=\"color:#79B8FF\">\\t</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> line:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        hash_and_caps, ref_name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> line.split(</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\t</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                        # Remove capability advertisements</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        object_hash </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> hash_and_caps.split(</span><span style=\"color:#9ECBFF\">' '</span><span style=\"color:#E1E4E8\">)[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                        if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(object_hash) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 40</span><span style=\"color:#E1E4E8\">:  </span><span style=\"color:#6A737D\"># Valid SHA-1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                            refs.append((ref_name, object_hash))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#E1E4E8\"> refs</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#E1E4E8\"> urllib.error.URLError </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> ConnectionError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Failed to connect to </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">url</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> RuntimeError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Error discovering refs: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> send_pack_request</span><span style=\"color:#E1E4E8\">(self, service: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, request_data: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Send pack request and receive response.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        url </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.base_url</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">/</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">service</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        request </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> urllib.request.Request(url, </span><span style=\"color:#FFAB70\">data</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">request_data)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        request.add_header(</span><span style=\"color:#9ECBFF\">'Content-Type'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">'application/x-</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">service</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">-request'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        request.add_header(</span><span style=\"color:#9ECBFF\">'Accept'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">'application/x-</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">service</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">-result'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        request.add_header(</span><span style=\"color:#9ECBFF\">'User-Agent'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'git/2.0 (custom-implementation)'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            with</span><span style=\"color:#E1E4E8\"> urllib.request.urlopen(request, </span><span style=\"color:#FFAB70\">timeout</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">300</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> response:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#E1E4E8\"> response.read()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#E1E4E8\"> urllib.error.HTTPError </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            error_msg </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> e.read().decode(</span><span style=\"color:#9ECBFF\">'utf-8'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> e.fp </span><span style=\"color:#F97583\">else</span><span style=\"color:#79B8FF\"> str</span><span style=\"color:#E1E4E8\">(e)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> RuntimeError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Server error </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e.code</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">error_msg</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> RuntimeError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Network error: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> PackProtocolHandler</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Handles Git pack protocol for efficient object transfer.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">staticmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> create_want_have_request</span><span style=\"color:#E1E4E8\">(wants: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">], haves: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]) -> </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Create want/have negotiation request.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        lines </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Add want lines</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> i, want </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> enumerate</span><span style=\"color:#E1E4E8\">(wants):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # First want line includes capabilities</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                line </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"want </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">want</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> multi_ack_detailed side-band-64k ofs-delta</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                line </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"want </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">want</span><span style=\"color:#79B8FF\">}\\n</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            lines.append(PackProtocolHandler._pkt_line(line))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Separator</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        lines.append(</span><span style=\"color:#F97583\">b</span><span style=\"color:#9ECBFF\">\"0000\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Add have lines</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> have </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> haves:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            line </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"have </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">have</span><span style=\"color:#79B8FF\">}\\n</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            lines.append(PackProtocolHandler._pkt_line(line))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # End negotiation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        lines.append(PackProtocolHandler._pkt_line(</span><span style=\"color:#9ECBFF\">\"done</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> b</span><span style=\"color:#9ECBFF\">''</span><span style=\"color:#E1E4E8\">.join(lines)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">staticmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _pkt_line</span><span style=\"color:#E1E4E8\">(data: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Format data as Git packet line.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(data, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> data.encode(</span><span style=\"color:#9ECBFF\">'utf-8'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        length </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(data) </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 4</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">length</span><span style=\"color:#F97583\">:04x</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">.encode(</span><span style=\"color:#9ECBFF\">'ascii'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> data</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">staticmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> parse_pack_response</span><span style=\"color:#E1E4E8\">(response: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> Tuple[</span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">, List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Parse pack response, extracting pack data and progress messages.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        pack_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> bytearray</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        messages </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        offset </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        while</span><span style=\"color:#E1E4E8\"> offset </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(response):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Read packet length</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> offset </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 4</span><span style=\"color:#F97583\"> ></span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(response):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                break</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            length_str </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> response[offset:offset</span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\">4</span><span style=\"color:#E1E4E8\">].decode(</span><span style=\"color:#9ECBFF\">'ascii'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> length_str </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> \"0000\"</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                offset </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 4</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                continue</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                packet_length </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> int</span><span style=\"color:#E1E4E8\">(length_str, </span><span style=\"color:#79B8FF\">16</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            except</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                break</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> packet_length </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 4</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                break</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            packet_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> response[offset</span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\">4</span><span style=\"color:#E1E4E8\">:offset</span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\">packet_length]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            offset </span><span style=\"color:#F97583\">+=</span><span style=\"color:#E1E4E8\"> packet_length</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> packet_data.startswith(</span><span style=\"color:#F97583\">b</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\x01</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">):  </span><span style=\"color:#6A737D\"># Pack data</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                pack_data.extend(packet_data[</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">:])</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            elif</span><span style=\"color:#E1E4E8\"> packet_data.startswith(</span><span style=\"color:#F97583\">b</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\x02</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">):  </span><span style=\"color:#6A737D\"># Progress message</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                messages.append(packet_data[</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">:].decode(</span><span style=\"color:#9ECBFF\">'utf-8'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">errors</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">'ignore'</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> bytes</span><span style=\"color:#E1E4E8\">(pack_data), messages</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeleton-code\">Core Logic Skeleton Code</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">#!/usr/bin/env python3</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Core pack file operations.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Skeleton implementations for learner completion.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> struct</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> zlib</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional, Tuple</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> PackFileReader</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Reads objects from Git pack files.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, pack_path: Path):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.pack_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> pack_path</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.index_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> pack_path.with_suffix(</span><span style=\"color:#9ECBFF\">'.idx'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._load_index()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _load_index</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Load pack index for efficient object lookup.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Open pack index file (.idx)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Read index header and verify format version</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Read fanout table (256 4-byte entries)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Read sorted object hash list</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Read CRC checksums for each object</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Read pack file offsets for each object</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Store index data in memory for fast lookup</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Index format is big-endian, use struct.unpack('>I', data)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> has_object</span><span style=\"color:#E1E4E8\">(self, object_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Check if object exists in this pack file.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Use fanout table for fast first-level lookup</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Binary search in appropriate hash segment</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return True if hash found in index</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Fanout table maps first hash byte to index range</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> read_object</span><span style=\"color:#E1E4E8\">(self, object_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Optional[Tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Read object from pack file, resolving deltas if necessary.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Look up object offset in pack index</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Seek to offset in pack file</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Read object header (type and size)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Handle different object types (commit, tree, blob, delta)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: If delta object, resolve against base object</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Decompress final object content</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Return (object_type, content) tuple</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Delta objects require recursive resolution</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _read_object_at_offset</span><span style=\"color:#E1E4E8\">(self, offset: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Tuple[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Read raw object data at given pack file offset.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Seek to offset in pack file</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Read variable-length object header</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Determine object type and uncompressed size</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Read compressed object data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return (object_type, size, compressed_data)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Object header uses variable-length encoding</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _resolve_delta_object</span><span style=\"color:#E1E4E8\">(self, delta_data: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">, base_content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Apply delta instructions to base object content.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Parse delta header (base size, result size)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Read delta instructions (copy or insert)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: For copy instructions, copy bytes from base content</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: For insert instructions, copy literal bytes from delta</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Verify result size matches delta header</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return reconstructed object content</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Delta format: base_size, result_size, then copy/insert ops</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> PackFileWriter</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Creates Git pack files with delta compression.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, output_path: Path):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.output_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> output_path</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.objects </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.written_objects </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> add_object</span><span style=\"color:#E1E4E8\">(self, object_hash: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, object_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Add object to pack file.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Store object information for later processing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Consider delta compression against similar objects</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Add to objects list with metadata</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Don't write immediately - collect all objects first</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> write_pack</span><span style=\"color:#E1E4E8\">(self) -> Tuple[Path, Path]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Write pack file and index to disk.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Sort objects for optimal delta compression</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Write pack file header (signature, version, object count)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Write each object with delta compression where beneficial</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Write pack file checksum</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Generate pack index file</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return (pack_file_path, index_file_path)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Process objects in dependency order (commits, trees, blobs)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _find_delta_base</span><span style=\"color:#E1E4E8\">(self, target_content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">, candidates: List[</span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">]) -> Optional[</span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Find best base object for delta compression.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Compare target content against each candidate</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Calculate potential compression ratio</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Select candidate with best compression ratio</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return best base content or None if no good match</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Simple heuristic - choose candidate with most common subsequences</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _create_delta</span><span style=\"color:#E1E4E8\">(self, base_content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">, target_content: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Create delta instructions to transform base into target.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Write delta header (base size, target size)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Find common subsequences between base and target</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Generate copy instructions for common parts</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Generate insert instructions for new parts</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return complete delta data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use simple longest common subsequence algorithm</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> GarbageCollector</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Performs repository garbage collection and pack generation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, repository):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.repository </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> repository</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.reachable_objects </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> set</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> collect_garbage</span><span style=\"color:#E1E4E8\">(self, aggressive: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> False</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Run complete garbage collection cycle.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Mark all reachable objects starting from references</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Identify unreachable objects in object store</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Generate pack files for reachable objects</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Remove loose objects that are now packed</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Remove unreachable objects</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Update repository statistics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Return statistics (objects packed, bytes saved, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: This is a complex multi-phase operation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _mark_reachable_objects</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Mark all objects reachable from references.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Get all references (HEAD, branches, tags)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: For each reference, traverse object graph</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Mark commits, then trees, then blobs as reachable</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Handle circular references properly</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Store reachable object hashes in self.reachable_objects</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use breadth-first search to avoid stack overflow</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _generate_packs</span><span style=\"color:#E1E4E8\">(self, objects_to_pack: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate pack files for specified objects.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Group objects into logical packs (by age, size, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: For each pack, collect object content</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Create PackFileWriter and add all objects</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Write pack and index files</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Verify pack integrity</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Recent objects should be packed together for access efficiency</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p><strong>Remote Operations Checkpoint:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test basic remote configuration</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python3</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from extensions.remote.config.remote_manager import RemoteConfig</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from pathlib import Path</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\"># Configure remote</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">config = RemoteConfig(Path('.git'))</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">config.add_remote('origin', 'https://github.com/git/git.git')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">print('Configured remotes:', config.list_remotes())</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\"># Test reference discovery</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from extensions.remote.transport.http_transport import GitHTTPTransport</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">transport = GitHTTPTransport('https://github.com/git/git.git')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">refs = transport.discover_refs('git-upload-pack')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">print(f'Discovered {len(refs)} references')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">print('Sample refs:', refs[:5])</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected: Shows configured remote and lists remote references</span></span></code></pre></div>\n\n<p><strong>Pack File Checkpoint:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Create pack file and verify reading</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python3</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from extensions.pack.pack_reader import PackFileReader</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from extensions.pack.pack_writer import PackFileWriter</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from pathlib import Path</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\"># Find existing pack file or create one</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">pack_dir = Path('.git/objects/pack')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">if pack_dir.exists():</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    pack_files = list(pack_dir.glob('*.pack'))</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    if pack_files:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        reader = PackFileReader(pack_files[0])</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        print(f'Pack file has objects: {reader.has_object}')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected: Successfully reads pack file metadata</span></span></code></pre></div>\n\n\n<h2 id=\"glossary\">Glossary</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This comprehensive glossary applies to all eight milestones, providing essential definitions for understanding Git&#39;s architecture and implementation. It serves as a reference throughout the entire project journey.</p>\n</blockquote>\n<p>This glossary serves as the definitive reference for all technical terms, Git-specific vocabulary, architectural concepts, and domain-specific language used throughout the Build Your Own Git project. The definitions are organized to build understanding progressively, starting with foundational concepts and moving to advanced implementation details.</p>\n<h3 id=\"mental-model-the-technical-dictionary\">Mental Model: The Technical Dictionary</h3>\n<p>Think of this glossary as a specialized technical dictionary for Git internals, similar to how a medical dictionary defines terms like &quot;myocardial infarction&quot; not just as &quot;heart attack&quot; but with the precise technical meaning that medical professionals need. Each definition here goes beyond surface-level explanations to provide the exact technical understanding needed to implement Git correctly. Just as a surgeon needs to understand the precise anatomical meaning of each term, a Git implementer needs to understand the exact algorithmic and data structure implications of each concept.</p>\n<h3 id=\"core-git-concepts\">Core Git Concepts</h3>\n<p><strong>Add Operation</strong>: The process of staging files for commit by computing their blob hash, creating blob objects in the object store, and recording index entries. This operation transforms working directory files into immutable blob objects and updates the staging area to prepare for commit creation.</p>\n<p><strong>Atomic Write</strong>: A file system operation that ensures either complete success or complete failure with no partial states. Implemented by writing to a temporary file, then using rename system call to atomically replace the target file. Critical for maintaining repository consistency during concurrent access.</p>\n<p><strong>Binary File Detection</strong>: Heuristic process for identifying non-text files by analyzing a sample of bytes for non-printable characters. Uses a threshold ratio (typically 75% printable characters) to distinguish text files suitable for line-based diff operations from binary files requiring different handling.</p>\n<p><strong>Binary Format</strong>: Compact binary representation of data structures optimized for storage efficiency and parsing speed. The Git index uses binary format to store file metadata and object hashes, requiring specialized serialization and deserialization logic.</p>\n<p><strong>Blob Object</strong>: Immutable storage container for file content in Git&#39;s object model. Contains only raw file bytes with no metadata like filename or permissions. Identified by SHA-1 hash of formatted content with &quot;blob {size}\\0&quot; header.</p>\n<p><strong>Branch Namespace</strong>: Hierarchical organization of branch names using path separators, enabling logical grouping like &quot;feature/user-auth&quot; or &quot;bugfix/memory-leak&quot;. Stored as nested directories under <code>.git/refs/heads/</code> to match the namespace structure.</p>\n<p><strong>Breadth-First Search</strong>: Graph traversal algorithm used for finding merge base by exploring all commits at distance N before moving to distance N+1. Ensures discovery of the lowest common ancestor when multiple common ancestors exist.</p>\n<p><strong>Commit Graph</strong>: Directed acyclic graph structure representing project history where commits reference parent commits. Forms the backbone of Git&#39;s version control model, enabling branch and merge operations while preventing circular history.</p>\n<p><strong>Commit Object</strong>: Immutable container storing project state snapshot with metadata. Contains tree hash, parent commit hashes, author/committer information with timestamps, and commit message. Forms nodes in the commit graph representing project evolution.</p>\n<p><strong>Compression Problems</strong>: Issues with zlib compression/decompression during object storage operations. Common manifestations include corrupted objects that cannot be decompressed, hash mismatches after decompression, and performance issues with large objects.</p>\n<p><strong>Conflict Detection</strong>: Algorithm for identifying overlapping modifications during three-way merge operations. Compares changes from both branches against the common base to detect lines modified in both branches, requiring manual resolution.</p>\n<p><strong>Conflict Markers</strong>: Special text sequences delimiting merge conflicts for manual resolution. Standard format uses &quot;&lt;&lt;&lt;&lt;&lt;&lt;&lt; ours&quot;, &quot;=======&quot; separator, and &quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt; theirs&quot; markers to clearly delineate conflicting content from different branches.</p>\n<p><strong>Content-Addressable Storage</strong>: Storage system where objects are identified and retrieved using cryptographic hashes of their content. Provides automatic deduplication, integrity verification, and immutable object properties fundamental to Git&#39;s architecture.</p>\n<p><strong>Context Lines</strong>: Unchanged lines displayed around modifications in diff output to provide context for understanding changes. Typically 3 lines before and after each change, configurable based on user preferences or diff complexity.</p>\n<p><strong>Detached HEAD</strong>: Repository state where HEAD points directly to a commit hash instead of a branch reference. Occurs when checking out specific commits, creating a temporary state where new commits don&#39;t advance any branch pointer.</p>\n<p><strong>Diagonal Move</strong>: Myers diff algorithm term for matching elements between sequences, representing unchanged lines. Visualized as diagonal movement in the algorithm&#39;s grid representation, indicating no insertion or deletion needed.</p>\n<p><strong>Diff Algorithm</strong>: Algorithm for computing differences between two sequences of lines. Myers algorithm finds the shortest edit script (minimum insertions and deletions) to transform one sequence into another, optimizing for minimal change representation.</p>\n<p><strong>Direct Reference</strong>: Git reference containing a raw 40-character SHA-1 commit hash. Contrasts with symbolic references that point to other references. Used for detached HEAD state and some internal Git operations.</p>\n<p><strong>Directed Acyclic Graph</strong>: Mathematical structure where commits reference parents with no circular dependencies. Ensures Git history has clear temporal ordering while supporting multiple branches and merge operations without paradoxes.</p>\n<p><strong>Edit Distance</strong>: Minimum number of insert/delete operations needed to transform one sequence into another. Central concept in diff algorithms, with Myers algorithm optimizing to find the shortest possible edit script between file versions.</p>\n<p><strong>Edit Script</strong>: Sequence of insertion and deletion operations that transforms one file into another. Generated by diff algorithms and used to reconstruct changes, apply patches, and display modifications in human-readable format.</p>\n<h3 id=\"storage-and-object-model\">Storage and Object Model</h3>\n<p><strong>Hash Mismatches</strong>: Errors where computed SHA-1 hash doesn&#39;t match expected value, indicating data corruption or implementation bugs. Can occur during object storage, retrieval, or transmission, requiring integrity verification and error recovery mechanisms.</p>\n<p><strong>Hunk</strong>: Contiguous block of changes in diff output, consisting of nearby modifications grouped together with context lines. Unified diff format organizes changes into hunks with headers showing affected line ranges in both file versions.</p>\n<p><strong>Immutable History</strong>: Property that historical commits cannot be modified once created, ensuring repository integrity and enabling reliable collaboration. Achieved through cryptographic hashing where any content change produces a different hash.</p>\n<p><strong>Index Binary Format</strong>: Compact binary representation of staging area contents optimized for performance. Contains header with version and entry count, sorted file entries with metadata and hashes, and SHA-1 checksum for corruption detection.</p>\n<p><strong>Lowest Common Ancestor</strong>: Most recent commit reachable from both branches in merge operations. Critical for three-way merge algorithm as the base version for comparing changes from both branches, found using breadth-first search.</p>\n<p><strong>Merge Base</strong>: The common ancestor commit used as the base version in three-way merge operations. Found by traversing commit history from both branch tips until discovering the most recent shared commit.</p>\n<p><strong>Metadata Caching</strong>: Storing file system metadata (timestamps, sizes, inodes) in the index to quickly detect modifications without re-reading file content. Enables efficient status calculations by comparing cached metadata with current file system state.</p>\n<p><strong>Myers Algorithm</strong>: Optimal diff algorithm that finds the shortest edit script between two sequences using dynamic programming. Visualizes the problem as finding the shortest path through a grid, with optimizations for practical performance.</p>\n<p><strong>Object Store</strong>: Git&#39;s content-addressable storage backend for immutable objects (blobs, trees, commits). Uses SHA-1 hashes as keys, stores compressed objects in <code>.git/objects/</code> directory structure, provides retrieval and verification capabilities.</p>\n<h3 id=\"references-and-branching\">References and Branching</h3>\n<p><strong>Reference Resolution</strong>: Process of following symbolic references to find the target commit hash. Handles chains of symbolic references and validates reference integrity, essential for operations requiring actual commit hashes.</p>\n<p><strong>Repository Consistency</strong>: Validation that repository satisfies all Git invariants including object reachability, reference validity, and structural integrity. Ensures reliable operation and prevents corruption from accumulating over time.</p>\n<p><strong>SHA-1 Hash</strong>: Cryptographic hash function producing 160-bit (40 hex character) digests used as object identifiers. While deprecated for cryptographic security, still used in Git for content addressing and object identification.</p>\n<p><strong>Staging Area</strong>: Intermediate layer between working directory and repository history where changes are prepared for commit. Implemented as the index file, allows incremental commit preparation and fine-grained control over version history.</p>\n<p><strong>Symbolic Reference</strong>: Reference pointing to another reference rather than directly to a commit hash. HEAD is typically a symbolic reference pointing to the current branch, enabling automatic branch advancement during commits.</p>\n<p><strong>Three-Way Comparison</strong>: Status calculation method comparing working directory, index (staging area), and HEAD to determine file states. Identifies modified, staged, untracked, and deleted files by analyzing differences between these three sources.</p>\n<p><strong>Three-Way Merge</strong>: Merge algorithm using base version (common ancestor) and two branch versions to automatically combine non-conflicting changes. More sophisticated than two-way merge, reduces false conflicts by understanding change attribution.</p>\n<p><strong>Tree Object</strong>: Immutable container representing directory structure in Git&#39;s object model. Contains sorted list of entries with file modes, names, and SHA-1 hashes pointing to blobs or other trees, forming hierarchical project snapshots.</p>\n<p><strong>Unified Diff Format</strong>: Industry standard for presenting file differences with context lines, hunk headers, and change markers. Provides human-readable representation of modifications suitable for code review and patch application.</p>\n<h3 id=\"advanced-concepts-and-extensions\">Advanced Concepts and Extensions</h3>\n<p><strong>Change Attribution</strong>: Process of determining which branch made each modification during merge operations. Essential for three-way merge algorithm to distinguish between conflicting and complementary changes from different development lines.</p>\n<p><strong>Delta Compression</strong>: Storage optimization technique using differences between similar objects rather than storing complete content. Reduces repository size by expressing objects as modifications to base objects, used in Git&#39;s pack file format.</p>\n<p><strong>Fanout Table</strong>: Index structure in pack files providing efficient object lookup by organizing objects by hash prefix. Contains 256 entries corresponding to first byte values, enabling binary search optimization for object retrieval.</p>\n<p><strong>Fast-Forward Update</strong>: Reference update where new commit is descendant of old commit, requiring only pointer movement without merge. Common in linear development workflows and during fetch operations with no local changes.</p>\n<p><strong>Fetch Operation</strong>: Retrieval of objects and references from remote repository without merging into local branches. Updates remote-tracking branches to reflect remote state while leaving local development branches unchanged.</p>\n<p><strong>Garbage Collection</strong>: Process of removing unreachable objects and optimizing repository storage. Identifies objects not reachable from any reference, removes them to reclaim disk space, and reorganizes remaining objects for efficiency.</p>\n<p><strong>Greedy Extension</strong>: Myers algorithm optimization that follows matching elements as far as possible before considering insertions or deletions. Improves algorithm performance by reducing the search space for optimal solutions.</p>\n<p><strong>Object Relationships</strong>: References between commits, trees, and blobs forming Git&#39;s directed acyclic graph structure. Enables repository validation, garbage collection, and history traversal by following hash-based connections.</p>\n<p><strong>Pack File</strong>: Compressed bundle of Git objects optimized for storage efficiency and network transfer. Uses delta compression and zlib to minimize space, essential for large repositories and efficient remote operations.</p>\n<p><strong>Pack Index</strong>: Lookup table enabling efficient random access to objects within pack files. Contains sorted object hashes with corresponding pack file offsets, supporting binary search for fast object retrieval.</p>\n<p><strong>Push Operation</strong>: Sending local objects and reference updates to remote repository. Includes object transfer optimization and reference update validation to maintain consistency across distributed repositories.</p>\n<p><strong>Remote-Tracking Branch</strong>: Local reference showing last known state of remote branch without affecting local development branches. Updated during fetch operations to track remote repository evolution.</p>\n<p><strong>Want/Have Negotiation</strong>: Network protocol optimization to minimize object transfer by identifying objects already present in destination repository. Reduces bandwidth usage during fetch and push operations.</p>\n<h3 id=\"implementation-details\">Implementation Details</h3>\n<p><strong>Working Directory</strong>: File system directory containing checked-out project files that users can modify. Represents current project state and serves as source for staging operations, distinct from immutable repository history.</p>\n<p><strong>Git Directory</strong>: The <code>.git</code> folder containing all repository metadata, object storage, references, and configuration. Hidden from normal file operations while containing all information needed to reconstruct project history.</p>\n<p><strong>Diagnostic Tools</strong>: Utilities for inspecting and validating Git repository internals during development and debugging. Include object inspection, reference validation, and repository consistency checking capabilities.</p>\n<p><strong>Repository Corruption</strong>: Data integrity failures in Git repositories including corrupted objects, missing references, and invalid repository states. Requires detection mechanisms and recovery strategies to maintain reliable operation.</p>\n<p><strong>Concurrent Access Patterns</strong>: Strategies for handling multiple processes accessing Git repository simultaneously without corruption. Includes file locking, atomic operations, and coordination mechanisms for safe concurrent operation.</p>\n<p><strong>File System Permissions</strong>: Access control settings for Git repository files ensuring security while enabling necessary operations. Critical for shared repositories and preventing unauthorized modification of repository data.</p>\n<p><strong>Binary Detection Size</strong>: Number of bytes analyzed when determining if file content is binary or text, typically 1024 bytes. Optimization balancing accuracy of detection with performance of file analysis.</p>\n<p><strong>Printable Ratio Threshold</strong>: Minimum proportion of printable characters required to classify content as text rather than binary, typically 75%. Used in heuristic binary detection algorithms.</p>\n<h3 id=\"data-structures-and-formats\">Data Structures and Formats</h3>\n<table>\n<thead>\n<tr>\n<th>Structure</th>\n<th>Purpose</th>\n<th>Key Components</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>Repository</code></td>\n<td>Main repository interface</td>\n<td>git_dir, work_tree paths</td>\n</tr>\n<tr>\n<td><code>ObjectStore</code></td>\n<td>Content-addressable storage</td>\n<td>objects_dir, hash-to-path mapping</td>\n</tr>\n<tr>\n<td><code>Index</code></td>\n<td>Staging area implementation</td>\n<td>entries list, binary serialization</td>\n</tr>\n<tr>\n<td><code>ReferenceManager</code></td>\n<td>Branch and reference handling</td>\n<td>refs_dir, heads_dir, head_file</td>\n</tr>\n<tr>\n<td><code>TreeEntry</code></td>\n<td>Directory entry representation</td>\n<td>mode, name, hash tuple</td>\n</tr>\n<tr>\n<td><code>IndexEntry</code></td>\n<td>Staged file metadata</td>\n<td>timestamps, size, hash, path</td>\n</tr>\n<tr>\n<td><code>GitObject</code></td>\n<td>Base object interface</td>\n<td>content bytes, type identification</td>\n</tr>\n<tr>\n<td><code>BlobObject</code></td>\n<td>File content storage</td>\n<td>raw content bytes</td>\n</tr>\n<tr>\n<td><code>TreeObject</code></td>\n<td>Directory structure</td>\n<td>sorted entries list</td>\n</tr>\n<tr>\n<td><code>CommitObject</code></td>\n<td>Project snapshot</td>\n<td>tree, parents, metadata</td>\n</tr>\n</tbody></table>\n<h3 id=\"error-conditions-and-recovery\">Error Conditions and Recovery</h3>\n<table>\n<thead>\n<tr>\n<th>Error Type</th>\n<th>Symptoms</th>\n<th>Detection Method</th>\n<th>Recovery Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Hash Mismatch</td>\n<td>Object corruption</td>\n<td>SHA-1 verification</td>\n<td>Recompute from source</td>\n</tr>\n<tr>\n<td>Missing Object</td>\n<td>Reference errors</td>\n<td>Object existence check</td>\n<td>Fetch from remote</td>\n</tr>\n<tr>\n<td>Index Corruption</td>\n<td>Staging failures</td>\n<td>Checksum validation</td>\n<td>Rebuild from working tree</td>\n</tr>\n<tr>\n<td>Reference Invalid</td>\n<td>Branch operations fail</td>\n<td>Path validation</td>\n<td>Reset to known good state</td>\n</tr>\n<tr>\n<td>Merge Conflicts</td>\n<td>Overlapping changes</td>\n<td>Three-way comparison</td>\n<td>Manual resolution</td>\n</tr>\n<tr>\n<td>Lock Contention</td>\n<td>Concurrent access</td>\n<td>File lock timeout</td>\n<td>Retry with backoff</td>\n</tr>\n</tbody></table>\n<h3 id=\"algorithm-categories\">Algorithm Categories</h3>\n<table>\n<thead>\n<tr>\n<th>Algorithm Type</th>\n<th>Primary Use</th>\n<th>Key Characteristics</th>\n<th>Implementation Notes</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Myers Diff</td>\n<td>File comparison</td>\n<td>Optimal edit distance</td>\n<td>Grid-based dynamic programming</td>\n</tr>\n<tr>\n<td>Breadth-First Search</td>\n<td>Merge base finding</td>\n<td>Graph traversal</td>\n<td>Queue-based exploration</td>\n</tr>\n<tr>\n<td>Three-Way Merge</td>\n<td>Branch combination</td>\n<td>Conflict detection</td>\n<td>Base-relative comparison</td>\n</tr>\n<tr>\n<td>SHA-1 Hashing</td>\n<td>Object identification</td>\n<td>Cryptographic integrity</td>\n<td>Content-addressable keys</td>\n</tr>\n<tr>\n<td>Zlib Compression</td>\n<td>Storage optimization</td>\n<td>Size reduction</td>\n<td>Standard deflate algorithm</td>\n</tr>\n</tbody></table>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>This glossary serves as a living reference throughout implementation, with definitions becoming more concrete as you implement each milestone. The terms progress from abstract concepts to specific data structures and algorithms as your understanding deepens.</p>\n<h4 id=\"essential-reference-patterns\">Essential Reference Patterns</h4>\n<p>When implementing Git operations, several reference patterns appear repeatedly:</p>\n<p><strong>Object Hash Calculation</strong>: Always format as <code>{type} {size}\\0{content}</code> before computing SHA-1 hash. The null byte separator is critical for proper hash computation and object integrity.</p>\n<p><strong>Path Resolution</strong>: Convert object hashes to file system paths by splitting into 2-character directory prefix and 38-character filename. This distribution ensures reasonable directory sizes even with millions of objects.</p>\n<p><strong>Reference Chain Following</strong>: When resolving references, follow symbolic references iteratively until reaching a direct hash reference. Implement cycle detection to prevent infinite loops from corrupted references.</p>\n<p><strong>Binary vs Text Detection</strong>: Sample initial bytes of file content, count printable characters, and apply threshold ratio. This heuristic approach balances accuracy with performance for large repositories.</p>\n<h4 id=\"common-implementation-mistakes\">Common Implementation Mistakes</h4>\n<p>⚠️ <strong>Pitfall: Hash Format Confusion</strong>\nMany implementations incorrectly store object hashes as 40-character hex strings in binary formats like the index. Git stores hashes as 20-byte binary data in most internal formats, converting to hex only for display and file names.</p>\n<p>⚠️ <strong>Pitfall: Reference File Encoding</strong>\nReference files must end with newlines and contain only the hash or symbolic reference. Missing newlines cause parsing errors, while extra whitespace breaks hash validation.</p>\n<p>⚠️ <strong>Pitfall: Tree Entry Sorting</strong>\nTree entries must be sorted using Git&#39;s specific comparison rules, treating directories as if they end with &#39;/&#39; for sorting purposes. Standard string sorting produces incorrect tree hashes.</p>\n<p>⚠️ <strong>Pitfall: Merge Base Edge Cases</strong>\nWhen multiple common ancestors exist, the merge base algorithm must select the lowest common ancestor, not just any shared commit. This affects merge conflict detection and resolution.</p>\n<h4 id=\"debugging-reference-guide\">Debugging Reference Guide</h4>\n<table>\n<thead>\n<tr>\n<th>Issue</th>\n<th>Likely Cause</th>\n<th>Investigation Steps</th>\n<th>Resolution</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Invalid object hash</td>\n<td>Header format wrong</td>\n<td>Check null byte placement</td>\n<td>Reformat as <code>type size\\0content</code></td>\n</tr>\n<tr>\n<td>Missing objects</td>\n<td>Storage path incorrect</td>\n<td>Verify <code>.git/objects/xx/yyyy</code> structure</td>\n<td>Fix path computation logic</td>\n</tr>\n<tr>\n<td>Index corruption</td>\n<td>Binary format error</td>\n<td>Validate header and checksum</td>\n<td>Implement proper serialization</td>\n</tr>\n<tr>\n<td>Reference resolution fails</td>\n<td>Symbolic ref chain broken</td>\n<td>Trace reference chain manually</td>\n<td>Repair or reset references</td>\n</tr>\n<tr>\n<td>Diff output wrong</td>\n<td>Algorithm implementation bug</td>\n<td>Compare with known good output</td>\n<td>Debug Myers algorithm step-by-step</td>\n</tr>\n<tr>\n<td>Merge conflicts incorrect</td>\n<td>Base calculation wrong</td>\n<td>Verify merge base commit</td>\n<td>Fix breadth-first search logic</td>\n</tr>\n</tbody></table>\n<p>This glossary evolves as your implementation progresses, with initially abstract concepts becoming concrete data structures and algorithms. Use it as both a learning tool and a reference during debugging sessions.</p>\n","toc":[{"level":1,"text":"Build Your Own Git: Design Document","id":"build-your-own-git-design-document"},{"level":2,"text":"Overview","id":"overview"},{"level":2,"text":"Context and Problem Statement","id":"context-and-problem-statement"},{"level":3,"text":"Mental Model: The Digital Filing Cabinet","id":"mental-model-the-digital-filing-cabinet"},{"level":3,"text":"Existing Version Control Approaches","id":"existing-version-control-approaches"},{"level":4,"text":"Simple File-Based Approaches","id":"simple-file-based-approaches"},{"level":4,"text":"Centralized Version Control Systems","id":"centralized-version-control-systems"},{"level":4,"text":"Distributed Version Control Systems","id":"distributed-version-control-systems"},{"level":4,"text":"Git&#39;s Content-Addressable Innovation","id":"git39s-content-addressable-innovation"},{"level":4,"text":"Summary of Architectural Trade-offs","id":"summary-of-architectural-trade-offs"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended Project Structure","id":"recommended-project-structure"},{"level":4,"text":"Core Infrastructure Components","id":"core-infrastructure-components"},{"level":4,"text":"Development Workflow Setup","id":"development-workflow-setup"},{"level":4,"text":"Milestone 1 Checkpoint: Repository Initialization","id":"milestone-1-checkpoint-repository-initialization"},{"level":4,"text":"Common Development Pitfalls","id":"common-development-pitfalls"},{"level":4,"text":"Language-Specific Hints for Python","id":"language-specific-hints-for-python"},{"level":2,"text":"Goals and Non-Goals","id":"goals-and-non-goals"},{"level":3,"text":"Functional Goals","id":"functional-goals"},{"level":3,"text":"Explicit Non-Goals","id":"explicit-non-goals"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"High-Level Architecture","id":"high-level-architecture"},{"level":3,"text":"System Components","id":"system-components"},{"level":4,"text":"Object Store: The Immutable Foundation","id":"object-store-the-immutable-foundation"},{"level":4,"text":"Index: The Staging Area Bridge","id":"index-the-staging-area-bridge"},{"level":4,"text":"References: The Human-Readable Navigation System","id":"references-the-human-readable-navigation-system"},{"level":4,"text":"Working Directory: The User Interface Layer","id":"working-directory-the-user-interface-layer"},{"level":3,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Data Model","id":"data-model"},{"level":3,"text":"Mental Model: The Universal Content Graph","id":"mental-model-the-universal-content-graph"},{"level":3,"text":"Git Object Types","id":"git-object-types"},{"level":4,"text":"Object Storage Format","id":"object-storage-format"},{"level":4,"text":"Blob Objects","id":"blob-objects"},{"level":4,"text":"Tree Objects","id":"tree-objects"},{"level":4,"text":"Commit Objects","id":"commit-objects"},{"level":3,"text":"Object Relationships","id":"object-relationships"},{"level":4,"text":"Content-Addressable References","id":"content-addressable-references"},{"level":4,"text":"The Complete Reference Graph","id":"the-complete-reference-graph"},{"level":4,"text":"Shared Object References","id":"shared-object-references"},{"level":4,"text":"Reference Resolution and Traversal","id":"reference-resolution-and-traversal"},{"level":4,"text":"Object Storage Efficiency","id":"object-storage-efficiency"},{"level":3,"text":"Common Pitfalls","id":"common-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeleton Code","id":"core-logic-skeleton-code"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":4,"text":"Debugging Tips","id":"debugging-tips"},{"level":2,"text":"Object Store Design","id":"object-store-design"},{"level":3,"text":"Mental Model: The Universal Library","id":"mental-model-the-universal-library"},{"level":3,"text":"Storage Algorithm","id":"storage-algorithm"},{"level":3,"text":"Retrieval and Verification","id":"retrieval-and-verification"},{"level":3,"text":"Architecture Decision Records","id":"architecture-decision-records"},{"level":3,"text":"Common Pitfalls","id":"common-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeleton Code","id":"core-logic-skeleton-code"},{"level":4,"text":"Language-Specific Hints","id":"language-specific-hints"},{"level":4,"text":"Milestone Checkpoint","id":"milestone-checkpoint"},{"level":2,"text":"Index and Staging Area","id":"index-and-staging-area"},{"level":3,"text":"Mental Model: The Photography Dark Room","id":"mental-model-the-photography-dark-room"},{"level":3,"text":"Index Binary Format","id":"index-binary-format"},{"level":3,"text":"Add and Remove Operations","id":"add-and-remove-operations"},{"level":3,"text":"Status Calculation","id":"status-calculation"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"References and Branch Management","id":"references-and-branch-management"},{"level":3,"text":"Mental Model: Bookmarks in History","id":"mental-model-bookmarks-in-history"},{"level":3,"text":"Symbolic vs Direct References","id":"symbolic-vs-direct-references"},{"level":3,"text":"Branch Creation and Switching","id":"branch-creation-and-switching"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Diff Algorithm Implementation","id":"diff-algorithm-implementation"},{"level":3,"text":"Mental Model: Document Comparison","id":"mental-model-document-comparison"},{"level":3,"text":"Myers Diff Algorithm","id":"myers-diff-algorithm"},{"level":4,"text":"Architecture Decision Records","id":"architecture-decision-records"},{"level":3,"text":"Unified Diff Output Format","id":"unified-diff-output-format"},{"level":4,"text":"Common Pitfalls","id":"common-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeleton Code","id":"core-logic-skeleton-code"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":4,"text":"Language-Specific Hints","id":"language-specific-hints"},{"level":2,"text":"Three-Way Merge Implementation","id":"three-way-merge-implementation"},{"level":3,"text":"Mental Model: Collaborative Document Editing","id":"mental-model-collaborative-document-editing"},{"level":3,"text":"Finding the Merge Base","id":"finding-the-merge-base"},{"level":3,"text":"Three-Way Merge Algorithm","id":"three-way-merge-algorithm"},{"level":3,"text":"Conflict Detection and Marking","id":"conflict-detection-and-marking"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Component Interactions and Data Flow","id":"component-interactions-and-data-flow"},{"level":3,"text":"Mental Model: The Assembly Line Factory","id":"mental-model-the-assembly-line-factory"},{"level":3,"text":"Commit Creation Data Flow","id":"commit-creation-data-flow"},{"level":4,"text":"Stage 1: File Staging (git add)","id":"stage-1-file-staging-git-add"},{"level":4,"text":"Stage 2: Tree Construction (git write-tree)","id":"stage-2-tree-construction-git-write-tree"},{"level":4,"text":"Stage 3: Commit Creation (git commit)","id":"stage-3-commit-creation-git-commit"},{"level":4,"text":"Data Flow Summary for Commit Creation","id":"data-flow-summary-for-commit-creation"},{"level":3,"text":"Branch Merge Data Flow","id":"branch-merge-data-flow"},{"level":4,"text":"Mental Model: The Document Reconciliation Process","id":"mental-model-the-document-reconciliation-process"},{"level":4,"text":"Stage 1: Merge Base Discovery","id":"stage-1-merge-base-discovery"},{"level":4,"text":"Stage 2: Three-Way File Comparison","id":"stage-2-three-way-file-comparison"},{"level":4,"text":"Stage 3: Conflict Resolution and Merge Commit Creation","id":"stage-3-conflict-resolution-and-merge-commit-creation"},{"level":4,"text":"Stage 4: Merge State Management","id":"stage-4-merge-state-management"},{"level":3,"text":"Common Pitfalls in Component Interactions","id":"common-pitfalls-in-component-interactions"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Commit Creation Workflow Implementation","id":"commit-creation-workflow-implementation"},{"level":4,"text":"Merge Workflow Implementation","id":"merge-workflow-implementation"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":2,"text":"Error Handling and Edge Cases","id":"error-handling-and-edge-cases"},{"level":3,"text":"Mental Model: The Digital Safety Net","id":"mental-model-the-digital-safety-net"},{"level":3,"text":"Repository Corruption Handling","id":"repository-corruption-handling"},{"level":4,"text":"Corruption Detection Strategies","id":"corruption-detection-strategies"},{"level":4,"text":"Corruption Recovery Strategies","id":"corruption-recovery-strategies"},{"level":4,"text":"Validation Error Types and Responses","id":"validation-error-types-and-responses"},{"level":3,"text":"Merge Conflict Resolution","id":"merge-conflict-resolution"},{"level":4,"text":"Conflict Detection and Classification","id":"conflict-detection-and-classification"},{"level":4,"text":"Conflict Marker Generation","id":"conflict-marker-generation"},{"level":4,"text":"Conflict Resolution Workflows","id":"conflict-resolution-workflows"},{"level":4,"text":"Interrupted Merge Recovery","id":"interrupted-merge-recovery"},{"level":3,"text":"Concurrent Access Patterns","id":"concurrent-access-patterns"},{"level":4,"text":"File System Level Concurrency","id":"file-system-level-concurrency"},{"level":4,"text":"Process Coordination Patterns","id":"process-coordination-patterns"},{"level":4,"text":"Error Recovery in Concurrent Scenarios","id":"error-recovery-in-concurrent-scenarios"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeletons","id":"core-logic-skeletons"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":4,"text":"Debugging Tips","id":"debugging-tips"},{"level":2,"text":"Testing Strategy and Milestone Checkpoints","id":"testing-strategy-and-milestone-checkpoints"},{"level":3,"text":"Mental Model: The Quality Assurance Laboratory","id":"mental-model-the-quality-assurance-laboratory"},{"level":3,"text":"Milestone Verification Steps","id":"milestone-verification-steps"},{"level":4,"text":"Milestone 1: Repository Initialization Verification","id":"milestone-1-repository-initialization-verification"},{"level":4,"text":"Milestone 2: Object Storage (Blobs) Verification","id":"milestone-2-object-storage-blobs-verification"},{"level":4,"text":"Milestone 3: Tree Objects Verification","id":"milestone-3-tree-objects-verification"},{"level":4,"text":"Milestone 4: Commit Objects Verification","id":"milestone-4-commit-objects-verification"},{"level":4,"text":"Milestone 5: References and Branches Verification","id":"milestone-5-references-and-branches-verification"},{"level":4,"text":"Milestone 6: Index (Staging Area) Verification","id":"milestone-6-index-staging-area-verification"},{"level":4,"text":"Milestone 7: Diff Algorithm Verification","id":"milestone-7-diff-algorithm-verification"},{"level":4,"text":"Milestone 8: Three-Way Merge Verification","id":"milestone-8-three-way-merge-verification"},{"level":3,"text":"Integration Testing Approach","id":"integration-testing-approach"},{"level":4,"text":"Golden Standard Testing Framework","id":"golden-standard-testing-framework"},{"level":4,"text":"Test Scenario Categories","id":"test-scenario-categories"},{"level":4,"text":"Automated Compatibility Verification","id":"automated-compatibility-verification"},{"level":4,"text":"Performance and Scalability Testing","id":"performance-and-scalability-testing"},{"level":3,"text":"Common Testing Pitfalls","id":"common-testing-pitfalls"},{"level":3,"text":"Integration with Development Workflow","id":"integration-with-development-workflow"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended Testing File Structure","id":"recommended-testing-file-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeleton Code","id":"core-logic-skeleton-code"},{"level":4,"text":"Language-Specific Testing Hints","id":"language-specific-testing-hints"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":4,"text":"Debugging Tips","id":"debugging-tips"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended Testing File Structure","id":"recommended-testing-file-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeleton Code","id":"core-logic-skeleton-code"},{"level":2,"text":"Debugging Guide","id":"debugging-guide"},{"level":3,"text":"Mental Model: The Medical Diagnostic Process","id":"mental-model-the-medical-diagnostic-process"},{"level":3,"text":"Object Storage Issues","id":"object-storage-issues"},{"level":4,"text":"Hash Mismatches and Computation Errors","id":"hash-mismatches-and-computation-errors"},{"level":4,"text":"Compression and Storage Problems","id":"compression-and-storage-problems"},{"level":4,"text":"File System Permissions and Path Issues","id":"file-system-permissions-and-path-issues"},{"level":3,"text":"Merge Algorithm Debugging","id":"merge-algorithm-debugging"},{"level":4,"text":"Conflict Detection Failures","id":"conflict-detection-failures"},{"level":4,"text":"Infinite Loops in Merge Base Calculation","id":"infinite-loops-in-merge-base-calculation"},{"level":4,"text":"Corrupted Merge States","id":"corrupted-merge-states"},{"level":3,"text":"Debugging Tools and Techniques","id":"debugging-tools-and-techniques"},{"level":4,"text":"Inspecting Git Internals","id":"inspecting-git-internals"},{"level":4,"text":"Tracing Object Relationships","id":"tracing-object-relationships"},{"level":4,"text":"Validating Repository Consistency","id":"validating-repository-consistency"},{"level":4,"text":"Debugging Workflow Integration","id":"debugging-workflow-integration"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Debugging Infrastructure Starter Code","id":"debugging-infrastructure-starter-code"},{"level":2,"text":"Future Extensions","id":"future-extensions"},{"level":3,"text":"Mental Model: The Local Shop Goes Global","id":"mental-model-the-local-shop-goes-global"},{"level":3,"text":"Remote Repository Support","id":"remote-repository-support"},{"level":4,"text":"Understanding Remote Operations","id":"understanding-remote-operations"},{"level":4,"text":"Remote Repository Data Model","id":"remote-repository-data-model"},{"level":4,"text":"Fetch Operation Architecture","id":"fetch-operation-architecture"},{"level":4,"text":"Push Operation Architecture","id":"push-operation-architecture"},{"level":4,"text":"Remote Reference Management","id":"remote-reference-management"},{"level":4,"text":"Pull Operation as Fetch + Merge","id":"pull-operation-as-fetch-merge"},{"level":4,"text":"Protocol Implementation Considerations","id":"protocol-implementation-considerations"},{"level":4,"text":"Architecture Decision Records for Remote Support","id":"architecture-decision-records-for-remote-support"},{"level":3,"text":"Pack File Optimization","id":"pack-file-optimization"},{"level":4,"text":"Understanding the Storage Efficiency Problem","id":"understanding-the-storage-efficiency-problem"},{"level":4,"text":"Mental Model: The Efficient Warehouse","id":"mental-model-the-efficient-warehouse"},{"level":4,"text":"Pack File Data Structure","id":"pack-file-data-structure"},{"level":4,"text":"Delta Compression Algorithm","id":"delta-compression-algorithm"},{"level":4,"text":"Pack Index Structure","id":"pack-index-structure"},{"level":4,"text":"Garbage Collection and Pack Generation","id":"garbage-collection-and-pack-generation"},{"level":4,"text":"Integration with Existing Object Store","id":"integration-with-existing-object-store"},{"level":4,"text":"Architecture Decision Records for Pack Files","id":"architecture-decision-records-for-pack-files"},{"level":4,"text":"Performance Impact Analysis","id":"performance-impact-analysis"},{"level":3,"text":"Integration Considerations","id":"integration-considerations"},{"level":4,"text":"Compatibility with Existing Components","id":"compatibility-with-existing-components"},{"level":4,"text":"Migration Strategy","id":"migration-strategy"},{"level":3,"text":"Common Pitfalls","id":"common-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeleton Code","id":"core-logic-skeleton-code"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":4,"text":"Debugging Tips for Remote Operations","id":"debugging-tips-for-remote-operations"},{"level":4,"text":"Performance Monitoring","id":"performance-monitoring"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeleton Code","id":"core-logic-skeleton-code"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":2,"text":"Glossary","id":"glossary"},{"level":3,"text":"Mental Model: The Technical Dictionary","id":"mental-model-the-technical-dictionary"},{"level":3,"text":"Core Git Concepts","id":"core-git-concepts"},{"level":3,"text":"Storage and Object Model","id":"storage-and-object-model"},{"level":3,"text":"References and Branching","id":"references-and-branching"},{"level":3,"text":"Advanced Concepts and Extensions","id":"advanced-concepts-and-extensions"},{"level":3,"text":"Implementation Details","id":"implementation-details"},{"level":3,"text":"Data Structures and Formats","id":"data-structures-and-formats"},{"level":3,"text":"Error Conditions and Recovery","id":"error-conditions-and-recovery"},{"level":3,"text":"Algorithm Categories","id":"algorithm-categories"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Essential Reference Patterns","id":"essential-reference-patterns"},{"level":4,"text":"Common Implementation Mistakes","id":"common-implementation-mistakes"},{"level":4,"text":"Debugging Reference Guide","id":"debugging-reference-guide"}],"title":"Build Your Own Git: Design Document","markdown":"# Build Your Own Git: Design Document\n\n\n## Overview\n\nThis system implements a version control system that uses content-addressable storage and a directed acyclic graph to track file changes over time. The key architectural challenge is designing an immutable object store where every piece of content is identified by its cryptographic hash, enabling efficient deduplication and integrity verification.\n\n\n> This guide is meant to help you understand the big picture before diving into each milestone. Refer back to it whenever you need context on how components connect.\n\n\n## Context and Problem Statement\n\n> **Milestone(s):** This section establishes the foundational concepts underlying all milestones\n\n### Mental Model: The Digital Filing Cabinet\n\nImagine you have a magical filing cabinet for all your documents. This isn't an ordinary filing cabinet—it has three extraordinary properties that make it perfect for managing the evolution of your work over time.\n\nFirst, the filing cabinet **never loses anything**. Every version of every document you've ever stored remains perfectly preserved, accessible whenever you need it. You can ask to see the draft of your thesis from six months ago, or the version of your code from last Tuesday, and the cabinet instantly produces an exact copy. Nothing ever gets overwritten or accidentally deleted.\n\nSecond, the filing cabinet is **impossibly organized**. Instead of using arbitrary folder names or date-based filing systems that might conflict or become confusing, it uses a perfect organizational scheme: every document gets filed based on a mathematical fingerprint of its exact contents. Two identical documents, even if created years apart, automatically go to the same location. This means there's never any duplication—the cabinet stores each unique piece of content exactly once, no matter how many times you reference it.\n\nThird, the filing cabinet **remembers the relationships** between documents. When you file a new version of your thesis that incorporates feedback, the cabinet automatically records that this new version is based on the previous draft. It builds a complete family tree of how your documents evolved, branched into different versions, and merged back together. You can trace the lineage of any document back to its origins and understand exactly how it came to be.\n\nThis magical filing cabinet is precisely what Git provides for software development. The **content-addressable storage** system acts as the perfect organizational scheme, using cryptographic hashes to ensure every piece of content has a unique, deterministic location. The **immutable object store** guarantees that once something is filed, it never disappears or changes. The **directed acyclic graph** of commits preserves the complete evolutionary history of your project, showing how each version builds upon previous work.\n\nUnlike physical filing cabinets where you might run out of space or struggle to find documents, Git's digital filing cabinet scales effortlessly. The mathematical properties of the hash-based organization ensure that even projects with millions of files and decades of history remain fast and reliable. The distributed nature means every developer gets their own complete copy of this magical cabinet, yet all copies can synchronize and share their contents seamlessly.\n\n> The fundamental insight that makes Git possible is that **content identity can be derived from content itself**. Instead of assigning arbitrary names or numbers to track different versions, Git computes a cryptographic fingerprint of each piece of content. This fingerprint serves as both the identity and the storage location, creating a self-organizing system that eliminates duplication and ensures integrity.\n\n### Existing Version Control Approaches\n\nThe challenge of tracking changes to files over time has been approached in several fundamentally different ways throughout the history of software development. Each approach represents different trade-offs between simplicity, functionality, and complexity. Understanding these approaches illuminates why Git's content-addressable architecture emerged as the dominant solution for modern software development.\n\n#### Simple File-Based Approaches\n\nThe most basic approach to version control involves manual copying and timestamping. Developers create copies of their entire project directory with names like `project-v1.0`, `project-v1.1-backup`, `project-final`, `project-final-REALLY-FINAL`. This approach is intuitive and requires no special tools, but it quickly becomes unworkable.\n\nThe fundamental problems with file copying are storage inefficiency and coordination impossibility. Each complete copy of the project consumes full disk space, even when changes affect only a few files. A project with 1000 files that undergoes 100 versions consumes space equivalent to 100,000 files, even if most files never changed. More critically, there's no systematic way to understand what changed between versions, merge contributions from multiple developers, or recover from mistakes. Finding specific changes requires manual comparison of directory trees, a process that becomes prohibitively expensive as project size grows.\n\nSome developers attempt to solve the comparison problem by maintaining change logs—text files that document what modified in each version. However, these logs are manually maintained and inevitably drift out of sync with actual changes. The change logs themselves become another file that needs version control, creating a recursive problem. Additionally, manual change tracking is error-prone and time-consuming, reducing developer productivity and introducing opportunities for human error.\n\n#### Centralized Version Control Systems\n\nCentralized systems like Subversion (SVN) and Concurrent Versions System (CVS) emerged to solve the coordination and storage problems of manual file copying. These systems introduce a central server that stores the complete history of the project and coordinates access among multiple developers.\n\nIn the centralized model, the server maintains a linear sequence of numbered revisions. Each revision represents a snapshot of the entire project at a specific point in time. Developers work with local working copies that contain only the current version of files. When they want to make changes, they update their working copy to the latest revision from the server, make modifications locally, and commit changes back to the server. The server automatically assigns sequential revision numbers and stores the differences between consecutive revisions.\n\n| Aspect | Centralized VCS Behavior | Advantages | Disadvantages |\n|--------|-------------------------|------------|---------------|\n| **Storage Model** | Server stores complete history, clients have working copies only | Efficient network usage, simple mental model | Single point of failure, requires network access |\n| **Branching** | Branches are server-side directories, expensive to create | Clear branch visualization in repository structure | Branch creation requires server round-trip, discourages experimentation |\n| **Merging** | Server coordinates all merges, maintains linear history when possible | Simplified conflict resolution workflow | Complex merges block other developers, limited merge strategies |\n| **Network Dependency** | Most operations require server communication | Always synchronized with team, simplified backup | Offline work impossible, network latency affects productivity |\n| **Access Control** | Server enforces permissions per-directory or per-file | Fine-grained security control, audit trails | Administrative overhead, inflexible workflows |\n\nThe centralized approach works well for small teams with reliable network connectivity and relatively simple branching needs. The linear revision numbering makes it easy to reference specific versions, and the central server provides a clear authoritative source of truth. However, centralized systems impose significant limitations on developer workflows and introduce architectural brittleness.\n\n#### Distributed Version Control Systems\n\nDistributed systems like Git, Mercurial, and Bazaar eliminate the central server bottleneck by giving every developer a complete copy of the project history. This architectural shift enables fundamentally new workflows while solving many limitations of centralized systems.\n\nIn the distributed model, every working copy is actually a complete repository containing the full history of the project. Developers can create branches, make commits, and view history entirely locally without network access. Synchronization between repositories happens through explicit push and pull operations that exchange sets of commits. There's no inherent hierarchy—any repository can serve as a coordination point, and different teams can use different topologies (centralized, peer-to-peer, hierarchical) based on their needs.\n\n| Aspect | Distributed VCS Behavior | Advantages | Disadvantages |\n|--------|-------------------------|------------|---------------|\n| **Storage Model** | Every clone contains complete history | Full offline capability, no single point of failure | Larger initial clone size, complex synchronization |\n| **Branching** | Branches are lightweight local references | Instant branch creation, encourages experimentation | Branch proliferation can become confusing |\n| **Merging** | Advanced three-way merge algorithms with multiple strategies | Sophisticated conflict resolution, non-linear history support | Steeper learning curve, potential for complex merge conflicts |\n| **Network Independence** | All operations work offline, sync when convenient | Flexible workflows, works with unreliable connectivity | Potential for repositories to diverge significantly |\n| **Collaboration Models** | Supports multiple coordination topologies | Adaptable to different team structures and policies | Requires explicit coordination protocols |\n\nThe distributed approach excels in scenarios with complex branching needs, unreliable network connectivity, or large teams with diverse collaboration patterns. The complete local history enables powerful operations like bisecting to find bug introductions, sophisticated blame tracking, and experimental branching without coordination overhead.\n\n#### Git's Content-Addressable Innovation\n\nGit's specific innovation within the distributed model is the use of content-addressable storage based on cryptographic hashing. While other distributed systems like Mercurial use similar overall architectures, Git's object model provides unique advantages for integrity, deduplication, and performance.\n\nEvery piece of content in Git—whether file contents, directory structures, or commit metadata—is stored as an object identified by the SHA-1 hash of its contents. This creates several powerful properties that distinguish Git from other approaches:\n\n**Automatic deduplication** occurs because identical content always produces identical hashes. If the same file appears in multiple commits or branches, Git stores it only once. This makes branching extremely lightweight compared to systems that copy files or store differences.\n\n**Cryptographic integrity verification** happens automatically because any corruption changes the hash. Git can detect repository corruption immediately when accessing objects, providing stronger integrity guarantees than systems relying on file system integrity alone.\n\n**Distributed consistency** emerges naturally because content hashes are identical across all repositories. Two developers who independently create identical commits will generate identical commit hashes, simplifying synchronization and conflict detection.\n\n**Immutable history** is enforced by the hash chain structure. Because each commit's hash includes the hashes of its parent commits, changing any historical commit would require recomputing all subsequent hashes, making tampering easily detectable.\n\n> **Decision: Content-Addressable Object Storage**\n> - **Context**: Version control systems need to store file contents, directory structures, and metadata efficiently while ensuring integrity and enabling distributed synchronization\n> - **Options Considered**: Sequential revision numbers (CVS/SVN), content-based addressing (Git), hybrid approaches (Mercurial)\n> - **Decision**: Use SHA-1 hashes of content as both object identity and storage location\n> - **Rationale**: Content-addressable storage provides automatic deduplication, cryptographic integrity, distributed consistency, and immutable history with minimal overhead\n> - **Consequences**: Enables lightweight branching, efficient storage, strong integrity guarantees, but requires understanding of hash-based addressing and occasional hash collisions\n\nThe trade-offs of Git's approach become apparent in specific scenarios. The content-addressable model requires understanding of hash-based addressing, which has a steeper learning curve than sequential revision numbers. The complete history in every clone means initial repository size is larger than centralized systems. Complex branching and merging capabilities can lead to confusing repository states if not managed carefully.\n\nHowever, for software development workflows involving frequent branching, distributed teams, or long-lived feature development, Git's advantages typically outweigh these costs. The ability to work completely offline while maintaining full version control capabilities, combined with the lightweight nature of Git's branching model, has made it the standard choice for most modern software projects.\n\n#### Summary of Architectural Trade-offs\n\n| Approach | Storage Efficiency | Branching Cost | Network Dependency | Learning Curve | Best Use Cases |\n|----------|-------------------|----------------|-------------------|----------------|----------------|\n| **File Copying** | Very Poor | Manual only | None | Minimal | Single developer, tiny projects |\n| **Centralized** | Good | Medium-High | Required for most operations | Low-Medium | Small teams, simple workflows |\n| **Distributed** | Excellent | Very Low | Optional | Medium-High | Complex projects, distributed teams |\n| **Git Specifically** | Excellent | Minimal | Optional | High | Software development, open source |\n\nThe evolution from manual copying through centralized systems to distributed version control reflects the growing complexity of software development projects and the need for more sophisticated collaboration models. Git's content-addressable approach represents the current state of the art, providing the flexibility and power needed for modern software development while maintaining the performance and reliability required for large-scale projects.\n\nUnderstanding these different approaches helps explain why Git is architected the way it is, and why certain design decisions that might seem complex in isolation actually solve fundamental problems that simpler approaches cannot address. The content-addressable object store that we will implement represents decades of evolution in version control system design, distilled into an elegant and powerful architecture.\n\n### Implementation Guidance\n\nThe following implementation guidance provides concrete technical recommendations for building the foundational components described in this section. This guidance targets Python development and establishes the coding patterns we'll use throughout the project.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| **Hashing** | `hashlib.sha1()` from standard library | `cryptography` library with hash verification |\n| **Compression** | `zlib` module from standard library | `lzma` for better compression ratios |\n| **File I/O** | `pathlib.Path` with context managers | `os.scandir()` for high-performance directory traversal |\n| **Binary Data** | `bytes` and `struct.pack/unpack` | `ctypes` for complex binary structures |\n| **Command Line** | `argparse` for basic CLI | `click` for advanced command interfaces |\n| **Testing** | `unittest` from standard library | `pytest` with fixtures and parametrization |\n\n#### Recommended Project Structure\n\nOrganize your Git implementation to mirror the architectural components and support iterative development across the eight milestones:\n\n```\ngit-implementation/\n├── mygit/                          # Main package\n│   ├── __init__.py                 # Package initialization\n│   ├── cli.py                      # Command-line interface entry point\n│   ├── repository.py               # Repository class and initialization\n│   ├── objects/                    # Object store implementation\n│   │   ├── __init__.py\n│   │   ├── blob.py                 # Blob object handling\n│   │   ├── tree.py                 # Tree object handling\n│   │   ├── commit.py               # Commit object handling\n│   │   └── store.py                # Object storage backend\n│   ├── index/                      # Staging area implementation\n│   │   ├── __init__.py\n│   │   ├── index.py                # Index file format and operations\n│   │   └── status.py               # Working directory status calculation\n│   ├── refs/                       # Reference management\n│   │   ├── __init__.py\n│   │   ├── head.py                 # HEAD reference handling\n│   │   └── branches.py             # Branch creation and management\n│   ├── diff/                       # Diff algorithm implementation\n│   │   ├── __init__.py\n│   │   ├── myers.py                # Myers diff algorithm\n│   │   └── unified.py              # Unified diff output format\n│   ├── merge/                      # Merge implementation\n│   │   ├── __init__.py\n│   │   ├── three_way.py            # Three-way merge algorithm\n│   │   └── conflicts.py            # Conflict detection and marking\n│   └── utils/                      # Shared utilities\n│       ├── __init__.py\n│       ├── hash.py                 # Hash computation helpers\n│       └── paths.py                # Path manipulation utilities\n├── tests/                          # Test suite\n│   ├── __init__.py\n│   ├── test_objects.py             # Object store tests\n│   ├── test_index.py               # Index operation tests\n│   ├── test_refs.py                # Reference management tests\n│   ├── test_diff.py                # Diff algorithm tests\n│   ├── test_merge.py               # Merge algorithm tests\n│   └── integration/                # Integration tests\n│       ├── __init__.py\n│       └── test_workflows.py       # End-to-end workflow tests\n├── examples/                       # Example repositories and scripts\n│   └── sample_repo/                # Test repository for development\n└── docs/                          # Documentation\n    └── milestones/                 # Milestone-specific documentation\n```\n\n#### Core Infrastructure Components\n\nBefore implementing Git-specific logic, establish these foundational utilities that will be used throughout the project:\n\n**Hash Computation Utility (utils/hash.py):**\n```python\nimport hashlib\nfrom typing import bytes\n\ndef compute_sha1(content: bytes) -> str:\n    \"\"\"\n    Compute SHA-1 hash of content and return as 40-character hex string.\n    \n    Args:\n        content: Raw bytes to hash\n        \n    Returns:\n        40-character lowercase hex digest\n        \n    Example:\n        >>> compute_sha1(b\"hello world\")\n        '2aae6c35c94fcfb415dbe95f408b9ce91ee846ed'\n    \"\"\"\n    hasher = hashlib.sha1()\n    hasher.update(content)\n    return hasher.hexdigest()\n\ndef compute_object_hash(object_type: str, content: bytes) -> str:\n    \"\"\"\n    Compute Git object hash including type and size header.\n    \n    Git objects are hashed as: \"{type} {size}\\0{content}\"\n    \n    Args:\n        object_type: Git object type (\"blob\", \"tree\", \"commit\")\n        content: Raw object content\n        \n    Returns:\n        40-character hex hash that matches git hash-object\n    \"\"\"\n    header = f\"{object_type} {len(content)}\".encode('ascii')\n    full_content = header + b'\\0' + content\n    return compute_sha1(full_content)\n```\n\n**Path Utilities (utils/paths.py):**\n```python\nimport os\nfrom pathlib import Path\nfrom typing import Optional\n\ndef find_git_directory(start_path: Path = None) -> Optional[Path]:\n    \"\"\"\n    Find .git directory by walking up the directory tree.\n    \n    Args:\n        start_path: Directory to start search from (default: current directory)\n        \n    Returns:\n        Path to .git directory, or None if not found\n    \"\"\"\n    if start_path is None:\n        start_path = Path.cwd()\n    \n    current = start_path.resolve()\n    while current != current.parent:\n        git_dir = current / '.git'\n        if git_dir.is_dir():\n            return git_dir\n        current = current.parent\n    \n    return None\n\ndef ensure_directory_exists(path: Path) -> None:\n    \"\"\"Create directory and all parent directories if they don't exist.\"\"\"\n    path.mkdir(parents=True, exist_ok=True)\n\ndef object_path_from_hash(git_dir: Path, object_hash: str) -> Path:\n    \"\"\"\n    Convert object hash to file system path in .git/objects.\n    \n    Git stores objects as .git/objects/xx/yyyyyyyy where xx is first 2 hex chars.\n    \n    Args:\n        git_dir: Path to .git directory\n        object_hash: 40-character hex hash\n        \n    Returns:\n        Path where object should be stored\n        \n    Example:\n        >>> object_path_from_hash(Path('.git'), 'abc123...')\n        Path('.git/objects/ab/c123...')\n    \"\"\"\n    return git_dir / 'objects' / object_hash[:2] / object_hash[2:]\n```\n\n**Repository Class Skeleton (repository.py):**\n```python\nfrom pathlib import Path\nfrom typing import Optional\nfrom .utils.paths import find_git_directory, ensure_directory_exists\n\nclass Repository:\n    \"\"\"\n    Represents a Git repository and provides access to its components.\n    \n    The Repository class serves as the main entry point for all Git operations,\n    coordinating between the object store, index, references, and working directory.\n    \"\"\"\n    \n    def __init__(self, path: Path = None):\n        \"\"\"\n        Initialize repository object.\n        \n        Args:\n            path: Path to repository root (default: find from current directory)\n        \"\"\"\n        self.git_dir = find_git_directory(path)\n        if self.git_dir is None:\n            raise ValueError(\"Not a git repository\")\n        \n        self.work_tree = self.git_dir.parent\n        \n    @classmethod\n    def init(cls, path: Path = None) -> 'Repository':\n        \"\"\"\n        Initialize a new Git repository.\n        \n        Args:\n            path: Directory to initialize (default: current directory)\n            \n        Returns:\n            Repository object for the newly created repository\n        \"\"\"\n        if path is None:\n            path = Path.cwd()\n        \n        git_dir = path / '.git'\n        \n        # TODO 1: Check if .git already exists and handle appropriately\n        # TODO 2: Create .git directory structure (objects, refs, etc.)\n        # TODO 3: Create initial HEAD file pointing to refs/heads/master\n        # TODO 4: Create config file with repository format version\n        # TODO 5: Set appropriate permissions on .git directory\n        \n        return cls(path)\n    \n    def object_exists(self, object_hash: str) -> bool:\n        \"\"\"Check if object with given hash exists in object store.\"\"\"\n        # TODO: Implement object existence check\n        pass\n    \n    def read_object(self, object_hash: str) -> tuple[str, bytes]:\n        \"\"\"\n        Read and decompress object from object store.\n        \n        Returns:\n            Tuple of (object_type, content)\n        \"\"\"\n        # TODO: Implement object reading with decompression\n        pass\n    \n    def write_object(self, object_type: str, content: bytes) -> str:\n        \"\"\"\n        Write object to object store with compression.\n        \n        Returns:\n            SHA-1 hash of the stored object\n        \"\"\"\n        # TODO: Implement object writing with compression\n        pass\n```\n\n#### Development Workflow Setup\n\n**Environment Configuration:**\n```python\n# requirements.txt\npytest>=7.0.0\npytest-cov>=4.0.0\nblack>=22.0.0\nmypy>=1.0.0\n\n# .gitignore for your implementation\n__pycache__/\n*.pyc\n*.pyo\n*.pyd\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\n.pytest_cache/\n.coverage\nhtmlcov/\n.mypy_cache/\nexamples/*/\ntest_repos/\n```\n\n#### Milestone 1 Checkpoint: Repository Initialization\n\nAfter implementing the repository initialization logic, verify your implementation with these tests:\n\n**Manual Verification Steps:**\n1. Run `python -m mygit init` in an empty directory\n2. Verify `.git` directory exists with mode 755: `ls -la | grep .git`\n3. Check directory structure: `find .git -type d | sort`\n4. Verify HEAD contents: `cat .git/HEAD` should show `ref: refs/heads/master`\n5. Test error handling: run `mygit init` again, should warn about existing repository\n\n**Expected Directory Structure:**\n```\n.git/\n├── objects/\n│   ├── info/\n│   └── pack/\n├── refs/\n│   ├── heads/\n│   └── tags/\n├── HEAD\n└── config\n```\n\n**Unit Test Template:**\n```python\ndef test_repository_initialization(tmp_path):\n    \"\"\"Test that repository initialization creates correct structure.\"\"\"\n    # Initialize repository\n    repo = Repository.init(tmp_path)\n    \n    # Verify .git directory exists\n    assert (tmp_path / '.git').is_dir()\n    \n    # Verify required subdirectories\n    required_dirs = ['.git/objects', '.git/refs/heads', '.git/refs/tags']\n    for dir_path in required_dirs:\n        assert (tmp_path / dir_path).is_dir()\n    \n    # Verify HEAD file contents\n    head_content = (tmp_path / '.git/HEAD').read_text().strip()\n    assert head_content == 'ref: refs/heads/master'\n    \n    # Verify repository can be reopened\n    repo2 = Repository(tmp_path)\n    assert repo2.git_dir == tmp_path / '.git'\n```\n\n#### Common Development Pitfalls\n\n⚠️ **Pitfall: Binary vs Text File Handling**\nGit objects contain binary data (especially the null bytes in object headers), but many file operations default to text mode. Always open object files in binary mode (`'rb'`, `'wb'`) and use `bytes` objects for all content handling.\n\n⚠️ **Pitfall: Platform Path Differences**\nGit uses forward slashes for paths internally, but your implementation runs on different operating systems. Use `pathlib.Path` for all path manipulation and normalize paths when storing them in Git objects.\n\n⚠️ **Pitfall: Hash Encoding Confusion**\nSHA-1 hashes appear in three forms: binary (20 bytes), hex string (40 chars), and hex bytes (40 bytes). Be explicit about which format you're using and convert consistently using `.digest()`, `.hexdigest()`, and `.encode()`.\n\n⚠️ **Pitfall: Directory Creation Race Conditions**\nWhen multiple Git operations run simultaneously, directory creation can fail if another process creates the directory first. Use `mkdir(parents=True, exist_ok=True)` to handle this gracefully.\n\n#### Language-Specific Hints for Python\n\n**File I/O Patterns:**\n- Use `with open(path, 'rb') as f:` for all object file operations\n- Use `Path.read_bytes()` and `Path.write_bytes()` for simple file operations\n- Use `os.makedirs(path, exist_ok=True)` for directory creation\n\n**Binary Data Handling:**\n- Use `struct.pack()` and `struct.unpack()` for binary index format\n- Use `bytes.join()` for concatenating binary data\n- Use `.encode('utf-8')` and `.decode('utf-8')` for string/bytes conversion\n\n**Error Handling:**\n- Catch `FileNotFoundError` for missing objects and references\n- Catch `OSError` for file system permission issues\n- Use custom exception classes like `ObjectNotFoundError` for Git-specific errors\n\nThis implementation foundation provides the scaffolding needed for all eight milestones. The modular structure allows you to implement components incrementally while maintaining clean separation of concerns. The utility functions handle cross-cutting concerns like hashing and path manipulation consistently across the entire codebase.\n\n\n## Goals and Non-Goals\n\n> **Milestone(s):** This section establishes the scope and boundaries for all eight milestones, from repository initialization through three-way merging\n\nBuilding a complete Git implementation requires making deliberate choices about what to include and what to exclude. Git itself has evolved over nearly two decades and includes hundreds of commands, optimization strategies, and edge case handling that would overwhelm any learning project. Our implementation focuses on the core mechanisms that make Git fundamentally different from other version control systems: content-addressable storage, immutable object graphs, and distributed merge capabilities.\n\nThe key insight driving our scope decisions is that Git's power comes from a small set of elegant primitives that compose to create sophisticated behaviors. By implementing these primitives correctly, we gain deep understanding of how modern version control systems work at their foundation. Advanced features like remote synchronization, pack file compression, and complex merge strategies are all built on top of these same primitives.\n\n### Functional Goals\n\nOur Git implementation will support eight core operations that demonstrate the fundamental principles of content-addressable version control. These operations form a complete workflow from repository creation through collaborative development scenarios.\n\n**Repository Lifecycle Management:**\n\n| Operation | Command | Purpose | Key Learning |\n|-----------|---------|---------|--------------|\n| Repository Initialization | `Repository.init()` | Create `.git` directory structure with proper permissions and default configuration | Understanding Git's on-disk layout and reference system initialization |\n| Repository Discovery | `find_git_directory()` | Locate the nearest `.git` directory by traversing parent directories | How Git commands work from any subdirectory within a repository |\n\nThe repository lifecycle operations establish the workspace where all other Git operations occur. Repository initialization demonstrates how Git creates its internal data structures, while repository discovery shows how Git maintains context across the entire project directory tree.\n\n**Content Storage and Retrieval:**\n\n| Operation | Command | Purpose | Key Learning |\n|-----------|---------|---------|--------------|\n| Blob Storage | `hash-object` | Compute SHA-1 hash and store file contents as compressed blob objects | Content-addressable storage principles and object deduplication |\n| Object Retrieval | `cat-file` | Decompress and display stored objects by their hash | How immutable objects enable reliable content addressing |\n| Tree Creation | `write-tree` | Build tree objects representing directory structure from staged files | Hierarchical directory representation using object references |\n| Tree Inspection | `ls-tree` | Display tree object contents showing file modes, types, and hashes | Understanding how Git tracks file metadata and permissions |\n\nContent operations form the foundation of Git's storage model. These operations demonstrate how Git transforms the familiar file system metaphor into an immutable, cryptographically-verified object store. The progression from individual file storage (blobs) to directory structure representation (trees) shows how Git builds complex data from simple primitives.\n\n**History and Version Management:**\n\n| Operation | Command | Purpose | Key Learning |\n|-----------|---------|---------|--------------|\n| Commit Creation | `commit-tree` | Create commit objects linking trees with metadata and parent pointers | How immutable history is built through directed acyclic graph structure |\n| History Traversal | Navigate parent commit chains | Follow commit links to reconstruct project history | Understanding Git's approach to temporal relationships between versions |\n\nHistory management operations demonstrate how Git creates tamper-evident project timelines. Unlike systems that store differences between versions, Git stores complete snapshots linked by cryptographic hashes, making history manipulation detectable and enabling powerful analysis capabilities.\n\n**Branch and Reference Management:**\n\n| Operation | Command | Purpose | Key Learning |\n|-----------|---------|---------|--------------|\n| Branch Creation | Create files in `.git/refs/heads/` | Associate human-readable names with commit hashes | How Git provides convenient aliases for navigating object graph |\n| Branch Switching | Update `HEAD` reference | Change working directory context to different branch tip | Understanding symbolic references and detached HEAD states |\n| Reference Resolution | Resolve symbolic and direct references | Convert branch names to specific commit hashes | How Git maintains consistency between human naming and content addressing |\n\nReference operations bridge the gap between Git's cryptographic object model and human workflow needs. These operations show how Git maintains the benefits of content-addressable storage while providing familiar branch-based development patterns.\n\n**Staging and Workflow Management:**\n\n| Operation | Command | Purpose | Key Learning |\n|-----------|---------|---------|--------------|\n| File Staging | `add` | Move files from working directory to staging area with blob creation | Understanding Git's three-tree architecture and incremental commit preparation |\n| Status Calculation | `status` | Compare working directory, index, and HEAD to show modification states | How Git efficiently detects changes across multiple contexts |\n| Index Management | Binary `.git/index` file operations | Maintain sorted list of staged files with metadata caching | Git's approach to performance optimization through cached file information |\n\nStaging operations demonstrate Git's unique three-stage workflow that separates file modification, commit preparation, and history recording. This separation enables precise control over what changes enter the permanent record and supports complex development workflows.\n\n**Change Analysis and Comparison:**\n\n| Operation | Command | Purpose | Key Learning |\n|-----------|---------|---------|--------------|\n| Difference Calculation | `diff` | Compute line-by-line changes between file versions using Myers algorithm | Understanding how version control systems analyze and present textual changes |\n| Unified Diff Output | Generate standard diff format | Present changes in human-readable format with context lines and hunk headers | Industry-standard approaches to change visualization |\n\nDifference calculation operations reveal how Git analyzes changes between versions. Understanding diff algorithms provides insight into how all version control systems approach the fundamental problem of change detection and presentation.\n\n**Collaborative Development Support:**\n\n| Operation | Command | Purpose | Key Learning |\n|-----------|---------|---------|--------------|\n| Three-Way Merge | `merge` | Combine changes from two branches using common ancestor as merge base | Understanding Git's approach to collaborative development and conflict resolution |\n| Merge Base Calculation | Find lowest common ancestor | Identify the optimal point for comparing divergent development lines | Graph algorithms applied to version control history |\n| Conflict Detection | Identify overlapping changes | Recognize when automatic merging is impossible and manual resolution is required | How version control systems handle ambiguous merge scenarios |\n\nMerge operations demonstrate Git's most sophisticated collaborative features. Three-way merging shows how distributed version control systems enable independent development while maintaining the ability to recombine work systematically.\n\n> **Design Insight**: These eight operation categories form a complete development workflow while teaching the core principles that make Git unique: content addressing, immutable history, three-tree architecture, and systematic merge handling. Each operation builds on primitives established in previous operations, creating a natural learning progression.\n\n### Explicit Non-Goals\n\nOur implementation deliberately excludes advanced Git features that, while important for production use, would distract from learning the core principles. These exclusions allow us to focus on fundamental concepts without getting lost in optimization details or edge case handling.\n\n**Remote Repository Operations:**\n\n| Excluded Feature | Rationale | Learning Impact |\n|------------------|-----------|-----------------|\n| `clone`, `fetch`, `push`, `pull` | Remote operations require network protocols, authentication, and synchronization strategies | These are applications of local Git primitives rather than fundamental storage concepts |\n| SSH/HTTPS transport protocols | Protocol implementation involves security, networking, and error handling unrelated to version control | Understanding local operations provides foundation for later network protocol study |\n| Remote reference tracking | Tracking multiple remote repositories adds complexity without teaching core storage principles | Local branch operations demonstrate the same reference management concepts |\n\nRemote operations, while essential for collaborative development, are fundamentally applications of the local operations we do implement. Understanding how Git stores and manipulates objects locally provides the foundation needed to later understand how those same objects are synchronized across repositories.\n\n**Performance Optimizations:**\n\n| Excluded Feature | Rationale | Learning Impact |\n|------------------|-----------|-----------------|\n| Pack files and delta compression | Pack files are storage optimizations that obscure the object model during learning | Understanding individual object storage first makes pack file optimizations more meaningful later |\n| Index version 2+ extensions | Newer index formats add performance features without changing fundamental staging concepts | Learning basic index operations provides foundation for understanding extensions |\n| Parallel object processing | Concurrency optimizations complicate core algorithm understanding | Sequential implementations are easier to debug and understand during learning |\n| Memory-mapped file access | Low-level optimizations distract from high-level version control concepts | Standard file I/O demonstrates the same concepts with clearer code |\n\nPerformance optimizations, while crucial for large repositories, often obscure the underlying algorithms during initial learning. Our implementation prioritizes clarity and correctness over performance, making the fundamental concepts more accessible.\n\n> **Critical Exclusion Rationale**: Pack files deserve special mention as they represent one of Git's most important optimizations. However, pack files are essentially a compression layer over the object model we do implement. Learning individual object storage first provides the conceptual foundation needed to understand why pack files exist and how they work.\n\n**Advanced Merge and Conflict Resolution:**\n\n| Excluded Feature | Rationale | Learning Impact |\n|------------------|-----------|-----------------|\n| Octopus merges (more than two parents) | Multiple parent merges are rare and don't teach additional concepts beyond two-parent merging | Two-parent merges demonstrate all the fundamental merge base and conflict resolution concepts |\n| Rename detection during merge | Rename tracking requires sophisticated file similarity algorithms | File-level merging demonstrates core three-way merge concepts without algorithmic complexity |\n| Advanced merge strategies (`subtree`, `ours`, `theirs`) | Alternative merge strategies are specialized tools for specific workflows | Standard recursive three-way merge teaches the fundamental merge principles |\n| Interactive conflict resolution | User interface concerns distract from merge algorithm understanding | Conflict marker generation demonstrates conflict detection principles |\n\nAdvanced merge features solve specific workflow problems but don't teach additional fundamental concepts beyond three-way merging with conflict detection. Our implementation covers the core merge principles that underlie all of Git's merge strategies.\n\n**Extended Object Model Features:**\n\n| Excluded Feature | Rationale | Learning Impact |\n|------------------|-----------|-----------------|\n| Annotated tags | Tags are references with additional metadata, not fundamental object types | Basic reference handling demonstrates the same storage and retrieval concepts |\n| Signed commits and tags | Cryptographic signatures are security features independent of version control concepts | Object integrity through SHA-1 hashing demonstrates core verification principles |\n| Git attributes and filters | Content filtering is a layer above the object model | Understanding basic object storage provides foundation for filter comprehension |\n| Submodules | Submodules are repository composition features built on basic Git operations | Core repository operations demonstrate the primitives submodules use |\n\nExtended object model features are important for production workflows but are built using the same storage primitives we do implement. Understanding blob, tree, and commit objects provides the foundation for understanding how these extensions work.\n\n**File System and Platform Features:**\n\n| Excluded Feature | Rationale | Learning Impact |\n|------------------|-----------|-----------------|\n| Symbolic link handling | Platform-specific file system features add complexity without teaching version control concepts | Regular file handling demonstrates core content tracking principles |\n| File permission preservation | File metadata tracking is important but secondary to content versioning concepts | Basic mode bits demonstrate metadata handling without platform complexity |\n| Large file support (LFS) | Large files require external storage systems beyond Git's scope | Understanding regular file storage shows why large file extensions exist |\n| Cross-platform line ending handling | Text file normalization is important but orthogonal to version control storage | Binary content handling demonstrates core storage without text processing complexity |\n\nFile system integration features solve important practical problems but don't teach the fundamental version control concepts that make Git unique. Our implementation focuses on the storage and merge algorithms that form Git's conceptual core.\n\n**Configuration and User Interface:**\n\n| Excluded Feature | Rationale | Learning Impact |\n|------------------|-----------|-----------------|\n| Global and local configuration files | Configuration management is important but separate from core version control algorithms | Hardcoded defaults allow focus on storage and merge logic |\n| Command-line argument parsing | User interface concerns distract from algorithmic understanding | Direct function calls demonstrate algorithm behavior more clearly |\n| Error message localization | User experience features don't teach version control concepts | Simple error messages focus attention on understanding failure modes |\n| Interactive staging (`add -p`) | User interface features for workflow convenience | Basic staging demonstrates the fundamental three-tree architecture |\n\nConfiguration and interface features improve user experience but don't teach the fundamental algorithms that make version control systems work. Our implementation uses direct function calls and simple interfaces to keep focus on the core concepts.\n\n> **Architecture Decision: Scope Boundary Principle**\n> - **Context**: Git includes hundreds of features accumulated over decades of development, making complete implementation impractical for learning\n> - **Options Considered**: \n>   1. Implement minimal subset (init, add, commit only)\n>   2. Implement core workflow with basic collaboration (our choice)\n>   3. Attempt complete Git compatibility\n> - **Decision**: Implement complete local workflow plus basic three-way merging\n> - **Rationale**: This scope teaches all fundamental Git concepts (content addressing, immutable history, three-tree architecture, collaborative merging) without overwhelming complexity. Each operation builds naturally on previous ones, creating clear learning progression.\n> - **Consequences**: Learners understand Git's conceptual foundation and can later study advanced features with solid grounding. Implementation remains manageable while covering realistic development workflows.\n\n### Implementation Guidance\n\nBuilding a Git implementation requires careful technology choices and project organization to manage complexity while maintaining focus on core learning objectives. The following recommendations balance educational value with practical implementation concerns.\n\n**A. Technology Recommendations:**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| SHA-1 Hashing | `hashlib.sha1()` built-in library | Custom SHA-1 implementation for deeper understanding |\n| File Compression | `zlib` standard library for object compression | Custom compression algorithms |\n| Binary Parsing | `struct` module for index file format | Custom binary serialization framework |\n| File System Operations | `pathlib.Path` for cross-platform path handling | Direct `os` module calls with manual path construction |\n| Diff Algorithm | Myers algorithm implementation from scratch | External diff library (`difflib` for validation) |\n| Command Interface | Direct function calls for simplicity | Full command-line parser (`argparse`) |\n\nThe simple options provide clear, focused implementations that highlight the core concepts without unnecessary complexity. Advanced options are available for learners who want deeper understanding of specific components.\n\n**B. Recommended File Structure:**\n\n```\nbuild-your-own-git/\n├── git/\n│   ├── __init__.py\n│   ├── repository.py          # Repository class and initialization\n│   ├── objects/\n│   │   ├── __init__.py\n│   │   ├── blob.py           # Blob object handling\n│   │   ├── tree.py           # Tree object creation and parsing\n│   │   ├── commit.py         # Commit object operations\n│   │   └── store.py          # Object store implementation\n│   ├── refs/\n│   │   ├── __init__.py\n│   │   ├── reference.py      # Reference resolution and management\n│   │   └── symbolic.py       # HEAD and symbolic reference handling\n│   ├── index/\n│   │   ├── __init__.py\n│   │   ├── staging.py        # Add and remove operations\n│   │   └── status.py         # Status calculation\n│   ├── diff/\n│   │   ├── __init__.py\n│   │   ├── myers.py          # Myers diff algorithm\n│   │   └── unified.py        # Unified diff output formatting\n│   └── merge/\n│       ├── __init__.py\n│       ├── three_way.py      # Three-way merge implementation\n│       └── conflicts.py      # Conflict detection and marking\n├── tests/\n│   ├── test_repository.py\n│   ├── test_objects.py\n│   ├── test_refs.py\n│   ├── test_index.py\n│   ├── test_diff.py\n│   └── test_merge.py\n├── examples/\n│   ├── basic_workflow.py     # Demonstrates typical Git workflow\n│   └── merge_scenario.py     # Shows merge and conflict resolution\n└── README.md\n```\n\nThis structure separates concerns logically while keeping related functionality together. Each major component lives in its own module with clear dependencies between layers.\n\n**C. Infrastructure Starter Code:**\n\n**Repository Discovery and Initialization** (Complete implementation):\n\n```python\n# git/repository.py\nimport os\nfrom pathlib import Path\nfrom typing import Optional\n\nclass Repository:\n    \"\"\"Represents a Git repository with working directory and git directory.\"\"\"\n    \n    def __init__(self, git_dir: Path, work_tree: Path):\n        self.git_dir = git_dir\n        self.work_tree = work_tree\n    \n    @classmethod\n    def init(cls, path: Path) -> 'Repository':\n        \"\"\"Initialize a new Git repository at the given path.\"\"\"\n        git_dir = path / '.git'\n        \n        # Create directory structure\n        git_dir.mkdir(exist_ok=True)\n        (git_dir / 'objects').mkdir(exist_ok=True)\n        (git_dir / 'refs' / 'heads').mkdir(parents=True, exist_ok=True)\n        (git_dir / 'refs' / 'tags').mkdir(exist_ok=True)\n        \n        # Create HEAD file pointing to default branch\n        head_file = git_dir / 'HEAD'\n        head_file.write_text('ref: refs/heads/master\\n')\n        \n        # Create basic config\n        config_file = git_dir / 'config'\n        config_content = \"\"\"[core]\n    repositoryformatversion = 0\n    filemode = true\n    bare = false\n\"\"\"\n        config_file.write_text(config_content)\n        \n        return cls(git_dir, path)\n    \n    def object_path_from_hash(self, object_hash: str) -> Path:\n        \"\"\"Convert SHA-1 hash to object file path.\"\"\"\n        return self.git_dir / 'objects' / object_hash[:2] / object_hash[2:]\n\ndef find_git_directory(start_path: Path) -> Optional[Path]:\n    \"\"\"Find .git directory by walking up the directory tree.\"\"\"\n    current = start_path.resolve()\n    while current != current.parent:\n        git_dir = current / '.git'\n        if git_dir.is_dir():\n            return git_dir\n        current = current.parent\n    return None\n```\n\n**SHA-1 and Object Hashing Utilities** (Complete implementation):\n\n```python\n# git/objects/store.py\nimport hashlib\nimport zlib\nfrom pathlib import Path\n\n# Constants\nSHA1_HEX_LENGTH = 40\nOBJECT_HEADER_FORMAT = '{type} {size}\\0{content}'\n\ndef compute_sha1(content: bytes) -> str:\n    \"\"\"Compute SHA-1 hash of raw bytes, returning hex string.\"\"\"\n    return hashlib.sha1(content).hexdigest()\n\ndef compute_object_hash(object_type: str, content: bytes) -> str:\n    \"\"\"Compute Git object hash with proper header.\"\"\"\n    header = f'{object_type} {len(content)}'.encode() + b'\\0'\n    full_content = header + content\n    return compute_sha1(full_content)\n\ndef store_object(git_dir: Path, object_type: str, content: bytes) -> str:\n    \"\"\"Store a Git object and return its hash.\"\"\"\n    object_hash = compute_object_hash(object_type, content)\n    \n    # Create object file path\n    obj_dir = git_dir / 'objects' / object_hash[:2]\n    obj_dir.mkdir(exist_ok=True)\n    obj_file = obj_dir / object_hash[2:]\n    \n    # Write compressed object\n    header = f'{object_type} {len(content)}'.encode() + b'\\0'\n    full_content = header + content\n    compressed = zlib.compress(full_content)\n    obj_file.write_bytes(compressed)\n    \n    return object_hash\n\ndef load_object(git_dir: Path, object_hash: str) -> tuple[str, bytes]:\n    \"\"\"Load and decompress a Git object, returning (type, content).\"\"\"\n    obj_file = git_dir / 'objects' / object_hash[:2] / object_hash[2:]\n    \n    if not obj_file.exists():\n        raise ValueError(f\"Object {object_hash} not found\")\n    \n    # Read and decompress\n    compressed = obj_file.read_bytes()\n    decompressed = zlib.decompress(compressed)\n    \n    # Parse header\n    null_index = decompressed.find(b'\\0')\n    header = decompressed[:null_index].decode()\n    content = decompressed[null_index + 1:]\n    \n    object_type, size_str = header.split(' ', 1)\n    expected_size = int(size_str)\n    \n    if len(content) != expected_size:\n        raise ValueError(f\"Object {object_hash} has incorrect size\")\n    \n    return object_type, content\n```\n\n**D. Core Logic Skeleton Code:**\n\n**Blob Operations** (signatures with detailed TODOs):\n\n```python\n# git/objects/blob.py\nfrom pathlib import Path\n\ndef hash_object(file_path: Path, git_dir: Path) -> str:\n    \"\"\"Hash a file and store it as a blob object.\n    \n    Returns the SHA-1 hash of the stored blob.\n    \"\"\"\n    # TODO 1: Read file content as bytes (handle both text and binary files)\n    # TODO 2: Use store_object() with object_type='blob' and file content\n    # TODO 3: Return the computed hash\n    # Hint: Git treats all files as binary data, don't decode as text\n    pass\n\ndef cat_file_blob(object_hash: str, git_dir: Path) -> bytes:\n    \"\"\"Retrieve and return blob content by hash.\"\"\"\n    # TODO 1: Use load_object() to get object type and content\n    # TODO 2: Verify object_type is 'blob', raise error if not\n    # TODO 3: Return the raw content bytes\n    # Hint: This is the reverse of hash_object - just extract content\n    pass\n```\n\n**Tree Operations** (signatures with detailed TODOs):\n\n```python\n# git/objects/tree.py\nfrom pathlib import Path\nfrom typing import List, Tuple\n\nTreeEntry = Tuple[str, str, str]  # (mode, name, hash)\n\ndef create_tree_from_index(index_entries: List[dict], git_dir: Path) -> str:\n    \"\"\"Create tree object from staged index entries.\n    \n    Returns the hash of the created tree object.\n    \"\"\"\n    # TODO 1: Sort index entries by name (Git requires lexicographic order)\n    # TODO 2: For each entry, format as: mode + ' ' + name + '\\0' + binary_hash\n    # TODO 3: Handle subdirectories by recursively creating tree objects\n    # TODO 4: Use store_object() with object_type='tree' and formatted content\n    # TODO 5: Return the computed tree hash\n    # Hint: Binary hash is bytes.fromhex(hash_string) - not the hex string!\n    pass\n\ndef parse_tree_object(tree_hash: str, git_dir: Path) -> List[TreeEntry]:\n    \"\"\"Parse tree object and return list of (mode, name, hash) entries.\"\"\"\n    # TODO 1: Use load_object() to get tree content\n    # TODO 2: Parse binary tree format: mode + ' ' + name + '\\0' + 20_byte_hash\n    # TODO 3: Convert each entry to (mode, name, hex_hash) tuple\n    # TODO 4: Return sorted list of entries\n    # Hint: Use content.find(b'\\0') to locate null bytes between name and hash\n    pass\n\ndef ls_tree(tree_hash: str, git_dir: Path) -> None:\n    \"\"\"Display tree contents in human-readable format.\"\"\"\n    # TODO 1: Use parse_tree_object() to get entries\n    # TODO 2: For each entry, determine object type (blob vs tree) from mode\n    # TODO 3: Print in format: mode object_type hash name\n    # TODO 4: Mode 40000 = tree, 100644 = regular file, 100755 = executable\n    # Hint: You can also load each referenced object to verify its type\n    pass\n```\n\n**E. Language-Specific Hints:**\n\n**Python-Specific Implementation Tips:**\n\n- Use `pathlib.Path` consistently for all file system operations - it handles cross-platform path differences automatically\n- The `hashlib.sha1()` function requires bytes input, not strings - use `.encode()` for text content\n- For binary file operations, always use `'rb'` and `'wb'` modes to avoid text encoding issues\n- Use `struct.pack()` and `struct.unpack()` for binary data formats like the index file\n- The `zlib.compress()` and `zlib.decompress()` functions handle Git's object compression transparently\n- Use `os.stat()` to get file modification times and permissions for index entries\n- Handle both relative and absolute paths using `Path.resolve()` to avoid confusion\n\n**Common Python Pitfalls:**\n\n⚠️ **Pitfall: String vs Bytes Confusion**\nMany Git formats use binary data, but Python 3 distinguishes strings (Unicode) from bytes. Always use bytes for:\n- File content when hashing\n- SHA-1 hash computation  \n- Compressed object storage\n- Binary parts of index file format\n\nUse strings only for:\n- Hash values in hex format\n- File paths and names\n- Text content when displaying to user\n\n⚠️ **Pitfall: Path Handling**\nDon't use string concatenation for file paths - use `Path` objects:\n```python\n# Wrong: path + '/' + filename\n# Right: path / filename\n```\n\nThe `Path` class handles platform differences and prevents common path-related bugs.\n\n**F. Milestone Checkpoints:**\n\nAfter implementing each milestone, verify functionality with these specific tests:\n\n**Milestone 1-2 Checkpoint (Repository + Blob Objects):**\n```python\n# Test repository initialization\nrepo = Repository.init(Path('./test-repo'))\nassert (repo.git_dir / 'objects').exists()\nassert (repo.git_dir / 'HEAD').read_text().strip() == 'ref: refs/heads/master'\n\n# Test blob storage and retrieval  \ntest_content = b\"Hello, Git!\"\nblob_hash = hash_object_from_content(test_content, repo.git_dir)\nretrieved = cat_file_blob(blob_hash, repo.git_dir)\nassert retrieved == test_content\nprint(f\"✓ Blob hash: {blob_hash}\")\n```\n\nExpected output: 40-character hex hash that matches running `echo \"Hello, Git!\" | git hash-object --stdin` in real Git.\n\n**Milestone 3-4 Checkpoint (Trees + Commits):**\n```python\n# Create a simple tree and commit\nentries = [\n    {'mode': '100644', 'name': 'README.md', 'hash': readme_blob_hash},\n    {'mode': '100644', 'name': 'main.py', 'hash': main_blob_hash}\n]\ntree_hash = create_tree_from_entries(entries, repo.git_dir)\ncommit_hash = create_commit(tree_hash, [], \"Initial commit\", repo.git_dir)\n\n# Verify tree parsing\ntree_entries = parse_tree_object(tree_hash, repo.git_dir)\nassert len(tree_entries) == 2\nprint(f\"✓ Tree: {tree_hash}\")\nprint(f\"✓ Commit: {commit_hash}\")\n```\n\n**G. Debugging Tips:**\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|-----------------|-----|\n| Hash mismatch with real Git | Incorrect object format or missing null bytes | Compare hex dump of your object vs Git's object | Check header format: `{type} {size}\\0{content}` |\n| \"Object not found\" errors | Wrong path calculation or hash format | Print object file paths and verify they exist | Ensure hash[:2] directory exists before creating file |\n| Compression errors | Storing uncompressed data or wrong compression level | Try decompressing stored objects manually | Use `zlib.compress()` with default settings |\n| Index corruption | Incorrect binary format or endianness | Hex dump the index file and compare to spec | Use `struct.pack('>I', value)` for big-endian integers |\n| Tree parsing failures | Binary hash vs hex hash confusion | Check if hash storage is 20 bytes or 40 chars | Store binary: `bytes.fromhex(hash_string)` |\n| Merge infinite loops | Cycle in commit graph or incorrect parent following | Trace parent chain manually and look for cycles | Add visited set to prevent infinite recursion |\n\nThe most common debugging approach is comparing your implementation's output with real Git using identical input. Git's object format is precisely specified, so byte-for-byte comparison reveals implementation errors quickly.\n\n\n## High-Level Architecture\n\n> **Milestone(s):** This section provides the architectural foundation for all milestones, with particular emphasis on Milestone 1 (Repository Initialization) and the component separation needed for Milestones 2-8\n\nThe architecture of our Git implementation follows a clean separation of concerns across four distinct layers, each with well-defined responsibilities and interfaces. Understanding this architectural foundation is crucial because Git's power emerges from the elegant interaction between these components, particularly how they all coordinate through the content-addressable object store.\n\n![Git System Architecture](./diagrams/system-architecture.svg)\n\n### System Components\n\nThe Git system architecture consists of four primary components that work together to provide version control functionality. Each component has distinct responsibilities and maintains its own data structures, but they interact through well-defined interfaces to create a cohesive system.\n\n#### Object Store: The Immutable Foundation\n\nThe **Object Store** serves as the foundational layer of our Git implementation, providing content-addressable storage for all repository data. Think of it as a digital warehouse where every item has a unique barcode derived from its contents - you can store something once and retrieve it forever using that barcode, with mathematical certainty that the contents haven't changed.\n\nThe Object Store manages three critical responsibilities: storing Git objects with SHA-1 hash-based addressing, providing immutable content retrieval, and maintaining data integrity through cryptographic verification. Every piece of content that enters Git - whether it's a file, directory structure, or commit metadata - gets processed through this layer and becomes permanently addressable by its hash.\n\n| Component | Responsibility | Data Managed | Interface Methods |\n|-----------|---------------|---------------|-------------------|\n| Object Store | Content-addressable storage | Blobs, trees, commits | `store_object()`, `retrieve_object()`, `object_exists()`, `list_objects()` |\n| Index | Staging area management | File metadata and hashes | `add_file()`, `remove_file()`, `get_status()`, `write_tree()` |\n| References | Branch and tag management | Commit pointers | `create_branch()`, `update_ref()`, `resolve_ref()`, `list_refs()` |\n| Working Directory | File system interface | Current project files | `checkout_files()`, `scan_changes()`, `apply_diff()` |\n\nThe Object Store's design centers around three core data structures that represent different types of content. **Blob objects** store file content as immutable byte sequences, with each blob identified by the SHA-1 hash of its contents. **Tree objects** represent directory structures, containing sorted lists of file and subdirectory entries with their corresponding hashes. **Commit objects** capture project snapshots, linking to a tree hash and containing metadata about the change.\n\n> **Key Insight**: The Object Store's immutability is what enables Git's powerful features. Because objects never change once stored, operations like branching, merging, and history traversal become safe and efficient. Multiple branches can share the same objects without fear of interference.\n\n**Object Store Data Structures:**\n\n| Object Type | Header Format | Content Structure | Key Properties |\n|-------------|---------------|-------------------|----------------|\n| Blob | `blob {size}\\0` | Raw file bytes | Content-addressed, immutable |\n| Tree | `tree {size}\\0` | Sorted entries: `{mode} {name}\\0{hash}` | Directory representation |\n| Commit | `commit {size}\\0` | Tree hash, parents, author, message | Links project snapshots |\n\nThe Object Store implements a simple but effective storage algorithm. When storing an object, it first computes the SHA-1 hash of the complete object (header plus content), then compresses the object using zlib compression, and finally stores the compressed data at a file system path derived from the hash. The path structure uses the first two hexadecimal characters of the hash as a directory name, with the remaining 38 characters as the filename.\n\n#### Index: The Staging Area Bridge\n\nThe **Index** acts as an intermediate layer between the working directory and the object store, implementing Git's distinctive staging area concept. Picture it as a photographer's contact sheet - a place where you arrange and review your shots before committing to the final print. The Index allows developers to incrementally prepare commits by selectively staging changes.\n\nThe Index maintains a binary file at `.git/index` that contains metadata about staged files, including their object hashes, file system timestamps, and permission modes. This metadata enables Git to quickly detect when files have been modified since they were last staged, without needing to re-hash file contents on every status check.\n\n**Index Entry Structure:**\n\n| Field | Size | Type | Description |\n|-------|------|------|-------------|\n| Create Time | 8 bytes | uint64 | File creation timestamp |\n| Modify Time | 8 bytes | uint64 | File modification timestamp |\n| Device ID | 4 bytes | uint32 | File system device identifier |\n| Inode | 4 bytes | uint32 | File system inode number |\n| Mode | 4 bytes | uint32 | File permissions and type |\n| UID | 4 bytes | uint32 | Owner user identifier |\n| GID | 4 bytes | uint32 | Owner group identifier |\n| File Size | 4 bytes | uint32 | Size of file in bytes |\n| SHA-1 Hash | 20 bytes | bytes | Object hash of file contents |\n| Flags | 2 bytes | uint16 | Name length and stage flags |\n| Path Name | Variable | UTF-8 string | Relative path from repository root |\n\nThe Index enables the three-way status calculation that shows users what changes are staged, unstaged, or untracked. It compares file timestamps and sizes between the working directory, index, and HEAD commit to efficiently determine file states without expensive hash computations for unchanged files.\n\n#### References: The Human-Readable Navigation System\n\nThe **References** component provides human-readable names for commits, implementing Git's branch and tag system. Think of references as bookmarks in a vast library - instead of memorizing long SHA-1 hashes, you can use meaningful names like \"main\" or \"feature-login\" to navigate your project's history.\n\nReferences are stored as simple text files in the `.git/refs` directory hierarchy. Branch references live in `.git/refs/heads/`, tag references in `.git/refs/tags/`, and remote references in `.git/refs/remotes/`. Each reference file contains a single line with either a commit hash (direct reference) or a reference to another reference (symbolic reference).\n\n**Reference Types:**\n\n| Reference Type | Storage Location | Content Format | Example |\n|----------------|------------------|----------------|---------|\n| Branch | `.git/refs/heads/{name}` | SHA-1 hash | `a1b2c3d4e5f6...` |\n| Tag | `.git/refs/tags/{name}` | SHA-1 hash or tag object | `a1b2c3d4e5f6...` |\n| HEAD | `.git/HEAD` | Symbolic or direct ref | `ref: refs/heads/main` |\n| Detached HEAD | `.git/HEAD` | Direct SHA-1 hash | `a1b2c3d4e5f6...` |\n\nThe HEAD reference deserves special attention as it tracks the current branch or commit. In normal operation, HEAD contains a symbolic reference like `ref: refs/heads/main`, indicating that commits should advance the main branch. In detached HEAD state, HEAD contains a direct commit hash, meaning commits won't advance any branch.\n\n> **Design Decision**: References use the file system as their storage layer rather than the object store. This allows atomic updates through file system operations and makes references easily readable by external tools, while keeping them separate from the immutable object history.\n\n#### Working Directory: The User Interface Layer\n\nThe **Working Directory** represents the file system view of your project, containing the actual files that users edit and build. It serves as the interface between Git's internal data structures and the user's development workflow. The Working Directory component is responsible for checking out files from the object store, detecting changes, and applying updates from commits.\n\nThe Working Directory maintains no persistent state of its own - it's purely a projection of some commit's tree structure onto the file system. However, it provides crucial functionality for detecting modifications, handling file permissions, and managing the checkout process when switching between branches or commits.\n\n**Working Directory Operations:**\n\n| Operation | Input | Output | Side Effects |\n|-----------|--------|--------|--------------|\n| Checkout | Tree hash | File system changes | Updates working files |\n| Scan Changes | File paths | Modified file list | None |\n| Apply Diff | Diff patches | File modifications | Updates working files |\n| Clean | None | Status report | Removes untracked files |\n\nThe Working Directory implements change detection through file system metadata comparison. By comparing modification times, file sizes, and inode numbers against the Index's cached values, it can quickly identify potentially modified files. Only files that appear changed need to be re-hashed to determine if their content actually differs.\n\n### Recommended File Structure\n\nOrganizing the codebase to mirror the architectural layers makes the system easier to understand, test, and maintain. Each component should have its own module with clear boundaries and minimal dependencies. The following structure separates concerns while enabling the necessary interactions between components.\n\n```\ngit_implementation/\n├── core/\n│   ├── __init__.py              # Core package exports\n│   ├── repository.py            # Repository class and initialization\n│   ├── hash_utils.py            # SHA-1 computation utilities\n│   └── constants.py             # Shared constants and formats\n├── objects/\n│   ├── __init__.py              # Object store package\n│   ├── store.py                 # Object storage and retrieval\n│   ├── blob.py                  # Blob object implementation\n│   ├── tree.py                  # Tree object implementation\n│   ├── commit.py                # Commit object implementation\n│   └── serialization.py         # Object serialization/parsing\n├── index/\n│   ├── __init__.py              # Index package\n│   ├── staging.py               # Index file management\n│   ├── status.py                # Status calculation logic\n│   └── binary_format.py         # Index binary format handling\n├── refs/\n│   ├── __init__.py              # References package\n│   ├── manager.py               # Reference CRUD operations\n│   ├── symbolic.py              # Symbolic reference handling\n│   └── head.py                  # HEAD reference management\n├── working_dir/\n│   ├── __init__.py              # Working directory package\n│   ├── checkout.py              # File checkout operations\n│   ├── scanner.py               # Change detection\n│   └── filesystem.py           # File system utilities\n├── algorithms/\n│   ├── __init__.py              # Algorithms package\n│   ├── diff.py                  # Myers diff implementation\n│   ├── merge.py                 # Three-way merge logic\n│   └── merge_base.py            # Common ancestor calculation\n├── commands/\n│   ├── __init__.py              # Commands package\n│   ├── init.py                  # git init implementation\n│   ├── add.py                   # git add implementation\n│   ├── commit.py                # git commit implementation\n│   ├── branch.py                # git branch implementation\n│   ├── merge.py                 # git merge implementation\n│   └── status.py                # git status implementation\n├── tests/\n│   ├── test_objects/            # Object store tests\n│   ├── test_index/              # Index tests\n│   ├── test_refs/               # References tests\n│   ├── test_algorithms/         # Algorithm tests\n│   └── integration/             # End-to-end tests\n└── main.py                      # CLI entry point\n```\n\nThis structure provides several important benefits for learners and maintainers. The separation between `objects/`, `index/`, `refs/`, and `working_dir/` mirrors the architectural components, making it easy to understand where functionality belongs. The `algorithms/` package isolates complex logic like diff and merge, which can be tested independently. The `commands/` package provides a clean CLI interface without mixing user interaction with core logic.\n\n**Module Dependencies and Interfaces:**\n\n| Module | Direct Dependencies | Key Interfaces |\n|--------|-------------------|----------------|\n| `core/` | None | `Repository`, `compute_sha1()` |\n| `objects/` | `core/` | `ObjectStore`, object type classes |\n| `index/` | `core/`, `objects/` | `Index`, `IndexEntry` |\n| `refs/` | `core/` | `ReferenceManager`, `HEAD` |\n| `working_dir/` | `core/`, `objects/` | `WorkingDirectory`, `FileScanner` |\n| `algorithms/` | `objects/`, `index/` | `diff()`, `merge()`, `find_merge_base()` |\n| `commands/` | All others | Command implementations |\n\n> **Architecture Decision Record: Component Isolation**\n> - **Context**: Git operations involve complex interactions between object storage, indexing, and file system operations. Poor separation leads to tangled dependencies and difficult testing.\n> - **Options Considered**: Monolithic design, layered architecture, component-based architecture\n> - **Decision**: Component-based architecture with clear interface boundaries\n> - **Rationale**: Each component can be developed and tested independently, interfaces prevent tight coupling, and the design mirrors Git's actual architecture making it easier to understand\n> - **Consequences**: Enables parallel development of components, requires more upfront design but pays dividends in maintainability, makes debugging easier by isolating failures to specific components\n\nThe `tests/` directory structure mirrors the main codebase, enabling focused testing of each component. Integration tests verify that components work together correctly, while unit tests ensure each component meets its individual contracts. This testing structure supports the milestone-based development approach by allowing verification of each component as it's built.\n\n**Common Pitfalls in Architecture Organization:**\n\n⚠️ **Pitfall: Circular Dependencies**\nMany learners create circular imports between components, such as the Index importing from References while References import from Index. This happens when components try to directly access each other's internals rather than going through well-defined interfaces. The fix is to pass dependencies as parameters and use dependency injection rather than direct imports between peer components.\n\n⚠️ **Pitfall: Mixing CLI Logic with Core Logic**\nAnother common mistake is embedding command-line parsing, user interaction, and error formatting inside the core Git logic. This makes the core components impossible to test and reuse. Keep all user interface concerns in the `commands/` package, and ensure core components only raise exceptions with structured data that the CLI layer can format appropriately.\n\n⚠️ **Pitfall: Putting Everything in the Repository Class**\nBeginners often make the `Repository` class a \"god object\" that contains all Git functionality. This creates a massive class that's difficult to test and understand. Instead, the `Repository` class should be a lightweight coordinator that holds references to the component instances and provides convenience methods that delegate to the appropriate components.\n\n### Implementation Guidance\n\nThe architectural components should be implemented with clear separation of concerns and well-defined interfaces. This guidance provides the foundational code structure and implementation patterns needed to build each component correctly.\n\n**Technology Recommendations:**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Object Storage | File system + zlib | LevelDB or SQLite |\n| Index Format | Binary struct packing | Protocol Buffers |\n| Hash Computation | hashlib.sha1() | Custom SHA-1 implementation |\n| File System Operations | pathlib.Path | os.path with error handling |\n| Compression | zlib standard library | LZ4 or custom compression |\n\n**Core Infrastructure Code:**\n\nThe following provides complete, working implementations of the foundational utilities that all components depend on:\n\n```python\n# core/constants.py - Shared constants across all components\nSHA1_HEX_LENGTH = 40\nSHA1_BINARY_LENGTH = 20\nOBJECT_HEADER_FORMAT = \"{type} {size}\\0{content}\"\n\n# Git object types\nBLOB_TYPE = \"blob\"\nTREE_TYPE = \"tree\" \nCOMMIT_TYPE = \"commit\"\n\n# Index constants\nINDEX_VERSION = 2\nINDEX_HEADER_SIZE = 12\nINDEX_ENTRY_MIN_SIZE = 62\n\n# File modes (octal values stored as integers)\nFILE_MODE_REGULAR = 0o100644\nFILE_MODE_EXECUTABLE = 0o100755\nFILE_MODE_TREE = 0o040000\nFILE_MODE_SYMLINK = 0o120000\n```\n\n```python\n# core/hash_utils.py - Complete hash computation utilities\nimport hashlib\nfrom typing import bytes\n\ndef compute_sha1(content: bytes) -> str:\n    \"\"\"Compute SHA-1 hash of raw bytes, returning hex digest.\"\"\"\n    hasher = hashlib.sha1()\n    hasher.update(content)\n    return hasher.hexdigest()\n\ndef compute_object_hash(object_type: str, content: bytes) -> str:\n    \"\"\"Compute Git object hash including type header.\"\"\"\n    header = f\"{object_type} {len(content)}\\0\".encode('ascii')\n    full_content = header + content\n    return compute_sha1(full_content)\n\ndef hash_to_path_components(object_hash: str) -> tuple[str, str]:\n    \"\"\"Convert hash to directory and filename components.\"\"\"\n    if len(object_hash) != SHA1_HEX_LENGTH:\n        raise ValueError(f\"Invalid hash length: {len(object_hash)}\")\n    return object_hash[:2], object_hash[2:]\n```\n\n```python\n# core/repository.py - Repository initialization and discovery\nfrom pathlib import Path\nfrom typing import Optional\nimport os\n\nclass Repository:\n    \"\"\"Represents a Git repository with its working tree and git directory.\"\"\"\n    \n    def __init__(self, work_tree: Path, git_dir: Path):\n        self.work_tree = work_tree.resolve()\n        self.git_dir = git_dir.resolve()\n        \n    @classmethod\n    def init(cls, path: Path) -> 'Repository':\n        \"\"\"Initialize a new Git repository at the given path.\"\"\"\n        # TODO 1: Create the target directory if it doesn't exist\n        # TODO 2: Create .git subdirectory structure\n        # TODO 3: Initialize .git/objects with subdirectories  \n        # TODO 4: Initialize .git/refs/heads and .git/refs/tags directories\n        # TODO 5: Create initial HEAD file pointing to refs/heads/master\n        # TODO 6: Create basic config file with repository settings\n        # TODO 7: Set appropriate permissions on .git directory (0755)\n        # Return Repository instance with work_tree=path and git_dir=path/.git\n        pass\n        \n    def object_path_from_hash(self, object_hash: str) -> Path:\n        \"\"\"Convert object hash to file system path.\"\"\"\n        dir_name, file_name = hash_to_path_components(object_hash)\n        return self.git_dir / \"objects\" / dir_name / file_name\n\ndef find_git_directory(start_path: Path) -> Optional[Path]:\n    \"\"\"Locate .git directory by walking up the directory tree.\"\"\"\n    current = start_path.resolve()\n    while current != current.parent:\n        git_dir = current / \".git\"\n        if git_dir.is_dir():\n            return git_dir\n        current = current.parent\n    return None\n```\n\n**Component Interface Skeletons:**\n\nEach major component should implement these interfaces. The skeletons provide method signatures and detailed TODO comments that map to the architectural responsibilities:\n\n```python\n# objects/store.py - Object store component skeleton\nimport zlib\nfrom pathlib import Path\nfrom typing import Optional, bytes\n\nclass ObjectStore:\n    \"\"\"Content-addressable storage for Git objects.\"\"\"\n    \n    def __init__(self, git_dir: Path):\n        self.objects_dir = git_dir / \"objects\"\n        \n    def store_object(self, object_type: str, content: bytes) -> str:\n        \"\"\"Store an object and return its hash.\"\"\"\n        # TODO 1: Compute object hash using compute_object_hash()\n        # TODO 2: Check if object already exists using object_exists()\n        # TODO 3: Create header with format \"{type} {size}\\0\"\n        # TODO 4: Combine header and content into full object\n        # TODO 5: Compress full object using zlib.compress()\n        # TODO 6: Determine storage path using hash_to_path_components()\n        # TODO 7: Create parent directory if it doesn't exist\n        # TODO 8: Write compressed data to object file atomically\n        # TODO 9: Set file permissions to 0444 (read-only)\n        # Return the computed hash\n        pass\n        \n    def retrieve_object(self, object_hash: str) -> tuple[str, bytes]:\n        \"\"\"Retrieve object content and type by hash.\"\"\"\n        # TODO 1: Validate hash format and length\n        # TODO 2: Construct object file path\n        # TODO 3: Check if object file exists, raise error if not\n        # TODO 4: Read and decompress object file using zlib.decompress()\n        # TODO 5: Parse header to extract type and size\n        # TODO 6: Validate content size matches header\n        # TODO 7: Return tuple of (object_type, content)\n        pass\n        \n    def object_exists(self, object_hash: str) -> bool:\n        \"\"\"Check if object exists in store.\"\"\"\n        # TODO: Check if object file exists at computed path\n        pass\n```\n\n**File Structure Creation:**\n\n```python\n# Directory structure creation helper\ndef create_git_directory_structure(git_dir: Path) -> None:\n    \"\"\"Create complete .git directory structure.\"\"\"\n    directories_to_create = [\n        git_dir,\n        git_dir / \"objects\" / \"info\",\n        git_dir / \"objects\" / \"pack\", \n        git_dir / \"refs\" / \"heads\",\n        git_dir / \"refs\" / \"tags\",\n        git_dir / \"hooks\",\n    ]\n    \n    for directory in directories_to_create:\n        directory.mkdir(parents=True, exist_ok=True)\n        # Set directory permissions to 0755\n        directory.chmod(0o755)\n    \n    # Create initial HEAD file\n    head_file = git_dir / \"HEAD\"\n    head_file.write_text(\"ref: refs/heads/master\\n\")\n    \n    # Create basic config\n    config_file = git_dir / \"config\"\n    config_content = \"\"\"[core]\n    repositoryformatversion = 0\n    filemode = true\n    bare = false\n    logallrefupdates = true\n\"\"\"\n    config_file.write_text(config_content)\n```\n\n**Milestone Checkpoints:**\n\nAfter implementing the basic architecture:\n\n1. **Repository Initialization Test**: Run `Repository.init(Path(\"test_repo\"))` and verify the directory structure:\n   ```bash\n   find test_repo/.git -type d | sort\n   # Should show: .git, .git/hooks, .git/objects, .git/objects/info, \n   # .git/objects/pack, .git/refs, .git/refs/heads, .git/refs/tags\n   ```\n\n2. **Object Store Test**: Store and retrieve a simple blob:\n   ```python\n   store = ObjectStore(Path(\"test_repo/.git\"))\n   hash1 = store.store_object(\"blob\", b\"hello world\")\n   obj_type, content = store.retrieve_object(hash1) \n   assert obj_type == \"blob\" and content == b\"hello world\"\n   ```\n\n3. **Component Independence Test**: Each component should be importable and testable in isolation without requiring the others to be fully implemented.\n\n**Debugging Tips:**\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|-----------------|-----|\n| \"Object not found\" errors | Incorrect path computation | Print the computed path and check if file exists | Verify hash_to_path_components() logic |\n| Permission denied on .git | Wrong directory permissions | Check with `ls -la .git` | Set permissions to 0755 on directories |\n| Hash mismatches | Header format incorrect | Print the raw content being hashed | Ensure null byte between size and content |\n| Import errors between components | Circular dependencies | Draw dependency graph | Move shared code to core/, use dependency injection |\n\n\n## Data Model\n\n> **Milestone(s):** This section establishes the data model foundations for Milestone 2 (Object Storage - Blobs), Milestone 3 (Tree Objects), and Milestone 4 (Commit Objects), while providing the conceptual framework for all remaining milestones\n\nThe data model forms the heart of Git's architecture, defining how content is structured, stored, and interconnected within the content-addressable object store. Understanding this model is crucial because every Git operation—from storing a single file to merging complex histories—ultimately manipulates these three fundamental object types and their relationships.\n\n![Git Object Model](./diagrams/object-model.svg)\n\n### Mental Model: The Universal Content Graph\n\nThink of Git's data model as a universal content graph, similar to how Wikipedia represents knowledge. In Wikipedia, articles (like commits) reference other articles and media files (like trees and blobs), creating an interconnected web of information where each piece of content has a unique, permanent address. Just as Wikipedia's internal links remain valid even when articles are moved or renamed, Git's objects reference each other through immutable cryptographic addresses that never change.\n\nThe key insight is that Git doesn't store files and directories the way your operating system does—it stores a graph of content relationships. A commit doesn't \"contain\" files; it points to a tree that describes the project structure at that moment in time. That tree doesn't \"contain\" files either; it points to blobs that hold the actual content. This indirection enables powerful features: two commits can share the same tree (identical project states), multiple trees can reference the same blob (duplicate files), and the entire history forms a graph where content is automatically deduplicated.\n\nConsider how this differs from traditional file storage. When you copy a directory, the operating system duplicates all the files. When Git stores multiple commits with identical files, those files exist only once in the object store, referenced by their content hash. This is why Git repositories remain compact despite having complete project history.\n\n### Git Object Types\n\nGit's object model consists of exactly three object types, each serving a specific purpose in representing project content and history. Every object follows the same fundamental structure: a header containing the object type and size, followed by the raw content, with the entire object identified by the SHA-1 hash of this formatted data.\n\n> **Design Insight:** The three-object model strikes an optimal balance between simplicity and expressiveness. Blobs handle raw content, trees handle directory structure, and commits handle history and metadata. This minimal set can represent arbitrarily complex projects and histories while maintaining Git's core properties of immutability and content-addressable storage.\n\n#### Object Storage Format\n\nEvery Git object follows a consistent storage format that enables content-addressable lookup and integrity verification. This uniformity allows the object store to handle all three object types through a single storage and retrieval mechanism.\n\n| Component | Format | Description |\n|-----------|--------|-------------|\n| Object Header | `{type} {size}\\0` | Object type string, space, decimal byte count, null terminator |\n| Object Content | `{raw_content}` | Type-specific content in binary or text format |\n| Storage Format | `compress(header + content)` | Zlib-compressed complete object |\n| Hash Calculation | `sha1(header + content)` | SHA-1 of uncompressed object |\n| File Path | `.git/objects/{hash[0:2]}/{hash[2:40]}` | First 2 hash chars as directory, remaining 38 as filename |\n\nThe hash calculation is performed on the complete uncompressed object (header + content), but the stored file contains the zlib-compressed version. This separation enables efficient storage while maintaining cryptographic integrity verification.\n\n> **Architecture Decision: Object Header Format**\n> - **Context**: Need a way to store different object types in a unified storage system while enabling type identification and content verification\n> - **Options Considered**: \n>   1. Store type as separate metadata file\n>   2. Use file extensions to indicate type\n>   3. Embed type and size in object content header\n> - **Decision**: Embed `{type} {size}\\0` header in each object's content\n> - **Rationale**: Self-describing objects eliminate metadata synchronization issues, size enables integrity verification, null terminator provides clear binary boundary\n> - **Consequences**: Every object is self-contained and verifiable, but adds small storage overhead for the header\n\n#### Blob Objects\n\nBlob objects store raw file content without any metadata such as filename, permissions, or timestamps. They represent the pure content of files at specific points in time, enabling content deduplication across the entire repository history.\n\n| Property | Description |\n|----------|-------------|\n| Purpose | Store raw file content without filesystem metadata |\n| Content Format | Exact byte sequence from the original file |\n| Deduplication | Files with identical content share the same blob object |\n| Size Limits | Practically unlimited, though performance degrades for very large files |\n| Binary Handling | All content treated as binary; no line-ending or encoding conversions |\n\n**Blob Object Structure:**\n```\nHeader: \"blob {content_length}\\0\"\nContent: {raw_file_bytes}\n```\n\nThe blob hash depends only on content, never on filename or location. This means moving a file without changing its content creates no new objects—the tree changes but the blob remains identical. Similarly, if multiple files in the project have identical content, they share a single blob object.\n\n**Content Handling Considerations:**\n\nBlob objects preserve file content exactly as it exists in the working directory, making no assumptions about text encoding, line endings, or binary formats. This byte-for-byte preservation ensures perfect fidelity when checking out files, but requires careful handling of cross-platform differences at higher levels of the system.\n\n| Scenario | Blob Behavior | Implications |\n|----------|---------------|-------------|\n| Text files with CRLF line endings | Stored exactly as provided | Cross-platform checkouts may differ |\n| Binary files | Stored as-is with no interpretation | Perfect preservation of executable and media files |\n| Empty files | Creates blob with zero-length content | Empty files still consume one object in the store |\n| Large files | Stored completely in single blob | No automatic chunking; entire file must fit in memory |\n\n#### Tree Objects\n\nTree objects represent directory structure at specific points in time, storing sorted lists of files and subdirectories with their associated permissions and object hashes. They provide the hierarchical organization that transforms flat blob storage into recognizable project structure.\n\n**Tree Object Structure:**\n```\nHeader: \"tree {content_length}\\0\"\nContent: {sorted_tree_entries}\n```\n\nEach tree entry follows a specific binary format that packs directory information efficiently while maintaining sort order for consistent hashing:\n\n| Field | Format | Size | Description |\n|-------|--------|------|-------------|\n| Mode | ASCII decimal string | Variable | Unix file mode (permissions and type) |\n| Space | ASCII space character | 1 byte | Separator between mode and name |\n| Name | UTF-8 string | Variable | Filename or directory name |\n| Null Terminator | `\\0` byte | 1 byte | Separator between name and hash |\n| Object Hash | Raw SHA-1 bytes | 20 bytes | Binary object hash (not hex-encoded) |\n\n**Tree Entry Format:**\n```\n{mode} {name}\\0{20_byte_hash}\n```\n\nThe mode field encodes both file permissions and type information using Unix conventions. Understanding these modes is crucial for preserving file system semantics across different platforms.\n\n| Mode | Type | Description |\n|------|------|-------------|\n| `100644` | Regular file | Normal file with read/write permissions |\n| `100755` | Executable file | File with execute permissions |\n| `040000` | Directory | Subdirectory (points to another tree object) |\n| `120000` | Symbolic link | Symlink (blob contains link target path) |\n| `160000` | Git submodule | Reference to another Git repository |\n\n**Sorting Requirements:**\n\nTree entries must be sorted to ensure consistent hashing across different systems and Git implementations. The sort order treats directory names specially to maintain proper tree structure:\n\n1. **Primary sort**: Lexicographic order by entry name\n2. **Directory handling**: Directories are sorted as if their names ended with `/`\n3. **Case sensitivity**: Sorting is case-sensitive using byte values\n4. **Locale independence**: Sorting uses binary comparison, not locale-specific rules\n\nThis sorting ensures that the same directory structure always produces the same tree hash, regardless of the order in which files were added to the index.\n\n**Nested Directory Representation:**\n\nTrees handle directory hierarchies through recursive object references. Each subdirectory becomes a separate tree object, referenced by its hash from the parent tree. This creates a tree-of-trees structure that mirrors the directory hierarchy.\n\n```\nproject/\n├── README.md          → blob abc123... (referenced from root tree)\n├── src/               → tree def456... (referenced from root tree)\n│   ├── main.py        → blob ghi789... (referenced from src tree)\n│   └── utils.py       → blob jkl012... (referenced from src tree)\n└── tests/             → tree mno345... (referenced from root tree)\n    └── test_main.py   → blob pqr678... (referenced from tests tree)\n```\n\nThis structure enables efficient sharing of subtrees between commits. If only `README.md` changes between commits, the `src/` and `tests/` tree objects remain identical and are reused.\n\n#### Commit Objects\n\nCommit objects capture complete project snapshots along with metadata about when, why, and by whom changes were made. They form the backbone of Git's history tracking by linking project states into a directed acyclic graph.\n\n**Commit Object Structure:**\n```\nHeader: \"commit {content_length}\\0\"\nContent: {commit_fields}\n```\n\nCommit content consists of structured text fields that provide complete context for each project snapshot:\n\n| Field | Format | Required | Description |\n|-------|--------|----------|-------------|\n| tree | `tree {hash}` | Yes | SHA-1 hash of root tree object |\n| parent | `parent {hash}` | No | SHA-1 hash of parent commit (0 or more) |\n| author | `author {name} <{email}> {timestamp} {timezone}` | Yes | Who created the changes |\n| committer | `committer {name} <{email}> {timestamp} {timezone}` | Yes | Who committed the changes |\n| blank line | `\\n` | Yes | Separates metadata from message |\n| message | Free-form text | Yes | Commit message (can span multiple lines) |\n\n**Example Commit Object Content:**\n```\ntree 4b825dc642cb6eb9a060e54bf8d69288fbee4904\nparent 3a1b2c3d4e5f6789abcd0123456789abcdef0123\nauthor John Doe <john@example.com> 1609459200 +0000\ncommitter John Doe <john@example.com> 1609459200 +0000\n\nInitial commit with basic project structure\n\nAdded README.md and basic source code layout\n```\n\n**Timestamp Format:**\n\nGit stores timestamps as Unix epoch seconds followed by timezone offset. This format enables precise temporal ordering while preserving timezone information for distributed development.\n\n| Component | Format | Example | Description |\n|-----------|--------|---------|-------------|\n| Unix Timestamp | Decimal seconds since epoch | `1609459200` | UTC seconds since January 1, 1970 |\n| Timezone Offset | `±HHMM` format | `+0000`, `-0500` | Offset from UTC in hours and minutes |\n| Complete Format | `{timestamp} {offset}` | `1609459200 +0000` | Combined timestamp and timezone |\n\nThe timezone preservation allows Git to maintain exact temporal context even when commits are created in different timezones, which is crucial for distributed teams.\n\n**Author vs Committer:**\n\nGit distinguishes between the person who authored changes and the person who committed them to the repository. This distinction supports workflows where patches are created by one person and applied by another.\n\n| Role | When Different | Example Scenario |\n|------|----------------|------------------|\n| Author | Original creator of changes | Developer writes patch |\n| Committer | Person who applies changes | Maintainer applies patch to repository |\n| Same Person | Direct commits | Developer commits own work directly |\n| Automated Systems | CI/CD commits | Build system commits generated changes |\n\n**Parent References and History Graph:**\n\nCommits link to their predecessors through parent references, creating the history graph that represents project evolution over time. The number of parents determines the commit type:\n\n| Parent Count | Commit Type | Description | Graph Implications |\n|--------------|-------------|-------------|-------------------|\n| 0 | Initial commit | First commit in repository | Root node of history graph |\n| 1 | Normal commit | Regular development progress | Linear history segment |\n| 2+ | Merge commit | Integration of multiple branches | Graph convergence point |\n\nMultiple parents enable Git to represent complex development histories where feature branches are merged back into main development lines. Each parent hash creates an edge in the commit graph, allowing Git to traverse history in multiple directions.\n\n### Object Relationships\n\nThe power of Git's data model emerges from how objects reference each other to form a complete content-addressable graph. These relationships enable efficient storage, robust history tracking, and powerful operations like merging and rebasing.\n\n#### Content-Addressable References\n\nAll object references in Git use SHA-1 hashes as addresses, creating a content-addressable system where references are derived from the content they point to. This approach provides several critical properties:\n\n| Property | Description | Benefits |\n|----------|-------------|----------|\n| Immutability | Object content cannot change without changing its hash | History integrity and tamper detection |\n| Deduplication | Identical content shares the same hash and storage | Efficient storage utilization |\n| Verification | Hash validates content integrity | Corruption detection and data consistency |\n| Location Independence | Hash works regardless of storage location | Distributed repository synchronization |\n\nWhen a commit references a tree, it references the exact content state represented by that tree's hash. If any file changes, the blob hash changes, which changes the tree hash, which changes the commit hash. This cascade ensures that commit hashes uniquely identify complete project states.\n\n#### The Complete Reference Graph\n\nGit objects form a directed acyclic graph (DAG) where commits point to trees, trees point to blobs and other trees, and commits point to parent commits. Understanding this graph structure is essential for implementing Git operations correctly.\n\n**Reference Flow:**\n1. **Commit → Tree**: Each commit references exactly one root tree representing the complete project state\n2. **Tree → Blob/Tree**: Each tree entry references either a blob (file) or another tree (subdirectory)\n3. **Commit → Commit**: Each commit references zero or more parent commits, forming the history graph\n4. **No Circular References**: The graph is acyclic—objects never reference themselves directly or indirectly\n\n**Graph Properties:**\n\n| Property | Description | Implementation Impact |\n|----------|-------------|----------------------|\n| Directed | References flow from commits toward content | History traversal has natural direction |\n| Acyclic | No reference cycles exist | Graph algorithms terminate reliably |\n| Multi-rooted | Multiple commits can exist without common ancestors | Supports repository merging |\n| Immutable | Objects never change after creation | Safe concurrent access without locking |\n\n#### Shared Object References\n\nOne of Git's most elegant features is automatic content sharing through hash-based references. When multiple objects need to reference identical content, they naturally share the same hash and storage location.\n\n**Blob Sharing Scenarios:**\n\n| Scenario | Sharing Mechanism | Storage Impact |\n|----------|-------------------|----------------|\n| Duplicate files | Same content produces identical blob hashes | Single blob stored regardless of file count |\n| File copies | Copying doesn't change content, shares blob | Zero storage cost for file copies |\n| Partial file duplication | Different files share blob only if completely identical | No automatic deduplication for similar files |\n\n**Tree Sharing Scenarios:**\n\n| Scenario | Sharing Mechanism | Storage Impact |\n|----------|-------------------|----------------|\n| Unchanged subdirectories | Same tree structure produces identical hash | Subtrees shared across commits |\n| Branch merging | Common directory states share tree objects | Efficient merge representation |\n| File renames within directory | Tree content unchanged, shares existing tree | Renames are metadata-only changes |\n\n**Commit Graph Sharing:**\n\nCommits share parent references to build the history graph, but the sharing goes deeper. When branches diverge from a common point, they share all ancestor commits, creating efficient representation of parallel development.\n\n```\nA ← B ← C ← D    (main branch)\n     ↖ E ← F     (feature branch)\n```\n\nIn this example:\n- Commits A and B are shared by both branches\n- Commits C,D belong only to main\n- Commits E,F belong only to feature\n- Storage cost is 6 commits, not 8 (no duplication of A,B)\n\n#### Reference Resolution and Traversal\n\nUnderstanding how to navigate the object graph is crucial for implementing Git operations. Different operations require different traversal patterns through the reference relationships.\n\n**Common Traversal Patterns:**\n\n| Operation | Traversal Pattern | Object Types Accessed |\n|-----------|-------------------|----------------------|\n| Checkout | Commit → Tree → Blobs | All three types for complete project reconstruction |\n| Log | Commit → Parent Commits | Commits only for history traversal |\n| Diff | Commit → Tree, Compare Trees → Blobs | Commits and trees for comparison, blobs for content diff |\n| Status | Working Directory ↔ Index ↔ HEAD | Trees and blobs for three-way comparison |\n\n**Graph Traversal Algorithms:**\n\nDifferent Git operations require different graph traversal strategies to efficiently access the required objects:\n\n| Algorithm | Use Case | Traversal Order | Termination Condition |\n|-----------|----------|-----------------|----------------------|\n| Breadth-First Search | Finding merge base | Level-by-level commit traversal | Common ancestor found |\n| Depth-First Search | Complete history traversal | Follow parent chains deeply | No more parents |\n| Topological Sort | Chronological history | Respect parent-child relationships | All commits processed |\n| Tree Recursion | File system operations | Directory-first or file-first | All tree entries processed |\n\n#### Object Storage Efficiency\n\nThe reference relationships enable significant storage efficiencies that make Git practical for large repositories with long histories. Understanding these efficiencies helps appreciate why Git's approach scales well.\n\n**Deduplication Through References:**\n\n| Content Type | Deduplication Level | Efficiency Gain |\n|--------------|-------------------|-----------------|\n| Identical files | Complete blob sharing | Near-zero cost for duplicates |\n| Unchanged directories | Complete tree sharing | Subtree reuse across commits |\n| Common history | Shared commit ancestors | Linear growth with unique changes |\n| Branch points | Shared parent references | Efficient parallel development |\n\n**Storage Growth Patterns:**\n\nUnderstanding how repository size grows helps design efficient operations and predict storage requirements:\n\n| Change Type | New Objects Created | Storage Impact |\n|-------------|-------------------|----------------|\n| Edit single file | 1 blob, 1+ trees, 1 commit | Proportional to directory depth |\n| Add new file | 1 blob, 1+ trees, 1 commit | Same as file edit |\n| Rename file | 0 blobs, 1+ trees, 1 commit | Metadata-only change |\n| Copy file | 0 blobs, 1+ trees, 1 commit | Blob reuse makes copies free |\n\nThis efficiency model explains why Git can maintain complete history with reasonable storage costs—most changes affect only a small portion of the total project content, and unchanged content is automatically shared.\n\n### Common Pitfalls\n\n⚠️ **Pitfall: Hash Encoding in Tree Objects**\nTree objects store SHA-1 hashes as raw 20-byte binary data, not as 40-character hex strings. This is a frequent source of errors when implementing tree parsing and creation. Using hex encoding doubles the storage size and produces incorrect hash values. Always convert hex hashes to binary using `bytes.fromhex()` before storing in tree objects, and convert back to hex using `.hex()` when displaying or comparing hashes.\n\n⚠️ **Pitfall: Incorrect Object Header Format**\nThe object header must use the exact format `{type} {size}\\0{content}` with a space between type and size, and a null byte (not newline) after the size. Using incorrect separators or missing the null terminator results in hash mismatches with standard Git. The size must be the decimal byte count of the content portion only, not including the header itself.\n\n⚠️ **Pitfall: Tree Entry Sorting**\nTree entries must be sorted lexicographically with directories treated as if their names end with `/`. Incorrect sorting produces different tree hashes for identical directory contents. Use byte-level comparison, not locale-specific string sorting. The sort must be stable and consistent across all platforms to ensure repository compatibility.\n\n⚠️ **Pitfall: Binary vs Text Content Handling**\nAlways treat object content as binary data, even for text files. Using text mode file operations can corrupt binary content through line-ending conversion or encoding transformations. Open files in binary mode (`'rb'`, `'wb'`) and handle encoding explicitly when needed for display purposes.\n\n⚠️ **Pitfall: Timestamp Format Confusion**\nGit timestamps use Unix epoch seconds with timezone offsets, not local time representations. The format is `{seconds_since_epoch} {±HHMM}`, where the timezone offset is hours and minutes from UTC. Using local time or incorrect timezone formats breaks chronological ordering and compatibility with standard Git.\n\n⚠️ **Pitfall: Parent Hash Storage**\nCommit objects can have zero, one, or multiple parent lines, but each parent must be stored as a separate `parent {hash}` line, not as multiple hashes on a single line. Initial commits have no parent lines, merge commits have multiple parent lines. The order of parent lines affects merge commit interpretation.\n\n### Implementation Guidance\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Hash Computation | `hashlib.sha1()` from standard library | Custom SHA-1 implementation for learning |\n| Binary Data Handling | `bytes` type with `struct.pack()/unpack()` | Custom binary serialization classes |\n| Object Storage | Direct file I/O with `pathlib.Path` | Abstract storage interface supporting multiple backends |\n| Content Compression | `zlib.compress()/decompress()` from standard library | Stream-based compression for large objects |\n\n#### Recommended File Structure\n\n```\ngit-implementation/\n├── core/\n│   ├── __init__.py\n│   ├── objects.py              ← Object model (this implementation)\n│   │   ├── class GitObject     ← Base object interface\n│   │   ├── class BlobObject    ← Blob implementation\n│   │   ├── class TreeObject    ← Tree implementation  \n│   │   └── class CommitObject  ← Commit implementation\n│   ├── hash_utils.py           ← SHA-1 and object hashing utilities\n│   └── storage.py              ← Object store interface\n├── tests/\n│   ├── test_objects.py         ← Object model tests\n│   └── fixtures/               ← Test data files\n└── examples/\n    └── object_examples.py      ← Usage examples\n```\n\nThis structure separates the core object model from storage concerns, making it easier to test object creation and parsing independently from file system operations.\n\n#### Infrastructure Starter Code\n\n**Hash Utilities (`core/hash_utils.py`):**\n```python\nimport hashlib\nimport zlib\nfrom typing import bytes\n\n# Complete utility functions for object hashing and storage format\ndef compute_sha1(content: bytes) -> str:\n    \"\"\"Compute SHA-1 hash of raw bytes, returning hex string.\"\"\"\n    return hashlib.sha1(content).hexdigest()\n\ndef compute_object_hash(object_type: str, content: bytes) -> str:\n    \"\"\"Compute Git object hash with proper header format.\"\"\"\n    header = f\"{object_type} {len(content)}\\0\".encode('utf-8')\n    full_content = header + content\n    return compute_sha1(full_content)\n\ndef format_object_for_storage(object_type: str, content: bytes) -> bytes:\n    \"\"\"Format object with header and compress for storage.\"\"\"\n    header = f\"{object_type} {len(content)}\\0\".encode('utf-8')\n    full_content = header + content\n    return zlib.compress(full_content)\n\ndef parse_stored_object(compressed_data: bytes) -> tuple[str, bytes]:\n    \"\"\"Decompress and parse stored object, returning (type, content).\"\"\"\n    decompressed = zlib.decompress(compressed_data)\n    # Find null terminator separating header from content\n    null_pos = decompressed.find(b'\\0')\n    if null_pos == -1:\n        raise ValueError(\"Invalid object format: no null terminator\")\n    \n    header = decompressed[:null_pos].decode('utf-8')\n    content = decompressed[null_pos + 1:]\n    \n    # Parse header: \"type size\"\n    header_parts = header.split(' ', 1)\n    if len(header_parts) != 2:\n        raise ValueError(f\"Invalid header format: {header}\")\n    \n    object_type, size_str = header_parts\n    expected_size = int(size_str)\n    if len(content) != expected_size:\n        raise ValueError(f\"Content size mismatch: expected {expected_size}, got {len(content)}\")\n    \n    return object_type, content\n\n# Constants for object types\nBLOB_TYPE = \"blob\"\nTREE_TYPE = \"tree\" \nCOMMIT_TYPE = \"commit\"\nSHA1_HEX_LENGTH = 40\n```\n\n**Object Storage Interface (`core/storage.py`):**\n```python\nfrom pathlib import Path\nimport os\nfrom typing import Optional, tuple\nfrom .hash_utils import format_object_for_storage, parse_stored_object\n\nclass ObjectStore:\n    \"\"\"Handles content-addressable object storage and retrieval.\"\"\"\n    \n    def __init__(self, objects_dir: Path):\n        self.objects_dir = objects_dir\n        # Ensure objects directory exists\n        self.objects_dir.mkdir(parents=True, exist_ok=True)\n    \n    def object_path_from_hash(self, object_hash: str) -> Path:\n        \"\"\"Convert hash to file system path: .git/objects/xx/yy...\"\"\"\n        if len(object_hash) != SHA1_HEX_LENGTH:\n            raise ValueError(f\"Invalid hash length: {len(object_hash)}\")\n        \n        dir_name = object_hash[:2]\n        file_name = object_hash[2:]\n        return self.objects_dir / dir_name / file_name\n    \n    def store_object(self, object_type: str, content: bytes) -> str:\n        \"\"\"Store object in content-addressable store, return hash.\"\"\"\n        # Format and compress object\n        compressed_data = format_object_for_storage(object_type, content)\n        \n        # Compute hash for lookup\n        object_hash = compute_object_hash(object_type, content)\n        \n        # Determine storage path\n        object_path = self.object_path_from_hash(object_hash)\n        \n        # Create directory if needed\n        object_path.parent.mkdir(exist_ok=True)\n        \n        # Write compressed object (only if not already exists)\n        if not object_path.exists():\n            object_path.write_bytes(compressed_data)\n        \n        return object_hash\n    \n    def retrieve_object(self, object_hash: str) -> tuple[str, bytes]:\n        \"\"\"Retrieve object content and type by hash.\"\"\"\n        object_path = self.object_path_from_hash(object_hash)\n        \n        if not object_path.exists():\n            raise FileNotFoundError(f\"Object {object_hash} not found\")\n        \n        compressed_data = object_path.read_bytes()\n        return parse_stored_object(compressed_data)\n    \n    def object_exists(self, object_hash: str) -> bool:\n        \"\"\"Check if object exists in store.\"\"\"\n        return self.object_path_from_hash(object_hash).exists()\n```\n\n#### Core Logic Skeleton Code\n\n**Object Model Base Classes (`core/objects.py`):**\n```python\nfrom abc import ABC, abstractmethod\nfrom typing import bytes, List, Optional, Tuple\nimport struct\nimport time\n\n# Type aliases for clarity\nTreeEntry = Tuple[str, str, str]  # (mode, name, hash)\n\nclass GitObject(ABC):\n    \"\"\"Base class for all Git objects.\"\"\"\n    \n    def __init__(self, content: bytes):\n        self.content = content\n    \n    @property\n    @abstractmethod\n    def object_type(self) -> str:\n        \"\"\"Return the Git object type string.\"\"\"\n        pass\n    \n    @abstractmethod\n    def serialize(self) -> bytes:\n        \"\"\"Serialize object content for storage.\"\"\"\n        pass\n    \n    @classmethod\n    @abstractmethod\n    def deserialize(cls, content: bytes) -> 'GitObject':\n        \"\"\"Create object from stored content.\"\"\"\n        pass\n    \n    def compute_hash(self) -> str:\n        \"\"\"Compute SHA-1 hash of this object.\"\"\"\n        return compute_object_hash(self.object_type, self.serialize())\n\nclass BlobObject(GitObject):\n    \"\"\"Git blob object for file content storage.\"\"\"\n    \n    def __init__(self, content: bytes):\n        super().__init__(content)\n    \n    @property\n    def object_type(self) -> str:\n        return BLOB_TYPE\n    \n    def serialize(self) -> bytes:\n        \"\"\"Serialize blob content - content is stored as-is.\"\"\"\n        # TODO 1: Return the raw content bytes without modification\n        # TODO 2: Blobs store file content exactly as it exists\n        # Hint: self.content already contains the file bytes\n        pass\n    \n    @classmethod\n    def deserialize(cls, content: bytes) -> 'BlobObject':\n        \"\"\"Create blob from stored content.\"\"\"\n        # TODO 1: Create new BlobObject with the provided content\n        # TODO 2: Blob deserialization is trivial - content is stored as-is\n        # Hint: Simply pass content to constructor\n        pass\n\nclass TreeObject(GitObject):\n    \"\"\"Git tree object for directory structure.\"\"\"\n    \n    def __init__(self, entries: List[TreeEntry]):\n        self.entries = entries\n        # Sort entries to ensure consistent hashing\n        self._sort_entries()\n        super().__init__(self._serialize_entries())\n    \n    @property\n    def object_type(self) -> str:\n        return TREE_TYPE\n    \n    def _sort_entries(self):\n        \"\"\"Sort tree entries according to Git rules.\"\"\"\n        # TODO 1: Sort entries lexicographically by name\n        # TODO 2: Treat directories as if their names end with '/'\n        # TODO 3: Use byte-level comparison, not locale-specific sorting\n        # Hint: key=lambda entry: entry[1] + ('/' if entry[0] == '40000' else '')\n        pass\n    \n    def _serialize_entries(self) -> bytes:\n        \"\"\"Serialize tree entries to binary format.\"\"\"\n        # TODO 1: For each entry, format as: {mode} {name}\\0{20-byte-hash}\n        # TODO 2: Mode is ASCII string, name is UTF-8, hash is binary\n        # TODO 3: Convert hex hash to 20-byte binary using bytes.fromhex()\n        # TODO 4: Concatenate all entries into single bytes object\n        # Hint: Use bytes.fromhex() to convert hash from hex to binary\n        pass\n    \n    def serialize(self) -> bytes:\n        \"\"\"Serialize tree content.\"\"\"\n        return self.content\n    \n    @classmethod\n    def deserialize(cls, content: bytes) -> 'TreeObject':\n        \"\"\"Create tree from stored binary content.\"\"\"\n        entries = []\n        pos = 0\n        \n        while pos < len(content):\n            # TODO 1: Find space character separating mode from name\n            # TODO 2: Extract mode as ASCII string\n            # TODO 3: Find null terminator separating name from hash\n            # TODO 4: Extract name as UTF-8 string\n            # TODO 5: Extract next 20 bytes as binary hash\n            # TODO 6: Convert binary hash to hex string for storage\n            # TODO 7: Add (mode, name, hex_hash) tuple to entries list\n            # TODO 8: Advance pos to next entry\n            # Hint: Use content.find() to locate separators\n            pass\n        \n        return cls(entries)\n    \n    def add_entry(self, mode: str, name: str, object_hash: str):\n        \"\"\"Add entry to tree and re-sort.\"\"\"\n        # TODO 1: Add new entry tuple to self.entries\n        # TODO 2: Re-sort entries to maintain Git ordering\n        # TODO 3: Re-serialize content to update self.content\n        # Hint: Call self._sort_entries() and update self.content\n        pass\n\nclass CommitObject(GitObject):\n    \"\"\"Git commit object for project snapshots.\"\"\"\n    \n    def __init__(self, tree_hash: str, parent_hashes: List[str], \n                 author: str, committer: str, message: str,\n                 author_timestamp: Optional[int] = None,\n                 committer_timestamp: Optional[int] = None,\n                 timezone: str = \"+0000\"):\n        self.tree_hash = tree_hash\n        self.parent_hashes = parent_hashes\n        self.author = author\n        self.committer = committer\n        self.message = message\n        self.author_timestamp = author_timestamp or int(time.time())\n        self.committer_timestamp = committer_timestamp or int(time.time())\n        self.timezone = timezone\n        super().__init__(self._serialize_commit())\n    \n    @property\n    def object_type(self) -> str:\n        return COMMIT_TYPE\n    \n    def _format_person_line(self, name: str, timestamp: int, timezone: str) -> str:\n        \"\"\"Format author/committer line with timestamp.\"\"\"\n        # TODO 1: Format as: {name} {timestamp} {timezone}\n        # TODO 2: timestamp is Unix epoch seconds as decimal string\n        # TODO 3: timezone is ±HHMM format (e.g., +0000, -0500)\n        # Hint: f\"{name} {timestamp} {timezone}\"\n        pass\n    \n    def _serialize_commit(self) -> bytes:\n        \"\"\"Serialize commit to text format.\"\"\"\n        lines = []\n        \n        # TODO 1: Add tree line: \"tree {hash}\"\n        # TODO 2: Add parent lines: \"parent {hash}\" for each parent\n        # TODO 3: Add author line with formatted timestamp\n        # TODO 4: Add committer line with formatted timestamp  \n        # TODO 5: Add blank line separator\n        # TODO 6: Add commit message (can be multiple lines)\n        # TODO 7: Join all lines with \\n and encode to UTF-8 bytes\n        # Hint: Use self._format_person_line() for author/committer\n        pass\n    \n    def serialize(self) -> bytes:\n        \"\"\"Serialize commit content.\"\"\"\n        return self.content\n    \n    @classmethod\n    def deserialize(cls, content: bytes) -> 'CommitObject':\n        \"\"\"Create commit from stored text content.\"\"\"\n        text = content.decode('utf-8')\n        lines = text.split('\\n')\n        \n        # TODO 1: Parse tree hash from first line\n        # TODO 2: Parse parent hashes from any \"parent\" lines\n        # TODO 3: Parse author line and extract name, timestamp, timezone\n        # TODO 4: Parse committer line and extract name, timestamp, timezone\n        # TODO 5: Find blank line separating metadata from message\n        # TODO 6: Extract message as remaining lines after blank line\n        # TODO 7: Create CommitObject with parsed data\n        # Hint: Use startswith() to identify line types\n        pass\n```\n\n#### Milestone Checkpoints\n\n**After Implementing Blob Objects:**\n- Create a test file: `echo \"Hello, Git!\" > test.txt`\n- Your implementation should compute the same hash as: `git hash-object test.txt`\n- Expected hash: `d95f3ad14dee633a758d2e331151e950dd13e4ed`\n- Verify blob content retrieval matches original file exactly\n\n**After Implementing Tree Objects:**\n- Create a simple directory structure with a few files\n- Your tree serialization should produce consistent hashes for identical directory contents\n- Test tree entry sorting by creating files in different orders\n- Verify nested directories create separate tree objects\n\n**After Implementing Commit Objects:**\n- Create a commit object with known tree hash and timestamp\n- Compare your commit hash with Git's output for the same tree/parent/message\n- Test merge commit with multiple parents\n- Verify author/committer timestamp parsing and formatting\n\n#### Debugging Tips\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|-----------------|-----|\n| Hash mismatch with Git | Incorrect object header format | Compare byte-by-byte with `git cat-file -p` | Check header format: `{type} {size}\\0{content}` |\n| Tree parsing errors | Binary hash vs hex confusion | Print hash lengths (should be 20 bytes in tree) | Use `bytes.fromhex()` when storing, `.hex()` when displaying |\n| Commit timestamp issues | Wrong timezone format | Compare with `git log --pretty=fuller` | Use `{timestamp} ±HHMM` format |\n| Object corruption | Text mode file operations | Check if binary files are corrupted | Always use binary mode for file I/O |\n| Tree entry order wrong | Incorrect sorting algorithm | Compare sorted entries with `git ls-tree` | Sort lexicographically with directory special case |\n\n\n## Object Store Design\n\n> **Milestone(s):** This section provides the storage engine foundation for Milestone 2 (Object Storage - Blobs), Milestone 3 (Tree Objects), and Milestone 4 (Commit Objects), establishing the content-addressable storage patterns used throughout all subsequent milestones\n\n![Object Store File Layout](./diagrams/object-storage-layout.svg)\n\n### Mental Model: The Universal Library\n\nImagine a vast, magical library where books are never filed by title or author, but instead by their exact content. Every book receives a unique fingerprint derived from every word, punctuation mark, and space within its pages. This fingerprint becomes the book's permanent address on the shelf. If you know the fingerprint, you can instantly locate any book. If two people write identical books independently, they receive the same fingerprint and occupy the same shelf space—the library automatically deduplicates content.\n\nThis is **content-addressable storage**, the revolutionary concept at Git's core. Unlike traditional file systems that assign arbitrary names and locations to files, Git computes a cryptographic fingerprint (SHA-1 hash) of each piece of content and uses that fingerprint as both the content's identifier and storage location. This approach provides several powerful properties that make distributed version control possible.\n\nThe fingerprint is deterministic—the same content always produces the same hash, regardless of when or where it's computed. This enables perfect deduplication: storing the same file in multiple commits or branches requires no additional space. The fingerprint is also tamper-evident: changing even a single bit of content produces a completely different hash, making corruption or malicious modification immediately detectable.\n\nIn Git's universal library, every piece of content becomes an **immutable object**. Once stored, objects never change—they can only be referenced by their hash. This immutability enables Git's powerful branching and merging capabilities: you never lose data by creating branches or switching between them, because every version of every file remains permanently accessible through its unique fingerprint.\n\nThe object store serves as the foundation layer for all Git operations. When you stage a file, Git computes its hash and stores it as a blob object. When you commit changes, Git creates tree objects that organize these blobs into directory structures, then creates a commit object that points to the root tree. Every object is stored once and referenced by its SHA-1 hash throughout the repository.\n\n### Storage Algorithm\n\nThe object storage process transforms arbitrary content into an immutable, verifiable object within Git's content-addressable store. This multi-step algorithm ensures consistency, integrity, and efficient retrieval across all Git operations.\n\n**Step 1: Object Header Construction**\n\nGit wraps every piece of content with a standardized header before computing its hash. The header follows the format `{type} {size}\\0{content}` where type is one of `blob`, `tree`, or `commit`, size is the decimal byte count of the raw content, and a null byte separates the header from content. This header serves multiple purposes: it prevents hash collisions between different object types containing identical content, enables type verification during retrieval, and provides size information for memory allocation and corruption detection.\n\nFor a text file containing \"Hello, World!\" (13 bytes), the complete object becomes `blob 13\\0Hello, World!` where `\\0` represents the null byte separator. This formatted object, not just the original content, becomes the input for hash calculation.\n\n**Step 2: SHA-1 Hash Computation**\n\nGit computes the SHA-1 cryptographic hash of the complete formatted object (header plus content) to generate a 160-bit digest, represented as a 40-character hexadecimal string. This hash serves as the object's immutable identifier throughout its lifetime. The SHA-1 algorithm ensures that identical content produces identical hashes deterministically, while any content modification results in a completely different hash.\n\nThe hash computation must be precise and consistent across all Git implementations. Python's `hashlib.sha1()` function provides the standard implementation, accepting the complete object bytes and returning the hexadecimal digest. This hash becomes the object's permanent name within the repository—it can never be changed without detecting the modification.\n\n**Step 3: Content Compression**\n\nGit compresses every object using the zlib compression algorithm before storage. This compression occurs after hash computation, ensuring the hash reflects the actual content while storage benefits from size reduction. The zlib algorithm typically achieves significant compression ratios for text-based content like source code, documentation, and configuration files commonly stored in version control.\n\nThe compression level balances storage space against compression time. Git uses zlib's default compression level (6 on a scale of 0-9), providing good compression ratios without excessive CPU overhead during write operations. The compressed data becomes the actual bytes written to the file system.\n\n**Step 4: File System Path Generation**\n\nGit derives the storage path from the object's SHA-1 hash using a two-level directory structure. The first two hexadecimal characters become the directory name within `.git/objects/`, while the remaining 38 characters become the filename. This sharding approach distributes objects across multiple directories, preventing performance degradation from storing thousands of files in a single directory.\n\nFor hash `a1b2c3d4e5f6789...`, the storage path becomes `.git/objects/a1/b2c3d4e5f6789...`. The directory `a1` must exist before writing the object file. Most file systems handle directories with hundreds of files efficiently, making this two-level approach sufficient for most repositories.\n\n**Step 5: Atomic File Writing**\n\nGit writes objects atomically to prevent corruption from interrupted operations or concurrent access. The atomic write process creates a temporary file with a unique name in the target directory, writes the compressed object content, ensures data reaches persistent storage through `fsync()`, then atomically renames the temporary file to the final object name.\n\nThis atomic operation ensures that object files are either completely present and valid or completely absent—partially written objects cannot exist. If a write operation fails at any point, the temporary file can be safely removed without affecting existing repository state.\n\nThe following table details the complete object storage algorithm:\n\n| Step | Operation | Input | Output | Purpose |\n|------|-----------|--------|---------|---------|\n| 1 | Header Construction | `(type, content)` | `formatted_object` | Standardize object format |\n| 2 | Hash Computation | `formatted_object` | `sha1_hash` | Generate unique identifier |\n| 3 | Compression | `formatted_object` | `compressed_data` | Reduce storage space |\n| 4 | Path Generation | `sha1_hash` | `file_path` | Determine storage location |\n| 5 | Atomic Write | `(file_path, compressed_data)` | `stored_object` | Persist object safely |\n\n### Retrieval and Verification\n\nObject retrieval reverses the storage process, locating objects by their SHA-1 hash and reconstructing the original content with integrity verification. This process must handle missing objects gracefully and detect corruption reliably.\n\n**Hash-to-Path Resolution**\n\nThe retrieval process begins by converting the 40-character SHA-1 hash into a file system path using the same sharding logic as storage. The first two characters specify the subdirectory within `.git/objects/`, and the remaining 38 characters identify the object file. The complete path becomes `.git/objects/XX/YYYYYY...` where XX and YYYY represent the hash prefix and suffix respectively.\n\nBefore attempting to read the object file, the retrieval system should verify that both the subdirectory and object file exist. Missing subdirectories indicate the object has never been stored, while missing object files within existing subdirectories may indicate corruption or incomplete write operations.\n\n**Decompression and Parsing**\n\nOnce located, the object file contains zlib-compressed data that must be decompressed to recover the original formatted object. The decompression operation may fail if the file is corrupted or truncated, requiring appropriate error handling to report repository corruption.\n\nAfter successful decompression, the formatted object must be parsed to separate the header from content. The parser locates the null byte separator, extracts the type and size information from the header, then validates that the declared size matches the actual content length. This validation detects various corruption scenarios including truncated objects and header modification.\n\n**Content Verification**\n\nThe most critical aspect of object retrieval is verifying that the retrieved content matches its claimed identity. Git recomputes the SHA-1 hash of the decompressed, formatted object and compares it to the hash used for retrieval. Any mismatch indicates corruption and must be treated as a fatal error.\n\nThis verification step provides Git's fundamental integrity guarantee: if an object can be retrieved successfully, its content is guaranteed to be identical to when it was stored. This property enables distributed collaboration without central authority—every participant can independently verify the integrity of shared history.\n\nThe following table outlines the complete retrieval and verification process:\n\n| Operation | Input | Process | Output | Error Conditions |\n|-----------|-------|---------|---------|------------------|\n| Path Resolution | `sha1_hash` | Split hash into directory/file components | `file_path` | Invalid hash format |\n| File Reading | `file_path` | Read compressed bytes from file system | `compressed_data` | File not found, permission denied |\n| Decompression | `compressed_data` | zlib decompression | `formatted_object` | Corruption, truncation |\n| Header Parsing | `formatted_object` | Extract type, size, content | `(type, size, content)` | Invalid format, size mismatch |\n| Hash Verification | `formatted_object` | Recompute SHA-1, compare to expected | `verified_content` | Hash mismatch (corruption) |\n\n**Error Recovery Strategies**\n\nWhen object retrieval fails, Git provides several diagnostic capabilities to help identify the root cause. Missing object files typically indicate incomplete repository clones or damaged file systems. Decompression failures suggest file corruption or storage hardware issues. Hash verification failures represent the most serious corruption type, indicating that stored content differs from its claimed identity.\n\nFor missing objects, Git can attempt to retrieve them from alternate object databases (alternates mechanism) or remote repositories. For corrupted objects, no automatic recovery is possible—the object must be restored from backup or reconstructed from other repository copies.\n\n### Architecture Decision Records\n\nThe object store design involves several critical architecture decisions that fundamentally shape Git's behavior, performance characteristics, and security properties. Each decision represents careful consideration of trade-offs between competing requirements.\n\n> **Decision: SHA-1 Hash Algorithm Selection**\n> - **Context**: Git requires a cryptographic hash function to generate unique, tamper-evident identifiers for all stored content. The hash function must provide strong collision resistance, fast computation, and consistent cross-platform behavior.\n> - **Options Considered**: MD5 (fast but cryptographically broken), SHA-1 (established but showing weaknesses), SHA-256 (stronger but larger hashes)\n> - **Decision**: SHA-1 for initial implementation, with migration path to SHA-256\n> - **Rationale**: SHA-1 provides adequate collision resistance for version control use cases while maintaining compatibility with existing Git repositories. The 160-bit hash size balances security with storage efficiency. Although theoretical weaknesses exist, practical collision attacks remain extremely difficult and detectable.\n> - **Consequences**: Enables compatibility with existing Git tools and repositories. Provides strong integrity guarantees for typical use cases. May require migration to SHA-256 in future for enhanced security as collision attacks become more practical.\n\nThe following table compares the hash algorithm options:\n\n| Algorithm | Digest Size | Performance | Collision Resistance | Compatibility | Chosen |\n|-----------|-------------|-------------|---------------------|---------------|---------|\n| MD5 | 128 bits | Fastest | Broken | Legacy only | ❌ |\n| SHA-1 | 160 bits | Fast | Weakening | Full Git compatibility | ✅ |\n| SHA-256 | 256 bits | Slower | Strong | Limited Git support | Future |\n\n> **Decision: Two-Level Directory Structure**\n> - **Context**: Storing thousands of objects in a single directory causes severe performance degradation on most file systems. The storage structure must distribute objects efficiently while maintaining simple hash-to-path mapping.\n> - **Options Considered**: Single flat directory (simple but slow), two-level sharding (balanced), three-level sharding (complex but scalable)\n> - **Decision**: Two-level directory structure using first two hex characters as directory name\n> - **Rationale**: Provides 256 possible subdirectories, distributing objects evenly across directories. Most repositories contain fewer than 10,000 objects per subdirectory, maintaining good file system performance. Simple mapping algorithm enables fast path computation.\n> - **Consequences**: Excellent performance for repositories of all practical sizes. Simple implementation with minimal complexity overhead. Requires directory pre-creation but provides efficient object distribution.\n\n| Structure | Directories | Objects per Dir | Lookup Speed | Implementation | Chosen |\n|-----------|-------------|-----------------|--------------|----------------|---------|\n| Flat | 1 | Unlimited | Very slow | Trivial | ❌ |\n| Two-level | 256 | ~400 (typical) | Fast | Simple | ✅ |\n| Three-level | 4,096 | ~25 (typical) | Fastest | Complex | ❌ |\n\n> **Decision: zlib Compression Algorithm**\n> - **Context**: Version control repositories often contain repetitive text content that compresses well. Compression reduces storage requirements but adds CPU overhead for every object operation.\n> - **Options Considered**: No compression (fast but large), gzip/zlib (balanced), specialized algorithms (complex)\n> - **Decision**: zlib compression with default level (6)\n> - **Rationale**: zlib provides excellent compression ratios for typical source code content while maintaining fast compression/decompression speed. Wide platform availability and mature implementations reduce compatibility risks. Default compression level balances space savings with CPU cost.\n> - **Consequences**: Significant storage space reduction (often 50-80% for text content). Minimal performance impact on modern systems. Universal compatibility across platforms and programming languages.\n\n| Algorithm | Compression Ratio | Speed | Availability | Complexity | Chosen |\n|-----------|------------------|-------|--------------|------------|---------|\n| None | 0% | Fastest | Universal | Minimal | ❌ |\n| zlib (level 6) | 60-80% | Fast | Universal | Low | ✅ |\n| LZMA | 70-85% | Slow | Limited | High | ❌ |\n\n> **Decision: Immutable Object Model**\n> - **Context**: Version control systems must preserve historical content while enabling efficient storage and reliable integrity verification. Objects could be mutable (updateable) or immutable (write-once).\n> - **Options Considered**: Mutable objects with versioning, immutable objects with content-addressing, hybrid approach with mutable metadata\n> - **Decision**: Fully immutable objects identified by content hash\n> - **Rationale**: Immutability provides strong integrity guarantees—content cannot be modified without detection. Content-addressing enables automatic deduplication and efficient comparison operations. Simplifies concurrent access by eliminating modification conflicts.\n> - **Consequences**: Perfect integrity preservation for historical data. Automatic deduplication across branches and repositories. Simplified concurrency model. Storage growth over time as objects accumulate, requiring periodic cleanup.\n\n| Model | Integrity | Deduplication | Concurrency | Storage Growth | Chosen |\n|-------|-----------|---------------|-------------|----------------|---------|\n| Mutable | Moderate | Manual | Complex locking | Controlled | ❌ |\n| Immutable | Perfect | Automatic | Lock-free reads | Unbounded | ✅ |\n| Hybrid | Variable | Partial | Mixed complexity | Moderate | ❌ |\n\n### Common Pitfalls\n\nBuilding a content-addressable object store presents several subtle challenges that frequently trip up implementers. Understanding these pitfalls and their solutions is crucial for creating a reliable Git implementation.\n\n⚠️ **Pitfall: Including Hash in Header During Hash Computation**\n\nMany implementers mistakenly include the object's SHA-1 hash within the object header when computing the hash, creating an impossible circular dependency. The hash cannot be computed until the complete object is formed, but the object cannot be complete if it includes its own hash.\n\nGit's object format includes only the object type and content size in the header, never the hash itself. The hash is computed from the complete formatted object (`{type} {size}\\0{content}`) and then used separately as the object's identifier and storage path. The hash never becomes part of the stored object content.\n\nTo avoid this pitfall, ensure your hash computation function receives the complete formatted object without any hash reference, computes the SHA-1 digest, then uses that digest for storage path generation and object identification.\n\n⚠️ **Pitfall: Hash Computation on Content Only (Excluding Header)**\n\nSome implementations compute the SHA-1 hash using only the raw content bytes, ignoring the type and size header. This approach fails to match Git's hash computation and can lead to hash collisions between different object types containing identical content.\n\nGit always computes hashes on the complete formatted object including the header. A blob containing \"tree abc\" and a tree containing the same bytes produce different hashes because their headers differ (`blob 8\\0tree abc` vs `tree 8\\0tree abc`). This separation prevents type confusion attacks and ensures object type integrity.\n\nVerify your hash computation includes the complete object header by testing with Git's `hash-object` command and comparing results. Your implementation must produce identical hashes for identical input.\n\n⚠️ **Pitfall: Compressing Content Before Hash Computation**\n\nThe sequence of hash computation and compression operations is critical but often confused. Computing the hash of compressed content instead of the original formatted object produces incorrect hashes that don't match Git's expectations.\n\nGit's algorithm always follows this sequence: format object with header, compute SHA-1 hash of formatted object, compress formatted object, store compressed data. The hash reflects the uncompressed content, while storage benefits from compression. This approach allows hash computation without decompression during future retrieval operations.\n\nEnsure your storage function computes the hash first, stores the hash for later use, then compresses the same formatted object for file system storage.\n\n⚠️ **Pitfall: Incorrect Directory Creation Permissions**\n\nObject directories within `.git/objects/` require specific permissions to function correctly across different operating systems and deployment scenarios. Using default directory permissions can cause access failures in shared repository environments.\n\nGit creates object directories with 0755 permissions (owner read/write/execute, group and other read/execute), ensuring they remain accessible to the repository owner while allowing read access for other authorized users. Execute permission on directories is required for file access within the directory.\n\nSet directory permissions explicitly using your platform's appropriate mechanism (`os.mkdir(path, 0o755)` in Python) rather than relying on default umask behavior.\n\n⚠️ **Pitfall: Non-Atomic Object Writing**\n\nWriting object files directly to their final location creates a race condition where other processes might read partially written objects, leading to corruption errors. This is particularly problematic during concurrent Git operations or system crashes during writes.\n\nGit ensures atomicity by writing to temporary files first, then atomically renaming them to the final object name. This approach guarantees that object files are either completely absent or completely valid—partially written objects cannot exist.\n\nImplement atomic writes using a temporary filename (such as appending `.tmp` plus process ID), write complete content to the temporary file, sync to disk, then rename to the final object filename.\n\n⚠️ **Pitfall: Missing fsync() for Durability**\n\nObject files must be durably written to persistent storage before being considered successfully stored. Without explicit synchronization, object data may remain in file system buffers and be lost during system crashes, leading to repository corruption.\n\nAfter writing the complete object file, call `fsync()` (or platform equivalent) to ensure data reaches persistent storage before proceeding. This operation may significantly impact write performance but is essential for repository integrity.\n\nInclude explicit sync operations in your atomic write sequence: write to temporary file, sync temporary file, rename to final name, sync parent directory to ensure directory entry is persistent.\n\n⚠️ **Pitfall: Inadequate Error Handling During Retrieval**\n\nObject retrieval involves multiple failure modes that require different handling strategies. Treating all retrieval failures identically can mask serious corruption issues or provide misleading error messages to users.\n\nDistinguish between expected failures (missing objects that haven't been stored) and unexpected failures (corruption, permission issues, file system errors). Missing objects should be handled gracefully with appropriate user feedback, while corruption should be treated as fatal errors requiring user intervention.\n\nImplement comprehensive error categorization that identifies the specific failure mode and provides appropriate recovery suggestions for each case.\n\n### Implementation Guidance\n\nThe object store implementation requires careful attention to file system operations, cryptographic hashing, and data integrity verification. This section provides complete infrastructure code and skeletal implementations for the core learning objectives.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Hashing | `hashlib.sha1()` (built-in) | `cryptography` library for future SHA-256 |\n| Compression | `zlib` module (built-in) | `python-lzo` for better performance |\n| File Operations | `pathlib.Path` + `open()` | `os.open()` with explicit flags |\n| Atomic Writes | `tempfile` + `os.rename()` | Platform-specific atomic operations |\n| Directory Creation | `os.makedirs()` | `os.mkdir()` with explicit permission handling |\n\n#### Recommended File Structure\n\n```\ngit-implementation/\n  src/\n    git_core/\n      __init__.py\n      objects/                  ← Object store implementation\n        __init__.py\n        store.py               ← ObjectStore class (core learning)\n        types.py               ← GitObject base classes\n        hash.py                ← Hashing utilities (infrastructure)\n        compression.py         ← Compression utilities (infrastructure)\n      repository.py            ← Repository class\n      exceptions.py            ← Git-specific exceptions\n  tests/\n    test_objects/\n      test_store.py            ← Object store tests\n      test_hash.py             ← Hash computation tests\n    fixtures/                  ← Test data files\n```\n\n#### Infrastructure Starter Code\n\n**Hash Computation Utilities** (`src/git_core/objects/hash.py`):\n```python\n\"\"\"\nHash computation utilities for Git objects.\nProvides SHA-1 computation with Git's object header format.\n\"\"\"\nimport hashlib\nfrom typing import Tuple\n\nSHA1_HEX_LENGTH = 40\nOBJECT_HEADER_FORMAT = \"{type} {size}\\0{content}\"\n\ndef compute_sha1(content: bytes) -> str:\n    \"\"\"Compute SHA-1 hash of raw bytes, returning hex digest.\"\"\"\n    return hashlib.sha1(content).hexdigest()\n\ndef format_git_object(object_type: str, content: bytes) -> bytes:\n    \"\"\"Format content with Git object header: '{type} {size}\\\\0{content}'\"\"\"\n    header = f\"{object_type} {len(content)}\"\n    return header.encode('utf-8') + b'\\0' + content\n\ndef compute_object_hash(object_type: str, content: bytes) -> str:\n    \"\"\"Compute Git object hash including type/size header.\"\"\"\n    formatted_object = format_git_object(object_type, content)\n    return compute_sha1(formatted_object)\n\ndef parse_git_object(formatted_object: bytes) -> Tuple[str, int, bytes]:\n    \"\"\"Parse formatted Git object, returning (type, size, content).\"\"\"\n    null_index = formatted_object.find(b'\\0')\n    if null_index == -1:\n        raise ValueError(\"Invalid Git object: missing null separator\")\n    \n    header = formatted_object[:null_index].decode('utf-8')\n    content = formatted_object[null_index + 1:]\n    \n    try:\n        object_type, size_str = header.split(' ', 1)\n        declared_size = int(size_str)\n    except ValueError:\n        raise ValueError(f\"Invalid Git object header: {header}\")\n    \n    if len(content) != declared_size:\n        raise ValueError(f\"Content size mismatch: declared {declared_size}, actual {len(content)}\")\n    \n    return object_type, declared_size, content\n\ndef validate_sha1_hash(hash_str: str) -> bool:\n    \"\"\"Validate SHA-1 hash format (40 hex characters).\"\"\"\n    return (len(hash_str) == SHA1_HEX_LENGTH and \n            all(c in '0123456789abcdef' for c in hash_str.lower()))\n```\n\n**Compression Utilities** (`src/git_core/objects/compression.py`):\n```python\n\"\"\"\nCompression utilities for Git object storage.\nHandles zlib compression/decompression with error handling.\n\"\"\"\nimport zlib\nfrom typing import bytes\n\nDEFAULT_COMPRESSION_LEVEL = 6\n\ndef compress_object(data: bytes, level: int = DEFAULT_COMPRESSION_LEVEL) -> bytes:\n    \"\"\"Compress data using zlib with specified compression level.\"\"\"\n    try:\n        return zlib.compress(data, level)\n    except zlib.error as e:\n        raise ValueError(f\"Compression failed: {e}\")\n\ndef decompress_object(compressed_data: bytes) -> bytes:\n    \"\"\"Decompress zlib-compressed data.\"\"\"\n    try:\n        return zlib.decompress(compressed_data)\n    except zlib.error as e:\n        raise ValueError(f\"Decompression failed: {e}\")\n```\n\n**Git Object Types** (`src/git_core/objects/types.py`):\n```python\n\"\"\"\nGit object type definitions and base classes.\n\"\"\"\nfrom abc import ABC, abstractmethod\nfrom typing import bytes\n\nBLOB_TYPE = \"blob\"\nTREE_TYPE = \"tree\" \nCOMMIT_TYPE = \"commit\"\n\nclass GitObject(ABC):\n    \"\"\"Base class for all Git objects (blob, tree, commit).\"\"\"\n    \n    def __init__(self, content: bytes):\n        self.content = content\n    \n    @property\n    @abstractmethod\n    def object_type(self) -> str:\n        \"\"\"Return the Git object type string.\"\"\"\n        pass\n    \n    def compute_hash(self) -> str:\n        \"\"\"Compute the SHA-1 hash of this object.\"\"\"\n        from .hash import compute_object_hash\n        return compute_object_hash(self.object_type, self.content)\n\nclass BlobObject(GitObject):\n    \"\"\"Git blob object representing file content.\"\"\"\n    \n    @property\n    def object_type(self) -> str:\n        return BLOB_TYPE\n\nclass TreeObject(GitObject):\n    \"\"\"Git tree object representing directory structure.\"\"\"\n    \n    @property\n    def object_type(self) -> str:\n        return TREE_TYPE\n\nclass CommitObject(GitObject):\n    \"\"\"Git commit object representing a project snapshot.\"\"\"\n    \n    @property\n    def object_type(self) -> str:\n        return COMMIT_TYPE\n```\n\n#### Core Logic Skeleton Code\n\n**Object Store Implementation** (`src/git_core/objects/store.py`):\n```python\n\"\"\"\nGit object store implementation.\nCore content-addressable storage for Git objects.\n\"\"\"\nimport os\nimport tempfile\nfrom pathlib import Path\nfrom typing import Optional, Tuple, bytes\n\nfrom .hash import compute_object_hash, parse_git_object, validate_sha1_hash, format_git_object\nfrom .compression import compress_object, decompress_object\n\nclass ObjectStore:\n    \"\"\"Content-addressable storage for Git objects.\"\"\"\n    \n    def __init__(self, objects_dir: Path):\n        self.objects_dir = objects_dir\n        self._ensure_objects_directory()\n    \n    def _ensure_objects_directory(self) -> None:\n        \"\"\"Create .git/objects directory structure if it doesn't exist.\"\"\"\n        # TODO 1: Create objects_dir with 0o755 permissions if it doesn't exist\n        # TODO 2: Create info/ and pack/ subdirectories for Git compatibility\n        # Hint: Use os.makedirs() with exist_ok=True\n        pass\n    \n    def object_path_from_hash(self, object_hash: str) -> Path:\n        \"\"\"Convert SHA-1 hash to file system path in objects directory.\"\"\"\n        # TODO 1: Validate hash format using validate_sha1_hash()\n        # TODO 2: Split hash into directory (first 2 chars) and filename (remaining 38)\n        # TODO 3: Return Path to .git/objects/XX/YYYYYYYY...\n        # Hint: hash[:2] gives first 2 characters, hash[2:] gives remainder\n        pass\n    \n    def store_object(self, object_type: str, content: bytes) -> str:\n        \"\"\"Store object in content-addressable store, return SHA-1 hash.\"\"\"\n        # TODO 1: Format object with header using format_git_object()\n        # TODO 2: Compute SHA-1 hash of formatted object\n        # TODO 3: Compress formatted object using compress_object()\n        # TODO 4: Generate storage path from hash using object_path_from_hash()\n        # TODO 5: Create parent directory if it doesn't exist (with 0o755 permissions)\n        # TODO 6: Write compressed data atomically using _write_object_file()\n        # TODO 7: Return computed SHA-1 hash\n        # Hint: Atomic write prevents corruption from interrupted operations\n        pass\n    \n    def retrieve_object(self, object_hash: str) -> Tuple[str, bytes]:\n        \"\"\"Retrieve object by hash, return (object_type, content).\"\"\"\n        # TODO 1: Validate hash format\n        # TODO 2: Generate file path from hash\n        # TODO 3: Check if object file exists, raise exception if missing\n        # TODO 4: Read compressed data from file\n        # TODO 5: Decompress data using decompress_object()\n        # TODO 6: Parse object header using parse_git_object()\n        # TODO 7: Verify integrity by recomputing hash and comparing\n        # TODO 8: Return (object_type, content) tuple\n        # Hint: Hash verification detects corruption\n        pass\n    \n    def object_exists(self, object_hash: str) -> bool:\n        \"\"\"Check if object exists in store without reading content.\"\"\"\n        # TODO 1: Validate hash format\n        # TODO 2: Generate file path from hash\n        # TODO 3: Return whether file exists using Path.exists()\n        # Hint: This is more efficient than retrieve_object() for existence checks\n        pass\n    \n    def _write_object_file(self, file_path: Path, compressed_data: bytes) -> None:\n        \"\"\"Atomically write compressed object data to file.\"\"\"\n        # TODO 1: Create temporary file in same directory as target\n        # TODO 2: Write compressed_data to temporary file\n        # TODO 3: Sync temporary file to disk (fsync)\n        # TODO 4: Atomically rename temporary file to final path\n        # TODO 5: Handle any errors by cleaning up temporary file\n        # Hint: Use tempfile.NamedTemporaryFile() with delete=False\n        # Hint: os.rename() is atomic on most platforms\n        pass\n    \n    def _create_object_directory(self, directory_path: Path) -> None:\n        \"\"\"Create object subdirectory with correct permissions.\"\"\"\n        # TODO 1: Create directory if it doesn't exist\n        # TODO 2: Set permissions to 0o755\n        # TODO 3: Handle race condition if directory is created concurrently\n        # Hint: Use os.makedirs() with exist_ok=True\n        pass\n```\n\n#### Language-Specific Hints\n\n**Python-Specific Implementation Details:**\n\n- Use `pathlib.Path` for all file system operations—it provides cross-platform path handling and convenient methods like `.exists()` and `.mkdir()`\n- The `os.rename()` function provides atomic file renaming on POSIX systems, but use `shutil.move()` on Windows for cross-platform compatibility\n- Use `tempfile.NamedTemporaryFile(delete=False)` to create temporary files that persist after closing, enabling atomic rename operations\n- Call `file.flush()` followed by `os.fsync(file.fileno())` to ensure data reaches persistent storage\n- Use `os.makedirs(path, mode=0o755, exist_ok=True)` to create directories with specific permissions while handling concurrent creation\n\n**Error Handling Patterns:**\n\n- Distinguish between `FileNotFoundError` (missing object) and `PermissionError` (access issue) when reading objects\n- Catch `zlib.error` during compression/decompression and convert to more descriptive exceptions\n- Use try/finally blocks around temporary file operations to ensure cleanup on failure\n- Validate input parameters (hash format, object type) before performing expensive operations\n\n#### Milestone Checkpoint\n\nAfter implementing the object store, verify functionality with these tests:\n\n**Basic Storage and Retrieval:**\n```bash\npython -m pytest tests/test_objects/test_store.py::test_store_blob -v\n```\nExpected behavior: Store a simple text blob, retrieve it, verify content matches exactly.\n\n**Hash Computation Verification:**\n```bash\n# Compare with Git's hash-object command\necho \"Hello, World!\" | git hash-object --stdin\n# Your implementation should produce: 8ab686eafeb1f44702738c8b0f24f2567c36da6d\n```\n\n**Directory Structure Validation:**\nAfter storing an object with hash `8ab686eafeb1f44702738c8b0f24f2567c36da6d`, verify:\n- Directory `.git/objects/8a/` exists with 0755 permissions  \n- File `.git/objects/8a/b686eafeb1f44702738c8b0f24f2567c36da6d` contains compressed data\n- File can be decompressed to recover original formatted object\n\n**Integrity Verification:**\n```bash\npython -c \"\nstore = ObjectStore(Path('.git/objects'))\nhash1 = store.store_object('blob', b'test content')\nhash2 = store.store_object('blob', b'test content')\nassert hash1 == hash2  # Same content produces same hash\n\"\n```\n\n**Signs of Problems:**\n- Hash mismatches indicate incorrect header formatting or hash computation sequence\n- Permission errors suggest incorrect directory creation or file permissions\n- Decompression failures indicate compression/decompression sequence problems\n- Missing files after storage suggest atomic write implementation issues\n\n\n## Index and Staging Area\n\n> **Milestone(s):** This section is crucial for Milestone 6 (Index/Staging Area) and provides the foundation for Milestone 7 (Diff Algorithm) and Milestone 8 (Merge) which rely heavily on index operations and status calculations\n\n### Mental Model: The Photography Dark Room\n\nThink of Git's staging area as a traditional photographer's darkroom where film is developed into photographs. In the days of film photography, taking a picture was just the beginning of a multi-stage process. After shooting a roll of film, the photographer would bring it into the darkroom to develop the negatives, examine each shot under a red light, choose which ones to print, make adjustments to exposure and contrast, and only then commit to creating the final prints.\n\nThe staging area works exactly like this darkroom process. Your **working directory** is like your camera - you can take as many shots as you want, modify files, experiment with changes, but nothing is permanent yet. The **staging area** (also called the index) is your darkroom where you carefully review each change, decide which modifications should be included in your next commit, and prepare them for final development. The **repository** is like your photo album - once you commit (develop and print), those changes become part of your permanent project history.\n\nJust as a photographer might take dozens of shots but only print their best work, you might make changes to many files in your working directory but selectively stage only specific changes for each commit. This selective staging allows you to craft meaningful, focused commits rather than dumping all your work-in-progress changes into the repository at once.\n\nThe key insight is that the staging area gives you a **preparation and review step** before committing to permanent history. You can stage a file, make more changes to it, stage those additional changes, or even unstage files if you decide they're not ready. This three-stage workflow (working directory → staging area → repository) is what makes Git so powerful for maintaining clean, logical project history.\n\n### Index Binary Format\n\nThe Git index is stored as a binary file at `.git/index` and serves as the implementation of the staging area. Unlike most Git internal files which are human-readable text, the index uses a compact binary format for performance reasons - Git needs to quickly read, write, and search through potentially thousands of file entries during common operations like `git status` and `git add`.\n\nThe index file follows a strict binary layout that begins with a fixed header, followed by a sorted array of file entries, and concludes with a SHA-1 checksum of the entire file content. This format enables Git to efficiently detect when files have been modified by comparing cached metadata against the current file system state.\n\n**Index File Header Structure:**\n\n| Field | Size (bytes) | Type | Description |\n|-------|-------------|------|-------------|\n| Signature | 4 | char[4] | Always \"DIRC\" (directory cache) |\n| Version | 4 | uint32 | Format version number (we use version 2) |\n| Entry Count | 4 | uint32 | Number of index entries that follow |\n\nThe header's 12-byte fixed size allows Git to quickly determine how many entries to expect when parsing the file. The \"DIRC\" signature serves as both a magic number for file type identification and a corruption detection mechanism - if these bytes are corrupted, Git immediately knows the index is invalid.\n\n**Index Entry Structure:**\n\nEach index entry represents a single staged file and contains both the file's content hash and cached file system metadata. This dual information allows Git to quickly determine whether a file has been modified since it was last staged, without having to re-read and hash the entire file content.\n\n| Field | Size (bytes) | Type | Description |\n|-------|-------------|------|-------------|\n| ctime seconds | 4 | uint32 | File creation time (seconds since Unix epoch) |\n| ctime nanoseconds | 4 | uint32 | File creation time fractional seconds |\n| mtime seconds | 4 | uint32 | File modification time (seconds since Unix epoch) |\n| mtime nanoseconds | 4 | uint32 | File modification time fractional seconds |\n| Device ID | 4 | uint32 | Device ID containing the file |\n| Inode | 4 | uint32 | File system inode number |\n| Mode | 4 | uint32 | File mode and permissions (0o100644 for regular files) |\n| UID | 4 | uint32 | User ID of file owner |\n| GID | 4 | uint32 | Group ID of file owner |\n| File Size | 4 | uint32 | Size of file content in bytes |\n| SHA-1 Hash | 20 | char[20] | Object hash of staged file content (binary, not hex) |\n| Flags | 2 | uint16 | Status flags including name length |\n| Path Name | variable | char[] | File path relative to repository root |\n| Padding | 0-3 | char[] | NUL bytes to align entry to 4-byte boundary |\n\nThe extensive metadata caching in each entry enables Git's famous performance. When you run `git status`, Git can quickly scan through the index entries and compare the cached timestamps and file sizes against the current working directory. Only files whose metadata has changed need to be re-read and hashed to determine if their content has actually been modified.\n\n> **Critical Implementation Detail**: The SHA-1 hash is stored as 20 binary bytes, not as 40 hexadecimal characters. This is a common source of bugs - you must convert between binary and hex representations when reading/writing the index versus displaying hashes to users.\n\n**Index Entry Sorting and Padding:**\n\nIndex entries must be stored in **lexicographic order** by their path name. This sorting enables Git to use binary search when looking up specific files and ensures consistent behavior across different implementations. The sorting is performed on the raw byte values of the UTF-8 encoded path strings.\n\nEach entry's total size must be a multiple of 4 bytes for memory alignment performance. After the variable-length path name, NUL padding bytes are added to reach the next 4-byte boundary. The entry size calculation is: `62 + path_length + padding_to_4_byte_boundary`.\n\n**Index Checksum:**\n\nThe index file concludes with a 20-byte SHA-1 checksum of all preceding content. This checksum serves multiple purposes:\n\n1. **Corruption Detection**: Git can verify the index hasn't been corrupted by disk errors or incomplete writes\n2. **Concurrent Access Safety**: Multiple Git processes can detect when another process has modified the index\n3. **Atomic Updates**: Git writes to a temporary file then renames it, ensuring the index is never in a partially-written state\n\nThe checksum is calculated over the entire file content except for the checksum bytes themselves.\n\n> **Decision: Binary Format vs Text Format**\n> - **Context**: The staging area needs to store metadata for potentially thousands of files and be read/written frequently during common Git operations\n> - **Options Considered**: \n>   - Text format (similar to .gitignore): Human readable, easy to debug, simple to parse\n>   - Binary format: Compact storage, faster parsing, fixed-width fields enable efficient seeking\n>   - Hybrid approach: Text metadata with binary hashes\n> - **Decision**: Binary format with fixed-width header and entries\n> - **Rationale**: Performance is critical for the staging area since it's accessed by almost every Git command. Binary format provides 3-5x faster parsing and 2x smaller file size compared to text alternatives. The complexity cost is justified by the performance benefits for large repositories.\n> - **Consequences**: More complex to implement and debug, but enables Git's famous speed even in repositories with thousands of files\n\n### Add and Remove Operations\n\nThe core staging area operations are adding files (staging changes) and removing files (unstaging changes). These operations maintain the index's binary format and sorted ordering while updating both the object store and the cached metadata.\n\n**Add Operation Algorithm:**\n\nThe `git add` operation stages a file's current content and metadata into the index. This involves both storing the file content as a blob object and creating or updating the corresponding index entry.\n\n1. **Read File Content**: Read the complete file content from the working directory. Handle binary files correctly by reading raw bytes without text encoding assumptions.\n\n2. **Create Blob Object**: Compute the SHA-1 hash of the blob object using the `compute_object_hash` function with `BLOB_TYPE`. Store the compressed object in the object store using `store_object`.\n\n3. **Gather File Metadata**: Use file system calls to collect the complete stat information including modification time, file size, inode number, device ID, permissions, and owner IDs. This metadata enables fast change detection later.\n\n4. **Load Current Index**: Read and parse the existing `.git/index` file if it exists. If the repository has no staged files yet, start with an empty index structure.\n\n5. **Update or Insert Entry**: Search for an existing entry with the same path name. If found, update its hash and metadata. If not found, create a new entry. The binary hash must be converted from the 40-character hex representation to 20 binary bytes.\n\n6. **Maintain Sort Order**: Keep all index entries sorted lexicographically by path name. Insert new entries in the correct position or re-sort after updates.\n\n7. **Write Updated Index**: Serialize the complete index structure back to binary format, calculate the SHA-1 checksum of the content, append the checksum, and atomically write to `.git/index` using a temporary file and rename operation.\n\n**Add Operation Data Flow:**\n\n| Component | Input | Processing | Output |\n|-----------|-------|------------|--------|\n| Working Directory | File path | Read file content and stat metadata | Raw bytes + file stats |\n| Object Store | File content | Hash, compress, store as blob | Object hash |\n| Index | Path + hash + stats | Update entry, maintain sort order | Updated index |\n| File System | Binary index data | Atomic write with checksum | Persistent .git/index |\n\n**Remove Operation Algorithm:**\n\nThe `git rm --cached` operation (unstaging) removes a file from the index without affecting the working directory. This is distinct from `git rm` which removes both the index entry and the working directory file.\n\n1. **Load Current Index**: Read and parse the existing `.git/index` file. If the index doesn't exist or is empty, the remove operation is a no-op.\n\n2. **Find Target Entry**: Search through the sorted index entries for the specified path name. Since entries are sorted, this can use binary search for efficiency in large repositories.\n\n3. **Remove Entry**: Delete the matching entry from the index entry list. This does not affect the blob object in the object store (other commits might reference it).\n\n4. **Update Entry Count**: Decrement the entry count in the index header to reflect the removal.\n\n5. **Write Updated Index**: Serialize the modified index structure back to binary format and write it atomically. The checksum will change since the content has changed.\n\n⚠️ **Pitfall: Object Store Cleanup**\nMany implementations mistakenly delete the blob object when removing an index entry. This is incorrect - the object store is append-only and blob objects should never be deleted during normal operations. Other commits in the repository history might reference the same blob hash. Git's garbage collection process handles cleanup of unreferenced objects separately.\n\n**Handling File Modifications:**\n\nWhen a file is modified after being staged, Git needs to handle the scenario where the working directory version differs from the staged version. The add operation naturally handles this case:\n\n1. The new file content gets a different SHA-1 hash than the previously staged version\n2. The old blob object remains in the object store (it might be referenced by previous commits)\n3. The new blob object is stored alongside the old one\n4. The index entry is updated with the new hash and current metadata\n\nThis design means that staging a file multiple times creates multiple blob objects, but this is acceptable because content-addressable storage ensures identical content is never duplicated (same content always produces the same hash).\n\n**Index Locking and Concurrency:**\n\nMultiple Git commands might attempt to read or write the index simultaneously. Git uses a file-based locking mechanism to prevent corruption:\n\n1. Before writing the index, Git creates a `.git/index.lock` file\n2. The actual index updates are written to this lock file\n3. When the update is complete, the lock file is atomically renamed to `.git/index`\n4. Other Git processes that find an existing lock file wait or abort with an error\n\nThis locking protocol ensures that the index is never in a partially-written state and that concurrent operations don't corrupt each other's changes.\n\n**Status Tracking for Modified Files:**\n\nThe cached metadata in index entries enables efficient change detection. When determining if a file has been modified since staging:\n\n1. **Fast Path**: Compare cached mtime and file size against current values. If both match, the file is likely unchanged (skip expensive content hashing).\n\n2. **Slow Path**: If metadata differs, read the file content, compute its SHA-1 hash, and compare against the staged hash. This definitively determines if content has changed.\n\n3. **Race Condition Handling**: If a file is modified during the status check, the metadata comparison might give inconsistent results. Git handles this by re-checking files whose metadata changed during processing.\n\nThis two-level approach makes `git status` extremely fast even in large repositories, since most files are unchanged and can be verified using only metadata comparison.\n\n![Commit Creation Sequence](./diagrams/commit-creation-flow.svg)\n\n### Status Calculation\n\nGit status determines the state of every file by performing a **three-way comparison** between the working directory, the staging area (index), and the current commit (HEAD). This comparison categorizes each file into one of several states that inform the user what changes are staged, what changes are unstaged, and what files are untracked.\n\nUnderstanding status calculation is crucial because it forms the foundation for diff algorithms and merge operations. The status calculation must be both comprehensive (finding all relevant files) and efficient (fast enough for interactive use).\n\n**Three-Way Comparison Overview:**\n\nThe status algorithm compares three different views of the project's files:\n\n1. **HEAD Commit**: The files and content from the current branch's most recent commit\n2. **Index (Staging Area)**: The files that have been staged for the next commit  \n3. **Working Directory**: The current files in the file system\n\nBy comparing these three states pairwise, Git can determine exactly what changes have been made and what actions the user might want to take next.\n\n**File State Categories:**\n\n| State | Working Directory | Index | HEAD | User Action Needed |\n|-------|------------------|-------|------|-------------------|\n| Untracked | Present | Absent | Absent | `git add` to begin tracking |\n| Added | Present | Present | Absent | `git commit` to confirm addition |\n| Modified | Modified | Original | Original | `git add` to stage changes |\n| Staged | Modified | Modified | Original | `git commit` to confirm changes |\n| Deleted | Absent | Original | Present | `git add` to stage deletion |\n| Renamed | New location | New location | Old location | `git commit` to confirm rename |\n| Conflicted | Conflicted | Multiple stages | Original | Resolve conflicts manually |\n\n**Status Calculation Algorithm:**\n\nThe status calculation follows a systematic approach to ensure no files are missed and all states are correctly identified:\n\n1. **Collect File Sets**: Gather the complete set of file paths from all three sources:\n   - Parse the HEAD commit tree to get all tracked files\n   - Read the index to get all staged files  \n   - Scan the working directory for all present files (respecting .gitignore rules)\n\n2. **Create Union of Paths**: Combine all file paths from the three sources into a single sorted set. This ensures every file that exists in any state gets examined.\n\n3. **Three-Way Comparison**: For each file path, determine its presence and content in each of the three states:\n   - HEAD state: File hash from the commit tree (if present)\n   - Index state: File hash from the index entry (if present)\n   - Working directory state: Computed hash of current file content (if present)\n\n4. **Apply Classification Rules**: Use the three-state comparison to classify each file according to the state table above.\n\n5. **Handle Special Cases**: Process renames, ignored files, and submodule states according to Git's specific rules.\n\n**Detailed State Classification:**\n\n**Untracked Files:**\nFiles present in the working directory but absent from both the index and HEAD commit. These represent new files that haven't been added to version control yet.\n\n```\nWorking Directory: file.txt (content: \"hello\")\nIndex: (absent)\nHEAD: (absent)\nStatus: Untracked\n```\n\n**Added Files (Staged for Addition):**\nFiles that have been staged but don't exist in the HEAD commit. These will be new files in the next commit.\n\n```\nWorking Directory: new-file.txt (hash: abc123)\nIndex: new-file.txt (hash: abc123) \nHEAD: (absent)\nStatus: Added\n```\n\n**Modified Files (Unstaged Changes):**\nFiles where the working directory content differs from what's staged in the index. The index matches HEAD, but the working directory has newer changes.\n\n```\nWorking Directory: file.txt (hash: def456)\nIndex: file.txt (hash: abc123)\nHEAD: file.txt (hash: abc123)\nStatus: Modified (unstaged)\n```\n\n**Staged Files (Staged Changes):**\nFiles where the index content differs from HEAD, indicating changes that are ready to be committed.\n\n```\nWorking Directory: file.txt (hash: def456)\nIndex: file.txt (hash: def456)\nHEAD: file.txt (hash: abc123)\nStatus: Modified (staged)\n```\n\n**Deleted Files:**\nFiles that exist in HEAD or the index but are missing from the working directory.\n\n```\nWorking Directory: (absent)\nIndex: file.txt (hash: abc123)\nHEAD: file.txt (hash: abc123)\nStatus: Deleted (unstaged)\n```\n\n**Both Modified (Conflicted State):**\nFiles that have different content in all three states, indicating both staged and unstaged changes exist simultaneously.\n\n```\nWorking Directory: file.txt (hash: ghi789)\nIndex: file.txt (hash: def456)  \nHEAD: file.txt (hash: abc123)\nStatus: Modified (both staged and unstaged)\n```\n\n**Optimization Strategies:**\n\nStatus calculation can be expensive in large repositories, so several optimization techniques are crucial:\n\n**Metadata-Based Change Detection:**\nUse the cached stat information in index entries to avoid re-reading file content. If a file's mtime and size haven't changed since it was staged, assume its content hasn't changed either.\n\n**Parallel Processing:**\nProcess different subtrees of the repository concurrently. Since file hashing is CPU-intensive, parallelizing across multiple files can significantly speed up status calculation.\n\n**Incremental Updates:**\nCache status results and only re-examine files whose metadata indicates they might have changed. This is particularly effective for interactive tools that repeatedly call status.\n\n**Ignore File Processing:**\nEfficiently skip untracked files that match .gitignore patterns without examining their content. This prevents status calculation from becoming slow in directories with many generated files.\n\n> **Decision: Three-Way vs Pair-Wise Comparison**\n> - **Context**: Need to determine file states for status display and as input to merge algorithms\n> - **Options Considered**: \n>   - Pair-wise comparisons: Compare working dir vs index, then index vs HEAD separately\n>   - Three-way comparison: Examine all three states simultaneously for each file\n>   - Lazy evaluation: Only compute states for files the user specifically requests\n> - **Decision**: Three-way comparison with optimization shortcuts\n> - **Rationale**: Three-way comparison provides complete information needed for merge operations and enables more accurate status reporting (can detect \"both modified\" states). Pair-wise approaches miss important state combinations and require multiple passes through file sets.\n> - **Consequences**: More complex algorithm but provides comprehensive status information needed by advanced Git operations like merge and rebase\n\n**Common Status Calculation Pitfalls:**\n\n⚠️ **Pitfall: Ignoring File System Case Sensitivity**\nOn case-insensitive file systems (macOS, Windows), files named `File.txt` and `file.txt` are the same file system object but different Git objects. Status calculation must handle this correctly by using the file system's canonical casing for working directory files while preserving the exact casing stored in Git objects.\n\n⚠️ **Pitfall: Race Conditions During Status Calculation**\nFiles can be modified while status is being calculated, leading to inconsistent results. The algorithm must handle cases where file metadata changes between when the file list is built and when individual files are examined.\n\n⚠️ **Pitfall: Memory Usage with Large Repositories**\nLoading all file paths into memory simultaneously can consume excessive memory in repositories with hundreds of thousands of files. Streaming approaches that process files incrementally are necessary for very large repositories.\n\n⚠️ **Pitfall: Inefficient Untracked File Detection**\nScanning the entire working directory tree for untracked files can be extremely slow. The algorithm must respect .gitignore rules early to avoid examining large directories full of generated files (like `node_modules` or build outputs).\n\n![Index File Structure](./diagrams/index-format.svg)\n\n### Implementation Guidance\n\nThe index implementation requires careful handling of binary data formats and efficient file system operations. This guidance provides complete infrastructure code for the non-core components and skeleton code for the core learning objectives.\n\n**Technology Recommendations:**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Binary Parsing | `struct` module with format strings | `ctypes` or `numpy` for performance |\n| File I/O | Standard `open()` with binary mode | `mmap` for large index files |\n| Sorting | Built-in `sorted()` function | Custom sorting with locale awareness |\n| Concurrency | File locking with `fcntl` (Unix) | Cross-platform locking library |\n| Status Display | Simple print statements | Rich terminal formatting with colors |\n\n**Recommended File Structure:**\n\n```\nproject-root/\n  git/\n    __init__.py\n    repository.py           ← Repository class\n    objects.py              ← Object store (from previous milestones)\n    index.py                ← Index implementation (THIS COMPONENT)\n      IndexEntry            ← Individual file entry\n      Index                 ← Main index operations\n      StatusCalculator      ← Three-way comparison logic\n    references.py           ← Branch/HEAD management (next milestone)\n    commands/\n      add.py                ← git add command\n      status.py             ← git status command\n      commit.py             ← git commit command\n    utils/\n      binary_parser.py      ← Binary format helpers (infrastructure)\n      file_utils.py         ← File system utilities (infrastructure)\n  tests/\n    test_index.py           ← Index unit tests\n    test_status.py          ← Status calculation tests\n```\n\n**Infrastructure: Binary Parser Utilities**\n\nThis complete utility module handles the low-level binary format parsing, so you can focus on the higher-level index logic:\n\n```python\n# utils/binary_parser.py - COMPLETE INFRASTRUCTURE CODE\nimport struct\nimport hashlib\nfrom typing import Tuple, List, Optional\nfrom pathlib import Path\n\nclass BinaryReader:\n    \"\"\"Helper for reading structured binary data from Git files.\"\"\"\n    \n    def __init__(self, data: bytes):\n        self.data = data\n        self.offset = 0\n    \n    def read_bytes(self, count: int) -> bytes:\n        \"\"\"Read exactly count bytes and advance position.\"\"\"\n        if self.offset + count > len(self.data):\n            raise ValueError(f\"Not enough data: need {count}, have {len(self.data) - self.offset}\")\n        result = self.data[self.offset:self.offset + count]\n        self.offset += count\n        return result\n    \n    def read_uint32(self) -> int:\n        \"\"\"Read big-endian 32-bit unsigned integer.\"\"\"\n        return struct.unpack(\">I\", self.read_bytes(4))[0]\n    \n    def read_uint16(self) -> int:\n        \"\"\"Read big-endian 16-bit unsigned integer.\"\"\"\n        return struct.unpack(\">H\", self.read_bytes(2))[0]\n    \n    def read_cstring(self) -> str:\n        \"\"\"Read null-terminated string.\"\"\"\n        start = self.offset\n        while self.offset < len(self.data) and self.data[self.offset] != 0:\n            self.offset += 1\n        if self.offset >= len(self.data):\n            raise ValueError(\"Unterminated string\")\n        result = self.data[start:self.offset].decode('utf-8')\n        self.offset += 1  # Skip null terminator\n        return result\n    \n    def align_to_4_bytes(self):\n        \"\"\"Advance to next 4-byte boundary.\"\"\"\n        while self.offset % 4 != 0:\n            self.offset += 1\n\nclass BinaryWriter:\n    \"\"\"Helper for writing structured binary data to Git files.\"\"\"\n    \n    def __init__(self):\n        self.data = bytearray()\n    \n    def write_bytes(self, data: bytes):\n        \"\"\"Write raw bytes.\"\"\"\n        self.data.extend(data)\n    \n    def write_uint32(self, value: int):\n        \"\"\"Write big-endian 32-bit unsigned integer.\"\"\"\n        self.data.extend(struct.pack(\">I\", value))\n    \n    def write_uint16(self, value: int):\n        \"\"\"Write big-endian 16-bit unsigned integer.\"\"\"\n        self.data.extend(struct.pack(\">H\", value))\n    \n    def write_cstring(self, text: str):\n        \"\"\"Write null-terminated UTF-8 string.\"\"\"\n        self.data.extend(text.encode('utf-8'))\n        self.data.append(0)\n    \n    def pad_to_4_bytes(self):\n        \"\"\"Pad with null bytes to next 4-byte boundary.\"\"\"\n        while len(self.data) % 4 != 0:\n            self.data.append(0)\n    \n    def get_data(self) -> bytes:\n        \"\"\"Get the complete binary data.\"\"\"\n        return bytes(self.data)\n\ndef compute_sha1(data: bytes) -> str:\n    \"\"\"Compute SHA-1 hash and return as hex string.\"\"\"\n    return hashlib.sha1(data).hexdigest()\n\ndef verify_checksum(data: bytes) -> bool:\n    \"\"\"Verify that the last 20 bytes are SHA-1 of the rest.\"\"\"\n    if len(data) < 20:\n        return False\n    content = data[:-20]\n    expected_checksum = data[-20:]\n    actual_checksum = hashlib.sha1(content).digest()\n    return expected_checksum == actual_checksum\n```\n\n**Infrastructure: File System Utilities**\n\nComplete utility functions for safe file operations and metadata handling:\n\n```python\n# utils/file_utils.py - COMPLETE INFRASTRUCTURE CODE\nimport os\nimport stat\nimport time\nimport tempfile\nfrom pathlib import Path\nfrom typing import Dict, Any, Optional\n\ndef get_file_metadata(file_path: Path) -> Dict[str, Any]:\n    \"\"\"Get complete file metadata for index storage.\"\"\"\n    try:\n        st = file_path.stat()\n        return {\n            'ctime_sec': int(st.st_ctime),\n            'ctime_nsec': int((st.st_ctime - int(st.st_ctime)) * 1_000_000_000),\n            'mtime_sec': int(st.st_mtime),  \n            'mtime_nsec': int((st.st_mtime - int(st.st_mtime)) * 1_000_000_000),\n            'device': st.st_dev,\n            'inode': st.st_ino,\n            'mode': st.st_mode,\n            'uid': st.st_uid,\n            'gid': st.st_gid,\n            'size': st.st_size,\n        }\n    except OSError:\n        return None\n\ndef is_file_modified(file_path: Path, cached_mtime_sec: int, cached_size: int) -> bool:\n    \"\"\"Fast check if file might be modified using cached metadata.\"\"\"\n    try:\n        st = file_path.stat()\n        return (int(st.st_mtime) != cached_mtime_sec or \n                st.st_size != cached_size)\n    except OSError:\n        return True  # File missing/inaccessible = modified\n\ndef atomic_write_file(file_path: Path, content: bytes):\n    \"\"\"Write file atomically using temp file + rename.\"\"\"\n    temp_path = file_path.with_suffix(file_path.suffix + '.tmp')\n    try:\n        with open(temp_path, 'wb') as f:\n            f.write(content)\n            f.flush()\n            os.fsync(f.fileno())  # Ensure written to disk\n        temp_path.rename(file_path)  # Atomic on most filesystems\n    except:\n        if temp_path.exists():\n            temp_path.unlink()\n        raise\n\ndef scan_directory(dir_path: Path, ignore_patterns: Optional[set] = None) -> List[Path]:\n    \"\"\"Recursively scan directory for all files, respecting ignore patterns.\"\"\"\n    if ignore_patterns is None:\n        ignore_patterns = {'.git', '__pycache__', '.pyc'}\n    \n    files = []\n    try:\n        for root, dirs, filenames in os.walk(dir_path):\n            # Remove ignored directories to prevent os.walk from entering them\n            dirs[:] = [d for d in dirs if d not in ignore_patterns]\n            \n            for filename in filenames:\n                if filename not in ignore_patterns:\n                    file_path = Path(root) / filename\n                    files.append(file_path.relative_to(dir_path))\n    except OSError:\n        pass  # Directory inaccessible\n    \n    return sorted(files)\n```\n\n**Core Logic: Index Entry Structure**\n\nHere's the skeleton for the core IndexEntry class that you need to implement:\n\n```python\n# index.py - CORE LOGIC SKELETON\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import Optional, List, Dict, Set\nfrom .utils.binary_parser import BinaryReader, BinaryWriter, compute_sha1\nfrom .utils.file_utils import get_file_metadata, atomic_write_file\n\nINDEX_VERSION = 2\nFILE_MODE_REGULAR = 0o100644\n\n@dataclass\nclass IndexEntry:\n    \"\"\"Represents a single file entry in the Git index.\"\"\"\n    # File metadata (cached for fast change detection)\n    ctime_sec: int\n    ctime_nsec: int\n    mtime_sec: int\n    mtime_nsec: int\n    device: int\n    inode: int\n    mode: int\n    uid: int\n    gid: int\n    size: int\n    \n    # Git object information\n    object_hash: str  # 40-character hex SHA-1\n    flags: int        # Status flags and path length\n    path: str         # Relative path from repository root\n\n    @classmethod\n    def from_file(cls, file_path: Path, object_hash: str, repo_root: Path) -> 'IndexEntry':\n        \"\"\"Create index entry from working directory file.\"\"\"\n        # TODO 1: Get file metadata using get_file_metadata()\n        # TODO 2: Calculate relative path from repo_root\n        # TODO 3: Set flags (path length in lower 12 bits, others zero)\n        # TODO 4: Return IndexEntry with all fields populated\n        # Hint: flags = min(len(relative_path), 0xfff)\n        pass\n    \n    def serialize(self) -> bytes:\n        \"\"\"Serialize entry to binary format for index file.\"\"\"\n        writer = BinaryWriter()\n        \n        # TODO 1: Write all metadata fields as uint32 (10 fields total)\n        # TODO 2: Write SHA-1 hash as 20 binary bytes (convert from hex)\n        # TODO 3: Write flags as uint16\n        # TODO 4: Write path as null-terminated string\n        # TODO 5: Pad to 4-byte boundary\n        # Order: ctime_sec, ctime_nsec, mtime_sec, mtime_nsec, device, \n        #        inode, mode, uid, gid, size, hash_bytes, flags, path\n        pass\n    \n    @classmethod\n    def deserialize(cls, reader: BinaryReader) -> 'IndexEntry':\n        \"\"\"Deserialize entry from binary format.\"\"\"\n        # TODO 1: Read all metadata fields as uint32 (10 fields)\n        # TODO 2: Read SHA-1 hash as 20 binary bytes, convert to hex\n        # TODO 3: Read flags as uint16\n        # TODO 4: Read path as null-terminated string\n        # TODO 5: Align reader to 4-byte boundary\n        # TODO 6: Return IndexEntry instance\n        pass\n```\n\n**Core Logic: Index Class**\n\nThe main Index class that manages the complete staging area:\n\n```python\nclass Index:\n    \"\"\"Git staging area implementation with binary format support.\"\"\"\n    \n    def __init__(self, git_dir: Path):\n        self.git_dir = git_dir\n        self.index_path = git_dir / 'index'\n        self.entries: List[IndexEntry] = []\n    \n    def load(self):\n        \"\"\"Load index from .git/index file.\"\"\"\n        if not self.index_path.exists():\n            self.entries = []\n            return\n        \n        with open(self.index_path, 'rb') as f:\n            data = f.read()\n        \n        # TODO 1: Verify checksum using verify_checksum()\n        # TODO 2: Create BinaryReader with content (excluding checksum)\n        # TODO 3: Read and verify header (signature \"DIRC\", version 2)\n        # TODO 4: Read entry count\n        # TODO 5: Read each entry using IndexEntry.deserialize()\n        # TODO 6: Store entries in self.entries list\n        # Hint: Content for checksum is data[:-20], checksum is data[-20:]\n        pass\n    \n    def save(self):\n        \"\"\"Save index to .git/index file with atomic write.\"\"\"\n        writer = BinaryWriter()\n        \n        # TODO 1: Write header (signature, version, entry count)\n        # TODO 2: Sort entries by path name\n        # TODO 3: Write each entry using entry.serialize()\n        # TODO 4: Calculate SHA-1 checksum of all content\n        # TODO 5: Append checksum as 20 binary bytes\n        # TODO 6: Write atomically using atomic_write_file()\n        pass\n    \n    def add_file(self, file_path: Path, repo_root: Path, object_store):\n        \"\"\"Stage a file by adding it to the index.\"\"\"\n        # TODO 1: Read file content from working directory\n        # TODO 2: Store file content as blob object using object_store.store_object()\n        # TODO 3: Create IndexEntry from file and object hash\n        # TODO 4: Remove any existing entry with same path\n        # TODO 5: Insert new entry maintaining sort order\n        # Hint: Use bisect module for efficient sorted insertion\n        pass\n    \n    def remove_file(self, file_path: str):\n        \"\"\"Remove file from index (unstage).\"\"\"\n        # TODO 1: Find entry with matching path\n        # TODO 2: Remove entry from self.entries list\n        # TODO 3: Don't modify object store (objects are immutable)\n        pass\n    \n    def get_entry(self, file_path: str) -> Optional[IndexEntry]:\n        \"\"\"Get index entry for specified path.\"\"\"\n        # TODO 1: Search through entries for matching path\n        # TODO 2: Return entry if found, None otherwise\n        # Hint: Since entries are sorted, can use binary search\n        pass\n    \n    def get_all_paths(self) -> Set[str]:\n        \"\"\"Get set of all paths in the index.\"\"\"\n        return {entry.path for entry in self.entries}\n```\n\n**Core Logic: Status Calculator**\n\nThe three-way comparison engine:\n\n```python\nclass StatusCalculator:\n    \"\"\"Calculates file status using three-way comparison.\"\"\"\n    \n    def __init__(self, repo_root: Path, git_dir: Path):\n        self.repo_root = repo_root\n        self.git_dir = git_dir\n    \n    def calculate_status(self) -> Dict[str, str]:\n        \"\"\"Perform three-way comparison and return file statuses.\"\"\"\n        # TODO 1: Load index and get all staged file paths\n        # TODO 2: Get HEAD commit and extract all tracked file paths/hashes\n        # TODO 3: Scan working directory for all present files\n        # TODO 4: Create union of all file paths from three sources\n        # TODO 5: For each path, determine state in all three locations\n        # TODO 6: Apply classification rules to determine status\n        # TODO 7: Return dict mapping file paths to status strings\n        pass\n    \n    def _get_head_files(self) -> Dict[str, str]:\n        \"\"\"Get files and hashes from HEAD commit.\"\"\"\n        # TODO 1: Read HEAD reference to get current commit hash\n        # TODO 2: Load commit object and get root tree hash\n        # TODO 3: Recursively walk tree objects to get all file paths/hashes\n        # TODO 4: Return dict mapping paths to object hashes\n        pass\n    \n    def _get_working_files(self) -> Dict[str, str]:\n        \"\"\"Get files and hashes from working directory.\"\"\"\n        # TODO 1: Scan working directory for all files\n        # TODO 2: For each file, compute what its blob hash would be\n        # TODO 3: Skip ignored files (.gitignore rules)\n        # TODO 4: Return dict mapping paths to computed hashes\n        pass\n    \n    def _classify_file_status(self, path: str, wd_hash: Optional[str], \n                             index_hash: Optional[str], head_hash: Optional[str]) -> str:\n        \"\"\"Classify single file status based on three-way comparison.\"\"\"\n        # TODO 1: Handle untracked case (wd present, index and head absent)\n        # TODO 2: Handle added case (wd and index present, head absent)\n        # TODO 3: Handle modified cases (various combinations)\n        # TODO 4: Handle deleted cases (wd absent, index/head present)\n        # TODO 5: Handle staged cases (index differs from head)\n        # TODO 6: Return appropriate status string\n        pass\n```\n\n**Milestone Checkpoint:**\n\nAfter implementing the index system, verify your implementation with these tests:\n\n1. **Basic Add Operation**: \n   ```bash\n   echo \"hello world\" > test.txt\n   python -m git.commands.add test.txt\n   # Should create .git/index file and store blob object\n   ```\n\n2. **Index File Format**:\n   ```bash\n   hexdump -C .git/index | head -5\n   # Should show \"DIRC\" signature, version 2, entry count\n   ```\n\n3. **Status Calculation**:\n   ```bash  \n   python -m git.commands.status\n   # Should show test.txt as \"new file\" (added)\n   ```\n\n4. **Index Persistence**:\n   ```bash\n   # Run status twice - should be fast second time (metadata caching)\n   time python -m git.commands.status\n   time python -m git.commands.status\n   ```\n\n**Debugging Tips:**\n\n| Symptom | Likely Cause | Diagnosis | Fix |\n|---------|--------------|-----------|-----|\n| Index file corrupted | Wrong binary format | `hexdump -C .git/index` | Check field sizes and byte order |\n| Status shows all files modified | Metadata caching broken | Compare cached vs actual mtime/size | Fix stat field extraction |  \n| Add operation fails | Path encoding issues | Check for non-ASCII characters | Use UTF-8 encoding consistently |\n| Performance poor on large repos | Not using metadata optimization | Profile status calculation | Implement fast-path metadata checks |\n\n\n## References and Branch Management\n\n> **Milestone(s):** This section is essential for Milestone 5 (References and Branches) and provides the foundation for branch-based operations in Milestone 7 (Diff Algorithm) and Milestone 8 (Merge)\n\nThe reference system forms the human-readable layer of Git's architecture, sitting above the cryptographic hash-based object store to provide meaningful names for commits and manage the current project state. While Git's underlying storage operates entirely through SHA-1 hashes, users need intuitive names like \"main\", \"feature-branch\", or \"v1.2.3\" to navigate their project history effectively. The reference system bridges this gap by maintaining a mapping from human-readable names to commit hashes, while also tracking the current branch state through the special HEAD reference.\n\n### Mental Model: Bookmarks in History\n\nThink of Git references as **bookmarks in a vast historical library**. Imagine you're researching in a library where every book represents a commit, and books are shelved by their unique catalog number (the SHA-1 hash). Without bookmarks, you'd need to remember cryptic 40-character numbers like \"a1b2c3d4e5f6...\" to find the books you care about.\n\nGit references are like labeled bookmarks you can place anywhere in this library:\n- **Branch references** are moveable bookmarks that automatically advance to new books as you add them to a series\n- **Tag references** are permanent bookmarks that never move, marking important milestones\n- **HEAD** is your special \"you are here\" bookmark that shows which book you're currently reading\n\nWhen you create a new branch called \"feature-login\", you're essentially placing a bookmark labeled \"feature-login\" at the current book (commit). As you write new chapters (make new commits), that bookmark automatically moves forward to always point to your latest work. Meanwhile, other bookmarks like \"main\" stay put unless you explicitly move them.\n\nThe HEAD reference is particularly special—it's like having a \"current location\" bookmark that can either:\n- Point to one of your labeled bookmarks (when you're \"on a branch\")\n- Point directly to a specific book (when you have a \"detached HEAD\")\n\nThis system allows you to navigate through your project's history using memorable names instead of memorizing long hash strings, while Git maintains the cryptographic integrity of the underlying object store.\n\n### Symbolic vs Direct References\n\nGit's reference system supports two fundamentally different types of references that serve distinct purposes in branch management and navigation. Understanding this distinction is crucial for implementing proper branch switching and detached HEAD state handling.\n\n**Direct references** store a raw commit SHA-1 hash and point directly to a commit object in the object store. These references contain exactly 40 hexadecimal characters followed by a newline, with no additional formatting or indirection. When Git needs to resolve a direct reference, it simply reads the hash value and uses it to look up the commit object.\n\n**Symbolic references** store a reference to another reference, creating a level of indirection in the resolution process. The most important symbolic reference is HEAD, which typically contains content like `ref: refs/heads/main\\n` instead of a raw hash. When Git resolves a symbolic reference, it first reads the reference name, then follows that reference to find the actual commit hash.\n\nThe HEAD reference demonstrates why this distinction matters for branch management. When you're working on a branch, HEAD contains a symbolic reference pointing to the current branch (e.g., `ref: refs/heads/feature-branch`). This means that when you make a new commit, Git updates the branch reference file, and HEAD automatically points to the new commit through the symbolic link. This is how Git knows to advance the current branch when you commit.\n\nHowever, when you check out a specific commit hash (creating a detached HEAD state), HEAD becomes a direct reference containing the raw commit SHA-1. In this state, making new commits doesn't update any branch—the commits exist but aren't reachable through any branch name.\n\n| Reference Type | Content Format | Resolution Process | Use Case | Example Content |\n|----------------|----------------|-------------------|----------|-----------------|\n| Direct | Raw SHA-1 hash + newline | Single lookup in object store | Branch tips, tags, detached HEAD | `a1b2c3d4e5f6789...` |\n| Symbolic | `ref: ` + reference path + newline | Two-step: resolve target ref, then lookup | HEAD pointing to current branch | `ref: refs/heads/main` |\n\n> **Design Principle**: The symbolic reference mechanism enables Git's branch semantics. Without symbolic references, there would be no concept of \"being on a branch\"—you would always be in a detached state, and commits wouldn't automatically advance any branch pointer.\n\n**Reference Resolution Algorithm**\n\nThe process of resolving any reference to its final commit hash follows these steps:\n\n1. **Read the reference file** from the appropriate location (`.git/HEAD`, `.git/refs/heads/branchname`, etc.)\n2. **Check the content format** by examining the first few bytes for the `ref: ` prefix\n3. **For symbolic references**: Extract the target reference path, then recursively resolve that reference\n4. **For direct references**: Validate the SHA-1 format (40 hex characters) and return the hash\n5. **Verify the target commit exists** in the object store before considering resolution successful\n\nThis resolution process can chain multiple symbolic references, though in practice Git repositories rarely have chains longer than two levels (HEAD → branch → commit).\n\n> **Decision: Single-Level Symbolic Reference Implementation**\n> - **Context**: While Git supports arbitrary symbolic reference chains, most real-world usage involves only HEAD pointing to branches\n> - **Options Considered**: Full recursive resolution vs single-level resolution vs direct references only\n> - **Decision**: Implement single-level symbolic reference resolution (HEAD → branch → commit)\n> - **Rationale**: Covers 99% of real Git usage while keeping implementation simple and reducing infinite loop risk\n> - **Consequences**: Enables proper branch semantics and detached HEAD handling without complex recursion logic\n\n### Branch Creation and Switching\n\nBranch management operations form the core of Git's workflow, allowing developers to create parallel lines of development and switch between them safely. The implementation must handle three primary operations: creating new branches, switching between existing branches, and managing the transition between attached and detached HEAD states.\n\n**Branch Creation Process**\n\nCreating a new branch involves establishing a new reference that points to a specific commit, typically the current HEAD commit. The process requires careful coordination between the reference system and the working directory to maintain repository consistency.\n\nThe branch creation algorithm proceeds through these steps:\n\n1. **Resolve the target commit hash** from the specified starting point (HEAD by default, or a specific commit/branch name)\n2. **Validate the target commit exists** in the object store to prevent creating branches that point to non-existent commits\n3. **Check for branch name conflicts** by verifying no file exists at `.git/refs/heads/branch-name`\n4. **Create the branch reference file** at `.git/refs/heads/branch-name` containing the target commit hash\n5. **Optionally switch to the new branch** by updating HEAD to point to the new branch reference\n\nBranch names must follow Git's reference naming rules to avoid conflicts with the file system and Git's internal operations. Valid branch names cannot contain spaces, control characters, or special sequences like `..` that could interfere with reference resolution.\n\n| Branch Creation Input | Target Commit Resolution | Result | Example |\n|----------------------|--------------------------|--------|---------|\n| `git branch feature` | Current HEAD commit | New branch at HEAD | `refs/heads/feature` → `abc123...` |\n| `git branch hotfix main` | Tip of main branch | New branch at main's tip | `refs/heads/hotfix` → `def456...` |\n| `git branch release abc123` | Specific commit hash | New branch at that commit | `refs/heads/release` → `abc123...` |\n\n**Branch Switching Algorithm**\n\nSwitching branches requires updating both HEAD and the working directory to reflect the target branch's state. This operation is one of the most complex in Git because it must handle file system changes while maintaining data safety.\n\nThe branch switching process involves several critical steps:\n\n1. **Resolve the target branch reference** to get the target commit hash, handling both local branches and commit hashes\n2. **Check working directory status** to detect uncommitted changes that might be lost during the switch\n3. **Load the target commit's tree object** to determine what files should exist in the working directory\n4. **Calculate working directory changes** by comparing current files with the target tree structure\n5. **Apply file system changes** by creating, modifying, or deleting files to match the target tree\n6. **Update HEAD reference** to point to the target branch (symbolic) or commit (direct)\n7. **Update the index** to reflect the new working directory state if necessary\n\nThe most critical aspect of branch switching is handling uncommitted changes safely. Git uses a three-way comparison between the current HEAD, target commit, and working directory to determine if changes can be preserved or if they would be lost.\n\n**Working Directory Update Strategy**\n\nWhen switching branches, Git must transform the working directory from one tree state to another while preserving user work where possible. This involves analyzing each file in both trees and applying the appropriate changes.\n\n| Current File State | Target File State | Action Required | Conflict Potential |\n|-------------------|-------------------|-----------------|-------------------|\n| Exists, clean | Exists, different content | Overwrite with target | None |\n| Exists, modified | Exists, different content | Check for conflicts | High - may lose changes |\n| Exists, clean | Does not exist | Delete file | None |\n| Exists, modified | Does not exist | Refuse switch or force delete | High - would lose changes |\n| Does not exist | Exists | Create with target content | Low - check for untracked conflicts |\n\n> **Safety Principle**: Git should never silently lose user data. Branch switching must either preserve all changes or explicitly warn the user about potential data loss and require confirmation.\n\n**Detached HEAD State Management**\n\nThe detached HEAD state occurs when HEAD points directly to a commit hash rather than to a branch reference. This state is essential for examining historical commits, building releases from specific points, or creating experimental commits that aren't part of any branch.\n\nEntering detached HEAD state happens in several scenarios:\n\n1. **Explicit commit checkout**: `git checkout abc123` where `abc123` is a commit hash\n2. **Tag checkout**: `git checkout v1.2.3` where the tag points to a commit rather than a branch\n3. **Historical navigation**: `git checkout HEAD~3` to examine a previous commit\n\nThe implementation must handle the transition between attached and detached states carefully, updating HEAD's content format and providing clear user feedback about the state change.\n\n**Detached HEAD State Transitions**\n\n![Reference State Machine](./diagrams/reference-states.svg)\n\nThe state machine shows the valid transitions between different HEAD states and the operations that trigger them. Each state has different implications for commit behavior and branch advancement.\n\n| Current State | Operation | Next State | HEAD Content | Branch Update Behavior |\n|---------------|-----------|------------|--------------|----------------------|\n| On branch `main` | `checkout feature-branch` | On branch `feature-branch` | `ref: refs/heads/feature-branch` | Commits advance feature-branch |\n| On branch `main` | `checkout abc123` | Detached HEAD | `abc123...` | Commits create orphan history |\n| Detached HEAD | `checkout main` | On branch `main` | `ref: refs/heads/main` | Commits advance main branch |\n| Detached HEAD | Create new branch from HEAD | On new branch | `ref: refs/heads/new-branch` | Commits advance new-branch |\n\n**Reference File Management**\n\nThe reference system stores all branch and tag information as plain text files within the `.git/refs/` directory tree. This simple approach makes Git repositories inspectable and debuggable with standard file system tools while providing atomic updates through file system operations.\n\nThe directory structure organizes references by type and namespace:\n\n```\n.git/\n  HEAD                    ← current branch pointer (symbolic ref)\n  refs/\n    heads/               ← local branches\n      main               ← contains commit hash for main branch\n      feature-login      ← contains commit hash for feature-login branch\n      hotfix/security    ← branches can have path separators\n    remotes/             ← remote-tracking branches (future extension)\n      origin/main        ← tracks remote main branch\n    tags/                ← tag references\n      v1.0.0            ← contains commit hash for v1.0.0 tag\n```\n\nEach reference file contains a single line of text: either a raw SHA-1 hash (for direct references) or a symbolic reference in the format `ref: refs/heads/branch-name`. The newline character at the end is significant and must be preserved for compatibility with Git's reference parsing.\n\n**Atomic Reference Updates**\n\nReference updates must be atomic to prevent repository corruption during concurrent operations or system failures. The implementation uses the standard technique of writing to a temporary file and then atomically renaming it to the target location.\n\nThe atomic update process follows these steps:\n\n1. **Generate a unique temporary filename** in the same directory as the target reference file\n2. **Write the new reference content** to the temporary file, including the required newline character\n3. **Sync the temporary file** to ensure the data is written to stable storage\n4. **Atomically rename** the temporary file to the final reference filename\n5. **Clean up** any temporary files on failure to avoid leaving debris in the repository\n\nThis approach ensures that reference files are never in an inconsistent state—they either contain the old value or the new value, never partial writes or corrupted data.\n\n> **Decision: Plain Text Reference Files**\n> - **Context**: Git needs to store mappings from branch names to commit hashes with atomic updates and human readability\n> - **Options Considered**: Plain text files vs binary packed format vs embedded database\n> - **Decision**: Use plain text files in .git/refs/ directory structure\n> - **Rationale**: Simple implementation, atomic updates via file system, human-readable for debugging, compatible with Git tooling\n> - **Consequences**: Slightly slower than packed refs for repositories with thousands of branches, but much simpler and more reliable\n\n**Branch Name Validation**\n\nBranch names must follow specific rules to avoid conflicts with Git's internal operations and file system limitations. The validation process ensures that branch names can be safely used as file names and don't interfere with Git's reference resolution algorithms.\n\nInvalid branch name patterns include:\n\n- **Control characters**: ASCII control characters (0x00-0x1f) that might interfere with text processing\n- **Path separators**: While `/` is allowed within branch names, `.` and `..` are prohibited to prevent directory traversal\n- **Special sequences**: Patterns like `@{` that Git uses for reference specifications\n- **Reserved names**: Names that conflict with Git's internal references or common conventions\n\n| Pattern | Valid? | Reason | Example |\n|---------|--------|--------|---------|\n| `feature-login` | ✓ | Alphanumeric with hyphens | Standard branch name |\n| `hotfix/security` | ✓ | Slash creates namespace | Organized branch structure |\n| `release-1.0` | ✓ | Alphanumeric with dash and dot | Version branch naming |\n| `.hidden` | ✗ | Leading dot reserved | Could conflict with Git internals |\n| `branch..name` | ✗ | Double dot reserved | Conflicts with revision syntax |\n| `branch name` | ✗ | Spaces cause parsing issues | Would break command line tools |\n\n**Common Pitfalls**\n\n⚠️ **Pitfall: Forgetting to Update Working Directory During Branch Switch**\n\nMany implementations correctly update HEAD but forget to modify the working directory files to match the target branch's tree. This leaves the repository in an inconsistent state where HEAD points to one commit but the working directory contains files from another commit.\n\nThe symptoms include: files appearing modified immediately after a branch switch, confusion about which branch's changes are visible, and potential data loss when users assume they're working on a different branch than their files represent.\n\n**Fix**: Always implement the complete branch switching algorithm that updates both HEAD and working directory atomically, or fail the entire operation if working directory updates cannot be completed safely.\n\n⚠️ **Pitfall: Creating Branches Without Validating Target Commits**\n\nCreating a branch reference that points to a non-existent commit hash creates a broken branch that cannot be checked out or used for any operations. This commonly happens when implementing branch creation from user-specified commit hashes without verifying the commits exist.\n\nThe symptoms include: branches that appear in branch listings but cannot be checked out, error messages about missing objects when trying to use the branch, and confusion about whether commits were lost or never existed.\n\n**Fix**: Always validate that the target commit exists in the object store before creating any reference that points to it. Use the `object_exists()` function to verify commit availability.\n\n⚠️ **Pitfall: Race Conditions in Reference Updates**\n\nWriting reference files without atomic updates can lead to corruption when multiple Git processes run simultaneously or when system failures occur during writes. This creates partially-written reference files containing truncated hashes or mixed content.\n\nThe symptoms include: references containing partial SHA-1 hashes, \"not a valid object name\" errors when resolving references, and repository corruption that requires manual repair.\n\n**Fix**: Always use atomic file updates with temporary files and rename operations. Never write directly to reference files in-place.\n\n⚠️ **Pitfall: Incorrect HEAD Format for Symbolic References**\n\nThe HEAD file format for symbolic references is strict: `ref: refs/heads/branch-name\\n` with exactly one space after the colon, no extra whitespace, and a single trailing newline. Deviating from this format breaks reference resolution.\n\nCommon mistakes include: missing the space after the colon (`ref:refs/heads/main`), adding extra spaces or tabs, omitting the trailing newline, or using Windows line endings (`\\r\\n`) instead of Unix line endings.\n\n**Fix**: Use string constants for the symbolic reference format and validate the exact format when reading symbolic references. Always use binary file writing to control line endings precisely.\n\n### Implementation Guidance\n\nThe reference management system requires careful attention to file system operations and atomic updates. This implementation provides a robust foundation for branch operations while maintaining compatibility with Git's reference format.\n\n**Technology Recommendations**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| File Operations | `pathlib.Path` with text read/write | `pathlib.Path` with atomic writes and file locking |\n| Reference Resolution | Recursive function with depth limit | State machine with cycle detection |\n| Branch Validation | Regular expression patterns | Full Git reference name validation |\n| Concurrent Access | File system atomic operations | Advisory file locking with timeouts |\n\n**Recommended File Structure**\n\n```python\nproject-root/\n  git_implementation/\n    core/\n      repository.py          ← Repository class with reference methods\n      reference_manager.py   ← ReferenceManager implementation\n      object_store.py       ← ObjectStore for commit validation\n    utils/\n      file_operations.py    ← Atomic file write utilities\n      validation.py         ← Branch name validation functions\n    tests/\n      test_references.py    ← Reference system tests\n      test_branches.py      ← Branch operation tests\n```\n\n**Infrastructure Starter Code**\n\nHere's a complete atomic file operations utility that handles the low-level file system operations needed for safe reference updates:\n\n```python\n\"\"\"\nAtomic file operations for safe repository updates.\nProvides utilities for writing files atomically to prevent corruption.\n\"\"\"\nimport os\nimport tempfile\nfrom pathlib import Path\nfrom typing import Union\n\ndef atomic_write_file(file_path: Path, content: Union[str, bytes]) -> None:\n    \"\"\"\n    Write content to a file atomically using temporary file and rename.\n    \n    Args:\n        file_path: Target file path to write\n        content: Content to write (str or bytes)\n    \n    Raises:\n        OSError: If file operations fail\n        UnicodeEncodeError: If string content cannot be encoded as UTF-8\n    \"\"\"\n    # Ensure parent directory exists\n    file_path.parent.mkdir(parents=True, exist_ok=True)\n    \n    # Create temporary file in same directory for atomic rename\n    temp_fd, temp_path = tempfile.mkstemp(\n        dir=file_path.parent,\n        prefix=f\".tmp_{file_path.name}_\",\n        suffix=\".tmp\"\n    )\n    \n    try:\n        with os.fdopen(temp_fd, 'wb') as temp_file:\n            if isinstance(content, str):\n                temp_file.write(content.encode('utf-8'))\n            else:\n                temp_file.write(content)\n            \n            # Force write to disk before rename\n            temp_file.flush()\n            os.fsync(temp_file.fileno())\n        \n        # Atomic rename to final location\n        os.rename(temp_path, file_path)\n        \n    except Exception:\n        # Clean up temp file on any error\n        try:\n            os.unlink(temp_path)\n        except OSError:\n            pass  # Temp file already gone\n        raise\n\ndef read_reference_file(ref_path: Path) -> str:\n    \"\"\"\n    Read a Git reference file and return its content.\n    \n    Args:\n        ref_path: Path to reference file\n        \n    Returns:\n        Reference content with trailing whitespace stripped\n        \n    Raises:\n        FileNotFoundError: If reference file doesn't exist\n        UnicodeDecodeError: If file contains invalid UTF-8\n    \"\"\"\n    try:\n        with open(ref_path, 'r', encoding='utf-8') as f:\n            return f.read().rstrip('\\n\\r')\n    except FileNotFoundError:\n        raise FileNotFoundError(f\"Reference not found: {ref_path}\")\n\ndef ensure_git_directory_structure(git_dir: Path) -> None:\n    \"\"\"\n    Create the basic .git directory structure needed for references.\n    \n    Args:\n        git_dir: Path to .git directory\n    \"\"\"\n    directories = [\n        git_dir / \"refs\",\n        git_dir / \"refs\" / \"heads\",\n        git_dir / \"refs\" / \"tags\",\n        git_dir / \"refs\" / \"remotes\"\n    ]\n    \n    for directory in directories:\n        directory.mkdir(parents=True, exist_ok=True)\n```\n\n**Branch Name Validation Utilities**\n\n```python\n\"\"\"\nGit reference name validation following Git's naming rules.\n\"\"\"\nimport re\nfrom typing import List\n\n# Git reference name validation patterns\nINVALID_REF_CHARS = re.compile(r'[\\x00-\\x1f\\x7f~^:\\\\\\*\\?]')\nINVALID_REF_SEQUENCES = ['.', '..', '@{', '//']\nRESERVED_REF_NAMES = {'HEAD', 'ORIG_HEAD', 'FETCH_HEAD', 'MERGE_HEAD'}\n\ndef validate_branch_name(name: str) -> List[str]:\n    \"\"\"\n    Validate a branch name against Git's reference naming rules.\n    \n    Args:\n        name: Proposed branch name\n        \n    Returns:\n        List of validation error messages (empty if valid)\n    \"\"\"\n    errors = []\n    \n    if not name:\n        errors.append(\"Branch name cannot be empty\")\n        return errors\n    \n    if name in RESERVED_REF_NAMES:\n        errors.append(f\"'{name}' is a reserved reference name\")\n    \n    if name.startswith('.') or name.endswith('.'):\n        errors.append(\"Branch name cannot start or end with '.'\")\n    \n    if name.startswith('/') or name.endswith('/'):\n        errors.append(\"Branch name cannot start or end with '/'\")\n    \n    if INVALID_REF_CHARS.search(name):\n        errors.append(\"Branch name contains invalid characters\")\n    \n    for sequence in INVALID_REF_SEQUENCES:\n        if sequence in name:\n            errors.append(f\"Branch name cannot contain '{sequence}'\")\n    \n    return errors\n\ndef is_valid_branch_name(name: str) -> bool:\n    \"\"\"Check if a branch name is valid.\"\"\"\n    return len(validate_branch_name(name)) == 0\n```\n\n**Core Logic Skeleton Code**\n\nHere's the main `ReferenceManager` class structure with detailed TODO comments for implementation:\n\n```python\n\"\"\"\nGit reference management system handling branches, HEAD, and symbolic references.\n\"\"\"\nfrom pathlib import Path\nfrom typing import Optional, Dict, Set\nimport hashlib\n\nclass ReferenceManager:\n    \"\"\"Manages Git references including branches, HEAD, and symbolic references.\"\"\"\n    \n    def __init__(self, git_dir: Path):\n        self.git_dir = git_dir\n        self.refs_dir = git_dir / \"refs\"\n        self.heads_dir = self.refs_dir / \"heads\"\n        self.tags_dir = self.refs_dir / \"tags\"\n        self.head_file = git_dir / \"HEAD\"\n    \n    def resolve_reference(self, ref_name: str) -> Optional[str]:\n        \"\"\"\n        Resolve a reference name to its target commit hash.\n        \n        Handles both direct references (containing commit hashes) and\n        symbolic references (containing 'ref: path/to/other/ref').\n        \n        Args:\n            ref_name: Reference to resolve (e.g., 'HEAD', 'main', 'refs/heads/feature')\n            \n        Returns:\n            Commit SHA-1 hash if reference exists and resolves, None otherwise\n        \"\"\"\n        # TODO 1: Handle special case of 'HEAD' - read from self.head_file\n        # TODO 2: If ref_name doesn't start with 'refs/', try 'refs/heads/' + ref_name\n        # TODO 3: Construct full path to reference file\n        # TODO 4: Check if reference file exists, return None if not\n        # TODO 5: Read reference file content using read_reference_file()\n        # TODO 6: Check if content starts with 'ref: ' (symbolic reference)\n        # TODO 7: For symbolic refs: extract target path and recursively resolve\n        # TODO 8: For direct refs: validate SHA-1 format and return hash\n        # TODO 9: Add recursion depth limit to prevent infinite loops\n        # Hint: Use validate_sha1_hash() to check hash format\n        pass\n    \n    def create_branch(self, branch_name: str, target_commit: str) -> bool:\n        \"\"\"\n        Create a new branch pointing to the specified commit.\n        \n        Args:\n            branch_name: Name for the new branch\n            target_commit: SHA-1 hash of commit to point to\n            \n        Returns:\n            True if branch was created successfully, False otherwise\n        \"\"\"\n        # TODO 1: Validate branch name using validate_branch_name()\n        # TODO 2: Verify target_commit exists in object store using object_exists()\n        # TODO 3: Check if branch already exists (refs/heads/branch_name file exists)\n        # TODO 4: Create branch reference file with atomic_write_file()\n        # TODO 5: Write target_commit hash + '\\n' to the branch file\n        # TODO 6: Return success/failure status\n        # Hint: Branch file path is self.heads_dir / branch_name\n        pass\n    \n    def switch_branch(self, branch_name: str) -> bool:\n        \"\"\"\n        Switch to an existing branch by updating HEAD.\n        \n        This is a simplified version that only updates references without\n        modifying the working directory or index.\n        \n        Args:\n            branch_name: Name of branch to switch to\n            \n        Returns:\n            True if switch was successful, False otherwise\n        \"\"\"\n        # TODO 1: Verify target branch exists using branch_exists()\n        # TODO 2: Create symbolic reference content: f\"ref: refs/heads/{branch_name}\\n\"\n        # TODO 3: Write symbolic reference to HEAD file using atomic_write_file()\n        # TODO 4: Return success status\n        # Note: Full implementation would also update working directory\n        pass\n    \n    def checkout_commit(self, commit_hash: str) -> bool:\n        \"\"\"\n        Enter detached HEAD state by pointing HEAD directly to a commit.\n        \n        Args:\n            commit_hash: SHA-1 hash of commit to check out\n            \n        Returns:\n            True if checkout was successful, False otherwise\n        \"\"\"\n        # TODO 1: Validate commit_hash format using validate_sha1_hash()\n        # TODO 2: Verify commit exists in object store using object_exists()\n        # TODO 3: Write commit hash + '\\n' directly to HEAD file (direct reference)\n        # TODO 4: Return success status\n        # Note: This creates detached HEAD state\n        pass\n    \n    def get_current_branch(self) -> Optional[str]:\n        \"\"\"\n        Get the name of the current branch, if HEAD points to a branch.\n        \n        Returns:\n            Branch name if on a branch, None if in detached HEAD state\n        \"\"\"\n        # TODO 1: Read HEAD file content\n        # TODO 2: Check if content starts with 'ref: refs/heads/'\n        # TODO 3: Extract branch name from symbolic reference\n        # TODO 4: Return branch name or None for detached HEAD\n        pass\n    \n    def list_branches(self) -> Set[str]:\n        \"\"\"\n        List all local branches in the repository.\n        \n        Returns:\n            Set of branch names\n        \"\"\"\n        # TODO 1: Check if refs/heads directory exists\n        # TODO 2: Iterate through all files in refs/heads directory\n        # TODO 3: Use glob or iterdir to find all branch files\n        # TODO 4: Extract branch names (relative paths from refs/heads/)\n        # TODO 5: Return set of branch names\n        # Hint: Use Path.iterdir() and handle subdirectories for namespaced branches\n        pass\n    \n    def delete_branch(self, branch_name: str, force: bool = False) -> bool:\n        \"\"\"\n        Delete a branch reference.\n        \n        Args:\n            branch_name: Name of branch to delete\n            force: If True, delete even if it's the current branch\n            \n        Returns:\n            True if deletion was successful, False otherwise\n        \"\"\"\n        # TODO 1: Check if branch exists\n        # TODO 2: If not force, verify branch is not current branch\n        # TODO 3: Remove branch reference file using Path.unlink()\n        # TODO 4: Handle FileNotFoundError gracefully\n        # TODO 5: Return success status\n        pass\n    \n    def branch_exists(self, branch_name: str) -> bool:\n        \"\"\"Check if a branch exists.\"\"\"\n        # TODO: Check if refs/heads/branch_name file exists\n        pass\n    \n    def is_detached_head(self) -> bool:\n        \"\"\"Check if HEAD is in detached state (points to commit, not branch).\"\"\"\n        # TODO 1: Read HEAD file content\n        # TODO 2: Return True if content is a SHA-1 hash, False if symbolic ref\n        pass\n\ndef validate_sha1_hash(hash_str: str) -> bool:\n    \"\"\"Validate that a string is a valid SHA-1 hash.\"\"\"\n    if len(hash_str) != 40:\n        return False\n    try:\n        int(hash_str, 16)\n        return True\n    except ValueError:\n        return False\n```\n\n**Language-Specific Hints**\n\n- Use `pathlib.Path` for all file system operations - it handles path joining and OS differences automatically\n- Python's `tempfile.mkstemp()` creates temporary files securely with proper permissions\n- Always use `'utf-8'` encoding when reading/writing text files to ensure compatibility\n- Use `os.fsync()` after writing critical files like references to ensure data reaches disk\n- The `rstrip('\\n\\r')` method handles both Unix and Windows line endings when reading files\n- Use `Path.mkdir(parents=True, exist_ok=True)` to create directory trees safely\n\n**Milestone Checkpoint**\n\nAfter implementing the reference management system, verify these behaviors:\n\n1. **Branch Creation**: Create a branch with `create_branch('feature', 'commit_hash')` and verify the file `refs/heads/feature` contains the commit hash\n2. **Branch Listing**: Call `list_branches()` and verify it returns all branch names from the file system\n3. **HEAD Management**: Switch branches and verify HEAD content changes between symbolic and direct references\n4. **Reference Resolution**: Test resolving 'HEAD', branch names, and full reference paths\n5. **Detached HEAD**: Checkout a commit hash and verify `is_detached_head()` returns True\n\nExpected file system state after creating branch 'feature':\n```\n.git/\n  HEAD                     ← contains \"ref: refs/heads/main\\n\"\n  refs/heads/\n    main                   ← contains commit hash\n    feature                ← contains same or different commit hash\n```\n\n**Debugging Tips**\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|-----------------|-----|\n| Branch appears in listing but cannot be resolved | Invalid commit hash in branch file | Check file contents with `cat .git/refs/heads/branch` | Recreate branch with valid commit hash |\n| HEAD resolution fails after branch switch | Incorrect symbolic reference format | Check HEAD file format: should be `ref: refs/heads/branch\\n` | Rewrite HEAD with correct format |\n| Branch creation succeeds but branch disappears | Missing newline in reference file | Check file ends with `\\n` character | Always append `\\n` to reference content |\n| Permission denied when updating references | Incorrect file permissions on .git directory | Check `.git` directory is writable | Set proper permissions with `chmod` |\n| Reference resolution enters infinite loop | Circular symbolic reference | Trace reference chain manually | Add recursion depth limit to resolution |\n\n\n## Diff Algorithm Implementation\n\n> **Milestone(s):** This section is critical for Milestone 7 (Diff Algorithm) and provides the foundation for conflict detection in Milestone 8 (Three-Way Merge). The diff algorithm serves as the core comparison engine for status calculation in Milestone 6 (Index/Staging Area).\n\nThe diff algorithm forms the analytical heart of any version control system. While Git's object store provides immutable content storage and the index manages staging, the diff algorithm answers the fundamental question: \"What changed between two versions of a file or project?\" This capability underpins virtually every Git operation that involves comparison - from `git status` showing modified files to `git merge` detecting conflicts between branches.\n\nThe challenge of implementing diff extends beyond simple file comparison. A naive approach of comparing files byte-by-byte would only tell us whether files are identical or different, but not what specifically changed. Users need to see exactly which lines were added, removed, or modified, preferably in a format that highlights the minimal set of changes required to transform one version into another. This is where sophisticated diff algorithms like Myers' algorithm excel, finding the shortest edit script between two sequences while producing human-readable output.\n\nOur diff implementation must handle several complex scenarios: comparing files with vastly different line counts, detecting when entire sections have moved, handling binary files gracefully, and producing output that follows industry-standard unified diff format. The algorithm must also be efficient enough to handle large files without consuming excessive memory or computation time.\n\n### Mental Model: Document Comparison\n\nThink of the diff algorithm as an expert editor comparing two drafts of the same manuscript. When an author submits a revised chapter, the editor doesn't simply declare \"these are different\" - instead, they meticulously identify each change: \"In paragraph 3, you added a new sentence about character motivation. In paragraph 7, you removed the description of the sunset. In paragraph 12, you changed 'walked' to 'strode'.\"\n\nThis editor has developed a systematic approach over years of experience. They don't just scan randomly - they find the longest unchanged passages first (these serve as anchor points), then focus their attention on the gaps between these passages where changes must have occurred. When they find a section that appears in both drafts but in different locations, they recognize it as moved content rather than a deletion followed by an addition.\n\nThe editor also knows that their goal isn't just accuracy, but usefulness. They present changes in a format that makes it easy for the author to understand what happened: showing a few lines of unchanged context around each change, grouping nearby changes together, and using clear markers to indicate additions and deletions. This is exactly how Myers' diff algorithm works - it finds the minimal set of changes between two text sequences and presents them in a format optimized for human comprehension.\n\nThe key insight is that effective diff algorithms don't just identify differences - they find the **optimal** set of differences that minimizes cognitive load for the person reviewing the changes. This requires sophisticated algorithms that can distinguish between genuine changes and coincidental similarities, while producing output that tells a coherent story about how one version evolved into another.\n\n### Myers Diff Algorithm\n\nThe Myers diff algorithm, developed by Eugene Myers in 1986, represents the gold standard for computing differences between two sequences. Unlike simpler approaches that might miss optimal solutions, Myers' algorithm is guaranteed to find the shortest edit script - the minimal sequence of insertions and deletions needed to transform one file into another. This optimality is crucial for producing readable diffs that don't overwhelm users with unnecessary noise.\n\nThe algorithm operates on a fundamental insight about the structure of edit problems. When comparing two sequences A and B, we can visualize the problem as finding a path through a two-dimensional grid where the x-axis represents positions in sequence A and the y-axis represents positions in sequence B. Each cell (i,j) in this grid represents the state where we've processed i elements from sequence A and j elements from sequence B.\n\nFrom any cell in this grid, we have three possible moves: move right (delete an element from A), move down (insert an element from B), or move diagonally (elements match, no edit required). Our goal is to find the path from the top-left corner (0,0) to the bottom-right corner (len(A), len(B)) that requires the fewest non-diagonal moves. Each non-diagonal move corresponds to an edit operation, so minimizing these moves gives us the shortest edit script.\n\nThe brilliance of Myers' algorithm lies in how it explores this space efficiently. Rather than examining every possible path (which would be exponential), it uses a technique called \"edit distance computation with greedy matching.\" The algorithm processes the comparison in phases, where each phase considers all possible paths that require exactly k edit operations. Within each phase, it greedily extends paths as far as possible using diagonal moves (matching elements), which cost nothing.\n\nHere's how the algorithm proceeds step by step:\n\n1. **Initialize the exploration**: Create a data structure to track the furthest position reachable along each diagonal for a given number of edits. A diagonal d represents positions where (x - y = d). We track V[d] = x, the furthest x-coordinate reached on diagonal d.\n\n2. **Iterative deepening by edit distance**: For each possible edit distance k from 0 to the maximum possible (len(A) + len(B)), explore all paths that require exactly k edits. This ensures we find the optimal solution as soon as one exists.\n\n3. **Diagonal exploration**: For each diagonal d that could be reached with k edits, calculate the furthest point reachable. We can reach diagonal d either by moving right from diagonal d-1 (deletion) or by moving down from diagonal d+1 (insertion). Choose the option that gets us furthest along diagonal d.\n\n4. **Greedy extension**: Once we've determined our starting position on diagonal d, extend as far as possible using diagonal moves (matching elements). This is the \"greedy\" part - we take all free matches we can get.\n\n5. **Termination check**: After exploring all diagonals for edit distance k, check if any path has reached the target position (len(A), len(B)). If so, we've found the optimal solution with k edits.\n\n6. **Backtracking for edit script**: Once we've found the optimal edit distance, we need to reconstruct the actual sequence of edits. This requires backtracking through our exploration data to find which moves led to the optimal path.\n\nThe algorithm's time complexity is O((M+N)D) where M and N are the lengths of the sequences and D is the length of the shortest edit script. In practice, this performs much better than the theoretical worst case because D is typically much smaller than M+N for most real-world comparisons.\n\n| Algorithm Phase | Purpose | Data Structure | Time Complexity |\n|-----------------|---------|----------------|-----------------|\n| Forward Pass | Find minimum edit distance | V array tracking furthest x per diagonal | O((M+N)D) |\n| Greedy Extension | Maximize diagonal moves within each step | Direct sequence comparison | O(matching characters) |\n| Backtrack Pass | Reconstruct edit sequence | Trace through V snapshots | O(D) |\n| Edit Script Generation | Convert path to insert/delete operations | List of edit commands | O(D) |\n\nThe implementation requires careful handling of several edge cases and optimizations:\n\n**Diagonal indexing**: Since diagonals can have negative indices (when y > x), we need to offset our array indices appropriately. The diagonal d=x-y ranges from -N to M, so we use V[d+N] to ensure non-negative array indices.\n\n**Memory optimization**: The basic algorithm stores the entire V array for each edit distance k, which can consume significant memory for large files. Advanced implementations use techniques like \"linear space refinement\" to reduce memory usage by recomputing portions of the search space as needed.\n\n**Snake detection**: A \"snake\" in Myers' terminology is a sequence of diagonal moves (matching elements). The algorithm spends most of its time detecting and following these snakes, so optimizing this inner loop is crucial for performance.\n\n**Boundary conditions**: Special care is needed when exploring diagonals at the edges of the search space, where we might only be able to reach a diagonal from one direction rather than both.\n\n> **Key Insight**: Myers' algorithm's efficiency comes from recognizing that most file changes are localized. By greedily consuming matching content (diagonal moves) whenever possible, the algorithm quickly navigates through unchanged regions and focuses computational effort on the areas where real differences exist.\n\n#### Architecture Decision Records\n\n> **Decision: Myers Algorithm vs. Patience Diff**\n> - **Context**: Multiple diff algorithms exist with different trade-offs in quality and performance. Myers finds shortest edit distance, while Patience diff often produces more intuitive results for code with moved functions.\n> - **Options Considered**: Myers' algorithm (shortest edit script), Patience diff (unique line anchoring), Hunt-McIlroy algorithm (classic LCS-based)\n> - **Decision**: Implement Myers' algorithm as the primary diff engine\n> - **Rationale**: Myers provides optimal edit distance with reasonable performance, matches Git's internal implementation for compatibility, and has well-understood complexity characteristics. Patience diff can be added later as an alternative strategy.\n> - **Consequences**: Optimal diff output for most cases, some counterintuitive results when functions are moved (can be addressed with post-processing), compatible with existing Git tooling expectations.\n\n| Algorithm Option | Pros | Cons | Performance | Quality |\n|------------------|------|------|-------------|---------|\n| Myers' Algorithm | Optimal edit distance, well-studied, Git-compatible | May miss intuitive moves | O((M+N)D) | Mathematically optimal |\n| Patience Diff | Better handling of moved code blocks | More complex, may not be shortest | O(N log N) typical | More intuitive for code |\n| Hunt-McIlroy | Simple LCS-based approach | Not optimized for text | O(MN) worst case | Basic but functional |\n\n> **Decision: Line-based vs. Character-based Comparison**\n> - **Context**: Diff algorithms can operate at different granularities - comparing entire lines, individual characters, or words. Each choice affects both performance and output usefulness.\n> - **Options Considered**: Character-level diff (finest granularity), word-level diff (balanced approach), line-level diff (Git standard)\n> - **Decision**: Implement line-based comparison as primary mode with character-level available for within-line changes\n> - **Rationale**: Line-based comparison matches user expectations for code review, provides good performance for large files, and aligns with Git's standard behavior. Character-level can be used for highlighting intra-line changes.\n> - **Consequences**: Fast comparison of large files, familiar output format, may miss some fine-grained changes within lines (addressed by intra-line diff post-processing).\n\n> **Decision: In-memory vs. Streaming Comparison**\n> - **Context**: Large files may not fit in memory, requiring either streaming algorithms or memory-mapped file access. This affects both memory usage and algorithm complexity.\n> - **Options Considered**: Full in-memory comparison, streaming with limited lookahead, memory-mapped file access\n> - **Decision**: Use in-memory comparison with fallback to \"binary file\" detection for very large files\n> - **Rationale**: Most source code files are small enough for in-memory processing, simplifies algorithm implementation, and provides better performance for typical use cases. Binary file detection prevents memory exhaustion on large files.\n> - **Consequences**: Excellent performance for typical source files, may not handle very large text files optimally, requires size-based heuristics to detect problematic files.\n\n### Unified Diff Output Format\n\nThe unified diff format represents the industry standard for presenting file differences in a human-readable form. Developed as an improvement over the older \"context diff\" format, unified diff consolidates additions and deletions into single hunks, making it easier to understand what changed while providing sufficient context for applying patches accurately.\n\nUnderstanding unified diff format is crucial because it serves as the common language between different version control systems, patch utilities, and code review tools. When you see a GitHub pull request, apply a patch with `git apply`, or review changes in your IDE, you're likely looking at some variation of unified diff output.\n\nThe format consists of several distinct components, each serving a specific purpose in conveying change information:\n\n**File headers** identify the files being compared and provide metadata about the comparison. The traditional unified diff header includes the original filename prefixed with `---` and the new filename prefixed with `+++`. These lines may include timestamps or revision identifiers, though Git typically uses commit hashes or symbolic names like \"HEAD\" instead of timestamps.\n\n**Hunk headers** mark the beginning of each contiguous block of changes. A hunk header appears as `@@ -start,count +start,count @@` where the first pair describes the line range in the original file and the second pair describes the corresponding range in the new file. The counts indicate how many lines from each file are included in this hunk, including both changed and context lines.\n\n**Context lines** provide unchanged content around modifications to help readers understand where changes occurred. These lines begin with a space character and appear exactly as they exist in both files. The standard is to include three lines of context before and after each change, though this is configurable.\n\n**Deletion lines** show content that was removed from the original file. These lines begin with a `-` character followed by the content that was deleted. Multiple consecutive deletion lines indicate a block of content that was removed.\n\n**Addition lines** show content that was added in the new file. These lines begin with a `+` character followed by the new content. When deletion and addition lines appear together, they typically represent content that was modified rather than purely removed and added.\n\nHere's the detailed structure of unified diff output:\n\n| Component | Format | Example | Purpose |\n|-----------|--------|---------|---------|\n| File Header (original) | `--- filename` | `--- a/src/main.py` | Identifies source file |\n| File Header (new) | `+++ filename` | `+++ b/src/main.py` | Identifies target file |\n| Hunk Header | `@@ -start,count +start,count @@` | `@@ -15,7 +15,8 @@` | Defines change location and scope |\n| Context Line | ` content` | ` def process_data():` | Shows unchanged content for reference |\n| Deletion Line | `-content` | `- return None` | Shows content removed from original |\n| Addition Line | `+content` | `+ return process_result()` | Shows content added in new version |\n| No newline marker | `\\ No newline at end of file` | `\\ No newline at end of file` | Indicates file doesn't end with newline |\n\nThe algorithm for generating unified diff output operates in several phases:\n\n1. **Edit script processing**: Convert the Myers algorithm output (a sequence of insert/delete operations) into a list of change regions. Consecutive operations of the same type can be grouped together for efficiency.\n\n2. **Context calculation**: For each change region, determine the appropriate context lines to include. This requires reading the unchanged content before and after each change, typically 3 lines in each direction.\n\n3. **Hunk consolidation**: Merge nearby change regions into single hunks when their context areas overlap. This prevents repetitive context lines and produces more readable output.\n\n4. **Line number calculation**: Track line numbers in both the original and new files as we process changes. This information is needed for the hunk headers and must account for how previous changes affect subsequent line numbering.\n\n5. **Output formatting**: Generate the actual diff text with proper prefixes, ensuring that each line type is correctly marked and that the overall format follows the unified diff specification.\n\nThe implementation must handle several special cases that commonly occur in real-world file comparisons:\n\n**Files with no final newline**: When a file doesn't end with a newline character, the unified diff format includes a special marker `\\ No newline at end of file` after the affected line. This distinction is important because adding or removing a final newline is a meaningful change in many contexts.\n\n**Empty files**: Comparing to or from empty files requires special handling in the hunk headers. An empty file is represented with line numbers `0,0`, and the hunk header must reflect this appropriately.\n\n**Large change regions**: When an entire file has been rewritten, generating a diff with every line marked as deleted and added may not be useful. Some implementations detect this case and either display a summary message or fall back to binary file handling.\n\n**Binary file detection**: The unified diff format is designed for text files. When binary content is detected (through null bytes or other heuristics), the output should indicate that the files differ without attempting to show the actual differences.\n\n**Tab vs. space handling**: Unified diff output should preserve the exact whitespace from the original files, including tabs and spaces. However, some display contexts may render these differently, so care must be taken to maintain fidelity.\n\n> **Implementation Note**: Generating clean unified diff output requires careful attention to line ending handling. Mixed line endings (LF vs. CRLF) within the same file can produce confusing output if not normalized consistently.\n\n#### Common Pitfalls\n\n⚠️ **Pitfall: Incorrect Line Number Tracking**\nA frequent mistake is failing to properly track line numbers as changes are processed. The line numbers in hunk headers must reflect the position in the original and new files respectively, accounting for how previous insertions and deletions shift subsequent positions. This is especially tricky when multiple hunks are generated for the same file comparison.\n\n**Why it's wrong**: Incorrect line numbers make the diff output unusable for patch applications and confuse users trying to locate changes in their editors.\n\n**How to fix**: Maintain separate line counters for the original and new files, updating them as each edit operation is processed. Validate line numbers by ensuring they align with the actual content being compared.\n\n⚠️ **Pitfall: Context Line Boundary Errors**\nWhen extracting context lines around changes, implementations often fail to handle file boundaries correctly. Requesting 3 lines of context before a change that occurs at line 2 should gracefully handle the fact that only 1 context line is available.\n\n**Why it's wrong**: Attempting to access lines before the beginning or after the end of a file will cause array bounds exceptions or produce incorrect context.\n\n**How to fix**: Always clamp context line ranges to the actual file boundaries using `max(0, start_line - context)` and `min(file_length, end_line + context)` when calculating context regions.\n\n⚠️ **Pitfall: Inefficient String Building**\nGenerating unified diff output often involves concatenating many small strings (line prefixes, content, newlines). Using simple string concatenation in a loop can result in O(n²) performance due to string immutability in many languages.\n\n**Why it's wrong**: Large files or files with many changes will experience severe performance degradation, making the diff operation unusably slow.\n\n**How to fix**: Use a string builder or array-based approach that can efficiently accumulate output. Build each hunk separately and then combine them, rather than building the entire output character by character.\n\n⚠️ **Pitfall: Inconsistent Newline Handling**\nText files may use different newline conventions (LF on Unix, CRLF on Windows, or even mixed). If the diff algorithm doesn't handle these consistently, it may report spurious changes where only line endings differ.\n\n**Why it's wrong**: Users will see confusing diffs where every line appears to have changed, even when only line endings are different.\n\n**How to fix**: Implement a consistent newline normalization strategy, either by converting all content to a standard format before comparison or by making the line-splitting logic aware of different newline conventions.\n\n### Implementation Guidance\n\nThe diff algorithm implementation requires careful coordination between the core Myers algorithm, output formatting, and integration with Git's object model. The following guidance provides both complete infrastructure and skeleton implementations to help you build a robust diff system.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Line Splitting | `str.splitlines()` with keepends=True | Custom line iterator with encoding detection |\n| Output Building | List accumulation with `''.join()` | `io.StringIO` for memory-efficient streaming |\n| File Comparison | Full file reading with `Path.read_text()` | Memory-mapped files with `mmap` module |\n| Binary Detection | Check for null bytes in first 1024 chars | Use `chardet` library for encoding confidence |\n| Performance Profiling | Simple timing with `time.perf_counter()` | `cProfile` with line-by-line analysis |\n\n#### Recommended File Structure\n\n```\nproject-root/\n├── src/\n│   ├── diff/\n│   │   ├── __init__.py           ← Public diff API\n│   │   ├── myers.py              ← Myers algorithm implementation\n│   │   ├── unified.py            ← Unified diff formatting\n│   │   ├── types.py              ← Diff data structures\n│   │   └── utils.py              ← File reading utilities\n│   ├── objects/\n│   │   └── retrieval.py          ← Object content access\n│   └── repository.py             ← Main Repository class\n├── tests/\n│   ├── diff/\n│   │   ├── test_myers.py         ← Myers algorithm tests\n│   │   ├── test_unified.py       ← Output format tests\n│   │   └── fixtures/             ← Test file pairs\n│   └── integration/\n│       └── test_git_compatibility.py  ← Compare with real Git\n└── examples/\n    └── diff_demo.py              ← Usage examples\n```\n\n#### Infrastructure Starter Code\n\n**File: `src/diff/types.py`** - Complete data structures for diff operations:\n\n```python\n\"\"\"Data structures for diff algorithm implementation.\"\"\"\n\nfrom dataclasses import dataclass\nfrom enum import Enum\nfrom typing import List, Tuple, Optional, Union\n\n\nclass EditType(Enum):\n    \"\"\"Types of edit operations in a diff.\"\"\"\n    INSERT = \"insert\"\n    DELETE = \"delete\"\n    MATCH = \"match\"\n\n\n@dataclass(frozen=True)\nclass Edit:\n    \"\"\"A single edit operation.\"\"\"\n    type: EditType\n    old_line: Optional[int]  # Line number in original file (None for inserts)\n    new_line: Optional[int]  # Line number in new file (None for deletes)\n    content: str             # The actual line content\n\n\n@dataclass(frozen=True)\nclass DiffHunk:\n    \"\"\"A contiguous block of changes with context.\"\"\"\n    old_start: int           # Starting line in original file\n    old_count: int           # Number of lines from original file\n    new_start: int           # Starting line in new file  \n    new_count: int           # Number of lines from new file\n    lines: List[str]         # Formatted diff lines (with +/- prefixes)\n\n\n@dataclass(frozen=True)\nclass FileDiff:\n    \"\"\"Complete diff result for a single file comparison.\"\"\"\n    old_path: Optional[str]   # Original file path (None for new file)\n    new_path: Optional[str]   # New file path (None for deleted file)\n    is_binary: bool          # True if files contain binary data\n    hunks: List[DiffHunk]    # List of change hunks\n\n\nclass DiffStats:\n    \"\"\"Statistics about a diff operation.\"\"\"\n    \n    def __init__(self):\n        self.files_changed = 0\n        self.insertions = 0\n        self.deletions = 0\n        self.binary_files = 0\n    \n    def add_file_diff(self, file_diff: FileDiff) -> None:\n        \"\"\"Update statistics with results from a file diff.\"\"\"\n        self.files_changed += 1\n        \n        if file_diff.is_binary:\n            self.binary_files += 1\n            return\n        \n        for hunk in file_diff.hunks:\n            for line in hunk.lines:\n                if line.startswith('+') and not line.startswith('+++'):\n                    self.insertions += 1\n                elif line.startswith('-') and not line.startswith('---'):\n                    self.deletions += 1\n    \n    def __str__(self) -> str:\n        \"\"\"Generate summary string like Git's diff --stat output.\"\"\"\n        parts = [f\"{self.files_changed} file(s) changed\"]\n        if self.insertions:\n            parts.append(f\"{self.insertions} insertion(s)\")\n        if self.deletions:\n            parts.append(f\"{self.deletions} deletion(s)\")\n        return \", \".join(parts)\n```\n\n**File: `src/diff/utils.py`** - Complete utilities for file handling:\n\n```python\n\"\"\"Utilities for file reading and binary detection.\"\"\"\n\nimport os\nfrom pathlib import Path\nfrom typing import List, Optional, Tuple\n\n\ndef is_binary_content(content: bytes) -> bool:\n    \"\"\"Detect if content appears to be binary data.\"\"\"\n    if not content:\n        return False\n    \n    # Check for null bytes (strong binary indicator)\n    if b'\\x00' in content[:1024]:  # Check first 1KB\n        return True\n    \n    # Check for high ratio of non-printable characters\n    printable_chars = sum(1 for b in content[:1024] \n                         if 32 <= b <= 126 or b in (9, 10, 13))\n    if len(content[:1024]) > 0:\n        printable_ratio = printable_chars / len(content[:1024])\n        return printable_ratio < 0.75\n    \n    return False\n\n\ndef read_file_lines(file_path: Path) -> Tuple[List[str], bool]:\n    \"\"\"Read file and return lines with binary detection.\n    \n    Returns:\n        Tuple of (lines, is_binary) where lines are empty if binary.\n    \"\"\"\n    try:\n        # Read as binary first for detection\n        with open(file_path, 'rb') as f:\n            content = f.read()\n        \n        if is_binary_content(content):\n            return [], True\n        \n        # Convert to text and split into lines\n        try:\n            text_content = content.decode('utf-8')\n        except UnicodeDecodeError:\n            try:\n                text_content = content.decode('latin1')\n            except UnicodeDecodeError:\n                return [], True\n        \n        # Split lines but keep line endings for accurate diff\n        lines = text_content.splitlines(keepends=True)\n        return lines, False\n        \n    except (IOError, OSError):\n        return [], True\n\n\ndef safe_file_size(file_path: Path) -> int:\n    \"\"\"Get file size safely, returning 0 if file doesn't exist.\"\"\"\n    try:\n        return file_path.stat().st_size\n    except (OSError, IOError):\n        return 0\n\n\ndef normalize_path(path: Optional[str]) -> Optional[str]:\n    \"\"\"Normalize file path for display in diff headers.\"\"\"\n    if path is None:\n        return None\n    \n    # Convert to forward slashes for consistency\n    normalized = str(Path(path)).replace(os.sep, '/')\n    \n    # Add a/ or b/ prefix if not already present (Git convention)\n    if not normalized.startswith(('a/', 'b/')):\n        return f\"a/{normalized}\"\n    \n    return normalized\n```\n\n#### Core Logic Skeleton Code\n\n**File: `src/diff/myers.py`** - Myers algorithm implementation skeleton:\n\n```python\n\"\"\"Myers diff algorithm implementation.\"\"\"\n\nfrom typing import List, Dict, Tuple, Optional\nfrom .types import Edit, EditType\n\n\nclass MyersDiff:\n    \"\"\"Implementation of Myers' O(ND) diff algorithm.\"\"\"\n    \n    def __init__(self, old_lines: List[str], new_lines: List[str]):\n        self.old_lines = old_lines\n        self.new_lines = new_lines\n        self.M = len(old_lines)\n        self.N = len(new_lines)\n    \n    def compute_diff(self) -> List[Edit]:\n        \"\"\"Compute the shortest edit script using Myers algorithm.\n        \n        Returns:\n            List of Edit operations to transform old_lines into new_lines.\n        \"\"\"\n        # TODO 1: Handle edge cases (empty files)\n        if self.M == 0:\n            # TODO: Return all insertions\n            pass\n        if self.N == 0:\n            # TODO: Return all deletions\n            pass\n        \n        # TODO 2: Find the shortest edit script length\n        edit_distance = self._find_shortest_edit_distance()\n        \n        # TODO 3: Backtrack to reconstruct the actual edit sequence\n        return self._backtrack_edit_script(edit_distance)\n    \n    def _find_shortest_edit_distance(self) -> int:\n        \"\"\"Find the length of the shortest edit script.\n        \n        Returns:\n            The minimum number of insertions + deletions needed.\n        \"\"\"\n        # Myers algorithm uses a V array to track furthest reaching paths\n        # V[d] = furthest x coordinate reached on diagonal d\n        # Diagonal d represents positions where x - y = d\n        \n        max_d = self.M + self.N\n        v = {}  # V array: diagonal -> furthest x position\n        \n        # TODO 4: Initialize V[1] = 0 (starting position)\n        \n        # TODO 5: For each possible edit distance from 0 to max_d:\n        for d in range(max_d + 1):\n            # TODO 6: For each diagonal that could be reached with d edits:\n            for k in range(-d, d + 1, 2):\n                # TODO 7: Determine starting x position on diagonal k\n                # Can reach diagonal k from k-1 (move right/delete) or k+1 (move down/insert)\n                if k == -d or (k != d and v.get(k-1, 0) < v.get(k+1, 0)):\n                    # TODO: Move down from diagonal k+1 (insert from new)\n                    x = v.get(k+1, 0)\n                else:\n                    # TODO: Move right from diagonal k-1 (delete from old)  \n                    x = v.get(k-1, 0) + 1\n                \n                # TODO 8: Calculate y position from x and diagonal\n                y = x - k\n                \n                # TODO 9: Extend diagonally while elements match (greedy)\n                while (x < self.M and y < self.N and \n                       self.old_lines[x] == self.new_lines[y]):\n                    # TODO: Advance both x and y\n                    pass\n                \n                # TODO 10: Store furthest position reached on this diagonal\n                v[k] = x\n                \n                # TODO 11: Check if we've reached the target position\n                if x >= self.M and y >= self.N:\n                    return d\n        \n        # Should never reach here for valid inputs\n        return max_d\n    \n    def _backtrack_edit_script(self, edit_distance: int) -> List[Edit]:\n        \"\"\"Reconstruct the edit script by backtracking through the search.\n        \n        Args:\n            edit_distance: The optimal edit distance found\n            \n        Returns:\n            List of Edit operations in forward order.\n        \"\"\"\n        # TODO 12: Re-run the forward search but save V arrays for each step\n        v_history = self._compute_v_history(edit_distance)\n        \n        # TODO 13: Start from the end position and work backwards\n        x, y = self.M, self.N\n        edits = []\n        \n        # TODO 14: For each edit distance from max down to 0:\n        for d in range(edit_distance, 0, -1):\n            v = v_history[d]\n            v_prev = v_history[d-1]\n            \n            # TODO 15: Find which diagonal we're on\n            k = x - y\n            \n            # TODO 16: Determine how we reached this position\n            # Check if we came from diagonal k-1 (right move) or k+1 (down move)\n            if k == -d or (k != d and v_prev.get(k-1, 0) < v_prev.get(k+1, 0)):\n                # TODO: We moved down (insertion)\n                prev_k = k + 1\n            else:\n                # TODO: We moved right (deletion)  \n                prev_k = k - 1\n            \n            # TODO 17: Calculate previous position\n            prev_x = v_prev[prev_k]\n            prev_y = prev_x - prev_k\n            \n            # TODO 18: Add diagonal moves (matches) first\n            while x > prev_x and y > prev_y:\n                # TODO: Add MATCH edit for diagonal moves\n                x -= 1\n                y -= 1\n                # edits.insert(0, Edit(EditType.MATCH, x, y, self.old_lines[x]))\n            \n            # TODO 19: Add the actual edit operation\n            if x > prev_x:\n                # TODO: Deletion (moved right)\n                x -= 1\n                # edits.insert(0, Edit(EditType.DELETE, x, None, self.old_lines[x]))\n            elif y > prev_y:\n                # TODO: Insertion (moved down)\n                y -= 1\n                # edits.insert(0, Edit(EditType.INSERT, None, y, self.new_lines[y]))\n        \n        return edits\n    \n    def _compute_v_history(self, max_d: int) -> Dict[int, Dict[int, int]]:\n        \"\"\"Recompute the V arrays and store history for backtracking.\"\"\"\n        # TODO 20: This is similar to _find_shortest_edit_distance but saves all V arrays\n        # Return dict where v_history[d] = V array after processing edit distance d\n        pass\n```\n\n**File: `src/diff/unified.py`** - Unified diff formatting skeleton:\n\n```python\n\"\"\"Unified diff output formatting.\"\"\"\n\nfrom typing import List, Optional\nfrom .types import Edit, EditType, FileDiff, DiffHunk\n\n\nclass UnifiedDiffFormatter:\n    \"\"\"Formats diff results as unified diff output.\"\"\"\n    \n    def __init__(self, context_lines: int = 3):\n        self.context_lines = context_lines\n    \n    def format_file_diff(self, file_diff: FileDiff) -> str:\n        \"\"\"Format a complete file diff in unified format.\n        \n        Args:\n            file_diff: The diff result to format\n            \n        Returns:\n            Unified diff string ready for display.\n        \"\"\"\n        if file_diff.is_binary:\n            return self._format_binary_diff(file_diff)\n        \n        lines = []\n        \n        # TODO 1: Add file headers (--- and +++ lines)\n        if file_diff.old_path:\n            # TODO: Add \"--- a/path\" line\n            pass\n        else:\n            # TODO: Add \"--- /dev/null\" for new files\n            pass\n            \n        if file_diff.new_path:\n            # TODO: Add \"+++ b/path\" line  \n            pass\n        else:\n            # TODO: Add \"+++ /dev/null\" for deleted files\n            pass\n        \n        # TODO 2: Add each hunk with its header\n        for hunk in file_diff.hunks:\n            # TODO: Add hunk header like \"@@ -15,7 +15,8 @@\"\n            hunk_header = f\"@@ -{hunk.old_start},{hunk.old_count} +{hunk.new_start},{hunk.new_count} @@\"\n            lines.append(hunk_header)\n            \n            # TODO: Add all hunk lines (already formatted with +/- prefixes)\n            lines.extend(hunk.lines)\n        \n        return '\\n'.join(lines) + '\\n' if lines else \"\"\n    \n    def edits_to_hunks(self, edits: List[Edit], old_lines: List[str], \n                      new_lines: List[str]) -> List[DiffHunk]:\n        \"\"\"Convert edit sequence to unified diff hunks with context.\n        \n        Args:\n            edits: Sequence of edit operations\n            old_lines: Original file lines\n            new_lines: New file lines\n            \n        Returns:\n            List of DiffHunk objects with context lines added.\n        \"\"\"\n        if not edits:\n            return []\n        \n        # TODO 3: Group edits into change regions\n        change_regions = self._group_edits_into_regions(edits)\n        \n        # TODO 4: Add context around each region  \n        hunks = []\n        for region in change_regions:\n            hunk = self._create_hunk_with_context(region, old_lines, new_lines)\n            hunks.append(hunk)\n        \n        # TODO 5: Merge overlapping hunks\n        return self._merge_adjacent_hunks(hunks, old_lines, new_lines)\n    \n    def _group_edits_into_regions(self, edits: List[Edit]) -> List[List[Edit]]:\n        \"\"\"Group consecutive edits into change regions.\"\"\"\n        # TODO 6: Separate MATCH edits from INSERT/DELETE edits\n        # TODO 7: Group consecutive non-MATCH edits together\n        # TODO 8: Return list of edit groups representing distinct change areas\n        pass\n    \n    def _create_hunk_with_context(self, region_edits: List[Edit], \n                                old_lines: List[str], new_lines: List[str]) -> DiffHunk:\n        \"\"\"Create a single hunk with context lines around the changes.\"\"\"\n        # TODO 9: Find the line range covered by this region\n        min_old_line = min((e.old_line for e in region_edits if e.old_line is not None), default=0)\n        max_old_line = max((e.old_line for e in region_edits if e.old_line is not None), default=0)\n        \n        # TODO 10: Calculate context boundaries\n        context_start_old = max(0, min_old_line - self.context_lines)\n        context_end_old = min(len(old_lines), max_old_line + self.context_lines + 1)\n        \n        # TODO 11: Build the hunk lines with proper prefixes\n        hunk_lines = []\n        \n        # TODO 12: Add leading context\n        for i in range(context_start_old, min_old_line):\n            # TODO: Add context line with space prefix\n            pass\n        \n        # TODO 13: Add the actual changes\n        for edit in region_edits:\n            if edit.type == EditType.DELETE:\n                # TODO: Add line with - prefix\n                pass\n            elif edit.type == EditType.INSERT:\n                # TODO: Add line with + prefix\n                pass\n            # MATCH edits within a change region become context\n        \n        # TODO 14: Add trailing context\n        for i in range(max_old_line + 1, context_end_old):\n            # TODO: Add context line with space prefix\n            pass\n        \n        # TODO 15: Calculate hunk header numbers\n        old_start = context_start_old + 1  # 1-based line numbers\n        old_count = context_end_old - context_start_old\n        # TODO: Calculate new_start and new_count similarly\n        \n        return DiffHunk(\n            old_start=old_start,\n            old_count=old_count, \n            new_start=0,  # TODO: Calculate this\n            new_count=0,  # TODO: Calculate this\n            lines=hunk_lines\n        )\n    \n    def _merge_adjacent_hunks(self, hunks: List[DiffHunk], \n                            old_lines: List[str], new_lines: List[str]) -> List[DiffHunk]:\n        \"\"\"Merge hunks whose context regions overlap.\"\"\"\n        # TODO 16: Check each pair of consecutive hunks\n        # TODO 17: If context regions overlap, merge them into single hunk\n        # TODO 18: Recalculate line counts after merging\n        pass\n    \n    def _format_binary_diff(self, file_diff: FileDiff) -> str:\n        \"\"\"Format a binary file diff message.\"\"\"\n        old_name = file_diff.old_path or \"/dev/null\"\n        new_name = file_diff.new_path or \"/dev/null\" \n        \n        return (f\"--- {old_name}\\n\"\n                f\"+++ {new_name}\\n\"\n                f\"Binary files {old_name} and {new_name} differ\\n\")\n```\n\n#### Milestone Checkpoints\n\nAfter implementing the diff algorithm, verify your implementation with these specific tests:\n\n**Basic Functionality Test:**\n```bash\n# Create test files\necho -e \"line1\\nline2\\nline3\" > old.txt\necho -e \"line1\\nmodified\\nline3\\nnew line\" > new.txt\n\n# Your diff should output:\n# --- old.txt\n# +++ new.txt  \n# @@ -1,3 +1,4 @@\n#  line1\n# -line2\n# +modified\n#  line3\n# +new line\n```\n\n**Empty File Test:**\n```bash\ntouch empty.txt\necho \"content\" > nonempty.txt\n\n# Diff from empty should show all additions\n# Diff to empty should show all deletions\n```\n\n**Binary File Test:**\n```bash\n# Create a binary file (contains null bytes)\nprintf \"binary\\x00data\" > binary.dat\necho \"text content\" > text.txt\n\n# Should output: \"Binary files binary.dat and text.txt differ\"\n```\n\n**Performance Test:**\n```bash\n# Generate large text files (1000+ lines)\n# Diff should complete within reasonable time (< 1 second for 1000 lines)\n# Memory usage should remain reasonable (< 100MB for typical files)\n```\n\n**Git Compatibility Test:**\n```bash\n# Compare your diff output with Git's output for same files\ngit diff --no-index old.txt new.txt > git_output.diff\nyour_git diff old.txt new.txt > your_output.diff\n\n# Outputs should be functionally equivalent (may differ in header details)\n```\n\n#### Language-Specific Hints\n\n**Python Performance Tips:**\n- Use `str.splitlines(keepends=True)` to preserve line ending information\n- Build diff output using lists and `''.join()` rather than string concatenation\n- Consider `collections.defaultdict(int)` for the V array in Myers algorithm\n- Use `enumerate()` when you need both index and value during iteration\n\n**Memory Management:**\n- For very large files, consider implementing a streaming version that processes chunks\n- The Myers algorithm V array can grow large - consider the linear space refinement for huge diffs\n- Use generators where possible to avoid loading entire diff output into memory\n\n**Error Handling:**\n- Wrap file I/O operations in try/except blocks for graceful error handling\n- Detect and handle different text encodings (UTF-8, Latin1, etc.)\n- Provide meaningful error messages when files cannot be read or compared\n\n**Testing Strategy:**\n- Create a comprehensive test suite with edge cases (empty files, binary files, identical files)\n- Include performance tests with large files to catch algorithmic issues\n- Test against Git's output for compatibility verification\n- Use property-based testing to generate random file pairs for robustness testing\n\n\n## Three-Way Merge Implementation\n\n> **Milestone(s):** This section is the culmination of Milestone 8 (Three-way Merge), building upon all previous milestones. The merge algorithm requires the object storage (Milestone 2-4), references (Milestone 5), index management (Milestone 6), and diff algorithms (Milestone 7) to function correctly.\n\n### Mental Model: Collaborative Document Editing\n\nThink of three-way merging like collaborative document editing in the pre-digital era. Imagine you and a colleague both receive copies of the same research paper draft on Monday morning. You each spend the week making independent edits - you focus on improving the introduction and methodology, while your colleague refines the conclusion and adds new references. On Friday, you need to combine both sets of changes into a single, improved document.\n\nThe naive approach would be to simply compare your final version with your colleague's final version. However, this creates confusion - if the same paragraph appears differently in both versions, you have no way to know whether both of you changed it (creating a conflict) or only one person modified it while the other left it unchanged. The solution is to keep the original Monday morning version as a reference point.\n\nWith the original document as your **merge base**, you can now perform a three-way comparison. For each paragraph, you examine three versions: the original (base), your version (branch A), and your colleague's version (branch B). If only you changed a paragraph, your changes win. If only your colleague changed it, their changes win. If neither of you touched it, it stays the same. But if both of you modified the same paragraph, you have a genuine conflict that requires manual resolution - perhaps you need to sit down together and decide how to combine both improvements.\n\nThis is exactly how Git's three-way merge works. The **merge base** is the common ancestor commit - the last point where both branches shared the same history. By comparing each file's content across all three versions (base, branch A, branch B), Git can automatically resolve most changes and only flag genuine conflicts where both branches modified the same lines.\n\nThe power of this approach is that it preserves the intent of both sets of changes. If you deleted a paragraph that your colleague left unchanged, the merge knows you intentionally removed it and won't restore it. If you both added different content at the same location, the merge knows this requires human judgment to resolve properly.\n\n### Finding the Merge Base\n\nThe merge base calculation is a graph traversal problem that finds the **lowest common ancestor** (LCA) between two commits in Git's directed acyclic graph. This ancestor represents the most recent point in history where both branches shared the same state, making it the ideal reference point for three-way comparison.\n\n![Merge Base Algorithm](./diagrams/merge-base-algorithm.svg)\n\nThe algorithm uses a breadth-first search approach that explores the commit history backwards from both branch tips simultaneously. The key insight is that Git's commit graph forms a DAG where each commit points to its parent(s), creating paths back through history. The merge base is the commit that appears in both traversal paths with the shortest distance from either starting point.\n\n![Three-Way Merge Process](./diagrams/three-way-merge.svg)\n\n**Merge Base Discovery Algorithm:**\n\n1. **Initialize Search State**: Create two sets to track visited commits - one for each branch being merged. Initialize two queues with the starting commit hashes from both branches. This dual-queue approach ensures we explore both histories simultaneously and can detect when they intersect.\n\n2. **Parallel Breadth-First Traversal**: While both queues contain commits, dequeue one commit from each queue in alternating fashion. This alternating approach ensures we explore both histories at roughly the same depth, increasing the likelihood of finding the nearest common ancestor quickly rather than exploring one branch much deeper than the other.\n\n3. **Intersection Detection**: For each dequeued commit, check if it already exists in the opposite branch's visited set. If a commit from branch A's queue appears in branch B's visited set, we've found a common ancestor. Record this commit as a potential merge base candidate.\n\n4. **Parent Expansion**: Load the commit object for the current commit and extract its parent commit hashes. Add each parent to the current branch's queue for future exploration. Mark the current commit as visited in the current branch's set to avoid revisiting it later.\n\n5. **Multiple Ancestor Resolution**: Continue the search even after finding the first common ancestor, as there might be multiple common ancestors at the same depth level. In Git's history, merge commits can create situations where two branches have multiple equally-valid common ancestors.\n\n6. **Best Candidate Selection**: Among all discovered common ancestors, select the one with the shortest path distance from either branch tip. This represents the most recent common state and provides the most meaningful base for comparison.\n\nThe algorithm handles several edge cases that commonly occur in Git repositories:\n\n| Edge Case | Detection Method | Resolution Strategy |\n|-----------|-----------------|-------------------|\n| No Common Ancestor | Both queues become empty without intersection | Return null - branches have completely separate histories |\n| Self-Merge Attempt | Source and target commits are identical | Return the commit itself as the merge base |\n| Fast-Forward Scenario | Target commit appears in source's ancestry | Return target commit - no merge needed, just update reference |\n| Multiple Merge Bases | Several ancestors found at same depth | Select the one with shortest path to either tip |\n| Octopus Merge History | Commits with more than two parents | Treat each parent equally in the traversal |\n\n**Performance Considerations:**\n\nThe merge base calculation can become expensive in repositories with deep history or complex branching patterns. The algorithm's time complexity is O(N) where N is the number of commits that must be examined before finding the common ancestor. In the worst case, this could require traversing most of the repository's history.\n\nTo optimize performance, the implementation can employ several strategies:\n\n- **Early Termination**: Stop the search immediately upon finding the first common ancestor if the repository structure guarantees a unique merge base\n- **Commit Metadata Caching**: Cache commit parent relationships to avoid repeated object loading during traversal\n- **Generation Numbers**: Use Git's commit-graph generation numbers (if available) to guide the search toward likely intersection points\n- **Path Limiting**: In repositories with known branching patterns, limit the search depth to reasonable bounds\n\n> **Critical Insight**: The merge base calculation is not just an optimization - it's fundamental to Git's ability to understand the intent behind changes. Without the correct merge base, Git cannot distinguish between deliberate deletions and independent additions, leading to incorrect automatic merges or false conflict detection.\n\n### Three-Way Merge Algorithm\n\nThe three-way merge algorithm performs a line-by-line comparison between three versions of each file: the merge base (common ancestor), the current branch (ours), and the branch being merged (theirs). This comparison determines which changes can be automatically applied and which require manual conflict resolution.\n\nThe algorithm operates on the principle of **change attribution** - understanding which branch introduced each modification relative to the common base. A change is considered safe to apply automatically if only one branch modified a particular region of the file. Conflicts arise when both branches made different changes to the same lines.\n\n**File-Level Merge Process:**\n\nThe merge algorithm begins by identifying all files that exist in any of the three versions (base, ours, theirs). For each file, it determines the merge scenario based on which versions contain the file:\n\n| Base Exists | Ours Exists | Theirs Exists | Scenario | Action |\n|-------------|-------------|---------------|----------|---------|\n| Yes | Yes | Yes | Modified in branches | Perform three-way content merge |\n| Yes | Yes | No | Deleted in theirs | Check if ours modified; conflict if yes |\n| Yes | No | Yes | Deleted in ours | Check if theirs modified; conflict if yes |\n| Yes | No | No | Deleted in both | Remove file (agreement) |\n| No | Yes | Yes | Added in both | Compare content; conflict if different |\n| No | Yes | No | Added in ours | Keep ours version |\n| No | No | Yes | Added in theirs | Keep theirs version |\n| No | No | No | Impossible | Error condition |\n\n**Line-Level Merge Logic:**\n\nFor files requiring content merging, the algorithm processes each line using three-way comparison logic. The merge result depends on which branches modified each line relative to the base:\n\n1. **Unchanged in All Versions**: If a line appears identically in base, ours, and theirs, include it unchanged in the merge result. This represents content that neither branch chose to modify.\n\n2. **Modified in Ours Only**: If a line differs between base and ours but matches between base and theirs, apply the change from ours. This represents an intentional modification made only on the current branch.\n\n3. **Modified in Theirs Only**: If a line differs between base and theirs but matches between base and ours, apply the change from theirs. This represents an intentional modification made only on the incoming branch.\n\n4. **Modified Identically**: If both branches made the same change to a line (ours and theirs match each other but differ from base), include the shared change. This represents convergent evolution or cherry-picked changes.\n\n5. **Modified Differently**: If base, ours, and theirs all differ from each other, mark this as a conflict requiring manual resolution. The automated merge cannot determine which change takes precedence.\n\n**Region-Based Conflict Detection:**\n\nThe merge algorithm groups consecutive conflicting lines into conflict regions to provide meaningful context for resolution. Rather than marking individual lines as conflicts, it identifies blocks of related changes that should be resolved together:\n\n1. **Conflict Region Identification**: Scan the line-by-line comparison results to find sequences of consecutive conflicts or near-conflicts (within a configurable context window).\n\n2. **Context Expansion**: Extend each conflict region to include surrounding unchanged lines for context. This helps developers understand the broader scope of conflicting changes.\n\n3. **Region Consolidation**: Merge adjacent conflict regions if they're separated by only a few unchanged lines. This prevents fragmented conflicts that would be difficult to resolve coherently.\n\n4. **Boundary Refinement**: Adjust conflict region boundaries to align with logical boundaries (function definitions, paragraph breaks) when possible, making the conflicts more intuitive to resolve.\n\n**Merge Result Generation:**\n\nThe algorithm produces a merged file containing three types of content:\n\n- **Clean Lines**: Lines where the three-way comparison produced an unambiguous result, included directly in the output\n- **Conflict Markers**: Special marker lines that delimit regions requiring manual resolution\n- **Conflict Content**: The competing versions from both branches, clearly labeled for comparison\n\nThe merge algorithm maintains metadata about the merge process for reporting and debugging:\n\n| Metadata Field | Purpose | Example Value |\n|----------------|---------|---------------|\n| Files Modified | Count of files requiring changes | 12 |\n| Auto-Merged Files | Files merged without conflicts | 8 |\n| Conflicted Files | Files requiring manual resolution | 4 |\n| Lines Added | Total lines added from both branches | 156 |\n| Lines Removed | Total lines removed from both branches | 89 |\n| Conflict Regions | Number of distinct conflict areas | 7 |\n\n**Error Handling and Recovery:**\n\nThe merge algorithm must handle various error conditions gracefully:\n\n- **Missing Objects**: If any required blob, tree, or commit object is missing from the object store, abort the merge with a clear error message indicating which object is unavailable.\n- **Binary File Conflicts**: When both branches modify a binary file differently, mark the entire file as conflicted rather than attempting line-based merging.\n- **Permission Conflicts**: If file modes differ between branches (executable vs non-executable), include mode information in conflict markers.\n- **Symlink Conflicts**: Handle symbolic links specially, as their target paths may conflict even when the content appears similar.\n\n> **Design Principle**: The three-way merge algorithm prioritizes correctness over convenience. When in doubt, it prefers to flag potential conflicts for manual review rather than making incorrect automatic decisions that could lose work or introduce bugs.\n\n### Conflict Detection and Marking\n\nConflict detection is the process of identifying regions where both branches made incompatible changes to the same content, requiring human judgment to resolve. The conflict marking system provides a structured format that allows developers to understand the competing changes and make informed decisions about the final content.\n\nGit uses a **conflict marker format** that clearly delineates the boundaries of each conflict and identifies which branch contributed each version of the conflicted content. This format has become an industry standard, recognized by merge tools, IDEs, and diff viewers.\n\n**Conflict Marker Structure:**\n\nWhen a conflict is detected, the merge algorithm inserts special marker lines into the file content to create a **conflict block**. Each conflict block follows a consistent structure:\n\n```\n<<<<<<< HEAD (or branch name)\n[Content from the current branch]\n=======\n[Content from the branch being merged]\n>>>>>>> branch-name (or commit hash)\n```\n\nThe conflict markers serve specific purposes:\n\n- **Opening Marker** (`<<<<<<<`): Indicates the start of a conflict region and identifies the current branch (usually \"HEAD\" or the branch name)\n- **Separator** (`=======`): Divides the two competing versions of the conflicted content\n- **Closing Marker** (`>>>>>>>`): Indicates the end of the conflict region and identifies the incoming branch or commit\n- **Content Sections**: The actual competing content from each branch, preserved exactly as it appears in each version\n\n**Advanced Conflict Scenarios:**\n\nBeyond simple line-level conflicts, the merge algorithm must handle several complex scenarios:\n\n| Conflict Type | Description | Example Scenario | Resolution Strategy |\n|--------------|-------------|------------------|-------------------|\n| Add/Add Conflict | Both branches added different content at same location | New function added with different implementations | Present both versions with clear branch labels |\n| Delete/Modify Conflict | One branch deleted content, other modified it | Function removed vs function refactored | Show deletion intent vs modification intent |\n| Mode Conflict | File permissions differ between branches | File made executable on one branch only | Include mode information in conflict markers |\n| Rename Conflict | Same file renamed differently on each branch | README.txt → README.md vs README.txt → readme.txt | Create conflict for filename choice |\n| Binary Conflict | Binary files modified differently | Image files updated independently | Mark entire file as binary conflict |\n\n**Context-Aware Conflict Boundaries:**\n\nThe merge algorithm attempts to create meaningful conflict boundaries that align with logical content structure. Rather than starting and ending conflicts at arbitrary line boundaries, it analyzes the content to find natural breakpoints:\n\n1. **Function Boundaries**: For source code, attempt to align conflict regions with function or method boundaries, including the complete function signature and closing brace.\n\n2. **Paragraph Boundaries**: For text content, extend conflicts to complete paragraphs or sentences when possible, avoiding mid-sentence breaks that would be confusing to resolve.\n\n3. **Indentation Consistency**: Maintain consistent indentation levels within conflict regions, ensuring that the conflicted code remains syntactically valid for each branch's version.\n\n4. **Comment Preservation**: Include related comments and documentation within conflict regions so that developers have full context for understanding the intent behind each change.\n\n**Conflict Metadata and Reporting:**\n\nThe merge system maintains detailed metadata about each conflict to support resolution tools and provide useful feedback to developers:\n\n| Conflict Property | Description | Usage |\n|------------------|-------------|-------|\n| File Path | Relative path of the conflicted file | Reporting and tool integration |\n| Line Range | Start and end line numbers of the conflict | IDE navigation and highlighting |\n| Conflict Type | Category of conflict (content, mode, rename) | Specialized resolution workflows |\n| Base Content | Content from the merge base version | Three-way merge tools |\n| Branch Labels | Names of the conflicting branches | User interface display |\n| Complexity Score | Estimated difficulty of resolution | Prioritizing resolution effort |\n\n**Conflict Resolution Workflow:**\n\nThe conflict marking system supports both manual and tool-assisted resolution workflows:\n\n1. **Manual Resolution**: Developers can edit the conflicted file directly, removing the conflict markers and combining the content as appropriate. The merge system validates that all markers are removed before allowing the merge to complete.\n\n2. **Merge Tool Integration**: External merge tools can parse the conflict markers to present a three-way view (base, ours, theirs) and generate the resolved content automatically when the user makes selections.\n\n3. **Partial Resolution**: Large conflicts can be resolved incrementally by addressing individual conflict blocks while leaving others for later resolution.\n\n4. **Resolution Validation**: The system checks that resolved files contain no remaining conflict markers and that the content compiles or validates according to project standards.\n\n**Binary File Conflict Handling:**\n\nBinary files require special conflict handling since line-based merging is not applicable:\n\n1. **Binary Detection**: Use heuristics to identify binary content (null bytes, high ratio of non-printable characters, or file extension patterns).\n\n2. **Whole-File Conflicts**: Mark the entire file as conflicted rather than attempting to merge portions of binary content.\n\n3. **Version Selection**: Provide mechanisms for users to select which branch's version of the binary file should be used in the final merge.\n\n4. **External Tool Integration**: Support launching specialized merge tools for specific binary file types (image editors, document processors).\n\n**Performance Optimization for Large Conflicts:**\n\nIn files with extensive conflicts, the merge algorithm employs optimization strategies to maintain reasonable performance:\n\n- **Streaming Processing**: Process large files in chunks rather than loading entire content into memory\n- **Conflict Batching**: Group small adjacent conflicts to reduce the total number of conflict regions\n- **Early Termination**: Stop processing files that exceed conflict thresholds and mark them for manual resolution\n- **Memory Management**: Use efficient data structures to minimize memory usage during conflict detection\n\n> **Critical Success Factor**: Effective conflict marking must balance completeness with usability. Too little context makes conflicts difficult to resolve, while too much context overwhelms developers with irrelevant information. The optimal approach provides just enough surrounding content to understand the intent of each change while keeping conflict regions focused on the actual disagreement.\n\n**Common Pitfalls in Conflict Detection:**\n\n⚠️ **Pitfall: Inconsistent Line Ending Handling**\nDifferent operating systems use different line ending conventions (LF vs CRLF). If the merge algorithm doesn't normalize line endings before comparison, it may generate false conflicts where the only difference is the line terminator. Always normalize line endings to a consistent format (typically LF) before performing three-way comparison.\n\n⚠️ **Pitfall: Whitespace-Only Conflicts**\nChanges that only affect whitespace (spaces vs tabs, trailing spaces) can create conflicts that are difficult to visualize and resolve. Implement configurable whitespace handling that can either ignore whitespace differences or normalize them according to project standards.\n\n⚠️ **Pitfall: Incomplete Conflict Markers**\nIf the merge process is interrupted (by system crash, user cancellation, or error), partially written conflict markers can corrupt the file. Always write conflict markers atomically - either the complete conflict block exists or none of it does. Use temporary files and atomic moves to ensure consistency.\n\n⚠️ **Pitfall: Nested Conflict Markers**\nIf one of the branches being merged already contains conflict markers from a previous merge, the new merge can create nested or malformed conflict structures. Detect existing conflict markers before merging and either resolve them first or use alternative marker styles to avoid confusion.\n\n### Implementation Guidance\n\nThe three-way merge implementation requires sophisticated algorithms for graph traversal, content comparison, and conflict resolution. This section provides concrete implementation patterns and complete working code for the supporting infrastructure.\n\n**A. Technology Recommendations:**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Graph Traversal | Collections.deque with manual BFS | NetworkX for complex graph algorithms |\n| Line Processing | Built-in file.readlines() | Memory-mapped files for large content |\n| Diff Algorithm | Simple longest common subsequence | Myers algorithm from previous section |\n| Conflict Output | String concatenation with markers | Template-based conflict formatting |\n| Binary Detection | Check for null bytes in first 1024 bytes | Use python-magic library for MIME type detection |\n\n**B. File Structure:**\n```\nsrc/git/\n  merge/\n    __init__.py                 ← Public merge API\n    merge_base.py              ← Merge base calculation algorithms\n    three_way_merge.py         ← Core three-way merge logic\n    conflict_detection.py     ← Conflict marking and resolution\n    merge_result.py           ← Data structures for merge results\n    test/\n      test_merge_base.py       ← Merge base algorithm tests\n      test_three_way_merge.py  ← Three-way merge tests\n      test_conflict_resolution.py ← Conflict handling tests\n  objects/\n    object_store.py           ← Required for commit traversal\n  refs/\n    reference_manager.py      ← Required for branch resolution\n```\n\n**C. Infrastructure Code - Merge Base Calculator:**\n\n```python\nfrom collections import deque\nfrom typing import Optional, Set, Dict, List, Tuple\nfrom pathlib import Path\n\nclass MergeBaseCalculator:\n    \"\"\"Finds the lowest common ancestor between two commits using BFS traversal.\"\"\"\n    \n    def __init__(self, object_store):\n        self.object_store = object_store\n        \n    def find_merge_base(self, commit_a: str, commit_b: str) -> Optional[str]:\n        \"\"\"\n        Find the merge base (lowest common ancestor) between two commits.\n        \n        Args:\n            commit_a: SHA-1 hash of first commit\n            commit_b: SHA-1 hash of second commit\n            \n        Returns:\n            SHA-1 hash of merge base commit, or None if no common ancestor\n        \"\"\"\n        # Handle trivial cases\n        if commit_a == commit_b:\n            return commit_a\n            \n        # Initialize dual BFS queues and visited sets\n        queue_a = deque([commit_a])\n        queue_b = deque([commit_b])\n        visited_a = {commit_a}\n        visited_b = {commit_b}\n        \n        # Track distances for selecting best candidate\n        distances = {commit_a: 0, commit_b: 0}\n        candidates = []\n        \n        # Alternating BFS traversal\n        while queue_a or queue_b:\n            # Process one commit from each queue per iteration\n            if queue_a:\n                current = queue_a.popleft()\n                if current in visited_b:\n                    candidates.append((current, distances[current]))\n                else:\n                    self._expand_parents(current, queue_a, visited_a, distances)\n                    \n            if queue_b:\n                current = queue_b.popleft()  \n                if current in visited_a:\n                    candidates.append((current, distances[current]))\n                else:\n                    self._expand_parents(current, queue_b, visited_b, distances)\n                    \n            # Early termination if we found candidates\n            if candidates:\n                break\n                \n        # Return the candidate with shortest distance\n        if candidates:\n            return min(candidates, key=lambda x: x[1])[0]\n        return None\n        \n    def _expand_parents(self, commit_hash: str, queue: deque, \n                       visited: Set[str], distances: Dict[str, int]):\n        \"\"\"Add commit's parents to the search queue.\"\"\"\n        try:\n            commit_obj = self.object_store.retrieve_object(commit_hash)\n            if commit_obj[0] != 'commit':\n                return\n                \n            # Parse commit object to extract parent hashes\n            content = commit_obj[1].decode('utf-8')\n            current_distance = distances[commit_hash]\n            \n            for line in content.split('\\n'):\n                if line.startswith('parent '):\n                    parent_hash = line[7:].strip()\n                    if parent_hash not in visited:\n                        visited.add(parent_hash)\n                        queue.append(parent_hash)\n                        distances[parent_hash] = current_distance + 1\n                elif not line.startswith('parent'):\n                    # Stop at first non-parent line\n                    break\n                    \n        except Exception:\n            # Skip commits we can't read\n            pass\n```\n\n**D. Core Logic Skeleton - Three-Way Merge:**\n\n```python\nfrom dataclasses import dataclass\nfrom typing import List, Optional, Dict, Tuple\nfrom enum import Enum\n\nclass MergeStatus(Enum):\n    CLEAN = \"clean\"\n    CONFLICTED = \"conflicted\"\n    \nclass ConflictType(Enum):\n    CONTENT = \"content\"\n    ADD_ADD = \"add_add\"  \n    DELETE_MODIFY = \"delete_modify\"\n    MODE_CHANGE = \"mode_change\"\n\n@dataclass\nclass ConflictRegion:\n    start_line: int\n    end_line: int\n    conflict_type: ConflictType\n    ours_content: List[str]\n    theirs_content: List[str]\n    base_content: List[str]\n\n@dataclass \nclass MergeResult:\n    status: MergeStatus\n    merged_content: Optional[str]\n    conflicts: List[ConflictRegion]\n    files_changed: int\n    lines_added: int\n    lines_deleted: int\n\nclass ThreeWayMerge:\n    \"\"\"Performs three-way merging with automatic conflict detection.\"\"\"\n    \n    def __init__(self, object_store, diff_algorithm):\n        self.object_store = object_store\n        self.diff_algorithm = diff_algorithm\n        \n    def merge_commits(self, base_commit: str, our_commit: str, \n                     their_commit: str) -> Dict[str, MergeResult]:\n        \"\"\"\n        Merge two commits using three-way algorithm.\n        \n        Returns:\n            Dictionary mapping file paths to their merge results\n        \"\"\"\n        # TODO 1: Extract tree objects from all three commits\n        # TODO 2: Build file lists from each tree (recursively for subdirectories)  \n        # TODO 3: Identify all unique file paths across the three trees\n        # TODO 4: For each file path, determine the merge scenario (see file-level table above)\n        # TODO 5: Call merge_file_content for files requiring content merging\n        # TODO 6: Handle add/add conflicts by comparing content hashes\n        # TODO 7: Handle delete/modify conflicts by checking if deleted file was modified\n        # TODO 8: Aggregate results and return file path -> MergeResult mapping\n        pass\n        \n    def merge_file_content(self, base_content: str, our_content: str, \n                          their_content: str, file_path: str) -> MergeResult:\n        \"\"\"\n        Perform line-by-line three-way merge of file content.\n        \n        Args:\n            base_content: Content from merge base commit\n            our_content: Content from current branch  \n            their_content: Content from branch being merged\n            file_path: Path for error reporting\n            \n        Returns:\n            MergeResult with merged content or conflicts\n        \"\"\"\n        # TODO 1: Split each content version into lines (handle different line endings)\n        # TODO 2: Run diff algorithm between base->ours and base->theirs\n        # TODO 3: Create line mapping showing which lines changed in each branch\n        # TODO 4: Iterate through lines applying three-way merge logic:\n        #         - Unchanged in both: keep base version  \n        #         - Changed in ours only: apply our change\n        #         - Changed in theirs only: apply their change\n        #         - Changed identically: keep the shared change\n        #         - Changed differently: mark as conflict\n        # TODO 5: Group consecutive conflicts into regions with context\n        # TODO 6: Generate conflict markers for unresolved regions  \n        # TODO 7: Return MergeResult with final content and conflict metadata\n        pass\n        \n    def _detect_conflicts(self, base_lines: List[str], our_lines: List[str],\n                         their_lines: List[str]) -> List[ConflictRegion]:\n        \"\"\"\n        Identify regions where both branches made incompatible changes.\n        \n        Returns:\n            List of conflict regions requiring manual resolution\n        \"\"\"  \n        # TODO 1: Use Myers diff to find edit scripts for base->ours and base->theirs\n        # TODO 2: Build change maps showing which lines were modified in each branch\n        # TODO 3: Find overlapping changes where both branches modified same line ranges\n        # TODO 4: Classify conflict types (content, add/add, delete/modify)  \n        # TODO 5: Group adjacent conflicts with context lines\n        # TODO 6: Create ConflictRegion objects with all necessary metadata\n        pass\n        \n    def _generate_conflict_markers(self, conflict: ConflictRegion, \n                                  our_branch: str, their_branch: str) -> List[str]:\n        \"\"\"\n        Generate standard Git conflict markers for a conflict region.\n        \n        Returns:\n            List of lines with conflict markers inserted\n        \"\"\"\n        # TODO 1: Create opening marker with our branch name: \"<<<<<<< {our_branch}\"\n        # TODO 2: Add all lines from our version of the conflict\n        # TODO 3: Add separator marker: \"=======\"  \n        # TODO 4: Add all lines from their version of the conflict\n        # TODO 5: Add closing marker with their branch name: \">>>>>>> {their_branch}\"\n        # TODO 6: Return complete conflict block as list of lines\n        pass\n        \n    def _is_binary_content(self, content: bytes) -> bool:\n        \"\"\"Check if content appears to be binary data.\"\"\"\n        if len(content) == 0:\n            return False\n            \n        # Check first 1024 bytes for null bytes or high ratio of non-printable chars\n        sample = content[:1024]\n        if b'\\x00' in sample:\n            return True\n            \n        printable_chars = sum(1 for byte in sample if 32 <= byte <= 126 or byte in [9, 10, 13])\n        ratio = printable_chars / len(sample) if sample else 1.0\n        return ratio < 0.75\n```\n\n**E. Language-Specific Implementation Hints:**\n\n- **Graph Traversal**: Use `collections.deque` for BFS queues - it has O(1) append/popleft operations compared to O(n) for lists\n- **String Processing**: Use `str.splitlines(keepends=True)` to preserve line ending information during merge\n- **Memory Management**: For large files, consider using generators or streaming processing rather than loading entire content\n- **Path Handling**: Use `pathlib.Path` consistently and call `.resolve()` to handle symbolic links properly\n- **Error Handling**: Catch `KeyError` when looking up objects that might not exist, and `UnicodeDecodeError` when processing potentially binary content\n\n**F. Milestone Checkpoint:**\n\nAfter implementing three-way merge:\n\n1. **Test Basic Merge**: Create two branches that modify different files, merge should complete cleanly\n2. **Test Conflict Detection**: Create branches that modify the same lines, verify conflict markers appear\n3. **Test Merge Base**: Verify merge base calculation finds correct common ancestor\n4. **Integration Test**: Run `python -m git merge branch-name` and compare results with real Git\n\nExpected behavior:\n- Clean merges complete without user intervention  \n- Conflicted files contain properly formatted conflict markers\n- Merge commit has two parent references\n- Working directory contains merged content\n\n**G. Debugging Tips:**\n\n| Symptom | Likely Cause | Diagnosis | Fix |\n|---------|--------------|-----------|-----|\n| \"No merge base found\" | Branches have separate histories | Check commit ancestry with log | Verify both branches descend from same root |\n| Merge creates wrong conflicts | Incorrect diff algorithm | Compare diff output with Git's | Debug Myers algorithm implementation |\n| Missing conflict markers | Binary file detected incorrectly | Check file content detection | Adjust binary detection thresholds |\n| Malformed conflict output | Line ending inconsistencies | Check line splitting logic | Normalize line endings before processing |\n\n\n## Component Interactions and Data Flow\n\n> **Milestone(s):** This section synthesizes all eight milestones, showing how components interact during complex operations. It's particularly crucial for understanding the complete workflows in Milestone 6 (Index/Staging Area), Milestone 7 (Diff Algorithm), and Milestone 8 (Three-Way Merge), while demonstrating how earlier milestones (Object Storage, References, Tree Objects, Commit Objects) integrate into cohesive operations.\n\n### Mental Model: The Assembly Line Factory\n\nThink of Git operations as an assembly line factory where raw materials (your file changes) flow through different stations, getting processed and transformed at each stage. The **working directory** is your raw materials warehouse, the **staging area** is the quality control station where you inspect and prepare items for production, the **object store** is the permanent inventory warehouse, and **references** are the catalog system that helps you find finished products later.\n\nJust as a factory has standard workflows—receiving materials, quality control, assembly, packaging, and shipping—Git has standard data flows for its core operations. A simple product might visit only a few stations (like storing a single file), while a complex product (like merging two feature branches) requires coordination across all stations with multiple quality checks and decision points.\n\nThe beauty of this assembly line design is that each station has a single, well-defined responsibility, but the stations can be combined in different sequences to handle everything from simple file storage to complex multi-branch merges. Understanding these workflows is essential because they reveal how Git maintains consistency and enables powerful features like atomic commits and conflict-free parallel development.\n\n![Git System Architecture](./diagrams/system-architecture.svg)\n\n### Commit Creation Data Flow\n\nThe commit creation process represents Git's most fundamental workflow, transforming scattered file changes in your working directory into an immutable entry in the project's permanent history. This operation demonstrates the elegant coordination between all four major components: the working directory provides the raw changes, the staging area curates which changes to include, the object store provides permanent storage with deduplication, and the reference system updates to point to the new history state.\n\n#### Stage 1: File Staging (git add)\n\nThe staging process begins when a developer runs the equivalent of `git add`, which moves changes from the working directory into the staging area. This operation involves complex coordination between the `WorkingDirectory`, `Index`, and `ObjectStore` components to ensure that file content is preserved exactly while metadata is captured for change detection.\n\nThe staging workflow follows these detailed steps:\n\n1. The `WorkingDirectory` component scans the specified file path and reads the complete file content into memory, handling both text and binary files uniformly as byte streams\n2. The system computes the SHA-1 hash of the file content using the blob object format: `blob {size}\\0{content}`, which ensures that identical file contents always produce identical hashes regardless of filename or location\n3. The `ObjectStore` checks whether an object with this hash already exists in the `.git/objects` directory, leveraging Git's content-addressable storage to avoid storing duplicate content\n4. If the object doesn't exist, the system compresses the full blob object using zlib compression and stores it at the path `.git/objects/xx/yy...` where `xx` is the first two hex characters of the SHA-1 hash\n5. The `Index` creates a new `IndexEntry` containing the file's complete metadata: modification times (`mtime_sec`, `mtime_nsec`), file size (`size`), file mode (`mode`), device and inode numbers for change detection, and the computed object hash\n6. The new entry replaces any existing entry for the same file path in the index's sorted entry list, maintaining the index's alphabetical ordering requirement\n7. The modified index is written atomically to `.git/index` using a temporary file and rename operation to ensure consistency even if the process is interrupted\n\nThis staging process creates a critical checkpoint where the file's content is permanently preserved in the object store, while the index maintains a snapshot of the working directory state at staging time.\n\n| Component | Responsibility | Data Input | Data Output | Side Effects |\n|-----------|---------------|-------------|-------------|--------------|\n| `WorkingDirectory` | File content reading | File path | Raw file bytes | None (read-only) |\n| `ObjectStore` | Content preservation | Blob object data | Object hash | Creates compressed object file |\n| `Index` | Change tracking | File metadata + hash | Updated entry list | Modifies .git/index file |\n\n#### Stage 2: Tree Construction (git write-tree)\n\nTree construction transforms the flat list of staged files into Git's hierarchical tree structure, which mirrors the directory organization while enabling efficient storage and comparison of project states. This process requires the `Index` to coordinate with the `ObjectStore` to build a nested tree structure where each directory becomes a tree object containing references to its files (as blobs) and subdirectories (as subtrees).\n\nThe tree construction algorithm proceeds recursively through the directory hierarchy:\n\n1. The `Index` groups all staged entries by their parent directory path, creating a hierarchical structure that mirrors the working directory organization\n2. For each directory level, starting from the deepest subdirectories and working upward, the system creates a tree object containing sorted entries\n3. Each tree entry consists of the file mode (e.g., `100644` for regular files, `040000` for subdirectories), the filename or directory name, and the 20-byte binary SHA-1 hash of the referenced object\n4. Subdirectories are processed first to obtain their tree hashes, which are then referenced by their parent directories, creating a bottom-up construction process\n5. The tree entries are sorted according to Git's specific sorting rules: directories sort as if they have a trailing slash, ensuring consistent tree hashes regardless of entry insertion order\n6. Each tree object is formatted as `tree {size}\\0{entry1}{entry2}...{entryN}` where each entry is the binary concatenation of mode, space, name, null byte, and 20-byte hash\n7. The formatted tree object is hashed, compressed, and stored in the object store using the same content-addressable storage mechanism as blob objects\n8. The process continues up the directory hierarchy until a single root tree hash represents the entire project structure\n\nThis tree construction process creates an immutable snapshot of the project's directory structure, where identical directory contents always produce identical tree hashes, enabling efficient comparison and storage.\n\n| Directory Level | Input Data | Processing | Output |\n|----------------|------------|------------|--------|\n| Leaf directories | File entries from index | Sort + format tree object | Tree hash |\n| Intermediate directories | File entries + subtree hashes | Sort + format tree object | Tree hash |\n| Root directory | All entries + subtree hashes | Sort + format tree object | Root tree hash |\n\n#### Stage 3: Commit Creation (git commit)\n\nCommit creation represents the culmination of the staging process, where the prepared tree object is wrapped with metadata to create a permanent, immutable entry in the project's history. This operation involves the `ObjectStore` for content storage and the `ReferenceManager` for updating the current branch pointer, creating an atomic transition from one project state to another.\n\nThe commit creation process follows these precise steps:\n\n1. The system retrieves the root tree hash from the tree construction phase, which represents the complete project state being committed\n2. The `ReferenceManager` resolves the current HEAD reference to determine the parent commit hash, handling both normal branch situations and detached HEAD states\n3. The system collects commit metadata including author information (name, email, timestamp with timezone), committer information (typically identical to author), and the commit message provided by the user\n4. A commit object is constructed with the format: `commit {size}\\0tree {tree_hash}\\nparent {parent_hash}\\nauthor {author_line}\\ncommitter {committer_line}\\n\\n{commit_message}`\n5. The formatted commit object is hashed using SHA-1, compressed with zlib, and stored in the object store using the same content-addressable mechanism as other Git objects\n6. The `ReferenceManager` atomically updates the current branch reference (or HEAD in detached state) to point to the new commit hash, using a temporary file and rename operation for consistency\n7. If the repository tracks a reflog, the reference change is logged with the commit hash, previous hash, author information, and commit message for audit purposes\n\nThis commit creation process establishes an immutable link in the project's history chain, where the new commit references both the project state (via the tree hash) and the previous history (via the parent hash), creating Git's characteristic directed acyclic graph structure.\n\n> The critical insight in commit creation is that the tree hash captures *what* changed while the parent hash captures *when* it changed relative to other commits. This dual referencing system enables Git to efficiently answer both \"what was the project state at this point?\" and \"how did we get to this state?\" questions.\n\n![Commit Creation Sequence](./diagrams/commit-creation-flow.svg)\n\n#### Data Flow Summary for Commit Creation\n\nThe complete commit creation flow demonstrates how Git's four-layer architecture enables atomic, consistent operations even when dealing with hundreds or thousands of files. Each component has a single responsibility, but they coordinate through well-defined interfaces to ensure that the working directory, index, and object store remain synchronized.\n\n| Operation Phase | Primary Component | Secondary Components | Critical Data | Failure Recovery |\n|----------------|-------------------|---------------------|---------------|------------------|\n| File staging | `Index` | `WorkingDirectory`, `ObjectStore` | File content + metadata | Partial index can be rebuilt from objects |\n| Tree construction | `ObjectStore` | `Index` | Directory structure + hashes | Trees can be reconstructed from index |\n| Commit creation | `ReferenceManager` | `ObjectStore` | Parent hash + tree hash | Reference can be reset to previous state |\n| Reference update | `ReferenceManager` | None | New commit hash | Atomic file operations prevent corruption |\n\n### Branch Merge Data Flow\n\nBranch merging represents Git's most complex operation, requiring coordination across all system components to combine changes from two independent lines of development while detecting and managing conflicts. Unlike the linear flow of commit creation, merge operations involve bidirectional data flow, backtracking algorithms, and conditional logic based on the discovered merge state.\n\n#### Mental Model: The Document Reconciliation Process\n\nThink of branch merging like two editors working independently on the same document. Each editor starts with the same original version (the merge base), makes their own changes, and then you need to create a final version that includes both sets of changes. Sometimes their edits don't overlap (easy merge), sometimes they edit different parts of the same paragraph (automatic merge), and sometimes they change the same sentence in conflicting ways (manual merge required).\n\nGit's three-way merge algorithm automates this reconciliation process by comparing three versions: the original document (merge base), editor A's version (our branch), and editor B's version (their branch). By understanding what each editor changed relative to the original, Git can intelligently combine non-conflicting changes and flag areas where human judgment is needed.\n\n#### Stage 1: Merge Base Discovery\n\nMerge base discovery involves traversing the commit history graph to find the most recent common ancestor between two branches. This operation requires the `ObjectStore` to retrieve commit objects and performs a graph search algorithm to identify the point where the branches diverged, which serves as the reference point for three-way comparison.\n\nThe merge base discovery algorithm uses a breadth-first search approach with distance tracking:\n\n1. The `MergeBaseCalculator` initializes two parallel breadth-first searches, one starting from each branch tip, maintaining separate visited sets and distance tracking for each search path\n2. Each iteration expands one level of parent commits from both starting points, retrieving commit objects from the `ObjectStore` and parsing their parent references\n3. The algorithm tracks the minimum distance from each starting commit to every discovered ancestor commit, enabling it to identify the lowest common ancestor when paths converge\n4. When a commit is discovered from both search paths, it represents a potential merge base, but the algorithm continues until it has explored all commits at the current distance level to ensure optimality\n5. Among all discovered common ancestors, the algorithm selects the one with the minimum combined distance from both branch tips, which represents the most recent common ancestor\n6. Special cases are handled including: merge commits with multiple parents (both parents are added to the search queue), initial commits with no parents (search terminates at repository root), and branches with no common history (rare but possible in repositories with multiple root commits)\n7. The algorithm returns the SHA-1 hash of the identified merge base commit, or signals an error if no common ancestry exists between the branches\n\nThis merge base discovery creates the foundation for three-way comparison by establishing the \"original document\" against which both branches' changes will be evaluated.\n\n| Search Phase | Data Structure | Content | Purpose |\n|-------------|----------------|---------|---------|\n| Initialization | `visited_a: Set[str]` | Branch A's starting commit | Track explored commits from branch A |\n| Initialization | `visited_b: Set[str]` | Branch B's starting commit | Track explored commits from branch B |\n| Expansion | `distances_a: Dict[str, int]` | Commit hash → distance mapping | Find shortest path from branch A |\n| Expansion | `distances_b: Dict[str, int]` | Commit hash → distance mapping | Find shortest path from branch B |\n| Convergence | `common_ancestors: Set[str]` | Intersection of visited sets | Identify potential merge bases |\n| Selection | `merge_base: str` | Optimal common ancestor hash | Reference point for three-way merge |\n\n#### Stage 2: Three-Way File Comparison\n\nThree-way file comparison forms the heart of Git's merge algorithm, analyzing each file that exists in any of the three versions (merge base, our branch, their branch) to determine whether changes can be automatically combined or require manual conflict resolution. This process requires the `ObjectStore` to retrieve file content and the `MyersDiff` algorithm to compute precise change locations.\n\nThe three-way comparison process analyzes each file through multiple decision paths:\n\n1. The `ThreeWayMerge` component enumerates all unique file paths that exist in any of the three commits (merge base, ours, theirs), creating a comprehensive list of files that require analysis\n2. For each file path, the system retrieves the file content from all three versions where the file exists, handling cases where the file was added, deleted, or modified in different branches\n3. The Myers diff algorithm computes two separate edit scripts: one from the merge base to our version, and another from the merge base to their version, identifying exactly which lines were added, deleted, or modified\n4. The system analyzes the two edit scripts to categorize the merge scenario: clean merge (non-overlapping changes), conflict (overlapping changes), or various edge cases like add/add conflicts where both branches created the same file path\n5. For clean merges, the algorithm applies both sets of changes to the merge base content, creating a unified result that incorporates modifications from both branches\n6. For conflicts, the system identifies the specific line ranges where changes overlap and generates conflict markers that preserve both versions for manual resolution\n7. Binary files receive special handling since line-by-line merging is not applicable; binary conflicts always require manual resolution by choosing one version or the other\n8. The result for each file is classified into one of several categories: cleanly merged content, conflicted content with markers, binary conflict requiring resolution, or deletion/modification conflicts\n\nThis three-way analysis produces a complete understanding of how the two branches diverged and where human intervention is required to complete the merge.\n\n| File State | Base Version | Our Version | Their Version | Merge Result |\n|-----------|--------------|-------------|---------------|--------------|\n| Unchanged | Exists | Identical | Identical | Use any version |\n| Modified by us only | Exists | Modified | Identical | Use our version |\n| Modified by them only | Exists | Identical | Modified | Use their version |\n| Modified by both (clean) | Exists | Modified | Modified | Merge both changes |\n| Modified by both (conflict) | Exists | Modified | Modified | Insert conflict markers |\n| Added by us only | None | Exists | None | Use our version |\n| Added by them only | None | None | Exists | Use their version |\n| Added by both (same content) | None | Exists | Exists | Use either version |\n| Added by both (different) | None | Exists | Exists | Insert conflict markers |\n| Deleted by us only | Exists | None | Identical | Delete file |\n| Deleted by them only | Exists | Identical | None | Delete file |\n| Deleted by both | Exists | None | None | Delete file |\n| Delete/modify conflict | Exists | None | Modified | Conflict requiring resolution |\n\n#### Stage 3: Conflict Resolution and Merge Commit Creation\n\nWhen conflicts are detected during three-way comparison, the system must create a partially merged state that preserves both versions for manual resolution, then provide mechanisms for completing the merge once conflicts are resolved. This process involves the `Index`, `WorkingDirectory`, and `ReferenceManager` components working together to maintain merge state across multiple user interactions.\n\nThe conflict resolution workflow manages the complex state transitions required for interactive merging:\n\n1. The `ThreeWayMerge` component writes conflicted files to the working directory with Git's standard conflict markers: `<<<<<<< HEAD` delimiting our changes, `=======` separating the versions, and `>>>>>>> {branch_name}` delimiting their changes\n2. The `Index` is updated to record the merge state by storing index entries for all three versions of conflicted files (stage 1 for merge base, stage 2 for our version, stage 3 for their version), while cleanly merged files are stored as normal stage 0 entries\n3. A `.git/MERGE_HEAD` file is created containing the SHA-1 hash of the branch being merged, which signals to other Git operations that a merge is in progress and prevents certain operations that could corrupt the merge state\n4. The user manually resolves conflicts by editing the working directory files to remove conflict markers and create the desired merged content, typically using text editors or specialized merge tools\n5. The user stages their resolution using the equivalent of `git add`, which removes the multi-stage index entries for each resolved file and replaces them with a single stage 0 entry containing the resolved content\n6. Once all conflicts are resolved (indicated by no remaining multi-stage index entries), the user can complete the merge by creating a merge commit\n7. The merge commit creation process follows the same object creation steps as regular commits, but includes two parent hashes: the current branch tip and the merged branch tip, creating Git's characteristic merge topology\n8. Upon successful merge commit creation, the `.git/MERGE_HEAD` file is removed, the current branch reference is updated to point to the new merge commit, and the merge state is cleared\n\nThis conflict resolution process maintains complete safety by preserving all original content while providing clear indicators of what requires manual attention.\n\n> The critical design insight for merge conflict handling is that Git never loses information during conflicts. The original versions from both branches are preserved in the index at different stages, the conflict markers clearly delineate the choices, and the user's resolution becomes part of the permanent history. This enables confident merging even in complex scenarios because you can always recover the original versions if needed.\n\n#### Stage 4: Merge State Management\n\nManaging merge state involves tracking the progress of a multi-step merge operation across multiple user interactions, ensuring that partial merge states are preserved consistently and that the system can detect incomplete merges to prevent data loss. This requires coordination between the `Index`, `ReferenceManager`, and file system to maintain merge metadata.\n\nThe merge state management system handles several complex scenarios:\n\n1. **In-progress merge detection**: The presence of `.git/MERGE_HEAD` signals that a merge is in progress, causing status commands to display merge information and preventing operations like starting new merges or switching branches that could lose merge state\n2. **Multi-stage index management**: Conflicted files are stored with stage numbers (1 = merge base, 2 = ours, 3 = theirs) in the index, while resolved files use stage 0, enabling precise tracking of which conflicts remain unresolved\n3. **Partial resolution handling**: Users can resolve conflicts incrementally, staging some files while leaving others conflicted, with the system maintaining accurate state for each file independently\n4. **Merge abort capability**: The system can restore the pre-merge state by resetting the working directory and index to the original branch tip and removing merge metadata files\n5. **Merge commit validation**: Before allowing merge commit creation, the system verifies that no multi-stage index entries remain, ensuring that all conflicts have been explicitly resolved\n6. **Reference safety**: During merge operations, the current branch reference is not updated until the merge commit is successfully created, maintaining a consistent rollback point\n7. **Working directory synchronization**: The system ensures that working directory file contents match the user's intended resolutions and that no uncommitted changes would be lost during merge completion\n\nThis comprehensive state management enables safe, incremental conflict resolution while maintaining system consistency throughout the merge process.\n\n| Merge State | Index Entries | Working Directory | Metadata Files | User Actions Available |\n|-------------|---------------|-------------------|----------------|------------------------|\n| Clean merge | Stage 0 only | Merged content | None | Commit merge immediately |\n| Conflicts present | Multi-stage entries | Conflict markers | `.git/MERGE_HEAD` | Resolve conflicts, stage files |\n| Partially resolved | Mixed stage entries | Some resolved, some conflicted | `.git/MERGE_HEAD` | Continue resolving, stage files |\n| Fully resolved | Stage 0 only | All resolved | `.git/MERGE_HEAD` | Commit merge |\n| Aborted merge | Original state | Original state | None | Normal operations |\n\n### Common Pitfalls in Component Interactions\n\nUnderstanding the complex data flows in Git operations helps identify common mistakes that can lead to inconsistent repository states or data loss. These pitfalls often occur at the boundaries between components where assumptions about data consistency or operation atomicity may not hold.\n\n⚠️ **Pitfall: Non-atomic Index Updates**\n\nMany implementers update the index entry by entry during staging operations, which can leave the repository in an inconsistent state if the process is interrupted. For example, partially updating the index during a large `git add` operation could result in some files being staged while others remain in an unknown state. The index file could become corrupted if the process crashes while writing, since the checksum at the end of the file would not match the partial content. Always use atomic writes with temporary files and rename operations, and ensure that the index checksum is computed over the complete final state before writing.\n\n⚠️ **Pitfall: Incorrect Object Hash Computation**\n\nA common mistake is computing object hashes over just the content bytes rather than the complete object format including the type header and size. This leads to hash mismatches where your implementation generates different hashes than real Git for identical content. The hash must be computed over the complete format: `{type} {size}\\0{content}` where the null byte is critical and often forgotten. Additionally, ensure that the size is the byte count of the raw content, not the formatted object, and that binary content is handled without text encoding conversions.\n\n⚠️ **Pitfall: Merge Base Calculation Errors**\n\nMerge base discovery can fail in repositories with complex branching topologies, particularly when dealing with merge commits that have multiple parents or when branches have been created and deleted repeatedly. A common error is implementing a simple \"first common ancestor\" algorithm rather than finding the *lowest* common ancestor, which can result in merge bases that are too far back in history. This leads to unnecessarily complex merges with spurious conflicts. Always implement breadth-first search with proper distance tracking, and handle edge cases like octopus merges and orphan branches.\n\n⚠️ **Pitfall: Conflict Marker Generation**\n\nWhen generating conflict markers during merge operations, many implementations fail to properly escape or handle edge cases in the conflict content itself. If the conflicted content already contains lines that look like conflict markers (e.g., lines starting with `<<<<<<<`), the generated markers can become ambiguous or confusing. Additionally, failing to include proper branch names or commit identifiers in the conflict markers makes it difficult for users to understand which version is which. Always validate that generated markers are unambiguous and include sufficient context for resolution.\n\n⚠️ **Pitfall: Reference Update Race Conditions**\n\nIn systems where multiple processes might access the repository simultaneously, updating references without proper locking can lead to lost commits or corrupted branch states. For example, if two processes attempt to commit to the same branch simultaneously, one commit might be lost if both read the same parent hash but only the last write succeeds. While single-user scenarios are common during learning, understanding the race conditions helps build more robust implementations. Use file locking or atomic operations for reference updates, and consider implementing basic conflict detection for concurrent access.\n\n### Implementation Guidance\n\nThis section provides concrete implementation support for building the component interactions and data flows described above. The code focuses on orchestrating the individual components built in previous milestones into cohesive, complex operations.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option | Notes |\n|-----------|---------------|-----------------|-------|\n| Flow orchestration | Simple function calls | Command pattern with undo | Commands enable better error recovery |\n| State management | Direct attribute access | State machine pattern | State machines prevent invalid transitions |\n| Error handling | Exception bubbling | Result/Option types | Explicit error handling improves debugging |\n| Concurrency | Sequential operations | Lock-free algorithms | Start simple, optimize later if needed |\n| Progress tracking | Print statements | Observer pattern with events | Useful for long-running merge operations |\n\n#### Recommended File Structure\n\nThe component interaction code should coordinate the individual components built in previous milestones:\n\n```\nsrc/\n  git/\n    commands/\n      add.py              ← Implements staging workflow\n      commit.py           ← Implements commit creation workflow  \n      merge.py            ← Implements merge workflow\n      status.py           ← Implements status calculation workflow\n    workflows/\n      commit_workflow.py  ← Complete commit creation orchestration\n      merge_workflow.py   ← Complete merge orchestration\n    core/                 ← Individual components from previous milestones\n      object_store.py     ← From Milestone 2-4\n      index.py           ← From Milestone 6\n      references.py      ← From Milestone 5\n      diff.py           ← From Milestone 7\n      merge.py          ← From Milestone 8\n```\n\n#### Infrastructure Starter Code\n\nComplete workflow orchestration helpers that coordinate the individual components:\n\n```python\n\"\"\"\nWorkflow orchestration utilities for complex Git operations.\nProvides high-level coordination between individual components.\n\"\"\"\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple, Set\nfrom dataclasses import dataclass\nfrom enum import Enum\n\nclass WorkflowError(Exception):\n    \"\"\"Base exception for workflow orchestration errors.\"\"\"\n    pass\n\nclass WorkflowStatus(Enum):\n    \"\"\"Status of a multi-step workflow operation.\"\"\"\n    SUCCESS = \"success\"\n    PARTIAL = \"partial\"\n    CONFLICT = \"conflict\"\n    ERROR = \"error\"\n\n@dataclass\nclass WorkflowResult:\n    \"\"\"Result of a workflow operation with detailed status information.\"\"\"\n    status: WorkflowStatus\n    message: str\n    files_changed: int = 0\n    conflicts: List[str] = None\n    warnings: List[str] = None\n    \n    def __post_init__(self):\n        if self.conflicts is None:\n            self.conflicts = []\n        if self.warnings is None:\n            self.warnings = []\n\nclass ProgressReporter:\n    \"\"\"Simple progress reporting for long-running operations.\"\"\"\n    \n    def __init__(self, total_items: int = 0):\n        self.total_items = total_items\n        self.completed_items = 0\n        self.current_operation = \"\"\n    \n    def start_operation(self, operation: str, total: int = 0):\n        \"\"\"Start a new operation with optional total item count.\"\"\"\n        self.current_operation = operation\n        self.completed_items = 0\n        if total > 0:\n            self.total_items = total\n        print(f\"Starting: {operation}\")\n    \n    def update_progress(self, items_completed: int = 1, message: str = \"\"):\n        \"\"\"Update progress by specified number of items.\"\"\"\n        self.completed_items += items_completed\n        if self.total_items > 0:\n            percentage = (self.completed_items / self.total_items) * 100\n            print(f\"Progress: {percentage:.1f}% ({self.completed_items}/{self.total_items}) {message}\")\n        else:\n            print(f\"Progress: {self.completed_items} items completed {message}\")\n    \n    def finish_operation(self, success: bool = True):\n        \"\"\"Mark current operation as finished.\"\"\"\n        status = \"completed\" if success else \"failed\"\n        print(f\"Finished: {self.current_operation} - {status}\")\n\ndef validate_repository_state(git_dir: Path) -> List[str]:\n    \"\"\"\n    Validate that repository is in a consistent state for operations.\n    Returns list of validation errors, empty list if valid.\n    \"\"\"\n    errors = []\n    \n    # Check basic repository structure\n    if not git_dir.exists():\n        errors.append(\"Git directory does not exist\")\n        return errors\n    \n    objects_dir = git_dir / \"objects\"\n    if not objects_dir.exists():\n        errors.append(\"Objects directory missing\")\n    \n    refs_dir = git_dir / \"refs\" / \"heads\"\n    if not refs_dir.exists():\n        errors.append(\"References directory missing\")\n    \n    head_file = git_dir / \"HEAD\"\n    if not head_file.exists():\n        errors.append(\"HEAD reference missing\")\n    \n    # Check for corrupted index\n    index_file = git_dir / \"index\"\n    if index_file.exists():\n        try:\n            # Attempt to read index header to validate format\n            with open(index_file, 'rb') as f:\n                signature = f.read(4)\n                if signature != b'DIRC':\n                    errors.append(\"Index file corrupted - invalid signature\")\n        except Exception as e:\n            errors.append(f\"Index file unreadable: {e}\")\n    \n    return errors\n\ndef atomic_workflow_operation(operation_name: str, operation_func, cleanup_func=None):\n    \"\"\"\n    Decorator for atomic workflow operations with automatic cleanup on failure.\n    If operation fails, cleanup_func is called to restore previous state.\n    \"\"\"\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            try:\n                print(f\"Starting atomic operation: {operation_name}\")\n                result = operation_func(*args, **kwargs)\n                print(f\"Atomic operation completed: {operation_name}\")\n                return result\n            except Exception as e:\n                print(f\"Atomic operation failed: {operation_name} - {e}\")\n                if cleanup_func:\n                    try:\n                        cleanup_func(*args, **kwargs)\n                        print(f\"Cleanup completed for: {operation_name}\")\n                    except Exception as cleanup_error:\n                        print(f\"Cleanup failed for {operation_name}: {cleanup_error}\")\n                raise\n        return wrapper\n    return decorator\n```\n\n#### Commit Creation Workflow Implementation\n\nComplete orchestration for the commit creation process:\n\n```python\n\"\"\"\nCommit creation workflow implementation.\nOrchestrates staging, tree building, and commit creation.\n\"\"\"\nfrom pathlib import Path\nfrom typing import List, Optional, Set\nfrom .workflows.base import WorkflowResult, WorkflowStatus, ProgressReporter\n\nclass CommitWorkflow:\n    \"\"\"Orchestrates the complete commit creation process.\"\"\"\n    \n    def __init__(self, repository, object_store, index, references):\n        self.repository = repository\n        self.object_store = object_store\n        self.index = index\n        self.references = references\n        self.progress = ProgressReporter()\n    \n    def stage_files(self, file_paths: List[Path]) -> WorkflowResult:\n        \"\"\"\n        Stage multiple files for commit.\n        Coordinates WorkingDirectory -> ObjectStore -> Index flow.\n        \"\"\"\n        # TODO 1: Validate that all file paths exist in working directory\n        # TODO 2: For each file, read content and compute blob hash\n        # TODO 3: Store blob object in object store (with deduplication check)\n        # TODO 4: Create IndexEntry with file metadata and object hash\n        # TODO 5: Add IndexEntry to index, replacing any existing entry\n        # TODO 6: Save updated index atomically to .git/index\n        # Hint: Use ProgressReporter to show staging progress for large numbers of files\n        # Hint: Collect any files that couldn't be staged and include in warnings\n        pass\n    \n    def build_tree_from_index(self) -> str:\n        \"\"\"\n        Build tree object hierarchy from current index state.\n        Returns root tree hash representing complete project state.\n        \"\"\"\n        # TODO 1: Group index entries by directory path (recursive grouping)\n        # TODO 2: Start with deepest subdirectories, build tree objects bottom-up\n        # TODO 3: For each directory level, create sorted list of tree entries\n        # TODO 4: Format tree entries as: mode + \" \" + name + \"\\0\" + 20-byte hash\n        # TODO 5: Create tree object with format: \"tree {size}\\0{entries}\"\n        # TODO 6: Store tree object in object store and get its hash\n        # TODO 7: Continue up directory hierarchy until root tree is built\n        # Hint: Directories sort as if they have trailing \"/\" for Git compatibility\n        # Hint: Tree entries must be sorted for deterministic tree hashes\n        pass\n    \n    def create_commit(self, tree_hash: str, message: str, parent_hashes: List[str] = None) -> str:\n        \"\"\"\n        Create commit object linking tree to history.\n        Returns commit hash for the new commit.\n        \"\"\"\n        # TODO 1: Get current HEAD reference to determine parent commit\n        # TODO 2: Format author and committer lines with timestamp and timezone\n        # TODO 3: Build commit content: tree line, parent lines, author, committer, blank line, message\n        # TODO 4: Create commit object with format: \"commit {size}\\0{content}\"\n        # TODO 5: Store commit object in object store and get its hash\n        # TODO 6: Update current branch reference to point to new commit\n        # TODO 7: Clear any merge state files if this completes a merge\n        # Hint: Handle both normal commits (1 parent) and merge commits (2+ parents)\n        # Hint: Use atomic reference update to prevent corruption\n        pass\n    \n    def execute_commit(self, message: str, stage_all: bool = False) -> WorkflowResult:\n        \"\"\"\n        Execute complete commit workflow: stage files, build tree, create commit.\n        This is the high-level orchestration function.\n        \"\"\"\n        self.progress.start_operation(\"Creating commit\")\n        \n        try:\n            # TODO 1: If stage_all=True, stage all modified files in working directory\n            # TODO 2: Validate that index contains at least one staged change\n            # TODO 3: Build tree object from current index state\n            # TODO 4: Create commit object with tree hash and commit message\n            # TODO 5: Update HEAD reference to point to new commit\n            # TODO 6: Return WorkflowResult with success status and commit details\n            # Hint: Use progress.update_progress() to show workflow steps\n            # Hint: Return appropriate error status if any step fails\n            # Hint: Include commit hash and files changed count in result\n            pass\n        except Exception as e:\n            self.progress.finish_operation(success=False)\n            return WorkflowResult(\n                status=WorkflowStatus.ERROR,\n                message=f\"Commit failed: {e}\"\n            )\n```\n\n#### Merge Workflow Implementation\n\nComplete orchestration for the merge process:\n\n```python\n\"\"\"\nMerge workflow implementation.\nOrchestrates merge base discovery, three-way merge, and conflict resolution.\n\"\"\"\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nfrom .workflows.base import WorkflowResult, WorkflowStatus, ProgressReporter\n\nclass MergeWorkflow:\n    \"\"\"Orchestrates the complete branch merge process.\"\"\"\n    \n    def __init__(self, repository, object_store, index, references, merge_algorithm):\n        self.repository = repository\n        self.object_store = object_store\n        self.index = index\n        self.references = references\n        self.merge_algorithm = merge_algorithm\n        self.progress = ProgressReporter()\n    \n    def discover_merge_base(self, our_commit: str, their_commit: str) -> Optional[str]:\n        \"\"\"\n        Find lowest common ancestor between two commits.\n        Uses breadth-first search with distance tracking.\n        \"\"\"\n        # TODO 1: Initialize BFS queues for both commits with distance 0\n        # TODO 2: Track visited commits and distances from each starting point  \n        # TODO 3: Expand one level at a time, adding parent commits to queues\n        # TODO 4: When commit appears in both visited sets, it's a common ancestor\n        # TODO 5: Continue until all commits at current distance level are processed\n        # TODO 6: Return common ancestor with minimum combined distance\n        # TODO 7: Handle edge cases: no common ancestor, identical commits\n        # Hint: Use object_store.retrieve_object() to get commit objects\n        # Hint: Parse commit objects to extract parent hashes\n        # Hint: Return None if branches have no common history\n        pass\n    \n    def analyze_merge_conflicts(self, base_commit: str, our_commit: str, their_commit: str) -> Dict[str, str]:\n        \"\"\"\n        Analyze all files in three commits to categorize merge requirements.\n        Returns dict mapping file paths to merge status.\n        \"\"\"\n        # TODO 1: Get tree objects for all three commits\n        # TODO 2: Extract all unique file paths from all three trees\n        # TODO 3: For each file path, determine what happened in each branch\n        # TODO 4: Categorize each file: clean merge, conflict, add/add, delete/modify, etc.\n        # TODO 5: Return mapping of file_path -> merge_status\n        # Hint: Use tree traversal to find all files in each commit\n        # Hint: Handle cases where file exists in some commits but not others\n        # Hint: Status values: \"clean\", \"conflict\", \"add_add\", \"delete_modify\", etc.\n        pass\n    \n    def execute_three_way_merge(self, base_commit: str, our_commit: str, their_commit: str) -> WorkflowResult:\n        \"\"\"\n        Perform three-way merge of two branches.\n        Handles both clean merges and conflicts.\n        \"\"\"\n        self.progress.start_operation(\"Merging branches\")\n        \n        try:\n            # TODO 1: Analyze all files to categorize merge requirements\n            # TODO 2: For each file, perform appropriate merge operation\n            # TODO 3: Write cleanly merged files to working directory\n            # TODO 4: Write conflicted files with conflict markers to working directory\n            # TODO 5: Update index with appropriate stage entries (0 for clean, 1/2/3 for conflicts)\n            # TODO 6: Create .git/MERGE_HEAD file with their commit hash\n            # TODO 7: Return result indicating clean merge or conflicts requiring resolution\n            # Hint: Use progress reporting for large merges\n            # Hint: Collect conflict file paths for result reporting\n            # Hint: Handle binary files (always conflict, no line-level merge)\n            pass\n        except Exception as e:\n            self.progress.finish_operation(success=False)\n            return WorkflowResult(\n                status=WorkflowStatus.ERROR,\n                message=f\"Merge failed: {e}\"\n            )\n    \n    def resolve_conflicts_and_commit(self, message: str = None) -> WorkflowResult:\n        \"\"\"\n        Complete merge after manual conflict resolution.\n        Creates merge commit with two parents.\n        \"\"\"\n        # TODO 1: Verify that no multi-stage index entries remain (all conflicts resolved)\n        # TODO 2: Build tree from resolved index state\n        # TODO 3: Get both parent commits: current HEAD and MERGE_HEAD\n        # TODO 4: Create merge commit with both parent hashes\n        # TODO 5: Update HEAD reference to new merge commit\n        # TODO 6: Remove .git/MERGE_HEAD file to clear merge state\n        # TODO 7: Return success result with merge commit details\n        # Hint: Generate default merge message if none provided\n        # Hint: Validate that working directory matches index (no unstaged changes)\n        # Hint: Merge commits have exactly two parent lines in commit object\n        pass\n```\n\n#### Milestone Checkpoints\n\nAfter implementing the component interactions, verify the complete workflows:\n\n**Commit Creation Verification:**\n```bash\n# Initialize test repository\npython -m git.init test_repo\ncd test_repo\n\n# Create and stage multiple files\necho \"Content A\" > file_a.txt\necho \"Content B\" > file_b.txt\nmkdir subdir\necho \"Content C\" > subdir/file_c.txt\n\npython -m git.add file_a.txt file_b.txt subdir/file_c.txt\npython -m git.commit \"Initial commit with multiple files\"\n\n# Verify objects were created correctly\npython -m git.log --oneline  # Should show commit\npython -m git.ls-tree HEAD   # Should show tree structure\n```\n\n**Expected output:** Commit creation should produce consistent tree and commit hashes, with working directory, index, and object store all synchronized.\n\n**Merge Workflow Verification:**\n```bash\n# Create two branches with diverging changes\npython -m git.checkout -b feature\necho \"Feature change\" >> file_a.txt\npython -m git.add file_a.txt\npython -m git.commit \"Feature commit\"\n\npython -m git.checkout main\necho \"Main change\" >> file_b.txt  \npython -m git.add file_b.txt\npython -m git.commit \"Main commit\"\n\n# Attempt merge - should be clean\npython -m git.merge feature\n\n# Verify merge commit was created\npython -m git.log --graph --oneline  # Should show merge topology\n```\n\n**Expected behavior:** Clean merge should complete automatically, conflicting merge should leave conflict markers and require manual resolution.\n\n\n## Error Handling and Edge Cases\n\n> **Milestone(s):** This section applies to all eight milestones but is particularly critical for Milestone 6 (Index/Staging Area), Milestone 7 (Diff Algorithm), and Milestone 8 (Three-Way Merge). Robust error handling becomes essential as operations grow more complex and involve multiple components interacting.\n\n### Mental Model: The Digital Safety Net\n\nThink of error handling in a version control system like the safety systems in a modern airplane. Just as aircraft have multiple redundant systems, automatic failure detection, and clear emergency procedures that pilots practice extensively, a robust Git implementation needs layered protection against data corruption, clear detection of problems, and well-defined recovery workflows that users can follow confidently.\n\nWhen turbulence hits an aircraft, the autopilot doesn't just crash—it has protocols for every conceivable failure mode. Similarly, when your Git implementation encounters corrupted objects, interrupted merges, or concurrent access conflicts, it should degrade gracefully, preserve data integrity above all else, and provide clear guidance for recovery.\n\nThe critical insight is that version control systems are **data custodians**—they hold irreplaceable project history. Like a bank vault, the system must be paranoid about data integrity and conservative about operations that could cause loss. This means validating everything, assuming hardware can fail at any moment, and always providing a path back to a known good state.\n\n### Repository Corruption Handling\n\nRepository corruption represents the most serious class of failures in version control systems. Unlike application crashes that lose only current work, corruption can destroy historical data that may be impossible to recreate. Our error handling strategy must prioritize **early detection**, **damage isolation**, and **graceful recovery** while maintaining data integrity above all other concerns.\n\n#### Corruption Detection Strategies\n\nThe foundation of corruption handling lies in comprehensive validation that occurs at multiple layers throughout the system. Rather than trusting that data remains intact, we implement verification at every access point to catch corruption as early as possible.\n\n**Object Integrity Verification** forms the first line of defense. Every time we retrieve an object from the content-addressable store, we must verify that its content still produces the expected SHA-1 hash. This catches both storage corruption and programming bugs that might corrupt objects in memory.\n\n| Validation Point | Check Performed | Frequency | Action on Failure |\n|------------------|----------------|-----------|-------------------|\n| Object Retrieval | SHA-1 verification | Every access | Return corruption error |\n| Object Storage | Hash before/after compression | Every write | Abort operation |\n| Index Loading | Checksum verification | On index read | Rebuild from working tree |\n| Reference Resolution | SHA-1 format validation | Every resolution | Report invalid reference |\n| Tree Traversal | Entry format validation | During traversal | Stop at corrupted tree |\n| Commit Parsing | Header format validation | During log operations | Mark commit as corrupted |\n\n**Repository Structure Validation** ensures that the fundamental directory structure and required files remain intact. This validation should occur during repository initialization and can be triggered explicitly by user commands.\n\nThe validation algorithm proceeds systematically through repository components:\n\n1. Verify that the git directory exists and has appropriate permissions (0755)\n2. Check that required subdirectories exist: objects, refs, refs/heads, refs/tags\n3. Validate that the HEAD file exists and contains either a valid symbolic reference or commit hash\n4. Scan the objects directory to ensure the two-character subdirectory structure is intact\n5. Verify that no objects have been corrupted by spot-checking a sample of stored objects\n6. Validate reference files to ensure they contain properly formatted commit hashes or symbolic references\n7. Check the index file format and checksum if present\n\n**Cross-Reference Consistency** validates that references between objects remain valid. A commit might reference a tree that no longer exists, or a tree might reference a blob that has been corrupted. These consistency checks require traversing object relationships and validating each link.\n\n#### Corruption Recovery Strategies\n\nRecovery from corruption depends heavily on the extent and location of the damage. Our recovery strategy follows a **progressive escalation** approach, starting with minimal intervention and escalating to more drastic measures only when necessary.\n\n> **Decision: Corruption Recovery Hierarchy**\n> - **Context**: When corruption is detected, we need a systematic approach to recovery that minimizes data loss while restoring repository functionality\n> - **Options Considered**: \n>   - Immediate full repository rebuild from working directory\n>   - Attempt to repair specific corrupted components\n>   - Progressive recovery starting with least invasive repairs\n> - **Decision**: Implement progressive recovery hierarchy starting with object-level repairs\n> - **Rationale**: Maximizes data preservation while providing clear escalation path; users retain control over recovery process\n> - **Consequences**: More complex recovery logic but better preservation of historical data and user confidence\n\n**Level 1: Object-Level Recovery** addresses corruption in individual objects while preserving the broader repository structure. When object retrieval fails due to hash mismatch or decompression errors, the system should attempt to recover the object from alternative sources.\n\n| Recovery Method | Source | Applicability | Success Rate |\n|----------------|--------|---------------|--------------|\n| Re-read from disk | Same object file | Transient I/O errors | High |\n| Rebuild from working tree | Current file content | Blob objects only | Medium |\n| Reconstruct from index | Staged content | Recently staged files | Medium |\n| Import from backup | External copy | Any object type | Variable |\n\n**Level 2: Reference Recovery** handles corruption in the reference system, including damaged HEAD files, missing branch references, or invalid symbolic references. Reference recovery is generally safer than object recovery since references can be reconstructed from known commit hashes.\n\nThe reference recovery process involves:\n\n1. Scan the objects directory to identify all available commit objects\n2. Parse each commit to extract author, timestamp, and message information\n3. Present a list of recent commits to the user for branch recreation\n4. Allow the user to select which commits should become branch heads\n5. Recreate the branch references pointing to the selected commits\n6. Reset HEAD to point to the user's preferred default branch\n\n**Level 3: Index Reconstruction** rebuilds the staging area when the index file becomes corrupted or inconsistent. Since the index represents only the current staging state, it can be safely reconstructed from the working directory without losing historical data.\n\n**Level 4: Repository Rebuild** represents the most drastic recovery option, essentially reinitializing the repository while preserving as much history as possible. This approach salvages individual objects and reconstructs the repository structure around them.\n\n#### Validation Error Types and Responses\n\nDifferent types of corruption require specialized detection and response strategies. Our implementation must recognize each category and apply appropriate recovery measures.\n\n| Error Type | Detection Method | Immediate Response | Recovery Strategy |\n|------------|-----------------|-------------------|------------------|\n| SHA-1 Mismatch | Hash verification | Block object access | Re-read or rebuild object |\n| Compression Failure | Zlib decompression | Return read error | Attempt raw file recovery |\n| Malformed Object | Header parsing | Parsing exception | Reconstruct from metadata |\n| Missing Object | File system access | File not found | Search for alternatives |\n| Invalid Reference | Reference resolution | Format validation | Reset to valid commit |\n| Corrupt Index | Checksum verification | Index load failure | Rebuild from working tree |\n| Permission Errors | File system operations | Access denied | Report and suggest fixes |\n\n⚠️ **Pitfall: Silent Corruption**\nMany corruption scenarios don't immediately cause obvious failures. A single bit flip in an object file might not be detected until that specific object is accessed, potentially weeks later. Always implement comprehensive validation rather than assuming storage is reliable. Check SHA-1 hashes on every object read, not just during explicit verification commands.\n\n### Merge Conflict Resolution\n\nMerge conflicts represent a normal part of collaborative development, but the complexity of conflict resolution can overwhelm users if not handled gracefully. Our conflict resolution system must provide **clear conflict presentation**, **intuitive resolution workflows**, and **safe mechanisms** for completing interrupted merges.\n\n#### Conflict Detection and Classification\n\nEffective conflict resolution begins with precise conflict detection that categorizes conflicts by type and complexity. This classification helps users understand what they're dealing with and choose appropriate resolution strategies.\n\n**Content Conflicts** occur when both branches modify the same lines of a file. These represent the classic merge conflict scenario where automated merging cannot determine which changes should take precedence.\n\nThe conflict detection algorithm compares changes from both branches against their common ancestor:\n\n1. Identify all lines that were modified in the \"ours\" branch relative to the merge base\n2. Identify all lines that were modified in the \"theirs\" branch relative to the merge base\n3. Find overlapping regions where both branches modified the same line numbers\n4. For each overlap, determine if the changes are identical (auto-resolve) or conflicting (require manual resolution)\n5. Generate conflict markers for regions that require manual resolution\n\n**Structural Conflicts** arise from changes to file organization rather than content. These conflicts require different resolution strategies than simple content conflicts.\n\n| Conflict Type | Scenario | Detection Method | Resolution Options |\n|---------------|----------|------------------|-------------------|\n| Add/Add | Both branches add file with same name | Path collision during merge | Keep one, keep both with rename, manual merge |\n| Delete/Modify | One branch deletes, other modifies | Missing file during content merge | Keep modification, confirm deletion |\n| Mode Change | Different permission changes | File mode comparison | Choose one mode or manual decision |\n| Rename/Rename | Both branches rename same file | Path tracking during merge | Choose one name or create new name |\n| Directory/File | Directory becomes file or vice versa | Path type validation | Manual resolution required |\n\n**Binary File Conflicts** require special handling since line-based merging doesn't apply to binary content. The system must detect binary files and present appropriate resolution options.\n\n#### Conflict Marker Generation\n\nWhen conflicts cannot be resolved automatically, the system must generate clear, standardized conflict markers that help users understand what happened and how to proceed. The conflict marker format follows Git's established conventions to maintain familiarity for users.\n\nThe standard conflict marker structure includes:\n\n1. Opening marker (`<<<<<<<`) followed by branch identifier for \"ours\" changes\n2. The conflicting content from the \"ours\" branch\n3. Separator marker (`=======`) dividing the conflicting versions\n4. The conflicting content from the \"theirs\" branch  \n5. Closing marker (`>>>>>>>`) followed by branch identifier for \"theirs\" changes\n\nFor three-way conflicts where the merge base content differs from both branches, an additional marker (`|||||||`) introduces the original content between the ours section and the separator.\n\n> The key insight for effective conflict markers is that they must tell a story. Users need to understand not just what the conflicting content is, but where it came from, why it conflicts, and what their options are for resolution. Clear branch identifiers and optional base content provide this context.\n\n#### Conflict Resolution Workflows\n\nSuccessful conflict resolution requires well-defined workflows that guide users through the resolution process without overwhelming them. The workflow design must accommodate both novice and experienced users while maintaining safety throughout the process.\n\n**Interactive Resolution Workflow** provides step-by-step guidance for users who prefer structured assistance:\n\n1. Present a summary of all conflicts found, categorized by type and file\n2. For each conflicted file, display the conflict in context with surrounding unchanged lines\n3. Offer resolution options: edit manually, choose ours, choose theirs, or skip for now\n4. After each resolution, validate that conflict markers have been properly removed\n5. Allow users to test their resolution by running builds or tests before finalizing\n6. Provide a final review showing all resolved conflicts before completing the merge\n\n**Batch Resolution Workflow** supports experienced users who want to resolve multiple conflicts efficiently:\n\n1. Generate a conflict summary report showing all conflicts and their types\n2. Allow pattern-based resolution for similar conflicts (e.g., \"choose ours for all .config files\")\n3. Provide bulk editing capabilities for systematic conflict resolution\n4. Validate that all conflicts have been addressed before allowing merge completion\n\n**Tool Integration Workflow** supports external merge tools by providing standardized interfaces:\n\n1. Generate temporary files containing base, ours, and theirs versions for each conflict\n2. Launch the configured merge tool with appropriate file arguments\n3. Wait for the tool to complete and validate the merged result\n4. Import the resolved content back into the working directory\n5. Continue with the next conflict or complete the merge process\n\n#### Interrupted Merge Recovery\n\nMerge operations can be interrupted by system crashes, user cancellation, or external factors. The system must maintain enough state information to allow users to resume or abort interrupted merges safely.\n\n**Merge State Tracking** records the current merge operation's progress and context in the git directory. This state information enables recovery after interruption.\n\n| State File | Content | Purpose |\n|------------|---------|---------|\n| MERGE_HEAD | Target commit hash | Identifies what we're merging |\n| MERGE_MODE | Merge type and options | Records merge algorithm settings |\n| MERGE_MSG | Proposed commit message | Preserves user's merge message |\n| MERGE_PROGRESS | Resolved/remaining files | Tracks completion status |\n\n**Recovery Options** provide users with clear paths forward when they encounter an interrupted merge:\n\n1. **Continue Merge**: Resume the merge process after resolving remaining conflicts\n2. **Abort Merge**: Return to the pre-merge state, discarding all merge progress\n3. **Reset Merge**: Restart the merge from the beginning with fresh conflict resolution\n\nThe continue workflow validates that all conflicts have been resolved before proceeding:\n\n1. Scan all files mentioned in MERGE_PROGRESS for remaining conflict markers\n2. Verify that the working directory contains no unexpected changes\n3. Build the final merge tree from resolved content\n4. Create the merge commit with both parent commits recorded\n5. Update the current branch reference and clean up merge state files\n\nThe abort workflow ensures complete restoration to the pre-merge state:\n\n1. Read the original HEAD commit from the merge state files\n2. Reset the working directory to match the original commit tree\n3. Clear the index of any merge-related staged content\n4. Remove all merge state files to indicate normal (non-merge) state\n5. Display a summary of what was discarded for user confirmation\n\n⚠️ **Pitfall: Partial Conflict Resolution**\nUsers often resolve some conflicts and then forget to complete the merge, leaving the repository in an intermediate state. Always check for incomplete merges during status operations and provide clear guidance. Store enough state to distinguish between \"merge in progress with remaining conflicts\" and \"merge ready to complete\" scenarios.\n\n### Concurrent Access Patterns\n\nModern development workflows often involve multiple processes accessing the same repository simultaneously. Build systems, IDE integrations, backup tools, and multiple Git commands can all attempt repository operations concurrently. Our implementation must handle these scenarios gracefully without corrupting data or creating inconsistent states.\n\n#### File System Level Concurrency\n\nThe fundamental challenge of concurrent access lies in the shared file system that underlies Git's storage model. Multiple processes writing to the same files or directories can create race conditions, partial updates, and corruption scenarios that are difficult to diagnose and recover from.\n\n**Atomic Operations Strategy** ensures that file operations either complete entirely or fail entirely, preventing partial updates that could leave the repository in an inconsistent state.\n\n| Operation Type | Atomicity Mechanism | Failure Handling |\n|----------------|-------------------|------------------|\n| Object Storage | Write to temp file, rename | Remove temp file on failure |\n| Reference Updates | Write to temp file, rename | Restore original reference |\n| Index Updates | Write complete index to temp, rename | Restore backup index |\n| Branch Creation | Atomic file creation with O_EXCL | Report if branch exists |\n| Lock Acquisition | Create lock file with O_EXCL | Wait or fail immediately |\n\nThe atomic write pattern forms the foundation of safe concurrent access:\n\n1. Generate a unique temporary filename in the same directory as the target file\n2. Write the complete content to the temporary file\n3. Sync the temporary file to ensure data reaches persistent storage\n4. Atomically rename the temporary file to the final filename\n5. If any step fails, remove the temporary file and report the error\n\n**Locking Protocols** prevent multiple processes from modifying the same repository components simultaneously. Our locking strategy balances safety with performance, using fine-grained locks where possible to minimize contention.\n\nThe repository uses several categories of locks:\n\n- **Reference Locks**: Protect individual branch and tag references during updates\n- **Index Lock**: Prevents concurrent modification of the staging area\n- **Object Store Locks**: Protect against concurrent writes to the same object (rare but possible)\n- **Merge State Locks**: Prevent multiple merge operations from running simultaneously\n\nLock acquisition follows a consistent protocol to avoid deadlocks:\n\n1. Determine all required locks for the operation in a predetermined order\n2. Attempt to acquire each lock in sequence with appropriate timeouts\n3. If any lock acquisition fails, release all previously acquired locks\n4. Either retry with backoff or report the failure to the user\n5. Upon successful completion, release all locks in reverse order\n\n**Lock File Implementation** uses the file system's atomic file creation semantics to implement advisory locks. This approach works across different operating systems and doesn't require specialized locking primitives.\n\nLock file creation process:\n\n1. Generate lock filename by appending `.lock` to the protected resource name\n2. Attempt to create the lock file with exclusive access (O_CREAT | O_EXCL)\n3. If creation succeeds, write lock metadata (process ID, operation type, timestamp)\n4. If creation fails because the file exists, another process holds the lock\n5. To release the lock, simply remove the lock file\n\n#### Process Coordination Patterns\n\nBeyond basic file locking, certain operations require coordination between processes to ensure consistent behavior and avoid conflicts that locks alone cannot prevent.\n\n**Read-Write Coordination** allows multiple readers to access repository data simultaneously while ensuring that write operations have exclusive access when needed. This pattern is particularly important for long-running operations like large merges or history traversals.\n\n| Access Pattern | Lock Type | Concurrency Level | Use Cases |\n|----------------|-----------|------------------|-----------|\n| Multiple Readers | Shared read access | High concurrency | Status, log, diff operations |\n| Single Writer | Exclusive write access | No concurrency | Commit, merge, rebase operations |\n| Reader-Writer | Upgrade from read to write | Medium concurrency | Add operations that become commits |\n\n**Operation Serialization** ensures that certain operations complete in a consistent order even when initiated simultaneously. This is particularly important for operations that depend on the current repository state.\n\nThe serialization mechanism works through operation queuing:\n\n1. Operations that require serialization acquire a queue position lock\n2. Each operation writes its intent and dependencies to a coordination file\n3. Operations check their dependencies before proceeding with actual work\n4. Upon completion, operations signal their completion and wake waiting operations\n5. The coordination file is cleaned up when no operations remain pending\n\n**Graceful Degradation Strategies** allow the system to continue operating even when some concurrent access patterns fail. Rather than failing completely, the system falls back to safer but potentially slower operation modes.\n\n| Failure Scenario | Degradation Strategy | Performance Impact |\n|------------------|--------------------|--------------------|\n| Lock timeout | Prompt user to retry or wait | User intervention required |\n| File contention | Retry with exponential backoff | Increased operation latency |\n| Coordination failure | Fall back to exclusive locking | Reduced concurrency |\n| Resource exhaustion | Queue operations sequentially | Serialized execution |\n\n#### Error Recovery in Concurrent Scenarios\n\nConcurrent access introduces additional failure modes that don't occur in single-process scenarios. These failures often involve partial state updates, timing-dependent races, and complex interactions between multiple operations.\n\n**Orphaned Lock Detection** identifies and recovers from situations where locks are left behind by crashed or killed processes. Without proper cleanup, these orphaned locks can permanently block repository access.\n\nThe orphaned lock detection algorithm:\n\n1. When lock acquisition fails, examine the existing lock file contents\n2. Extract the process ID and timestamp from the lock metadata\n3. Check if the process ID still exists and is running the expected operation\n4. If the process is gone or running a different operation, consider the lock orphaned\n5. Verify that sufficient time has passed since lock creation to avoid false positives\n6. Remove the orphaned lock and proceed with the operation\n\n**Partial Operation Recovery** handles scenarios where an operation begins but cannot complete due to concurrent access conflicts. The system must be able to detect these partial states and either complete the operation or roll back to a consistent state.\n\nPartial operation scenarios include:\n\n- Reference updates that write the new value but fail to remove backup files\n- Index updates that complete partially before lock contention forces abandonment\n- Object store operations that create objects but fail to update references\n- Merge operations that resolve some conflicts but encounter locking issues\n\nThe recovery strategy involves state validation and corrective action:\n\n1. During repository initialization, scan for signs of incomplete operations\n2. For each incomplete operation type, determine if completion is safe\n3. If completion is safe and beneficial, finish the operation automatically\n4. If completion is risky or impossible, roll back to the previous consistent state\n5. Log the recovery action for user awareness and debugging\n\n**Deadlock Prevention** ensures that multiple processes cannot create circular waiting conditions that would permanently block progress. While file-based locking reduces deadlock risk compared to more complex locking primitives, careful lock ordering prevents the remaining deadlock scenarios.\n\nThe deadlock prevention protocol establishes a global ordering for all repository locks:\n\n1. Object store locks (ordered by object hash)\n2. Index lock\n3. Reference locks (ordered alphabetically by reference name)\n4. Merge state locks\n\nAll operations must acquire locks in this predetermined order and release them in reverse order. Operations that cannot acquire all needed locks within the timeout period must release all locks and retry to avoid deadlock scenarios.\n\n⚠️ **Pitfall: Lock File Cleanup**\nLock files can accumulate over time if processes crash or are killed forcefully. Always implement cleanup logic that runs during normal operations to detect and remove orphaned locks. However, be very conservative about timing—removing a lock that's actually held by a slow operation can cause corruption.\n\n⚠️ **Pitfall: Cross-Platform File Locking**\nFile locking semantics vary across operating systems, particularly between Windows and Unix-like systems. Test your locking implementation thoroughly on all target platforms, and consider using advisory locks rather than mandatory locks for better portability and recovery options.\n\n### Implementation Guidance\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|--------------|-----------------|\n| Error Types | Python exceptions with custom hierarchy | Structured error enums with detailed context |\n| Logging | Python logging module with file handlers | Structured logging with correlation IDs |\n| File Locking | fcntl-based advisory locks (Unix) | Cross-platform locking with timeout |\n| Validation | Manual checks with custom validators | Schema-based validation with automatic checking |\n| Recovery | Interactive prompts with user choice | Automated recovery with safety checks |\n| Concurrency | Process-level coordination with lock files | Thread-safe operations with proper synchronization |\n\n#### Recommended File Structure\n\n```\nproject-root/\n  src/\n    git_impl/\n      errors/\n        __init__.py              ← error hierarchy and base classes\n        corruption.py            ← repository corruption errors\n        merge.py                 ← merge conflict and resolution errors  \n        concurrency.py           ← concurrent access errors\n      validation/\n        __init__.py              ← validation framework\n        repository.py            ← repository structure validation\n        objects.py               ← object integrity validation\n        references.py            ← reference consistency validation\n      recovery/\n        __init__.py              ← recovery orchestration\n        corruption.py            ← corruption detection and repair\n        merge.py                 ← merge conflict resolution workflows\n        locks.py                 ← lock management and cleanup\n      concurrency/\n        __init__.py              ← concurrency coordination\n        locks.py                 ← file-based locking implementation\n        coordination.py          ← process coordination patterns\n```\n\n#### Infrastructure Starter Code\n\n**Error Hierarchy Implementation:**\n\n```python\n\"\"\"\nGit error hierarchy for comprehensive error handling and recovery.\n\"\"\"\n\nclass GitError(Exception):\n    \"\"\"Base exception for all Git-related errors.\"\"\"\n    \n    def __init__(self, message: str, error_code: str = None, recoverable: bool = True):\n        super().__init__(message)\n        self.message = message\n        self.error_code = error_code\n        self.recoverable = recoverable\n        self.timestamp = time.time()\n\nclass CorruptionError(GitError):\n    \"\"\"Raised when repository corruption is detected.\"\"\"\n    \n    def __init__(self, component: str, details: str, corruption_type: str):\n        message = f\"Corruption detected in {component}: {details}\"\n        super().__init__(message, f\"CORRUPT_{corruption_type}\", recoverable=True)\n        self.component = component\n        self.corruption_type = corruption_type\n        self.details = details\n\nclass MergeConflictError(GitError):\n    \"\"\"Raised when merge conflicts require manual resolution.\"\"\"\n    \n    def __init__(self, conflicted_files: List[str], conflict_count: int):\n        message = f\"Merge conflicts in {len(conflicted_files)} files ({conflict_count} regions)\"\n        super().__init__(message, \"MERGE_CONFLICT\", recoverable=True)\n        self.conflicted_files = conflicted_files\n        self.conflict_count = conflict_count\n\nclass ConcurrencyError(GitError):\n    \"\"\"Raised when concurrent access prevents operation completion.\"\"\"\n    \n    def __init__(self, resource: str, operation: str, retry_possible: bool = True):\n        message = f\"Concurrent access conflict on {resource} during {operation}\"\n        super().__init__(message, \"CONCURRENCY_CONFLICT\", recoverable=retry_possible)\n        self.resource = resource\n        self.operation = operation\n        self.retry_possible = retry_possible\n```\n\n**File Lock Manager:**\n\n```python\n\"\"\"\nCross-platform file locking for safe concurrent repository access.\n\"\"\"\nimport os\nimport time\nimport fcntl\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom typing import Optional\n\nclass FileLock:\n    \"\"\"Advisory file lock for coordinating repository access.\"\"\"\n    \n    def __init__(self, lock_path: Path, timeout: float = 30.0):\n        self.lock_path = lock_path\n        self.timeout = timeout\n        self.lock_fd: Optional[int] = None\n        self.acquired = False\n    \n    def acquire(self) -> bool:\n        \"\"\"Acquire the lock, waiting up to timeout seconds.\"\"\"\n        start_time = time.time()\n        \n        while time.time() - start_time < self.timeout:\n            try:\n                # Create lock file exclusively\n                self.lock_fd = os.open(\n                    self.lock_path, \n                    os.O_CREAT | os.O_EXCL | os.O_WRONLY,\n                    0o644\n                )\n                \n                # Write lock metadata\n                lock_info = f\"pid={os.getpid()}\\ntime={time.time()}\\n\"\n                os.write(self.lock_fd, lock_info.encode())\n                os.fsync(self.lock_fd)\n                \n                self.acquired = True\n                return True\n                \n            except OSError as e:\n                if e.errno == errno.EEXIST:\n                    # Lock file exists, check if it's orphaned\n                    if self._check_orphaned_lock():\n                        continue  # Try again after cleanup\n                    time.sleep(0.1)  # Wait briefly before retry\n                else:\n                    raise ConcurrencyError(str(self.lock_path), \"lock_acquire\")\n        \n        return False\n    \n    def release(self):\n        \"\"\"Release the lock if currently held.\"\"\"\n        if self.acquired and self.lock_fd is not None:\n            os.close(self.lock_fd)\n            self.lock_path.unlink(missing_ok=True)\n            self.acquired = False\n            self.lock_fd = None\n\n@contextmanager\ndef repository_lock(git_dir: Path, operation: str):\n    \"\"\"Context manager for repository-wide locking.\"\"\"\n    lock_file = git_dir / f\"{operation}.lock\"\n    lock = FileLock(lock_file)\n    \n    try:\n        if not lock.acquire():\n            raise ConcurrencyError(str(lock_file), operation)\n        yield lock\n    finally:\n        lock.release()\n```\n\n#### Core Logic Skeletons\n\n**Repository Validation Framework:**\n\n```python\ndef validate_repository_state(git_dir: Path) -> List[str]:\n    \"\"\"\n    Comprehensive repository validation returning list of issues found.\n    \n    Returns:\n        List of validation error messages, empty if repository is valid\n    \"\"\"\n    errors = []\n    \n    # TODO 1: Validate basic directory structure exists and has correct permissions\n    # Check: .git directory, objects/, refs/, refs/heads/, refs/tags/\n    # Verify: Directory permissions are 0755, accessible to current user\n    \n    # TODO 2: Validate HEAD file exists and contains valid reference\n    # Check: HEAD file exists and is readable\n    # Verify: Content is either valid SHA-1 or symbolic reference format\n    \n    # TODO 3: Validate object store integrity\n    # Scan: All objects in .git/objects directory structure\n    # Verify: Each object file can be read, decompressed, and SHA-1 verified\n    \n    # TODO 4: Validate reference consistency\n    # Check: All reference files contain valid SHA-1 hashes\n    # Verify: Referenced commits exist in object store\n    \n    # TODO 5: Validate index file if present\n    # Check: Index file format and checksum\n    # Verify: All referenced objects exist\n    \n    return errors\n\ndef recover_corrupted_object(object_hash: str, object_store, working_dir: Path) -> bool:\n    \"\"\"\n    Attempt to recover a corrupted object from alternative sources.\n    \n    Returns:\n        True if recovery succeeded, False otherwise\n    \"\"\"\n    # TODO 1: Try re-reading object from disk (handle transient I/O errors)\n    # Use: Multiple read attempts with delays between attempts\n    \n    # TODO 2: For blob objects, attempt rebuild from working directory\n    # Check: If file exists in working directory with matching path\n    # Verify: Recompute hash and store if it matches expected hash\n    \n    # TODO 3: Check if object exists in index for recent staging\n    # Load: Current index entries\n    # Match: Object hash to staged files for potential recovery\n    \n    # TODO 4: Log recovery attempt results for debugging\n    # Record: What recovery methods were tried and their outcomes\n    \n    return False\n```\n\n**Merge Conflict Resolution:**\n\n```python\ndef resolve_merge_conflicts(conflicted_files: List[str], merge_info: Dict) -> WorkflowResult:\n    \"\"\"\n    Interactive merge conflict resolution workflow.\n    \n    Args:\n        conflicted_files: List of files containing merge conflicts\n        merge_info: Information about the merge operation (branches, commits)\n    \n    Returns:\n        WorkflowResult indicating resolution status and remaining conflicts\n    \"\"\"\n    resolved_files = []\n    remaining_conflicts = []\n    \n    # TODO 1: Present conflict summary to user\n    # Display: Number of conflicts, affected files, conflict types\n    # Offer: Resolution options (interactive, tool-based, manual)\n    \n    # TODO 2: For each conflicted file, detect conflict markers\n    # Scan: File content for <<<<<<< ======= >>>>>>> patterns\n    # Parse: Conflict regions and extract ours/theirs/base content\n    \n    # TODO 3: Offer resolution strategies for each conflict\n    # Options: Keep ours, keep theirs, manual edit, launch merge tool\n    # Validate: Ensure all conflict markers are removed after resolution\n    \n    # TODO 4: Track resolution progress and allow resumption\n    # Save: Resolution state to allow interruption and continuation\n    # Update: MERGE_PROGRESS file with completed resolutions\n    \n    # TODO 5: Validate complete resolution before allowing merge completion\n    # Check: No remaining conflict markers in any resolved files\n    # Verify: All conflicted files have been addressed\n    \n    return WorkflowResult(\n        status=WorkflowStatus.SUCCESS,\n        message=\"All conflicts resolved\",\n        files_changed=len(resolved_files),\n        conflicts=remaining_conflicts\n    )\n\ndef generate_conflict_markers(conflict: ConflictRegion, our_branch: str, their_branch: str) -> str:\n    \"\"\"\n    Generate standard Git conflict markers for a conflict region.\n    \n    Returns:\n        Formatted conflict markers with content from both sides\n    \"\"\"\n    # TODO 1: Format opening marker with our branch identifier\n    # Format: \"<<<<<<< {our_branch}\" or \"<<<<<<< HEAD\" for detached state\n    \n    # TODO 2: Add our content with proper line endings\n    # Include: All lines from our version of the conflict region\n    \n    # TODO 3: Add separator marker\n    # Insert: \"=======\" line to separate our content from theirs\n    \n    # TODO 4: Add their content with branch identifier\n    # Include: All lines from their version\n    # Format: \">>>>>>> {their_branch}\" closing marker\n    \n    # TODO 5: Optionally include base content for three-way conflicts\n    # Insert: \"||||||| merged common ancestors\" section if base differs\n    \n    return \"\"\n```\n\n#### Milestone Checkpoints\n\n**After implementing corruption detection:**\n```bash\n# Test repository validation\npython -m git_impl.validation.repository /path/to/repo\n\n# Expected output: List of validation results\n# Should detect: Missing directories, corrupted objects, invalid references\n# Should report: Specific error locations and types\n\n# Test object corruption recovery\necho \"test content\" > test.txt\npython -m git_impl add test.txt\n# Manually corrupt the blob object file\npython -m git_impl.recovery.corruption --scan --fix\n\n# Expected behavior: Detection of corrupted object, attempt recovery from working tree\n```\n\n**After implementing merge conflict resolution:**\n```bash\n# Create merge conflict scenario\ngit checkout -b feature\necho \"feature change\" >> file.txt\ngit add file.txt && git commit -m \"feature\"\n\ngit checkout main  \necho \"main change\" >> file.txt\ngit add file.txt && git commit -m \"main\"\n\npython -m git_impl.merge feature\n\n# Expected output: Conflict detection, interactive resolution prompt\n# Should create: Conflict markers in file.txt\n# Should provide: Resolution options and validation\n```\n\n#### Debugging Tips\n\n| Symptom | Likely Cause | Diagnosis | Fix |\n|---------|--------------|-----------|-----|\n| \"Object not found\" errors | Corrupted object store | Check .git/objects structure | Run repository validation |\n| Merge hangs indefinitely | Deadlock in file locking | Check for orphaned lock files | Remove old .lock files |\n| \"Repository corrupt\" on startup | Interrupted operation | Check for partial state files | Run corruption recovery |\n| Conflicts not detected properly | Three-way merge base error | Verify merge base calculation | Check commit history integrity |\n| Lock timeout errors | High concurrent access | Monitor lock file creation/deletion | Increase timeout or serialize operations |\n| Index corruption after crash | Non-atomic index write | Check index file permissions and size | Rebuild index from working tree |\n\n\n## Testing Strategy and Milestone Checkpoints\n\n> **Milestone(s):** This section provides comprehensive testing approaches for all eight milestones, with specific verification steps for each milestone and integration testing strategies to ensure compatibility with real Git.\n\n### Mental Model: The Quality Assurance Laboratory\n\nThink of testing your Git implementation like running a quality assurance laboratory for a manufacturing process. Each milestone represents a critical component that must pass rigorous inspection before moving to the next stage. Just as a car manufacturer tests each subsystem (engine, brakes, transmission) individually before assembling the complete vehicle, we must verify each Git component works correctly in isolation before testing the integrated system.\n\nThe testing laboratory has multiple inspection stations. **Unit testing** is like checking individual parts under a microscope - ensuring each bolt meets specifications. **Integration testing** is like testing how parts work together - does the engine properly connect to the transmission? **Compatibility testing** is like verifying your car can drive on the same roads as other vehicles - does your Git produce the same results as the official Git implementation?\n\nThe most crucial aspect of this testing laboratory is the **golden standard comparison**. Just as manufacturers compare their products against industry standards, we compare our Git implementation against the official Git behavior. Every hash, every file format, every command output must match exactly. This isn't just about correctness - it's about ensuring users can seamlessly switch between your implementation and official Git without any surprises.\n\n### Milestone Verification Steps\n\nEach milestone builds upon previous ones, creating a dependency chain that requires careful validation. The verification approach uses both **black-box testing** (testing external behavior) and **white-box testing** (verifying internal state). The key insight is that Git's deterministic nature means identical inputs should always produce identical outputs, making automated verification straightforward.\n\n#### Milestone 1: Repository Initialization Verification\n\nRepository initialization is the foundation - if the directory structure is incorrect, all subsequent operations will fail mysteriously. The verification process must check both the presence and exact contents of each required file and directory.\n\n| Verification Step | Command | Expected Result | Validation Method |\n|------------------|---------|------------------|-------------------|\n| Directory Structure Creation | `ls -la .git/` | Shows objects/, refs/, HEAD with correct permissions | Directory existence and permissions check |\n| Objects Directory Layout | `ls -la .git/objects/` | Empty directory with proper subdirectory structure | Subdirectory count and permissions |\n| References Directory | `ls -la .git/refs/` | Contains heads/ and tags/ subdirectories | Directory structure validation |\n| HEAD File Content | `cat .git/HEAD` | Exactly \"ref: refs/heads/master\\n\" | String comparison with newline |\n| Git Recognition | `git status` (using official Git) | Recognizes as valid Git repository | Official Git compatibility test |\n\nThe most critical validation is ensuring the HEAD file contains the exact string format. Many implementations fail because they forget the newline character or use incorrect reference syntax.\n\n**Detailed Verification Procedure:**\n\n1. **Structure Validation**: Use `find .git -type d` to list all directories and compare against the expected structure. The output should include `.git/objects/`, `.git/refs/`, `.git/refs/heads/`, `.git/refs/tags/`, and `.git/hooks/`.\n\n2. **Permissions Check**: Verify directory permissions using `stat -c '%a' .git/` - should return `755` for proper read/write/execute permissions.\n\n3. **HEAD Content Validation**: Read the HEAD file byte-by-byte and compare against the expected content. The file must contain exactly 21 bytes: \"ref: refs/heads/master\" followed by a newline character (0x0A).\n\n4. **Official Git Compatibility**: Run `git rev-parse --git-dir` using official Git - it should return `.git` without errors, confirming the repository structure is valid.\n\n5. **Empty Repository State**: Verify `git log` returns \"fatal: your current branch 'master' does not have any commits yet\" - this confirms the repository is properly initialized but empty.\n\n#### Milestone 2: Object Storage (Blobs) Verification\n\nBlob storage is the foundation of Git's content-addressable system. Every aspect must match official Git exactly - hash computation, compression, file paths, and retrieval. The verification process focuses on round-trip consistency and hash determinism.\n\n| Verification Step | Test Input | Expected Hash | Validation Method |\n|------------------|------------|---------------|-------------------|\n| Empty File Hash | `\"\"` (empty string) | `e69de29bb2d1d6434b8b29ae775ad8c2e48c5391` | Hash comparison with official Git |\n| Simple Text Hash | `\"hello world\"` | `95d09f2b10159347eece71399a7e2e907ea3df4f` | Hash comparison with official Git |\n| Binary Content Hash | Random 1KB binary data | Must match `git hash-object` output | Binary content handling test |\n| Large File Hash | 10MB text file | Must match official Git hash | Performance and correctness test |\n| Round-trip Consistency | Any content | `cat-file` output matches original input | Storage and retrieval verification |\n\nThe hash computation must implement the exact Git algorithm: `SHA1(\"blob \" + content_length + \"\\0\" + content)`. Many implementations fail by forgetting the space after \"blob\" or using incorrect size formatting.\n\n**Detailed Verification Procedure:**\n\n1. **Hash Algorithm Verification**: Create a test file with known content and verify your hash matches official Git exactly. Use `echo -n \"test content\" | git hash-object --stdin` as the reference.\n\n2. **File Path Generation**: Verify your implementation creates the correct object path. For hash `abc123...`, the file should be stored at `.git/objects/ab/c123...` with the first two characters forming the directory name.\n\n3. **Compression Verification**: Decompress stored objects manually using Python's zlib and verify the content matches the expected format: `blob {size}\\0{content}`.\n\n4. **Binary Content Handling**: Test with files containing null bytes, non-UTF8 content, and various binary formats. Git treats all content as binary internally.\n\n5. **Performance Baseline**: Measure hash computation and storage time for various file sizes. Your implementation should handle files up to several megabytes without excessive memory usage.\n\n**Cross-Implementation Testing**:\n```bash\n# Create test file\necho \"test content\" > test.txt\n\n# Hash with your implementation\n./your-git hash-object test.txt\n\n# Hash with official Git\ngit hash-object test.txt\n\n# Both should produce identical output\n```\n\n#### Milestone 3: Tree Objects Verification\n\nTree objects represent directory structures and must maintain exact sorting and binary format compatibility with official Git. The verification focuses on directory traversal, entry sorting, and nested tree creation.\n\n| Verification Step | Test Scenario | Expected Behavior | Validation Method |\n|------------------|---------------|-------------------|-------------------|\n| Single File Tree | Directory with one file | Tree with single blob entry | Tree content comparison |\n| Sorted Entries | Files: z.txt, a.txt, m.txt | Tree entries sorted alphabetically | Entry order verification |\n| Nested Directories | Subdirectory with files | Parent tree references child tree | Tree hierarchy validation |\n| Mixed Content Types | Files and subdirectories | Correct mode values (100644, 040000) | Mode field verification |\n| Empty Directory Handling | Empty subdirectory | Directory not included in tree | Git's empty directory behavior |\n\nTree objects use a specific binary format where each entry is: `{mode} {name}\\0{20-byte-hash}`. The mode values are crucial - regular files use `100644`, executable files use `100755`, and directories use `040000`.\n\n**Detailed Verification Procedure:**\n\n1. **Entry Sorting Verification**: Create a directory with files named in non-alphabetical order. Verify your tree object lists entries in exact alphabetical order, matching `git ls-tree` output.\n\n2. **Binary Format Validation**: Extract a tree object and verify the binary format byte-by-byte. Each entry should be null-terminated, followed by exactly 20 bytes of binary hash data.\n\n3. **Mode Value Accuracy**: Test files with different permissions and verify the mode values match Git's behavior. Use `git ls-tree -l` to see detailed mode information.\n\n4. **Nested Tree Verification**: Create a directory structure with subdirectories and verify your implementation creates the correct tree hierarchy. Each subdirectory should become a separate tree object referenced by its parent.\n\n5. **Hash Consistency**: Build the same directory structure twice and verify identical tree hashes are produced. Tree building must be deterministic.\n\n#### Milestone 4: Commit Objects Verification\n\nCommit objects tie together trees, parents, and metadata to form Git's history graph. Verification must ensure exact format compatibility and proper parent linking.\n\n| Verification Step | Test Case | Expected Format | Validation Method |\n|------------------|-----------|-----------------|-------------------|\n| Initial Commit | Commit with no parents | No parent field in commit object | Commit format verification |\n| Parent Linking | Commit with one parent | Single parent line with hash | Parent reference validation |\n| Merge Commit | Commit with two parents | Multiple parent lines | Multi-parent commit handling |\n| Author/Committer Data | Different author and committer | Separate author/committer lines with timestamps | Metadata format verification |\n| Message Handling | Multi-line commit message | Message separated by blank line | Message format validation |\n\nCommit objects follow a strict text format with specific field ordering and timestamp formatting. The timestamp format is Unix epoch seconds followed by timezone offset (e.g., `1609459200 +0000`).\n\n**Detailed Verification Procedure:**\n\n1. **Commit Format Validation**: Create commits and verify the object format matches `git cat-file commit <hash>` exactly. Field order is: tree, parent(s), author, committer, blank line, message.\n\n2. **Timestamp Format**: Verify timestamps use Unix epoch format with timezone. Compare your output with `git log --format=fuller` to ensure exact match.\n\n3. **Parent Chain Verification**: Create multiple commits and verify the parent relationships form a proper chain. Each commit should reference its predecessor correctly.\n\n4. **Character Encoding**: Test commits with non-ASCII characters in messages and author names. Git uses UTF-8 encoding internally.\n\n5. **Empty Message Handling**: Test commits with empty messages and verify they're handled correctly (Git allows empty messages).\n\n#### Milestone 5: References and Branches Verification\n\nReferences provide human-readable names for commits and must handle both symbolic and direct references correctly. The verification focuses on file-based storage and HEAD state management.\n\n| Verification Step | Test Operation | Expected Outcome | Validation Method |\n|------------------|----------------|------------------|-------------------|\n| Branch Creation | Create branch \"feature\" | File `.git/refs/heads/feature` contains commit hash | File content verification |\n| HEAD Update | Switch to branch | HEAD contains `ref: refs/heads/feature` | Symbolic reference validation |\n| Detached HEAD | Checkout specific commit | HEAD contains raw commit hash | Direct reference handling |\n| Branch Deletion | Delete branch | Reference file removed | File system state check |\n| Invalid Names | Create branch with invalid characters | Operation fails with clear error | Error handling validation |\n\nReference files are plain text containing either a commit hash (direct reference) or a symbolic reference in the format `ref: refs/heads/branch-name`.\n\n**Detailed Verification Procedure:**\n\n1. **Reference File Format**: Create branches and verify the reference files contain exactly 41 characters - 40 hex digits for the hash plus a newline character.\n\n2. **Symbolic Reference Handling**: Switch branches and verify HEAD is updated to point to the correct branch reference, not the commit hash directly.\n\n3. **Detached HEAD State**: Checkout a specific commit and verify HEAD contains the raw hash. Test that subsequent commits update HEAD directly rather than through a branch.\n\n4. **Branch Namespace**: Test branch names with slashes (e.g., `feature/login`) and verify the directory structure is created correctly under `.git/refs/heads/`.\n\n5. **Concurrent Access**: Test rapid branch creation/deletion to ensure file operations are atomic and don't leave partially written files.\n\n#### Milestone 6: Index (Staging Area) Verification\n\nThe index is Git's most complex binary format, requiring exact compatibility for field layouts, checksums, and metadata handling. Verification must cover all aspects of the binary format specification.\n\n| Verification Step | Test Scenario | Expected Behavior | Validation Method |\n|------------------|---------------|-------------------|-------------------|\n| File Staging | Add single file | Index entry with correct metadata | Binary format parsing |\n| Multiple Files | Stage several files | Entries sorted by path | Entry ordering validation |\n| File Modification | Modify staged file | Status shows modified state | Three-way comparison accuracy |\n| Index Checksum | Any index operation | Valid SHA-1 checksum at file end | Checksum verification |\n| Metadata Accuracy | Stage file with specific timestamps | Index preserves exact metadata | Metadata comparison |\n\nThe index binary format includes a 12-byte header, variable-length entries, and a 20-byte SHA-1 checksum. Each entry contains extensive file metadata for change detection.\n\n**Detailed Verification Procedure:**\n\n1. **Binary Format Compliance**: Parse index files created by official Git and verify your implementation can read them correctly. Also verify official Git can read your index files.\n\n2. **Checksum Validation**: Verify the SHA-1 checksum at the end of index files. Any corruption should be detected when loading the index.\n\n3. **Metadata Preservation**: Stage files and verify all metadata (timestamps, file size, permissions, device/inode numbers) is stored and retrieved accurately.\n\n4. **Path Sorting**: Stage files with various path names and verify they're stored in correct sort order. The sorting algorithm affects index format compatibility.\n\n5. **Partial Updates**: Test staging individual files multiple times and verify the index is updated correctly without corrupting other entries.\n\n#### Milestone 7: Diff Algorithm Verification\n\nThe Myers diff algorithm must produce output that matches Git's diff format exactly, including context lines, hunk headers, and binary file detection.\n\n| Verification Step | Test Case | Expected Output | Validation Method |\n|------------------|-----------|------------------|-------------------|\n| Simple Addition | Add lines to file | Unified diff with + markers | Output format comparison |\n| Line Deletion | Remove lines from file | Unified diff with - markers | Deletion marking accuracy |\n| Line Modification | Change existing lines | Shows as deletion + addition | Edit sequence accuracy |\n| Context Lines | Large file changes | Correct @@ hunk headers with line numbers | Hunk formatting validation |\n| Binary Files | Binary file changes | \"Binary files differ\" message | Binary detection accuracy |\n\nThe unified diff format includes specific hunk headers with old and new line number ranges, plus context lines around changes.\n\n**Detailed Verification Procedure:**\n\n1. **Algorithm Correctness**: Test the Myers algorithm against known inputs with verified shortest edit scripts. The algorithm must find optimal solutions.\n\n2. **Unified Format Compliance**: Compare your diff output with `git diff` for identical files. Header format, line prefixes, and hunk boundaries must match exactly.\n\n3. **Binary Detection**: Test various file types (images, executables, text with null bytes) and verify binary detection matches Git's heuristics.\n\n4. **Large File Performance**: Test diff performance with large files (thousands of lines) and verify the algorithm completes in reasonable time.\n\n5. **Edge Cases**: Test empty files, single-line files, files with only whitespace changes, and files with no final newline.\n\n#### Milestone 8: Three-Way Merge Verification\n\nThree-way merge is the most complex operation, requiring correct merge base calculation, conflict detection, and merge commit creation. Verification must cover all merge scenarios.\n\n| Verification Step | Test Scenario | Expected Result | Validation Method |\n|------------------|---------------|------------------|------------------|\n| Fast-Forward Merge | One branch is ancestor of other | Branch pointer update only | Merge strategy detection |\n| Clean Merge | Non-overlapping changes | Automatic merge completion | Conflict-free merging |\n| Content Conflict | Overlapping line changes | Conflict markers in file | Conflict detection accuracy |\n| Merge Base Calculation | Complex branch history | Correct common ancestor | Graph traversal validation |\n| Merge Commit Creation | Successful merge | Commit with two parents | Multi-parent commit handling |\n\nThe merge algorithm must handle various conflict types and produce standard conflict markers compatible with Git's format.\n\n**Detailed Verification Procedure:**\n\n1. **Merge Base Accuracy**: Create complex branch histories and verify merge base calculation matches `git merge-base` output exactly.\n\n2. **Conflict Marker Format**: Create conflicting changes and verify conflict markers match Git's format exactly, including branch name labels.\n\n3. **Three-Way Algorithm**: Test merge scenarios where base, ours, and theirs all differ, ensuring the algorithm correctly identifies conflicting vs. non-conflicting regions.\n\n4. **File-Level Conflicts**: Test scenarios where files are added, deleted, or modified in conflicting ways across branches.\n\n5. **Performance Testing**: Test merge performance with large files and many conflicts to ensure the algorithm scales reasonably.\n\n### Integration Testing Approach\n\nIntegration testing verifies that your Git implementation behaves identically to official Git across complete workflows. The approach uses **comparative testing** where every operation is performed with both implementations and results are compared.\n\n#### Golden Standard Testing Framework\n\nThe golden standard approach treats official Git as the authoritative reference. Every test scenario is executed with both your implementation and official Git, with results compared byte-for-byte where applicable.\n\n| Testing Layer | Scope | Comparison Method | Failure Handling |\n|---------------|--------|-------------------|------------------|\n| Object Compatibility | Individual objects | Hash and content comparison | Object format debugging |\n| Repository State | Complete repository state | File system diff of .git directory | State reconstruction analysis |\n| Command Output | User-visible output | String comparison with normalization | Output format adjustment |\n| File Content | Working directory files | Byte-by-byte comparison | Content merge verification |\n| Performance Baseline | Operation timing | Relative performance comparison | Performance regression detection |\n\nThe framework must handle **environment differences** that don't indicate implementation bugs. For example, timestamps will differ between test runs, so they must be normalized or ignored during comparison.\n\n#### Test Scenario Categories\n\n**Basic Workflow Testing** covers the fundamental Git operations that users perform daily. These scenarios must work flawlessly as they form the foundation of version control workflows.\n\n1. **Repository Lifecycle**: Initialize repository, add files, create commits, view history. This tests the basic object creation and storage pipeline.\n\n2. **Branch Operations**: Create branches, switch branches, merge branches. This tests the reference management and merge algorithms.\n\n3. **Staging Operations**: Stage files, unstage files, partial staging. This tests the index management and status calculation.\n\n4. **History Navigation**: Checkout previous commits, view diffs between versions. This tests object retrieval and diff algorithms.\n\n5. **Merge Scenarios**: Fast-forward merges, three-way merges, conflict resolution. This tests the most complex algorithms in your implementation.\n\n**Edge Case Testing** covers unusual but valid Git operations that might expose implementation bugs or missing functionality.\n\n| Edge Case Category | Test Scenarios | Common Failure Points |\n|--------------------|----------------|----------------------|\n| Empty Content | Empty files, empty directories, empty commits | Null pointer handling, zero-length content |\n| Large Content | Large files, many files, deep directory trees | Memory usage, performance degradation |\n| Special Characters | Unicode filenames, binary content, line endings | Character encoding, binary detection |\n| Concurrent Operations | Multiple processes modifying repository | File locking, atomic operations |\n| Corrupted State | Missing objects, invalid references, corrupted index | Error detection, graceful degradation |\n\n**Cross-Platform Testing** ensures your implementation works consistently across different operating systems and file systems.\n\n- **File System Differences**: Test on case-sensitive and case-insensitive file systems. Some Git operations behave differently based on file system capabilities.\n\n- **Path Separator Handling**: Verify path normalization works correctly on Windows (backslashes) and Unix (forward slashes).\n\n- **Permission Model Differences**: Test file permissions and executable bit handling across platforms where permission models differ.\n\n- **Line Ending Handling**: Test files with different line ending conventions (LF, CRLF, mixed) to ensure consistent behavior.\n\n#### Automated Compatibility Verification\n\nThe compatibility verification system runs automated test suites that compare your implementation against official Git across hundreds of scenarios. The system must handle the inherent non-determinism in some Git operations (like timestamps) while catching genuine compatibility issues.\n\n**Test Data Generation** creates comprehensive test scenarios programmatically rather than maintaining large test fixtures. This ensures broad coverage without overwhelming the test suite with data.\n\n```\nTest Repository Generator:\n1. Generate random file content with various characteristics\n2. Create random directory structures with different depths\n3. Simulate realistic commit histories with merges and branches\n4. Create conflict scenarios with overlapping changes\n5. Generate edge cases (empty files, binary content, special names)\n```\n\n**Result Comparison Engine** handles the complex task of comparing Git repository states while accounting for acceptable differences.\n\n| Comparison Aspect | Exact Match Required | Acceptable Differences | Normalization Method |\n|-------------------|---------------------|------------------------|---------------------|\n| Object Hashes | Yes | None | Direct string comparison |\n| Object Content | Yes | None | Byte-by-byte comparison |\n| Reference Values | Yes | None | Hash comparison |\n| File Timestamps | No | Any difference | Ignore during comparison |\n| Commit Timestamps | No | Any difference | Normalize to fixed value |\n| Author Information | Yes | None | String comparison |\n| File Permissions | Yes | None | Octal comparison |\n\n**Regression Testing** maintains a suite of previously passing tests to ensure new changes don't break existing functionality. The regression suite includes both successful operations and expected failures.\n\n#### Performance and Scalability Testing\n\nPerformance testing ensures your Git implementation scales reasonably with repository size and complexity. While exact performance parity with official Git isn't required, your implementation should handle realistic workloads without excessive resource consumption.\n\n**Scalability Test Scenarios:**\n\n| Scale Factor | Repository Size | File Count | Commit History | Expected Behavior |\n|--------------|----------------|------------|----------------|-------------------|\n| Small | < 10MB | < 100 files | < 50 commits | Sub-second operations |\n| Medium | 10-100MB | 100-1000 files | 50-500 commits | Operations complete in seconds |\n| Large | 100MB-1GB | 1000-10000 files | 500-5000 commits | Operations complete in minutes |\n| Stress Test | > 1GB | > 10000 files | > 5000 commits | Graceful degradation, no crashes |\n\n**Memory Usage Monitoring** ensures your implementation doesn't have memory leaks or excessive memory consumption during normal operations.\n\n**Performance Regression Detection** compares operation timing across implementation versions to catch performance regressions early.\n\n### Common Testing Pitfalls\n\nUnderstanding common testing mistakes helps avoid frustration and ensures your testing efforts are effective. These pitfalls are based on frequent issues encountered when building Git implementations.\n\n⚠️ **Pitfall: Ignoring Byte-Level Compatibility**\n\nMany implementers focus on functional correctness while ignoring exact byte-level compatibility with Git's formats. This leads to repositories that work with your implementation but fail when accessed by official Git.\n\n**Why it's problematic**: Git's binary formats (index file, pack files, object formats) have specific layouts that must be followed exactly. Even single-byte differences can cause incompatibility.\n\n**How to avoid**: Always test round-trip compatibility - create objects with your implementation and verify official Git can read them, and vice versa. Use hex dumps to compare binary formats byte-by-byte when debugging.\n\n⚠️ **Pitfall: Testing Only Happy Paths**\n\nFocusing testing on successful operations while ignoring error conditions and edge cases leads to implementations that fail unexpectedly in real-world usage.\n\n**Why it's problematic**: Real Git repositories encounter corrupted files, network failures, concurrent access, and unusual content. Your implementation must handle these gracefully.\n\n**How to avoid**: Dedicate significant testing effort to error conditions. Test with corrupted objects, missing files, invalid references, and concurrent operations. Verify error messages are helpful and recovery is possible.\n\n⚠️ **Pitfall: Timestamp and Environment Dependencies**\n\nWriting tests that depend on specific timestamps, user information, or system configuration makes tests brittle and difficult to reproduce across different environments.\n\n**Why it's problematic**: Tests fail randomly based on when they're run or what system they're run on, making it difficult to distinguish real bugs from environmental issues.\n\n**How to avoid**: Use fixed timestamps and author information in tests. Normalize or ignore environment-specific data when comparing results. Use dependency injection to control environmental factors.\n\n⚠️ **Pitfall: Insufficient Cross-Platform Testing**\n\nTesting only on one operating system misses compatibility issues that arise from file system differences, path handling, and permission models.\n\n**Why it's problematic**: Git repositories are often shared across different operating systems. Incompatibilities can corrupt repositories or cause data loss.\n\n**How to avoid**: Test on multiple platforms, especially Windows and Linux. Pay special attention to path separators, case sensitivity, and file permissions. Use continuous integration to automate cross-platform testing.\n\n⚠️ **Pitfall: Missing Performance Reality Checks**\n\nImplementing algorithms without testing performance on realistic data sizes leads to implementations that work on small test cases but become unusable on real repositories.\n\n**Why it's problematic**: Algorithms with poor complexity (like O(n²) diff algorithms) work fine on small test files but become unusably slow on large files or repositories.\n\n**How to avoid**: Include performance tests with realistic data sizes in your test suite. Set reasonable performance expectations and fail tests that exceed them. Profile your implementation to identify bottlenecks.\n\n### Integration with Development Workflow\n\nThe testing strategy must integrate seamlessly with the development workflow to provide rapid feedback and prevent regressions. The approach uses multiple testing layers triggered at different points in the development process.\n\n**Pre-commit Testing** runs quickly during development to catch obvious bugs before they're committed to version control.\n\n**Continuous Integration Testing** runs comprehensive test suites on every code change, including cross-platform and performance testing.\n\n**Release Testing** performs exhaustive compatibility testing before releasing new versions, including testing against multiple Git versions and large real-world repositories.\n\n### Implementation Guidance\n\nThe testing implementation requires careful attention to automation, reliability, and maintainability. The goal is creating a testing framework that provides confidence in your Git implementation while being practical to maintain and extend.\n\n#### Technology Recommendations\n\n| Testing Component | Simple Option | Advanced Option |\n|------------------|---------------|-----------------|\n| Test Framework | pytest with subprocess calls | Custom test harness with Git process management |\n| Repository Setup | Manual git init in test directories | Programmatic repository generation with GitPython |\n| Result Comparison | String comparison with basic normalization | AST-based parsing and semantic comparison |\n| Performance Testing | Manual timing with time.time() | pytest-benchmark with statistical analysis |\n| Cross-Platform Testing | Manual testing on multiple systems | GitHub Actions matrix builds |\n\n#### Recommended Testing File Structure\n\n```\nbuild-your-own-git/\n├── tests/\n│   ├── unit/                    # Unit tests for individual components\n│   │   ├── test_object_store.py\n│   │   ├── test_index.py\n│   │   ├── test_references.py\n│   │   └── test_diff_algorithm.py\n│   ├── integration/             # Integration tests comparing with official Git\n│   │   ├── test_basic_workflow.py\n│   │   ├── test_branch_operations.py\n│   │   ├── test_merge_scenarios.py\n│   │   └── test_compatibility.py\n│   ├── milestone/               # Milestone-specific verification tests\n│   │   ├── test_milestone_1.py  # Repository initialization\n│   │   ├── test_milestone_2.py  # Blob storage\n│   │   └── ...\n│   ├── fixtures/                # Test data and repository templates\n│   │   ├── sample_repos/\n│   │   ├── binary_files/\n│   │   └── conflict_scenarios/\n│   └── utils/                   # Testing utilities and helpers\n│       ├── git_comparison.py    # Compare with official Git\n│       ├── repo_generator.py    # Generate test repositories\n│       └── binary_parser.py     # Parse Git binary formats\n├── src/\n│   └── your_git/               # Your Git implementation\n└── conftest.py                 # pytest configuration and fixtures\n```\n\n#### Infrastructure Starter Code\n\n**Git Comparison Utility** provides a complete framework for comparing your implementation with official Git:\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nGit Comparison Utility - Complete implementation for comparing custom Git with official Git.\nThis utility handles environment normalization and result comparison.\n\"\"\"\n\nimport os\nimport subprocess\nimport tempfile\nimport shutil\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple, Any\nimport hashlib\nimport json\n\nclass GitComparison:\n    \"\"\"Utility for comparing custom Git implementation with official Git.\"\"\"\n    \n    def __init__(self, custom_git_path: str, official_git_path: str = \"git\"):\n        self.custom_git = custom_git_path\n        self.official_git = official_git_path\n        self.test_dir = None\n        self.comparison_results = []\n    \n    def setup_test_environment(self) -> Path:\n        \"\"\"Create isolated test directory with proper Git environment.\"\"\"\n        self.test_dir = Path(tempfile.mkdtemp(prefix=\"git_test_\"))\n        \n        # Set consistent Git environment\n        os.environ.update({\n            'GIT_AUTHOR_NAME': 'Test Author',\n            'GIT_AUTHOR_EMAIL': 'test@example.com',\n            'GIT_COMMITTER_NAME': 'Test Committer',\n            'GIT_COMMITTER_EMAIL': 'test@example.com',\n            'GIT_AUTHOR_DATE': '2021-01-01T12:00:00Z',\n            'GIT_COMMITTER_DATE': '2021-01-01T12:00:00Z'\n        })\n        \n        return self.test_dir\n    \n    def cleanup_test_environment(self):\n        \"\"\"Remove test directory and reset environment.\"\"\"\n        if self.test_dir and self.test_dir.exists():\n            shutil.rmtree(self.test_dir)\n        self.test_dir = None\n    \n    def run_command(self, git_binary: str, args: List[str], cwd: Path) -> Tuple[int, str, str]:\n        \"\"\"Run Git command and return exit code, stdout, stderr.\"\"\"\n        try:\n            result = subprocess.run(\n                [git_binary] + args,\n                cwd=cwd,\n                capture_output=True,\n                text=True,\n                timeout=30\n            )\n            return result.returncode, result.stdout, result.stderr\n        except subprocess.TimeoutExpired:\n            return -1, \"\", \"Command timed out\"\n        except Exception as e:\n            return -1, \"\", f\"Command failed: {e}\"\n    \n    def normalize_output(self, output: str, operation: str) -> str:\n        \"\"\"Normalize output for comparison, handling acceptable differences.\"\"\"\n        lines = output.strip().split('\\n')\n        normalized_lines = []\n        \n        for line in lines:\n            # Remove timestamp variations for certain operations\n            if operation in ['log', 'show'] and 'Date:' in line:\n                continue  # Skip timestamp lines\n            \n            # Normalize path separators\n            line = line.replace('\\\\', '/')\n            \n            # Remove trailing whitespace\n            line = line.rstrip()\n            \n            normalized_lines.append(line)\n        \n        return '\\n'.join(normalized_lines)\n    \n    def compare_repository_state(self, repo_path: Path) -> Dict[str, Any]:\n        \"\"\"Compare complete repository state between implementations.\"\"\"\n        state_comparison = {\n            'objects_match': True,\n            'refs_match': True,\n            'index_match': True,\n            'differences': []\n        }\n        \n        git_dir = repo_path / '.git'\n        if not git_dir.exists():\n            state_comparison['differences'].append(\"No .git directory found\")\n            return state_comparison\n        \n        # Compare object store\n        objects_dir = git_dir / 'objects'\n        if objects_dir.exists():\n            for obj_dir in objects_dir.iterdir():\n                if obj_dir.is_dir() and len(obj_dir.name) == 2:\n                    for obj_file in obj_dir.iterdir():\n                        obj_hash = obj_dir.name + obj_file.name\n                        # Verify object can be read by both implementations\n                        custom_result = self.run_command(\n                            self.custom_git, ['cat-file', '-p', obj_hash], repo_path\n                        )\n                        official_result = self.run_command(\n                            self.official_git, ['cat-file', '-p', obj_hash], repo_path\n                        )\n                        \n                        if custom_result[1] != official_result[1]:\n                            state_comparison['objects_match'] = False\n                            state_comparison['differences'].append(\n                                f\"Object {obj_hash} content differs\"\n                            )\n        \n        return state_comparison\n```\n\n**Repository Generator** creates test repositories programmatically:\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nRepository Generator - Creates test repositories with various characteristics.\n\"\"\"\n\nimport os\nimport random\nimport string\nfrom pathlib import Path\nfrom typing import List, Dict, Any\nimport tempfile\n\nclass TestRepositoryGenerator:\n    \"\"\"Generate Git repositories for testing various scenarios.\"\"\"\n    \n    def __init__(self, base_dir: Path):\n        self.base_dir = base_dir\n        self.base_dir.mkdir(exist_ok=True)\n    \n    def create_simple_repository(self, name: str) -> Path:\n        \"\"\"Create a simple repository with a few commits.\"\"\"\n        repo_path = self.base_dir / name\n        repo_path.mkdir(exist_ok=True)\n        \n        # Initialize repository\n        os.system(f\"cd {repo_path} && git init\")\n        \n        # Create initial commit\n        (repo_path / \"README.md\").write_text(\"# Test Repository\\n\")\n        os.system(f\"cd {repo_path} && git add README.md && git commit -m 'Initial commit'\")\n        \n        # Create second commit\n        (repo_path / \"file1.txt\").write_text(\"Content of file 1\\n\")\n        os.system(f\"cd {repo_path} && git add file1.txt && git commit -m 'Add file1'\")\n        \n        return repo_path\n    \n    def create_merge_scenario(self, name: str) -> Path:\n        \"\"\"Create repository with merge scenario for testing.\"\"\"\n        repo_path = self.base_dir / name\n        repo_path.mkdir(exist_ok=True)\n        \n        os.system(f\"cd {repo_path} && git init\")\n        \n        # Create main branch commits\n        (repo_path / \"main.txt\").write_text(\"Main branch content\\n\")\n        os.system(f\"cd {repo_path} && git add main.txt && git commit -m 'Main commit'\")\n        \n        # Create feature branch\n        os.system(f\"cd {repo_path} && git checkout -b feature\")\n        (repo_path / \"feature.txt\").write_text(\"Feature branch content\\n\")\n        os.system(f\"cd {repo_path} && git add feature.txt && git commit -m 'Feature commit'\")\n        \n        # Return to main and create conflicting change\n        os.system(f\"cd {repo_path} && git checkout main\")\n        (repo_path / \"main.txt\").write_text(\"Modified main branch content\\n\")\n        os.system(f\"cd {repo_path} && git add main.txt && git commit -m 'Main modification'\")\n        \n        return repo_path\n    \n    def generate_random_content(self, size: int, binary: bool = False) -> bytes:\n        \"\"\"Generate random content for testing.\"\"\"\n        if binary:\n            return bytes(random.randint(0, 255) for _ in range(size))\n        else:\n            chars = string.ascii_letters + string.digits + '\\n \\t'\n            return ''.join(random.choice(chars) for _ in range(size)).encode('utf-8')\n```\n\n#### Core Logic Skeleton Code\n\n**Milestone Verification Test Template**:\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nMilestone Verification Template - Complete test structure for milestone validation.\n\"\"\"\n\nimport pytest\nimport tempfile\nimport subprocess\nfrom pathlib import Path\nfrom typing import List, Dict, Any\n\nclass MilestoneVerifier:\n    \"\"\"Base class for milestone verification tests.\"\"\"\n    \n    def __init__(self, git_implementation_path: str):\n        self.git_path = git_implementation_path\n        self.test_repo = None\n    \n    def setup_test_repo(self) -> Path:\n        \"\"\"Create temporary test repository.\"\"\"\n        # TODO 1: Create temporary directory for test repository\n        # TODO 2: Set consistent Git environment variables (author, committer, dates)\n        # TODO 3: Return path to test repository\n        pass\n    \n    def cleanup_test_repo(self):\n        \"\"\"Clean up temporary test repository.\"\"\"\n        # TODO 1: Remove temporary directory if it exists\n        # TODO 2: Reset environment variables if needed\n        pass\n    \n    def run_git_command(self, args: List[str]) -> tuple[int, str, str]:\n        \"\"\"Run Git command with your implementation.\"\"\"\n        # TODO 1: Build command line with git_path and args\n        # TODO 2: Execute command in test repository directory\n        # TODO 3: Return (exit_code, stdout, stderr) tuple\n        # TODO 4: Handle timeout and other execution errors\n        pass\n    \n    def verify_file_exists(self, file_path: Path, expected_content: str = None) -> bool:\n        \"\"\"Verify file exists and optionally check content.\"\"\"\n        # TODO 1: Check if file exists at expected path\n        # TODO 2: If expected_content provided, read file and compare\n        # TODO 3: Return True if verification passes, False otherwise\n        pass\n    \n    def compare_with_official_git(self, command: List[str]) -> bool:\n        \"\"\"Compare command output with official Git.\"\"\"\n        # TODO 1: Run command with your implementation\n        # TODO 2: Run same command with official Git\n        # TODO 3: Normalize outputs (remove timestamps, etc.)\n        # TODO 4: Return True if outputs match, False otherwise\n        pass\n\nclass Milestone1Verifier(MilestoneVerifier):\n    \"\"\"Verify Milestone 1: Repository Initialization.\"\"\"\n    \n    def test_git_init(self):\n        \"\"\"Test repository initialization creates correct structure.\"\"\"\n        # TODO 1: Run 'init' command in test directory\n        # TODO 2: Verify .git directory exists with correct permissions\n        # TODO 3: Verify .git/objects directory exists with subdirectories\n        # TODO 4: Verify .git/refs/heads directory exists\n        # TODO 5: Verify HEAD file exists with correct content\n        # TODO 6: Test official Git recognizes repository as valid\n        pass\n    \n    def test_directory_structure(self):\n        \"\"\"Verify complete .git directory structure.\"\"\"\n        # TODO 1: Initialize repository\n        # TODO 2: Check all required directories exist: objects, refs, refs/heads, refs/tags\n        # TODO 3: Check directory permissions are correct (0755)\n        # TODO 4: Verify no extra files or directories are created\n        pass\n    \n    def test_head_file_format(self):\n        \"\"\"Verify HEAD file has exact correct format.\"\"\"\n        # TODO 1: Initialize repository\n        # TODO 2: Read HEAD file content as bytes\n        # TODO 3: Verify content is exactly \"ref: refs/heads/master\\n\"\n        # TODO 4: Verify file has exactly 21 bytes\n        pass\n```\n\n#### Language-Specific Testing Hints\n\n**Python Testing Environment**:\n- Use `pytest` as the test framework for its excellent fixtures and parametrization\n- Use `subprocess.run()` with `capture_output=True` for running Git commands\n- Use `tempfile.TemporaryDirectory()` for isolated test environments\n- Use `pathlib.Path` for cross-platform path handling\n- Set `PYTHONPATH` to include your Git implementation directory\n\n**Test Data Management**:\n- Store binary test data as base64 strings in test files to avoid Git corruption\n- Use `pytest.mark.parametrize` to run the same test with multiple inputs\n- Create reusable fixtures for common repository states\n- Use `pytest-xdist` for parallel test execution to speed up large test suites\n\n**Cross-Platform Considerations**:\n- Use `os.name` and `platform.system()` to detect platform-specific behavior\n- Normalize path separators using `pathlib` or `os.path.normpath()`\n- Handle case sensitivity differences in file system operations\n- Test file permissions carefully on Windows where the model differs from Unix\n\n#### Milestone Checkpoints\n\nAfter implementing each milestone, run these specific verification commands to ensure correctness:\n\n**Milestone 1 Checkpoint**:\n```bash\n# Test repository initialization\npython your_git.py init\nls -la .git/\ncat .git/HEAD\ngit status  # Using official Git to verify structure\n```\n\n**Milestone 2 Checkpoint**:\n```bash\n# Test blob storage and retrieval\necho \"test content\" | python your_git.py hash-object --stdin\npython your_git.py cat-file blob <hash>\n# Compare hash with: echo \"test content\" | git hash-object --stdin\n```\n\n**Milestone 3 Checkpoint**:\n```bash\n# Test tree object creation\nmkdir testdir\necho \"file content\" > testdir/file.txt\npython your_git.py write-tree\npython your_git.py ls-tree <tree-hash>\n```\n\n**Milestone 4 Checkpoint**:\n```bash\n# Test commit creation\npython your_git.py commit-tree <tree-hash> -m \"Test commit\"\npython your_git.py cat-file commit <commit-hash>\n```\n\n**Milestone 5 Checkpoint**:\n```bash\n# Test branch operations\npython your_git.py branch feature <commit-hash>\ncat .git/refs/heads/feature\npython your_git.py checkout feature\ncat .git/HEAD\n```\n\n**Milestone 6 Checkpoint**:\n```bash\n# Test staging operations\necho \"new content\" > newfile.txt\npython your_git.py add newfile.txt\npython your_git.py status\nhexdump -C .git/index  # Verify binary format\n```\n\n**Milestone 7 Checkpoint**:\n```bash\n# Test diff algorithm\necho -e \"line1\\nline2\\nline3\" > file1.txt\necho -e \"line1\\nmodified\\nline3\" > file2.txt\npython your_git.py diff file1.txt file2.txt\n```\n\n**Milestone 8 Checkpoint**:\n```bash\n# Test merge operations\npython your_git.py merge feature\npython your_git.py status  # Check for conflicts\npython your_git.py log --oneline  # Verify merge commit\n```\n\n#### Debugging Tips\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|-----------------|-----|\n| Hash mismatch with official Git | Incorrect object header format | Compare object content byte-by-byte | Ensure exact \"blob {size}\\0{content}\" format |\n| \"Not a git repository\" error | Missing or incorrect .git structure | Check directory permissions and HEAD file | Verify .git directory and all subdirectories exist |\n| Index corruption | Binary format errors | Parse index with hexdump -C | Follow Git index format specification exactly |\n| Merge conflicts not detected | Incorrect three-way comparison | Trace merge algorithm with debug output | Verify merge base calculation and line-by-line comparison |\n| Performance problems | Inefficient algorithms | Profile with cProfile | Optimize hot paths, especially diff and merge algorithms |\n\nThe testing strategy provides comprehensive coverage while remaining practical for development workflows. The key insight is that Git's deterministic nature makes automated testing straightforward - identical operations should always produce identical results, making regression detection reliable and comprehensive compatibility verification achievable.\n\n### Implementation Guidance\n\nThe testing implementation provides the foundation for confident development and reliable milestone verification. The comprehensive approach ensures your Git implementation works correctly both in isolation and in comparison with official Git.\n\n#### Technology Recommendations\n\n| Testing Component | Simple Option | Advanced Option |\n|------------------|---------------|-----------------|\n| Test Framework | pytest with basic assertions | pytest with custom plugins and fixtures |\n| Git Execution | subprocess.run() with shell commands | GitPython library for programmatic Git operations |\n| Binary Format Testing | Manual hex dump comparison | Custom binary format parsers and validators |\n| Performance Testing | Basic timing with time.time() | pytest-benchmark with statistical analysis |\n| Cross-Platform Testing | Manual testing on available systems | GitHub Actions matrix with multiple OS versions |\n\n#### Recommended Testing File Structure\n\n```\nbuild-your-own-git/\n├── tests/\n│   ├── __init__.py\n│   ├── conftest.py                 # pytest configuration and shared fixtures\n│   ├── unit/                       # Unit tests for individual components\n│   │   ├── __init__.py\n│   │   ├── test_object_store.py    # ObjectStore class testing\n│   │   ├── test_index.py           # Index class testing\n│   │   ├── test_references.py      # ReferenceManager testing\n│   │   ├── test_diff_algorithm.py  # MyersDiff algorithm testing\n│   │   └── test_merge_algorithm.py # ThreeWayMerge testing\n│   ├── integration/                # Integration tests comparing with official Git\n│   │   ├── __init__.py\n│   │   ├── test_basic_workflow.py  # init, add, commit workflow\n│   │   ├── test_branch_operations.py # branch creation, switching, merging\n│   │   ├── test_merge_scenarios.py # various merge conflict scenarios\n│   │   └── test_compatibility.py   # comprehensive compatibility testing\n│   ├── milestone/                  # Milestone-specific verification tests\n│   │   ├── __init__.py\n│   │   ├── test_milestone_1.py     # Repository initialization verification\n│   │   ├── test_milestone_2.py     # Blob storage verification\n│   │   ├── test_milestone_3.py     # Tree objects verification\n│   │   ├── test_milestone_4.py     # Commit objects verification\n│   │   ├── test_milestone_5.py     # References and branches verification\n│   │   ├── test_milestone_6.py     # Index and staging verification\n│   │   ├── test_milestone_7.py     # Diff algorithm verification\n│   │   └── test_milestone_8.py     # Three-way merge verification\n│   ├── fixtures/                   # Test data and repository templates\n│   │   ├── sample_repos/           # Pre-built test repositories\n│   │   ├── binary_files/           # Binary test files for blob storage\n│   │   ├── conflict_scenarios/     # Merge conflict test cases\n│   │   └── large_files/            # Performance testing files\n│   └── utils/                      # Testing utilities and helpers\n│       ├── __init__.py\n│       ├── git_comparison.py       # Compare with official Git implementation\n│       ├── repo_generator.py       # Generate test repositories programmatically\n│       ├── binary_parser.py        # Parse and validate Git binary formats\n│       └── performance_monitor.py  # Monitor performance and memory usage\n├── src/\n│   └── your_git/                   # Your Git implementation modules\n│       ├── __init__.py\n│       ├── repository.py           # Repository class\n│       ├── object_store.py         # ObjectStore class\n│       ├── index.py                # Index class\n│       └── ...\n└── pytest.ini                     # pytest configuration file\n```\n\n#### Infrastructure Starter Code\n\n**Complete Git Comparison Framework**:\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nComplete Git Comparison Framework for testing compatibility with official Git.\nThis framework handles environment setup, command execution, and result comparison.\n\"\"\"\n\nimport os\nimport sys\nimport subprocess\nimport tempfile\nimport shutil\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple, Any, Set\nimport hashlib\nimport json\nimport re\nimport time\nfrom dataclasses import dataclass, field\nfrom enum import Enum\n\nclass ComparisonResult(Enum):\n    \"\"\"Results of comparing custom Git with official Git.\"\"\"\n    IDENTICAL = \"identical\"\n    ACCEPTABLE_DIFFERENCE = \"acceptable_difference\" \n    INCOMPATIBLE = \"incompatible\"\n    ERROR = \"error\"\n\n@dataclass\nclass CommandResult:\n    \"\"\"Result of running a Git command.\"\"\"\n    exit_code: int\n    stdout: str\n    stderr: str\n    execution_time: float\n    command: List[str]\n\n@dataclass  \nclass ComparisonReport:\n    \"\"\"Report comparing two Git implementations.\"\"\"\n    command: List[str]\n    custom_result: CommandResult\n    official_result: CommandResult\n    comparison_result: ComparisonResult\n    differences: List[str] = field(default_factory=list)\n    notes: List[str] = field(default_factory=list)\n\nclass GitTestEnvironment:\n    \"\"\"Manages isolated Git testing environment with consistent configuration.\"\"\"\n    \n    def __init__(self, custom_git_path: str, test_name: str):\n        self.custom_git_path = custom_git_path\n        self.official_git_path = shutil.which(\"git\")\n        self.test_name = test_name\n        self.test_dir: Optional[Path] = None\n        self.original_env = {}\n        \n        if not self.official_git_path:\n            raise RuntimeError(\"Official Git not found in PATH\")\n    \n    def __enter__(self):\n        \"\"\"Set up test environment.\"\"\"\n        self.test_dir = Path(tempfile.mkdtemp(prefix=f\"git_test_{self.test_name}_\"))\n        \n        # Save original environment\n        self.original_env = {\n            key: os.environ.get(key) for key in [\n                'GIT_AUTHOR_NAME', 'GIT_AUTHOR_EMAIL', 'GIT_COMMITTER_NAME',\n                'GIT_COMMITTER_EMAIL', 'GIT_AUTHOR_DATE', 'GIT_COMMITTER_DATE'\n            ]\n        }\n        \n        # Set consistent Git environment for reproducible results\n        os.environ.update({\n            'GIT_AUTHOR_NAME': 'Test Author',\n            'GIT_AUTHOR_EMAIL': 'author@test.com',\n            'GIT_COMMITTER_NAME': 'Test Committer', \n            'GIT_COMMITTER_EMAIL': 'committer@test.com',\n            'GIT_AUTHOR_DATE': '1609459200 +0000',    # 2021-01-01 00:00:00 UTC\n            'GIT_COMMITTER_DATE': '1609459200 +0000'  # 2021-01-01 00:00:00 UTC\n        })\n        \n        return self\n    \n    def __exit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Clean up test environment.\"\"\"\n        if self.test_dir and self.test_dir.exists():\n            shutil.rmtree(self.test_dir)\n        \n        # Restore original environment\n        for key, value in self.original_env.items():\n            if value is None:\n                os.environ.pop(key, None)\n            else:\n                os.environ[key] = value\n    \n    def run_custom_git(self, args: List[str], cwd: Optional[Path] = None) -> CommandResult:\n        \"\"\"Run command with custom Git implementation.\"\"\"\n        return self._run_git_command(self.custom_git_path, args, cwd or self.test_dir)\n    \n    def run_official_git(self, args: List[str], cwd: Optional[Path] = None) -> CommandResult:\n        \"\"\"Run command with official Git.\"\"\"\n        return self._run_git_command(self.official_git_path, args, cwd or self.test_dir)\n    \n    def _run_git_command(self, git_path: str, args: List[str], cwd: Path) -> CommandResult:\n        \"\"\"Execute Git command and capture results.\"\"\"\n        start_time = time.time()\n        \n        try:\n            result = subprocess.run(\n                [git_path] + args,\n                cwd=cwd,\n                capture_output=True,\n                text=True,\n                timeout=60  # 60 second timeout for commands\n            )\n            \n            execution_time = time.time() - start_time\n            \n            return CommandResult(\n                exit_code=result.returncode,\n                stdout=result.stdout,\n                stderr=result.stderr,\n                execution_time=execution_time,\n                command=[git_path] + args\n            )\n            \n        except subprocess.TimeoutExpired:\n            return CommandResult(\n                exit_code=-1,\n                stdout=\"\",\n                stderr=\"Command timed out after 60 seconds\",\n                execution_time=60.0,\n                command=[git_path] + args\n            )\n        except Exception as e:\n            return CommandResult(\n                exit_code=-1,\n                stdout=\"\",\n                stderr=f\"Command execution failed: {str(e)}\",\n                execution_time=time.time() - start_time,\n                command=[git_path] + args\n            )\n\nclass GitCompatibilityTester:\n    \"\"\"Comprehensive Git compatibility testing framework.\"\"\"\n    \n    def __init__(self, custom_git_path: str):\n        self.custom_git_path = custom_git_path\n        self.comparison_reports: List[ComparisonReport] = []\n        \n        # Patterns for acceptable differences\n        self.timestamp_patterns = [\n            re.compile(r'\\d{10} [+-]\\d{4}'),  # Unix timestamp with timezone\n            re.compile(r'\\w{3} \\w{3} \\d{1,2} \\d{2}:\\d{2}:\\d{2} \\d{4} [+-]\\d{4}'),  # Date format\n        ]\n        \n        self.hash_pattern = re.compile(r'[0-9a-f]{40}')  # SHA-1 hashes\n    \n    def compare_commands(self, test_name: str, commands: List[List[str]]) -> List[ComparisonReport]:\n        \"\"\"Compare series of commands between implementations.\"\"\"\n        reports = []\n        \n        with GitTestEnvironment(self.custom_git_path, test_name) as env:\n            for command in commands:\n                custom_result = env.run_custom_git(command)\n                official_result = env.run_official_git(command)\n                \n                report = self._compare_results(command, custom_result, official_result)\n                reports.append(report)\n                self.comparison_reports.append(report)\n        \n        return reports\n    \n    def _compare_results(self, command: List[str], custom: CommandResult, official: CommandResult) -> ComparisonReport:\n        \"\"\"Compare results from custom and official Git.\"\"\"\n        report = ComparisonReport(\n            command=command,\n            custom_result=custom,\n            official_result=official,\n            comparison_result=ComparisonResult.ERROR,\n            differences=[],\n            notes=[]\n        )\n        \n        # Check exit codes\n        if custom.exit_code != official.exit_code:\n            report.differences.append(f\"Exit code differs: {custom.exit_code} vs {official.exit_code}\")\n            report.comparison_result = ComparisonResult.INCOMPATIBLE\n            return report\n        \n        # Normalize outputs for comparison\n        custom_stdout_norm = self._normalize_output(custom.stdout)\n        official_stdout_norm = self._normalize_output(official.stdout)\n        \n        custom_stderr_norm = self._normalize_output(custom.stderr)\n        official_stderr_norm = self._normalize_output(official.stderr)\n        \n        # Compare normalized outputs\n        stdout_match = custom_stdout_norm == official_stdout_norm\n        stderr_acceptable = self._is_stderr_acceptable(custom_stderr_norm, official_stderr_norm)\n        \n        if stdout_match and stderr_acceptable:\n            report.comparison_result = ComparisonResult.IDENTICAL\n        elif self._outputs_are_functionally_equivalent(custom_stdout_norm, official_stdout_norm):\n            report.comparison_result = ComparisonResult.ACCEPTABLE_DIFFERENCE\n            report.notes.append(\"Outputs are functionally equivalent despite formatting differences\")\n        else:\n            report.comparison_result = ComparisonResult.INCOMPATIBLE\n            if not stdout_match:\n                report.differences.append(\"stdout differs\")\n            if not stderr_acceptable:\n                report.differences.append(\"stderr differs significantly\")\n        \n        return report\n    \n    def _normalize_output(self, output: str) -> str:\n        \"\"\"Normalize output for comparison by removing acceptable variations.\"\"\"\n        if not output:\n            return \"\"\n        \n        lines = output.strip().split('\\n')\n        normalized_lines = []\n        \n        for line in lines:\n            # Replace timestamps with placeholder\n            for pattern in self.timestamp_patterns:\n                line = pattern.sub('[TIMESTAMP]', line)\n            \n            # Normalize path separators\n            line = line.replace('\\\\', '/')\n            \n            # Remove trailing whitespace\n            line = line.rstrip()\n            \n            if line:  # Skip empty lines\n                normalized_lines.append(line)\n        \n        return '\\n'.join(normalized_lines)\n    \n    def _is_stderr_acceptable(self, custom_stderr: str, official_stderr: str) -> bool:\n        \"\"\"Determine if stderr differences are acceptable.\"\"\"\n        # Both empty is OK\n        if not custom_stderr and not official_stderr:\n            return True\n        \n        # Different error messages might be OK if they convey the same information\n        # This is a simplified check - expand based on specific error message patterns\n        return abs(len(custom_stderr) - len(official_stderr)) < 100\n    \n    def _outputs_are_functionally_equivalent(self, custom_output: str, official_output: str) -> bool:\n        \"\"\"Check if outputs are functionally equivalent despite formatting differences.\"\"\"\n        # Extract all SHA-1 hashes from both outputs\n        custom_hashes = set(self.hash_pattern.findall(custom_output))\n        official_hashes = set(self.hash_pattern.findall(official_output))\n        \n        # If hashes match, outputs are likely functionally equivalent\n        return custom_hashes == official_hashes and len(custom_hashes) > 0\n    \n    def generate_compatibility_report(self) -> Dict[str, Any]:\n        \"\"\"Generate comprehensive compatibility report.\"\"\"\n        total_tests = len(self.comparison_reports)\n        if total_tests == 0:\n            return {\"error\": \"No tests run\"}\n        \n        results_summary = {}\n        for result_type in ComparisonResult:\n            count = sum(1 for r in self.comparison_reports if r.comparison_result == result_type)\n            results_summary[result_type.value] = {\n                \"count\": count,\n                \"percentage\": (count / total_tests) * 100\n            }\n        \n        failed_commands = [\n            {\n                \"command\": \" \".join(r.command),\n                \"result\": r.comparison_result.value,\n                \"differences\": r.differences,\n                \"notes\": r.notes\n            }\n            for r in self.comparison_reports\n            if r.comparison_result == ComparisonResult.INCOMPATIBLE\n        ]\n        \n        return {\n            \"total_tests\": total_tests,\n            \"results_summary\": results_summary,\n            \"compatibility_score\": results_summary.get(\"identical\", {}).get(\"percentage\", 0),\n            \"failed_commands\": failed_commands,\n            \"test_timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S UTC\", time.gmtime())\n        }\n```\n\n**Repository Test Data Generator**:\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nRepository Test Data Generator - Creates diverse test repositories for comprehensive testing.\n\"\"\"\n\nimport os\nimport random\nimport string\nimport struct\nfrom pathlib import Path\nfrom typing import List, Dict, Any, Optional\nimport tempfile\nimport subprocess\n\nclass TestDataGenerator:\n    \"\"\"Generate test data and repositories for Git testing.\"\"\"\n    \n    def __init__(self, base_dir: Optional[Path] = None):\n        self.base_dir = base_dir or Path(tempfile.mkdtemp(prefix=\"git_test_data_\"))\n        self.base_dir.mkdir(exist_ok=True)\n    \n    def generate_text_content(self, lines: int = 10, line_length: int = 80) -> str:\n        \"\"\"Generate realistic text content for testing.\"\"\"\n        content_lines = []\n        \n        for i in range(lines):\n            # Generate line with realistic word structure\n            line_content = []\n            current_length = 0\n            \n            while current_length < line_length - 10:  # Leave room for final word\n                word_length = random.randint(3, 12)\n                word = ''.join(random.choice(string.ascii_letters) for _ in range(word_length))\n                \n                if current_length + word_length + 1 <= line_length:\n                    line_content.append(word)\n                    current_length += word_length + 1\n                else:\n                    break\n            \n            content_lines.append(' '.join(line_content))\n        \n        return '\\n'.join(content_lines) + '\\n'\n    \n    def generate_binary_content(self, size: int) -> bytes:\n        \"\"\"Generate binary content for testing blob storage.\"\"\"\n        # Mix of various byte values including null bytes\n        content = bytearray()\n        \n        for _ in range(size):\n            # Include null bytes and high-bit characters\n            content.append(random.randint(0, 255))\n        \n        return bytes(content)\n    \n    def create_repository_with_history(self, name: str, commit_count: int = 10) -> Path:\n        \"\"\"Create repository with specified number of commits.\"\"\"\n        repo_path = self.base_dir / name\n        repo_path.mkdir(exist_ok=True)\n        \n        # Initialize repository\n        subprocess.run(['git', 'init'], cwd=repo_path, check=True, capture_output=True)\n        \n        # Create commits with diverse content\n        for i in range(commit_count):\n            # Create or modify files\n            if i == 0:\n                # Initial commit with README\n                (repo_path / 'README.md').write_text(f'# {name}\\n\\nTest repository created for Git compatibility testing.\\n')\n                subprocess.run(['git', 'add', 'README.md'], cwd=repo_path, check=True)\n                message = 'Initial commit'\n            else:\n                # Add new files or modify existing ones\n                if random.choice([True, False]):\n                    # Add new file\n                    filename = f'file_{i}.txt'\n                    content = self.generate_text_content(random.randint(5, 50))\n                    (repo_path / filename).write_text(content)\n                    subprocess.run(['git', 'add', filename], cwd=repo_path, check=True)\n                    message = f'Add {filename}'\n                else:\n                    # Modify existing file\n                    existing_files = [f for f in repo_path.iterdir() if f.suffix == '.txt' or f.suffix == '.md']\n                    if existing_files:\n                        target_file = random.choice(existing_files)\n                        content = self.generate_text_content(random.randint(5, 50))\n                        target_file.write_text(content)\n                        subprocess.run(['git', 'add', target_file.name], cwd=repo_path, check=True)\n                        message = f'Modify {target_file.name}'\n                    else:\n                        continue\n            \n            # Create commit\n            subprocess.run(['git', 'commit', '-m', message], cwd=repo_path, check=True, capture_output=True)\n        \n        return repo_path\n    \n    def create_merge_conflict_repository(self, name: str) -> Path:\n        \"\"\"Create repository with merge conflict scenario.\"\"\"\n        repo_path = self.base_dir / name\n        repo_path.mkdir(exist_ok=True)\n        \n        subprocess.run(['git', 'init'], cwd=repo_path, check=True, capture_output=True)\n        \n        # Create initial commit\n        content = \"line 1\\nline 2\\nline 3\\nline 4\\nline 5\\n\"\n        (repo_path / 'conflict.txt').write_text(content)\n        subprocess.run(['git', 'add', 'conflict.txt'], cwd=repo_path, check=True)\n        subprocess.run(['git', 'commit', '-m', 'Initial version'], cwd=repo_path, check=True, capture_output=True)\n        \n        # Create feature branch\n        subprocess.run(['git', 'checkout', '-b', 'feature'], cwd=repo_path, check=True, capture_output=True)\n        \n        # Modify file in feature branch\n        modified_content = \"line 1\\nmodified line 2 (feature)\\nline 3\\nline 4\\nfeature addition\\n\"\n        (repo_path / 'conflict.txt').write_text(modified_content)\n        subprocess.run(['git', 'add', 'conflict.txt'], cwd=repo_path, check=True)\n        subprocess.run(['git', 'commit', '-m', 'Feature changes'], cwd=repo_path, check=True, capture_output=True)\n        \n        # Switch back to main and make conflicting changes\n        subprocess.run(['git', 'checkout', 'main'], cwd=repo_path, check=True, capture_output=True)\n        \n        conflicting_content = \"line 1\\nmodified line 2 (main)\\nline 3\\nmain modification\\nline 5\\n\"\n        (repo_path / 'conflict.txt').write_text(conflicting_content)\n        subprocess.run(['git', 'add', 'conflict.txt'], cwd=repo_path, check=True)\n        subprocess.run(['git', 'commit', '-m', 'Main branch changes'], cwd=repo_path, check=True, capture_output=True)\n        \n        return repo_path\n```\n\n#### Core Logic Skeleton Code\n\n**Milestone Verification Test Template**:\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nMilestone Verification Test Framework - Template for systematic milestone testing.\n\"\"\"\n\nimport pytest\nimport tempfile\nimport subprocess\nimport hashlib\nfrom pathlib import Path\nfrom typing import List, Dict, Any, Optional, Tuple\n\nclass MilestoneTestBase:\n    \"\"\"Base class providing common testing infrastructure for all milestones.\"\"\"\n    \n    def __init__(self, git_implementation_path: str):\n        self.git_path = git_implementation_path\n        self.test_repo: Optional[Path] = None\n        self.original_cwd = Path.cwd()\n    \n    def setup_test_repo(self, repo_name: str = \"test_repo\") -> Path:\n        \"\"\"Create isolated test repository environment.\"\"\"\n        # TODO 1: Create temporary directory for test repository\n        # TODO 2: Set consistent Git environment variables for reproducible results\n        # TODO 3: Change to test repository directory\n        # TODO 4: Return path to test repository for use in tests\n        # Hint: Use tempfile.mkdtemp() and os.environ for environment setup\n        pass\n    \n    def cleanup_test_repo(self):\n        \"\"\"Clean up test repository and restore environment.\"\"\"\n        # TODO 1:\n\n```\n\n\n## Debugging Guide\n\n> **Milestone(s):** This section applies to all eight milestones but is particularly critical for complex operations in Milestone 6 (Index/Staging Area), Milestone 7 (Diff Algorithm), and Milestone 8 (Three-Way Merge) where multiple components interact and failure modes can be subtle.\n\n### Mental Model: The Medical Diagnostic Process\n\nThink of debugging a Git implementation like diagnosing a patient in a hospital. When someone comes to the emergency room saying \"I feel terrible,\" that's just the symptom—the real challenge is systematically working backward to find the root cause. A good doctor doesn't just treat the fever; they run tests to determine whether it's caused by an infection, an autoimmune disorder, or something else entirely.\n\nSimilarly, when your Git implementation fails with \"object not found\" or \"merge conflicts detected incorrectly,\" these are symptoms of deeper issues in the object store, hashing logic, file I/O, or algorithm implementation. Just like medical diagnosis follows a systematic process—gather symptoms, form hypotheses, run tests, eliminate possibilities—debugging Git requires a methodical approach to trace problems back through the system's layers.\n\nThe key insight is that Git's components form a dependency chain: merge algorithms depend on diff algorithms, diff algorithms depend on tree comparisons, tree comparisons depend on object retrieval, and object retrieval depends on correct hashing and storage. A failure in any lower layer manifests as confusing symptoms in higher layers, just like how a kidney problem might first show up as fatigue or swelling.\n\nThis section provides the diagnostic tools and systematic approaches you need to isolate problems quickly and fix them at their source, rather than chasing symptoms through multiple system layers.\n\n### Object Storage Issues\n\nThe object store is the foundation of Git's architecture, and problems here propagate throughout the entire system. Since every other operation depends on storing and retrieving objects correctly, object storage bugs often manifest as mysterious failures in seemingly unrelated components.\n\n#### Hash Mismatches and Computation Errors\n\nHash mismatches are among the most common and frustrating problems in Git implementation. When your computed hash doesn't match the expected value, it indicates a fundamental error in how you're constructing or processing object content.\n\n| Symptom | Likely Root Cause | Diagnostic Steps | Solution |\n|---------|-------------------|------------------|----------|\n| `compute_object_hash()` returns different hash than real Git | Missing or incorrect null byte separator | Print raw bytes before hashing, check for `\\0` at correct position | Ensure format is exactly `{type} {size}\\0{content}` |\n| Hash computation works for text but fails for binary files | Line ending conversion corrupting binary data | Check if file reading mode is binary vs text | Always open files in binary mode (`'rb'`) |\n| Same content produces different hashes on different runs | Including timestamp or metadata in hash calculation | Log exactly what bytes are being hashed | Only hash the canonical object format, not filesystem metadata |\n| Objects store but can't be retrieved | Hash computed incorrectly during storage vs retrieval | Compare hashes at storage time vs retrieval time | Ensure identical hash computation algorithm in both paths |\n| Repository corruption errors when using stored objects | Hash collision or truncated hash | Validate hash is exactly 40 hex characters | Check for off-by-one errors in string slicing |\n\nThe most critical debugging technique for hash issues is to log the exact byte sequence being hashed. Hash functions are deterministic—if you get different outputs, your inputs are different, even if they look identical when printed as strings.\n\n**⚠️ Pitfall: Text Mode File Reading**\nOne of the most subtle bugs occurs when reading files in text mode instead of binary mode. On Windows, text mode automatically converts `\\r\\n` to `\\n`, which changes the file's byte content and produces a different hash. Always use binary mode for all file operations, then handle line endings explicitly if needed.\n\n**⚠️ Pitfall: Unicode Encoding Issues**\nWhen handling file paths or commit messages with non-ASCII characters, inconsistent encoding between storage and retrieval will cause hash mismatches. Git internally uses UTF-8 for all text content, but filesystem paths might use different encodings. Establish a consistent encoding strategy early and apply it everywhere.\n\n> **Key Insight**: Hash mismatches are never random—they indicate a systematic difference in how content is processed. The debugging approach should focus on isolating exactly where the byte streams diverge, typically by comparing hex dumps of the content at each processing stage.\n\n#### Compression and Storage Problems\n\nGit uses zlib compression for all stored objects, and compression-related bugs can cause object corruption, storage failures, or retrieval errors that are difficult to trace back to their source.\n\n| Symptom | Likely Root Cause | Diagnostic Steps | Solution |\n|---------|-------------------|------------------|----------|\n| `zlib.error: Error -3 while decompressing` | Stored object wasn't properly compressed | Try decompressing stored file manually with Python zlib | Ensure `zlib.compress()` before writing to disk |\n| Objects store successfully but retrieval returns corrupted content | Partial write or filesystem buffering issue | Check file size on disk vs expected compressed size | Use `fsync()` or atomic writes to ensure complete storage |\n| Compression works for small files but fails for large ones | Memory exhaustion or buffer overflow | Monitor memory usage during compression | Stream compression for files larger than available RAM |\n| Decompression succeeds but content doesn't match original | Wrong compression level or algorithm variant | Compare compression settings between storage/retrieval | Use consistent `zlib.compress()` with default level |\n| Storage location exists but appears empty | Race condition in concurrent access | Check if multiple processes are accessing same object | Implement file locking around object store operations |\n\nThe key diagnostic tool for compression issues is to manually test compression and decompression outside your Git implementation. Python's `zlib` module makes this straightforward:\n\n```python\n# Test compression/decompression manually\nimport zlib\noriginal = b\"blob 5\\x00hello\"\ncompressed = zlib.compress(original)\ndecompressed = zlib.decompress(compressed)\nassert original == decompressed\n```\n\nIf this test passes but your Git implementation fails, the problem is in your file I/O, not the compression logic.\n\n**⚠️ Pitfall: Forgetting to Compress Before Storage**\nA common mistake is computing the hash correctly (from uncompressed content) but then storing the uncompressed content to disk. Git always stores compressed objects, so retrieval will fail when trying to decompress uncompressed data. The rule is: hash the uncompressed content, store the compressed content.\n\n**⚠️ Pitfall: Double Compression**\nAnother subtle bug occurs when accidentally compressing already-compressed data. This typically happens when a higher-level function calls a lower-level storage function that also performs compression. The symptom is that stored objects become corrupted and can't be retrieved. Always maintain clear boundaries about which layer handles compression.\n\n#### File System Permissions and Path Issues\n\nObject storage relies heavily on filesystem operations, and permission or path-related problems can cause mysterious failures that are difficult to diagnose because error messages often don't clearly indicate the root cause.\n\n| Symptom | Likely Root Cause | Diagnostic Steps | Solution |\n|---------|-------------------|------------------|----------|\n| `PermissionError` when storing objects | `.git/objects` directory has wrong permissions | Check directory permissions with `ls -la .git/objects` | Ensure `.git` hierarchy has appropriate read/write permissions |\n| Objects store but can't be found during retrieval | Incorrect path construction from hash | Print full file path during storage and retrieval | Verify path format is `.git/objects/xx/yy...` with correct hash splitting |\n| Storage succeeds on some systems but fails on others | Case sensitivity differences (Windows vs Linux) | Test with hashes that differ only in case | Ensure consistent case handling in hash-to-path conversion |\n| Intermittent storage failures | Directory creation race condition | Check if `.git/objects/xx/` directory exists before object creation | Create intermediate directories atomically |\n| Storage works but repository appears empty to other tools | Objects stored in wrong location relative to `.git` | Verify object paths relative to repository root | Ensure `.git` directory detection is working correctly |\n\nThe most effective diagnostic approach for path issues is to log the complete file paths being used and manually verify they match Git's expected structure. Use `find .git/objects -type f` to see what's actually stored and compare against your expectations.\n\n**⚠️ Pitfall: Relative vs Absolute Paths**\nBe extremely careful about working directory context when constructing object paths. If your Git implementation changes working directories, relative paths to `.git/objects` can suddenly point to the wrong location. Always resolve to absolute paths early in your program and maintain them consistently.\n\n**⚠️ Pitfall: Directory Creation Timing**\nThe `.git/objects/xx` subdirectories need to be created before storing objects. A common bug is assuming these directories exist, leading to storage failures for objects whose hash prefix hasn't been seen before. Always create the directory structure on demand during object storage.\n\n### Merge Algorithm Debugging\n\nMerge algorithms are among the most complex components in Git, involving multiple algorithms working together: finding merge bases, comparing file trees, detecting conflicts, and combining changes. Problems here often involve subtle edge cases in graph traversal, incorrect conflict detection, or malformed output.\n\n#### Conflict Detection Failures\n\nIncorrect conflict detection is one of the most subtle categories of merge bugs because the symptoms often don't appear until the merge completes, and by then the root cause is buried in complex algorithm state.\n\n| Symptom | Likely Root Cause | Diagnostic Steps | Solution |\n|---------|-------------------|------------------|----------|\n| Changes merge cleanly that should conflict | Incorrect base version used in three-way comparison | Print base, ours, theirs content for conflicted regions | Verify merge base calculation is finding correct common ancestor |\n| Conflicts detected where files merge cleanly | Overly aggressive conflict detection algorithm | Compare line-by-line diffs manually | Check that identical changes in both branches aren't flagged as conflicts |\n| Conflict markers appear in wrong locations | Line numbering bug in conflict region calculation | Log start/end line numbers for each conflict region | Ensure conflict boundaries account for previous insertions/deletions |\n| Some conflicts detected but others missed | Incomplete coverage in conflict scanning | Test with files that have multiple conflict regions | Scan entire file, not just first conflict |\n| Binary files show text conflict markers | Binary file detection failing | Check `is_binary_content()` with problematic files | Improve binary detection or handle binary conflicts differently |\n\nThe key diagnostic technique for conflict detection is to manually perform the three-way comparison that your algorithm should be doing. Take the base version, your changes, and their changes, and determine by hand what the result should be. Then trace through your algorithm step-by-step to find where it diverges from the correct result.\n\n**⚠️ Pitfall: Off-by-One Line Numbering**\nConflict detection algorithms typically work with zero-indexed line arrays, but conflict markers need to reference one-indexed line numbers for human readability. Mixing these conventions leads to conflicts appearing in the wrong locations or spanning incorrect ranges.\n\n**⚠️ Pitfall: Assuming Clean Three-Way Split**\nReal merge conflicts are messier than textbook examples. A single file might have multiple conflict regions, conflicts might be adjacent (requiring marker consolidation), or one branch might delete lines while the other modifies them. Design your conflict detection to handle overlapping and adjacent conflicts gracefully.\n\n#### Infinite Loops in Merge Base Calculation\n\nFinding the merge base requires graph traversal of the commit history, and bugs in the traversal algorithm can cause infinite loops, incorrect results, or performance problems that make merges unusable.\n\n| Symptom | Likely Root Cause | Diagnostic Steps | Solution |\n|---------|-------------------|------------------|----------|\n| Merge base calculation never terminates | Not tracking visited commits in graph traversal | Add logging to see which commits are being processed repeatedly | Maintain `visited` set to prevent revisiting same commit |\n| Merge base returns wrong commit | Breadth-first search implementation bug | Manually trace commit graph and identify expected merge base | Ensure BFS queue processes commits in chronological order |\n| Merge base works for simple cases but fails on complex history | Algorithm doesn't handle merge commits properly | Test with repository that has merge commits in history | Ensure algorithm follows all parent links, not just first parent |\n| Performance degrades with large repositories | Inefficient graph traversal or storage | Profile memory and time usage during merge base calculation | Use efficient data structures for visited set and processing queue |\n| Merge base calculation crashes on corrupted history | Missing error handling for invalid parent references | Check for commits that reference non-existent parents | Validate parent commits exist before following references |\n\nThe standard approach for debugging graph traversal is to visualize the commit graph manually (using `git log --graph --oneline`) and trace through your algorithm by hand to verify it produces the same result.\n\n**⚠️ Pitfall: Not Handling Multiple Merge Bases**\nIn complex histories, two branches might have multiple common ancestors at the same distance. The merge base algorithm should return the most recent common ancestor, not just any common ancestor. This requires careful handling of the BFS termination condition.\n\n**⚠️ Pitfall: Stack Overflow on Deep History**\nRecursive implementations of merge base calculation can overflow the call stack on repositories with very deep history. Use iterative algorithms with explicit queues or stacks to handle arbitrarily deep commit graphs.\n\n#### Corrupted Merge States\n\nMerge operations involve multiple steps and temporary state, creating opportunities for corruption if the process is interrupted or if there are bugs in state management.\n\n| Symptom | Likely Root Cause | Diagnostic Steps | Solution |\n|---------|-------------------|------------------|----------|\n| Merge appears successful but working directory is corrupted | Incomplete file updates during merge | Check if all files in merge result were written to working directory | Ensure atomic updates—write to temp files, then rename |\n| Merge conflicts resolved but commit creation fails | Index not updated with merge resolution | Check index contents after conflict resolution | Update index entries for all resolved files before committing |\n| Merge process can't be resumed after interruption | Missing or corrupted merge state files | Look for `.git/MERGE_HEAD` and related state files | Save merge state atomically and restore on resume |\n| Merged content loses changes from one branch | Three-way merge algorithm bug | Compare merge result against manual merge | Debug three-way merge logic with simple test cases |\n| Merge completes but repository is in inconsistent state | Transaction boundary not properly implemented | Verify all merge operations succeed before updating references | Implement rollback capability for failed merges |\n\nThe most effective debugging approach for merge state corruption is to implement comprehensive state validation at each step of the merge process. Before proceeding from one step to the next, verify that all previous steps completed successfully and left the repository in a consistent state.\n\n**⚠️ Pitfall: Not Cleaning Up Merge State**\nAfter a successful merge, temporary state files (like `.git/MERGE_HEAD`) must be cleaned up. Leaving these files around confuses subsequent operations and can cause Git tools to think a merge is still in progress.\n\n**⚠️ Pitfall: Race Conditions in Concurrent Access**\nIf multiple processes try to perform merges simultaneously, or if a merge is interrupted and restarted, corrupted state can result. Implement proper locking around merge operations to prevent concurrent modifications.\n\n### Debugging Tools and Techniques\n\nEffective Git debugging requires a systematic toolkit of techniques for inspecting internal state, validating data structures, and tracing execution flow. Unlike application debugging, Git debugging often involves understanding the interaction between your implementation and the filesystem, as well as validating that your data structures match Git's exact specifications.\n\n#### Inspecting Git Internals\n\nThe ability to inspect and validate Git's internal data structures is crucial for debugging, because many bugs manifest as subtle differences between your implementation's output and Git's expected formats.\n\n| Technique | Purpose | Implementation | Usage Example |\n|-----------|---------|----------------|---------------|\n| Object content validation | Verify stored objects match expected format | Decompress `.git/objects/xx/yy...` files and examine raw content | Check that blob headers are exactly `blob {size}\\0{content}` |\n| Hash verification | Confirm object hashes are computed correctly | Recompute hash from stored content and compare to filename | Detect corruption or computation bugs |\n| Index inspection | Examine staging area contents and metadata | Parse binary `.git/index` file and display entries | Debug staging/unstaging operations |\n| Reference tracing | Follow symbolic and direct references | Read `.git/HEAD` and `.git/refs/heads/*` files | Debug branch switching and reference updates |\n| Tree traversal validation | Verify directory structure representation | Recursively expand tree objects and compare to filesystem | Debug tree building and directory representation |\n\nA comprehensive Git internals inspection tool should provide commands to examine each type of internal data structure. This tool becomes invaluable when your implementation produces different results than expected, because it lets you identify exactly where the differences occur.\n\n```python\ndef inspect_object(object_hash: str, git_dir: Path) -> Dict[str, Any]:\n    \"\"\"\n    Comprehensive object inspection that validates format and content.\n    Returns detailed breakdown of object structure for debugging.\n    \"\"\"\n    # TODO: Implement object retrieval and format validation\n    # TODO: Parse object header and extract type, size\n    # TODO: Validate content matches declared size\n    # TODO: For tree objects, parse and validate entry format\n    # TODO: For commit objects, parse and validate all fields\n    # TODO: Return structured data for comparison with expected values\n    pass\n```\n\n**⚠️ Pitfall: Endianness in Binary Parsing**\nWhen inspecting the binary index file or other Git data structures, be aware that multi-byte integers use network byte order (big-endian). Python's `struct` module requires explicit endianness specification (`>I` for big-endian 32-bit integer).\n\n**⚠️ Pitfall: String Encoding in Object Content**\nGit objects can contain both text (UTF-8) and binary content. When displaying object content for debugging, handle encoding errors gracefully and clearly distinguish between text and binary data to avoid corrupting the debugging output itself.\n\n#### Tracing Object Relationships\n\nGit's object model forms a directed acyclic graph where commits point to trees, trees point to blobs and subtrees, and commits can have multiple parents. Bugs often involve incorrect relationships in this graph, so tracing these relationships is a crucial debugging technique.\n\n| Relationship Type | Validation Method | Common Issues | Debugging Approach |\n|------------------|-------------------|---------------|-------------------|\n| Commit → Tree | Verify tree hash in commit object exists and is valid tree | Commit references non-existent tree | Trace tree creation during commit process |\n| Tree → Blob/Subtree | Check all tree entries reference valid objects of correct type | Tree entry points to blob but declares mode as directory | Validate tree building algorithm |\n| Commit → Parent | Ensure parent hashes reference valid commit objects | Commit parent chain broken or circular | Graph traversal to detect cycles |\n| Branch → Commit | Verify branch reference points to valid commit | Branch reference corrupted or points to non-commit object | Check reference update logic |\n| Index → Blob | Confirm staged files reference valid blob objects | Index entry hash doesn't match stored blob | Debug file staging process |\n\nThe most effective relationship tracing involves building a complete graph of your repository's objects and validating that it matches expected Git invariants. This can reveal subtle bugs like commits that reference trees built incorrectly, or index entries that point to non-existent blobs.\n\n> **Critical Debugging Insight**: Object relationship bugs often cascade—a corrupted tree leads to a corrupted commit, which leads to a corrupted branch reference. Always trace problems back to their root cause in the dependency graph rather than fixing symptoms at higher levels.\n\n#### Validating Repository Consistency\n\nA well-formed Git repository must satisfy numerous consistency invariants, and validating these invariants systematically can catch bugs that would otherwise be difficult to reproduce or diagnose.\n\n| Consistency Check | Validation Rule | Implementation | Common Violations |\n|-------------------|-----------------|----------------|-------------------|\n| Object reachability | All referenced objects exist and are accessible | Graph traversal from all branch heads | Dangling references, missing objects |\n| Hash integrity | Stored object hash matches computed hash of content | Recompute hash for every stored object | Hash computation bugs, storage corruption |\n| Reference validity | All references point to valid objects of expected type | Validate reference targets | References pointing to non-existent or wrong-type objects |\n| Index consistency | All index entries reference valid blobs with correct metadata | Compare index entries to actual blobs and filesystem | Staged files don't match working directory or stored blobs |\n| Tree structure validity | Tree objects properly represent directory hierarchy | Validate tree entry formats and recursive structure | Malformed tree entries, incorrect permissions |\n\nImplementing a comprehensive repository validation function provides a systematic way to detect corruption and verify that your implementation maintains Git's invariants correctly.\n\n```python\ndef validate_repository_consistency(git_dir: Path) -> List[str]:\n    \"\"\"\n    Comprehensive repository validation that checks all Git invariants.\n    Returns list of consistency violations found.\n    \"\"\"\n    violations = []\n    \n    # TODO: Validate all objects in .git/objects have correct hash\n    # TODO: Check that all references point to valid objects\n    # TODO: Verify index entries reference existing blobs\n    # TODO: Validate tree objects have proper entry format\n    # TODO: Check commit objects have valid parent references\n    # TODO: Ensure no circular references in commit history\n    # TODO: Verify working directory matches HEAD commit + index\n    \n    return violations\n```\n\n**⚠️ Pitfall: Performance of Full Validation**\nRepository validation can be expensive for large repositories. Implement incremental validation that focuses on recently modified objects, and provide full validation as a separate diagnostic tool rather than running it automatically.\n\n**⚠️ Pitfall: Validation During Intermediate States**\nSome Git operations go through intermediate states where the repository temporarily violates consistency rules. For example, during a merge, the working directory might not match any single commit. Design validation to account for these legitimate intermediate states.\n\n#### Debugging Workflow Integration\n\nEffective Git debugging requires integrating diagnostic capabilities into your normal development workflow, so that problems can be detected and diagnosed quickly rather than accumulating until they cause major failures.\n\n| Integration Point | Diagnostic Capability | Implementation Strategy | Benefit |\n|------------------|----------------------|------------------------|---------|\n| Object storage | Automatic hash verification | Verify stored object can be retrieved and matches original | Catch storage bugs immediately |\n| Commit creation | Tree validation | Ensure generated tree matches working directory structure | Detect tree building bugs |\n| Merge operations | State consistency checks | Validate repository state at each merge step | Prevent merge corruption |\n| Index operations | Metadata validation | Check that index metadata matches filesystem | Catch staging bugs early |\n| Reference updates | Atomicity verification | Ensure reference updates are atomic and consistent | Prevent reference corruption |\n\nThe key insight is that debugging capabilities should be built into the core operations, not added as an afterthought. This allows problems to be detected at their source rather than discovered much later when their effects become visible.\n\n**⚠️ Pitfall: Debug Code Affecting Performance**\nExtensive validation and logging can significantly impact performance. Design debug features to be easily disabled in production builds, or implement them as optional validation passes that can be enabled when problems are suspected.\n\n**⚠️ Pitfall: Debug Output Affecting Test Results**\nWhen implementing diagnostic logging, ensure that debug output doesn't interfere with normal program output that tests might depend on. Use separate streams for debug output, or implement a logging system that can be configured to different levels of verbosity.\n\n### Implementation Guidance\n\nBuilding effective debugging capabilities requires a systematic approach that integrates diagnostic tools into your Git implementation from the beginning. The debugging infrastructure should be designed to help you understand not just what went wrong, but why it went wrong and how to prevent similar issues in the future.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Logging | Python's `logging` module with file handlers | Structured logging with JSON output for analysis |\n| Validation | Simple assertion-based checks | Property-based testing with hypothesis |\n| Object inspection | Manual hex dump utilities | Custom binary parser with formatted output |\n| State debugging | Print statements with manual formatting | Interactive debugger integration with repository state |\n| Performance profiling | Basic timing with `time.time()` | Full profiling with `cProfile` and memory tracking |\n\n#### Debugging Infrastructure Starter Code\n\nHere's a complete debugging infrastructure that provides comprehensive diagnostic capabilities for your Git implementation:\n\n```python\nimport logging\nimport hashlib\nimport zlib\nimport struct\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Any, Tuple\nfrom dataclasses import dataclass\nfrom enum import Enum\n\nclass ValidationLevel(Enum):\n    MINIMAL = \"minimal\"      # Only critical invariants\n    STANDARD = \"standard\"    # Common consistency checks  \n    COMPREHENSIVE = \"comprehensive\"  # Full repository validation\n\n@dataclass\nclass ValidationResult:\n    is_valid: bool\n    violations: List[str]\n    warnings: List[str]\n    validation_time: float\n\nclass GitDebugger:\n    \"\"\"\n    Comprehensive debugging and validation toolkit for Git implementations.\n    Provides object inspection, consistency checking, and diagnostic utilities.\n    \"\"\"\n    \n    def __init__(self, git_dir: Path):\n        self.git_dir = git_dir\n        self.objects_dir = git_dir / \"objects\"\n        self.refs_dir = git_dir / \"refs\"\n        self.index_path = git_dir / \"index\"\n        self.head_path = git_dir / \"HEAD\"\n        \n        # Set up logging\n        self.logger = logging.getLogger(\"git_debugger\")\n        handler = logging.FileHandler(git_dir / \"debug.log\")\n        handler.setFormatter(logging.Formatter(\n            '%(asctime)s - %(levelname)s - %(message)s'\n        ))\n        self.logger.addHandler(handler)\n        self.logger.setLevel(logging.INFO)\n\n    def inspect_object(self, object_hash: str) -> Dict[str, Any]:\n        \"\"\"\n        Comprehensive object inspection with format validation.\n        Returns detailed object structure for debugging.\n        \"\"\"\n        try:\n            object_path = self._get_object_path(object_hash)\n            if not object_path.exists():\n                return {\"error\": f\"Object {object_hash} not found\"}\n            \n            # Read and decompress object\n            with open(object_path, 'rb') as f:\n                compressed_data = f.read()\n            \n            try:\n                raw_data = zlib.decompress(compressed_data)\n            except zlib.error as e:\n                return {\"error\": f\"Decompression failed: {e}\"}\n            \n            # Parse header\n            null_pos = raw_data.find(b'\\0')\n            if null_pos == -1:\n                return {\"error\": \"Invalid object format: no null separator\"}\n            \n            header = raw_data[:null_pos].decode('utf-8')\n            content = raw_data[null_pos + 1:]\n            \n            # Parse object type and size\n            try:\n                obj_type, size_str = header.split(' ', 1)\n                declared_size = int(size_str)\n            except ValueError:\n                return {\"error\": f\"Invalid header format: {header}\"}\n            \n            # Validate size\n            if len(content) != declared_size:\n                return {\n                    \"error\": f\"Size mismatch: declared {declared_size}, actual {len(content)}\"\n                }\n            \n            # Verify hash\n            expected_hash = hashlib.sha1(raw_data).hexdigest()\n            if expected_hash != object_hash:\n                return {\n                    \"error\": f\"Hash mismatch: expected {object_hash}, computed {expected_hash}\"\n                }\n            \n            result = {\n                \"hash\": object_hash,\n                \"type\": obj_type,\n                \"size\": declared_size,\n                \"content_preview\": self._preview_content(content, obj_type),\n                \"valid\": True\n            }\n            \n            # Type-specific parsing\n            if obj_type == \"tree\":\n                result[\"entries\"] = self._parse_tree_entries(content)\n            elif obj_type == \"commit\":\n                result[\"commit_info\"] = self._parse_commit_info(content)\n            \n            return result\n            \n        except Exception as e:\n            return {\"error\": f\"Inspection failed: {e}\"}\n\n    def validate_repository(self, level: ValidationLevel = ValidationLevel.STANDARD) -> ValidationResult:\n        \"\"\"\n        Comprehensive repository validation with configurable depth.\n        \"\"\"\n        start_time = time.time()\n        violations = []\n        warnings = []\n        \n        try:\n            if level in [ValidationLevel.STANDARD, ValidationLevel.COMPREHENSIVE]:\n                violations.extend(self._validate_object_store())\n                violations.extend(self._validate_references())\n                violations.extend(self._validate_index())\n            \n            if level == ValidationLevel.COMPREHENSIVE:\n                violations.extend(self._validate_object_relationships())\n                violations.extend(self._validate_working_directory())\n                warnings.extend(self._check_performance_issues())\n            \n            validation_time = time.time() - start_time\n            is_valid = len(violations) == 0\n            \n            return ValidationResult(is_valid, violations, warnings, validation_time)\n            \n        except Exception as e:\n            violations.append(f\"Validation failed with error: {e}\")\n            return ValidationResult(False, violations, warnings, time.time() - start_time)\n\n    def trace_object_relationships(self, start_hash: str, max_depth: int = 10) -> Dict[str, Any]:\n        \"\"\"\n        Trace object relationships from a starting object (typically a commit).\n        Returns graph structure showing all reachable objects.\n        \"\"\"\n        visited = set()\n        relationships = {}\n        queue = [(start_hash, 0)]\n        \n        while queue and len(visited) < 1000:  # Safety limit\n            obj_hash, depth = queue.pop(0)\n            \n            if obj_hash in visited or depth > max_depth:\n                continue\n            \n            visited.add(obj_hash)\n            obj_info = self.inspect_object(obj_hash)\n            \n            if \"error\" in obj_info:\n                relationships[obj_hash] = {\"error\": obj_info[\"error\"], \"depth\": depth}\n                continue\n            \n            relationships[obj_hash] = {\n                \"type\": obj_info[\"type\"],\n                \"depth\": depth,\n                \"references\": []\n            }\n            \n            # Find referenced objects\n            if obj_info[\"type\"] == \"commit\":\n                commit_info = obj_info.get(\"commit_info\", {})\n                if \"tree\" in commit_info:\n                    queue.append((commit_info[\"tree\"], depth + 1))\n                    relationships[obj_hash][\"references\"].append(commit_info[\"tree\"])\n                \n                for parent in commit_info.get(\"parents\", []):\n                    queue.append((parent, depth + 1))\n                    relationships[obj_hash][\"references\"].append(parent)\n            \n            elif obj_info[\"type\"] == \"tree\":\n                for entry in obj_info.get(\"entries\", []):\n                    entry_hash = entry.get(\"hash\")\n                    if entry_hash:\n                        queue.append((entry_hash, depth + 1))\n                        relationships[obj_hash][\"references\"].append(entry_hash)\n        \n        return {\n            \"start_object\": start_hash,\n            \"total_objects\": len(relationships),\n            \"max_depth_reached\": max(r.get(\"depth\", 0) for r in relationships.values()),\n            \"relationships\": relationships\n        }\n\n    def diagnose_merge_failure(self, our_commit: str, their_commit: str) -> Dict[str, Any]:\n        \"\"\"\n        Comprehensive merge failure diagnosis.\n        \"\"\"\n        diagnosis = {\n            \"our_commit\": our_commit,\n            \"their_commit\": their_commit,\n            \"issues\": [],\n            \"recommendations\": []\n        }\n        \n        # Validate input commits\n        our_info = self.inspect_object(our_commit)\n        their_info = self.inspect_object(their_commit)\n        \n        if \"error\" in our_info:\n            diagnosis[\"issues\"].append(f\"Our commit invalid: {our_info['error']}\")\n        if \"error\" in their_info:\n            diagnosis[\"issues\"].append(f\"Their commit invalid: {their_info['error']}\")\n        \n        if diagnosis[\"issues\"]:\n            return diagnosis\n        \n        # Try to find merge base\n        try:\n            merge_base = self._find_merge_base_debug(our_commit, their_commit)\n            if merge_base:\n                diagnosis[\"merge_base\"] = merge_base\n                base_info = self.inspect_object(merge_base)\n                if \"error\" in base_info:\n                    diagnosis[\"issues\"].append(f\"Merge base corrupted: {base_info['error']}\")\n            else:\n                diagnosis[\"issues\"].append(\"No common ancestor found\")\n                diagnosis[\"recommendations\"].append(\"Check if commits are from same repository\")\n        except Exception as e:\n            diagnosis[\"issues\"].append(f\"Merge base calculation failed: {e}\")\n        \n        # Analyze tree differences\n        try:\n            our_tree = our_info[\"commit_info\"][\"tree\"]\n            their_tree = their_info[\"commit_info\"][\"tree\"]\n            \n            tree_diff = self._analyze_tree_differences(our_tree, their_tree)\n            diagnosis[\"tree_analysis\"] = tree_diff\n            \n            if tree_diff[\"binary_conflicts\"] > 0:\n                diagnosis[\"recommendations\"].append(\"Binary file conflicts require manual resolution\")\n            \n            if tree_diff[\"large_files\"] > 0:\n                diagnosis[\"recommendations\"].append(\"Large file conflicts may cause performance issues\")\n                \n        except Exception as e:\n            diagnosis[\"issues\"].append(f\"Tree analysis failed: {e}\")\n        \n        return diagnosis\n\n    # Helper methods for internal functionality\n    \n    def _get_object_path(self, object_hash: str) -> Path:\n        \"\"\"Convert object hash to filesystem path.\"\"\"\n        return self.objects_dir / object_hash[:2] / object_hash[2:]\n    \n    def _preview_content(self, content: bytes, obj_type: str) -> str:\n        \"\"\"Generate human-readable content preview.\"\"\"\n        if obj_type == \"blob\":\n            # Try to decode as text, fall back to hex for binary\n            try:\n                text = content.decode('utf-8')\n                if len(text) > 200:\n                    return text[:200] + \"...\"\n                return text\n            except UnicodeDecodeError:\n                return f\"<binary content, {len(content)} bytes>\"\n        else:\n            # For tree and commit objects, always try text first\n            try:\n                return content.decode('utf-8')[:500]\n            except UnicodeDecodeError:\n                return content.hex()[:100] + \"...\"\n\n    def _parse_tree_entries(self, content: bytes) -> List[Dict[str, str]]:\n        \"\"\"Parse tree object entries for inspection.\"\"\"\n        entries = []\n        offset = 0\n        \n        while offset < len(content):\n            # Find null terminator for mode/name\n            null_pos = content.find(b'\\0', offset)\n            if null_pos == -1:\n                break\n                \n            mode_name = content[offset:null_pos].decode('utf-8')\n            try:\n                mode, name = mode_name.split(' ', 1)\n            except ValueError:\n                break\n                \n            # Extract 20-byte hash\n            if null_pos + 21 > len(content):\n                break\n                \n            hash_bytes = content[null_pos + 1:null_pos + 21]\n            hash_hex = hash_bytes.hex()\n            \n            entries.append({\n                \"mode\": mode,\n                \"name\": name,\n                \"hash\": hash_hex\n            })\n            \n            offset = null_pos + 21\n        \n        return entries\n\n    def _parse_commit_info(self, content: bytes) -> Dict[str, Any]:\n        \"\"\"Parse commit object for inspection.\"\"\"\n        try:\n            text = content.decode('utf-8')\n            lines = text.split('\\n')\n            \n            info = {\"parents\": []}\n            message_start = None\n            \n            for i, line in enumerate(lines):\n                if not line.strip():\n                    message_start = i + 1\n                    break\n                    \n                if line.startswith('tree '):\n                    info[\"tree\"] = line[5:]\n                elif line.startswith('parent '):\n                    info[\"parents\"].append(line[7:])\n                elif line.startswith('author '):\n                    info[\"author\"] = line[7:]\n                elif line.startswith('committer '):\n                    info[\"committer\"] = line[10:]\n            \n            if message_start:\n                info[\"message\"] = '\\n'.join(lines[message_start:])\n            \n            return info\n        except UnicodeDecodeError:\n            return {\"error\": \"Commit content is not valid UTF-8\"}\n\n    def _validate_object_store(self) -> List[str]:\n        \"\"\"Validate object store consistency.\"\"\"\n        violations = []\n        \n        if not self.objects_dir.exists():\n            violations.append(\"Objects directory missing\")\n            return violations\n        \n        # Check object files\n        for obj_dir in self.objects_dir.iterdir():\n            if not obj_dir.is_dir() or len(obj_dir.name) != 2:\n                continue\n                \n            for obj_file in obj_dir.iterdir():\n                if not obj_file.is_file():\n                    continue\n                    \n                full_hash = obj_dir.name + obj_file.name\n                if len(full_hash) != 40:\n                    violations.append(f\"Invalid object filename: {full_hash}\")\n                    continue\n                \n                # Validate object can be read and hash matches\n                obj_info = self.inspect_object(full_hash)\n                if \"error\" in obj_info:\n                    violations.append(f\"Corrupted object {full_hash}: {obj_info['error']}\")\n        \n        return violations\n\n    def _validate_references(self) -> List[str]:\n        \"\"\"Validate reference consistency.\"\"\"\n        violations = []\n        \n        # Check HEAD\n        if not self.head_path.exists():\n            violations.append(\"HEAD file missing\")\n        else:\n            try:\n                head_content = self.head_path.read_text().strip()\n                if head_content.startswith('ref: '):\n                    ref_path = self.git_dir / head_content[5:]\n                    if not ref_path.exists():\n                        violations.append(f\"HEAD points to non-existent ref: {head_content[5:]}\")\n                elif len(head_content) == 40:\n                    # Direct hash - validate object exists\n                    if not self._get_object_path(head_content).exists():\n                        violations.append(f\"HEAD points to non-existent object: {head_content}\")\n                else:\n                    violations.append(f\"Invalid HEAD content: {head_content}\")\n            except Exception as e:\n                violations.append(f\"Cannot read HEAD: {e}\")\n        \n        return violations\n\n    def _validate_index(self) -> List[str]:\n        \"\"\"Validate index consistency.\"\"\"\n        violations = []\n        \n        if not self.index_path.exists():\n            return []  # Index is optional\n        \n        try:\n            with open(self.index_path, 'rb') as f:\n                # Read index header\n                signature = f.read(4)\n                if signature != b'DIRC':\n                    violations.append(\"Invalid index signature\")\n                    return violations\n                \n                version = struct.unpack('>I', f.read(4))[0]\n                if version != 2:\n                    violations.append(f\"Unsupported index version: {version}\")\n                    return violations\n                \n                entry_count = struct.unpack('>I', f.read(4))[0]\n                \n                # Validate each entry references existing blob\n                for i in range(entry_count):\n                    try:\n                        entry_data = f.read(62)  # Fixed portion of entry\n                        if len(entry_data) != 62:\n                            violations.append(f\"Truncated index entry {i}\")\n                            break\n                        \n                        # Extract hash (20 bytes starting at offset 40)\n                        hash_bytes = entry_data[40:60]\n                        hash_hex = hash_bytes.hex()\n                        \n                        # Check if blob exists\n                        if not self._get_object_path(hash_hex).exists():\n                            violations.append(f\"Index entry {i} references non-existent blob: {hash_hex}\")\n                        \n                        # Skip variable-length path name\n                        flags = struct.unpack('>H', entry_data[60:62])[0]\n                        name_length = flags & 0xfff\n                        f.read(name_length)\n                        \n                        # Skip padding\n                        total_read = 62 + name_length\n                        padding = (8 - (total_read % 8)) % 8\n                        f.read(padding)\n                        \n                    except Exception as e:\n                        violations.append(f\"Error reading index entry {i}: {e}\")\n                        break\n        \n        except Exception as e:\n            violations.append(f\"Cannot read index: {e}\")\n        \n        return violations\n```\n\nThis debugging infrastructure provides comprehensive diagnostic capabilities that will help you identify and resolve issues throughout your Git implementation development.\n\n\n## Future Extensions\n\n> **Milestone(s):** This section goes beyond the eight core milestones, exploring advanced Git features that could be added to extend the basic implementation. Understanding these extensions helps architects plan for scalability and provides a roadmap for evolving the system.\n\nBuilding a basic Git implementation teaches the fundamental concepts of distributed version control, but Git's true power comes from its advanced features that enable large-scale collaboration and efficient storage. This section explores two critical extensions that transform a working but basic Git implementation into a production-ready system: remote repository support for distributed collaboration and pack file optimization for efficient storage.\n\n### Mental Model: The Local Shop Goes Global\n\nThink of our current Git implementation as a successful local bookstore. The store has excellent organization (object storage), efficient inventory management (index), clear categorization (references), and a good return policy (merge conflict resolution). Customers love shopping there, but they can only visit in person.\n\nNow imagine the bookstore wants to expand globally. They need two major capabilities: **shipping and receiving** (remote repository support) to exchange books with other locations, and **warehouse optimization** (pack files) to store thousands of books efficiently instead of keeping each book in its own individual box.\n\nRemote repository support is like building a shipping network - books (objects) need to be packaged, addressed, sent, received, unpacked, and integrated into the local inventory. Pack file optimization is like switching from individual book boxes to efficient warehouse shelving - instead of storing each book separately, related books are grouped together and compressed to save space.\n\n### Remote Repository Support\n\nRemote repository support transforms Git from a local version control system into a distributed collaboration platform. This extension adds the ability to synchronize changes with other repositories through push, pull, and fetch operations while maintaining the integrity of the content-addressable object store.\n\n#### Understanding Remote Operations\n\nThe fundamental challenge of remote repository support is **object synchronization** - determining which objects exist in each repository and transferring only the missing ones. Unlike simple file synchronization, Git's content-addressable storage enables sophisticated optimizations because identical content always has identical hashes regardless of repository location.\n\nEach remote operation follows a similar pattern: **discovery, negotiation, transfer, and integration**. The discovery phase determines what references (branches and tags) exist in each repository. The negotiation phase computes the minimal set of objects needed to bring repositories into sync. The transfer phase moves objects efficiently across the network. The integration phase updates local references and working directory to reflect the new state.\n\n> **Key Insight**: Remote operations are fundamentally about moving objects and updating references. The content-addressable nature of Git's object store makes this conceptually simple - if two repositories have the same object hash, they have identical content. The complexity lies in efficiently determining what needs to be transferred and handling reference conflicts.\n\n#### Remote Repository Data Model\n\nThe remote system extends our existing architecture with several new components that manage distributed state and network operations.\n\n| Component | Purpose | Storage Location | Key Responsibilities |\n|-----------|---------|------------------|----------------------|\n| `RemoteRepository` | Represents connection to remote Git repository | `.git/config` file | URL management, authentication, protocol selection |\n| `RemoteReferenceStore` | Tracks remote branch and tag states | `.git/refs/remotes/` | Remote reference caching, tracking branch relationships |\n| `TransferProtocol` | Handles network communication with remote repositories | Memory/network | Object discovery, negotiation, data transfer |\n| `PackProtocol` | Efficient object transfer format for network operations | Memory/temporary files | Object bundling, progress reporting, error recovery |\n| `RefSpec` | Maps local and remote reference names | `.git/config` | Branch mapping rules, push/fetch behavior configuration |\n\n#### Fetch Operation Architecture\n\nThe **fetch operation** retrieves objects and references from a remote repository without modifying the local working directory or current branch. This is the foundation operation that pull builds upon.\n\nThe fetch algorithm follows these detailed steps:\n\n1. **Remote Discovery**: Connect to the remote repository and retrieve the complete list of references (branches and tags) with their current commit hashes. This uses Git's upload-pack protocol to get an advertisement of all available references.\n\n2. **Reference Analysis**: Compare remote references against local remote-tracking branches stored in `.git/refs/remotes/origin/` to determine which references have changed since the last fetch.\n\n3. **Object Graph Walking**: Starting from new or updated remote references, walk backward through the commit graph to identify all objects (commits, trees, blobs) that exist in the remote repository but are missing from the local object store.\n\n4. **Want/Have Negotiation**: Send the remote repository a list of object hashes we \"want\" (missing objects) and \"have\" (existing objects). The remote responds with the minimal set of objects needed to satisfy our wants without sending objects we already possess.\n\n5. **Pack File Reception**: Receive a compressed pack file containing all requested objects in dependency order. Objects are transmitted in a format that allows streaming processing without requiring the entire pack file in memory.\n\n6. **Object Extraction**: Decompress and validate each object from the pack file, then store it in the local object store using the standard `.git/objects/xx/yy...` directory structure.\n\n7. **Reference Updates**: Update remote-tracking branches in `.git/refs/remotes/origin/` to reflect the current state of the remote repository. These references show what the remote looked like at fetch time.\n\n8. **Fast-Forward Analysis**: For each local branch that tracks a remote branch, determine if the local branch can be fast-forwarded to match the remote state (when the local branch is a direct ancestor of the remote).\n\n#### Push Operation Architecture\n\nThe **push operation** sends local objects and reference updates to a remote repository, requiring careful handling of concurrent modifications and reference conflicts.\n\nPush is more complex than fetch because it modifies the remote repository state, which may conflict with concurrent changes from other users. The push algorithm implements these steps:\n\n1. **Pre-Push Validation**: Verify that all local references being pushed point to valid commits in the local object store and that the user has appropriate permissions for the target remote repository.\n\n2. **Remote Reference Check**: Retrieve current remote references to detect if any branches being pushed have been modified by other users since the last fetch. This prevents accidentally overwriting concurrent work.\n\n3. **Fast-Forward Verification**: For each branch being pushed, verify that the push represents a fast-forward update (the remote branch is an ancestor of the local branch) unless force push is explicitly enabled.\n\n4. **Object Dependency Analysis**: Walk the commit graph from local branch tips back to the last known remote state, collecting all objects that need to be transmitted to the remote repository.\n\n5. **Pack File Generation**: Create a pack file containing all objects that exist locally but are missing from the remote repository. Objects are compressed and ordered to optimize transmission efficiency.\n\n6. **Atomic Push Transaction**: Send the pack file and reference updates to the remote repository as an atomic transaction. Either all references update successfully, or none do, preventing partial updates that could corrupt remote repository state.\n\n7. **Reference Conflict Resolution**: If remote references have changed during the push operation, abort the push and require the user to fetch latest changes and resolve conflicts locally before retrying.\n\n8. **Success Confirmation**: Receive confirmation from the remote repository that all objects were stored successfully and all references were updated atomically.\n\n#### Remote Reference Management\n\nRemote-tracking branches solve the problem of maintaining local knowledge about remote repository state without interfering with local development. These references use a separate namespace to avoid conflicts with local branches.\n\n| Reference Type | Storage Location | Format | Purpose |\n|----------------|------------------|---------|---------|\n| Local Branch | `.git/refs/heads/feature` | `commit_hash` | Local development work |\n| Remote Branch | `.git/refs/remotes/origin/feature` | `commit_hash` | Last known state of remote branch |\n| Tracking Relationship | `.git/config` | `[branch \"feature\"] remote = origin merge = refs/heads/feature` | Links local and remote branches |\n\nThe tracking relationship enables Git to provide helpful information about branch divergence - whether the local branch is ahead, behind, or has diverged from its remote counterpart.\n\n#### Pull Operation as Fetch + Merge\n\nThe **pull operation** combines fetch with automatic merging, implementing the common workflow of retrieving remote changes and integrating them into the current local branch.\n\nPull executes as two distinct phases:\n\n1. **Fetch Phase**: Execute a complete fetch operation to retrieve all remote objects and update remote-tracking branches. This ensures local knowledge of remote state is current.\n\n2. **Integration Phase**: Merge the updated remote-tracking branch into the current local branch using the three-way merge algorithm implemented in Milestone 8. If conflicts arise, they are presented to the user for manual resolution.\n\nThe integration phase supports multiple strategies:\n- **Merge Strategy**: Create a merge commit that combines local and remote changes, preserving the parallel development history\n- **Rebase Strategy**: Replay local commits on top of the remote branch, creating a linear history without merge commits\n- **Fast-Forward Strategy**: If the local branch hasn't diverged, simply update the local branch pointer to match the remote\n\n> **Decision: Pull Integration Strategy**\n> - **Context**: Pull operations need to integrate remote changes into local branches, but different projects prefer different history structures\n> - **Options Considered**: Always merge, always rebase, configurable per repository, configurable per branch\n> - **Decision**: Default to merge with configuration options for rebase and fast-forward-only modes\n> - **Rationale**: Merge preserves complete history and is safest for beginners, while advanced users can configure alternative strategies per their workflow needs\n> - **Consequences**: More complex pull implementation but supports both simple and advanced workflows without forcing a single approach\n\n#### Protocol Implementation Considerations\n\nGit's network protocols have evolved to optimize performance and security for distributed collaboration. The modern protocol supports multiple transport layers and advanced features.\n\n| Protocol Feature | HTTP(S) Transport | SSH Transport | Local Filesystem |\n|------------------|-------------------|---------------|-------------------|\n| Authentication | Username/password, tokens | SSH keys, agents | File permissions |\n| Encryption | TLS | SSH tunnel | None needed |\n| Firewall Friendly | Yes (port 80/443) | No (port 22) | N/A |\n| Performance | Good | Excellent | Excellent |\n| Setup Complexity | Medium | High | Low |\n\nThe protocol implements several optimizations:\n- **Multi-round Negotiation**: Multiple rounds of want/have negotiation minimize transferred objects\n- **Thin Packs**: Pack files can reference objects assumed to exist in the destination repository\n- **Progress Reporting**: Long operations provide progress feedback for user experience\n- **Resumable Transfers**: Large transfers can resume after network interruptions\n\n#### Architecture Decision Records for Remote Support\n\n> **Decision: Remote Configuration Storage**\n> - **Context**: Remote repository URLs, authentication, and mapping rules need persistent storage\n> - **Options Considered**: Separate remote config file, embed in main .git/config, database storage\n> - **Decision**: Extend existing .git/config file with [remote] and [branch] sections\n> - **Rationale**: Maintains compatibility with existing Git configuration patterns, supports version control of configuration, enables per-repository customization\n> - **Consequences**: Config file becomes more complex but remains human-readable and editable\n\n> **Decision: Object Transfer Batching**\n> - **Context**: Large repositories may have thousands of objects to transfer, requiring efficient batching\n> - **Options Considered**: Transfer all objects in single batch, fixed-size batches, adaptive batching based on network conditions\n> - **Decision**: Implement adaptive batching with fallback to smaller batches on network errors\n> - **Rationale**: Optimizes for fast networks while providing resilience on unreliable connections\n> - **Consequences**: More complex transfer logic but better user experience across different network conditions\n\n### Pack File Optimization\n\nPack files transform Git's storage efficiency by replacing individual compressed objects with highly optimized compressed bundles that use delta compression and cross-object deduplication.\n\n#### Understanding the Storage Efficiency Problem\n\nOur current object store implementation stores each blob, tree, and commit as an individual zlib-compressed file. While this provides excellent simplicity and reliability, it has significant storage inefficiencies for real-world repositories:\n\n- **Similar Content Duplication**: Multiple versions of the same file share most content but are stored completely separately. A single-line change to a large file results in two complete compressed copies.\n- **Small Object Overhead**: Each object requires a minimum file system block (typically 4KB), so a 100-byte commit object wastes ~3900 bytes of storage.\n- **Directory Fragmentation**: Thousands of small files in `.git/objects/` create file system performance problems and backup inefficiencies.\n\nPack files solve these problems by implementing **delta compression** - storing one version of a file completely, then storing subsequent versions as compact diffs against the base version.\n\n#### Mental Model: The Efficient Warehouse\n\nThink of our current object storage as a warehouse where every item, no matter how similar, gets its own labeled box. If you stock 50 different versions of the same book that only differ in minor edits, you need 50 complete boxes.\n\nPack files are like an efficient warehouse manager who says: \"Let's keep one complete copy of the first edition, then for each subsequent edition, just store a note saying 'same as first edition but change page 247 paragraph 2'.\" The warehouse still contains all versions, but uses dramatically less space.\n\nThe warehouse manager also batches related items together - instead of individual boxes scattered throughout the warehouse, related items are grouped on the same shelf for efficient access.\n\n#### Pack File Data Structure\n\nA pack file consists of a header, a series of packed objects, and an index for efficient random access. The structure optimizes for both storage efficiency and access performance.\n\n| Component | Size | Purpose | Format |\n|-----------|------|---------|---------|\n| Pack Header | 12 bytes | File format identification | `PACK` signature + version + object count |\n| Packed Objects | Variable | Compressed object data with delta chains | Type + size + compressed data or delta instructions |\n| Pack Checksum | 20 bytes | Data integrity verification | SHA-1 hash of all preceding pack data |\n| Pack Index | Separate file | Fast object lookup by hash | Sorted hash table with offset pointers |\n\n#### Delta Compression Algorithm\n\nDelta compression identifies similar objects and stores only the differences, achieving dramatic space savings for repositories with many similar files.\n\nThe delta compression algorithm works as follows:\n\n1. **Base Object Selection**: For each object being packed, identify potential base objects that share significant content. Heuristics prioritize objects with similar paths, sizes, and content signatures.\n\n2. **Delta Generation**: Create a delta script that transforms the base object into the target object. The delta consists of copy instructions (copy N bytes from offset X in base) and insert instructions (insert these literal bytes).\n\n3. **Chain Length Management**: Limit delta chains to prevent excessive decompression overhead. If Object C is a delta of Object B, which is a delta of Object A, accessing Object C requires decompressing A, then B, then C.\n\n4. **Size Efficiency Verification**: Only use delta compression when it actually saves space. Sometimes small files or completely different files are more efficient stored as complete objects.\n\n5. **Access Pattern Optimization**: Place frequently accessed objects (recent commits, popular branches) early in the pack file and avoid long delta chains for objects likely to be accessed frequently.\n\n#### Pack Index Structure\n\nThe pack index enables efficient random access to objects within pack files without scanning the entire pack. The index uses a sophisticated multi-level structure optimized for both space and lookup performance.\n\n| Index Level | Purpose | Structure | Access Time |\n|-------------|---------|-----------|-------------|\n| Hash Fanout Table | First-level lookup by hash prefix | 256 entries (one per hash byte value) | O(1) |\n| Object Hash Table | Sorted list of all object hashes in pack | 20-byte SHA-1 hashes in sorted order | O(log n) |\n| CRC Checksums | Integrity verification for individual objects | 4-byte CRC per object | O(1) |\n| Pack Offsets | File positions of objects within pack file | 4 or 8-byte offsets depending on pack size | O(1) |\n\nThe index lookup algorithm:\n1. Use the first byte of the target object hash to index into the fanout table\n2. Binary search the hash table segment identified by the fanout table\n3. If hash is found, retrieve the corresponding pack offset\n4. Seek to that offset in the pack file and read the object data\n5. Verify object integrity using the stored CRC checksum\n\n#### Garbage Collection and Pack Generation\n\nGarbage collection transforms loose objects into efficient pack files and removes objects that are no longer reachable from any reference.\n\nThe garbage collection process implements these phases:\n\n1. **Reachability Analysis**: Starting from all references (branches, tags, HEAD), walk the complete object graph to identify all reachable objects. Any object not reachable from a reference is considered garbage.\n\n2. **Pack Candidate Selection**: Group objects into logical packs based on access patterns. Typically, recent objects accessed together are packed together, while historical objects form separate packs.\n\n3. **Delta Base Selection**: For each object, identify optimal delta bases using heuristics based on path similarity, size, and content. This is computationally expensive but critical for pack efficiency.\n\n4. **Pack Generation**: Create pack files with objects ordered to optimize delta compression and access patterns. Recent commits and trees are typically placed early in packs.\n\n5. **Index Generation**: Build pack index files that enable efficient random access to packed objects without decompressing the entire pack.\n\n6. **Atomic Replacement**: Atomically replace loose objects with pack files, ensuring repository integrity is maintained even if the process is interrupted.\n\n7. **Cleanup**: Remove loose objects that are now redundant with packed versions, and remove old pack files that have been superseded.\n\n#### Integration with Existing Object Store\n\nPack file support extends our existing `ObjectStore` component without breaking existing functionality. The enhanced object store checks both loose objects and pack files when retrieving objects.\n\n| Operation | Loose Objects | Pack Files | Combined Behavior |\n|-----------|---------------|------------|-------------------|\n| Store Object | Write to `.git/objects/xx/yy...` | N/A (packs are read-only after creation) | New objects always stored loose initially |\n| Retrieve Object | Check `.git/objects/` first | Search pack indexes if not found loose | Transparent to callers |\n| Object Exists | Scan directory | Search pack indexes | Return true if found in either location |\n| List All Objects | Directory traversal | Parse all pack indexes | Union of loose and packed objects |\n\nThe object retrieval algorithm becomes:\n1. Check for loose object at `.git/objects/xx/yy...`\n2. If found, decompress and return\n3. If not found, search all pack indexes for the object hash\n4. If found in pack, seek to pack offset and decompress object (following delta chain if necessary)\n5. If not found anywhere, return object not found error\n\n#### Architecture Decision Records for Pack Files\n\n> **Decision: Delta Chain Length Limits**\n> - **Context**: Long delta chains save more space but increase access time for individual objects\n> - **Options Considered**: No limit (maximum compression), fixed limit of 10, adaptive limit based on object access frequency\n> - **Decision**: Implement fixed limit of 50 with shorter limits for frequently accessed objects\n> - **Rationale**: Balances storage efficiency with access performance, prevents pathological cases where accessing one object requires decompressing hundreds of deltas\n> - **Consequences**: Some compression efficiency is sacrificed for predictable access performance\n\n> **Decision: Pack File Size Limits**\n> - **Context**: Large pack files are more efficient but harder to transfer and backup\n> - **Options Considered**: No size limit, 2GB limit (32-bit offset compatibility), 4GB limit, multiple size tiers\n> - **Decision**: 2GB size limit with automatic pack splitting for larger repositories\n> - **Rationale**: Maintains compatibility with systems that have 32-bit limitations while supporting large repositories through multiple packs\n> - **Consequences**: More complex pack management but broader system compatibility\n\n#### Performance Impact Analysis\n\nPack file optimization provides dramatic improvements in storage efficiency and some operations, while slightly impacting others.\n\n| Operation | Storage Impact | Performance Impact | Network Impact |\n|-----------|----------------|-------------------|----------------|\n| Repository Size | 60-90% reduction typical | N/A | Faster clones and fetches |\n| Object Retrieval | N/A | Slightly slower (delta decompression) | N/A |\n| Garbage Collection | Enables cleanup of unreachable objects | CPU intensive during pack generation | N/A |\n| Backup/Transfer | Much smaller repository size | N/A | Dramatically faster |\n\nThe storage savings are particularly dramatic for repositories with:\n- Many small commits (reduces per-object overhead)\n- Large files with incremental changes (delta compression)\n- Long history (more opportunities for similar content)\n\nTypical compression ratios:\n- **Text-heavy repositories**: 70-85% size reduction\n- **Binary-heavy repositories**: 30-60% size reduction  \n- **Mixed repositories**: 60-80% size reduction\n\n### Integration Considerations\n\nBoth remote repository support and pack file optimization integrate cleanly with the existing eight-milestone architecture without requiring fundamental changes to core components.\n\n#### Compatibility with Existing Components\n\nThe extensions maintain full compatibility with existing functionality:\n\n- **Object Store**: Enhanced to check both loose objects and pack files transparently\n- **References**: Remote-tracking branches use the same reference format as local branches\n- **Index**: Unchanged - staging area works identically with packed and loose objects\n- **Merge Algorithm**: Unchanged - operates on object content regardless of storage format\n- **Diff Algorithm**: Unchanged - compares object content regardless of storage location\n\n#### Migration Strategy\n\nImplementing these extensions follows a progressive enhancement approach:\n\n1. **Phase 1**: Add remote repository configuration and basic fetch/push without pack file support\n2. **Phase 2**: Implement pack file reading to support repositories that already contain pack files\n3. **Phase 3**: Add pack file generation during garbage collection\n4. **Phase 4**: Optimize remote operations to use pack protocol for efficient transfers\n\nThis approach allows the system to evolve incrementally while maintaining full functionality at each stage.\n\n### Common Pitfalls\n\n⚠️ **Pitfall: Ignoring Network Failure Recovery**\nWhen implementing remote operations, developers often assume network operations will succeed. In reality, network transfers can fail at any point, leaving repositories in inconsistent states. Always implement atomic operations where either all references update successfully or none do. Use temporary files for pack reception and atomic rename operations for reference updates.\n\n⚠️ **Pitfall: Delta Chain Performance Degradation**\nLong delta chains can make individual object access extremely slow, especially for frequently accessed objects like recent commits. Implement delta chain length limits and prioritize recent/frequently accessed objects as delta bases rather than targets. Monitor access patterns and repack when performance degrades.\n\n⚠️ **Pitfall: Pack Index Corruption Handling**\nPack indexes can become corrupted, making objects inaccessible even though they exist in the pack file. Always verify pack index integrity on startup and implement index regeneration from pack files. Never trust index entries without verifying the corresponding pack file data.\n\n⚠️ **Pitfall: Concurrent Access to Pack Files**\nMultiple processes may try to read pack files simultaneously, or garbage collection may try to delete packs while they're being read. Implement proper file locking for pack operations and use atomic operations for pack replacement. Consider delayed deletion of old pack files to allow ongoing operations to complete.\n\n### Implementation Guidance\n\nThe implementation of these advanced features requires careful attention to network protocols, binary file formats, and concurrent access patterns. The following guidance provides a foundation for building production-ready extensions.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| HTTP Transport | `urllib3` with basic auth | `requests` with session management and retry logic |\n| SSH Transport | `subprocess` calls to `ssh` command | `paramiko` library for pure Python SSH |\n| Pack File I/O | `struct` module for binary formats | `mmap` for efficient large file access |\n| Delta Compression | Custom implementation following Git format | `python-delta` library if available |\n| Network Protocol | Simple HTTP POST/GET | Full Git smart HTTP protocol |\n\n#### Recommended File Structure\n\n```python\n# Remote repository support\nremote/\n    __init__.py\n    protocols/\n        __init__.py\n        http_transport.py      # HTTP/HTTPS transport implementation\n        ssh_transport.py       # SSH transport implementation  \n        local_transport.py     # Local filesystem transport\n    operations/\n        __init__.py\n        fetch.py              # Fetch operation implementation\n        push.py               # Push operation implementation\n        pull.py               # Pull operation (fetch + merge)\n    config/\n        __init__.py\n        remote_config.py      # Remote repository configuration\n        refspec.py            # Reference specification parsing\n\n# Pack file support  \npack/\n    __init__.py\n    pack_file.py             # Pack file reading and writing\n    pack_index.py            # Pack index management\n    delta.py                 # Delta compression implementation\n    garbage_collection.py    # GC and pack generation\n```\n\n#### Infrastructure Starter Code\n\nHere's complete infrastructure code for basic remote configuration management:\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nRemote repository configuration management.\nComplete implementation ready for use.\n\"\"\"\n\nimport configparser\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\nfrom urllib.parse import urlparse\n\nclass RemoteConfig:\n    \"\"\"Manages remote repository configuration in .git/config file.\"\"\"\n    \n    def __init__(self, git_dir: Path):\n        self.git_dir = git_dir\n        self.config_path = git_dir / \"config\"\n        self.config = configparser.ConfigParser()\n        if self.config_path.exists():\n            self.config.read(self.config_path)\n    \n    def add_remote(self, name: str, url: str, fetch_refspec: str = None) -> bool:\n        \"\"\"Add a new remote repository configuration.\"\"\"\n        if fetch_refspec is None:\n            fetch_refspec = f\"+refs/heads/*:refs/remotes/{name}/*\"\n        \n        section_name = f\"remote \\\"{name}\\\"\"\n        self.config[section_name] = {\n            'url': url,\n            'fetch': fetch_refspec\n        }\n        self._save_config()\n        return True\n    \n    def remove_remote(self, name: str) -> bool:\n        \"\"\"Remove a remote repository configuration.\"\"\"\n        section_name = f\"remote \\\"{name}\\\"\"\n        if section_name in self.config:\n            self.config.remove_section(section_name)\n            self._save_config()\n            return True\n        return False\n    \n    def get_remote_url(self, name: str) -> Optional[str]:\n        \"\"\"Get URL for named remote.\"\"\"\n        section_name = f\"remote \\\"{name}\\\"\"\n        if section_name in self.config:\n            return self.config[section_name].get('url')\n        return None\n    \n    def list_remotes(self) -> List[str]:\n        \"\"\"List all configured remote names.\"\"\"\n        remotes = []\n        for section in self.config.sections():\n            if section.startswith('remote \"'):\n                # Extract name from 'remote \"origin\"' format\n                name = section[8:-1]  # Remove 'remote \"' and '\"'\n                remotes.append(name)\n        return remotes\n    \n    def get_fetch_refspecs(self, name: str) -> List[str]:\n        \"\"\"Get fetch refspecs for named remote.\"\"\"\n        section_name = f\"remote \\\"{name}\\\"\"\n        if section_name in self.config:\n            fetch_spec = self.config[section_name].get('fetch', '')\n            return [fetch_spec] if fetch_spec else []\n        return []\n    \n    def _save_config(self):\n        \"\"\"Save configuration to .git/config file.\"\"\"\n        with open(self.config_path, 'w') as f:\n            self.config.write(f)\n\nclass RefSpec:\n    \"\"\"Parses and manages Git refspecs for push/fetch operations.\"\"\"\n    \n    def __init__(self, refspec: str):\n        self.refspec = refspec\n        self.force = refspec.startswith('+')\n        spec = refspec[1:] if self.force else refspec\n        \n        if ':' in spec:\n            self.source, self.destination = spec.split(':', 1)\n        else:\n            self.source = spec\n            self.destination = spec\n    \n    def matches_ref(self, ref: str) -> bool:\n        \"\"\"Check if this refspec matches the given reference.\"\"\"\n        if '*' in self.source:\n            # Handle wildcard matching\n            prefix = self.source[:self.source.index('*')]\n            return ref.startswith(prefix)\n        else:\n            return ref == self.source\n    \n    def transform_ref(self, ref: str) -> str:\n        \"\"\"Transform source ref to destination using this refspec.\"\"\"\n        if '*' in self.source and '*' in self.destination:\n            # Handle wildcard transformation\n            prefix = self.source[:self.source.index('*')]\n            suffix = ref[len(prefix):]\n            dest_prefix = self.destination[:self.destination.index('*')]\n            return dest_prefix + suffix\n        else:\n            return self.destination\n\n# Network transport helper\nclass HTTPTransport:\n    \"\"\"Simple HTTP transport for Git operations.\"\"\"\n    \n    def __init__(self, base_url: str):\n        self.base_url = base_url.rstrip('/')\n        \n    def discover_refs(self, service: str) -> List[Tuple[str, str]]:\n        \"\"\"Discover available references on remote repository.\"\"\"\n        import urllib.request\n        \n        url = f\"{self.base_url}/info/refs?service={service}\"\n        try:\n            with urllib.request.urlopen(url) as response:\n                # Parse Git's advertisement format\n                refs = []\n                for line in response:\n                    line = line.decode('utf-8').strip()\n                    if line and not line.startswith('#'):\n                        parts = line.split('\\t')\n                        if len(parts) == 2:\n                            hash_val, ref_name = parts\n                            refs.append((ref_name, hash_val))\n                return refs\n        except Exception as e:\n            print(f\"Failed to discover refs: {e}\")\n            return []\n```\n\n#### Core Logic Skeleton Code\n\nHere are the skeleton implementations for the main remote operations:\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nCore remote operations - fetch, push, pull.\nSkeletons for learner implementation.\n\"\"\"\n\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Set, Tuple\n\nclass FetchOperation:\n    \"\"\"Implements git fetch operation.\"\"\"\n    \n    def __init__(self, repository, object_store, reference_manager, remote_config):\n        self.repository = repository\n        self.object_store = object_store\n        self.reference_manager = reference_manager\n        self.remote_config = remote_config\n    \n    def fetch(self, remote_name: str, refspecs: List[str] = None) -> Dict[str, str]:\n        \"\"\"\n        Fetch objects and references from remote repository.\n        Returns mapping of updated references to their new commit hashes.\n        \"\"\"\n        # TODO 1: Get remote URL from configuration\n        # TODO 2: Discover available references on remote repository  \n        # TODO 3: Determine which references need updating based on refspecs\n        # TODO 4: Calculate missing objects using want/have negotiation\n        # TODO 5: Request pack file containing missing objects from remote\n        # TODO 6: Receive and validate pack file from remote\n        # TODO 7: Extract objects from pack file and store in object store\n        # TODO 8: Update remote-tracking references in .git/refs/remotes/\n        # TODO 9: Return mapping of updated references\n        # Hint: Use _discover_remote_refs(), _negotiate_objects(), _receive_pack()\n        pass\n    \n    def _discover_remote_refs(self, remote_url: str) -> List[Tuple[str, str]]:\n        \"\"\"Discover what references exist on the remote repository.\"\"\"\n        # TODO 1: Connect to remote repository using appropriate transport\n        # TODO 2: Send upload-pack request to get reference advertisement\n        # TODO 3: Parse response to extract (ref_name, commit_hash) pairs\n        # TODO 4: Return list of available references\n        # Hint: Different transports (HTTP, SSH, local) have different protocols\n        pass\n    \n    def _negotiate_objects(self, remote_refs: List[Tuple[str, str]]) -> Set[str]:\n        \"\"\"Determine which objects need to be fetched from remote.\"\"\"\n        # TODO 1: Identify commit hashes we want (from remote refs we're fetching)\n        # TODO 2: Walk local object store to identify commit hashes we have\n        # TODO 3: Send want/have lists to remote repository\n        # TODO 4: Receive response indicating which objects will be sent\n        # TODO 5: Return set of object hashes that will be transferred\n        # Hint: This minimizes network transfer by avoiding duplicate objects\n        pass\n    \n    def _receive_pack(self, expected_objects: Set[str]) -> Path:\n        \"\"\"Receive pack file containing requested objects.\"\"\"\n        # TODO 1: Receive pack file header with object count\n        # TODO 2: Stream pack file data to temporary file\n        # TODO 3: Validate pack file checksum\n        # TODO 4: Verify pack contains expected objects\n        # TODO 5: Return path to temporary pack file\n        # Hint: Pack files can be large - stream to disk, don't buffer in memory\n        pass\n\nclass PushOperation:\n    \"\"\"Implements git push operation.\"\"\"\n    \n    def __init__(self, repository, object_store, reference_manager, remote_config):\n        self.repository = repository\n        self.object_store = object_store\n        self.reference_manager = reference_manager\n        self.remote_config = remote_config\n    \n    def push(self, remote_name: str, refspecs: List[str], force: bool = False) -> Dict[str, str]:\n        \"\"\"\n        Push local references and objects to remote repository.\n        Returns mapping of pushed references to their commit hashes.\n        \"\"\"\n        # TODO 1: Get remote URL and discover current remote references\n        # TODO 2: Validate push refspecs and check for conflicts\n        # TODO 3: Verify fast-forward requirement unless force=True\n        # TODO 4: Calculate objects that need to be sent to remote\n        # TODO 5: Generate pack file containing required objects\n        # TODO 6: Send pack file and reference updates atomically\n        # TODO 7: Verify remote accepted all updates successfully\n        # TODO 8: Update local remote-tracking references\n        # TODO 9: Return mapping of successfully pushed references\n        # Hint: Push must be atomic - either all refs update or none do\n        pass\n    \n    def _verify_fast_forward(self, local_ref: str, remote_ref: str, force: bool) -> bool:\n        \"\"\"Verify that push represents a fast-forward update.\"\"\"\n        # TODO 1: Get commit hash for local reference\n        # TODO 2: Get commit hash for remote reference  \n        # TODO 3: If force=True, allow any update\n        # TODO 4: Check if remote commit is ancestor of local commit\n        # TODO 5: Return True only if update is fast-forward or forced\n        # Hint: Use commit graph traversal to check ancestry\n        pass\n    \n    def _generate_pack_file(self, required_objects: Set[str]) -> Path:\n        \"\"\"Generate pack file containing objects to send to remote.\"\"\"\n        # TODO 1: Create temporary pack file\n        # TODO 2: Write pack header with object count\n        # TODO 3: Write each object in dependency order (commits, trees, blobs)\n        # TODO 4: Apply delta compression where beneficial\n        # TODO 5: Write pack file checksum\n        # TODO 6: Return path to completed pack file\n        # Hint: Objects must be ordered so dependencies come before referents\n        pass\n\n# Pack file skeleton implementation\nclass PackFile:\n    \"\"\"Reads and writes Git pack files.\"\"\"\n    \n    def __init__(self, pack_path: Path):\n        self.pack_path = pack_path\n        self.index_path = pack_path.with_suffix('.idx')\n    \n    def read_object(self, object_hash: str) -> Optional[Tuple[str, bytes]]:\n        \"\"\"Read an object from this pack file.\"\"\"\n        # TODO 1: Look up object hash in pack index to get offset\n        # TODO 2: Seek to offset in pack file\n        # TODO 3: Read object header (type and size)\n        # TODO 4: If object is delta, resolve delta chain\n        # TODO 5: Decompress object content\n        # TODO 6: Return (object_type, content) tuple\n        # Hint: Delta objects require recursive resolution\n        pass\n    \n    def _resolve_delta_chain(self, offset: int) -> bytes:\n        \"\"\"Resolve delta chain to get final object content.\"\"\"\n        # TODO 1: Read delta object at given offset\n        # TODO 2: Identify base object (by offset or hash)\n        # TODO 3: Recursively resolve base object content\n        # TODO 4: Apply delta instructions to base content\n        # TODO 5: Return final reconstructed content\n        # Hint: Delta chains can be deep - avoid stack overflow\n        pass\n```\n\n#### Milestone Checkpoints\n\nAfter implementing remote repository support:\n\n**Checkpoint 1: Basic Remote Configuration**\n```bash\n# Test remote configuration\npython -c \"\nfrom remote.config.remote_config import RemoteConfig\nfrom pathlib import Path\n\nconfig = RemoteConfig(Path('.git'))\nconfig.add_remote('origin', 'https://github.com/user/repo.git')\nprint('Remotes:', config.list_remotes())\nprint('Origin URL:', config.get_remote_url('origin'))\n\"\n# Expected: Shows 'origin' in remote list with correct URL\n```\n\n**Checkpoint 2: Reference Discovery**\n```bash\n# Test remote reference discovery\npython -c \"\nfrom remote.operations.fetch import FetchOperation\n# Should connect to remote and list available branches/tags\n# Expected: List of (ref_name, commit_hash) pairs\n\"\n```\n\nAfter implementing pack file support:\n\n**Checkpoint 3: Pack File Reading**\n```bash\n# Create a pack file and verify reading\npython -c \"\nfrom pack.pack_file import PackFile\n# Should be able to read existing pack files\n# Expected: Successfully retrieve objects from pack\n\"\n```\n\n**Checkpoint 4: Repository Size Comparison**\n```bash\n# Compare repository size before/after packing\ndu -sh .git/objects  # Before packing\n# Run garbage collection with pack generation\ndu -sh .git/objects  # After packing - should be much smaller\n```\n\n#### Debugging Tips for Remote Operations\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|----------------|-----|\n| Fetch hangs forever | Network timeout or incorrect URL | Check network connectivity, verify URL format | Add timeout handling, validate URLs |\n| Objects missing after fetch | Pack file corruption or incomplete transfer | Verify pack file checksum, check object count | Re-fetch with integrity verification |\n| Push rejected | Non-fast-forward update or permissions | Check if remote branch has new commits | Fetch first, merge conflicts, then push |\n| Pack files not found | Index corruption or missing pack files | List `.git/objects/pack/` directory contents | Regenerate pack indexes or re-clone |\n\n#### Performance Monitoring\n\nTrack key metrics when implementing these extensions:\n\n```python\nclass RemoteOperationMetrics:\n    \"\"\"Track performance metrics for remote operations.\"\"\"\n    \n    def __init__(self):\n        self.objects_transferred = 0\n        self.bytes_transferred = 0\n        self.operation_time = 0.0\n        self.network_time = 0.0\n        self.compression_ratio = 0.0\n    \n    def log_fetch_completed(self, objects: int, bytes_total: int, duration: float):\n        \"\"\"Log successful fetch operation metrics.\"\"\"\n        print(f\"Fetch completed: {objects} objects, {bytes_total} bytes, {duration:.2f}s\")\n        print(f\"Transfer rate: {bytes_total / duration / 1024:.1f} KB/s\")\n```\n\nThese extensions transform the basic Git implementation into a system capable of handling real-world distributed development workflows and large-scale repositories efficiently.\n\n### Implementation Guidance\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Remote Transport | `urllib3` with basic HTTP | `requests` with session pooling and retry logic |\n| Pack File I/O | `struct` module for binary parsing | `mmap` for efficient large file access |\n| Delta Compression | Basic diff implementation | Optimized Myers algorithm with binary search |\n| Network Protocol | Simple request/response | Full Git smart protocol with capability negotiation |\n| Concurrency | Sequential operations | `asyncio` for concurrent fetch/push operations |\n\n#### Recommended File Structure\n\n```python\n# Extensions to existing structure\nextensions/\n    remote/\n        __init__.py\n        transport/\n            __init__.py\n            http_transport.py      # HTTP/HTTPS protocol implementation\n            ssh_transport.py       # SSH protocol implementation\n            protocol.py            # Git wire protocol parsing\n        operations/\n            __init__.py\n            fetch.py              # Fetch operation with negotiation\n            push.py               # Push with conflict detection\n            pull.py               # Pull as fetch + merge\n        config/\n            __init__.py\n            remote_manager.py     # Remote repository management\n            refspec_parser.py     # Reference specification handling\n    \n    pack/\n        __init__.py\n        pack_reader.py           # Read existing pack files\n        pack_writer.py           # Create new pack files\n        pack_index.py            # Pack index management\n        delta_compression.py     # Delta encoding/decoding\n        garbage_collector.py     # Pack generation and cleanup\n```\n\n#### Infrastructure Starter Code\n\nComplete network transport implementation:\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nGit HTTP transport implementation.\nProduction-ready code for network operations.\n\"\"\"\n\nimport urllib.request\nimport urllib.parse\nfrom typing import Dict, List, Optional, Tuple\nfrom pathlib import Path\n\nclass GitHTTPTransport:\n    \"\"\"Handles Git smart HTTP protocol operations.\"\"\"\n    \n    def __init__(self, base_url: str, username: str = None, password: str = None):\n        self.base_url = base_url.rstrip('/')\n        self.username = username\n        self.password = password\n        self._setup_auth()\n    \n    def _setup_auth(self):\n        \"\"\"Configure HTTP authentication if credentials provided.\"\"\"\n        if self.username and self.password:\n            password_mgr = urllib.request.HTTPPasswordMgrWithDefaultRealm()\n            password_mgr.add_password(None, self.base_url, self.username, self.password)\n            auth_handler = urllib.request.HTTPBasicAuthHandler(password_mgr)\n            opener = urllib.request.build_opener(auth_handler)\n            urllib.request.install_opener(opener)\n    \n    def discover_refs(self, service: str) -> List[Tuple[str, str]]:\n        \"\"\"\n        Discover available references on remote repository.\n        Service should be 'git-upload-pack' for fetch or 'git-receive-pack' for push.\n        \"\"\"\n        url = f\"{self.base_url}/info/refs?service={service}\"\n        \n        try:\n            request = urllib.request.Request(url)\n            request.add_header('User-Agent', 'git/2.0 (custom-implementation)')\n            \n            with urllib.request.urlopen(request, timeout=30) as response:\n                # Parse Git smart HTTP protocol response\n                refs = []\n                lines = response.read().decode('utf-8').splitlines()\n                \n                # Skip protocol header lines\n                for line in lines:\n                    if line.startswith('#'):\n                        continue\n                    if '\\t' in line:\n                        hash_and_caps, ref_name = line.split('\\t', 1)\n                        # Remove capability advertisements\n                        object_hash = hash_and_caps.split(' ')[0]\n                        if len(object_hash) == 40:  # Valid SHA-1\n                            refs.append((ref_name, object_hash))\n                \n                return refs\n                \n        except urllib.error.URLError as e:\n            raise ConnectionError(f\"Failed to connect to {url}: {e}\")\n        except Exception as e:\n            raise RuntimeError(f\"Error discovering refs: {e}\")\n    \n    def send_pack_request(self, service: str, request_data: bytes) -> bytes:\n        \"\"\"Send pack request and receive response.\"\"\"\n        url = f\"{self.base_url}/{service}\"\n        \n        request = urllib.request.Request(url, data=request_data)\n        request.add_header('Content-Type', f'application/x-{service}-request')\n        request.add_header('Accept', f'application/x-{service}-result')\n        request.add_header('User-Agent', 'git/2.0 (custom-implementation)')\n        \n        try:\n            with urllib.request.urlopen(request, timeout=300) as response:\n                return response.read()\n        except urllib.error.HTTPError as e:\n            error_msg = e.read().decode('utf-8') if e.fp else str(e)\n            raise RuntimeError(f\"Server error {e.code}: {error_msg}\")\n        except Exception as e:\n            raise RuntimeError(f\"Network error: {e}\")\n\nclass PackProtocolHandler:\n    \"\"\"Handles Git pack protocol for efficient object transfer.\"\"\"\n    \n    @staticmethod\n    def create_want_have_request(wants: List[str], haves: List[str]) -> bytes:\n        \"\"\"Create want/have negotiation request.\"\"\"\n        lines = []\n        \n        # Add want lines\n        for i, want in enumerate(wants):\n            if i == 0:\n                # First want line includes capabilities\n                line = f\"want {want} multi_ack_detailed side-band-64k ofs-delta\\n\"\n            else:\n                line = f\"want {want}\\n\"\n            lines.append(PackProtocolHandler._pkt_line(line))\n        \n        # Separator\n        lines.append(b\"0000\")\n        \n        # Add have lines\n        for have in haves:\n            line = f\"have {have}\\n\"\n            lines.append(PackProtocolHandler._pkt_line(line))\n        \n        # End negotiation\n        lines.append(PackProtocolHandler._pkt_line(\"done\\n\"))\n        \n        return b''.join(lines)\n    \n    @staticmethod\n    def _pkt_line(data: str) -> bytes:\n        \"\"\"Format data as Git packet line.\"\"\"\n        if isinstance(data, str):\n            data = data.encode('utf-8')\n        length = len(data) + 4\n        return f\"{length:04x}\".encode('ascii') + data\n    \n    @staticmethod\n    def parse_pack_response(response: bytes) -> Tuple[bytes, List[str]]:\n        \"\"\"Parse pack response, extracting pack data and progress messages.\"\"\"\n        pack_data = bytearray()\n        messages = []\n        offset = 0\n        \n        while offset < len(response):\n            # Read packet length\n            if offset + 4 > len(response):\n                break\n                \n            length_str = response[offset:offset+4].decode('ascii')\n            if length_str == \"0000\":\n                offset += 4\n                continue\n                \n            try:\n                packet_length = int(length_str, 16)\n            except ValueError:\n                break\n                \n            if packet_length < 4:\n                break\n                \n            packet_data = response[offset+4:offset+packet_length]\n            offset += packet_length\n            \n            if packet_data.startswith(b'\\x01'):  # Pack data\n                pack_data.extend(packet_data[1:])\n            elif packet_data.startswith(b'\\x02'):  # Progress message\n                messages.append(packet_data[1:].decode('utf-8', errors='ignore'))\n        \n        return bytes(pack_data), messages\n```\n\n#### Core Logic Skeleton Code\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nCore pack file operations.\nSkeleton implementations for learner completion.\n\"\"\"\n\nimport struct\nimport zlib\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\n\nclass PackFileReader:\n    \"\"\"Reads objects from Git pack files.\"\"\"\n    \n    def __init__(self, pack_path: Path):\n        self.pack_path = pack_path\n        self.index_path = pack_path.with_suffix('.idx')\n        self._load_index()\n    \n    def _load_index(self):\n        \"\"\"Load pack index for efficient object lookup.\"\"\"\n        # TODO 1: Open pack index file (.idx)\n        # TODO 2: Read index header and verify format version\n        # TODO 3: Read fanout table (256 4-byte entries)\n        # TODO 4: Read sorted object hash list\n        # TODO 5: Read CRC checksums for each object\n        # TODO 6: Read pack file offsets for each object\n        # TODO 7: Store index data in memory for fast lookup\n        # Hint: Index format is big-endian, use struct.unpack('>I', data)\n        pass\n    \n    def has_object(self, object_hash: str) -> bool:\n        \"\"\"Check if object exists in this pack file.\"\"\"\n        # TODO 1: Use fanout table for fast first-level lookup\n        # TODO 2: Binary search in appropriate hash segment\n        # TODO 3: Return True if hash found in index\n        # Hint: Fanout table maps first hash byte to index range\n        pass\n    \n    def read_object(self, object_hash: str) -> Optional[Tuple[str, bytes]]:\n        \"\"\"Read object from pack file, resolving deltas if necessary.\"\"\"\n        # TODO 1: Look up object offset in pack index\n        # TODO 2: Seek to offset in pack file\n        # TODO 3: Read object header (type and size)\n        # TODO 4: Handle different object types (commit, tree, blob, delta)\n        # TODO 5: If delta object, resolve against base object\n        # TODO 6: Decompress final object content\n        # TODO 7: Return (object_type, content) tuple\n        # Hint: Delta objects require recursive resolution\n        pass\n    \n    def _read_object_at_offset(self, offset: int) -> Tuple[int, int, bytes]:\n        \"\"\"Read raw object data at given pack file offset.\"\"\"\n        # TODO 1: Seek to offset in pack file\n        # TODO 2: Read variable-length object header\n        # TODO 3: Determine object type and uncompressed size\n        # TODO 4: Read compressed object data\n        # TODO 5: Return (object_type, size, compressed_data)\n        # Hint: Object header uses variable-length encoding\n        pass\n    \n    def _resolve_delta_object(self, delta_data: bytes, base_content: bytes) -> bytes:\n        \"\"\"Apply delta instructions to base object content.\"\"\"\n        # TODO 1: Parse delta header (base size, result size)\n        # TODO 2: Read delta instructions (copy or insert)\n        # TODO 3: For copy instructions, copy bytes from base content\n        # TODO 4: For insert instructions, copy literal bytes from delta\n        # TODO 5: Verify result size matches delta header\n        # TODO 6: Return reconstructed object content\n        # Hint: Delta format: base_size, result_size, then copy/insert ops\n        pass\n\nclass PackFileWriter:\n    \"\"\"Creates Git pack files with delta compression.\"\"\"\n    \n    def __init__(self, output_path: Path):\n        self.output_path = output_path\n        self.objects = []\n        self.written_objects = {}\n    \n    def add_object(self, object_hash: str, object_type: str, content: bytes):\n        \"\"\"Add object to pack file.\"\"\"\n        # TODO 1: Store object information for later processing\n        # TODO 2: Consider delta compression against similar objects\n        # TODO 3: Add to objects list with metadata\n        # Hint: Don't write immediately - collect all objects first\n        pass\n    \n    def write_pack(self) -> Tuple[Path, Path]:\n        \"\"\"Write pack file and index to disk.\"\"\"\n        # TODO 1: Sort objects for optimal delta compression\n        # TODO 2: Write pack file header (signature, version, object count)\n        # TODO 3: Write each object with delta compression where beneficial\n        # TODO 4: Write pack file checksum\n        # TODO 5: Generate pack index file\n        # TODO 6: Return (pack_file_path, index_file_path)\n        # Hint: Process objects in dependency order (commits, trees, blobs)\n        pass\n    \n    def _find_delta_base(self, target_content: bytes, candidates: List[bytes]) -> Optional[bytes]:\n        \"\"\"Find best base object for delta compression.\"\"\"\n        # TODO 1: Compare target content against each candidate\n        # TODO 2: Calculate potential compression ratio\n        # TODO 3: Select candidate with best compression ratio\n        # TODO 4: Return best base content or None if no good match\n        # Hint: Simple heuristic - choose candidate with most common subsequences\n        pass\n    \n    def _create_delta(self, base_content: bytes, target_content: bytes) -> bytes:\n        \"\"\"Create delta instructions to transform base into target.\"\"\"\n        # TODO 1: Write delta header (base size, target size)\n        # TODO 2: Find common subsequences between base and target\n        # TODO 3: Generate copy instructions for common parts\n        # TODO 4: Generate insert instructions for new parts\n        # TODO 5: Return complete delta data\n        # Hint: Use simple longest common subsequence algorithm\n        pass\n\nclass GarbageCollector:\n    \"\"\"Performs repository garbage collection and pack generation.\"\"\"\n    \n    def __init__(self, repository):\n        self.repository = repository\n        self.reachable_objects = set()\n    \n    def collect_garbage(self, aggressive: bool = False) -> Dict[str, int]:\n        \"\"\"Run complete garbage collection cycle.\"\"\"\n        # TODO 1: Mark all reachable objects starting from references\n        # TODO 2: Identify unreachable objects in object store\n        # TODO 3: Generate pack files for reachable objects\n        # TODO 4: Remove loose objects that are now packed\n        # TODO 5: Remove unreachable objects\n        # TODO 6: Update repository statistics\n        # TODO 7: Return statistics (objects packed, bytes saved, etc.)\n        # Hint: This is a complex multi-phase operation\n        pass\n    \n    def _mark_reachable_objects(self):\n        \"\"\"Mark all objects reachable from references.\"\"\"\n        # TODO 1: Get all references (HEAD, branches, tags)\n        # TODO 2: For each reference, traverse object graph\n        # TODO 3: Mark commits, then trees, then blobs as reachable\n        # TODO 4: Handle circular references properly\n        # TODO 5: Store reachable object hashes in self.reachable_objects\n        # Hint: Use breadth-first search to avoid stack overflow\n        pass\n    \n    def _generate_packs(self, objects_to_pack: List[str]):\n        \"\"\"Generate pack files for specified objects.\"\"\"\n        # TODO 1: Group objects into logical packs (by age, size, etc.)\n        # TODO 2: For each pack, collect object content\n        # TODO 3: Create PackFileWriter and add all objects\n        # TODO 4: Write pack and index files\n        # TODO 5: Verify pack integrity\n        # Hint: Recent objects should be packed together for access efficiency\n        pass\n```\n\n#### Milestone Checkpoints\n\n**Remote Operations Checkpoint:**\n```bash\n# Test basic remote configuration\npython3 -c \"\nfrom extensions.remote.config.remote_manager import RemoteConfig\nfrom pathlib import Path\n\n# Configure remote\nconfig = RemoteConfig(Path('.git'))\nconfig.add_remote('origin', 'https://github.com/git/git.git')\nprint('Configured remotes:', config.list_remotes())\n\n# Test reference discovery\nfrom extensions.remote.transport.http_transport import GitHTTPTransport\ntransport = GitHTTPTransport('https://github.com/git/git.git')\nrefs = transport.discover_refs('git-upload-pack')\nprint(f'Discovered {len(refs)} references')\nprint('Sample refs:', refs[:5])\n\"\n# Expected: Shows configured remote and lists remote references\n```\n\n**Pack File Checkpoint:**\n```bash\n# Create pack file and verify reading\npython3 -c \"\nfrom extensions.pack.pack_reader import PackFileReader\nfrom extensions.pack.pack_writer import PackFileWriter\nfrom pathlib import Path\n\n# Find existing pack file or create one\npack_dir = Path('.git/objects/pack')\nif pack_dir.exists():\n    pack_files = list(pack_dir.glob('*.pack'))\n    if pack_files:\n        reader = PackFileReader(pack_files[0])\n        print(f'Pack file has objects: {reader.has_object}')\n\"\n# Expected: Successfully reads pack file metadata\n\n```\n\n\n## Glossary\n\n> **Milestone(s):** This comprehensive glossary applies to all eight milestones, providing essential definitions for understanding Git's architecture and implementation. It serves as a reference throughout the entire project journey.\n\nThis glossary serves as the definitive reference for all technical terms, Git-specific vocabulary, architectural concepts, and domain-specific language used throughout the Build Your Own Git project. The definitions are organized to build understanding progressively, starting with foundational concepts and moving to advanced implementation details.\n\n### Mental Model: The Technical Dictionary\n\nThink of this glossary as a specialized technical dictionary for Git internals, similar to how a medical dictionary defines terms like \"myocardial infarction\" not just as \"heart attack\" but with the precise technical meaning that medical professionals need. Each definition here goes beyond surface-level explanations to provide the exact technical understanding needed to implement Git correctly. Just as a surgeon needs to understand the precise anatomical meaning of each term, a Git implementer needs to understand the exact algorithmic and data structure implications of each concept.\n\n### Core Git Concepts\n\n**Add Operation**: The process of staging files for commit by computing their blob hash, creating blob objects in the object store, and recording index entries. This operation transforms working directory files into immutable blob objects and updates the staging area to prepare for commit creation.\n\n**Atomic Write**: A file system operation that ensures either complete success or complete failure with no partial states. Implemented by writing to a temporary file, then using rename system call to atomically replace the target file. Critical for maintaining repository consistency during concurrent access.\n\n**Binary File Detection**: Heuristic process for identifying non-text files by analyzing a sample of bytes for non-printable characters. Uses a threshold ratio (typically 75% printable characters) to distinguish text files suitable for line-based diff operations from binary files requiring different handling.\n\n**Binary Format**: Compact binary representation of data structures optimized for storage efficiency and parsing speed. The Git index uses binary format to store file metadata and object hashes, requiring specialized serialization and deserialization logic.\n\n**Blob Object**: Immutable storage container for file content in Git's object model. Contains only raw file bytes with no metadata like filename or permissions. Identified by SHA-1 hash of formatted content with \"blob {size}\\0\" header.\n\n**Branch Namespace**: Hierarchical organization of branch names using path separators, enabling logical grouping like \"feature/user-auth\" or \"bugfix/memory-leak\". Stored as nested directories under `.git/refs/heads/` to match the namespace structure.\n\n**Breadth-First Search**: Graph traversal algorithm used for finding merge base by exploring all commits at distance N before moving to distance N+1. Ensures discovery of the lowest common ancestor when multiple common ancestors exist.\n\n**Commit Graph**: Directed acyclic graph structure representing project history where commits reference parent commits. Forms the backbone of Git's version control model, enabling branch and merge operations while preventing circular history.\n\n**Commit Object**: Immutable container storing project state snapshot with metadata. Contains tree hash, parent commit hashes, author/committer information with timestamps, and commit message. Forms nodes in the commit graph representing project evolution.\n\n**Compression Problems**: Issues with zlib compression/decompression during object storage operations. Common manifestations include corrupted objects that cannot be decompressed, hash mismatches after decompression, and performance issues with large objects.\n\n**Conflict Detection**: Algorithm for identifying overlapping modifications during three-way merge operations. Compares changes from both branches against the common base to detect lines modified in both branches, requiring manual resolution.\n\n**Conflict Markers**: Special text sequences delimiting merge conflicts for manual resolution. Standard format uses \"<<<<<<< ours\", \"=======\" separator, and \">>>>>>> theirs\" markers to clearly delineate conflicting content from different branches.\n\n**Content-Addressable Storage**: Storage system where objects are identified and retrieved using cryptographic hashes of their content. Provides automatic deduplication, integrity verification, and immutable object properties fundamental to Git's architecture.\n\n**Context Lines**: Unchanged lines displayed around modifications in diff output to provide context for understanding changes. Typically 3 lines before and after each change, configurable based on user preferences or diff complexity.\n\n**Detached HEAD**: Repository state where HEAD points directly to a commit hash instead of a branch reference. Occurs when checking out specific commits, creating a temporary state where new commits don't advance any branch pointer.\n\n**Diagonal Move**: Myers diff algorithm term for matching elements between sequences, representing unchanged lines. Visualized as diagonal movement in the algorithm's grid representation, indicating no insertion or deletion needed.\n\n**Diff Algorithm**: Algorithm for computing differences between two sequences of lines. Myers algorithm finds the shortest edit script (minimum insertions and deletions) to transform one sequence into another, optimizing for minimal change representation.\n\n**Direct Reference**: Git reference containing a raw 40-character SHA-1 commit hash. Contrasts with symbolic references that point to other references. Used for detached HEAD state and some internal Git operations.\n\n**Directed Acyclic Graph**: Mathematical structure where commits reference parents with no circular dependencies. Ensures Git history has clear temporal ordering while supporting multiple branches and merge operations without paradoxes.\n\n**Edit Distance**: Minimum number of insert/delete operations needed to transform one sequence into another. Central concept in diff algorithms, with Myers algorithm optimizing to find the shortest possible edit script between file versions.\n\n**Edit Script**: Sequence of insertion and deletion operations that transforms one file into another. Generated by diff algorithms and used to reconstruct changes, apply patches, and display modifications in human-readable format.\n\n### Storage and Object Model\n\n**Hash Mismatches**: Errors where computed SHA-1 hash doesn't match expected value, indicating data corruption or implementation bugs. Can occur during object storage, retrieval, or transmission, requiring integrity verification and error recovery mechanisms.\n\n**Hunk**: Contiguous block of changes in diff output, consisting of nearby modifications grouped together with context lines. Unified diff format organizes changes into hunks with headers showing affected line ranges in both file versions.\n\n**Immutable History**: Property that historical commits cannot be modified once created, ensuring repository integrity and enabling reliable collaboration. Achieved through cryptographic hashing where any content change produces a different hash.\n\n**Index Binary Format**: Compact binary representation of staging area contents optimized for performance. Contains header with version and entry count, sorted file entries with metadata and hashes, and SHA-1 checksum for corruption detection.\n\n**Lowest Common Ancestor**: Most recent commit reachable from both branches in merge operations. Critical for three-way merge algorithm as the base version for comparing changes from both branches, found using breadth-first search.\n\n**Merge Base**: The common ancestor commit used as the base version in three-way merge operations. Found by traversing commit history from both branch tips until discovering the most recent shared commit.\n\n**Metadata Caching**: Storing file system metadata (timestamps, sizes, inodes) in the index to quickly detect modifications without re-reading file content. Enables efficient status calculations by comparing cached metadata with current file system state.\n\n**Myers Algorithm**: Optimal diff algorithm that finds the shortest edit script between two sequences using dynamic programming. Visualizes the problem as finding the shortest path through a grid, with optimizations for practical performance.\n\n**Object Store**: Git's content-addressable storage backend for immutable objects (blobs, trees, commits). Uses SHA-1 hashes as keys, stores compressed objects in `.git/objects/` directory structure, provides retrieval and verification capabilities.\n\n### References and Branching\n\n**Reference Resolution**: Process of following symbolic references to find the target commit hash. Handles chains of symbolic references and validates reference integrity, essential for operations requiring actual commit hashes.\n\n**Repository Consistency**: Validation that repository satisfies all Git invariants including object reachability, reference validity, and structural integrity. Ensures reliable operation and prevents corruption from accumulating over time.\n\n**SHA-1 Hash**: Cryptographic hash function producing 160-bit (40 hex character) digests used as object identifiers. While deprecated for cryptographic security, still used in Git for content addressing and object identification.\n\n**Staging Area**: Intermediate layer between working directory and repository history where changes are prepared for commit. Implemented as the index file, allows incremental commit preparation and fine-grained control over version history.\n\n**Symbolic Reference**: Reference pointing to another reference rather than directly to a commit hash. HEAD is typically a symbolic reference pointing to the current branch, enabling automatic branch advancement during commits.\n\n**Three-Way Comparison**: Status calculation method comparing working directory, index (staging area), and HEAD to determine file states. Identifies modified, staged, untracked, and deleted files by analyzing differences between these three sources.\n\n**Three-Way Merge**: Merge algorithm using base version (common ancestor) and two branch versions to automatically combine non-conflicting changes. More sophisticated than two-way merge, reduces false conflicts by understanding change attribution.\n\n**Tree Object**: Immutable container representing directory structure in Git's object model. Contains sorted list of entries with file modes, names, and SHA-1 hashes pointing to blobs or other trees, forming hierarchical project snapshots.\n\n**Unified Diff Format**: Industry standard for presenting file differences with context lines, hunk headers, and change markers. Provides human-readable representation of modifications suitable for code review and patch application.\n\n### Advanced Concepts and Extensions\n\n**Change Attribution**: Process of determining which branch made each modification during merge operations. Essential for three-way merge algorithm to distinguish between conflicting and complementary changes from different development lines.\n\n**Delta Compression**: Storage optimization technique using differences between similar objects rather than storing complete content. Reduces repository size by expressing objects as modifications to base objects, used in Git's pack file format.\n\n**Fanout Table**: Index structure in pack files providing efficient object lookup by organizing objects by hash prefix. Contains 256 entries corresponding to first byte values, enabling binary search optimization for object retrieval.\n\n**Fast-Forward Update**: Reference update where new commit is descendant of old commit, requiring only pointer movement without merge. Common in linear development workflows and during fetch operations with no local changes.\n\n**Fetch Operation**: Retrieval of objects and references from remote repository without merging into local branches. Updates remote-tracking branches to reflect remote state while leaving local development branches unchanged.\n\n**Garbage Collection**: Process of removing unreachable objects and optimizing repository storage. Identifies objects not reachable from any reference, removes them to reclaim disk space, and reorganizes remaining objects for efficiency.\n\n**Greedy Extension**: Myers algorithm optimization that follows matching elements as far as possible before considering insertions or deletions. Improves algorithm performance by reducing the search space for optimal solutions.\n\n**Object Relationships**: References between commits, trees, and blobs forming Git's directed acyclic graph structure. Enables repository validation, garbage collection, and history traversal by following hash-based connections.\n\n**Pack File**: Compressed bundle of Git objects optimized for storage efficiency and network transfer. Uses delta compression and zlib to minimize space, essential for large repositories and efficient remote operations.\n\n**Pack Index**: Lookup table enabling efficient random access to objects within pack files. Contains sorted object hashes with corresponding pack file offsets, supporting binary search for fast object retrieval.\n\n**Push Operation**: Sending local objects and reference updates to remote repository. Includes object transfer optimization and reference update validation to maintain consistency across distributed repositories.\n\n**Remote-Tracking Branch**: Local reference showing last known state of remote branch without affecting local development branches. Updated during fetch operations to track remote repository evolution.\n\n**Want/Have Negotiation**: Network protocol optimization to minimize object transfer by identifying objects already present in destination repository. Reduces bandwidth usage during fetch and push operations.\n\n### Implementation Details\n\n**Working Directory**: File system directory containing checked-out project files that users can modify. Represents current project state and serves as source for staging operations, distinct from immutable repository history.\n\n**Git Directory**: The `.git` folder containing all repository metadata, object storage, references, and configuration. Hidden from normal file operations while containing all information needed to reconstruct project history.\n\n**Diagnostic Tools**: Utilities for inspecting and validating Git repository internals during development and debugging. Include object inspection, reference validation, and repository consistency checking capabilities.\n\n**Repository Corruption**: Data integrity failures in Git repositories including corrupted objects, missing references, and invalid repository states. Requires detection mechanisms and recovery strategies to maintain reliable operation.\n\n**Concurrent Access Patterns**: Strategies for handling multiple processes accessing Git repository simultaneously without corruption. Includes file locking, atomic operations, and coordination mechanisms for safe concurrent operation.\n\n**File System Permissions**: Access control settings for Git repository files ensuring security while enabling necessary operations. Critical for shared repositories and preventing unauthorized modification of repository data.\n\n**Binary Detection Size**: Number of bytes analyzed when determining if file content is binary or text, typically 1024 bytes. Optimization balancing accuracy of detection with performance of file analysis.\n\n**Printable Ratio Threshold**: Minimum proportion of printable characters required to classify content as text rather than binary, typically 75%. Used in heuristic binary detection algorithms.\n\n### Data Structures and Formats\n\n| Structure | Purpose | Key Components |\n|-----------|---------|----------------|\n| `Repository` | Main repository interface | git_dir, work_tree paths |\n| `ObjectStore` | Content-addressable storage | objects_dir, hash-to-path mapping |\n| `Index` | Staging area implementation | entries list, binary serialization |\n| `ReferenceManager` | Branch and reference handling | refs_dir, heads_dir, head_file |\n| `TreeEntry` | Directory entry representation | mode, name, hash tuple |\n| `IndexEntry` | Staged file metadata | timestamps, size, hash, path |\n| `GitObject` | Base object interface | content bytes, type identification |\n| `BlobObject` | File content storage | raw content bytes |\n| `TreeObject` | Directory structure | sorted entries list |\n| `CommitObject` | Project snapshot | tree, parents, metadata |\n\n### Error Conditions and Recovery\n\n| Error Type | Symptoms | Detection Method | Recovery Strategy |\n|------------|----------|------------------|-------------------|\n| Hash Mismatch | Object corruption | SHA-1 verification | Recompute from source |\n| Missing Object | Reference errors | Object existence check | Fetch from remote |\n| Index Corruption | Staging failures | Checksum validation | Rebuild from working tree |\n| Reference Invalid | Branch operations fail | Path validation | Reset to known good state |\n| Merge Conflicts | Overlapping changes | Three-way comparison | Manual resolution |\n| Lock Contention | Concurrent access | File lock timeout | Retry with backoff |\n\n### Algorithm Categories\n\n| Algorithm Type | Primary Use | Key Characteristics | Implementation Notes |\n|----------------|-------------|-------------------|---------------------|\n| Myers Diff | File comparison | Optimal edit distance | Grid-based dynamic programming |\n| Breadth-First Search | Merge base finding | Graph traversal | Queue-based exploration |\n| Three-Way Merge | Branch combination | Conflict detection | Base-relative comparison |\n| SHA-1 Hashing | Object identification | Cryptographic integrity | Content-addressable keys |\n| Zlib Compression | Storage optimization | Size reduction | Standard deflate algorithm |\n\n### Implementation Guidance\n\nThis glossary serves as a living reference throughout implementation, with definitions becoming more concrete as you implement each milestone. The terms progress from abstract concepts to specific data structures and algorithms as your understanding deepens.\n\n#### Essential Reference Patterns\n\nWhen implementing Git operations, several reference patterns appear repeatedly:\n\n**Object Hash Calculation**: Always format as `{type} {size}\\0{content}` before computing SHA-1 hash. The null byte separator is critical for proper hash computation and object integrity.\n\n**Path Resolution**: Convert object hashes to file system paths by splitting into 2-character directory prefix and 38-character filename. This distribution ensures reasonable directory sizes even with millions of objects.\n\n**Reference Chain Following**: When resolving references, follow symbolic references iteratively until reaching a direct hash reference. Implement cycle detection to prevent infinite loops from corrupted references.\n\n**Binary vs Text Detection**: Sample initial bytes of file content, count printable characters, and apply threshold ratio. This heuristic approach balances accuracy with performance for large repositories.\n\n#### Common Implementation Mistakes\n\n⚠️ **Pitfall: Hash Format Confusion**\nMany implementations incorrectly store object hashes as 40-character hex strings in binary formats like the index. Git stores hashes as 20-byte binary data in most internal formats, converting to hex only for display and file names.\n\n⚠️ **Pitfall: Reference File Encoding**\nReference files must end with newlines and contain only the hash or symbolic reference. Missing newlines cause parsing errors, while extra whitespace breaks hash validation.\n\n⚠️ **Pitfall: Tree Entry Sorting**\nTree entries must be sorted using Git's specific comparison rules, treating directories as if they end with '/' for sorting purposes. Standard string sorting produces incorrect tree hashes.\n\n⚠️ **Pitfall: Merge Base Edge Cases**\nWhen multiple common ancestors exist, the merge base algorithm must select the lowest common ancestor, not just any shared commit. This affects merge conflict detection and resolution.\n\n#### Debugging Reference Guide\n\n| Issue | Likely Cause | Investigation Steps | Resolution |\n|-------|--------------|-------------------|-----------|\n| Invalid object hash | Header format wrong | Check null byte placement | Reformat as `type size\\0content` |\n| Missing objects | Storage path incorrect | Verify `.git/objects/xx/yyyy` structure | Fix path computation logic |\n| Index corruption | Binary format error | Validate header and checksum | Implement proper serialization |\n| Reference resolution fails | Symbolic ref chain broken | Trace reference chain manually | Repair or reset references |\n| Diff output wrong | Algorithm implementation bug | Compare with known good output | Debug Myers algorithm step-by-step |\n| Merge conflicts incorrect | Base calculation wrong | Verify merge base commit | Fix breadth-first search logic |\n\nThis glossary evolves as your implementation progresses, with initially abstract concepts becoming concrete data structures and algorithms. Use it as both a learning tool and a reference during debugging sessions.\n"}