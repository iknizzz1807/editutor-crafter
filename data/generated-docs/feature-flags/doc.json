{"html":"<h1 id=\"feature-flag-system-design-document\">Feature Flag System: Design Document</h1>\n<h2 id=\"overview\">Overview</h2>\n<p>A feature flag system that enables controlled feature rollouts, A/B testing, and real-time configuration updates. The key architectural challenge is building a low-latency evaluation engine that can process complex targeting rules while maintaining consistency across distributed clients and supporting real-time updates without overwhelming the infrastructure.</p>\n<blockquote>\n<p>This guide is meant to help you understand the big picture before diving into each milestone. Refer back to it whenever you need context on how components connect.</p>\n</blockquote>\n<h2 id=\"context-and-problem-statement\">Context and Problem Statement</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section provides foundational context for all three milestones by establishing why feature flags are essential and the unique challenges they address.</p>\n</blockquote>\n<h3 id=\"mental-model-software-release-as-air-traffic-control\">Mental Model: Software Release as Air Traffic Control</h3>\n<p>Think of modern software deployment as managing air traffic at a busy international airport. Without proper coordination, you have hundreds of flights trying to land simultaneously on the same runway—a recipe for disaster. Traditional software releases work exactly like this chaotic scenario: all features launch together at a predetermined time, with no ability to adjust course once the &quot;planes are in the air.&quot;</p>\n<p><strong>Feature flags transform your release process into a sophisticated air traffic control system.</strong> Just as air traffic controllers can direct specific flights to different runways, adjust landing sequences based on weather conditions, and even redirect planes to alternate airports when problems arise, feature flags give you granular control over which users see which features and when.</p>\n<p>Consider how air traffic control handles a busy evening rush. Controllers don&#39;t just flip a switch and let all planes land at once. Instead, they carefully orchestrate arrivals: &quot;Flight 447, you&#39;re cleared for runway 24L. Flight 852, hold at 5,000 feet until weather clears. Flight 213, divert to the cargo runway for your oversized load.&quot; This is precisely what feature flags enable for software features—you can route different user &quot;flights&quot; to different feature &quot;runways&quot; based on their characteristics, current system conditions, and business requirements.</p>\n<p>The air traffic control analogy extends beautifully to the technical challenges we face. Air traffic controllers need real-time weather data, aircraft positions, and runway status to make split-second decisions. Similarly, our feature flag system needs real-time user context, system health metrics, and business KPIs to make intelligent routing decisions. When a storm hits the airport, controllers can quickly reroute traffic to alternate runways. When a feature causes performance issues, feature flags let you instantly reroute users to the stable code path without any deployments or restarts.</p>\n<blockquote>\n<p><strong>Key Insight</strong>: Just as air traffic control systems must never fail (planes can&#39;t just &quot;hover indefinitely&quot;), feature flag systems require exceptional reliability with graceful degradation strategies. A feature flag outage shouldn&#39;t ground your entire application.</p>\n</blockquote>\n<p>The complexity emerges when you realize that modern applications aren&#39;t managing just one airport—they&#39;re coordinating a global network of airports (distributed systems) where decisions made at one location affect traffic patterns everywhere else. A feature flag change in your recommendation engine doesn&#39;t just affect the users who see new recommendations; it impacts database load, cache hit rates, API response times, and downstream service capacity across your entire infrastructure.</p>\n<p>This mental model helps us understand why building a feature flag system is more challenging than it initially appears. It&#39;s not enough to have a simple on/off switch. You need the equivalent of sophisticated radar systems (real-time monitoring), weather prediction models (A/B testing and analytics), emergency protocols (fallback strategies), and a control tower that never sleeps (24/7 reliability with real-time updates).</p>\n<h3 id=\"existing-approaches-comparison\">Existing Approaches Comparison</h3>\n<p>Before diving into our comprehensive solution, let&#39;s examine how teams typically handle feature toggles today and why each approach breaks down as systems scale. Understanding these limitations helps justify the complexity we&#39;re about to introduce.</p>\n<h4 id=\"configuration-files-approach\">Configuration Files Approach</h4>\n<p>The simplest approach stores feature toggles in configuration files (YAML, JSON, or properties files) that are read at application startup. This feels natural because it leverages existing configuration management practices that most teams already understand.</p>\n<table>\n<thead>\n<tr>\n<th>Aspect</th>\n<th>Description</th>\n<th>Limitations</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Implementation</strong></td>\n<td>JSON/YAML files with boolean flags loaded at startup</td>\n<td>Requires application restart for any flag change</td>\n</tr>\n<tr>\n<td><strong>Deployment</strong></td>\n<td>Flags bundled with application code in the same deployment artifact</td>\n<td>Cannot change flags without full deployment pipeline</td>\n</tr>\n<tr>\n<td><strong>Targeting</strong></td>\n<td>Single global value per flag, no user-specific targeting</td>\n<td>All users see the same flag state simultaneously</td>\n</tr>\n<tr>\n<td><strong>Rollback Speed</strong></td>\n<td>10-30 minutes (full deployment cycle)</td>\n<td>Too slow for emergency feature disabling</td>\n</tr>\n<tr>\n<td><strong>Consistency</strong></td>\n<td>Eventually consistent after all instances restart</td>\n<td>Inconsistent during rolling deployments</td>\n</tr>\n<tr>\n<td><strong>A/B Testing</strong></td>\n<td>Not supported without custom implementation</td>\n<td>No statistical rigor or experiment tracking</td>\n</tr>\n</tbody></table>\n<p>The configuration file approach works well for simple environment-specific settings (database URLs, API timeouts) but breaks down catastrophically for feature management. Imagine discovering a critical bug in your new checkout flow during Black Friday traffic. With configuration files, you&#39;re looking at a 20-minute deployment cycle to disable the feature—an eternity when you&#39;re losing thousands of dollars per minute.</p>\n<p><strong>Real-world failure scenario</strong>: A major e-commerce platform used configuration files for feature flags. During a flash sale, their new inventory calculation feature caused database deadlocks. The 15-minute rollback time resulted in $2.3 million in lost sales and required manually switching to backup servers—a problem that feature flags with instant rollback could have resolved in under 30 seconds.</p>\n<h4 id=\"environment-variables-approach\">Environment Variables Approach</h4>\n<p>Environment variables offer slightly more flexibility than configuration files, especially in containerized environments where you can restart individual service instances without full redeployments.</p>\n<table>\n<thead>\n<tr>\n<th>Aspect</th>\n<th>Description</th>\n<th>Limitations</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Implementation</strong></td>\n<td>Feature flags stored as environment variables (FEATURE_X=true)</td>\n<td>Still requires container/process restart for changes</td>\n</tr>\n<tr>\n<td><strong>Deployment</strong></td>\n<td>Can be changed via orchestration platforms (Kubernetes, Docker Compose)</td>\n<td>Rolling restart still takes several minutes</td>\n</tr>\n<tr>\n<td><strong>Targeting</strong></td>\n<td>Global per environment, potentially per service instance</td>\n<td>No user segmentation or gradual rollouts</td>\n</tr>\n<tr>\n<td><strong>Observability</strong></td>\n<td>Difficult to track which features are active across the fleet</td>\n<td>No centralized view of flag states</td>\n</tr>\n<tr>\n<td><strong>Type Safety</strong></td>\n<td>String-based with manual parsing prone to errors</td>\n<td>&quot;true&quot;, &quot;TRUE&quot;, &quot;1&quot;, &quot;yes&quot; all need handling</td>\n</tr>\n<tr>\n<td><strong>Audit Trail</strong></td>\n<td>Limited to orchestration platform logs</td>\n<td>No feature-specific change history</td>\n</tr>\n</tbody></table>\n<p>Environment variables solve the bundling problem of configuration files but introduce new operational complexities. Managing dozens of feature flags across multiple services and environments quickly becomes unwieldy. Consider a microservices architecture with 20 services, each having 5-10 feature flags across development, staging, and production environments—you&#39;re now managing 300-600 individual environment variables with no central visibility.</p>\n<p><strong>Real-world failure scenario</strong>: A fintech startup used environment variables for feature flags across their microservices. During a gradual rollout of a new fraud detection algorithm, they discovered the flag was accidentally enabled in production but disabled in staging—the opposite of their intent. The mismatch went undetected for three days, during which time their testing was validating the old algorithm while the new (buggy) algorithm was processing live transactions, resulting in 12% false positives and hundreds of customer complaints.</p>\n<h4 id=\"database-toggle-approach\">Database Toggle Approach</h4>\n<p>Many teams evolve from static configuration to storing feature flags in their application database, often starting with a simple <code>feature_flags</code> table with name and enabled columns. This approach provides runtime configurability without deployment cycles.</p>\n<table>\n<thead>\n<tr>\n<th>Aspect</th>\n<th>Description</th>\n<th>Limitations</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Implementation</strong></td>\n<td>Database table storing flag names, enabled state, optional targeting rules</td>\n<td>Database becomes single point of failure for all features</td>\n</tr>\n<tr>\n<td><strong>Real-time Updates</strong></td>\n<td>Requires polling or cache invalidation strategy</td>\n<td>Polling creates database load; caching creates staleness</td>\n</tr>\n<tr>\n<td><strong>Performance</strong></td>\n<td>Database query on every flag evaluation</td>\n<td>Adds latency and load to primary database</td>\n</tr>\n<tr>\n<td><strong>Targeting</strong></td>\n<td>Can store complex rules but evaluation logic mixed with business logic</td>\n<td>Rule evaluation code scattered across application</td>\n</tr>\n<tr>\n<td><strong>Consistency</strong></td>\n<td>Depends on database consistency model</td>\n<td>Read replicas can serve stale flag states</td>\n</tr>\n<tr>\n<td><strong>Fallback</strong></td>\n<td>Application breaks if database unavailable</td>\n<td>No graceful degradation during database outages</td>\n</tr>\n</tbody></table>\n<p>The database approach initially feels like a natural progression, but it introduces a fundamental architectural problem: your feature management system now shares fate with your primary application database. When your database is under heavy load or experiencing issues, your ability to disable problematic features disappears exactly when you need it most.</p>\n<p><strong>Performance implications</strong>: Every flag evaluation requires a database query or cache lookup. For a high-traffic application evaluating flags on every request, this can easily add 50-100 million additional database queries per day. The irony is that the performance impact of your flagging system can become worse than the features you&#39;re trying to protect.</p>\n<p><strong>Real-world failure scenario</strong>: A social media platform stored feature flags in their primary PostgreSQL database. During a traffic spike, database connections were exhausted, causing not only user-facing features to fail but also preventing them from disabling the problematic new timeline algorithm that was causing the load spike in the first place. The circular dependency meant their feature flags couldn&#39;t help them recover from the very problems they were designed to solve.</p>\n<h4 id=\"dedicated-feature-flag-services\">Dedicated Feature Flag Services</h4>\n<p>Recognizing the limitations of the previous approaches, many organizations turn to dedicated feature flag platforms (LaunchDarkly, Unleash, Flagsmith) or build custom services specifically for flag management.</p>\n<table>\n<thead>\n<tr>\n<th>Aspect</th>\n<th>Description</th>\n<th>Benefits</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Implementation</strong></td>\n<td>Standalone service with API for flag evaluation and management</td>\n<td>Purpose-built for feature flag requirements</td>\n</tr>\n<tr>\n<td><strong>Real-time Updates</strong></td>\n<td>WebSocket or SSE connections for instant flag changes</td>\n<td>Sub-second flag propagation across all clients</td>\n</tr>\n<tr>\n<td><strong>Targeting</strong></td>\n<td>Sophisticated rule engines with user attributes, segments, and percentages</td>\n<td>Gradual rollouts and A/B testing built-in</td>\n</tr>\n<tr>\n<td><strong>Performance</strong></td>\n<td>Client-side SDKs with local caching and background sync</td>\n<td>Flag evaluation in microseconds with fallbacks</td>\n</tr>\n<tr>\n<td><strong>Observability</strong></td>\n<td>Rich analytics, audit logs, and experiment tracking</td>\n<td>Data-driven feature decisions</td>\n</tr>\n<tr>\n<td><strong>Reliability</strong></td>\n<td>Designed for high availability with graceful degradation</td>\n<td>Feature flags available even during service outages</td>\n</tr>\n</tbody></table>\n<p>However, dedicated services introduce their own complexities and architectural decisions. The fundamental challenge is balancing the richness of targeting capabilities with the performance and reliability requirements of flag evaluation.</p>\n<blockquote>\n<p><strong>Architecture Decision: Build vs Buy for Feature Flags</strong></p>\n<ul>\n<li><strong>Context</strong>: Teams must decide whether to use existing feature flag services or build custom solutions</li>\n<li><strong>Options Considered</strong>:<ul>\n<li><strong>Third-party SaaS</strong>: LaunchDarkly, Split, Optimizely</li>\n<li><strong>Open-source hosted</strong>: Unleash, Flagsmith, GrowthBook  </li>\n<li><strong>Custom-built</strong>: Internal feature flag service</li>\n</ul>\n</li>\n<li><strong>Decision</strong>: Build custom for learning purposes, but understand trade-offs</li>\n<li><strong>Rationale</strong>: Commercial services offer mature ecosystems but limit customization and create vendor dependency. Building custom provides deep understanding of the technical challenges and architectural decisions involved.</li>\n<li><strong>Consequences</strong>: Higher development effort but complete control over performance characteristics, data residency, and integration patterns.</li>\n</ul>\n</blockquote>\n<p><strong>Comparison of dedicated service approaches</strong>:</p>\n<table>\n<thead>\n<tr>\n<th>Approach</th>\n<th>Pros</th>\n<th>Cons</th>\n<th>Best For</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Third-party SaaS</strong></td>\n<td>Mature features, no operational overhead, proven reliability</td>\n<td>Vendor lock-in, data privacy concerns, recurring costs</td>\n<td>Teams wanting to focus on core business features</td>\n</tr>\n<tr>\n<td><strong>Open-source hosted</strong></td>\n<td>Full control, customizable, community support</td>\n<td>Operational overhead, need internal expertise</td>\n<td>Teams with strong infrastructure capabilities</td>\n</tr>\n<tr>\n<td><strong>Custom-built</strong></td>\n<td>Complete customization, no vendor dependency, cost control</td>\n<td>High development effort, need to solve hard problems</td>\n<td>Organizations with unique requirements or learning goals</td>\n</tr>\n</tbody></table>\n<p>The key insight from this comparison is that feature flags are deceptively complex. What starts as a simple boolean toggle quickly evolves into a distributed system with requirements for real-time updates, complex targeting logic, statistical analysis, and fault tolerance. This complexity explains why dedicated solutions exist and why building a robust feature flag system is a substantial engineering undertaking.</p>\n<p><strong>Common anti-patterns observed across all approaches</strong>:</p>\n<p>⚠️ <strong>Pitfall: Flag Evaluation in Critical Path</strong>\nMany implementations put flag evaluation directly in their request processing path without proper caching or fallbacks. This creates latency and reliability problems where feature management becomes a bottleneck for core functionality. The fix is to always evaluate flags asynchronously with local caching and sensible defaults.</p>\n<p>⚠️ <strong>Pitfall: No Flag Lifecycle Management</strong> \nTeams often create feature flags without establishing processes for flag cleanup and removal. This leads to &quot;flag debt&quot; where codebases accumulate hundreds of obsolete flags that nobody dares to remove. The fix is to treat flags as temporary by default with expiration dates and regular cleanup processes.</p>\n<p>⚠️ <strong>Pitfall: Inconsistent Flag Evaluation</strong>\nWithout proper user identification and consistent hashing, users can flip-flop between different variants of a feature, creating confusing experiences and invalidating A/B test results. The fix is to ensure deterministic flag evaluation based on stable user identifiers.</p>\n<p>Understanding these existing approaches and their failure modes helps us appreciate why building a robust feature flag system requires careful attention to performance, reliability, and consistency challenges. Our design must address the fundamental problems that cause each approach to break down while providing the sophisticated targeting and real-time capabilities that modern applications demand.</p>\n<p>The remainder of this design document will show how to build a feature flag system that combines the best aspects of each approach while avoiding their critical failure modes. We&#39;ll focus particularly on the three core challenges that distinguish robust feature flag systems from naive implementations: consistent flag evaluation under high load, real-time flag updates without infrastructure overload, and statistical rigor for A/B testing and gradual rollouts.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>This foundational section helps establish the technology choices and project structure that will support the sophisticated feature flag system we&#39;re building. Understanding these early decisions will inform how we approach the more complex challenges in subsequent milestones.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>HTTP Framework</strong></td>\n<td>Standard library <code>net/http</code> with JSON</td>\n<td>Gin or Echo framework with middleware</td>\n</tr>\n<tr>\n<td><strong>Database</strong></td>\n<td>SQLite for development, PostgreSQL for production</td>\n<td>PostgreSQL with Redis for caching</td>\n</tr>\n<tr>\n<td><strong>Real-time Updates</strong></td>\n<td>Server-Sent Events with <code>net/http</code></td>\n<td>WebSocket with Gorilla WebSocket library</td>\n</tr>\n<tr>\n<td><strong>User Context</strong></td>\n<td>Simple JSON structures</td>\n<td>Protocol Buffers for type safety</td>\n</tr>\n<tr>\n<td><strong>Configuration</strong></td>\n<td>YAML with <code>gopkg.in/yaml.v3</code></td>\n<td>Viper for hierarchical configuration</td>\n</tr>\n<tr>\n<td><strong>Logging</strong></td>\n<td>Standard library <code>log/slog</code></td>\n<td>Structured logging with <code>logrus</code> or <code>zap</code></td>\n</tr>\n<tr>\n<td><strong>Testing</strong></td>\n<td>Standard library <code>testing</code></td>\n<td>Testify for assertions, Ginkgo for BDD</td>\n</tr>\n</tbody></table>\n<p><strong>Language-Specific Considerations for Go</strong>:</p>\n<ul>\n<li><strong>Consistent Hashing</strong>: Use <code>hash/fnv</code> for fast, stable hashing of user identifiers</li>\n<li><strong>JSON Handling</strong>: Leverage <code>encoding/json</code> for flag definitions and user context</li>\n<li><strong>Concurrency</strong>: Utilize Go&#39;s goroutines for handling real-time connections</li>\n<li><strong>Error Handling</strong>: Embrace explicit error returns for robust flag evaluation</li>\n<li><strong>Interface Design</strong>: Use interfaces to support multiple storage backends and update mechanisms</li>\n</ul>\n<h4 id=\"recommended-project-structure\">Recommended Project Structure</h4>\n<p>Understanding how to organize a feature flag system helps avoid common architectural mistakes where flag evaluation logic gets scattered throughout the application.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>feature-flag-system/\n├── cmd/\n│   ├── flagserver/           ← HTTP API server for flag management\n│   │   └── main.go\n│   ├── flagproxy/           ← Lightweight evaluation proxy\n│   │   └── main.go\n│   └── migrator/            ← Database migration tool\n│       └── main.go\n├── internal/\n│   ├── core/                ← Core domain logic (no external dependencies)\n│   │   ├── flag.go          ← Flag entity and business logic\n│   │   ├── evaluation.go    ← Evaluation engine\n│   │   ├── targeting.go     ← User targeting and segmentation\n│   │   └── experiment.go    ← A/B testing logic\n│   ├── storage/             ← Data persistence layer\n│   │   ├── interface.go     ← Storage abstraction\n│   │   ├── postgres/        ← PostgreSQL implementation\n│   │   └── memory/          ← In-memory for testing\n│   ├── realtime/            ← Real-time update service\n│   │   ├── sse.go          ← Server-Sent Events implementation\n│   │   ├── websocket.go    ← WebSocket implementation\n│   │   └── broadcaster.go   ← Update broadcasting logic\n│   ├── analytics/           ← Flag evaluation tracking and A/B analysis\n│   │   ├── collector.go     ← Event collection\n│   │   ├── aggregator.go    ← Metrics aggregation\n│   │   └── stats.go         ← Statistical analysis\n│   └── api/                 ← HTTP API layer\n│       ├── handlers/        ← HTTP request handlers\n│       ├── middleware/      ← Authentication, logging, CORS\n│       └── routes.go        ← Route definitions\n├── pkg/                     ← Public APIs (can be imported by other projects)\n│   ├── client/              ← Go SDK for consuming feature flags\n│   │   ├── sdk.go          ← Main SDK interface\n│   │   ├── cache.go        ← Local flag caching\n│   │   └── streaming.go    ← Real-time update handling\n│   └── types/               ← Shared types and interfaces\n│       ├── flag.go         ← Flag data structures\n│       ├── context.go      ← User context types\n│       └── events.go       ← Event and analytics types\n├── web/                     ← Web dashboard (optional)\n│   ├── static/             ← CSS, JavaScript assets\n│   └── templates/          ← HTML templates\n├── migrations/              ← Database schema migrations\n│   ├── 001_initial.sql\n│   ├── 002_add_experiments.sql\n│   └── 003_add_analytics.sql\n├── docs/                    ← Additional documentation\n│   ├── api.md              ← API documentation\n│   ├── sdk.md              ← SDK usage guide\n│   └── deployment.md       ← Deployment instructions\n└── docker-compose.yml       ← Local development environment</code></pre></div>\n\n<p><strong>Key organizational principles</strong>:</p>\n<ol>\n<li><p><strong>Domain-Driven Structure</strong>: The <code>internal/core</code> package contains pure business logic with no external dependencies, making it easy to unit test and reason about.</p>\n</li>\n<li><p><strong>Interface Segregation</strong>: Each major component (<code>storage</code>, <code>realtime</code>, <code>analytics</code>) defines its own interfaces, allowing for multiple implementations and easy testing with mocks.</p>\n</li>\n<li><p><strong>Dependency Direction</strong>: Dependencies flow inward toward the core domain logic. Storage implementations depend on core interfaces, not vice versa.</p>\n</li>\n<li><p><strong>Client SDK Separation</strong>: The <code>pkg/client</code> provides a clean API for applications consuming feature flags, with its own caching and connection management logic separate from the server implementation.</p>\n</li>\n</ol>\n<h4 id=\"core-type-definitions\">Core Type Definitions</h4>\n<p>These fundamental types will be referenced throughout the implementation. Understanding them now will help you follow the more complex algorithms in later sections.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// Package: pkg/types</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// FlagKey uniquely identifies a feature flag across the system</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> FlagKey</span><span style=\"color:#F97583\"> string</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// UserID represents a stable identifier for users in targeting decisions</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> UserID</span><span style=\"color:#F97583\"> string</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Variant represents a specific variation of a feature flag</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> Variant</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Key     </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">                 `json:\"key\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Value   </span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{}           </span><span style=\"color:#9ECBFF\">`json:\"value\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Weight  </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">                   `json:\"weight\"`</span><span style=\"color:#6A737D\">  // For percentage rollouts</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// UserContext contains attributes used for flag targeting decisions</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> UserContext</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    UserID     </span><span style=\"color:#B392F0\">UserID</span><span style=\"color:#9ECBFF\">                 `json:\"user_id\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Attributes </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{} </span><span style=\"color:#9ECBFF\">`json:\"attributes\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Segments   []</span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">              `json:\"segments\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// EvaluationResult contains the result of flag evaluation plus debugging info</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> EvaluationResult</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    FlagKey   </span><span style=\"color:#B392F0\">FlagKey</span><span style=\"color:#9ECBFF\">     `json:\"flag_key\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Value     </span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{} </span><span style=\"color:#9ECBFF\">`json:\"value\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Variant   </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"variant\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Reason    </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"reason\"`</span><span style=\"color:#6A737D\">     // Why this variant was chosen</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Source    </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"source\"`</span><span style=\"color:#6A737D\">     // \"cache\", \"storage\", \"default\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p>This complete HTTP server foundation handles the basic web serving infrastructure so you can focus on the core feature flag logic:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// cmd/flagserver/main.go</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> main</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">context</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">log/slog</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">net/http</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">os</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">os/signal</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">syscall</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">github.com/your-org/feature-flags/internal/api</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">github.com/your-org/feature-flags/internal/storage/postgres</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> main</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Initialize structured logging</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    logger </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> slog.</span><span style=\"color:#B392F0\">New</span><span style=\"color:#E1E4E8\">(slog.</span><span style=\"color:#B392F0\">NewJSONHandler</span><span style=\"color:#E1E4E8\">(os.Stdout, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#B392F0\">slog</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">HandlerOptions</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Level: slog.LevelInfo,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Initialize storage layer</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    storage, err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> postgres.</span><span style=\"color:#B392F0\">NewStorage</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"postgres://localhost/flagdb?sslmode=disable\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        logger.</span><span style=\"color:#B392F0\">Error</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Failed to initialize storage\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"error\"</span><span style=\"color:#E1E4E8\">, err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        os.</span><span style=\"color:#B392F0\">Exit</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> storage.</span><span style=\"color:#B392F0\">Close</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Initialize API server</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    server </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> api.</span><span style=\"color:#B392F0\">NewServer</span><span style=\"color:#E1E4E8\">(storage, logger)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Configure HTTP server with timeouts</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    httpServer </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">http</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Server</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Addr:         </span><span style=\"color:#9ECBFF\">\":8080\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Handler:      server.</span><span style=\"color:#B392F0\">Routes</span><span style=\"color:#E1E4E8\">(),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ReadTimeout:  </span><span style=\"color:#79B8FF\">15</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\"> time.Second,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        WriteTimeout: </span><span style=\"color:#79B8FF\">15</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\"> time.Second,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        IdleTimeout:  </span><span style=\"color:#79B8FF\">60</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\"> time.Second,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Start server in background</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    go</span><span style=\"color:#F97583\"> func</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        logger.</span><span style=\"color:#B392F0\">Info</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Starting flag server\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"addr\"</span><span style=\"color:#E1E4E8\">, httpServer.Addr)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> httpServer.</span><span style=\"color:#B392F0\">ListenAndServe</span><span style=\"color:#E1E4E8\">(); err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#F97583\"> &#x26;&#x26;</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> http.ErrServerClosed {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            logger.</span><span style=\"color:#B392F0\">Error</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"HTTP server failed\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"error\"</span><span style=\"color:#E1E4E8\">, err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            os.</span><span style=\"color:#B392F0\">Exit</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Wait for shutdown signal</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    stop </span><span style=\"color:#F97583\">:=</span><span style=\"color:#B392F0\"> make</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">chan</span><span style=\"color:#B392F0\"> os</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Signal</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    signal.</span><span style=\"color:#B392F0\">Notify</span><span style=\"color:#E1E4E8\">(stop, syscall.SIGINT, syscall.SIGTERM)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    &#x3C;-</span><span style=\"color:#E1E4E8\">stop</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Graceful shutdown</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    logger.</span><span style=\"color:#B392F0\">Info</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Shutting down server...\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ctx, cancel </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> context.</span><span style=\"color:#B392F0\">WithTimeout</span><span style=\"color:#E1E4E8\">(context.</span><span style=\"color:#B392F0\">Background</span><span style=\"color:#E1E4E8\">(), </span><span style=\"color:#79B8FF\">30</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">time.Second)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#B392F0\"> cancel</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> httpServer.</span><span style=\"color:#B392F0\">Shutdown</span><span style=\"color:#E1E4E8\">(ctx); err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        logger.</span><span style=\"color:#B392F0\">Error</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Server shutdown failed\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"error\"</span><span style=\"color:#E1E4E8\">, err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    } </span><span style=\"color:#F97583\">else</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        logger.</span><span style=\"color:#B392F0\">Info</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Server shut down successfully\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"development-environment-setup\">Development Environment Setup</h4>\n<p>Complete Docker Compose configuration for local development with all required dependencies:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">yaml</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># docker-compose.yml</span></span>\n<span class=\"line\"><span style=\"color:#85E89D\">version</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'3.8'</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#85E89D\">services</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#85E89D\">  postgres</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#85E89D\">    image</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">postgres:15</span></span>\n<span class=\"line\"><span style=\"color:#85E89D\">    environment</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#85E89D\">      POSTGRES_DB</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">flagdb</span></span>\n<span class=\"line\"><span style=\"color:#85E89D\">      POSTGRES_USER</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">flaguser</span></span>\n<span class=\"line\"><span style=\"color:#85E89D\">      POSTGRES_PASSWORD</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">flagpass</span></span>\n<span class=\"line\"><span style=\"color:#85E89D\">    ports</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      - </span><span style=\"color:#9ECBFF\">\"5432:5432\"</span></span>\n<span class=\"line\"><span style=\"color:#85E89D\">    volumes</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      - </span><span style=\"color:#9ECBFF\">postgres_data:/var/lib/postgresql/data</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      - </span><span style=\"color:#9ECBFF\">./migrations:/docker-entrypoint-initdb.d</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#85E89D\">  redis</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#85E89D\">    image</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">redis:7-alpine</span></span>\n<span class=\"line\"><span style=\"color:#85E89D\">    ports</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      - </span><span style=\"color:#9ECBFF\">\"6379:6379\"</span></span>\n<span class=\"line\"><span style=\"color:#85E89D\">    command</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">redis-server --appendonly yes</span></span>\n<span class=\"line\"><span style=\"color:#85E89D\">    volumes</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      - </span><span style=\"color:#9ECBFF\">redis_data:/data</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#85E89D\">  flagserver</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#85E89D\">    build</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">.</span></span>\n<span class=\"line\"><span style=\"color:#85E89D\">    ports</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      - </span><span style=\"color:#9ECBFF\">\"8080:8080\"</span></span>\n<span class=\"line\"><span style=\"color:#85E89D\">    environment</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#85E89D\">      DATABASE_URL</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">postgres://flaguser:flagpass@postgres:5432/flagdb?sslmode=disable</span></span>\n<span class=\"line\"><span style=\"color:#85E89D\">      REDIS_URL</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">redis://redis:6379/0</span></span>\n<span class=\"line\"><span style=\"color:#85E89D\">    depends_on</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      - </span><span style=\"color:#9ECBFF\">postgres</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      - </span><span style=\"color:#9ECBFF\">redis</span></span>\n<span class=\"line\"><span style=\"color:#85E89D\">    volumes</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      - </span><span style=\"color:#9ECBFF\">.:/app</span></span>\n<span class=\"line\"><span style=\"color:#85E89D\">    working_dir</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">/app</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#85E89D\">volumes</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#85E89D\">  postgres_data</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#85E89D\">  redis_data</span><span style=\"color:#E1E4E8\">:</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoint-for-foundation\">Milestone Checkpoint for Foundation</h4>\n<p>After setting up the project structure and basic infrastructure:</p>\n<p><strong>What to verify</strong>:</p>\n<ol>\n<li>Run <code>go mod init github.com/your-org/feature-flags</code> to initialize the Go module</li>\n<li>Set up the directory structure as shown above</li>\n<li>Copy the starter code into the appropriate files</li>\n<li>Run <code>docker-compose up postgres redis</code> to start dependencies</li>\n<li>Run <code>go run cmd/flagserver/main.go</code> - server should start without errors</li>\n<li>Visit <code>http://localhost:8080/health</code> (you&#39;ll implement this endpoint) - should return 200 OK</li>\n</ol>\n<p><strong>Expected behavior</strong>:</p>\n<ul>\n<li>Server starts and listens on port 8080</li>\n<li>Database connection succeeds (you&#39;ll see connection logs)</li>\n<li>Graceful shutdown works with Ctrl+C</li>\n<li>Project structure follows Go conventions with clear separation of concerns</li>\n</ul>\n<p><strong>Signs something is wrong</strong>:</p>\n<ul>\n<li>Import cycle errors indicate incorrect dependency structure</li>\n<li>Database connection failures suggest configuration issues  </li>\n<li>Server doesn&#39;t respond to shutdown signals cleanly</li>\n</ul>\n<p>This foundation provides the scaffolding for implementing the three core milestones: the flag evaluation engine, real-time updates, and analytics. Each subsequent section will build upon this structure with specific components and algorithms needed for a production-quality feature flag system.</p>\n<h2 id=\"goals-and-non-goals\">Goals and Non-Goals</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section establishes the scope and boundaries for all three milestones, defining what functionality the Flag Evaluation Engine, Real-time Flag Updates, and Flag Analytics &amp; Experiments will and will not include.</p>\n</blockquote>\n<h3 id=\"mental-model-air-traffic-control-tower-responsibilities\">Mental Model: Air Traffic Control Tower Responsibilities</h3>\n<p>Think of defining goals and non-goals for a feature flag system like establishing the responsibilities of an <strong>air traffic control tower</strong>. The tower has clear, well-defined duties: it guides aircraft safely to their destinations, manages takeoffs and landings, and coordinates flight paths to prevent collisions. However, the tower doesn&#39;t design aircraft engines, forecast weather patterns weeks in advance, or handle passenger boarding processes.</p>\n<p>Similarly, our feature flag system must have crystal-clear boundaries. It will excel at its core mission—safely routing users to different feature experiences based on targeting rules—while explicitly avoiding responsibilities that belong to other systems. Just as air traffic controllers need reliable radar, communication systems, and weather updates to make split-second decisions, our feature flag system needs robust evaluation logic, real-time updates, and comprehensive analytics to guide software releases safely.</p>\n<p>The key insight is that <strong>scope creep</strong> in feature flag systems is like asking air traffic controllers to also handle airline scheduling, aircraft maintenance, and passenger services. Each additional responsibility increases complexity exponentially and threatens the reliability of the core mission. By establishing clear goals and non-goals upfront, we create focused, maintainable software that excels at its intended purpose.</p>\n<h3 id=\"primary-goals\">Primary Goals</h3>\n<p>Our feature flag system will deliver four core capabilities that directly support the air traffic control analogy of coordinating software releases safely and efficiently.</p>\n<h4 id=\"goal-1-reliable-flag-evaluation-with-complex-targeting\">Goal 1: Reliable Flag Evaluation with Complex Targeting</h4>\n<p>The system will provide <strong>deterministic, low-latency flag evaluation</strong> that consistently assigns users to the correct variants based on sophisticated targeting rules. This is the fundamental responsibility—like air traffic control&#39;s primary duty of guiding aircraft to safe landing strips.</p>\n<table>\n<thead>\n<tr>\n<th>Capability</th>\n<th>Description</th>\n<th>Success Criteria</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Multi-type Flag Support</strong></td>\n<td>Boolean, string, number, and JSON flag values</td>\n<td>All primitive types plus structured data variants</td>\n</tr>\n<tr>\n<td><strong>Complex Rule Logic</strong></td>\n<td>AND/OR conditions with multiple user attributes</td>\n<td>Nested boolean expressions with proper precedence</td>\n</tr>\n<tr>\n<td><strong>Percentage Rollouts</strong></td>\n<td>Gradual feature exposure using consistent hashing</td>\n<td>Stable user assignment across evaluations</td>\n</tr>\n<tr>\n<td><strong>User Segmentation</strong></td>\n<td>Target specific user groups with attribute matching</td>\n<td>Rule-based segments with real-time membership</td>\n</tr>\n<tr>\n<td><strong>Evaluation Reasoning</strong></td>\n<td>Detailed explanation of why specific variant returned</td>\n<td>Audit trail for debugging and compliance</td>\n</tr>\n<tr>\n<td><strong>Fallback Handling</strong></td>\n<td>Default values when targeting rules fail or malfunction</td>\n<td>Graceful degradation without service interruption</td>\n</tr>\n</tbody></table>\n<p>The evaluation engine will process complex targeting scenarios like &quot;show new checkout flow to 25% of premium users in North America, but exclude users who signed up in the last 7 days.&quot; This requires sophisticated rule processing with proper precedence, consistent user bucketing, and comprehensive context matching.</p>\n<h4 id=\"goal-2-real-time-configuration-updates\">Goal 2: Real-time Configuration Updates</h4>\n<p>The system will deliver <strong>sub-second flag changes</strong> to all connected clients without requiring application restarts or deployments. This enables the rapid course corrections that make feature flags valuable for risk mitigation and experimentation.</p>\n<table>\n<thead>\n<tr>\n<th>Capability</th>\n<th>Description</th>\n<th>Success Criteria</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Streaming Updates</strong></td>\n<td>Server-Sent Events or WebSocket delivery</td>\n<td>Flag changes reach clients within 2-3 seconds</td>\n</tr>\n<tr>\n<td><strong>Connection Recovery</strong></td>\n<td>Automatic reconnection with exponential backoff</td>\n<td>Clients reconnect after network disruption</td>\n</tr>\n<tr>\n<td><strong>State Synchronization</strong></td>\n<td>Consistent flag values across all SDK instances</td>\n<td>No client serves stale flags after updates</td>\n</tr>\n<tr>\n<td><strong>Offline Resilience</strong></td>\n<td>Local caching with configurable TTL policies</td>\n<td>Applications continue functioning during outages</td>\n</tr>\n<tr>\n<td><strong>Update Ordering</strong></td>\n<td>Changes applied in correct chronological sequence</td>\n<td>No race conditions between rapid flag modifications</td>\n</tr>\n<tr>\n<td><strong>Selective Updates</strong></td>\n<td>Only changed flags transmitted to reduce bandwidth</td>\n<td>Efficient delta updates rather than full snapshots</td>\n</tr>\n</tbody></table>\n<p>Real-time updates enable emergency scenarios like &quot;immediately disable the new payment processor for all users&quot; or &quot;increase checkout optimization rollout from 10% to 50% during peak traffic.&quot; The system must handle these critical configuration changes reliably across distributed deployments.</p>\n<h4 id=\"goal-3-comprehensive-analytics-and-ab-testing\">Goal 3: Comprehensive Analytics and A/B Testing</h4>\n<p>The system will provide <strong>statistical rigor</strong> for controlled experiments and comprehensive visibility into flag performance. This transforms feature flags from simple toggles into a data-driven experimentation platform.</p>\n<table>\n<thead>\n<tr>\n<th>Capability</th>\n<th>Description</th>\n<th>Success Criteria</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Flag Exposure Tracking</strong></td>\n<td>Record every flag evaluation with user context</td>\n<td>Complete audit trail of feature exposure</td>\n</tr>\n<tr>\n<td><strong>A/B Test Framework</strong></td>\n<td>Controlled experiments with proper randomization</td>\n<td>Statistical significance testing with confidence intervals</td>\n</tr>\n<tr>\n<td><strong>Metrics Collection</strong></td>\n<td>Conversion and engagement tracking by variant</td>\n<td>Real-time performance comparison across variants</td>\n</tr>\n<tr>\n<td><strong>Sample Size Calculation</strong></td>\n<td>Required user counts for statistical power</td>\n<td>Experiment duration estimates based on traffic</td>\n</tr>\n<tr>\n<td><strong>Sequential Analysis</strong></td>\n<td>Early stopping with proper alpha spending</td>\n<td>Avoid peeking problems while enabling early wins</td>\n</tr>\n<tr>\n<td><strong>Experiment Reports</strong></td>\n<td>Automated analysis with actionable recommendations</td>\n<td>Clear visualization of variant performance differences</td>\n</tr>\n</tbody></table>\n<p>The analytics engine will detect scenarios like sample ratio mismatches that invalidate experiments, calculate required sample sizes for desired statistical power, and provide early stopping recommendations when variants show significant differences.</p>\n<h4 id=\"goal-4-production-ready-reliability\">Goal 4: Production-Ready Reliability</h4>\n<p>The system will demonstrate <strong>enterprise-grade reliability</strong> suitable for business-critical applications with proper error handling, monitoring, and operational support.</p>\n<table>\n<thead>\n<tr>\n<th>Capability</th>\n<th>Description</th>\n<th>Success Criteria</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>High Availability</strong></td>\n<td>Multi-region deployment with failover capabilities</td>\n<td>99.9% uptime with sub-100ms P99 latency</td>\n</tr>\n<tr>\n<td><strong>Graceful Degradation</strong></td>\n<td>Service continues with cached/default values during outages</td>\n<td>No application failures due to flag service issues</td>\n</tr>\n<tr>\n<td><strong>Comprehensive Monitoring</strong></td>\n<td>Detailed metrics, logging, and alerting integration</td>\n<td>Proactive detection of performance degradation</td>\n</tr>\n<tr>\n<td><strong>Security Integration</strong></td>\n<td>Authentication, authorization, and audit logging</td>\n<td>Role-based access control with compliance support</td>\n</tr>\n<tr>\n<td><strong>Scalability</strong></td>\n<td>Handle millions of flag evaluations per second</td>\n<td>Linear scaling with horizontal infrastructure growth</td>\n</tr>\n<tr>\n<td><strong>Data Consistency</strong></td>\n<td>ACID properties for critical flag configuration changes</td>\n<td>No lost updates or corrupted flag definitions</td>\n</tr>\n</tbody></table>\n<h3 id=\"non-goals\">Non-Goals</h3>\n<p>Understanding what our feature flag system will <strong>not</strong> include is equally important for maintaining focus and avoiding scope creep. These boundaries prevent the system from becoming an overly complex platform that fails at its core mission.</p>\n<h4 id=\"non-goal-1-advanced-infrastructure-management\">Non-Goal 1: Advanced Infrastructure Management</h4>\n<p>The system will not provide comprehensive DevOps tooling or infrastructure orchestration capabilities that belong in specialized platforms.</p>\n<table>\n<thead>\n<tr>\n<th>Excluded Capability</th>\n<th>Rationale</th>\n<th>Alternative Approach</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Container Orchestration</strong></td>\n<td>Kubernetes and Docker management requires specialized expertise</td>\n<td>Deploy flag service using existing container platforms</td>\n</tr>\n<tr>\n<td><strong>Service Mesh Integration</strong></td>\n<td>Complex networking concerns beyond flag evaluation scope</td>\n<td>Use standard service mesh patterns for traffic management</td>\n</tr>\n<tr>\n<td><strong>Multi-Cloud Management</strong></td>\n<td>Cloud provider abstractions add significant complexity</td>\n<td>Deploy using cloud-specific infrastructure as code</td>\n</tr>\n<tr>\n<td><strong>Database Administration</strong></td>\n<td>Schema migrations, backup/restore, performance tuning</td>\n<td>Use managed database services with standard operational practices</td>\n</tr>\n<tr>\n<td><strong>Load Balancer Configuration</strong></td>\n<td>Traffic routing policies beyond basic health checks</td>\n<td>Integrate with existing load balancing infrastructure</td>\n</tr>\n</tbody></table>\n<p>This boundary ensures the development team focuses on flag evaluation logic rather than becoming infrastructure specialists. Organizations should deploy the flag service using their existing DevOps toolchain and operational practices.</p>\n<h4 id=\"non-goal-2-complex-business-logic-integration\">Non-Goal 2: Complex Business Logic Integration</h4>\n<p>The system will not embed application-specific business rules or domain logic that belongs in individual applications.</p>\n<table>\n<thead>\n<tr>\n<th>Excluded Capability</th>\n<th>Rationale</th>\n<th>Alternative Approach</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Custom Business Rules</strong></td>\n<td>Domain-specific logic creates tight coupling between flag service and applications</td>\n<td>Applications implement business logic using flag values as inputs</td>\n</tr>\n<tr>\n<td><strong>Workflow Orchestration</strong></td>\n<td>Multi-step business processes require specialized workflow engines</td>\n<td>Use flag values to control workflow behavior in dedicated orchestration systems</td>\n</tr>\n<tr>\n<td><strong>Data Transformation</strong></td>\n<td>Complex ETL operations belong in dedicated data processing pipelines</td>\n<td>Flag service provides raw evaluation data; applications handle transformation</td>\n</tr>\n<tr>\n<td><strong>External API Orchestration</strong></td>\n<td>Coordinating multiple external services creates reliability dependencies</td>\n<td>Applications manage external integrations using flags for feature gating</td>\n</tr>\n<tr>\n<td><strong>Payment Processing</strong></td>\n<td>Financial transactions require specialized compliance and security</td>\n<td>Use flags to control payment feature availability, not process transactions</td>\n</tr>\n</tbody></table>\n<p>By avoiding business logic integration, the flag service remains reusable across different applications and domains while maintaining clear separation of concerns.</p>\n<h4 id=\"non-goal-3-advanced-machine-learning-features\">Non-Goal 3: Advanced Machine Learning Features</h4>\n<p>The system will not include sophisticated AI/ML capabilities that require specialized data science expertise and infrastructure.</p>\n<table>\n<thead>\n<tr>\n<th>Excluded Capability</th>\n<th>Rationale</th>\n<th>Alternative Approach</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Predictive Targeting</strong></td>\n<td>User behavior prediction requires ML model training and maintenance</td>\n<td>Use rule-based targeting with external ML insights as input attributes</td>\n</tr>\n<tr>\n<td><strong>Automated Flag Management</strong></td>\n<td>AI-driven flag lifecycle management introduces unpredictable system behavior</td>\n<td>Provide APIs for external automation tools to manage flags programmatically</td>\n</tr>\n<tr>\n<td><strong>Anomaly Detection</strong></td>\n<td>Statistical outlier detection needs specialized algorithms and tuning</td>\n<td>Integrate with existing monitoring tools that provide anomaly detection</td>\n</tr>\n<tr>\n<td><strong>Recommendation Engine</strong></td>\n<td>Variant recommendations require complex user modeling and collaborative filtering</td>\n<td>External recommendation systems can use flag values for A/B testing recommendations</td>\n</tr>\n<tr>\n<td><strong>Natural Language Processing</strong></td>\n<td>Flag configuration from natural language requires NLP infrastructure</td>\n<td>Provide structured APIs with clear documentation for programmatic flag management</td>\n</tr>\n</tbody></table>\n<p>Organizations needing ML-powered feature management should integrate external ML platforms with the flag service through standard APIs rather than embedding ML capabilities directly.</p>\n<h4 id=\"non-goal-4-comprehensive-application-performance-monitoring\">Non-Goal 4: Comprehensive Application Performance Monitoring</h4>\n<p>The system will not replace dedicated APM and observability platforms that provide comprehensive application monitoring.</p>\n<table>\n<thead>\n<tr>\n<th>Excluded Capability</th>\n<th>Rationale</th>\n<th>Alternative Approach</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Distributed Tracing</strong></td>\n<td>Request tracing across microservices requires specialized instrumentation</td>\n<td>Flag evaluations participate in existing distributed tracing systems</td>\n</tr>\n<tr>\n<td><strong>Application Metrics</strong></td>\n<td>Business and technical metrics belong in dedicated monitoring infrastructure</td>\n<td>Flag exposure events feed into existing metrics collection systems</td>\n</tr>\n<tr>\n<td><strong>Log Aggregation</strong></td>\n<td>Centralized logging requires significant infrastructure and storage management</td>\n<td>Flag service logs integrate with existing log aggregation platforms</td>\n</tr>\n<tr>\n<td><strong>Error Tracking</strong></td>\n<td>Application error monitoring needs specialized error analysis and grouping</td>\n<td>Flag-related errors report to existing error tracking systems</td>\n</tr>\n<tr>\n<td><strong>Performance Profiling</strong></td>\n<td>Code-level performance analysis requires runtime instrumentation</td>\n<td>Flag evaluation performance monitored through standard profiling tools</td>\n</tr>\n</tbody></table>\n<p>The flag service will provide observability hooks and structured logging that integrate seamlessly with existing monitoring infrastructure rather than replacing specialized observability tools.</p>\n<h3 id=\"scope-boundaries-and-integration-points\">Scope Boundaries and Integration Points</h3>\n<p>Understanding how our feature flag system integrates with existing infrastructure helps clarify responsibility boundaries and prevents architectural conflicts.</p>\n<h4 id=\"integration-philosophy\">Integration Philosophy</h4>\n<blockquote>\n<p><strong>Design Principle: Complementary System Integration</strong></p>\n<p>The feature flag system follows the <strong>Unix philosophy</strong> of doing one thing exceptionally well while providing clean interfaces for integration with other systems. Rather than replacing existing infrastructure, it enhances current development and operational workflows.</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Integration Category</th>\n<th>Flag System Responsibility</th>\n<th>External System Responsibility</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>User Authentication</strong></td>\n<td>Accept authenticated user context for targeting</td>\n<td>Provide user identity and session management</td>\n</tr>\n<tr>\n<td><strong>Metrics and Analytics</strong></td>\n<td>Generate flag exposure events with structured metadata</td>\n<td>Aggregate, visualize, and alert on flag usage patterns</td>\n</tr>\n<tr>\n<td><strong>Configuration Management</strong></td>\n<td>Store and serve flag definitions with versioning</td>\n<td>Manage application configuration, secrets, and environment variables</td>\n</tr>\n<tr>\n<td><strong>Deployment Pipeline</strong></td>\n<td>Provide APIs for automated flag lifecycle management</td>\n<td>Orchestrate deployments, run tests, and manage release processes</td>\n</tr>\n<tr>\n<td><strong>Service Discovery</strong></td>\n<td>Register flag service endpoints for client SDK discovery</td>\n<td>Provide service mesh, load balancing, and health checking</td>\n</tr>\n<tr>\n<td><strong>Data Storage</strong></td>\n<td>Persist flag definitions, rules, and evaluation results</td>\n<td>Provide database infrastructure, backup, and disaster recovery</td>\n</tr>\n</tbody></table>\n<h4 id=\"client-sdk-integration-requirements\">Client SDK Integration Requirements</h4>\n<p>The flag system must provide lightweight, efficient client SDKs that minimize application impact while maximizing developer productivity.</p>\n<table>\n<thead>\n<tr>\n<th>SDK Capability</th>\n<th>Design Requirements</th>\n<th>Performance Constraints</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Evaluation Latency</strong></td>\n<td>Sub-millisecond flag evaluation using local cache</td>\n<td>No network calls during normal flag evaluation</td>\n</tr>\n<tr>\n<td><strong>Memory Footprint</strong></td>\n<td>Minimal memory usage for flag storage and evaluation context</td>\n<td>Cache only active flags with efficient serialization</td>\n</tr>\n<tr>\n<td><strong>Startup Time</strong></td>\n<td>Fast SDK initialization without blocking application startup</td>\n<td>Asynchronous flag loading with sensible defaults</td>\n</tr>\n<tr>\n<td><strong>Error Isolation</strong></td>\n<td>Flag evaluation failures never crash or block application code</td>\n<td>Comprehensive fallback strategies with circuit breaker patterns</td>\n</tr>\n<tr>\n<td><strong>Async Updates</strong></td>\n<td>Background flag updates without interrupting application threads</td>\n<td>Non-blocking update processing with atomic configuration swaps</td>\n</tr>\n<tr>\n<td><strong>Observability</strong></td>\n<td>Rich debugging information without performance penalty</td>\n<td>Structured logging and metrics with configurable verbosity</td>\n</tr>\n</tbody></table>\n<h3 id=\"architecture-decision-records\">Architecture Decision Records</h3>\n<h4 id=\"decision-evaluation-first-design-priority\">Decision: Evaluation-First Design Priority</h4>\n<blockquote>\n<p><strong>Context</strong>: Feature flag systems must balance multiple concerns including evaluation performance, real-time updates, analytics collection, and operational complexity. Different prioritization leads to fundamentally different architectures.</p>\n<p><strong>Options Considered</strong>:</p>\n<ol>\n<li><strong>Analytics-First</strong>: Optimize for comprehensive data collection and experiment analysis</li>\n<li><strong>Updates-First</strong>: Optimize for real-time configuration changes and operational flexibility  </li>\n<li><strong>Evaluation-First</strong>: Optimize for low-latency, high-throughput flag evaluation performance</li>\n</ol>\n<p><strong>Decision</strong>: Evaluation-First design with analytics and updates as secondary concerns</p>\n<p><strong>Rationale</strong>: Flag evaluation occurs orders of magnitude more frequently than configuration updates or analytics queries. A single application might evaluate flags thousands of times per request across millions of requests daily, but flag updates happen at most dozens of times per day. Poor evaluation performance directly impacts user experience and application scalability, while slower updates or analytics primarily affect developer productivity.</p>\n<p><strong>Consequences</strong>: This prioritization enables sub-millisecond evaluation latency through aggressive local caching and optimized rule processing, but requires more sophisticated approaches for real-time updates and analytics collection that don&#39;t compromise evaluation performance.</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Approach</th>\n<th>Evaluation Latency</th>\n<th>Update Latency</th>\n<th>Analytics Richness</th>\n<th>Operational Complexity</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Analytics-First</strong></td>\n<td>50-100ms (network calls)</td>\n<td>5-10 seconds</td>\n<td>Comprehensive real-time</td>\n<td>High (complex data pipeline)</td>\n</tr>\n<tr>\n<td><strong>Updates-First</strong></td>\n<td>10-50ms (cache misses)</td>\n<td>Sub-second</td>\n<td>Limited batch processing</td>\n<td>Medium (event streaming)</td>\n</tr>\n<tr>\n<td><strong>Evaluation-First ✓</strong></td>\n<td>Sub-millisecond (local)</td>\n<td>2-5 seconds</td>\n<td>Rich but eventually consistent</td>\n<td>Medium (caching complexity)</td>\n</tr>\n</tbody></table>\n<h4 id=\"decision-explicit-feature-scope-definition\">Decision: Explicit Feature Scope Definition</h4>\n<blockquote>\n<p><strong>Context</strong>: Feature flag systems can evolve into comprehensive platforms handling everything from basic toggles to complex workflow orchestration, user management, and business intelligence. This scope expansion often leads to maintenance burden and reliability issues.</p>\n<p><strong>Options Considered</strong>:</p>\n<ol>\n<li><strong>Platform Approach</strong>: Build comprehensive feature management platform with extensive built-in capabilities</li>\n<li><strong>Minimal Approach</strong>: Provide only basic boolean flags with simple on/off functionality</li>\n<li><strong>Focused Approach</strong>: Provide sophisticated flag evaluation, updates, and analytics while avoiding peripheral features</li>\n</ol>\n<p><strong>Decision</strong>: Focused Approach with explicit non-goals to prevent scope creep</p>\n<p><strong>Rationale</strong>: Platform approaches often fail because they attempt to solve too many problems simultaneously, leading to suboptimal solutions for each concern. Minimal approaches lack the sophistication needed for production use cases like gradual rollouts and A/B testing. The focused approach enables excellence in core flag management while providing integration points for specialized external systems.</p>\n<p><strong>Consequences</strong>: Development effort concentrates on flag evaluation excellence, real-time updates, and experiment analytics. External integration requirements are explicitly designed from the beginning rather than retrofitted later, leading to cleaner architecture and more reliable operation.</p>\n</blockquote>\n<h3 id=\"common-pitfalls-in-goal-definition\">Common Pitfalls in Goal Definition</h3>\n<p>Understanding common mistakes in feature flag system scoping helps avoid architectural decisions that lead to maintenance problems and reliability issues.</p>\n<p>⚠️ <strong>Pitfall: Kitchen Sink Feature Creep</strong></p>\n<p>Many teams start with simple flag requirements but gradually add user management, complex workflow orchestration, custom business logic, and comprehensive monitoring capabilities. This transforms a focused flag service into a sprawling platform that&#39;s difficult to maintain and often unreliable.</p>\n<p><strong>Why it&#39;s Wrong</strong>: Each additional feature domain requires different expertise, testing approaches, and operational considerations. A system optimized for microsecond flag evaluation has fundamentally different requirements than one optimized for complex data analytics or user interface workflows.</p>\n<p><strong>How to Fix</strong>: Establish explicit non-goals documentation and review all feature requests against core system responsibilities. When teams request additional capabilities, provide integration APIs that allow external systems to handle peripheral concerns while leveraging flag data.</p>\n<p>⚠️ <strong>Pitfall: Premature Optimization Boundaries</strong></p>\n<p>Teams sometimes define overly restrictive goals based on current performance requirements without considering reasonable growth scenarios. This leads to systems that can&#39;t handle obvious scaling needs or require complete rewrites when traffic increases.</p>\n<p><strong>Why it&#39;s Wrong</strong>: Flag evaluation requirements often grow exponentially with application adoption. A system designed for 1,000 evaluations per second might face 100,000 evaluations per second within months. Similarly, simple boolean flags often evolve into complex multi-variant experiments as organizations mature their feature management practices.</p>\n<p><strong>How to Fix</strong>: Define goals that accommodate 10x growth in evaluation volume and rule complexity without architectural changes. Plan for linear scaling through horizontal infrastructure rather than requiring fundamental design modifications.</p>\n<p>⚠️ <strong>Pitfall: Integration Assumption Mismatch</strong></p>\n<p>Development teams often assume their flag system will integrate seamlessly with existing infrastructure without explicitly designing integration points. This leads to architecture conflicts, performance problems, and operational complexity.</p>\n<p><strong>Why it&#39;s Wrong</strong>: Different organizations have varying authentication systems, monitoring infrastructure, deployment pipelines, and data storage approaches. A flag system designed assuming specific external dependencies often requires significant modifications during deployment.</p>\n<p><strong>How to Fix</strong>: Define explicit integration interfaces and assumptions in the goals documentation. Design abstraction layers for authentication, metrics, storage, and configuration that allow adaptation to different organizational infrastructure without core logic changes.</p>\n<h3 id=\"validation-criteria-and-success-metrics\">Validation Criteria and Success Metrics</h3>\n<p>Establishing measurable success criteria ensures the implemented system meets its defined goals while respecting non-goal boundaries.</p>\n<h4 id=\"functional-validation-requirements\">Functional Validation Requirements</h4>\n<table>\n<thead>\n<tr>\n<th>Goal Category</th>\n<th>Validation Method</th>\n<th>Success Threshold</th>\n<th>Measurement Approach</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Flag Evaluation</strong></td>\n<td>Load testing with complex rules</td>\n<td>99.9% evaluations complete within 1ms</td>\n<td>Synthetic traffic with realistic user contexts</td>\n</tr>\n<tr>\n<td><strong>Real-time Updates</strong></td>\n<td>Flag change propagation timing</td>\n<td>95% of clients receive updates within 3 seconds</td>\n<td>Distributed update monitoring with client-side timestamps</td>\n</tr>\n<tr>\n<td><strong>A/B Testing</strong></td>\n<td>Statistical accuracy validation</td>\n<td>Experiment results within 2% of ground truth</td>\n<td>Controlled experiments with known conversion differences</td>\n</tr>\n<tr>\n<td><strong>Reliability</strong></td>\n<td>Chaos engineering and failure injection</td>\n<td>No application failures due to flag service issues</td>\n<td>Systematic infrastructure failure testing</td>\n</tr>\n</tbody></table>\n<h4 id=\"non-goal-compliance-validation\">Non-Goal Compliance Validation</h4>\n<table>\n<thead>\n<tr>\n<th>Non-Goal Category</th>\n<th>Validation Method</th>\n<th>Compliance Criteria</th>\n<th>Red Flag Indicators</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Infrastructure Scope</strong></td>\n<td>Architecture review</td>\n<td>Zero database administration or container orchestration features</td>\n<td>Custom deployment scripts or database schema management</td>\n</tr>\n<tr>\n<td><strong>Business Logic Scope</strong></td>\n<td>Code review</td>\n<td>No domain-specific rules or workflow orchestration</td>\n<td>Application-specific constants or business rule encoding</td>\n</tr>\n<tr>\n<td><strong>ML Feature Scope</strong></td>\n<td>Dependency analysis</td>\n<td>No machine learning libraries or model training capabilities</td>\n<td>Statistical modeling or prediction algorithm implementations</td>\n</tr>\n<tr>\n<td><strong>APM Scope</strong></td>\n<td>Integration testing</td>\n<td>Flag service data flows to existing monitoring infrastructure</td>\n<td>Custom metrics dashboards or log aggregation systems</td>\n</tr>\n</tbody></table>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The goals and non-goals established in this section provide the foundation for all implementation decisions throughout the project. Here&#39;s how to translate these scope boundaries into concrete development practices.</p>\n<h4 id=\"technology-selection-framework\">Technology Selection Framework</h4>\n<p>When choosing technologies and dependencies for each milestone, evaluate options against the established goals and explicitly reject solutions that violate non-goal boundaries.</p>\n<table>\n<thead>\n<tr>\n<th>Component Category</th>\n<th>Evaluation Criteria</th>\n<th>Recommended Approach</th>\n<th>Red Flag Dependencies</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Flag Storage</strong></td>\n<td>Evaluation latency priority, consistency guarantees</td>\n<td>In-memory caching with persistent backing store</td>\n<td>Complex ORM frameworks, heavy database abstraction layers</td>\n</tr>\n<tr>\n<td><strong>Real-time Updates</strong></td>\n<td>Connection management, bandwidth efficiency</td>\n<td>Server-Sent Events with JSON payloads</td>\n<td>Complex message brokers, heavyweight pub/sub systems</td>\n</tr>\n<tr>\n<td><strong>Analytics Backend</strong></td>\n<td>Statistical accuracy, query performance</td>\n<td>Time-series database with statistical functions</td>\n<td>Full-featured business intelligence or data warehouse platforms</td>\n</tr>\n<tr>\n<td><strong>Client SDK</strong></td>\n<td>Minimal footprint, fast evaluation</td>\n<td>Simple HTTP client with local caching</td>\n<td>Complex frameworks, heavyweight serialization libraries</td>\n</tr>\n</tbody></table>\n<h4 id=\"project-structure-organization\">Project Structure Organization</h4>\n<p>Organize the codebase to reinforce goal boundaries and prevent scope creep through clear module separation:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>feature-flag-system/\n├── cmd/\n│   ├── flag-server/              ← Core flag evaluation and updates service\n│   └── analytics-processor/      ← Experiment analysis and reporting\n├── internal/\n│   ├── evaluation/               ← Flag evaluation engine (Goal 1)\n│   │   ├── engine.go\n│   │   ├── rules.go\n│   │   └── consistent_hash.go\n│   ├── realtime/                 ← Update streaming (Goal 2)\n│   │   ├── sse_handler.go\n│   │   └── connection_manager.go\n│   ├── analytics/                ← A/B testing framework (Goal 3)\n│   │   ├── experiment.go\n│   │   └── statistics.go\n│   └── storage/                  ← Data persistence abstraction\n│       ├── memory_store.go\n│       └── postgres_store.go\n├── pkg/\n│   └── sdk/                      ← Client SDK for applications\n│       ├── client.go\n│       └── cache.go\n└── examples/\n    ├── basic-usage/              ← Simple flag evaluation examples\n    └── ab-testing/               ← Experiment setup examples</code></pre></div>\n\n<h4 id=\"core-interface-definitions\">Core Interface Definitions</h4>\n<p>Define clean interfaces that enforce goal boundaries and prevent feature creep:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// FlagEvaluator handles core evaluation logic (Goal 1)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> FlagEvaluator</span><span style=\"color:#F97583\"> interface</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // EvaluateFlag returns variant assignment with reasoning</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    EvaluateFlag</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">flagKey</span><span style=\"color:#B392F0\"> FlagKey</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">context</span><span style=\"color:#B392F0\"> UserContext</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#B392F0\">EvaluationResult</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Implement consistent hashing for stable user assignment</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Process targeting rules with proper precedence</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Handle fallback values when rules don't match</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// UpdateStreamer manages real-time flag changes (Goal 2)  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> UpdateStreamer</span><span style=\"color:#F97583\"> interface</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // StreamUpdates sends flag changes to connected clients</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    StreamUpdates</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">clientID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">&#x3C;-chan</span><span style=\"color:#B392F0\"> FlagUpdate</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Implement SSE connection management</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Handle client reconnection with state recovery</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Broadcast updates to all connected clients</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ExperimentTracker handles A/B testing analytics (Goal 3)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> ExperimentTracker</span><span style=\"color:#F97583\"> interface</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // RecordExposure logs flag evaluation for analysis</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    RecordExposure</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">exposure</span><span style=\"color:#B392F0\"> FlagExposure</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // CalculateSignificance computes experiment statistical results</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    CalculateSignificance</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">experimentID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#B392F0\">SignificanceResult</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Implement exposure event collection</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Calculate statistical significance with proper methods</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Generate experiment reports with confidence intervals</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"milestone-validation-checkpoints\">Milestone Validation Checkpoints</h4>\n<p>After implementing each milestone, validate that the system meets its goals without violating non-goal boundaries:</p>\n<p><strong>Milestone 1 Checkpoint (Flag Evaluation Engine):</strong></p>\n<ul>\n<li>Run <code>go test ./internal/evaluation/...</code> - all tests pass</li>\n<li>Load test: 10,000 flag evaluations complete within 10ms total</li>\n<li>Complex rule test: nested AND/OR conditions evaluate correctly</li>\n<li>Consistency test: same user receives identical variants across multiple evaluations</li>\n<li>Verify: No business logic hardcoded, no ML dependencies, no infrastructure management code</li>\n</ul>\n<p><strong>Milestone 2 Checkpoint (Real-time Updates):</strong></p>\n<ul>\n<li>Start flag server: <code>go run cmd/flag-server/main.go</code></li>\n<li>Connect test client, modify flag via API, client receives update within 3 seconds</li>\n<li>Network disruption test: disconnect/reconnect client, verify state synchronization</li>\n<li>Verify: No complex message broker usage, no container orchestration, updates don&#39;t impact evaluation latency</li>\n</ul>\n<p><strong>Milestone 3 Checkpoint (Analytics &amp; Experiments):</strong></p>\n<ul>\n<li>Create A/B test with known 10% conversion difference</li>\n<li>Run experiment with synthetic traffic for statistical significance</li>\n<li>Verify: Statistical calculations accurate within 2%, no ML model training, no custom APM dashboard</li>\n</ul>\n<h4 id=\"scope-enforcement-techniques\">Scope Enforcement Techniques</h4>\n<p>Implement these development practices to maintain goal focus and prevent scope creep:</p>\n<p><strong>Code Review Checklist:</strong></p>\n<ul>\n<li>Does this change directly support one of the four primary goals?</li>\n<li>Are we adding infrastructure management, business logic, ML features, or APM capabilities?</li>\n<li>Do new dependencies align with evaluation-first performance priorities?</li>\n<li>Are integration points cleanly separated from core flag logic?</li>\n</ul>\n<p><strong>Architecture Decision Template:</strong>\nFor any significant design choice, explicitly evaluate against goals:</p>\n<ul>\n<li>How does this support flag evaluation performance?</li>\n<li>Does this compromise real-time update capabilities?</li>\n<li>Will this enable or hinder A/B testing statistical accuracy?</li>\n<li>Are we maintaining production reliability standards?</li>\n<li>Which non-goals might this violate, and how do we prevent that?</li>\n</ul>\n<p><strong>Dependency Review Process:</strong>\nBefore adding any external dependency:</p>\n<ul>\n<li>Measure impact on flag evaluation latency</li>\n<li>Verify alignment with focused system approach  </li>\n<li>Confirm integration rather than replacement of existing infrastructure</li>\n<li>Document why simpler alternatives are insufficient</li>\n</ul>\n<p>This systematic approach to goal enforcement ensures the feature flag system delivers exceptional performance in its core mission while maintaining clean integration boundaries with existing organizational infrastructure.</p>\n<h2 id=\"high-level-architecture\">High-Level Architecture</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section provides the architectural foundation for all three milestones by defining the core components that support the Flag Evaluation Engine (Milestone 1), Real-time Flag Updates (Milestone 2), and Flag Analytics &amp; Experiments (Milestone 3).</p>\n</blockquote>\n<h3 id=\"mental-model-feature-flags-as-air-traffic-control\">Mental Model: Feature Flags as Air Traffic Control</h3>\n<p>Think of a feature flag system as an <strong>air traffic control tower</strong> managing the flow of software releases into production. Just as air traffic control coordinates aircraft approaches, assigns landing sequences, and manages emergency protocols, a feature flag system orchestrates which features reach which users under what conditions.</p>\n<p>The air traffic control analogy illuminates several key architectural principles. The <strong>control tower</strong> (Flag Management API) provides centralized oversight and coordination, while <strong>flight controllers</strong> (Client SDKs) execute instructions at the ground level. <strong>Radar systems</strong> (Real-time Update Service) provide continuous situational awareness, and <strong>flight plans</strong> (flag configurations) define predetermined routes and conditions. <strong>Emergency protocols</strong> (fallback mechanisms) ensure safe operation when communication fails.</p>\n<p>This mental model emphasizes why feature flag architecture must prioritize <strong>reliability over performance</strong>. A crashed air traffic control system grounds all flights; similarly, a failed flag evaluation system can block all feature rollouts or, worse, expose unstable features to production traffic. The architecture must embrace <strong>graceful degradation</strong> principles, where partial system failures reduce capability rather than causing complete outages.</p>\n<p>The evaluation-first design principle emerges naturally from this analogy. Air traffic control systems prioritize rapid decision-making over comprehensive data collection—controllers need split-second aircraft positioning, not detailed historical flight patterns. Similarly, flag evaluation must complete in single-digit milliseconds, even if analytics data has eventual consistency.</p>\n<p><img src=\"/api/project/feature-flags/architecture-doc/asset?path=diagrams%2Fsystem-architecture.svg\" alt=\"System Architecture Overview\"></p>\n<h3 id=\"component-overview\">Component Overview</h3>\n<p>The feature flag system consists of four primary components that work together to provide fast, reliable flag evaluation with real-time updates and comprehensive analytics. Each component owns specific responsibilities and maintains clear boundaries to support independent scaling and deployment.</p>\n<h4 id=\"flag-management-api\">Flag Management API</h4>\n<p>The <strong>Flag Management API</strong> serves as the central command center for all flag operations, similar to how air traffic control manages flight plans and clearances. This component handles the administrative lifecycle of feature flags while maintaining the authoritative state that drives evaluation decisions across all client SDKs.</p>\n<p>The Flag Management API owns the complete flag definition lifecycle, from initial creation through rule updates to eventual flag retirement. It provides RESTful endpoints for creating flags, configuring targeting rules, setting up A/B experiments, and managing percentage rollouts. The API validates all flag configurations before persistence, ensuring that rule syntax is correct, percentage allocations sum appropriately, and dependency graphs remain acyclic.</p>\n<table>\n<thead>\n<tr>\n<th>Operation</th>\n<th>Method</th>\n<th>Endpoint</th>\n<th>Description</th>\n<th>Authentication</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Create Flag</td>\n<td>POST</td>\n<td><code>/api/flags</code></td>\n<td>Create new feature flag with targeting rules</td>\n<td>Admin</td>\n</tr>\n<tr>\n<td>Update Flag</td>\n<td>PUT</td>\n<td><code>/api/flags/{flagKey}</code></td>\n<td>Modify flag configuration or targeting</td>\n<td>Admin</td>\n</tr>\n<tr>\n<td>Get Flag</td>\n<td>GET</td>\n<td><code>/api/flags/{flagKey}</code></td>\n<td>Retrieve flag definition and current status</td>\n<td>Admin/Read-Only</td>\n</tr>\n<tr>\n<td>List Flags</td>\n<td>GET</td>\n<td><code>/api/flags</code></td>\n<td>List all flags with filtering and pagination</td>\n<td>Admin/Read-Only</td>\n</tr>\n<tr>\n<td>Delete Flag</td>\n<td>DELETE</td>\n<td><code>/api/flags/{flagKey}</code></td>\n<td>Archive flag and clean up references</td>\n<td>Admin</td>\n</tr>\n<tr>\n<td>Create Experiment</td>\n<td>POST</td>\n<td><code>/api/experiments</code></td>\n<td>Set up A/B test with statistical configuration</td>\n<td>Admin</td>\n</tr>\n<tr>\n<td>Get Experiment Results</td>\n<td>GET</td>\n<td><code>/api/experiments/{id}/results</code></td>\n<td>Retrieve experiment metrics and significance</td>\n<td>Admin/Read-Only</td>\n</tr>\n</tbody></table>\n<p>The API implements <strong>optimistic concurrency control</strong> using entity versioning to prevent conflicting updates from multiple administrators. Each flag definition includes a version number that increments with each modification. Update requests must specify the expected version, and the API rejects requests where the expected version doesn&#39;t match the current state.</p>\n<p><strong>Data consistency</strong> across the system starts with the Flag Management API&#39;s write operations. When administrators modify flag configurations, the API immediately persists changes to the primary data store and broadcasts update notifications through the Real-time Update Service. This ensures that all client SDKs receive consistent flag definitions without requiring complex distributed consensus protocols.</p>\n<p>The Flag Management API also serves as the <strong>audit trail</strong> for all flag-related changes, recording who made what changes when for compliance and debugging purposes. This audit log proves invaluable when investigating unexpected behavior or understanding the timeline of feature rollouts.</p>\n<blockquote>\n<p><strong>Key Design Insight:</strong> The Flag Management API prioritizes consistency and auditability over raw performance. Administrative operations are infrequent compared to flag evaluations, so we can afford stronger consistency guarantees and comprehensive validation at this layer.</p>\n</blockquote>\n<h4 id=\"evaluation-engine\">Evaluation Engine</h4>\n<p>The <strong>Evaluation Engine</strong> represents the high-performance core of the feature flag system, analogous to the split-second decision-making capabilities of air traffic controllers during peak operations. This component must process thousands of flag evaluation requests per second while maintaining consistent user assignments and respecting complex targeting rules.</p>\n<p>The Evaluation Engine implements the <code>EvaluateFlag</code> function that takes a <code>FlagKey</code> and <code>UserContext</code> and returns an <code>EvaluationResult</code> containing the assigned variant, the computed value, and detailed reasoning for debugging purposes. The engine processes targeting rules in strict precedence order, applies percentage rollouts using consistent hashing, and returns appropriate fallback values when no rules match.</p>\n<table>\n<thead>\n<tr>\n<th>Evaluation Step</th>\n<th>Input</th>\n<th>Processing</th>\n<th>Output</th>\n<th>Performance Target</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Context Validation</td>\n<td><code>UserContext</code></td>\n<td>Validate required attributes present</td>\n<td>Valid context or error</td>\n<td>&lt; 0.1ms</td>\n</tr>\n<tr>\n<td>Rule Matching</td>\n<td>Flag rules + context</td>\n<td>Evaluate conditions with AND/OR logic</td>\n<td>Matching rule or none</td>\n<td>&lt; 0.5ms</td>\n</tr>\n<tr>\n<td>Percentage Allocation</td>\n<td>User ID + rollout config</td>\n<td>Apply consistent hashing algorithm</td>\n<td>Variant assignment</td>\n<td>&lt; 0.1ms</td>\n</tr>\n<tr>\n<td>Value Resolution</td>\n<td>Variant config</td>\n<td>Lookup variant value and metadata</td>\n<td>Resolved value</td>\n<td>&lt; 0.1ms</td>\n</tr>\n<tr>\n<td>Result Assembly</td>\n<td>All previous outputs</td>\n<td>Construct evaluation result with reason</td>\n<td><code>EvaluationResult</code></td>\n<td>&lt; 0.1ms</td>\n</tr>\n</tbody></table>\n<p><strong>Consistent hashing</strong> ensures that users receive the same variant assignment across multiple evaluations, even as flag configurations change. The engine combines the user&#39;s stable identifier with the flag key using a cryptographic hash function, then maps the hash output to variant buckets based on configured weight distributions. This approach prevents users from flip-flopping between variants when percentage rollouts expand or contract.</p>\n<p>The evaluation engine maintains <strong>in-memory flag caches</strong> to avoid database lookups on every evaluation request. These caches update immediately when the Real-time Update Service broadcasts flag changes, ensuring sub-millisecond evaluation performance while maintaining data freshness. The cache implementation uses read-write locks to allow concurrent evaluations while blocking only during cache updates.</p>\n<p><strong>Rule evaluation</strong> follows a deterministic precedence system where more specific targeting rules override general percentage rollouts. The engine evaluates user segment membership first, then individual user targeting, followed by attribute-based conditions, and finally percentage rollouts for the remaining population. This precedence system ensures predictable behavior when multiple rules could apply to the same user.</p>\n<blockquote>\n<p><strong>Performance Guarantee:</strong> The Evaluation Engine must complete flag evaluations in under 1 millisecond for 99% of requests. This strict performance requirement drives architectural decisions around caching, rule complexity limits, and fallback behaviors.</p>\n</blockquote>\n<h4 id=\"real-time-update-service\">Real-time Update Service</h4>\n<p>The <strong>Real-time Update Service</strong> functions as the radar and communication system of our air traffic control analogy, providing continuous situational awareness to all client SDKs about changing flag configurations. This component bridges the gap between administrative flag changes and their immediate propagation to production evaluation contexts.</p>\n<p>The service maintains persistent connections to client SDKs using <strong>Server-Sent Events (SSE)</strong> for flag update streaming. SSE provides the right balance of simplicity and real-time performance for flag updates, avoiding the complexity of WebSocket bi-directional communication while maintaining sub-second update latency. The service can handle thousands of concurrent client connections while batching update notifications to minimize bandwidth usage.</p>\n<table>\n<thead>\n<tr>\n<th>Connection State</th>\n<th>Allowed Operations</th>\n<th>Automatic Actions</th>\n<th>Client Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Connected</td>\n<td>Receive updates, send heartbeats</td>\n<td>Send flag changes immediately</td>\n<td>Process updates, maintain cache</td>\n</tr>\n<tr>\n<td>Reconnecting</td>\n<td>Buffer incoming requests</td>\n<td>Apply exponential backoff</td>\n<td>Use cached flags, attempt reconnect</td>\n</tr>\n<tr>\n<td>Disconnected</td>\n<td>Use local cache only</td>\n<td>Log connection attempts</td>\n<td>Graceful degradation to cache</td>\n</tr>\n</tbody></table>\n<p><strong>Connection management</strong> implements intelligent reconnection strategies with exponential backoff and jitter to prevent thundering herd problems when network connectivity returns after outages. The service tracks the last successful update timestamp for each client, enabling state synchronization when connections restore. Clients that reconnect after extended downtime receive complete flag configuration snapshots rather than incremental updates.</p>\n<p>The Real-time Update Service implements <strong>update deduplication</strong> to handle rapid successive changes to the same flag. Rather than sending multiple update notifications within a short time window, the service batches changes and sends only the final flag state. This optimization reduces network traffic and client processing overhead during periods of intensive flag configuration changes.</p>\n<p><strong>Broadcasting efficiency</strong> uses topic-based subscription patterns where clients can subscribe to specific flag changes rather than receiving all system updates. This selective subscription reduces bandwidth usage for deployments with hundreds of flags where individual services only need subsets of the total flag configuration.</p>\n<p>The service maintains detailed <strong>connection metrics</strong> including client count, update delivery success rates, and reconnection patterns. These metrics provide visibility into update propagation performance and help identify clients experiencing connectivity issues that might be serving stale flag configurations.</p>\n<h4 id=\"client-sdks\">Client SDKs</h4>\n<p>The <strong>Client SDKs</strong> represent the ground-level flight controllers in our air traffic control system, executing flag evaluation decisions within application processes while maintaining connection to the central coordination infrastructure. These SDKs provide the developer-facing API that applications use to check flag values and record analytics events.</p>\n<p>Client SDKs implement <strong>local evaluation</strong> patterns where flag configurations are cached within the application process, enabling flag evaluations to complete without network round trips. This local evaluation approach ensures that flag checks remain fast even during network partitions or service outages, supporting the graceful degradation requirements of production systems.</p>\n<table>\n<thead>\n<tr>\n<th>SDK Component</th>\n<th>Responsibility</th>\n<th>Performance Impact</th>\n<th>Fallback Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Evaluation Cache</td>\n<td>Store flag definitions locally</td>\n<td>Enables sub-ms evaluations</td>\n<td>Serves stale data during outages</td>\n</tr>\n<tr>\n<td>Update Client</td>\n<td>Receive real-time flag changes</td>\n<td>Minimal—async background updates</td>\n<td>Continues with cached flags</td>\n</tr>\n<tr>\n<td>Analytics Buffer</td>\n<td>Queue exposure events for batch upload</td>\n<td>Minimal—async fire-and-forget</td>\n<td>Drops events when buffer full</td>\n</tr>\n<tr>\n<td>Context Manager</td>\n<td>Handle user context and segmentation</td>\n<td>Minimal—in-memory operations</td>\n<td>Uses empty context as fallback</td>\n</tr>\n</tbody></table>\n<p><strong>Cache management</strong> within SDKs uses a two-tier approach with hot and warm flag storage. Frequently accessed flags remain in optimized in-memory structures for microsecond lookup times, while less active flags use more compact serialized representations. The SDK automatically promotes flags to hot storage based on evaluation frequency patterns.</p>\n<p><strong>Analytics integration</strong> enables SDKs to record flag exposure events using the <code>RecordExposure</code> function without impacting evaluation performance. SDKs batch exposure events and upload them asynchronously, ensuring that analytics tracking doesn&#39;t slow down the application&#39;s critical path. When analytics services are unavailable, SDKs gracefully drop events rather than blocking flag evaluations.</p>\n<p>The SDK provides <strong>configuration options</strong> for different deployment scenarios, including strict mode for development environments where flag evaluation failures should cause obvious errors, and permissive mode for production where graceful fallbacks maintain application stability.</p>\n<p><strong>Language-specific optimizations</strong> allow SDKs to leverage platform capabilities like Go&#39;s lightweight goroutines for background updates or Java&#39;s concurrent data structures for thread-safe cache access. However, all SDKs maintain consistent evaluation semantics and API contracts across language boundaries.</p>\n<blockquote>\n<p><strong>Design Trade-off:</strong> Client SDKs prioritize evaluation speed and resilience over perfect consistency. They may serve flag values that are seconds out of date during network partitions, but they guarantee that applications continue functioning rather than failing due to flag service dependencies.</p>\n</blockquote>\n<h3 id=\"project-structure-and-organization\">Project Structure and Organization</h3>\n<p>The feature flag system follows a <strong>modular architecture</strong> that separates concerns cleanly while supporting independent development and testing of each component. The project structure reflects the logical component boundaries and provides clear interfaces between subsystems.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>flagsystem/\n├── cmd/                          # Application entry points\n│   ├── flagserver/               # Flag Management API server\n│   ├── updateservice/            # Real-time Update Service\n│   └── analytics/                # Analytics processing service\n├── internal/                     # Private application packages\n│   ├── evaluation/               # Core evaluation engine\n│   ├── storage/                  # Data persistence layer\n│   ├── realtime/                 # Update streaming infrastructure\n│   ├── analytics/                # Metrics and experiment analysis\n│   └── common/                   # Shared utilities and types\n├── pkg/                          # Public API packages\n│   ├── sdk/                      # Client SDK implementations\n│   ├── api/                      # API client libraries\n│   └── types/                    # Shared type definitions\n├── configs/                      # Configuration files\n├── migrations/                   # Database schema migrations\n├── deployments/                  # Deployment configurations\n└── docs/                         # Additional documentation</code></pre></div>\n\n<h4 id=\"core-internal-packages\">Core Internal Packages</h4>\n<p>The <strong>internal/evaluation</strong> package contains the flag evaluation engine and implements all rule processing logic. This package has no external dependencies beyond basic data structures, making it highly testable and portable across different deployment environments.</p>\n<table>\n<thead>\n<tr>\n<th>File</th>\n<th>Purpose</th>\n<th>Key Types</th>\n<th>External Dependencies</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>engine.go</code></td>\n<td>Core evaluation logic and <code>EvaluateFlag</code> implementation</td>\n<td><code>EvaluationEngine</code>, <code>EvaluationResult</code></td>\n<td>None</td>\n</tr>\n<tr>\n<td><code>rules.go</code></td>\n<td>Targeting rule processing and precedence handling</td>\n<td><code>Rule</code>, <code>Condition</code>, <code>RuleEvaluator</code></td>\n<td>None</td>\n</tr>\n<tr>\n<td><code>hashing.go</code></td>\n<td>Consistent hashing for user assignment</td>\n<td><code>UserHasher</code>, <code>BucketAllocator</code></td>\n<td>crypto/sha256</td>\n</tr>\n<tr>\n<td><code>cache.go</code></td>\n<td>In-memory flag definition caching</td>\n<td><code>FlagCache</code>, <code>CacheEntry</code></td>\n<td>sync</td>\n</tr>\n</tbody></table>\n<p>The <strong>internal/storage</strong> package abstracts data persistence operations and provides interfaces that support multiple backend implementations. The package defines repository interfaces for flags, experiments, and analytics data while implementing concrete adapters for specific databases.</p>\n<p>The <strong>internal/realtime</strong> package handles all streaming update functionality including SSE connection management, client tracking, and update broadcasting. This package integrates with the storage layer to detect flag changes and with the evaluation engine to validate update consistency.</p>\n<h4 id=\"public-sdk-package-structure\">Public SDK Package Structure</h4>\n<p>The <strong>pkg/sdk</strong> package provides client libraries for different programming languages while maintaining consistent APIs and evaluation semantics. Each language implementation follows the same architectural patterns adapted to platform-specific idioms and performance characteristics.</p>\n<table>\n<thead>\n<tr>\n<th>Language</th>\n<th>Package Structure</th>\n<th>Key Files</th>\n<th>Platform Optimizations</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Go</td>\n<td><code>pkg/sdk/go/</code></td>\n<td><code>client.go</code>, <code>cache.go</code>, <code>types.go</code></td>\n<td>Goroutines for background updates</td>\n</tr>\n<tr>\n<td>Python</td>\n<td><code>pkg/sdk/python/</code></td>\n<td><code>client.py</code>, <code>cache.py</code>, <code>types.py</code></td>\n<td>Asyncio for concurrent operations</td>\n</tr>\n<tr>\n<td>Java</td>\n<td><code>pkg/sdk/java/</code></td>\n<td><code>Client.java</code>, <code>Cache.java</code>, <code>Types.java</code></td>\n<td>ExecutorService for thread management</td>\n</tr>\n</tbody></table>\n<h4 id=\"configuration-and-deployment-structure\">Configuration and Deployment Structure</h4>\n<p>The <strong>configs/</strong> directory contains environment-specific configuration files using a hierarchical structure that supports local development, testing, staging, and production deployments. Configuration files use YAML format with clear sections for each system component.</p>\n<p>The <strong>deployments/</strong> directory includes Docker configurations, Kubernetes manifests, and infrastructure-as-code definitions that support the feature flag system&#39;s deployment across different environments. The deployment configurations reflect the component architecture with separate services for the Flag Management API, Real-time Update Service, and analytics processing.</p>\n<blockquote>\n<p><strong>Organizational Principle:</strong> The project structure emphasizes <strong>interface-driven development</strong> where each package exports clear contracts through interface definitions. This approach supports testing with mock implementations and enables incremental migration to different storage or streaming technologies.</p>\n</blockquote>\n<h3 id=\"architecture-decision-records\">Architecture Decision Records</h3>\n<blockquote>\n<p><strong>Decision: Evaluation-First Architecture</strong></p>\n<ul>\n<li><strong>Context</strong>: Feature flag systems must balance evaluation performance, update latency, administrative functionality, and analytics capabilities within resource constraints</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>Admin-first: Comprehensive management UI with basic evaluation</li>\n<li>Analytics-first: Detailed experiment tracking with slower evaluation  </li>\n<li>Evaluation-first: Optimized flag checking with supporting services</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Build an evaluation-first architecture that prioritizes flag evaluation performance above other concerns</li>\n<li><strong>Rationale</strong>: Flag evaluations occur orders of magnitude more frequently than administrative operations. A typical application performs thousands of evaluations per second but only updates flag configurations a few times per day. Slow evaluations directly impact user-facing application performance, while slower administrative interfaces only affect developer productivity</li>\n<li><strong>Consequences</strong>: This architecture enables sub-millisecond flag evaluations through local caching and optimized rule processing, but requires more sophisticated real-time update mechanisms to maintain cache consistency across distributed clients</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Approach</th>\n<th>Evaluation Latency</th>\n<th>Update Propagation</th>\n<th>Administrative Features</th>\n<th>Chosen?</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Admin-first</td>\n<td>10-50ms (DB per eval)</td>\n<td>Immediate</td>\n<td>Rich UI, complex workflows</td>\n<td>❌</td>\n</tr>\n<tr>\n<td>Analytics-first</td>\n<td>5-20ms (logging overhead)</td>\n<td>Eventual consistency</td>\n<td>Basic admin, detailed metrics</td>\n<td>❌</td>\n</tr>\n<tr>\n<td>Evaluation-first</td>\n<td>&lt;1ms (cached local eval)</td>\n<td>&lt;5 seconds via SSE</td>\n<td>Functional admin, core metrics</td>\n<td>✅</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Server-Sent Events for Real-time Updates</strong></p>\n<ul>\n<li><strong>Context</strong>: Client SDKs need real-time flag updates to maintain cache consistency while supporting thousands of concurrent connections efficiently</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Polling: Clients request updates on fixed intervals</li>\n<li>WebSockets: Full bidirectional communication channels</li>\n<li>Server-Sent Events: Unidirectional server-to-client streaming</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Use Server-Sent Events (SSE) for streaming flag updates to client SDKs</li>\n<li><strong>Rationale</strong>: Flag updates are inherently unidirectional—the server pushes configuration changes to clients, but clients don&#39;t need to send data back through the same channel. SSE provides automatic reconnection, built-in event typing, and lower overhead than WebSockets. The protocol handles connection failures gracefully with exponential backoff, reducing server load during network instability</li>\n<li><strong>Consequences</strong>: SSE enables sub-second update propagation with minimal server resources, but limits future bidirectional features like client-initiated flag requests or real-time debugging commands</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Protocol</th>\n<th>Connection Overhead</th>\n<th>Reconnection Handling</th>\n<th>Browser Support</th>\n<th>Server Complexity</th>\n<th>Chosen?</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Polling</td>\n<td>Low per request</td>\n<td>Automatic</td>\n<td>Universal</td>\n<td>Minimal</td>\n<td>❌</td>\n</tr>\n<tr>\n<td>WebSockets</td>\n<td>High (persistent TCP)</td>\n<td>Manual implementation</td>\n<td>Good</td>\n<td>High</td>\n<td>❌</td>\n</tr>\n<tr>\n<td>SSE</td>\n<td>Medium (HTTP streaming)</td>\n<td>Automatic with backoff</td>\n<td>Good</td>\n<td>Medium</td>\n<td>✅</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: In-Memory Flag Caching with Real-time Invalidation</strong></p>\n<ul>\n<li><strong>Context</strong>: Flag evaluations must complete in under 1 millisecond while maintaining reasonable consistency when flag configurations change</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Direct database access: Query flag definitions on every evaluation</li>\n<li>Application-level caching: Cache flags with TTL-based expiration</li>\n<li>Real-time cache invalidation: Cache flags and invalidate immediately on changes</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Implement in-memory flag caching with real-time cache invalidation triggered by update notifications</li>\n<li><strong>Rationale</strong>: Database queries add 5-50ms latency that violates performance requirements, while TTL-based caching can serve stale flag values for extended periods during rapid configuration changes. Real-time invalidation provides the best balance of performance and consistency by maintaining microsecond evaluation speeds while propagating changes within seconds</li>\n<li><strong>Consequences</strong>: This approach enables target performance goals and ensures timely update propagation, but requires sophisticated cache management logic and increases system complexity through the real-time update infrastructure</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Caching Strategy</th>\n<th>Evaluation Latency</th>\n<th>Consistency Guarantee</th>\n<th>Implementation Complexity</th>\n<th>Chosen?</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>No caching</td>\n<td>5-50ms</td>\n<td>Strong</td>\n<td>Low</td>\n<td>❌</td>\n</tr>\n<tr>\n<td>TTL-based</td>\n<td>&lt;1ms</td>\n<td>Eventual (TTL period)</td>\n<td>Medium</td>\n<td>❌</td>\n</tr>\n<tr>\n<td>Real-time invalidation</td>\n<td>&lt;1ms</td>\n<td>Near real-time (&lt;5sec)</td>\n<td>High</td>\n<td>✅</td>\n</tr>\n</tbody></table>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>HTTP Server</td>\n<td><code>net/http</code> with <code>gorilla/mux</code></td>\n<td><code>gin-gonic/gin</code> with middleware</td>\n</tr>\n<tr>\n<td>Database</td>\n<td>PostgreSQL with <code>lib/pq</code></td>\n<td>PostgreSQL with <code>gorm</code> ORM</td>\n</tr>\n<tr>\n<td>Caching</td>\n<td>In-memory <code>sync.Map</code></td>\n<td>Redis with <code>go-redis/redis</code></td>\n</tr>\n<tr>\n<td>Real-time Updates</td>\n<td>SSE with <code>net/http</code> flusher</td>\n<td>Custom SSE library with reconnection</td>\n</tr>\n<tr>\n<td>Configuration</td>\n<td>YAML files with <code>gopkg.in/yaml.v3</code></td>\n<td>Consul/etcd with <code>spf13/viper</code></td>\n</tr>\n<tr>\n<td>Logging</td>\n<td>Standard <code>log</code> package</td>\n<td><code>sirupsen/logrus</code> structured logging</td>\n</tr>\n<tr>\n<td>Testing</td>\n<td>Built-in <code>testing</code> package</td>\n<td><code>testify/suite</code> with assertions</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-project-structure\">Recommended Project Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>flagsystem/\n├── cmd/\n│   ├── flagserver/\n│   │   └── main.go                 # Flag Management API entry point\n│   ├── updateservice/\n│   │   └── main.go                 # Real-time Update Service entry point\n│   └── analytics/\n│       └── main.go                 # Analytics service entry point\n├── internal/\n│   ├── evaluation/\n│   │   ├── engine.go               # Core evaluation implementation\n│   │   ├── engine_test.go          # Evaluation engine tests\n│   │   ├── rules.go                # Rule processing logic\n│   │   ├── rules_test.go           # Rule evaluation tests\n│   │   ├── cache.go                # Flag definition caching\n│   │   └── hashing.go              # Consistent user assignment\n│   ├── storage/\n│   │   ├── interfaces.go           # Repository interfaces\n│   │   ├── postgres.go             # PostgreSQL implementation\n│   │   ├── memory.go               # In-memory implementation for testing\n│   │   └── migrations/             # Database schema migrations\n│   ├── realtime/\n│   │   ├── server.go               # SSE server implementation\n│   │   ├── connections.go          # Client connection management\n│   │   └── broadcaster.go          # Update broadcasting logic\n│   ├── api/\n│   │   ├── handlers.go             # HTTP request handlers\n│   │   ├── middleware.go           # Authentication and logging middleware\n│   │   └── validation.go           # Request validation logic\n│   ├── analytics/\n│   │   ├── collector.go            # Exposure event collection\n│   │   ├── experiments.go          # A/B testing logic\n│   │   └── statistics.go           # Statistical significance calculation\n│   └── common/\n│       ├── types.go                # Shared type definitions\n│       ├── errors.go               # Error types and handling\n│       └── config.go               # Configuration structures\n├── pkg/\n│   └── sdk/\n│       └── go/\n│           ├── client.go           # SDK client implementation\n│           ├── client_test.go      # SDK integration tests\n│           ├── cache.go            # Client-side flag caching\n│           └── types.go            # SDK-specific types\n├── configs/\n│   ├── development.yaml            # Development environment config\n│   ├── testing.yaml                # Testing environment config\n│   └── production.yaml             # Production environment config\n├── deployments/\n│   ├── docker-compose.yaml         # Local development setup\n│   ├── kubernetes/                 # Kubernetes manifests\n│   └── terraform/                  # Infrastructure as code\n├── docs/\n│   ├── api.md                      # API documentation\n│   └── deployment.md               # Deployment guide\n├── go.mod                          # Go module definition\n├── go.sum                          # Dependency checksums\n├── Makefile                        # Build and test automation\n└── README.md                       # Project overview and setup</code></pre></div>\n\n<h4 id=\"core-type-definitions\">Core Type Definitions</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// internal/common/types.go</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> common</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#9ECBFF\"> \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Core identifier types for type safety</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> FlagKey</span><span style=\"color:#F97583\"> string</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> UserID</span><span style=\"color:#F97583\"> string</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// User context for flag evaluation targeting</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> UserContext</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    UserID     </span><span style=\"color:#B392F0\">UserID</span><span style=\"color:#9ECBFF\">                    `json:\"user_id\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Attributes </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{}    </span><span style=\"color:#9ECBFF\">`json:\"attributes\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Segments   []</span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">                  `json:\"segments\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Flag variant definition with weighted allocation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> Variant</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Key    </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"key\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Value  </span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{} </span><span style=\"color:#9ECBFF\">`json:\"value\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Weight </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">         `json:\"weight\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Result of flag evaluation with debugging information</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> EvaluationResult</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    FlagKey </span><span style=\"color:#B392F0\">FlagKey</span><span style=\"color:#9ECBFF\">     `json:\"flag_key\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Value   </span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{} </span><span style=\"color:#9ECBFF\">`json:\"value\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Variant </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"variant\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Reason  </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"reason\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Source  </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"source\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Flag change notification for real-time updates</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> FlagUpdate</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    FlagKey   </span><span style=\"color:#B392F0\">FlagKey</span><span style=\"color:#9ECBFF\">   `json:\"flag_key\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Operation </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">    `json:\"operation\"`</span><span style=\"color:#6A737D\"> // \"create\", \"update\", \"delete\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Timestamp </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\"> `json:\"timestamp\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Version   </span><span style=\"color:#F97583\">int64</span><span style=\"color:#9ECBFF\">     `json:\"version\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Flag evaluation event for analytics</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> FlagExposure</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    FlagKey     </span><span style=\"color:#B392F0\">FlagKey</span><span style=\"color:#9ECBFF\">                `json:\"flag_key\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    UserID      </span><span style=\"color:#B392F0\">UserID</span><span style=\"color:#9ECBFF\">                 `json:\"user_id\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Variant     </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">                 `json:\"variant\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Value       </span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{}            </span><span style=\"color:#9ECBFF\">`json:\"value\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Context     </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{} </span><span style=\"color:#9ECBFF\">`json:\"context\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Timestamp   </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">              `json:\"timestamp\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ExperimentID </span><span style=\"color:#F97583\">*</span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">               `json:\"experiment_id,omitempty\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Statistical significance calculation result</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> SignificanceResult</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ExperimentID     </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">    `json:\"experiment_id\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ControlVariant   </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">    `json:\"control_variant\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    TreatmentVariant </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">    `json:\"treatment_variant\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PValue           </span><span style=\"color:#F97583\">float64</span><span style=\"color:#9ECBFF\">   `json:\"p_value\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Confidence       </span><span style=\"color:#F97583\">float64</span><span style=\"color:#9ECBFF\">   `json:\"confidence\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Significant      </span><span style=\"color:#F97583\">bool</span><span style=\"color:#9ECBFF\">      `json:\"significant\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CalculatedAt     </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\"> `json:\"calculated_at\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"core-interface-definitions\">Core Interface Definitions</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// internal/evaluation/interfaces.go</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> evaluation</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Core flag evaluation interface</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> Evaluator</span><span style=\"color:#F97583\"> interface</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // EvaluateFlag processes targeting rules and returns appropriate variant</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    EvaluateFlag</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">flagKey</span><span style=\"color:#B392F0\"> FlagKey</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">context</span><span style=\"color:#B392F0\"> UserContext</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">EvaluationResult</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // UpdateFlags refreshes cached flag definitions</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    UpdateFlags</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">updates</span><span style=\"color:#E1E4E8\"> []</span><span style=\"color:#B392F0\">FlagUpdate</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // GetFlags returns all currently cached flag keys</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    GetFlags</span><span style=\"color:#E1E4E8\">() []</span><span style=\"color:#B392F0\">FlagKey</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// internal/realtime/interfaces.go</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> realtime</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Real-time update streaming interface</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> UpdateStreamer</span><span style=\"color:#F97583\"> interface</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // StreamUpdates provides real-time flag changes for specific client</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    StreamUpdates</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">clientID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">chan</span><span style=\"color:#B392F0\"> FlagUpdate</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // BroadcastUpdate sends flag changes to all connected clients</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    BroadcastUpdate</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">update</span><span style=\"color:#B392F0\"> FlagUpdate</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // DisconnectClient cleans up resources for disconnected client</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    DisconnectClient</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">clientID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// internal/analytics/interfaces.go</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> analytics</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Analytics and experiment tracking interface</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> AnalyticsCollector</span><span style=\"color:#F97583\"> interface</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // RecordExposure logs flag evaluation event for analysis</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    RecordExposure</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">exposure</span><span style=\"color:#B392F0\"> FlagExposure</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // CalculateSignificance computes experiment statistical results</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    CalculateSignificance</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">experimentID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">SignificanceResult</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // GetExperimentMetrics returns aggregated experiment data</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    GetExperimentMetrics</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">experimentID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{}, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// internal/storage/memory.go - Complete in-memory storage for testing</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> storage</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">fmt</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">sync</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">flagsystem/internal/common</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// InMemoryFlagStore provides thread-safe in-memory flag storage</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> InMemoryFlagStore</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    flags  </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#B392F0\">common</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">FlagKey</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FlagDefinition</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    mutex  </span><span style=\"color:#B392F0\">sync</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">RWMutex</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Audit trail for debugging</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    changes []</span><span style=\"color:#B392F0\">FlagChange</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> FlagDefinition</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Key         </span><span style=\"color:#B392F0\">common</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">FlagKey</span><span style=\"color:#9ECBFF\">           `json:\"key\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Name        </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">                   `json:\"name\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Description </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">                   `json:\"description\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Enabled     </span><span style=\"color:#F97583\">bool</span><span style=\"color:#9ECBFF\">                     `json:\"enabled\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Variants    []</span><span style=\"color:#B392F0\">common</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Variant</span><span style=\"color:#9ECBFF\">         `json:\"variants\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Rules       []</span><span style=\"color:#B392F0\">TargetingRule</span><span style=\"color:#9ECBFF\">          `json:\"rules\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    DefaultRule </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">PercentageRule</span><span style=\"color:#9ECBFF\">          `json:\"default_rule\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Version     </span><span style=\"color:#F97583\">int64</span><span style=\"color:#9ECBFF\">                    `json:\"version\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CreatedAt   </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">                `json:\"created_at\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    UpdatedAt   </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">                `json:\"updated_at\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> TargetingRule</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ID          </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">                   `json:\"id\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Name        </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">                   `json:\"name\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Conditions  []</span><span style=\"color:#B392F0\">Condition</span><span style=\"color:#9ECBFF\">              `json:\"conditions\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Operator    </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">                   `json:\"operator\"`</span><span style=\"color:#6A737D\"> // \"AND\" or \"OR\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Allocation  []</span><span style=\"color:#B392F0\">VariantAllocation</span><span style=\"color:#9ECBFF\">      `json:\"allocation\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Enabled     </span><span style=\"color:#F97583\">bool</span><span style=\"color:#9ECBFF\">                     `json:\"enabled\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> Condition</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Attribute </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"attribute\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Operator  </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"operator\"`</span><span style=\"color:#6A737D\"> // \"equals\", \"in\", \"contains\", etc.</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Value     </span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{} </span><span style=\"color:#9ECBFF\">`json:\"value\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> VariantAllocation</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Variant    </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\"> `json:\"variant\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Percentage </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">    `json:\"percentage\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> PercentageRule</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Allocations []</span><span style=\"color:#B392F0\">VariantAllocation</span><span style=\"color:#9ECBFF\"> `json:\"allocations\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> FlagChange</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    FlagKey   </span><span style=\"color:#B392F0\">common</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">FlagKey</span><span style=\"color:#9ECBFF\"> `json:\"flag_key\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Operation </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">         `json:\"operation\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Timestamp </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">      `json:\"timestamp\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Version   </span><span style=\"color:#F97583\">int64</span><span style=\"color:#9ECBFF\">          `json:\"version\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// NewInMemoryFlagStore creates a new in-memory flag store</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewInMemoryFlagStore</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">InMemoryFlagStore</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">InMemoryFlagStore</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        flags:   </span><span style=\"color:#B392F0\">make</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#B392F0\">common</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">FlagKey</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FlagDefinition</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        changes: </span><span style=\"color:#B392F0\">make</span><span style=\"color:#E1E4E8\">([]</span><span style=\"color:#B392F0\">FlagChange</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// GetFlag retrieves a flag definition by key</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">s </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">InMemoryFlagStore</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">GetFlag</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">key</span><span style=\"color:#B392F0\"> common</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">FlagKey</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FlagDefinition</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    s.mutex.</span><span style=\"color:#B392F0\">RLock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> s.mutex.</span><span style=\"color:#B392F0\">RUnlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    flag, exists </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> s.flags[key]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> !</span><span style=\"color:#E1E4E8\">exists {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\">, fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"flag not found: </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, key)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Return a copy to prevent external mutation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    flagCopy </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\">flag</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#E1E4E8\">flagCopy, </span><span style=\"color:#79B8FF\">nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// CreateFlag stores a new flag definition</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">s </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">InMemoryFlagStore</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">CreateFlag</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">flag</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">FlagDefinition</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    s.mutex.</span><span style=\"color:#B392F0\">Lock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> s.mutex.</span><span style=\"color:#B392F0\">Unlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> _, exists </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> s.flags[flag.Key]; exists {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"flag already exists: </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, flag.Key)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    now </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> time.</span><span style=\"color:#B392F0\">Now</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    flag.Version </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    flag.CreatedAt </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> now</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    flag.UpdatedAt </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> now</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Store a copy to prevent external mutation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    flagCopy </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\">flag</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    s.flags[flag.Key] </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#E1E4E8\">flagCopy</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Record change for audit trail</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    s.changes </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> append</span><span style=\"color:#E1E4E8\">(s.changes, </span><span style=\"color:#B392F0\">FlagChange</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        FlagKey:   flag.Key,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Operation: </span><span style=\"color:#9ECBFF\">\"create\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Timestamp: now,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Version:   flag.Version,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    })</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// UpdateFlag modifies an existing flag definition</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">s </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">InMemoryFlagStore</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">UpdateFlag</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">flag</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">FlagDefinition</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    s.mutex.</span><span style=\"color:#B392F0\">Lock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> s.mutex.</span><span style=\"color:#B392F0\">Unlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    existing, exists </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> s.flags[flag.Key]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> !</span><span style=\"color:#E1E4E8\">exists {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"flag not found: </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, flag.Key)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    now </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> time.</span><span style=\"color:#B392F0\">Now</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    flag.Version </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> existing.Version </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    flag.CreatedAt </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> existing.CreatedAt</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    flag.UpdatedAt </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> now</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Store a copy to prevent external mutation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    flagCopy </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\">flag</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    s.flags[flag.Key] </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#E1E4E8\">flagCopy</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Record change for audit trail</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    s.changes </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> append</span><span style=\"color:#E1E4E8\">(s.changes, </span><span style=\"color:#B392F0\">FlagChange</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        FlagKey:   flag.Key,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Operation: </span><span style=\"color:#9ECBFF\">\"update\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Timestamp: now,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Version:   flag.Version,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    })</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ListFlags returns all flag definitions with optional filtering</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">s </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">InMemoryFlagStore</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">ListFlags</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">enabledOnly</span><span style=\"color:#F97583\"> bool</span><span style=\"color:#E1E4E8\">) ([]</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FlagDefinition</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    s.mutex.</span><span style=\"color:#B392F0\">RLock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> s.mutex.</span><span style=\"color:#B392F0\">RUnlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    flags </span><span style=\"color:#F97583\">:=</span><span style=\"color:#B392F0\"> make</span><span style=\"color:#E1E4E8\">([]</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FlagDefinition</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#B392F0\">len</span><span style=\"color:#E1E4E8\">(s.flags))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> _, flag </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> range</span><span style=\"color:#E1E4E8\"> s.flags {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> !</span><span style=\"color:#E1E4E8\">enabledOnly </span><span style=\"color:#F97583\">||</span><span style=\"color:#E1E4E8\"> flag.Enabled {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // Return copies to prevent external mutation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            flagCopy </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\">flag</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            flags </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> append</span><span style=\"color:#E1E4E8\">(flags, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">flagCopy)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> flags, </span><span style=\"color:#79B8FF\">nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// GetChangesSince returns flag changes after specified timestamp</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">s </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">InMemoryFlagStore</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">GetChangesSince</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">since</span><span style=\"color:#B392F0\"> time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#E1E4E8\">) ([]</span><span style=\"color:#B392F0\">FlagChange</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    s.mutex.</span><span style=\"color:#B392F0\">RLock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> s.mutex.</span><span style=\"color:#B392F0\">RUnlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    changes </span><span style=\"color:#F97583\">:=</span><span style=\"color:#B392F0\"> make</span><span style=\"color:#E1E4E8\">([]</span><span style=\"color:#B392F0\">FlagChange</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> _, change </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> range</span><span style=\"color:#E1E4E8\"> s.changes {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> change.Timestamp.</span><span style=\"color:#B392F0\">After</span><span style=\"color:#E1E4E8\">(since) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            changes </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> append</span><span style=\"color:#E1E4E8\">(changes, change)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> changes, </span><span style=\"color:#79B8FF\">nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeletons\">Core Logic Skeletons</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// internal/evaluation/engine.go - Core evaluation logic to implement</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> evaluation</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">crypto/sha256</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">encoding/binary</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">fmt</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">math</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">flagsystem/internal/common</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">flagsystem/internal/storage</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// EvaluationEngine implements the core flag evaluation logic</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> EvaluationEngine</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    flagStore </span><span style=\"color:#B392F0\">storage</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">FlagRepository</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cache     </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FlagCache</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// NewEvaluationEngine creates a new evaluation engine</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewEvaluationEngine</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">flagStore</span><span style=\"color:#B392F0\"> storage</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">FlagRepository</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">EvaluationEngine</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">EvaluationEngine</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        flagStore: flagStore,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        cache:     </span><span style=\"color:#B392F0\">NewFlagCache</span><span style=\"color:#E1E4E8\">(),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// EvaluateFlag processes targeting rules and returns appropriate variant</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">e </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">EvaluationEngine</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">EvaluateFlag</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">flagKey</span><span style=\"color:#B392F0\"> common</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">FlagKey</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">context</span><span style=\"color:#B392F0\"> common</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">UserContext</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">common</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">EvaluationResult</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Validate input parameters - check flagKey is not empty, context has valid UserID</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //         Return error result if validation fails</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Retrieve flag definition from cache, falling back to storage if cache miss</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //         Use e.cache.GetFlag(flagKey) first, then e.flagStore.GetFlag(flagKey) as fallback</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Check if flag is enabled - if disabled, return default variant with reason \"flag_disabled\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Evaluate targeting rules in precedence order using evaluateTargetingRules()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //         Rules should be processed from most specific to most general</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: If no targeting rules match, apply percentage rollout using consistent hashing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //         Call calculateUserBucket() to get user's bucket assignment</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: If no percentage rule matches, return default variant from flag definition</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //         Include detailed reason explaining why this fallback was used</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Construct and return EvaluationResult with variant key, resolved value, evaluation reason</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#B392F0\"> common</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">EvaluationResult</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        FlagKey: flagKey,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Value:   </span><span style=\"color:#79B8FF\">nil</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#6A737D\">// TODO: Replace with actual resolved value</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Variant: </span><span style=\"color:#9ECBFF\">\"\"</span><span style=\"color:#E1E4E8\">,  </span><span style=\"color:#6A737D\">// TODO: Replace with selected variant key</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Reason:  </span><span style=\"color:#9ECBFF\">\"\"</span><span style=\"color:#E1E4E8\">,  </span><span style=\"color:#6A737D\">// TODO: Replace with evaluation reason</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Source:  </span><span style=\"color:#9ECBFF\">\"evaluation_engine\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// evaluateTargetingRules processes flag rules against user context</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">e </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">EvaluationEngine</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">evaluateTargetingRules</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">rules</span><span style=\"color:#E1E4E8\"> []</span><span style=\"color:#B392F0\">storage</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">TargetingRule</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">context</span><span style=\"color:#B392F0\"> common</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">UserContext</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{}, </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Iterate through rules in order (rules are pre-sorted by precedence)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: For each rule, check if it's enabled - skip disabled rules</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Evaluate rule conditions using evaluateRuleConditions()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //         Handle AND/OR operators correctly based on rule.Operator</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: If rule matches, apply percentage allocation within the rule</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //         Use consistent hashing to select variant from rule's allocation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Return selected variant key, resolved value, and evaluation reason</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //         Reason should indicate which rule matched (e.g., \"targeting_rule:user_segment\")</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">nil</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">false</span><span style=\"color:#6A737D\"> // TODO: Replace with actual values</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// evaluateRuleConditions checks if user context satisfies rule conditions</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">e </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">EvaluationEngine</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">evaluateRuleConditions</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">conditions</span><span style=\"color:#E1E4E8\"> []</span><span style=\"color:#B392F0\">storage</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Condition</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">operator</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">context</span><span style=\"color:#B392F0\"> common</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">UserContext</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Handle empty conditions array (should return true - matches all users)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Evaluate each condition using evaluateCondition()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //         Store boolean result for each condition</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Apply logical operator (AND/OR) to combine condition results</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //         AND: all conditions must be true</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //         OR: at least one condition must be true</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Return final boolean result</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#6A737D\"> // TODO: Replace with actual logic</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// evaluateCondition checks a single condition against user context</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">e </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">EvaluationEngine</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">evaluateCondition</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">condition</span><span style=\"color:#B392F0\"> storage</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Condition</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">context</span><span style=\"color:#B392F0\"> common</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">UserContext</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Get attribute value from context.Attributes using condition.Attribute</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //         Handle missing attributes (return false for most operators)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Handle special attributes like \"user_id\" and \"segments\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //         user_id should use context.UserID value</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //         segments should check if condition.Value is in context.Segments</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Apply condition operator:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //         \"equals\": attribute == condition.Value</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //         \"not_equals\": attribute != condition.Value  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //         \"in\": attribute is in condition.Value (array)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //         \"not_in\": attribute is not in condition.Value (array)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //         \"contains\": string(attribute) contains string(condition.Value)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //         \"starts_with\": string(attribute) starts with string(condition.Value)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //         \"greater_than\": numeric comparison</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //         \"less_than\": numeric comparison</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Handle type conversions and edge cases gracefully</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //         String comparisons should be case-sensitive</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //         Numeric comparisons should handle int/float conversions</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#6A737D\"> // TODO: Replace with actual logic</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// calculateUserBucket determines user's allocation bucket using consistent hashing</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">e </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">EvaluationEngine</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">calculateUserBucket</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">userID</span><span style=\"color:#B392F0\"> common</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">UserID</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">flagKey</span><span style=\"color:#B392F0\"> common</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">FlagKey</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Create hash input by combining userID and flagKey</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //         Use format like \"userID:flagKey\" to ensure uniqueness across flags</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Calculate SHA-256 hash of the input string</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //         Use crypto/sha256 package for cryptographically secure hashing</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Convert first 8 bytes of hash to uint64 using binary.BigEndian</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //         This provides consistent numeric value from hash bytes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Map hash to percentage bucket (0-99) using modulo operation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //         Ensure uniform distribution across the 0-99 range</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // HINT: Consistent hashing ensures the same user always gets the same bucket</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // for a given flag, even across multiple evaluation calls</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#6A737D\"> // TODO: Replace with calculated bucket</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// resolveVariantValue gets the configured value for a variant key</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">e </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">EvaluationEngine</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">resolveVariantValue</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">variants</span><span style=\"color:#E1E4E8\"> []</span><span style=\"color:#B392F0\">common</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Variant</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">variantKey</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{}, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Search through variants array to find variant with matching Key</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Return the variant's Value field if found</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Return error if variant key not found in variants array</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //         Include both the sought key and available keys in error message</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\">, fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"variant not found: </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, variantKey) </span><span style=\"color:#6A737D\">// TODO: Replace with actual logic</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p><strong>After Milestone 1 (Flag Evaluation Engine):</strong></p>\n<ul>\n<li>Run <code>go test ./internal/evaluation/...</code> - all tests should pass</li>\n<li>Create a simple flag with boolean variants and percentage rollout</li>\n<li>Verify that the same user ID always gets the same variant across multiple evaluations</li>\n<li>Test rule evaluation with user segments and attribute conditions</li>\n<li>Check that evaluation completes in under 1 millisecond for cached flags</li>\n</ul>\n<p><strong>After Milestone 2 (Real-time Flag Updates):</strong></p>\n<ul>\n<li>Start the update service with <code>go run cmd/updateservice/main.go</code></li>\n<li>Connect a test client and verify SSE connection establishment</li>\n<li>Update a flag configuration and confirm the change propagates within 5 seconds</li>\n<li>Disconnect the client, update flags, reconnect, and verify state synchronization</li>\n<li>Monitor connection metrics to ensure proper cleanup of disconnected clients</li>\n</ul>\n<p><strong>After Milestone 3 (Flag Analytics &amp; Experiments):</strong></p>\n<ul>\n<li>Run an A/B test with two variants and record exposure events</li>\n<li>Generate test conversion data and verify statistical significance calculation</li>\n<li>Check that exposure events are batched and uploaded without blocking evaluations</li>\n<li>Verify experiment reports show confidence intervals and p-values</li>\n<li>Test sample ratio mismatch detection with uneven traffic allocation</li>\n</ul>\n<h2 id=\"data-model\">Data Model</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section establishes the data structures for Milestone 1 (Flag Evaluation Engine), Milestone 2 (Real-time Flag Updates), and Milestone 3 (Flag Analytics &amp; Experiments) by defining how flags, rules, user contexts, and experiments are modeled and stored.</p>\n</blockquote>\n<p>Think of the data model as the <strong>blueprint for a sophisticated air traffic control system</strong>. Just as air traffic control needs detailed information about each aircraft (flight number, destination, altitude, speed), weather conditions (wind patterns, visibility), and flight rules (priority levels, restricted airspace), our feature flag system needs comprehensive data structures to make intelligent routing decisions about which users receive which features.</p>\n<p><img src=\"/api/project/feature-flags/architecture-doc/asset?path=diagrams%2Fdata-model.svg\" alt=\"Data Model Relationships\"></p>\n<p>The air traffic control analogy extends to the relationships between data entities. Aircraft have dependencies on runways, weather affects multiple flights simultaneously, and control tower decisions must be logged for safety audits. Similarly, feature flags have complex relationships with targeting rules, user contexts affect multiple flag evaluations, and every flag decision must be tracked for analysis and compliance.</p>\n<p>Our data model must support three critical capabilities that parallel air traffic control operations. First, <strong>real-time decision making</strong> requires rich context about each &quot;aircraft&quot; (user) and current &quot;weather conditions&quot; (system state) to route traffic safely. Second, <strong>historical tracking</strong> demands comprehensive logging of every decision for post-incident analysis and performance optimization. Third, <strong>predictive planning</strong> needs structured experiment data to forecast the impact of routing changes before they affect live traffic.</p>\n<h3 id=\"flag-definition-structure\">Flag Definition Structure</h3>\n<p>The flag definition structure serves as the <strong>master flight plan</strong> for each feature, containing all the information needed to make consistent routing decisions across millions of users. Just as a flight plan specifies departure gates, flight paths, alternate routes, and emergency procedures, a flag definition specifies variants, targeting rules, fallback behavior, and operational metadata.</p>\n<p>The core challenge in modeling flag definitions lies in supporting <strong>flexible targeting without sacrificing evaluation performance</strong>. Simple boolean flags might seem sufficient initially, but production systems quickly demand percentage rollouts, user segmentation, geographic targeting, and complex rule combinations. Our data model must accommodate this complexity while ensuring that flag evaluation remains fast enough for real-time request processing.</p>\n<blockquote>\n<p><strong>Decision: Hierarchical Rule Structure with Explicit Precedence</strong></p>\n<ul>\n<li><strong>Context</strong>: Flag targeting can involve multiple overlapping rules (user attributes, segments, percentage rollouts), and the order of evaluation affects which users receive which variants</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>Flat rule list with implicit precedence</li>\n<li>Hierarchical rules with explicit priority numbers</li>\n<li>Single rule type with complex nested conditions</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Hierarchical rules with explicit precedence ordering</li>\n<li><strong>Rationale</strong>: Explicit precedence prevents non-deterministic evaluation when rules overlap, hierarchical structure supports complex logic without performance penalties, and clear separation enables easier debugging and rule management</li>\n<li><strong>Consequences</strong>: Enables predictable evaluation behavior and supports complex targeting scenarios, but requires careful precedence management and slightly more complex rule authoring</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Rule Precedence</th>\n<th>Rule Type</th>\n<th>Purpose</th>\n<th>Example Use Case</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1 (Highest)</td>\n<td>User Override Rules</td>\n<td>Target specific users or segments</td>\n<td>Enable beta feature for internal team</td>\n</tr>\n<tr>\n<td>2</td>\n<td>Attribute-Based Rules</td>\n<td>Target based on user properties</td>\n<td>Show premium features to paid users</td>\n</tr>\n<tr>\n<td>3</td>\n<td>Percentage Rules</td>\n<td>Gradual rollouts with consistent assignment</td>\n<td>Release to 25% of users in US region</td>\n</tr>\n<tr>\n<td>4 (Lowest)</td>\n<td>Default Rule</td>\n<td>Fallback when no other rules match</td>\n<td>Disable feature for remaining users</td>\n</tr>\n</tbody></table>\n<p>The <code>FlagDefinition</code> structure captures this hierarchical approach while maintaining evaluation efficiency. Each flag contains multiple rule layers that are processed in strict precedence order, ensuring deterministic outcomes regardless of rule complexity or user context variations.</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Key</td>\n<td>FlagKey</td>\n<td>Unique identifier for the flag across all environments</td>\n</tr>\n<tr>\n<td>Name</td>\n<td>string</td>\n<td>Human-readable name for management interface display</td>\n</tr>\n<tr>\n<td>Description</td>\n<td>string</td>\n<td>Purpose and context documentation for team collaboration</td>\n</tr>\n<tr>\n<td>Enabled</td>\n<td>bool</td>\n<td>Master switch to disable flag evaluation without deleting</td>\n</tr>\n<tr>\n<td>Type</td>\n<td>string</td>\n<td>Value type: &quot;boolean&quot;, &quot;string&quot;, &quot;number&quot;, &quot;json&quot;</td>\n</tr>\n<tr>\n<td>Variants</td>\n<td>[]Variant</td>\n<td>Available variants with keys, values, and allocation weights</td>\n</tr>\n<tr>\n<td>TargetingRules</td>\n<td>[]TargetingRule</td>\n<td>Ordered list of conditional rules with explicit precedence</td>\n</tr>\n<tr>\n<td>PercentageRule</td>\n<td>PercentageRule</td>\n<td>Default percentage allocation when no targeting rules match</td>\n</tr>\n<tr>\n<td>DefaultVariant</td>\n<td>string</td>\n<td>Fallback variant key when all rules fail or flag is disabled</td>\n</tr>\n<tr>\n<td>Prerequisites</td>\n<td>[]FlagKey</td>\n<td>Other flags that must be enabled before evaluating this flag</td>\n</tr>\n<tr>\n<td>CreatedAt</td>\n<td>time.Time</td>\n<td>Flag creation timestamp for audit trail</td>\n</tr>\n<tr>\n<td>UpdatedAt</td>\n<td>time.Time</td>\n<td>Last modification timestamp for cache invalidation</td>\n</tr>\n<tr>\n<td>CreatedBy</td>\n<td>string</td>\n<td>User identifier who created the flag</td>\n</tr>\n<tr>\n<td>UpdatedBy</td>\n<td>string</td>\n<td>User identifier who last modified the flag</td>\n</tr>\n<tr>\n<td>Tags</td>\n<td>[]string</td>\n<td>Categorical labels for organization and filtering</td>\n</tr>\n<tr>\n<td>Archived</td>\n<td>bool</td>\n<td>Soft deletion marker for flags no longer in use</td>\n</tr>\n</tbody></table>\n<p>The <code>Variant</code> structure represents each possible outcome of a flag evaluation, containing not just the value but also metadata needed for consistent allocation and debugging. Think of variants as different <strong>flight destinations</strong> that users can be routed to based on the evaluation rules.</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Key</td>\n<td>string</td>\n<td>Unique identifier for the variant within the flag</td>\n</tr>\n<tr>\n<td>Value</td>\n<td>interface{}</td>\n<td>Actual value returned to client (string, number, boolean, or JSON object)</td>\n</tr>\n<tr>\n<td>Weight</td>\n<td>int</td>\n<td>Relative weight for percentage allocation (higher numbers = larger allocation)</td>\n</tr>\n<tr>\n<td>Name</td>\n<td>string</td>\n<td>Human-readable name for management interface</td>\n</tr>\n<tr>\n<td>Description</td>\n<td>string</td>\n<td>Documentation of variant purpose and expected behavior</td>\n</tr>\n</tbody></table>\n<p>Targeting rules provide the <strong>conditional logic engine</strong> that determines which users receive which variants. Each rule represents a specific targeting strategy with its own conditions and variant allocation scheme.</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>ID</td>\n<td>string</td>\n<td>Unique identifier for the rule within the flag</td>\n</tr>\n<tr>\n<td>Description</td>\n<td>string</td>\n<td>Human-readable explanation of rule purpose</td>\n</tr>\n<tr>\n<td>Conditions</td>\n<td>[]Condition</td>\n<td>List of attribute-based conditions that must be satisfied</td>\n</tr>\n<tr>\n<td>ConditionOperator</td>\n<td>string</td>\n<td>Logical operator combining conditions: &quot;AND&quot; or &quot;OR&quot;</td>\n</tr>\n<tr>\n<td>VariantAllocations</td>\n<td>[]VariantAllocation</td>\n<td>How to distribute users matching this rule across variants</td>\n</tr>\n<tr>\n<td>Enabled</td>\n<td>bool</td>\n<td>Switch to temporarily disable rule without deletion</td>\n</tr>\n</tbody></table>\n<p>Individual conditions within targeting rules specify <strong>attribute-based matching criteria</strong> that are evaluated against the user context. The condition model supports various comparison operations to handle different attribute types and matching scenarios.</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Attribute</td>\n<td>string</td>\n<td>User context attribute name to evaluate (e.g., &quot;email&quot;, &quot;plan&quot;, &quot;region&quot;)</td>\n</tr>\n<tr>\n<td>Operator</td>\n<td>string</td>\n<td>Comparison operator: &quot;equals&quot;, &quot;in&quot;, &quot;contains&quot;, &quot;greater_than&quot;, &quot;less_than&quot;</td>\n</tr>\n<tr>\n<td>Values</td>\n<td>[]interface{}</td>\n<td>List of values to compare against (type matches operator requirements)</td>\n</tr>\n<tr>\n<td>Negate</td>\n<td>bool</td>\n<td>Whether to invert the condition result (NOT operation)</td>\n</tr>\n</tbody></table>\n<p>The percentage rule provides <strong>default allocation behavior</strong> when no targeting rules match the user context. This ensures every user receives a variant assignment through consistent hashing, even when they don&#39;t match any specific targeting criteria.</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>VariantAllocations</td>\n<td>[]VariantAllocation</td>\n<td>Distribution of unmatched users across variants</td>\n</tr>\n<tr>\n<td>Enabled</td>\n<td>bool</td>\n<td>Whether to apply percentage rule or return default variant</td>\n</tr>\n</tbody></table>\n<p>Variant allocations specify how users matching a rule are distributed across available variants using <strong>deterministic percentage splits</strong>. The allocation system ensures stable assignment where users consistently receive the same variant across multiple evaluations.</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>VariantKey</td>\n<td>string</td>\n<td>Key of variant to assign</td>\n</tr>\n<tr>\n<td>Percentage</td>\n<td>int</td>\n<td>Percentage of matched users to assign this variant (0-100)</td>\n</tr>\n<tr>\n<td>RangeStart</td>\n<td>int</td>\n<td>Starting bucket number for this allocation (computed from percentage)</td>\n</tr>\n<tr>\n<td>RangeEnd</td>\n<td>int</td>\n<td>Ending bucket number for this allocation (computed from percentage)</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p>The critical insight for percentage allocation is that percentages are converted to <strong>bucket ranges</strong> during flag creation, not during evaluation. This preprocessing enables fast evaluation by checking which bucket a user falls into rather than performing percentage calculations on every request.</p>\n</blockquote>\n<p><strong>Common Rule Modeling Pitfalls:</strong></p>\n<p>⚠️ <strong>Pitfall: Overlapping Percentage Allocations</strong>\nMany implementations allow variant allocations that sum to more or less than 100%, causing non-deterministic assignment or users falling through cracks. Always validate that percentages sum exactly to 100% within each rule and use bucket ranges to ensure complete coverage.</p>\n<p>⚠️ <strong>Pitfall: Circular Flag Prerequisites</strong>\nFlag A depends on Flag B which depends on Flag A, creating infinite loops during evaluation. Implement dependency graph validation during flag creation to detect cycles, and consider topological sorting for complex dependency chains.</p>\n<p>⚠️ <strong>Pitfall: Implicit Rule Precedence</strong>\nWithout explicit ordering, rules evaluated in database insertion order or hash map iteration order produce different results across system restarts. Always maintain explicit rule precedence and process rules in consistent order during evaluation.</p>\n<h3 id=\"user-context-and-segmentation\">User Context and Segmentation</h3>\n<p>User context serves as the <strong>aircraft identification and flight characteristics</strong> that enable intelligent routing decisions. Just as air traffic controllers need to know aircraft type, destination, fuel levels, and passenger count to make safe routing decisions, the feature flag system needs comprehensive user attributes to apply targeting rules effectively.</p>\n<p>The challenge in context modeling lies in balancing <strong>flexibility with performance</strong>. User contexts must support arbitrary attributes for complex targeting scenarios, but evaluation latency requirements demand efficient attribute lookup and comparison operations. Additionally, contexts must accommodate both real-time attributes (current location, device type) and slowly-changing attributes (subscription plan, account creation date) without compromising evaluation consistency.</p>\n<blockquote>\n<p><strong>Decision: Flat Attribute Map with Type Inference</strong></p>\n<ul>\n<li><strong>Context</strong>: User contexts need to support arbitrary attributes with different data types, but complex nested structures slow down rule evaluation and serialization</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Strongly-typed context with predefined fields</li>\n<li>Nested JSON object with hierarchical attributes</li>\n<li>Flat map with runtime type inference</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Flat attribute map with interface{} values and runtime type inference</li>\n<li><strong>Rationale</strong>: Flat structure enables fast attribute lookup, interface{} values support all JSON-serializable types, runtime inference handles type coercion for rule operators, and simple structure simplifies SDK integration</li>\n<li><strong>Consequences</strong>: Supports arbitrary attributes without schema constraints and enables efficient evaluation, but requires careful type handling and limits nesting capabilities</li>\n</ul>\n</blockquote>\n<p>The <code>UserContext</code> structure captures all information needed to evaluate targeting rules against a specific user. This context travels with every flag evaluation request and serves as the primary input to the rule matching engine.</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>UserID</td>\n<td>UserID</td>\n<td>Stable user identifier for consistent variant assignment across sessions</td>\n</tr>\n<tr>\n<td>Attributes</td>\n<td>map[string]interface{}</td>\n<td>Key-value pairs representing user characteristics and properties</td>\n</tr>\n<tr>\n<td>Segments</td>\n<td>[]string</td>\n<td>Pre-computed segment memberships for efficient group-based targeting</td>\n</tr>\n<tr>\n<td>RequestContext</td>\n<td>map[string]interface{}</td>\n<td>Request-specific attributes (IP address, user agent, timestamp)</td>\n</tr>\n<tr>\n<td>SessionID</td>\n<td>string</td>\n<td>Session identifier for request grouping and analytics attribution</td>\n</tr>\n<tr>\n<td>AnonymousID</td>\n<td>string</td>\n<td>Anonymous identifier for users without stable UserID</td>\n</tr>\n<tr>\n<td>CustomProperties</td>\n<td>map[string]interface{}</td>\n<td>Application-specific context not fitting standard categories</td>\n</tr>\n</tbody></table>\n<p>The user ID serves as the <strong>aircraft tail number</strong> - a stable, unique identifier that ensures consistent variant assignment through the consistent hashing algorithm. This identifier must remain constant across user sessions and devices to prevent users from receiving different variants as they interact with the system.</p>\n<p>User attributes provide the <strong>flight characteristics and metadata</strong> needed for sophisticated targeting scenarios. These attributes can represent user demographics, subscription details, behavioral data, device information, or any other criteria relevant for feature targeting decisions.</p>\n<p>| Attribute Category | Example Attributes | Typical Use Cases |\n|---|---|---|---|\n| Demographics | age, country, language, timezone | Geographic rollouts, localization features |\n| Subscription | plan, trial_end_date, payment_method | Premium feature access, billing experiments |\n| Behavioral | login_count, last_active, feature_usage | Engagement experiments, onboarding flows |\n| Technical | device_type, browser, app_version | Platform-specific features, compatibility testing |\n| Business | company_size, industry, account_tier | B2B feature targeting, enterprise experiments |</p>\n<p>User segments represent <strong>pre-computed group memberships</strong> that enable efficient targeting of user cohorts without evaluating complex membership criteria on every flag request. Think of segments as <strong>flight categories</strong> (commercial, cargo, emergency) that group aircraft with similar handling requirements.</p>\n<p>Segments provide significant performance advantages over dynamic attribute-based targeting because segment membership is computed asynchronously and cached in the user context. This approach trades some real-time accuracy for substantial evaluation speed improvements, particularly important for high-traffic applications.</p>\n<table>\n<thead>\n<tr>\n<th>Segment Type</th>\n<th>Computation Strategy</th>\n<th>Update Frequency</th>\n<th>Example Segments</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Static Segments</td>\n<td>Manual user assignment</td>\n<td>On-demand updates</td>\n<td>beta_users, internal_team, vip_customers</td>\n</tr>\n<tr>\n<td>Dynamic Segments</td>\n<td>Batch computation from user attributes</td>\n<td>Daily or hourly refresh</td>\n<td>high_engagement, trial_expiring, mobile_users</td>\n</tr>\n<tr>\n<td>Real-time Segments</td>\n<td>Streaming computation from user events</td>\n<td>Continuous updates</td>\n<td>recently_active, shopping_cart_abandoned</td>\n</tr>\n</tbody></table>\n<p>The <code>UserContext</code> also captures request-specific information that affects flag evaluation but doesn&#39;t represent persistent user characteristics. This request context enables targeting based on current conditions rather than historical user properties.</p>\n<p>Request context attributes include information like client IP address for geographic targeting, user agent for device detection, request timestamp for time-based experiments, and feature flags for cross-flag dependencies. These attributes have shorter lifespans than user attributes but play crucial roles in sophisticated targeting scenarios.</p>\n<blockquote>\n<p><strong>Key Design Insight</strong>: The distinction between user attributes and request context is critical for <strong>caching strategy</strong>. User attributes can be cached longer because they change infrequently, while request context must be computed fresh for each evaluation because it represents current conditions.</p>\n</blockquote>\n<p><strong>Context Integration Patterns:</strong></p>\n<p>The user context integrates with the broader system through several key patterns that affect both performance and functionality. Understanding these patterns helps avoid common implementation mistakes and architectural issues.</p>\n<p><strong>Context Enrichment</strong> involves augmenting basic user identification with additional attributes from user databases, analytics systems, or third-party services. This enrichment can happen synchronously during flag evaluation (trading latency for freshness) or asynchronously through background processes (trading freshness for performance).</p>\n<p><strong>Context Caching</strong> stores enriched user contexts to avoid repeated database lookups during flag evaluation. Effective caching strategies must balance memory usage, cache hit rates, and data freshness while handling cache invalidation when user attributes change.</p>\n<p><strong>Context Versioning</strong> addresses the challenge of evolving user schemas without breaking existing flag configurations. As applications add new user attributes or modify existing ones, the flag system must gracefully handle missing attributes and type mismatches in targeting rules.</p>\n<p><strong>Common Context Modeling Pitfalls:</strong></p>\n<p>⚠️ <strong>Pitfall: Missing User ID Fallback Strategy</strong>\nSystems that require stable user IDs for consistent hashing break when evaluating flags for anonymous users or during authentication failures. Always provide anonymous ID generation and graceful degradation when stable identifiers are unavailable.</p>\n<p>⚠️ <strong>Pitfall: Context Attribute Type Confusion</strong>\nStoring numeric values as strings breaks greater-than/less-than operators in targeting rules, while storing strings as numbers breaks substring matching. Implement consistent type inference and validation to prevent rule evaluation errors.</p>\n<p>⚠️ <strong>Pitfall: Overly Large Context Objects</strong>\nIncluding too many attributes or large nested objects in user context increases serialization overhead and network latency. Focus on attributes actually used in targeting rules and consider separate attribute fetching for rarely-used properties.</p>\n<p>⚠️ <strong>Pitfall: Stale Segment Memberships</strong>\nPre-computed segments that update infrequently can cause users to receive inappropriate variants when their characteristics change. Balance segment freshness requirements with computation overhead, and provide manual refresh capabilities for critical segments.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The data model implementation requires careful attention to serialization, validation, and performance characteristics. The following guidance helps translate the conceptual data structures into efficient, maintainable code.</p>\n<p><strong>A. Technology Recommendations:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Data Storage</td>\n<td>SQLite with JSON columns</td>\n<td>PostgreSQL with JSONB indexing</td>\n</tr>\n<tr>\n<td>Serialization</td>\n<td>encoding/json with struct tags</td>\n<td>Protocol Buffers with code generation</td>\n</tr>\n<tr>\n<td>Validation</td>\n<td>Manual field checking</td>\n<td>JSON Schema validation library</td>\n</tr>\n<tr>\n<td>Type Safety</td>\n<td>interface{} with runtime checks</td>\n<td>Generic types with constraints</td>\n</tr>\n</tbody></table>\n<p><strong>B. Recommended File Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>internal/\n  model/\n    flag.go              ← FlagDefinition and related structures\n    context.go           ← UserContext and attribute handling\n    evaluation.go        ← EvaluationResult and response types\n    experiment.go        ← Experiment and analytics structures\n    validation.go        ← Data validation and constraint checking\n    serialization.go     ← JSON marshaling and unmarshaling helpers\n  storage/\n    flag_store.go        ← Flag persistence interface and implementations\n    segment_store.go     ← User segment storage and retrieval</code></pre></div>\n\n<p><strong>C. Infrastructure Starter Code:</strong></p>\n<p>Complete validation framework for ensuring data integrity across all model structures:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> model</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">fmt</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">strings</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ValidationError represents a data model validation failure</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> ValidationError</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Field   </span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Value   </span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Message </span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">e </span><span style=\"color:#B392F0\">ValidationError</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Error</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Sprintf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"validation failed for field </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">: </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, e.Field, e.Message)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ValidationErrors aggregates multiple validation failures</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> ValidationErrors</span><span style=\"color:#E1E4E8\"> []</span><span style=\"color:#B392F0\">ValidationError</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">e </span><span style=\"color:#B392F0\">ValidationErrors</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Error</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#B392F0\"> len</span><span style=\"color:#E1E4E8\">(e) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> \"no validation errors\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    var</span><span style=\"color:#E1E4E8\"> messages []</span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> _, err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> range</span><span style=\"color:#E1E4E8\"> e {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        messages </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> append</span><span style=\"color:#E1E4E8\">(messages, err.</span><span style=\"color:#B392F0\">Error</span><span style=\"color:#E1E4E8\">())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> strings.</span><span style=\"color:#B392F0\">Join</span><span style=\"color:#E1E4E8\">(messages, </span><span style=\"color:#9ECBFF\">\"; \"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">e </span><span style=\"color:#B392F0\">ValidationErrors</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">HasErrors</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#B392F0\"> len</span><span style=\"color:#E1E4E8\">(e) </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ValidateFlag performs comprehensive validation of flag definitions</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> ValidateFlag</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">flag</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">FlagDefinition</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    var</span><span style=\"color:#E1E4E8\"> errors </span><span style=\"color:#B392F0\">ValidationErrors</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Implement validation logic</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ValidateUserContext ensures context structure meets requirements</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> ValidateUserContext</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">UserContext</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    var</span><span style=\"color:#E1E4E8\"> errors </span><span style=\"color:#B392F0\">ValidationErrors</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Implement context validation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p>Complete serialization helpers that handle type conversion and JSON marshaling:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> model</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">encoding/json</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">reflect</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">strconv</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// AttributeValue provides type-safe access to user context attributes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> AttributeValue</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    raw </span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewAttributeValue</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">value</span><span style=\"color:#F97583\"> interface</span><span style=\"color:#E1E4E8\">{}) </span><span style=\"color:#B392F0\">AttributeValue</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#B392F0\"> AttributeValue</span><span style=\"color:#E1E4E8\">{raw: value}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">av </span><span style=\"color:#B392F0\">AttributeValue</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">String</span><span style=\"color:#E1E4E8\">() (</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Implement string conversion with type checking</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">false</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">av </span><span style=\"color:#B392F0\">AttributeValue</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Int</span><span style=\"color:#E1E4E8\">() (</span><span style=\"color:#F97583\">int64</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Implement integer conversion with type checking</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">false</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">av </span><span style=\"color:#B392F0\">AttributeValue</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Float</span><span style=\"color:#E1E4E8\">() (</span><span style=\"color:#F97583\">float64</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Implement float conversion with type checking</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">false</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">av </span><span style=\"color:#B392F0\">AttributeValue</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Bool</span><span style=\"color:#E1E4E8\">() (</span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Implement boolean conversion with type checking</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">false</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">av </span><span style=\"color:#B392F0\">AttributeValue</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">StringSlice</span><span style=\"color:#E1E4E8\">() ([]</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Implement string slice conversion for \"in\" operator</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">false</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>D. Core Logic Skeleton Code:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> model</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ValidateFlag ensures flag definition meets all requirements</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> ValidateFlag</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">flag</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">FlagDefinition</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    var</span><span style=\"color:#E1E4E8\"> errors </span><span style=\"color:#B392F0\">ValidationErrors</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Validate flag key is non-empty and follows naming conventions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Ensure at least one variant is defined and default variant exists</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Validate all targeting rule conditions reference valid operators</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Check percentage allocations sum to 100% in each rule</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Detect circular dependencies in prerequisites</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Verify variant weights are positive integers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Validate attribute names in conditions don't contain reserved characters</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> errors.</span><span style=\"color:#B392F0\">HasErrors</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> errors</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ValidateUserContext checks context structure and attribute types</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> ValidateUserContext</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">UserContext</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    var</span><span style=\"color:#E1E4E8\"> errors </span><span style=\"color:#B392F0\">ValidationErrors</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Ensure either UserID or AnonymousID is present</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Validate attribute values are JSON-serializable types</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Check segment names follow naming conventions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Verify request context doesn't contain oversized values</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Validate session ID format if present</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> errors.</span><span style=\"color:#B392F0\">HasErrors</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> errors</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// DetectCircularDependencies finds cycles in flag prerequisite relationships</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> DetectCircularDependencies</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">flags</span><span style=\"color:#F97583\"> map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#B392F0\">FlagKey</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FlagDefinition</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Build adjacency list representation of prerequisite graph</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Perform depth-first search from each flag node</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Track visited and recursion stack to detect back edges</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Return specific error identifying circular dependency path</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use topological sorting or DFS with color marking</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>E. Language-Specific Hints:</strong></p>\n<ul>\n<li>Use <code>json:&quot;-&quot;</code> struct tags to exclude sensitive fields from JSON serialization</li>\n<li>Implement <code>json.Marshaler</code> and <code>json.Unmarshaler</code> interfaces for custom serialization logic</li>\n<li>Use <code>reflect.TypeOf()</code> carefully for type checking - prefer type assertions when possible</li>\n<li>Store percentage ranges as <code>[start, end)</code> intervals where start is inclusive and end is exclusive</li>\n<li>Use <code>sync.RWMutex</code> for concurrent access to flag definitions if caching in memory</li>\n<li>Consider <code>time.Time.UTC()</code> for consistent timezone handling in timestamps</li>\n</ul>\n<p><strong>F. Milestone Checkpoint:</strong></p>\n<p>After implementing the data model structures:</p>\n<ol>\n<li><strong>Validation Test</strong>: Run <code>go test ./internal/model/...</code> - all validation functions should correctly reject invalid flags and accept valid configurations</li>\n<li><strong>Serialization Test</strong>: Create a complex flag definition, marshal to JSON, unmarshal back, and verify all fields are preserved correctly</li>\n<li><strong>Type Conversion Test</strong>: Create user context with mixed attribute types, verify AttributeValue conversions work for all supported operators</li>\n<li><strong>Dependency Detection</strong>: Create flags with circular prerequisites, verify the detection algorithm identifies the cycle and provides helpful error messages</li>\n</ol>\n<p>Expected behavior after completion:</p>\n<ul>\n<li>Flag definitions serialize to clean JSON suitable for storage and API responses</li>\n<li>User contexts handle missing attributes gracefully during rule evaluation</li>\n<li>Validation catches common configuration errors before flags are stored</li>\n<li>Type conversion supports all comparison operators used in targeting rules</li>\n</ul>\n<p>Signs something is wrong:</p>\n<ul>\n<li>Serialized flags lose information during round-trip JSON conversion</li>\n<li>Validation allows invalid configurations that break evaluation engine</li>\n<li>Type conversion produces inconsistent results for the same input values</li>\n<li>Circular dependency detection has false positives or misses actual cycles</li>\n</ul>\n<h2 id=\"flag-evaluation-engine\">Flag Evaluation Engine</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section covers Milestone 1 (Flag Evaluation Engine) by implementing the core flag evaluation logic with consistent user assignment, complex rule processing, and proper fallback handling.</p>\n</blockquote>\n<p>The flag evaluation engine serves as the heart of the feature flag system, responsible for taking a user context and flag configuration and determining which variant that user should receive. Think of the evaluation engine as a <strong>sophisticated restaurant host</strong> - when a customer (user) arrives, the host considers their reservation details, party size, dietary restrictions, and membership status (user context) against the restaurant&#39;s current seating rules, special promotions, and capacity constraints (flag rules) to determine the best table assignment (variant) while ensuring repeat customers get consistent treatment.</p>\n<p>The evaluation engine must balance several competing requirements: it needs to be extremely fast since it&#39;s called on every feature check, deterministic so users get consistent experiences, flexible enough to support complex targeting rules, and resilient enough to gracefully handle edge cases and partial failures. The architecture prioritizes <strong>evaluation-first design</strong>, meaning every component decision is optimized for the critical path of flag evaluation performance.</p>\n<p><img src=\"/api/project/feature-flags/architecture-doc/asset?path=diagrams%2Fevaluation-flow.svg\" alt=\"Flag Evaluation Sequence\"></p>\n<p>The evaluation process follows a structured decision tree that processes rules in order of precedence, applies consistent hashing for percentage-based rollouts, and provides detailed reasoning for audit and debugging purposes. This deterministic approach ensures that the same user context always produces the same result, which is critical for maintaining consistent user experiences across multiple application instances.</p>\n<h3 id=\"consistent-user-assignment\">Consistent User Assignment</h3>\n<p>Consistent user assignment is the foundation that ensures users receive the same variant across multiple evaluations, even as flag configurations change or the system scales horizontally. Without consistency, users would experience jarring feature flip-flopping as they navigate through an application - imagine if a user&#39;s shopping cart suddenly changed its interface mid-checkout because they triggered a different variant.</p>\n<p>The system achieves consistency through <strong>consistent hashing</strong>, which maps each user to a deterministic position in a virtual &quot;allocation space&quot; that remains stable regardless of when or where the evaluation occurs. Think of this allocation space as a circular dartboard numbered 0 to 99, where each user&#39;s <code>UserID</code> and <code>FlagKey</code> combination determines exactly where their dart lands, and the variant allocations define which sections of the dartboard correspond to which variants.</p>\n<table>\n<thead>\n<tr>\n<th>Hash Function Component</th>\n<th>Purpose</th>\n<th>Example Value</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>UserID</td>\n<td>Stable user identifier ensuring same user gets same position</td>\n<td>&quot;user_12345&quot;</td>\n</tr>\n<tr>\n<td>FlagKey</td>\n<td>Flag-specific salt preventing correlation across flags</td>\n<td>&quot;checkout_redesign&quot;</td>\n</tr>\n<tr>\n<td>Combined Input</td>\n<td>Hash input ensuring flag-specific consistency</td>\n<td>&quot;user_12345:checkout_redesign&quot;</td>\n</tr>\n<tr>\n<td>Hash Algorithm</td>\n<td>CRC32 or SHA256 providing uniform distribution</td>\n<td>CRC32</td>\n</tr>\n<tr>\n<td>Bucket Number</td>\n<td>Final position in 0-99 allocation space</td>\n<td>67</td>\n</tr>\n</tbody></table>\n<p>The <code>calculateUserBucket</code> function transforms a user&#39;s identity into a bucket number between 0 and 99, providing 1% granularity for percentage rollouts. This granularity strikes the optimal balance between precision and performance - finer granularity would provide minimal benefit while consuming more computation and memory.</p>\n<blockquote>\n<p><strong>Design Insight:</strong> Using both <code>UserID</code> and <code>FlagKey</code> in the hash input is crucial because it prevents users from being consistently assigned to the same relative position across all flags. Without the flag-specific salt, a user who falls into the &quot;early adopter&quot; bucket for one flag would fall into early adopter buckets for all flags, creating unwanted correlation effects.</p>\n</blockquote>\n<p><strong>Bucket Range Allocation</strong> determines which bucket ranges correspond to each variant based on the configured weights. For a flag with variants A (weight: 30), B (weight: 20), and C (weight: 50), the system assigns buckets 0-29 to variant A, buckets 30-49 to variant B, and buckets 50-99 to variant C. This approach ensures that percentage changes affect users at the margins rather than causing random reassignments.</p>\n<table>\n<thead>\n<tr>\n<th>Variant</th>\n<th>Weight</th>\n<th>Bucket Range</th>\n<th>Users Affected by 10% Increase</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Control</td>\n<td>50%</td>\n<td>0-49</td>\n<td>New users in buckets 50-59</td>\n</tr>\n<tr>\n<td>Treatment</td>\n<td>40%</td>\n<td>50-89</td>\n<td>New users in buckets 90-99</td>\n</tr>\n<tr>\n<td>Holdout</td>\n<td>10%</td>\n<td>90-99</td>\n<td>Users in buckets 90-99 reassigned</td>\n</tr>\n</tbody></table>\n<p>The allocation algorithm processes variant weights in declaration order, ensuring deterministic bucket assignments even when weights don&#39;t sum to exactly 100%. If weights sum to less than 100%, the remaining users receive the flag&#39;s default value. If weights exceed 100%, the system normalizes proportionally and logs a warning for operational visibility.</p>\n<blockquote>\n<p><strong>Critical Stability Property:</strong> Once a user receives a variant assignment, they must continue receiving that assignment until explicitly moved through configuration changes. The consistent hashing approach guarantees this stability by ensuring the hash function remains deterministic across evaluations, even as the application restarts or scales.</p>\n</blockquote>\n<p>The system handles several edge cases to maintain assignment stability:</p>\n<ol>\n<li><strong>Zero-weight variants</strong> remain in the configuration but receive no bucket allocation, allowing for quick re-enablement without reassignment</li>\n<li><strong>Weight normalization</strong> proportionally adjusts weights that exceed 100% while preserving relative ratios</li>\n<li><strong>Default fallback</strong> handles users whose buckets fall outside allocated ranges due to configuration errors</li>\n</ol>\n<h3 id=\"rule-evaluation-logic\">Rule Evaluation Logic</h3>\n<p>The rule evaluation logic implements a sophisticated decision tree that processes targeting rules in strict precedence order, ensuring deterministic outcomes when multiple rules could potentially match a user. Think of rule evaluation as a <strong>courthouse with multiple judges</strong> - cases (user evaluations) are presented to judges (targeting rules) in order of seniority, and the first judge who claims jurisdiction (matching conditions) renders the final verdict (variant assignment).</p>\n<p><img src=\"/api/project/feature-flags/architecture-doc/asset?path=diagrams%2Fevaluation-algorithm.svg\" alt=\"Rule Evaluation Algorithm\"></p>\n<p>The evaluation algorithm follows a waterfall approach with four distinct phases, each with specific responsibilities and fallback behavior:</p>\n<table>\n<thead>\n<tr>\n<th>Evaluation Phase</th>\n<th>Purpose</th>\n<th>Input Requirements</th>\n<th>Success Criteria</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Targeting Rules</td>\n<td>User-specific overrides</td>\n<td>UserContext with attributes</td>\n<td>All rule conditions evaluate to true</td>\n</tr>\n<tr>\n<td>Percentage Rules</td>\n<td>Gradual rollout control</td>\n<td>UserID for consistent hashing</td>\n<td>User bucket falls within variant range</td>\n</tr>\n<tr>\n<td>Default Value</td>\n<td>Configuration fallback</td>\n<td>Flag definition</td>\n<td>Default value exists</td>\n</tr>\n<tr>\n<td>System Fallback</td>\n<td>Emergency degradation</td>\n<td>None</td>\n<td>Always succeeds with false/null</td>\n</tr>\n</tbody></table>\n<p><strong>Targeting Rule Processing</strong> begins with the highest-priority rule and evaluates each rule&#39;s conditions against the provided user context. Each <code>TargetingRule</code> contains a collection of <code>Condition</code> objects combined with either <code>AND</code> or <code>OR</code> logic, allowing for sophisticated user segmentation based on multiple attributes.</p>\n<p>The <code>evaluateRuleConditions</code> function processes each condition within a rule, applying the specified logical operator to determine overall rule satisfaction. For <code>AND</code> operations, all conditions must evaluate to true; for <code>OR</code> operations, any single condition can satisfy the rule. This flexibility enables complex targeting scenarios like &quot;show premium features to users in the US OR Canada AND with subscription tier gold OR platinum&quot;.</p>\n<table>\n<thead>\n<tr>\n<th>Condition Operator</th>\n<th>Purpose</th>\n<th>Example Usage</th>\n<th>Type Requirements</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>equals</td>\n<td>Exact match comparison</td>\n<td>country equals &quot;US&quot;</td>\n<td>String, number, boolean</td>\n</tr>\n<tr>\n<td>in</td>\n<td>Array membership testing</td>\n<td>user_id in [&quot;admin1&quot;, &quot;admin2&quot;]</td>\n<td>Any type with array</td>\n</tr>\n<tr>\n<td>contains</td>\n<td>Substring matching</td>\n<td>email contains &quot;@company.com&quot;</td>\n<td>String values only</td>\n</tr>\n<tr>\n<td>greater_than</td>\n<td>Numeric comparison</td>\n<td>account_age greater_than 30</td>\n<td>Numeric values only</td>\n</tr>\n<tr>\n<td>less_than</td>\n<td>Numeric comparison</td>\n<td>session_count less_than 5</td>\n<td>Numeric values only</td>\n</tr>\n</tbody></table>\n<p>The <code>AttributeValue</code> wrapper provides type-safe access to user context attributes while handling the common problem of dynamic typing in user data. Each attribute access method returns both the converted value and a boolean indicating whether the conversion succeeded, allowing the evaluation logic to gracefully handle type mismatches without panicking.</p>\n<p><strong>Rule Precedence and Ordering</strong> ensures deterministic evaluation when multiple rules could match the same user. Rules are processed in declaration order within the flag definition, with the first matching rule taking precedence. This approach provides predictable behavior and allows flag administrators to structure rules from specific to general, similar to firewall rule processing.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Rule Evaluation Example:\n1. IF user_id in [&quot;beta_user_1&quot;, &quot;beta_user_2&quot;] THEN variant=&quot;beta&quot;\n2. IF country equals &quot;US&quot; AND subscription=&quot;premium&quot; THEN variant=&quot;premium_us&quot; \n3. IF country equals &quot;US&quot; THEN variant=&quot;standard_us&quot;\n4. PERCENTAGE ROLLOUT: 20% get variant=&quot;treatment&quot;, 80% get variant=&quot;control&quot;</code></pre></div>\n\n<p>In this example, beta users always receive the beta variant regardless of location or subscription status, premium US users receive premium_us unless they&#39;re beta users, and other US users receive standard_us. Only users who don&#39;t match any targeting rule enter the percentage rollout phase.</p>\n<p><strong>Percentage Rule Evaluation</strong> activates when no targeting rules match the user context. The system calculates the user&#39;s bucket using consistent hashing and determines which variant allocation range contains that bucket. This phase implements gradual rollouts and A/B testing by assigning users to variants based on stable, pseudorandom distribution.</p>\n<p>The <code>PercentageRule</code> defines variant allocations as a list of <code>VariantAllocation</code> objects, each specifying a variant key and weight. The evaluation engine converts weights into cumulative bucket ranges, ensuring efficient lookup during evaluation.</p>\n<table>\n<thead>\n<tr>\n<th>Variant Allocation</th>\n<th>Weight</th>\n<th>Cumulative Weight</th>\n<th>Bucket Range</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>control</td>\n<td>60</td>\n<td>60</td>\n<td>0-59</td>\n</tr>\n<tr>\n<td>treatment_a</td>\n<td>25</td>\n<td>85</td>\n<td>60-84</td>\n</tr>\n<tr>\n<td>treatment_b</td>\n<td>15</td>\n<td>100</td>\n<td>85-99</td>\n</tr>\n</tbody></table>\n<p><strong>Default Value Fallback</strong> provides the safety net when both targeting rules and percentage rules fail to assign a variant. This situation occurs when targeting rules don&#39;t match and percentage rules have zero total weight or the user&#39;s bucket falls outside allocated ranges due to configuration errors.</p>\n<p>The <code>EvaluationResult</code> includes a detailed <code>Reason</code> field that traces the evaluation path, enabling debugging and audit capabilities. Reason codes follow a structured format that indicates which evaluation phase produced the result and why.</p>\n<table>\n<thead>\n<tr>\n<th>Reason Code</th>\n<th>Evaluation Path</th>\n<th>Example Scenario</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>targeting_rule_match</td>\n<td>Targeting rule satisfied</td>\n<td>&quot;targeting_rule_match:rule_2&quot;</td>\n</tr>\n<tr>\n<td>percentage_rollout</td>\n<td>Percentage allocation</td>\n<td>&quot;percentage_rollout:treatment_20pct&quot;</td>\n</tr>\n<tr>\n<td>default_value</td>\n<td>Fallback to default</td>\n<td>&quot;default_value:no_rules_matched&quot;</td>\n</tr>\n<tr>\n<td>flag_not_found</td>\n<td>Missing flag definition</td>\n<td>&quot;flag_not_found:invalid_key&quot;</td>\n</tr>\n<tr>\n<td>evaluation_error</td>\n<td>Processing failure</td>\n<td>&quot;evaluation_error:invalid_context&quot;</td>\n</tr>\n</tbody></table>\n<h3 id=\"architecture-decision-records\">Architecture Decision Records</h3>\n<p>The flag evaluation engine embodies several critical architectural decisions that fundamentally shape system behavior, performance, and maintainability. Each decision represents a careful trade-off between competing requirements and establishes constraints that influence the entire system design.</p>\n<blockquote>\n<p><strong>Decision: Consistent Hashing Algorithm Selection</strong></p>\n<ul>\n<li><strong>Context</strong>: Users must receive consistent variant assignments across evaluations, but the hashing algorithm must balance performance, distribution quality, and collision resistance for production workloads.</li>\n<li><strong>Options Considered</strong>: CRC32 for speed, SHA256 for cryptographic strength, MD5 for legacy compatibility</li>\n<li><strong>Decision</strong>: CRC32 as the primary algorithm with SHA256 as a configurable alternative</li>\n<li><strong>Rationale</strong>: CRC32 provides excellent distribution uniformity and high performance for non-adversarial inputs, while SHA256 offers cryptographic strength for compliance-sensitive environments at the cost of 3-4x slower computation</li>\n<li><strong>Consequences</strong>: Enables sub-microsecond evaluation performance while maintaining uniform user distribution, but requires SHA256 fallback for environments with strict cryptographic requirements</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Hash Algorithm</th>\n<th>Performance</th>\n<th>Distribution Quality</th>\n<th>Collision Resistance</th>\n<th>Chosen</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>CRC32</td>\n<td>Excellent (ns)</td>\n<td>Uniform for random inputs</td>\n<td>Weak against adversaries</td>\n<td>Primary</td>\n</tr>\n<tr>\n<td>SHA256</td>\n<td>Good (μs)</td>\n<td>Cryptographically uniform</td>\n<td>Strong against adversaries</td>\n<td>Optional</td>\n</tr>\n<tr>\n<td>MD5</td>\n<td>Very Good (ns)</td>\n<td>Good but deprecated</td>\n<td>Weak against adversaries</td>\n<td>No</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Rule Evaluation Precedence Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Multiple targeting rules may match the same user, requiring a deterministic resolution strategy that balances flexibility with predictability.</li>\n<li><strong>Options Considered</strong>: Priority scoring system, first-match-wins ordering, most-specific-rule-wins analysis</li>\n<li><strong>Decision</strong>: First-match-wins with declaration order precedence</li>\n<li><strong>Rationale</strong>: Declaration order provides intuitive, predictable behavior that mirrors firewall rules and allows administrators to structure rules from specific to general without complex priority calculations</li>\n<li><strong>Consequences</strong>: Simplifies rule authoring and debugging at the cost of requiring careful rule ordering, with no automatic optimization of rule evaluation sequence</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Precedence Strategy</th>\n<th>Complexity</th>\n<th>Predictability</th>\n<th>Performance</th>\n<th>Chosen</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Declaration Order</td>\n<td>Low</td>\n<td>High</td>\n<td>Excellent</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>Priority Scoring</td>\n<td>Medium</td>\n<td>Medium</td>\n<td>Good</td>\n<td>No</td>\n</tr>\n<tr>\n<td>Most Specific</td>\n<td>High</td>\n<td>Low</td>\n<td>Poor</td>\n<td>No</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: User Context Attribute Type System</strong></p>\n<ul>\n<li><strong>Context</strong>: User attributes arrive as untyped JSON values but must support type-safe comparison operations across different programming languages and data sources.</li>\n<li><strong>Options Considered</strong>: Dynamic typing with runtime coercion, strict typing with validation, hybrid approach with type-safe wrappers</li>\n<li><strong>Decision</strong>: Hybrid approach using <code>AttributeValue</code> wrapper with explicit type conversion methods</li>\n<li><strong>Rationale</strong>: Provides type safety during evaluation while accepting flexible input formats, preventing runtime panics from type mismatches and enabling graceful degradation when attributes don&#39;t match expected types</li>\n<li><strong>Consequences</strong>: Adds wrapper overhead and API complexity but eliminates a major class of runtime evaluation failures and provides clear error reporting for type mismatches</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Type System</th>\n<th>Safety</th>\n<th>Flexibility</th>\n<th>Performance</th>\n<th>Chosen</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Dynamic</td>\n<td>Low</td>\n<td>High</td>\n<td>Excellent</td>\n<td>No</td>\n</tr>\n<tr>\n<td>Strict</td>\n<td>High</td>\n<td>Low</td>\n<td>Good</td>\n<td>No</td>\n</tr>\n<tr>\n<td>Hybrid Wrapper</td>\n<td>High</td>\n<td>Medium</td>\n<td>Good</td>\n<td>Yes</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Evaluation Result Caching Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Flag evaluations may be called hundreds of times per request, but user context and flag definitions change infrequently, creating opportunities for performance optimization through caching.</li>\n<li><strong>Options Considered</strong>: No caching for simplicity, request-scoped caching, time-based TTL caching</li>\n<li><strong>Decision</strong>: Optional request-scoped caching with explicit cache invalidation</li>\n<li><strong>Rationale</strong>: Request-scoped caching eliminates redundant evaluations within a single request while avoiding stale data issues across requests, providing significant performance benefits for evaluation-heavy code paths</li>\n<li><strong>Consequences</strong>: Enables 10-100x performance improvement for repeated evaluations but requires careful integration with request lifecycle management and adds complexity to multi-threaded environments</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Caching Strategy</th>\n<th>Performance Gain</th>\n<th>Consistency Risk</th>\n<th>Implementation Complexity</th>\n<th>Chosen</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>No Caching</td>\n<td>None</td>\n<td>None</td>\n<td>Minimal</td>\n<td>No</td>\n</tr>\n<tr>\n<td>Request-Scoped</td>\n<td>High (10-100x)</td>\n<td>Low</td>\n<td>Medium</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>TTL-Based</td>\n<td>Very High</td>\n<td>High</td>\n<td>High</td>\n<td>No</td>\n</tr>\n</tbody></table>\n<p><strong>Common Pitfalls in Evaluation Engine Implementation</strong></p>\n<p>⚠️ <strong>Pitfall: Inconsistent Hash Input Formatting</strong>\nThe most subtle and dangerous mistake involves inconsistent string formatting when constructing hash inputs. Using <code>fmt.Sprintf(&quot;%s:%s&quot;, userID, flagKey)</code> versus <code>userID + &quot;:&quot; + flagKey</code> can produce different results if format specifiers behave unexpectedly with special characters. Always use explicit string concatenation or a standardized formatting function with thorough unit tests covering edge cases like empty strings, unicode characters, and values containing the separator character.</p>\n<p>⚠️ <strong>Pitfall: Floating Point Percentage Calculations</strong>\nUsing floating-point arithmetic for percentage calculations introduces rounding errors that can cause users to &quot;fall through the cracks&quot; or be double-assigned. For example, three variants with 33.33% each don&#39;t sum to exactly 100%, leaving some bucket ranges unassigned. Always use integer arithmetic with bucket ranges (0-99 for 1% granularity) and handle remainder allocation explicitly rather than relying on floating-point precision.</p>\n<p>⚠️ <strong>Pitfall: Rule Condition Short-Circuiting Bugs</strong>\nWhen implementing <code>AND</code> and <code>OR</code> logic for rule conditions, developers often implement short-circuiting incorrectly, causing later conditions to be skipped even when they have side effects like logging or metrics collection. Ensure that all conditions are evaluated for observability purposes, or clearly document when short-circuiting behavior is intentional versus when complete evaluation is required.</p>\n<p>⚠️ <strong>Pitfall: Missing User Context Validation</strong>\nFailing to validate user context structure before evaluation can cause panic conditions when accessing nested attributes or applying type conversions. The evaluation engine must gracefully handle missing attributes, null values, and type mismatches by returning sensible defaults rather than failing the entire evaluation. Implement comprehensive input validation with detailed error logging for debugging purposes.</p>\n<p>⚠️ <strong>Pitfall: Circular Dependency Detection</strong>\nWhen flags support prerequisites (flag A depends on flag B being enabled), developers often forget to detect circular dependencies during flag creation or updates. A circular dependency can cause infinite recursion during evaluation, crashing the service. Implement dependency graph validation using depth-first search cycle detection before allowing flag modifications to be persisted.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The flag evaluation engine requires careful attention to performance and correctness, as it sits in the critical path of every feature flag check. The implementation balances sophisticated rule processing capabilities with sub-millisecond evaluation performance.</p>\n<p><strong>Technology Recommendations:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Hash Function</td>\n<td>crypto/sha256 (built-in)</td>\n<td>github.com/spaolacci/murmur3 (faster)</td>\n</tr>\n<tr>\n<td>JSON Parsing</td>\n<td>encoding/json (built-in)</td>\n<td>github.com/json-iterator/go (faster)</td>\n</tr>\n<tr>\n<td>Validation</td>\n<td>Manual checks</td>\n<td>github.com/go-playground/validator</td>\n</tr>\n<tr>\n<td>Logging</td>\n<td>log package (built-in)</td>\n<td>github.com/sirupsen/logrus (structured)</td>\n</tr>\n<tr>\n<td>Testing</td>\n<td>testing package (built-in)</td>\n<td>github.com/stretchr/testify (assertions)</td>\n</tr>\n</tbody></table>\n<p><strong>Recommended File Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>internal/evaluation/\n  engine.go                 ← Main evaluation logic and EvaluateFlag function\n  engine_test.go           ← Comprehensive evaluation test cases  \n  hashing.go              ← Consistent hashing implementation\n  hashing_test.go         ← Hash distribution and stability tests\n  rules.go                ← Rule and condition evaluation logic\n  rules_test.go           ← Rule precedence and condition tests\n  types.go                ← Core data structures and validation\n  validation.go           ← Input validation and error handling\n  validation_test.go      ← Validation edge case tests</code></pre></div>\n\n<p><strong>Core Data Structures (Complete Implementation):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> evaluation</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">crypto/sha256</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">encoding/json</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">fmt</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">hash/crc32</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">strconv</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">strings</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Core evaluation types with complete field definitions</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> FlagKey</span><span style=\"color:#F97583\"> string</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> UserID</span><span style=\"color:#F97583\"> string</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Variant represents a single flag variation with its configuration</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> Variant</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Key    </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"key\"`</span><span style=\"color:#6A737D\">    // Unique variant identifier</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Value  </span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{} </span><span style=\"color:#9ECBFF\">`json:\"value\"`</span><span style=\"color:#6A737D\">  // The actual value returned to client</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Weight </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">         `json:\"weight\"`</span><span style=\"color:#6A737D\"> // Allocation weight for percentage rollouts</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// UserContext provides all user information needed for targeting decisions</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> UserContext</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    UserID     </span><span style=\"color:#B392F0\">UserID</span><span style=\"color:#9ECBFF\">                 `json:\"user_id\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Attributes </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{} </span><span style=\"color:#9ECBFF\">`json:\"attributes\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Segments   []</span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">              `json:\"segments\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// EvaluationResult contains the complete output of flag evaluation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> EvaluationResult</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    FlagKey </span><span style=\"color:#B392F0\">FlagKey</span><span style=\"color:#9ECBFF\">     `json:\"flag_key\"`</span><span style=\"color:#6A737D\"> // Which flag was evaluated</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Value   </span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{} </span><span style=\"color:#9ECBFF\">`json:\"value\"`</span><span style=\"color:#6A737D\">    // The resolved variant value</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Variant </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"variant\"`</span><span style=\"color:#6A737D\">  // The variant key that was selected</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Reason  </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"reason\"`</span><span style=\"color:#6A737D\">   // Why this variant was chosen</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Source  </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"source\"`</span><span style=\"color:#6A737D\">   // Where the flag definition came from</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Complete flag configuration structure</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> FlagDefinition</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Key             </span><span style=\"color:#B392F0\">FlagKey</span><span style=\"color:#9ECBFF\">          `json:\"key\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Enabled         </span><span style=\"color:#F97583\">bool</span><span style=\"color:#9ECBFF\">             `json:\"enabled\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    DefaultVariant  </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">           `json:\"default_variant\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Variants        []</span><span style=\"color:#B392F0\">Variant</span><span style=\"color:#9ECBFF\">        `json:\"variants\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    TargetingRules  []</span><span style=\"color:#B392F0\">TargetingRule</span><span style=\"color:#9ECBFF\">  `json:\"targeting_rules\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PercentageRules </span><span style=\"color:#B392F0\">PercentageRule</span><span style=\"color:#9ECBFF\">   `json:\"percentage_rules\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Prerequisites   []</span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">         `json:\"prerequisites\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Rule structures for complex targeting</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> TargetingRule</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Conditions []</span><span style=\"color:#B392F0\">Condition</span><span style=\"color:#9ECBFF\"> `json:\"conditions\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Operator   </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"operator\"`</span><span style=\"color:#6A737D\"> // \"AND\" or \"OR\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Variant    </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"variant\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Enabled    </span><span style=\"color:#F97583\">bool</span><span style=\"color:#9ECBFF\">        `json:\"enabled\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> Condition</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Attribute </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"attribute\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Operator  </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"operator\"`</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Value     </span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{} </span><span style=\"color:#9ECBFF\">`json:\"value\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> PercentageRule</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Variants []</span><span style=\"color:#B392F0\">VariantAllocation</span><span style=\"color:#9ECBFF\"> `json:\"variants\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> VariantAllocation</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Variant </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\"> `json:\"variant\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Weight  </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">    `json:\"weight\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Type-safe attribute access wrapper</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> AttributeValue</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    value </span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewAttributeValue</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">value</span><span style=\"color:#F97583\"> interface</span><span style=\"color:#E1E4E8\">{}) </span><span style=\"color:#B392F0\">AttributeValue</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#B392F0\"> AttributeValue</span><span style=\"color:#E1E4E8\">{value: value}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">av </span><span style=\"color:#B392F0\">AttributeValue</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">String</span><span style=\"color:#E1E4E8\">() (</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> str, ok </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> av.value.(</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">); ok {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> str, </span><span style=\"color:#79B8FF\">true</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">false</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">av </span><span style=\"color:#B392F0\">AttributeValue</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Int</span><span style=\"color:#E1E4E8\">() (</span><span style=\"color:#F97583\">int64</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    switch</span><span style=\"color:#E1E4E8\"> v </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> av.value.(</span><span style=\"color:#F97583\">type</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    case</span><span style=\"color:#F97583\"> int64</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> v, </span><span style=\"color:#79B8FF\">true</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    case</span><span style=\"color:#F97583\"> float64</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> int64</span><span style=\"color:#E1E4E8\">(v), </span><span style=\"color:#79B8FF\">true</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    case</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> i, err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> strconv.</span><span style=\"color:#B392F0\">ParseInt</span><span style=\"color:#E1E4E8\">(v, </span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">64</span><span style=\"color:#E1E4E8\">); err </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> i, </span><span style=\"color:#79B8FF\">true</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">false</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">av </span><span style=\"color:#B392F0\">AttributeValue</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Float</span><span style=\"color:#E1E4E8\">() (</span><span style=\"color:#F97583\">float64</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    switch</span><span style=\"color:#E1E4E8\"> v </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> av.value.(</span><span style=\"color:#F97583\">type</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    case</span><span style=\"color:#F97583\"> float64</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> v, </span><span style=\"color:#79B8FF\">true</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    case</span><span style=\"color:#F97583\"> int64</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> float64</span><span style=\"color:#E1E4E8\">(v), </span><span style=\"color:#79B8FF\">true</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    case</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> f, err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> strconv.</span><span style=\"color:#B392F0\">ParseFloat</span><span style=\"color:#E1E4E8\">(v, </span><span style=\"color:#79B8FF\">64</span><span style=\"color:#E1E4E8\">); err </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> f, </span><span style=\"color:#79B8FF\">true</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">false</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">av </span><span style=\"color:#B392F0\">AttributeValue</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Bool</span><span style=\"color:#E1E4E8\">() (</span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> b, ok </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> av.value.(</span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\">); ok {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> b, </span><span style=\"color:#79B8FF\">true</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">false</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">av </span><span style=\"color:#B392F0\">AttributeValue</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">StringSlice</span><span style=\"color:#E1E4E8\">() ([]</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> slice, ok </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> av.value.([]</span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{}); ok {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        result </span><span style=\"color:#F97583\">:=</span><span style=\"color:#B392F0\"> make</span><span style=\"color:#E1E4E8\">([]</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#B392F0\">len</span><span style=\"color:#E1E4E8\">(slice))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> i, item </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> range</span><span style=\"color:#E1E4E8\"> slice {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> str, ok </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> item.(</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">); ok {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                result[i] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            } </span><span style=\"color:#F97583\">else</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">false</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> result, </span><span style=\"color:#79B8FF\">true</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">false</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Validation and error types</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> ValidationError</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Field   </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\"> `json:\"field\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Message </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\"> `json:\"message\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">ve </span><span style=\"color:#B392F0\">ValidationError</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Error</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Sprintf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">: </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, ve.Field, ve.Message)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> ValidationErrors</span><span style=\"color:#E1E4E8\"> []</span><span style=\"color:#B392F0\">ValidationError</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">ve </span><span style=\"color:#B392F0\">ValidationErrors</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Error</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    var</span><span style=\"color:#E1E4E8\"> messages []</span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> _, err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> range</span><span style=\"color:#E1E4E8\"> ve {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        messages </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> append</span><span style=\"color:#E1E4E8\">(messages, err.</span><span style=\"color:#B392F0\">Error</span><span style=\"color:#E1E4E8\">())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> strings.</span><span style=\"color:#B392F0\">Join</span><span style=\"color:#E1E4E8\">(messages, </span><span style=\"color:#9ECBFF\">\"; \"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Constants for operators and values</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">const</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Logical operators</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    AND</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"AND\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    OR</span><span style=\"color:#F97583\">  =</span><span style=\"color:#9ECBFF\"> \"OR\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Condition operators  </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    equals</span><span style=\"color:#F97583\">       =</span><span style=\"color:#9ECBFF\"> \"equals\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    in</span><span style=\"color:#F97583\">          =</span><span style=\"color:#9ECBFF\"> \"in\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    contains</span><span style=\"color:#F97583\">    =</span><span style=\"color:#9ECBFF\"> \"contains\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    greater_than</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"greater_than\"</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    less_than</span><span style=\"color:#F97583\">   =</span><span style=\"color:#9ECBFF\"> \"less_than\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p><strong>Consistent Hashing Implementation (Complete):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// calculateUserBucket determines user's allocation bucket using consistent hashing</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> calculateUserBucket</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">userID</span><span style=\"color:#B392F0\"> UserID</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">flagKey</span><span style=\"color:#B392F0\"> FlagKey</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Create hash input by combining userID and flagKey with separator</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Compute hash using CRC32 or SHA256 based on configuration  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Convert hash to bucket number in range [0, 99]</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Return bucket ensuring same input always produces same bucket</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use fmt.Sprintf(\"%s:%s\", userID, flagKey) for consistent input format</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use hash % 100 to get bucket, but handle negative values correctly</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Helper function for creating deterministic hash inputs</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> createHashInput</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">userID</span><span style=\"color:#B392F0\"> UserID</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">flagKey</span><span style=\"color:#B392F0\"> FlagKey</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Sprintf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">:</span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">(userID), </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">(flagKey))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Hash function that provides uniform distribution</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> hashToBucket</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">input</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    hasher </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> crc32.</span><span style=\"color:#B392F0\">NewIEEE</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    hasher.</span><span style=\"color:#B392F0\">Write</span><span style=\"color:#E1E4E8\">([]</span><span style=\"color:#F97583\">byte</span><span style=\"color:#E1E4E8\">(input))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    hashValue </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> hasher.</span><span style=\"color:#B392F0\">Sum32</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\">(hashValue </span><span style=\"color:#F97583\">%</span><span style=\"color:#79B8FF\"> 100</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Core Evaluation Engine Skeleton:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// EvaluateFlag performs complete flag evaluation with targeting and fallback</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> EvaluateFlag</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">flagKey</span><span style=\"color:#B392F0\"> FlagKey</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">context</span><span style=\"color:#B392F0\"> UserContext</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">EvaluationResult</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Validate input parameters (flagKey not empty, context has UserID)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Retrieve flag definition, return error result if not found</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Check if flag is enabled, return default if disabled</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Process targeting rules in order, return first match</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: If no targeting rules match, evaluate percentage rules</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: If no percentage allocation, return default variant</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Construct EvaluationResult with value, variant, and reason</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use early returns for error cases to avoid deep nesting</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Always populate the Reason field for debugging</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// evaluateTargetingRules processes user-specific override rules</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> evaluateTargetingRules</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">rules</span><span style=\"color:#E1E4E8\"> []</span><span style=\"color:#B392F0\">TargetingRule</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">context</span><span style=\"color:#B392F0\"> UserContext</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{}, </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Iterate through rules in declaration order</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Skip disabled rules  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Evaluate rule conditions using specified operator (AND/OR)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Return variant info for first matching rule</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Return false if no rules match</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Call evaluateRuleConditions for each rule</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Short-circuit AND on first false, OR on first true</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// evaluateRuleConditions checks if user context satisfies rule conditions  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> evaluateRuleConditions</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">conditions</span><span style=\"color:#E1E4E8\"> []</span><span style=\"color:#B392F0\">Condition</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">operator</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">context</span><span style=\"color:#B392F0\"> UserContext</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Handle empty conditions list (should return true)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: For AND operator, all conditions must be true</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: For OR operator, any condition can be true  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Evaluate each condition using evaluateCondition helper</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Apply short-circuiting logic for performance</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use a loop with early return for short-circuiting</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Default to false for unknown operators</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// evaluateCondition checks single attribute condition</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> evaluateCondition</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">condition</span><span style=\"color:#B392F0\"> Condition</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">context</span><span style=\"color:#B392F0\"> UserContext</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Extract attribute value from context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Handle missing attributes gracefully (return false)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Apply condition operator (equals, in, contains, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Use AttributeValue wrapper for type-safe comparisons</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Return comparison result</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use NewAttributeValue(context.Attributes[condition.Attribute])</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Each operator has different type requirements</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Milestone Checkpoint:</strong>\nAfter implementing the evaluation engine, you should be able to:</p>\n<ol>\n<li><strong>Run unit tests</strong>: <code>go test ./internal/evaluation/...</code> should show all tests passing</li>\n<li><strong>Test basic evaluation</strong>: Create a simple flag with percentage rollout, verify users get consistent assignments</li>\n<li><strong>Test targeting rules</strong>: Create rules with different operators, verify correct matching behavior  </li>\n<li><strong>Test hash distribution</strong>: Generate 1000 user evaluations, verify roughly even distribution across variants</li>\n<li><strong>Test edge cases</strong>: Verify graceful handling of missing flags, invalid context, malformed rules</li>\n</ol>\n<p><strong>Expected behavior:</strong></p>\n<ul>\n<li>Same user + flag always returns same variant (consistency test)</li>\n<li>Rule precedence works correctly (first matching rule wins)</li>\n<li>Percentage rollouts distribute users evenly across variants  </li>\n<li>Missing attributes cause conditions to fail gracefully</li>\n<li>Detailed reason codes explain evaluation decisions</li>\n</ul>\n<p><strong>Common debugging steps:</strong></p>\n<ul>\n<li>Check hash input format if users get inconsistent assignments</li>\n<li>Verify rule order if wrong targeting rules match</li>\n<li>Examine bucket calculations if percentage distributions look wrong</li>\n<li>Review attribute types if conditions evaluate unexpectedly</li>\n</ul>\n<h2 id=\"real-time-flag-updates\">Real-time Flag Updates</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section covers Milestone 2 (Real-time Flag Updates) by implementing streaming protocols for instant flag propagation, connection management with automatic recovery, and intelligent caching strategies to ensure consistent flag state across all client SDKs.</p>\n</blockquote>\n<p>Real-time flag updates transform a feature flag system from a static configuration tool into a dynamic control plane for live applications. Think of this system as a <strong>broadcast network for air traffic control</strong> — when weather conditions change or new safety protocols are established, every pilot needs to receive these updates instantly and reliably. Similarly, when a feature flag is modified to disable a problematic feature or adjust a rollout percentage, all connected applications must receive this change within seconds to maintain consistent user experiences and operational safety.</p>\n<p>The challenge lies in maintaining reliable, low-latency communication with potentially thousands of client SDKs while handling network interruptions, connection failures, and varying client capabilities. Unlike traditional request-response APIs, real-time updates require persistent connections, careful state management, and sophisticated fallback strategies to ensure flags remain available even during infrastructure failures.</p>\n<p>This system must balance several competing requirements: minimizing latency for critical flag changes, avoiding overwhelming the infrastructure during mass reconnections, ensuring eventual consistency across all clients, and providing graceful degradation when real-time updates are unavailable. The architecture decisions we make here directly impact both the reliability of feature rollouts and the operational overhead of maintaining the flag system.</p>\n<h3 id=\"streaming-protocol-design\">Streaming Protocol Design</h3>\n<p>Modern feature flag systems require sub-second flag propagation to support rapid incident response and real-time experimentation. The choice of streaming protocol fundamentally shapes the system&#39;s scalability, reliability, and operational characteristics. This decision affects everything from server resource usage to client SDK complexity and failure recovery strategies.</p>\n<p><strong>Mental Model: Television Broadcasting vs. Telephone Networks</strong></p>\n<p>Think of streaming protocols as the difference between television broadcasting and telephone networks. Server-Sent Events (SSE) work like television broadcasts — the server transmits updates to all connected clients simultaneously through a one-way channel, with clients passively receiving updates. WebSockets function like telephone networks, establishing bidirectional communication channels where both parties can initiate conversations. For feature flags, we typically need the broadcasting model since flag changes flow primarily from server to clients, but the choice impacts connection management, resource usage, and failure scenarios.</p>\n<blockquote>\n<p><strong>Decision: Server-Sent Events for Flag Updates</strong></p>\n<ul>\n<li><strong>Context</strong>: Feature flag systems need efficient one-way communication from server to multiple clients with standard HTTP infrastructure compatibility and simple client implementation.</li>\n<li><strong>Options Considered</strong>: Server-Sent Events (SSE), WebSockets, HTTP Long Polling</li>\n<li><strong>Decision</strong>: Server-Sent Events (SSE) as the primary streaming protocol with HTTP polling fallback</li>\n<li><strong>Rationale</strong>: SSE provides automatic reconnection, works through HTTP proxies and load balancers, has lower server resource overhead than WebSockets for one-way communication, and offers built-in event ordering and message replay. WebSockets add unnecessary bidirectional complexity for predominantly unidirectional flag updates.</li>\n<li><strong>Consequences</strong>: Enables simple client implementation with browser compatibility, reduces server connection overhead, but limits real-time client feedback and requires polling fallback for SSE-incompatible environments.</li>\n</ul>\n</blockquote>\n<p>The following table compares streaming protocol options for feature flag updates:</p>\n<table>\n<thead>\n<tr>\n<th>Protocol Option</th>\n<th>Latency</th>\n<th>Resource Usage</th>\n<th>HTTP Compatibility</th>\n<th>Complexity</th>\n<th>Reconnection</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Server-Sent Events</strong></td>\n<td>100-500ms</td>\n<td>Low memory/CPU</td>\n<td>Full proxy support</td>\n<td>Simple client</td>\n<td>Automatic with Last-Event-ID</td>\n</tr>\n<tr>\n<td>WebSockets</td>\n<td>50-100ms</td>\n<td>Higher memory</td>\n<td>Proxy configuration required</td>\n<td>Complex handshake</td>\n<td>Manual reconnection logic</td>\n</tr>\n<tr>\n<td>HTTP Long Polling</td>\n<td>200-1000ms</td>\n<td>High connection overhead</td>\n<td>Full compatibility</td>\n<td>Simple</td>\n<td>Built-in with timeouts</td>\n</tr>\n</tbody></table>\n<p>Server-Sent Events provide the optimal balance for feature flag systems. The protocol naturally handles connection drops with automatic reconnection, includes built-in event identification for message replay, and works seamlessly with existing HTTP infrastructure. The slight latency increase compared to WebSockets (typically 50-200ms) is acceptable for feature flag use cases where sub-second updates are sufficient.</p>\n<h4 id=\"sse-message-format-design\">SSE Message Format Design</h4>\n<p>Feature flag updates require structured messages that convey not just the flag changes but also metadata necessary for proper client state management. Each SSE message must include enough information for clients to apply updates correctly, detect message loss, and maintain consistency during reconnection scenarios.</p>\n<p>The core message structure contains several essential components:</p>\n<table>\n<thead>\n<tr>\n<th>Message Component</th>\n<th>Type</th>\n<th>Purpose</th>\n<th>Example</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Event Type</td>\n<td>String</td>\n<td>Categorizes update type for client routing</td>\n<td><code>flag_updated</code>, <code>flag_created</code>, <code>flag_deleted</code></td>\n</tr>\n<tr>\n<td>Event ID</td>\n<td>String</td>\n<td>Unique sequence identifier for replay</td>\n<td><code>seq_12345_1640995200</code></td>\n</tr>\n<tr>\n<td>Timestamp</td>\n<td>ISO 8601</td>\n<td>Update occurrence time for ordering</td>\n<td><code>2024-01-15T10:30:00Z</code></td>\n</tr>\n<tr>\n<td>Payload</td>\n<td>JSON Object</td>\n<td>Flag change details and metadata</td>\n<td>Flag definition or change summary</td>\n</tr>\n</tbody></table>\n<p><strong>Complete Flag Updates vs. Delta Updates</strong></p>\n<p>The system supports two update strategies depending on the nature of changes:</p>\n<ol>\n<li><p><strong>Complete Flag Definition Updates</strong>: When targeting rules, variants, or core flag properties change, the server sends the entire updated <code>FlagDefinition</code> to ensure clients have complete context for evaluation. This approach eliminates potential inconsistencies from partial updates but increases message size.</p>\n</li>\n<li><p><strong>Delta Updates</strong>: For simple changes like enabling/disabling flags or adjusting rollout percentages, the server sends only the changed fields. This reduces bandwidth usage but requires more complex client-side merging logic.</p>\n</li>\n</ol>\n<p>The message format accommodates both strategies through a <code>change_type</code> field that instructs clients how to process the update:</p>\n<table>\n<thead>\n<tr>\n<th>Change Type</th>\n<th>Description</th>\n<th>Client Action</th>\n<th>Message Size</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>full_update</code></td>\n<td>Complete flag definition</td>\n<td>Replace existing flag entirely</td>\n<td>Large (1-5KB)</td>\n</tr>\n<tr>\n<td><code>delta_update</code></td>\n<td>Specific field changes</td>\n<td>Merge changes into existing flag</td>\n<td>Small (100-500B)</td>\n</tr>\n<tr>\n<td><code>flag_deleted</code></td>\n<td>Flag removal</td>\n<td>Remove from local cache</td>\n<td>Minimal (50B)</td>\n</tr>\n</tbody></table>\n<h4 id=\"event-ordering-and-replay\">Event Ordering and Replay</h4>\n<p>SSE&#39;s built-in event identification system enables reliable message ordering and replay during reconnection. Each event receives a unique, monotonically increasing identifier that clients include in reconnection requests via the <code>Last-Event-ID</code> header. The server maintains a bounded buffer of recent events (typically 1000-5000 events covering 1-24 hours) to support client reconnection without requiring full flag synchronization.</p>\n<p>Event identifiers follow a structured format: <code>seq_{sequence_number}_{timestamp}</code>. This format enables both chronological ordering and efficient buffer management on the server side. When clients reconnect after network interruption, they automatically provide their last received event ID, and the server replays all subsequent events to restore consistency.</p>\n<blockquote>\n<p><strong>Critical Design Insight</strong>: Event replay must be bounded to prevent memory exhaustion from maintaining infinite event history. The replay buffer size represents a trade-off between supporting long-disconnected clients and server resource usage. Clients disconnected longer than the replay buffer require full flag synchronization via the REST API.</p>\n</blockquote>\n<h3 id=\"connection-management-and-recovery\">Connection Management and Recovery</h3>\n<p>Robust connection management distinguishes production-ready feature flag systems from simple implementations. Client SDKs face numerous connectivity challenges: network interruptions, server restarts, load balancer changes, and varying network conditions across different environments. The connection management strategy must handle these scenarios gracefully while avoiding common pitfalls that can overwhelm infrastructure or create inconsistent flag states.</p>\n<p><strong>Mental Model: Cellular Network Roaming</strong></p>\n<p>Connection management resembles cellular network roaming systems. When your phone moves between cell towers or loses signal temporarily, it doesn&#39;t immediately give up — it systematically searches for connectivity using increasingly patient strategies. Similarly, feature flag clients must gracefully handle connection loss with intelligent retry patterns, maintaining local functionality while persistently attempting to restore real-time updates.</p>\n<h4 id=\"connection-state-machine\">Connection State Machine</h4>\n<p>The client SDK connection lifecycle follows a well-defined state machine that governs transitions between connectivity states and defines appropriate actions for each state:</p>\n<table>\n<thead>\n<tr>\n<th>Current State</th>\n<th>Event</th>\n<th>Next State</th>\n<th>Actions Taken</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Disconnected</strong></td>\n<td><code>connect()</code> called</td>\n<td>Connecting</td>\n<td>Initiate SSE connection request</td>\n</tr>\n<tr>\n<td><strong>Connecting</strong></td>\n<td>Connection established</td>\n<td>Connected</td>\n<td>Start receiving events, clear retry count</td>\n</tr>\n<tr>\n<td><strong>Connecting</strong></td>\n<td>Connection failed</td>\n<td>Reconnecting</td>\n<td>Start exponential backoff timer</td>\n</tr>\n<tr>\n<td><strong>Connected</strong></td>\n<td>Connection lost</td>\n<td>Reconnecting</td>\n<td>Begin reconnection attempt with backoff</td>\n</tr>\n<tr>\n<td><strong>Connected</strong></td>\n<td>Explicit disconnect</td>\n<td>Disconnected</td>\n<td>Close connection cleanly</td>\n</tr>\n<tr>\n<td><strong>Reconnecting</strong></td>\n<td>Retry timer expires</td>\n<td>Connecting</td>\n<td>Attempt reconnection with Last-Event-ID</td>\n</tr>\n<tr>\n<td><strong>Reconnecting</strong></td>\n<td>Max retries exceeded</td>\n<td>Disconnected</td>\n<td>Enter degraded mode, log error</td>\n</tr>\n</tbody></table>\n<p><img src=\"/api/project/feature-flags/architecture-doc/asset?path=diagrams%2Frealtime-state-machine.svg\" alt=\"Real-time Connection State Machine\"></p>\n<p>Each state defines specific behaviors and responsibilities:</p>\n<p><strong>Connected State</strong>: The client actively receives SSE events, applies flag updates to the local cache, and maintains a heartbeat mechanism to detect connection health. The client tracks the last received event ID for potential replay scenarios and monitors message timestamps to detect clock skew or processing delays.</p>\n<p><strong>Reconnecting State</strong>: The client implements exponential backoff with jitter to avoid thundering herd problems during mass reconnections. Base retry intervals start at 1 second and increase exponentially (2s, 4s, 8s, 16s) up to a maximum of 300 seconds. Random jitter (±25% of the interval) prevents synchronized reconnection attempts from multiple clients.</p>\n<p><strong>Disconnected State</strong>: The client operates in degraded mode, serving flags from local cache while optionally falling back to periodic HTTP polling for critical updates. This state indicates either intentional disconnection or exhausted retry attempts.</p>\n<h4 id=\"exponential-backoff-with-jitter\">Exponential Backoff with Jitter</h4>\n<p>Reconnection timing follows a carefully tuned exponential backoff algorithm that balances rapid recovery with infrastructure protection. The algorithm prevents thundering herd scenarios where thousands of clients simultaneously reconnect after a server restart or network partition.</p>\n<p>The backoff calculation incorporates several factors:</p>\n<ol>\n<li><strong>Base Delay</strong>: Starts at 1 second for the first retry attempt</li>\n<li><strong>Exponential Multiplier</strong>: Doubles the delay after each failed attempt (2x multiplier)</li>\n<li><strong>Maximum Delay</strong>: Caps at 300 seconds (5 minutes) to prevent indefinite delays</li>\n<li><strong>Jitter Factor</strong>: Adds ±25% randomization to prevent synchronized retries</li>\n<li><strong>Success Reset</strong>: Resets to base delay after successful connection</li>\n</ol>\n<p><strong>Backoff Implementation Algorithm</strong>:</p>\n<ol>\n<li>Initialize retry count to zero and base delay to 1 second</li>\n<li>When connection attempt fails, increment retry count</li>\n<li>Calculate raw delay as <code>base_delay * (2 ^ retry_count)</code></li>\n<li>Apply maximum delay cap: <code>min(raw_delay, max_delay)</code></li>\n<li>Apply jitter: <code>final_delay = capped_delay * (0.75 + random(0.5))</code></li>\n<li>Wait for final delay before next attempt</li>\n<li>Reset retry count to zero on successful connection</li>\n</ol>\n<p>This approach distributes reconnection attempts over time while ensuring clients don&#39;t wait excessively long during brief network interruptions.</p>\n<h4 id=\"state-synchronization-and-recovery\">State Synchronization and Recovery</h4>\n<p>When clients reconnect after extended disconnection, they must efficiently synchronize their local flag state with the current server state. The synchronization strategy depends on the disconnection duration and available event replay history.</p>\n<p><strong>Replay-Based Recovery</strong> (preferred for short disconnections):</p>\n<ol>\n<li>Client includes <code>Last-Event-ID</code> header in SSE reconnection request</li>\n<li>Server validates event ID exists in replay buffer</li>\n<li>Server replays all events since the specified ID</li>\n<li>Client applies events sequentially to update local cache</li>\n<li>Client resumes normal operation after replay completion</li>\n</ol>\n<p><strong>Full Synchronization Recovery</strong> (required for long disconnections):</p>\n<ol>\n<li>Server responds with HTTP 204 (No Replay Available) if event ID is too old</li>\n<li>Client initiates full flag synchronization via REST API</li>\n<li>Client retrieves all active flags using <code>ListFlags(true)</code></li>\n<li>Client replaces entire local cache with fresh flag definitions</li>\n<li>Client establishes new SSE connection without Last-Event-ID</li>\n</ol>\n<blockquote>\n<p><strong>Critical Implementation Note</strong>: Clients must handle partial replay scenarios where some events in the replay buffer are corrupted or out of order. The synchronization process should validate event sequence numbers and detect gaps that require full synchronization fallback.</p>\n</blockquote>\n<p>The state synchronization process includes several validation checkpoints:</p>\n<table>\n<thead>\n<tr>\n<th>Checkpoint</th>\n<th>Validation</th>\n<th>Recovery Action</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Event Sequence</td>\n<td>Verify sequential event IDs</td>\n<td>Request full sync if gaps detected</td>\n</tr>\n<tr>\n<td>Flag Versions</td>\n<td>Compare flag modification timestamps</td>\n<td>Apply updates for newer versions only</td>\n</tr>\n<tr>\n<td>Cache Consistency</td>\n<td>Validate flag references and dependencies</td>\n<td>Rebuild dependency graph</td>\n</tr>\n<tr>\n<td>Targeting Rules</td>\n<td>Ensure rule conditions are parseable</td>\n<td>Mark invalid flags as disabled</td>\n</tr>\n</tbody></table>\n<h3 id=\"cache-invalidation-strategy\">Cache Invalidation Strategy</h3>\n<p>Intelligent caching enables feature flag clients to continue operating during network interruptions while maintaining reasonable freshness guarantees. The caching strategy must balance several competing requirements: minimizing evaluation latency, supporting offline scenarios, ensuring eventual consistency, and avoiding excessive memory usage. Cache invalidation represents the critical mechanism for maintaining correctness when flag definitions change.</p>\n<p><strong>Mental Model: Library Book System</strong></p>\n<p>Think of flag caching like a library book checkout system. Each client SDK has checked out copies of flag definitions to use locally (cache). When the library updates a book (flag change), it needs to notify everyone with checked-out copies to return them and get the new version (cache invalidation). However, if someone is reading offline, they can continue using their copy temporarily (graceful degradation) until they reconnect and synchronize.</p>\n<h4 id=\"multi-level-cache-architecture\">Multi-Level Cache Architecture</h4>\n<p>The caching system employs a hierarchical approach with different cache levels optimized for specific access patterns and consistency requirements:</p>\n<table>\n<thead>\n<tr>\n<th>Cache Level</th>\n<th>Location</th>\n<th>TTL</th>\n<th>Update Mechanism</th>\n<th>Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Memory Cache</strong></td>\n<td>Client SDK process</td>\n<td>No TTL (event-driven)</td>\n<td>SSE updates + invalidation</td>\n<td>Ultra-fast flag evaluation</td>\n</tr>\n<tr>\n<td><strong>Local Storage Cache</strong></td>\n<td>Client filesystem/database</td>\n<td>24 hours</td>\n<td>Periodic refresh + SSE</td>\n<td>Offline support and persistence</td>\n</tr>\n<tr>\n<td><strong>CDN Cache</strong></td>\n<td>Edge locations</td>\n<td>60 seconds</td>\n<td>Server-side invalidation</td>\n<td>Global distribution and load reduction</td>\n</tr>\n</tbody></table>\n<p><strong>Memory Cache</strong>: Provides microsecond flag evaluation latency by keeping all active flag definitions in process memory. Updates occur immediately upon receiving SSE events, ensuring memory cache reflects the most current server state. This cache has no TTL since real-time updates maintain freshness.</p>\n<p><strong>Local Storage Cache</strong>: Supports offline scenarios by persisting flag definitions to local storage (filesystem, embedded database, or browser localStorage). This cache includes timestamps and ETags to support conditional requests during synchronization. Local storage cache serves as the fallback when memory cache is empty or during SDK initialization.</p>\n<p><strong>CDN Cache</strong>: Reduces server load by caching flag responses at edge locations close to client SDKs. CDN cache enables geographic distribution of flag data while supporting rapid invalidation for critical updates.</p>\n<h4 id=\"event-driven-invalidation\">Event-Driven Invalidation</h4>\n<p>Real-time flag updates trigger targeted cache invalidation events that maintain cache consistency without requiring full cache flushes. The invalidation strategy varies based on the type and scope of flag changes:</p>\n<p><strong>Individual Flag Updates</strong>: When a single flag changes, the system sends targeted invalidation events containing the specific <code>FlagKey</code>. Clients remove or update only the affected flag, preserving the remainder of their cache. This approach minimizes cache rebuild overhead and maintains evaluation performance for unchanged flags.</p>\n<p><strong>Bulk Flag Updates</strong>: Administrative operations that affect multiple flags (such as environment switches or emergency rollbacks) trigger batch invalidation events. These events contain arrays of affected flag keys or invalidation patterns (such as &quot;all flags for environment X&quot;).</p>\n<p><strong>Dependency-Driven Invalidation</strong>: When prerequisite flags change, the system must also invalidate any dependent flags to prevent evaluation inconsistencies. The server maintains a dependency graph and includes downstream flag keys in invalidation events.</p>\n<p>The invalidation message structure provides clients with sufficient information to make intelligent caching decisions:</p>\n<table>\n<thead>\n<tr>\n<th>Invalidation Field</th>\n<th>Type</th>\n<th>Purpose</th>\n<th>Example</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>invalidation_type</code></td>\n<td>String</td>\n<td>Scope of invalidation</td>\n<td><code>single_flag</code>, <code>bulk_flags</code>, <code>full_cache</code></td>\n</tr>\n<tr>\n<td><code>affected_flags</code></td>\n<td>Array</td>\n<td>List of flag keys requiring invalidation</td>\n<td><code>[&quot;feature_x&quot;, &quot;experiment_abc&quot;]</code></td>\n</tr>\n<tr>\n<td><code>reason</code></td>\n<td>String</td>\n<td>Cause of invalidation for debugging</td>\n<td><code>flag_updated</code>, <code>dependency_changed</code>, <code>emergency_rollback</code></td>\n</tr>\n<tr>\n<td><code>timestamp</code></td>\n<td>ISO 8601</td>\n<td>When invalidation was triggered</td>\n<td><code>2024-01-15T10:30:00Z</code></td>\n</tr>\n</tbody></table>\n<h4 id=\"graceful-degradation-patterns\">Graceful Degradation Patterns</h4>\n<p>When real-time updates become unavailable, the cache system must provide predictable degradation behavior that maintains application functionality while indicating reduced freshness guarantees. The degradation strategy follows a priority-based approach that preserves the most critical functionality while clearly communicating system state.</p>\n<p><strong>Degradation Priority Levels</strong>:</p>\n<ol>\n<li><p><strong>Memory Cache Only</strong>: Real-time updates unavailable, but memory cache remains valid. Evaluation continues normally with potentially stale data. This level supports minutes to hours of operation depending on flag change frequency.</p>\n</li>\n<li><p><strong>Local Storage Fallback</strong>: Memory cache becomes unreliable, system falls back to persisted local storage cache. Freshness guarantees reduce to hours or days, but core functionality remains available.</p>\n</li>\n<li><p><strong>Default Values Only</strong>: All cache levels are unavailable or corrupted, system serves only default values specified in flag definitions. This level maintains application stability but disables all dynamic flag behavior.</p>\n</li>\n<li><p><strong>Fail-Safe Mode</strong>: Even default values are unavailable, system returns conservative defaults (typically feature flags disabled, experiments off). This level prevents application crashes but may impact user experience.</p>\n</li>\n</ol>\n<blockquote>\n<p><strong>Operational Insight</strong>: Each degradation level should emit distinct telemetry and logging to enable operations teams to understand system health and take appropriate remedial action. Clear degradation indicators help distinguish between minor connectivity issues and serious infrastructure failures.</p>\n</blockquote>\n<p>The degradation strategy includes automatic recovery mechanisms:</p>\n<p><strong>Recovery Detection</strong>: Clients periodically attempt to restore higher-priority cache levels by testing connectivity, validating cache consistency, and requesting fresh data. Recovery attempts follow exponential backoff similar to connection retry logic.</p>\n<p><strong>Cache Warming</strong>: When recovering from degraded states, clients prioritize loading the most frequently evaluated flags first, ensuring critical application paths resume normal operation quickly. Less critical flags load in the background.</p>\n<p><strong>Consistency Verification</strong>: During recovery, clients validate cache consistency by comparing local flag versions with server versions, ensuring degraded operation didn&#39;t introduce inconsistencies that could affect user experience.</p>\n<h4 id=\"common-pitfalls\">Common Pitfalls</h4>\n<p>⚠️ <strong>Pitfall: Thundering Herd on Reconnection</strong>\nMass client reconnection after server restart can overwhelm infrastructure and cause cascading failures. This occurs when all clients lose connectivity simultaneously and attempt immediate reconnection without coordination. The result is thousands of concurrent connection attempts that exceed server capacity and connection limits.</p>\n<p><strong>Fix</strong>: Implement exponential backoff with jitter for all reconnection attempts. Add connection rate limiting on the server side and consider connection queuing during startup periods. Monitor connection establishment rates and alert on unusual spikes.</p>\n<p>⚠️ <strong>Pitfall: Infinite Event Replay Buffer</strong>\nMaintaining unlimited event history for client replay consumes unbounded memory and can cause server crashes during high-throughput periods. Some implementations attempt to store every flag change indefinitely to support arbitrary client reconnection scenarios.</p>\n<p><strong>Fix</strong>: Implement bounded replay buffers with configurable size limits (recommend 1000-5000 events). Clients requesting replay beyond buffer limits must perform full synchronization. Monitor buffer usage and tune size based on typical client disconnection patterns.</p>\n<p>⚠️ <strong>Pitfall: Cache Corruption During Partial Updates</strong>\nDelta updates can corrupt client cache if applied out of order or when base flag state is inconsistent. This manifests as clients serving incorrect flag values that don&#39;t match server state, leading to inconsistent user experiences.</p>\n<p><strong>Fix</strong>: Include flag version numbers in all updates and validate version compatibility before applying changes. Implement cache consistency checksums and fallback to full synchronization when corruption is detected. Prefer complete flag updates over delta updates for complex changes.</p>\n<p>⚠️ <strong>Pitfall: Blocking Evaluation During Cache Updates</strong>\nApplying cache updates synchronously during flag evaluation can cause evaluation latency spikes and thread contention in multi-threaded applications. This particularly impacts high-throughput applications where flag evaluation occurs on critical request paths.</p>\n<p><strong>Fix</strong>: Implement lock-free cache updates using atomic operations or copy-on-write semantics. Stage cache updates in background threads and atomically swap complete cache instances. Never block flag evaluation for cache maintenance operations.</p>\n<p><img src=\"/api/project/feature-flags/architecture-doc/asset?path=diagrams%2Fupdate-propagation.svg\" alt=\"Flag Update Propagation\"></p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>This section provides concrete implementation guidance for building real-time flag updates in Go, focusing on production-ready patterns that handle the complexities of streaming connections, intelligent caching, and graceful degradation.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>SSE Server</strong></td>\n<td><code>net/http</code> with <code>http.Flusher</code></td>\n<td><code>gin-gonic/gin</code> with streaming middleware</td>\n</tr>\n<tr>\n<td><strong>Client HTTP</strong></td>\n<td><code>net/http</code> with <code>EventSource</code> pattern</td>\n<td><code>gorilla/websocket</code> for WebSocket fallback</td>\n</tr>\n<tr>\n<td><strong>Local Cache</strong></td>\n<td><code>sync.Map</code> with TTL cleanup</td>\n<td><code>patrickmn/go-cache</code> or <code>allegro/bigcache</code></td>\n</tr>\n<tr>\n<td><strong>Persistent Storage</strong></td>\n<td>JSON files with <code>os</code> package</td>\n<td><code>bolt/bbolt</code> embedded database</td>\n</tr>\n<tr>\n<td><strong>Backoff Logic</strong></td>\n<td>Custom exponential calculation</td>\n<td><code>cenkalti/backoff</code> library</td>\n</tr>\n<tr>\n<td><strong>Event Serialization</strong></td>\n<td><code>encoding/json</code></td>\n<td><code>vmihailenco/msgpack</code> for efficiency</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>internal/realtime/\n  server.go                 ← SSE server implementation\n  client.go                ← Client SDK with connection management\n  cache.go                 ← Multi-level cache implementation\n  backoff.go               ← Exponential backoff utilities\n  events.go                ← Event message definitions\n  connection_manager.go    ← Connection state machine\n  server_test.go          ← SSE server tests\n  client_test.go          ← Client connection tests\n  cache_test.go           ← Cache invalidation tests\ninternal/storage/\n  flag_store.go           ← Flag storage interface\n  memory_store.go         ← In-memory flag storage\npkg/sdk/\n  client.go               ← Public SDK interface\n  evaluation.go           ← Flag evaluation with caching\nexamples/\n  sse_server/main.go      ← Complete SSE server example\n  flag_client/main.go     ← Example client usage</code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p><strong>Complete SSE Server Implementation</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// internal/realtime/server.go</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> realtime</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">context</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">encoding/json</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">fmt</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">log</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">net/http</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">strconv</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">sync</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// FlagUpdateEvent represents a flag change notification</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> FlagUpdateEvent</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    EventType   </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"event_type\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    EventID     </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"event_id\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Timestamp   </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">   `json:\"timestamp\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    FlagKey     </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"flag_key\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Payload     </span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{} </span><span style=\"color:#9ECBFF\">`json:\"payload\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ChangeType  </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"change_type\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// SSEServer manages Server-Sent Events for flag updates</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> SSEServer</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    clients      </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">SSEClient</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    eventBuffer  []</span><span style=\"color:#B392F0\">FlagUpdateEvent</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    bufferSize   </span><span style=\"color:#F97583\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    mu           </span><span style=\"color:#B392F0\">sync</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">RWMutex</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    eventCounter </span><span style=\"color:#F97583\">int64</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// SSEClient represents a connected client</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> SSEClient</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ID           </span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ResponseWriter </span><span style=\"color:#B392F0\">http</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">ResponseWriter</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Flusher      </span><span style=\"color:#B392F0\">http</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Flusher</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LastEventID  </span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Connected    </span><span style=\"color:#F97583\">bool</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    mu           </span><span style=\"color:#B392F0\">sync</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Mutex</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// NewSSEServer creates a new SSE server with bounded event buffer</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewSSEServer</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">bufferSize</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">SSEServer</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">SSEServer</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        clients:     </span><span style=\"color:#B392F0\">make</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">SSEClient</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        eventBuffer: </span><span style=\"color:#B392F0\">make</span><span style=\"color:#E1E4E8\">([]</span><span style=\"color:#B392F0\">FlagUpdateEvent</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, bufferSize),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        bufferSize:  bufferSize,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ServeHTTP handles SSE connection requests</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">s </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">SSEServer</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">ServeHTTP</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">w</span><span style=\"color:#B392F0\"> http</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">ResponseWriter</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">r</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">http</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Request</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Set SSE headers</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    w.</span><span style=\"color:#B392F0\">Header</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#B392F0\">Set</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Content-Type\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"text/event-stream\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    w.</span><span style=\"color:#B392F0\">Header</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#B392F0\">Set</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Cache-Control\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"no-cache\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    w.</span><span style=\"color:#B392F0\">Header</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#B392F0\">Set</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Connection\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"keep-alive\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    w.</span><span style=\"color:#B392F0\">Header</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#B392F0\">Set</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Access-Control-Allow-Origin\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"*\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    flusher, ok </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> w.(</span><span style=\"color:#B392F0\">http</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Flusher</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> !</span><span style=\"color:#E1E4E8\">ok {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        http.</span><span style=\"color:#B392F0\">Error</span><span style=\"color:#E1E4E8\">(w, </span><span style=\"color:#9ECBFF\">\"Streaming unsupported\"</span><span style=\"color:#E1E4E8\">, http.StatusInternalServerError)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    clientID </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> r.Header.</span><span style=\"color:#B392F0\">Get</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"X-Client-ID\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> clientID </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        clientID </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Sprintf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"client_</span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, time.</span><span style=\"color:#B392F0\">Now</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#B392F0\">UnixNano</span><span style=\"color:#E1E4E8\">())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    client </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">SSEClient</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ID:             clientID,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ResponseWriter: w,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Flusher:        flusher,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        LastEventID:    r.Header.</span><span style=\"color:#B392F0\">Get</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Last-Event-ID\"</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Connected:      </span><span style=\"color:#79B8FF\">true</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    s.mu.</span><span style=\"color:#B392F0\">Lock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    s.clients[clientID] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> client</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    s.mu.</span><span style=\"color:#B392F0\">Unlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#F97583\"> func</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        s.mu.</span><span style=\"color:#B392F0\">Lock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        delete</span><span style=\"color:#E1E4E8\">(s.clients, clientID)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        s.mu.</span><span style=\"color:#B392F0\">Unlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Send replay events if requested</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> client.LastEventID </span><span style=\"color:#F97583\">!=</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        s.</span><span style=\"color:#B392F0\">sendReplayEvents</span><span style=\"color:#E1E4E8\">(client)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Keep connection alive and detect disconnection</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ctx </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> r.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ticker </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> time.</span><span style=\"color:#B392F0\">NewTicker</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">30</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\"> time.Second)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> ticker.</span><span style=\"color:#B392F0\">Stop</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        select</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        case</span><span style=\"color:#F97583\"> &#x3C;-</span><span style=\"color:#E1E4E8\">ctx.</span><span style=\"color:#B392F0\">Done</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        case</span><span style=\"color:#F97583\"> &#x3C;-</span><span style=\"color:#E1E4E8\">ticker.C:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> s.</span><span style=\"color:#B392F0\">sendHeartbeat</span><span style=\"color:#E1E4E8\">(client); err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                log.</span><span style=\"color:#B392F0\">Printf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Client </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\"> disconnected: </span><span style=\"color:#79B8FF\">%v</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, clientID, err)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// sendReplayEvents replays buffered events to reconnecting clients</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">s </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">SSEServer</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">sendReplayEvents</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">client</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">SSEClient</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    s.mu.</span><span style=\"color:#B392F0\">RLock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> s.mu.</span><span style=\"color:#B392F0\">RUnlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    lastEventNum </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> s.</span><span style=\"color:#B392F0\">parseEventID</span><span style=\"color:#E1E4E8\">(client.LastEventID)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> lastEventNum </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Invalid event ID, client needs full sync</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        s.</span><span style=\"color:#B392F0\">sendEvent</span><span style=\"color:#E1E4E8\">(client, </span><span style=\"color:#B392F0\">FlagUpdateEvent</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            EventType: </span><span style=\"color:#9ECBFF\">\"sync_required\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            EventID:   s.</span><span style=\"color:#B392F0\">generateEventID</span><span style=\"color:#E1E4E8\">(),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            Timestamp: time.</span><span style=\"color:#B392F0\">Now</span><span style=\"color:#E1E4E8\">(),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        })</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Find starting position in buffer</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    startIndex </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> i, event </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> range</span><span style=\"color:#E1E4E8\"> s.eventBuffer {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> s.</span><span style=\"color:#B392F0\">parseEventID</span><span style=\"color:#E1E4E8\">(event.EventID) </span><span style=\"color:#F97583\">></span><span style=\"color:#E1E4E8\"> lastEventNum {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            startIndex </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> i</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            break</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> startIndex </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // No events to replay or event too old</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Send all events since last received</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> startIndex; i </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#B392F0\"> len</span><span style=\"color:#E1E4E8\">(s.eventBuffer); i</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        s.</span><span style=\"color:#B392F0\">sendEvent</span><span style=\"color:#E1E4E8\">(client, s.eventBuffer[i])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// sendHeartbeat sends keep-alive ping to client</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">s </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">SSEServer</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">sendHeartbeat</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">client</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">SSEClient</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    client.mu.</span><span style=\"color:#B392F0\">Lock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> client.mu.</span><span style=\"color:#B392F0\">Unlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> !</span><span style=\"color:#E1E4E8\">client.Connected {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"client disconnected\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    _, err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Fprintf</span><span style=\"color:#E1E4E8\">(client.ResponseWriter, </span><span style=\"color:#9ECBFF\">\": heartbeat</span><span style=\"color:#79B8FF\">\\n\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        client.Connected </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> err</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    client.Flusher.</span><span style=\"color:#B392F0\">Flush</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// BroadcastFlagUpdate sends flag change to all connected clients</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">s </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">SSEServer</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">BroadcastFlagUpdate</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">flagKey</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">payload</span><span style=\"color:#F97583\"> interface</span><span style=\"color:#E1E4E8\">{}, </span><span style=\"color:#FFAB70\">changeType</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    event </span><span style=\"color:#F97583\">:=</span><span style=\"color:#B392F0\"> FlagUpdateEvent</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        EventType:  </span><span style=\"color:#9ECBFF\">\"flag_updated\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        EventID:    s.</span><span style=\"color:#B392F0\">generateEventID</span><span style=\"color:#E1E4E8\">(),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Timestamp:  time.</span><span style=\"color:#B392F0\">Now</span><span style=\"color:#E1E4E8\">(),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        FlagKey:    flagKey,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Payload:    payload,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ChangeType: changeType,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Add to buffer for replay</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    s.mu.</span><span style=\"color:#B392F0\">Lock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    s.eventBuffer </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> append</span><span style=\"color:#E1E4E8\">(s.eventBuffer, event)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#B392F0\"> len</span><span style=\"color:#E1E4E8\">(s.eventBuffer) </span><span style=\"color:#F97583\">></span><span style=\"color:#E1E4E8\"> s.bufferSize {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Remove oldest event to maintain buffer size</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        s.eventBuffer </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> s.eventBuffer[</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">:]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    clients </span><span style=\"color:#F97583\">:=</span><span style=\"color:#B392F0\"> make</span><span style=\"color:#E1E4E8\">([]</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">SSEClient</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#B392F0\">len</span><span style=\"color:#E1E4E8\">(s.clients))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> _, client </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> range</span><span style=\"color:#E1E4E8\"> s.clients {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        clients </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> append</span><span style=\"color:#E1E4E8\">(clients, client)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    s.mu.</span><span style=\"color:#B392F0\">Unlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Broadcast to all clients</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> _, client </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> range</span><span style=\"color:#E1E4E8\"> clients {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> s.</span><span style=\"color:#B392F0\">sendEvent</span><span style=\"color:#E1E4E8\">(client, event); err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            log.</span><span style=\"color:#B392F0\">Printf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Failed to send event to client </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">: </span><span style=\"color:#79B8FF\">%v</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, client.ID, err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// sendEvent writes SSE event to client connection</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">s </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">SSEServer</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">sendEvent</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">client</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">SSEClient</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">event</span><span style=\"color:#B392F0\"> FlagUpdateEvent</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    client.mu.</span><span style=\"color:#B392F0\">Lock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> client.mu.</span><span style=\"color:#B392F0\">Unlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> !</span><span style=\"color:#E1E4E8\">client.Connected {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"client disconnected\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    data, err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> json.</span><span style=\"color:#B392F0\">Marshal</span><span style=\"color:#E1E4E8\">(event)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> err</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    _, err </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Fprintf</span><span style=\"color:#E1E4E8\">(client.ResponseWriter, </span><span style=\"color:#9ECBFF\">\"id: </span><span style=\"color:#79B8FF\">%s\\n</span><span style=\"color:#9ECBFF\">event: </span><span style=\"color:#79B8FF\">%s\\n</span><span style=\"color:#9ECBFF\">data: </span><span style=\"color:#79B8FF\">%s\\n\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        event.EventID, event.EventType, </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">(data))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        client.Connected </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> err</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    client.Flusher.</span><span style=\"color:#B392F0\">Flush</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// generateEventID creates unique sequential event identifier</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">s </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">SSEServer</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">generateEventID</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    s.eventCounter</span><span style=\"color:#F97583\">++</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Sprintf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"seq_</span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#9ECBFF\">_</span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, s.eventCounter, time.</span><span style=\"color:#B392F0\">Now</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#B392F0\">Unix</span><span style=\"color:#E1E4E8\">())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// parseEventID extracts sequence number from event ID</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">s </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">SSEServer</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">parseEventID</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">eventID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">int64</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> eventID </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    var</span><span style=\"color:#E1E4E8\"> seq </span><span style=\"color:#F97583\">int64</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    var</span><span style=\"color:#E1E4E8\"> timestamp </span><span style=\"color:#F97583\">int64</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> _, err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Sscanf</span><span style=\"color:#E1E4E8\">(eventID, </span><span style=\"color:#9ECBFF\">\"seq_</span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#9ECBFF\">_</span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">seq, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">timestamp); err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> seq</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Complete Connection Manager with State Machine</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// internal/realtime/connection_manager.go</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> realtime</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">bufio</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">context</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">fmt</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">math</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">math/rand</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">net/http</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">sync</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ConnectionState represents the current connection status</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> ConnectionState</span><span style=\"color:#F97583\"> int</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">const</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    StateDisconnected</span><span style=\"color:#B392F0\"> ConnectionState</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> iota</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    StateConnecting</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    StateConnected</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    StateReconnecting</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ConnectionManager handles SSE connection lifecycle</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> ConnectionManager</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    serverURL      </span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    clientID       </span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    lastEventID    </span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    state          </span><span style=\"color:#B392F0\">ConnectionState</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    retryCount     </span><span style=\"color:#F97583\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    maxRetries     </span><span style=\"color:#F97583\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    baseDelay      </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    maxDelay       </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    eventHandler   </span><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">FlagUpdateEvent</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    errorHandler   </span><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cancelFunc     </span><span style=\"color:#B392F0\">context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">CancelFunc</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    mu             </span><span style=\"color:#B392F0\">sync</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">RWMutex</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    stateChan      </span><span style=\"color:#F97583\">chan</span><span style=\"color:#B392F0\"> ConnectionState</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// NewConnectionManager creates a new connection manager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewConnectionManager</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">serverURL</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">clientID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">ConnectionManager</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">ConnectionManager</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        serverURL:    serverURL,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        clientID:     clientID,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        state:        StateDisconnected,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        maxRetries:   </span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        baseDelay:    time.Second,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        maxDelay:     </span><span style=\"color:#79B8FF\">5</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\"> time.Minute,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        stateChan:    </span><span style=\"color:#B392F0\">make</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">chan</span><span style=\"color:#B392F0\"> ConnectionState</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Connect initiates SSE connection with automatic retry</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">cm </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">ConnectionManager</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Connect</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cm.mu.</span><span style=\"color:#B392F0\">Lock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> cm.mu.</span><span style=\"color:#B392F0\">Unlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> cm.state </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> StateDisconnected {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"connection already active\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    connectCtx, cancel </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> context.</span><span style=\"color:#B392F0\">WithCancel</span><span style=\"color:#E1E4E8\">(ctx)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cm.cancelFunc </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> cancel</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cm.</span><span style=\"color:#B392F0\">setState</span><span style=\"color:#E1E4E8\">(StateConnecting)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    go</span><span style=\"color:#E1E4E8\"> cm.</span><span style=\"color:#B392F0\">connectionLoop</span><span style=\"color:#E1E4E8\">(connectCtx)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// connectionLoop manages the connection lifecycle with retry logic</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">cm </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">ConnectionManager</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">connectionLoop</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        select</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        case</span><span style=\"color:#F97583\"> &#x3C;-</span><span style=\"color:#E1E4E8\">ctx.</span><span style=\"color:#B392F0\">Done</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            cm.</span><span style=\"color:#B392F0\">setState</span><span style=\"color:#E1E4E8\">(StateDisconnected)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        default</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> cm.</span><span style=\"color:#B392F0\">attemptConnection</span><span style=\"color:#E1E4E8\">(ctx); err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> cm.</span><span style=\"color:#B392F0\">shouldRetry</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    cm.</span><span style=\"color:#B392F0\">setState</span><span style=\"color:#E1E4E8\">(StateReconnecting)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    delay </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> cm.</span><span style=\"color:#B392F0\">calculateBackoffDelay</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    select</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    case</span><span style=\"color:#F97583\"> &#x3C;-</span><span style=\"color:#E1E4E8\">ctx.</span><span style=\"color:#B392F0\">Done</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        cm.</span><span style=\"color:#B392F0\">setState</span><span style=\"color:#E1E4E8\">(StateDisconnected)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                        return</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    case</span><span style=\"color:#F97583\"> &#x3C;-</span><span style=\"color:#E1E4E8\">time.</span><span style=\"color:#B392F0\">After</span><span style=\"color:#E1E4E8\">(delay):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        cm.retryCount</span><span style=\"color:#F97583\">++</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                        continue</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                } </span><span style=\"color:#F97583\">else</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    cm.</span><span style=\"color:#B392F0\">setState</span><span style=\"color:#E1E4E8\">(StateDisconnected)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    if</span><span style=\"color:#E1E4E8\"> cm.errorHandler </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        cm.</span><span style=\"color:#B392F0\">errorHandler</span><span style=\"color:#E1E4E8\">(fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"max retries exceeded\"</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    return</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            } </span><span style=\"color:#F97583\">else</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                // Connection successful, reset retry count</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                cm.retryCount </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// attemptConnection tries to establish SSE connection</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">cm </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">ConnectionManager</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">attemptConnection</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    req, err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> http.</span><span style=\"color:#B392F0\">NewRequestWithContext</span><span style=\"color:#E1E4E8\">(ctx, </span><span style=\"color:#9ECBFF\">\"GET\"</span><span style=\"color:#E1E4E8\">, cm.serverURL, </span><span style=\"color:#79B8FF\">nil</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> err</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Set SSE headers</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    req.Header.</span><span style=\"color:#B392F0\">Set</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Accept\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"text/event-stream\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    req.Header.</span><span style=\"color:#B392F0\">Set</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Cache-Control\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"no-cache\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    req.Header.</span><span style=\"color:#B392F0\">Set</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"X-Client-ID\"</span><span style=\"color:#E1E4E8\">, cm.clientID)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cm.mu.</span><span style=\"color:#B392F0\">RLock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> cm.lastEventID </span><span style=\"color:#F97583\">!=</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        req.Header.</span><span style=\"color:#B392F0\">Set</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Last-Event-ID\"</span><span style=\"color:#E1E4E8\">, cm.lastEventID)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cm.mu.</span><span style=\"color:#B392F0\">RUnlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    client </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">http</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Client</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Timeout: </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#6A737D\">// No timeout for streaming connection</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    resp, err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> client.</span><span style=\"color:#B392F0\">Do</span><span style=\"color:#E1E4E8\">(req)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> err</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> resp.Body.</span><span style=\"color:#B392F0\">Close</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> resp.StatusCode </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> http.StatusOK {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"SSE connection failed: </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, resp.Status)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cm.</span><span style=\"color:#B392F0\">setState</span><span style=\"color:#E1E4E8\">(StateConnected)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> cm.</span><span style=\"color:#B392F0\">processEventStream</span><span style=\"color:#E1E4E8\">(ctx, resp)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// processEventStream reads and processes SSE events</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">cm </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">ConnectionManager</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">processEventStream</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">resp</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">http</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Response</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    scanner </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> bufio.</span><span style=\"color:#B392F0\">NewScanner</span><span style=\"color:#E1E4E8\">(resp.Body)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    var</span><span style=\"color:#E1E4E8\"> currentEvent </span><span style=\"color:#B392F0\">FlagUpdateEvent</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    var</span><span style=\"color:#E1E4E8\"> eventID, eventType, eventData </span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> scanner.</span><span style=\"color:#B392F0\">Scan</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        line </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> scanner.</span><span style=\"color:#B392F0\">Text</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        select</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        case</span><span style=\"color:#F97583\"> &#x3C;-</span><span style=\"color:#E1E4E8\">ctx.</span><span style=\"color:#B392F0\">Done</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> ctx.</span><span style=\"color:#B392F0\">Err</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        default</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> line </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // Empty line indicates end of event</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> eventType </span><span style=\"color:#F97583\">!=</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#F97583\"> &#x26;&#x26;</span><span style=\"color:#E1E4E8\"> eventData </span><span style=\"color:#F97583\">!=</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                // Parse and handle event</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> cm.</span><span style=\"color:#B392F0\">handleSSEEvent</span><span style=\"color:#E1E4E8\">(eventID, eventType, eventData); err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    if</span><span style=\"color:#E1E4E8\"> cm.errorHandler </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        cm.</span><span style=\"color:#B392F0\">errorHandler</span><span style=\"color:#E1E4E8\">(err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                }</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                // Reset for next event</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                eventID, eventType, eventData </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            continue</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#B392F0\"> len</span><span style=\"color:#E1E4E8\">(line) </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 5</span><span style=\"color:#F97583\"> &#x26;&#x26;</span><span style=\"color:#E1E4E8\"> line[:</span><span style=\"color:#79B8FF\">3</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> \"id:\"</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            eventID </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> line[</span><span style=\"color:#79B8FF\">4</span><span style=\"color:#E1E4E8\">:]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        } </span><span style=\"color:#F97583\">else</span><span style=\"color:#F97583\"> if</span><span style=\"color:#B392F0\"> len</span><span style=\"color:#E1E4E8\">(line) </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 7</span><span style=\"color:#F97583\"> &#x26;&#x26;</span><span style=\"color:#E1E4E8\"> line[:</span><span style=\"color:#79B8FF\">6</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> \"event:\"</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            eventType </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> line[</span><span style=\"color:#79B8FF\">7</span><span style=\"color:#E1E4E8\">:]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        } </span><span style=\"color:#F97583\">else</span><span style=\"color:#F97583\"> if</span><span style=\"color:#B392F0\"> len</span><span style=\"color:#E1E4E8\">(line) </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 6</span><span style=\"color:#F97583\"> &#x26;&#x26;</span><span style=\"color:#E1E4E8\"> line[:</span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> \"data:\"</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            eventData </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> line[</span><span style=\"color:#79B8FF\">6</span><span style=\"color:#E1E4E8\">:]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> scanner.</span><span style=\"color:#B392F0\">Err</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// handleSSEEvent processes individual SSE events</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">cm </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">ConnectionManager</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">handleSSEEvent</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">eventID</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">eventType</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">eventData</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Update last event ID for replay</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cm.mu.</span><span style=\"color:#B392F0\">Lock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cm.lastEventID </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> eventID</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cm.mu.</span><span style=\"color:#B392F0\">Unlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Skip heartbeat events</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> eventData </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Parse eventData JSON into FlagUpdateEvent</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Call eventHandler with parsed event</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // This is where learners implement the event parsing logic</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// calculateBackoffDelay computes exponential backoff with jitter</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">cm </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">ConnectionManager</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">calculateBackoffDelay</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Exponential backoff: baseDelay * (2 ^ retryCount)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    delay </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> cm.baseDelay </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> time.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#E1E4E8\">(math.</span><span style=\"color:#B392F0\">Pow</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">float64</span><span style=\"color:#E1E4E8\">(cm.retryCount)))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Apply maximum delay cap</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> delay </span><span style=\"color:#F97583\">></span><span style=\"color:#E1E4E8\"> cm.maxDelay {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        delay </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> cm.maxDelay</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Add jitter (±25%)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    jitter </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> delay </span><span style=\"color:#F97583\">/</span><span style=\"color:#79B8FF\"> 4</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    jitterAmount </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> time.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#E1E4E8\">(rand.</span><span style=\"color:#B392F0\">Int63n</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int64</span><span style=\"color:#E1E4E8\">(jitter</span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">))) </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> jitter</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> delay </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> jitterAmount</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// shouldRetry determines if connection should be retried</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">cm </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">ConnectionManager</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">shouldRetry</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> cm.retryCount </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> cm.maxRetries</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// setState updates connection state and notifies listeners</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">cm </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">ConnectionManager</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">setState</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">newState</span><span style=\"color:#B392F0\"> ConnectionState</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cm.state </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> newState</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    select</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    case</span><span style=\"color:#E1E4E8\"> cm.stateChan </span><span style=\"color:#F97583\">&#x3C;-</span><span style=\"color:#E1E4E8\"> newState:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    default</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Channel full, skip notification</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// GetState returns current connection state</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">cm </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">ConnectionManager</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">GetState</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#B392F0\">ConnectionState</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cm.mu.</span><span style=\"color:#B392F0\">RLock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> cm.mu.</span><span style=\"color:#B392F0\">RUnlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> cm.state</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Disconnect cleanly closes the connection</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">cm </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">ConnectionManager</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Disconnect</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cm.mu.</span><span style=\"color:#B392F0\">Lock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> cm.mu.</span><span style=\"color:#B392F0\">Unlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> cm.cancelFunc </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        cm.</span><span style=\"color:#B392F0\">cancelFunc</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        cm.cancelFunc </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cm.</span><span style=\"color:#B392F0\">setState</span><span style=\"color:#E1E4E8\">(StateDisconnected)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeleton-code\">Core Logic Skeleton Code</h4>\n<p><strong>Flag Cache Implementation with Invalidation</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// internal/realtime/cache.go</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> realtime</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">encoding/json</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">sync</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// FlagCache provides multi-level caching with real-time invalidation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> FlagCache</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    memoryCache   </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">CachedFlag</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    localStorage  </span><span style=\"color:#B392F0\">LocalStorage</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    mu            </span><span style=\"color:#B392F0\">sync</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">RWMutex</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    stats         </span><span style=\"color:#B392F0\">CacheStats</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// CachedFlag wraps flag definition with metadata</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> CachedFlag</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Definition  </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FlagDefinition</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Version     </span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Timestamp   </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Source      </span><span style=\"color:#F97583\">string</span><span style=\"color:#6A737D\">  // \"memory\", \"local\", \"default\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// CacheStats tracks cache performance metrics</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> CacheStats</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Hits          </span><span style=\"color:#F97583\">int64</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Misses        </span><span style=\"color:#F97583\">int64</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Invalidations </span><span style=\"color:#F97583\">int64</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    mu            </span><span style=\"color:#B392F0\">sync</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">RWMutex</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// LocalStorage interface for persistent flag storage</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> LocalStorage</span><span style=\"color:#F97583\"> interface</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    Store</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">key</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">flag</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">FlagDefinition</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    Load</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">key</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FlagDefinition</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    Delete</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">key</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    List</span><span style=\"color:#E1E4E8\">() ([]</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// NewFlagCache creates a new multi-level cache</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewFlagCache</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">localStorage</span><span style=\"color:#B392F0\"> LocalStorage</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FlagCache</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">FlagCache</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        memoryCache:  </span><span style=\"color:#B392F0\">make</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">CachedFlag</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        localStorage: localStorage,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// GetFlag retrieves flag from cache with fallback hierarchy</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FlagCache</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">GetFlag</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">flagKey</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FlagDefinition</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Check memory cache first for fastest access</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: If not in memory, try local storage cache</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: If not in local storage, return error for cache miss</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Update cache statistics (hits/misses)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: When loading from local storage, populate memory cache</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use read lock for cache access, upgrade to write lock only when updating</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// InvalidateFlag removes flag from all cache levels</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FlagCache</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">InvalidateFlag</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">flagKey</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Remove from memory cache using write lock</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Remove from local storage cache</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Update invalidation statistics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Log invalidation event for debugging</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Always update statistics even if flag wasn't cached</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// UpdateFlag stores new flag version in cache</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FlagCache</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">UpdateFlag</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">flagKey</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">flag</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">FlagDefinition</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">source</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Create CachedFlag wrapper with metadata (version, timestamp, source)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Store in memory cache with write lock</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Persist to local storage for offline support</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Validate flag structure before caching</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Handle storage errors gracefully (memory cache still updates)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Generate version string from flag content hash or timestamp</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ApplyFlagUpdate processes real-time flag change events</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FlagCache</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">ApplyFlagUpdate</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">event</span><span style=\"color:#B392F0\"> FlagUpdateEvent</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Parse event payload based on change_type</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: For \"full_update\": replace entire flag definition</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: For \"delta_update\": merge changes into existing flag</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: For \"flag_deleted\": remove flag from all cache levels</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Validate update consistency (version numbers, timestamps)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Handle update conflicts and version mismatches</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Delta updates should validate base flag exists and versions match</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// GetCacheStats returns current cache performance metrics</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FlagCache</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">GetCacheStats</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#B392F0\">CacheStats</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    c.stats.mu.</span><span style=\"color:#B392F0\">RLock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> c.stats.mu.</span><span style=\"color:#B392F0\">RUnlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#B392F0\"> CacheStats</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Hits:          c.stats.Hits,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Misses:        c.stats.Misses,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Invalidations: c.stats.Invalidations,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// WarmCache preloads frequently used flags</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FlagCache</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">WarmCache</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">flagKeys</span><span style=\"color:#E1E4E8\"> []</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Load specified flags from local storage</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Populate memory cache with loaded flags</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Handle missing flags gracefully</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Load flags in priority order (most critical first)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Report warming progress and errors</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use goroutines for concurrent warming but limit concurrency</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ValidateConsistency checks cache integrity</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FlagCache</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">ValidateConsistency</span><span style=\"color:#E1E4E8\">() []</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Compare memory cache versions with local storage</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Detect corrupted or unparseable flag definitions  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Find flags with invalid dependency references</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Return list of inconsistent flag keys</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Log detailed consistency issues for debugging</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: This method helps detect cache corruption during degraded operation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p><strong>Checkpoint 1: SSE Server Basic Functionality</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Start the SSE server</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> run</span><span style=\"color:#9ECBFF\"> examples/sse_server/main.go</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test connection with curl</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">curl</span><span style=\"color:#79B8FF\"> -N</span><span style=\"color:#79B8FF\"> -H</span><span style=\"color:#9ECBFF\"> \"Accept: text/event-stream\"</span><span style=\"color:#9ECBFF\"> http://localhost:8080/stream</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected: Heartbeat messages every 30 seconds</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected: Connection remains open indefinitely</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected: Server logs show client connection and heartbeat events</span></span></code></pre></div>\n\n<p><strong>Checkpoint 2: Event Replay and Reconnection</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Connect client, then kill connection and reconnect</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Client should automatically reconnect with exponential backoff</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Server should replay missed events based on Last-Event-ID header</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test event replay</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">curl</span><span style=\"color:#79B8FF\"> -N</span><span style=\"color:#79B8FF\"> -H</span><span style=\"color:#9ECBFF\"> \"Accept: text/event-stream\"</span><span style=\"color:#79B8FF\"> -H</span><span style=\"color:#9ECBFF\"> \"Last-Event-ID: seq_100_1640995200\"</span><span style=\"color:#79B8FF\"> \\</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">  http://localhost:8080/stream</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected: Server replays events newer than specified ID</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected: If ID too old, server sends sync_required event</span></span></code></pre></div>\n\n<p><strong>Checkpoint 3: Cache Invalidation Integration</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Update a flag via management API</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">curl</span><span style=\"color:#79B8FF\"> -X</span><span style=\"color:#9ECBFF\"> PUT</span><span style=\"color:#9ECBFF\"> http://localhost:8080/flags/test_flag</span><span style=\"color:#79B8FF\"> \\</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">  -d</span><span style=\"color:#9ECBFF\"> '{\"enabled\": true, \"variants\": [{\"key\": \"on\", \"value\": true}]}'</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Verify SSE clients receive flag_updated event within 1 second</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Verify client caches invalidate and serve new flag values</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test with multiple connected clients for broadcast verification</span></span></code></pre></div>\n\n<h4 id=\"debugging-tips\">Debugging Tips</h4>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>Diagnosis</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Clients never reconnect</strong></td>\n<td>Missing exponential backoff or infinite retry loop</td>\n<td>Check client logs for retry attempts and delays</td>\n<td>Implement bounded retry with proper delay calculation</td>\n</tr>\n<tr>\n<td><strong>Thundering herd on server restart</strong></td>\n<td>All clients reconnecting simultaneously</td>\n<td>Monitor connection rate and server resource usage</td>\n<td>Add jitter to backoff delays and connection rate limiting</td>\n</tr>\n<tr>\n<td><strong>Events delivered out of order</strong></td>\n<td>Missing event sequencing or buffer overflow</td>\n<td>Compare event IDs between server and client logs</td>\n<td>Implement proper event ordering and sequence validation</td>\n</tr>\n<tr>\n<td><strong>Cache serves stale data</strong></td>\n<td>Invalidation events not processed or lost</td>\n<td>Check SSE connection status and event processing logs</td>\n<td>Verify event handling and add cache TTL as backup</td>\n</tr>\n<tr>\n<td><strong>Memory leak in event buffer</strong></td>\n<td>Unbounded event history storage</td>\n<td>Monitor server memory usage over time</td>\n<td>Implement fixed-size circular buffer with proper cleanup</td>\n</tr>\n<tr>\n<td><strong>Clients stuck in reconnecting state</strong></td>\n<td>Network issues or server unavailability</td>\n<td>Test network connectivity and server health endpoints</td>\n<td>Add connection timeout and fallback to polling mode</td>\n</tr>\n</tbody></table>\n<h2 id=\"flag-analytics-and-ab-testing\">Flag Analytics and A/B Testing</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section covers Milestone 3 (Flag Analytics &amp; Experiments) by implementing flag exposure tracking, A/B testing framework, and statistical significance calculation for data-driven feature decisions.</p>\n</blockquote>\n<p>Think of <strong>flag analytics</strong> as the flight data recorder for your feature flags. Just as aviation authorities need detailed logs to understand what happened during a flight and whether aircraft systems performed correctly, product teams need comprehensive exposure tracking to understand how features are performing in the wild. The analytics system captures every flag evaluation event, much like how a black box records every instrument reading and pilot action throughout a flight.</p>\n<p>The <strong>A/B testing framework</strong> extends this analogy to become your experimental flight test program. When aircraft manufacturers test new designs, they don&#39;t just throw them into commercial service—they run controlled experiments with careful measurement protocols, statistical analysis, and safety monitoring. Similarly, your A/B testing framework provides the rigorous experimental methodology needed to validate that new features actually improve user outcomes rather than just looking good in demos.</p>\n<p>This analytics foundation transforms feature flags from simple configuration toggles into a sophisticated experimentation platform that enables evidence-based product development. Without proper analytics, feature flags become &quot;fire and forget&quot; deployments where teams never know whether their features succeeded or failed.</p>\n<p><img src=\"/api/project/feature-flags/architecture-doc/asset?path=diagrams%2Fexperiment-lifecycle.svg\" alt=\"A/B Test Experiment Lifecycle\"></p>\n<h3 id=\"flag-exposure-tracking\">Flag Exposure Tracking</h3>\n<p>Flag exposure tracking forms the observational backbone of the entire analytics system. Think of <strong>exposure events</strong> as the breadcrumbs that users leave behind as they navigate through your feature variations. Each time the evaluation engine determines which variant a user should see, the system records this decision along with the complete context that influenced it.</p>\n<p>The core insight behind exposure tracking is that simply deploying a feature flag isn&#39;t enough—you need to know which users actually encountered each variant under what circumstances. This detailed record enables you to answer critical questions: Did the targeting rules work as expected? Are certain user segments seeing variants at different rates? Which environmental factors correlate with feature performance?</p>\n<blockquote>\n<p><strong>Decision: Event-Based Exposure Recording</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to capture flag evaluations for analytics without impacting evaluation performance</li>\n<li><strong>Options Considered</strong>: Synchronous database writes, asynchronous event queues, in-memory buffers with batch writes</li>\n<li><strong>Decision</strong>: Asynchronous event queues with batch persistence</li>\n<li><strong>Rationale</strong>: Removes database I/O from the critical evaluation path while ensuring reliable event capture</li>\n<li><strong>Consequences</strong>: Enables high-throughput evaluation with complete audit trails but requires queue failure handling</li>\n</ul>\n</blockquote>\n<p>The <code>FlagExposure</code> data structure captures every essential piece of information about a flag evaluation event:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>EventID</code></td>\n<td><code>string</code></td>\n<td>Unique identifier for this specific exposure event</td>\n</tr>\n<tr>\n<td><code>FlagKey</code></td>\n<td><code>FlagKey</code></td>\n<td>The flag that was evaluated</td>\n</tr>\n<tr>\n<td><code>UserID</code></td>\n<td><code>UserID</code></td>\n<td>The user who received the variant</td>\n</tr>\n<tr>\n<td><code>Variant</code></td>\n<td><code>string</code></td>\n<td>The variant key that was assigned</td>\n</tr>\n<tr>\n<td><code>Value</code></td>\n<td><code>interface{}</code></td>\n<td>The actual value returned to the application</td>\n</tr>\n<tr>\n<td><code>UserContext</code></td>\n<td><code>UserContext</code></td>\n<td>Complete user attributes and segments at evaluation time</td>\n</tr>\n<tr>\n<td><code>Timestamp</code></td>\n<td><code>time.Time</code></td>\n<td>Precise moment when evaluation occurred</td>\n</tr>\n<tr>\n<td><code>Source</code></td>\n<td><code>string</code></td>\n<td>Evaluation source (cache, database, default)</td>\n</tr>\n<tr>\n<td><code>Reason</code></td>\n<td><code>string</code></td>\n<td>Why this variant was chosen (targeting rule, percentage, fallback)</td>\n</tr>\n<tr>\n<td><code>ExperimentID</code></td>\n<td><code>string</code></td>\n<td>Experiment identifier if flag is part of A/B test</td>\n</tr>\n<tr>\n<td><code>SessionID</code></td>\n<td><code>string</code></td>\n<td>User session to group related exposures</td>\n</tr>\n<tr>\n<td><code>RequestID</code></td>\n<td><code>string</code></td>\n<td>Request context for debugging and tracing</td>\n</tr>\n</tbody></table>\n<p>The exposure tracking pipeline operates through several coordinated stages. When <code>EvaluateFlag</code> completes its variant assignment, it immediately calls <code>RecordExposure</code> with the complete evaluation result. This function packages the exposure data into a <code>FlagExposure</code> event and submits it to an asynchronous processing queue.</p>\n<p>The queue consumer operates as a separate goroutine that batches exposure events and writes them to persistent storage in configurable intervals. This design prevents individual flag evaluations from blocking on database writes while ensuring that exposure data is captured reliably even under high load.</p>\n<p>Here&#39;s how the exposure tracking flow operates:</p>\n<ol>\n<li>The evaluation engine completes a flag evaluation and produces an <code>EvaluationResult</code></li>\n<li><code>RecordExposure</code> transforms the evaluation result into a <code>FlagExposure</code> event</li>\n<li>The event is submitted to the exposure queue with a unique event ID and timestamp</li>\n<li>The queue consumer batches events (typically 100-1000 events per batch)</li>\n<li>Batched events are written to the analytics database with error retry logic</li>\n<li>Successfully persisted events are removed from the queue buffer</li>\n</ol>\n<blockquote>\n<p>The critical insight here is that exposure tracking must be completely decoupled from flag evaluation performance. A slow analytics database cannot be allowed to make feature flag evaluations slow, as this would defeat the entire purpose of having a responsive flagging system.</p>\n</blockquote>\n<p>The system maintains exposure event ordering through sequential event IDs that enable gap detection and replay capabilities. If the analytics pipeline falls behind or experiences failures, operators can identify missing event ranges and trigger replay from the persistent queue storage.</p>\n<p><strong>Aggregation and Real-time Processing</strong></p>\n<p>Raw exposure events provide the granular audit trail, but most analytics queries require aggregated views. The system maintains several real-time aggregation tables that are updated as exposure events flow through the pipeline:</p>\n<table>\n<thead>\n<tr>\n<th>Aggregation Type</th>\n<th>Granularity</th>\n<th>Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Flag Summary</td>\n<td>Flag + Day</td>\n<td>Daily exposure counts per variant</td>\n</tr>\n<tr>\n<td>User Journey</td>\n<td>User + Session</td>\n<td>User&#39;s variant assignments across flags</td>\n</tr>\n<tr>\n<td>Segment Analysis</td>\n<td>Segment + Flag + Hour</td>\n<td>How targeting rules distribute users</td>\n</tr>\n<tr>\n<td>Experiment Metrics</td>\n<td>Experiment + Variant + Hour</td>\n<td>A/B test exposure tracking</td>\n</tr>\n</tbody></table>\n<p>These aggregations enable fast dashboard queries without requiring full table scans of the raw exposure events. The aggregation logic runs as stream processing jobs that consume the same exposure event queue, ensuring consistency between raw events and summary tables.</p>\n<h3 id=\"ab-testing-framework\">A/B Testing Framework</h3>\n<p>The A/B testing framework transforms feature flags from simple configuration switches into rigorous experimental instruments. Think of <strong>experiments</strong> as controlled clinical trials for your product features. Just as medical researchers follow strict protocols to ensure their findings are statistically valid and not due to chance, the A/B testing framework provides the methodological rigor needed to distinguish genuine feature improvements from random variation.</p>\n<p>An <strong>experiment</strong> represents a formal hypothesis test where you compare user behavior across different feature variants to determine which approach produces better outcomes. The framework handles the complex statistical machinery behind the scenes while presenting a clean interface for defining experiments, tracking metrics, and interpreting results.</p>\n<blockquote>\n<p><strong>Decision: Experiment-Centric Design</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to support both simple feature flags and rigorous A/B testing</li>\n<li><strong>Options Considered</strong>: Flag-first with experiment metadata, experiment-first with flag integration, separate systems</li>\n<li><strong>Decision</strong>: Experiment-first design with automatic flag generation</li>\n<li><strong>Rationale</strong>: Ensures experimental rigor by making statistical considerations primary rather than afterthoughts</li>\n<li><strong>Consequences</strong>: More complex setup for simple flags but proper experimental design for A/B tests</li>\n</ul>\n</blockquote>\n<p>The experiment data model extends the flag system with additional statistical metadata:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>ExperimentID</code></td>\n<td><code>string</code></td>\n<td>Unique identifier for the experiment</td>\n</tr>\n<tr>\n<td><code>Name</code></td>\n<td><code>string</code></td>\n<td>Human-readable experiment name</td>\n</tr>\n<tr>\n<td><code>Hypothesis</code></td>\n<td><code>string</code></td>\n<td>Specific hypothesis being tested</td>\n</tr>\n<tr>\n<td><code>FlagKey</code></td>\n<td><code>FlagKey</code></td>\n<td>Associated feature flag for variant assignment</td>\n</tr>\n<tr>\n<td><code>Variants</code></td>\n<td><code>[]ExperimentVariant</code></td>\n<td>Available variants with allocation percentages</td>\n</tr>\n<tr>\n<td><code>PrimaryMetric</code></td>\n<td><code>string</code></td>\n<td>Key performance indicator for success measurement</td>\n</tr>\n<tr>\n<td><code>SecondaryMetrics</code></td>\n<td><code>[]string</code></td>\n<td>Additional metrics to track for insights</td>\n</tr>\n<tr>\n<td><code>StartDate</code></td>\n<td><code>time.Time</code></td>\n<td>When experiment began collecting data</td>\n</tr>\n<tr>\n<td><code>EndDate</code></td>\n<td><code>time.Time</code></td>\n<td>When experiment stopped (nil if running)</td>\n</tr>\n<tr>\n<td><code>MinSampleSize</code></td>\n<td><code>int</code></td>\n<td>Minimum users per variant for statistical power</td>\n</tr>\n<tr>\n<td><code>SignificanceLevel</code></td>\n<td><code>float64</code></td>\n<td>Required confidence level (typically 0.05)</td>\n</tr>\n<tr>\n<td><code>PowerLevel</code></td>\n<td><code>float64</code></td>\n<td>Statistical power target (typically 0.8)</td>\n</tr>\n<tr>\n<td><code>TargetingRules</code></td>\n<td><code>[]TargetingRule</code></td>\n<td>Conditions for experiment eligibility</td>\n</tr>\n<tr>\n<td><code>Status</code></td>\n<td><code>string</code></td>\n<td>Current state (draft, running, paused, completed)</td>\n</tr>\n</tbody></table>\n<p>Each <code>ExperimentVariant</code> defines a specific treatment condition within the experiment:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>Key</code></td>\n<td><code>string</code></td>\n<td>Variant identifier (control, treatment_a, treatment_b)</td>\n</tr>\n<tr>\n<td><code>Name</code></td>\n<td><code>string</code></td>\n<td>Descriptive variant name</td>\n</tr>\n<tr>\n<td><code>Description</code></td>\n<td><code>string</code></td>\n<td>What this variant implements</td>\n</tr>\n<tr>\n<td><code>Allocation</code></td>\n<td><code>float64</code></td>\n<td>Percentage of users assigned to this variant</td>\n</tr>\n<tr>\n<td><code>Configuration</code></td>\n<td><code>interface{}</code></td>\n<td>Variant-specific feature configuration</td>\n</tr>\n<tr>\n<td><code>IsControl</code></td>\n<td><code>bool</code></td>\n<td>Whether this represents the baseline condition</td>\n</tr>\n</tbody></table>\n<p><strong>Experiment Lifecycle Management</strong></p>\n<p>Experiments progress through a carefully managed lifecycle that ensures statistical validity and prevents common experimental errors:</p>\n<ol>\n<li><strong>Draft Phase</strong>: Experiment definition with power analysis and sample size calculation</li>\n<li><strong>Review Phase</strong>: Statistical review of experimental design and success metrics</li>\n<li><strong>Launch Phase</strong>: Begin user assignment and exposure tracking</li>\n<li><strong>Monitoring Phase</strong>: Real-time tracking of sample ratio mismatch and metric collection</li>\n<li><strong>Analysis Phase</strong>: Statistical significance testing and confidence interval calculation</li>\n<li><strong>Decision Phase</strong>: Determine winning variant and plan rollout or rollback</li>\n</ol>\n<p>The framework automatically enforces statistical best practices throughout this lifecycle. For example, it prevents &quot;peeking&quot; at results before reaching minimum sample sizes and warns when sample ratio mismatches indicate assignment problems.</p>\n<blockquote>\n<p>The fundamental principle of rigorous A/B testing is that experimental parameters must be locked before data collection begins. Changing success metrics, variant allocations, or targeting rules after seeing preliminary results invalidates the statistical guarantees.</p>\n</blockquote>\n<p><strong>Sample Size and Power Analysis</strong></p>\n<p>Before launching any experiment, the framework performs power analysis to determine the minimum sample size needed for reliable results. This calculation depends on several statistical parameters:</p>\n<table>\n<thead>\n<tr>\n<th>Parameter</th>\n<th>Typical Value</th>\n<th>Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Significance Level (α)</td>\n<td>0.05</td>\n<td>Maximum false positive rate</td>\n</tr>\n<tr>\n<td>Statistical Power (1-β)</td>\n<td>0.80</td>\n<td>Minimum true positive detection rate</td>\n</tr>\n<tr>\n<td>Effect Size</td>\n<td>Varies</td>\n<td>Minimum improvement worth detecting</td>\n</tr>\n<tr>\n<td>Baseline Conversion Rate</td>\n<td>Historical</td>\n<td>Current metric performance</td>\n</tr>\n</tbody></table>\n<p>The power calculation ensures that experiments run long enough to detect meaningful differences while avoiding the costs of over-powered tests. Experiments that launch without proper power analysis often either run forever without reaching conclusions or declare false victories based on insufficient data.</p>\n<p><strong>Assignment Consistency and Tracking</strong></p>\n<p>The experiment framework leverages the same consistent hashing mechanism used for percentage rollouts to ensure stable user assignment. However, experiments require additional tracking to maintain assignment consistency across the entire experiment duration.</p>\n<p>When a user first encounters an experiment flag, the system records their variant assignment in the experiment assignment table:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>ExperimentID</code></td>\n<td><code>string</code></td>\n<td>Which experiment this assignment belongs to</td>\n</tr>\n<tr>\n<td><code>UserID</code></td>\n<td><code>UserID</code></td>\n<td>The assigned user</td>\n</tr>\n<tr>\n<td><code>Variant</code></td>\n<td><code>string</code></td>\n<td>Assigned variant key</td>\n</tr>\n<tr>\n<td><code>AssignmentTime</code></td>\n<td><code>time.Time</code></td>\n<td>When assignment first occurred</td>\n</tr>\n<tr>\n<td><code>FirstExposure</code></td>\n<td><code>time.Time</code></td>\n<td>When user first saw the variant</td>\n</tr>\n<tr>\n<td><code>LastExposure</code></td>\n<td><code>time.Time</code></td>\n<td>Most recent variant exposure</td>\n</tr>\n<tr>\n<td><code>ExposureCount</code></td>\n<td><code>int</code></td>\n<td>Total number of exposures</td>\n</tr>\n</tbody></table>\n<p>This assignment persistence ensures that users see the same variant throughout the experiment duration, even if flag configurations change or targeting rules are modified. The assignment record also enables intent-to-treat analysis, which measures the effect of being assigned to a variant regardless of whether the user actually experienced it.</p>\n<h3 id=\"statistical-significance-calculation\">Statistical Significance Calculation</h3>\n<p>Statistical significance calculation transforms raw exposure and conversion data into actionable insights about which variants actually perform better. Think of <strong>significance testing</strong> as the mathematical microscope that helps you distinguish genuine improvements from random noise. Just as a microscope reveals whether an apparent difference is real cellular structure or just optical artifacts, significance testing reveals whether an apparent performance difference represents true variant superiority or just random variation.</p>\n<p>The statistical engine provides the mathematical rigor that prevents teams from making costly product decisions based on misleading data patterns. Without proper significance testing, teams often fall victim to false positives (celebrating improvements that don&#39;t exist) or false negatives (missing genuine improvements because they don&#39;t look dramatic enough).</p>\n<blockquote>\n<p><strong>Decision: Frequentist Statistical Framework</strong></p>\n<ul>\n<li><strong>Context</strong>: Need reliable statistical testing for experiment result interpretation</li>\n<li><strong>Options Considered</strong>: Frequentist hypothesis testing, Bayesian analysis, non-parametric methods</li>\n<li><strong>Decision</strong>: Classical frequentist testing with t-tests and chi-square tests</li>\n<li><strong>Rationale</strong>: Well-understood methodology with clear decision criteria and wide industry acceptance</li>\n<li><strong>Consequences</strong>: Provides definitive go/no-go decisions but requires careful interpretation of p-values</li>\n</ul>\n</blockquote>\n<p>The <code>SignificanceResult</code> data structure encapsulates the complete statistical analysis for an experiment:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>ExperimentID</code></td>\n<td><code>string</code></td>\n<td>Experiment being analyzed</td>\n</tr>\n<tr>\n<td><code>MetricName</code></td>\n<td><code>string</code></td>\n<td>Performance metric being tested</td>\n</tr>\n<tr>\n<td><code>AnalysisTime</code></td>\n<td><code>time.Time</code></td>\n<td>When this analysis was computed</td>\n</tr>\n<tr>\n<td><code>VariantResults</code></td>\n<td><code>[]VariantStatistics</code></td>\n<td>Statistical summary for each variant</td>\n</tr>\n<tr>\n<td><code>Comparisons</code></td>\n<td><code>[]PairwiseComparison</code></td>\n<td>Significance tests between variant pairs</td>\n</tr>\n<tr>\n<td><code>OverallSignificant</code></td>\n<td><code>bool</code></td>\n<td>Whether any variant shows significant difference</td>\n</tr>\n<tr>\n<td><code>RecommendedAction</code></td>\n<td><code>string</code></td>\n<td>Statistical recommendation (continue, stop, extend)</td>\n</tr>\n<tr>\n<td><code>SampleSizeAdequate</code></td>\n<td><code>bool</code></td>\n<td>Whether minimum sample requirements are met</td>\n</tr>\n<tr>\n<td><code>SampleRatioMismatch</code></td>\n<td><code>bool</code></td>\n<td>Whether variant assignments deviate from expected ratios</td>\n</tr>\n<tr>\n<td><code>ConfidenceLevel</code></td>\n<td><code>float64</code></td>\n<td>Statistical confidence level used</td>\n</tr>\n<tr>\n<td><code>AnalysisMethod</code></td>\n<td><code>string</code></td>\n<td>Statistical test applied (t-test, chi-square, etc.)</td>\n</tr>\n</tbody></table>\n<p>Each <code>VariantStatistics</code> entry provides detailed statistical measures for a single variant:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>Variant</code></td>\n<td><code>string</code></td>\n<td>Variant identifier</td>\n</tr>\n<tr>\n<td><code>SampleSize</code></td>\n<td><code>int64</code></td>\n<td>Number of users assigned to this variant</td>\n</tr>\n<tr>\n<td><code>ConversionCount</code></td>\n<td><code>int64</code></td>\n<td>Number of users who performed the target action</td>\n</tr>\n<tr>\n<td><code>ConversionRate</code></td>\n<td><code>float64</code></td>\n<td>Conversion rate (conversions / sample size)</td>\n</tr>\n<tr>\n<td><code>StandardError</code></td>\n<td><code>float64</code></td>\n<td>Standard error of the conversion rate</td>\n</tr>\n<tr>\n<td><code>ConfidenceInterval</code></td>\n<td><code>ConfidenceInterval</code></td>\n<td>Upper and lower bounds for conversion rate</td>\n</tr>\n<tr>\n<td><code>ZScore</code></td>\n<td><code>float64</code></td>\n<td>Standardized test statistic</td>\n</tr>\n<tr>\n<td><code>RelativeImprovement</code></td>\n<td><code>float64</code></td>\n<td>Percentage change from control variant</td>\n</tr>\n</tbody></table>\n<p>The <code>PairwiseComparison</code> structure captures the statistical test results between any two variants:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>VariantA</code></td>\n<td><code>string</code></td>\n<td>First variant in comparison</td>\n</tr>\n<tr>\n<td><code>VariantB</code></td>\n<td><code>string</code></td>\n<td>Second variant in comparison</td>\n</tr>\n<tr>\n<td><code>PValue</code></td>\n<td><code>float64</code></td>\n<td>Probability of observing difference by chance</td>\n</tr>\n<tr>\n<td><code>Significant</code></td>\n<td><code>bool</code></td>\n<td>Whether difference exceeds significance threshold</td>\n</tr>\n<tr>\n<td><code>TestStatistic</code></td>\n<td><code>float64</code></td>\n<td>Calculated test statistic value</td>\n</tr>\n<tr>\n<td><code>DegreesOfFreedom</code></td>\n<td><code>int</code></td>\n<td>Degrees of freedom for the test</td>\n</tr>\n<tr>\n<td><code>EffectSize</code></td>\n<td><code>float64</code></td>\n<td>Magnitude of the observed difference</td>\n</tr>\n<tr>\n<td><code>PowerAchieved</code></td>\n<td><code>float64</code></td>\n<td>Statistical power achieved with current sample sizes</td>\n</tr>\n</tbody></table>\n<p><strong>Statistical Test Selection and Execution</strong></p>\n<p>The significance calculation engine automatically selects appropriate statistical tests based on the metric type and data distribution characteristics:</p>\n<table>\n<thead>\n<tr>\n<th>Metric Type</th>\n<th>Data Distribution</th>\n<th>Statistical Test</th>\n<th>Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Conversion Rate</td>\n<td>Binomial</td>\n<td>Two-proportion z-test</td>\n<td>Compare success rates between variants</td>\n</tr>\n<tr>\n<td>Continuous Metric</td>\n<td>Normal</td>\n<td>Welch&#39;s t-test</td>\n<td>Compare means with unequal variances</td>\n</tr>\n<tr>\n<td>Count Data</td>\n<td>Poisson</td>\n<td>Chi-square goodness of fit</td>\n<td>Compare event frequencies</td>\n</tr>\n<tr>\n<td>Time-to-Event</td>\n<td>Exponential</td>\n<td>Log-rank test</td>\n<td>Compare survival curves</td>\n</tr>\n</tbody></table>\n<p>The statistical engine executes these tests through a standardized procedure:</p>\n<ol>\n<li><strong>Data Validation</strong>: Verify sample sizes meet minimum requirements and check for data quality issues</li>\n<li><strong>Assumption Testing</strong>: Validate statistical assumptions (normality, independence, equal variance)</li>\n<li><strong>Test Selection</strong>: Choose appropriate statistical test based on metric type and data characteristics</li>\n<li><strong>Calculation</strong>: Compute test statistics, p-values, and confidence intervals</li>\n<li><strong>Multiple Comparison Correction</strong>: Apply Bonferroni or FDR correction for multiple variant tests</li>\n<li><strong>Interpretation</strong>: Generate actionable recommendations based on statistical results</li>\n</ol>\n<blockquote>\n<p>The critical insight in significance testing is that statistical significance doesn&#39;t automatically imply practical significance. A tiny improvement might be statistically significant with enough data but not worth implementing given engineering costs and opportunity costs.</p>\n</blockquote>\n<p><strong>Sequential Testing and Early Stopping</strong></p>\n<p>Traditional fixed-horizon testing requires pre-determining experiment duration and sample sizes, then waiting until completion before analyzing results. However, many business contexts require the ability to stop experiments early when results become conclusive or when variants show concerning negative effects.</p>\n<p>The framework implements sequential testing procedures that allow valid statistical inference at multiple time points:</p>\n<table>\n<thead>\n<tr>\n<th>Method</th>\n<th>Use Case</th>\n<th>Advantages</th>\n<th>Limitations</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Group Sequential</td>\n<td>Pre-planned interim analyses</td>\n<td>Maintains Type I error control</td>\n<td>Requires predetermined stopping boundaries</td>\n</tr>\n<tr>\n<td>Alpha Spending</td>\n<td>Flexible interim monitoring</td>\n<td>Allows unplanned analyses</td>\n<td>More complex boundary calculations</td>\n</tr>\n<tr>\n<td>Bayesian Sequential</td>\n<td>Continuous monitoring</td>\n<td>Natural probability interpretation</td>\n<td>Requires prior specification</td>\n</tr>\n</tbody></table>\n<p>Sequential testing maintains statistical validity while providing the operational flexibility that product teams require. However, these methods require careful implementation to avoid the statistical pitfalls of repeated testing.</p>\n<p><strong>Sample Ratio Mismatch Detection</strong></p>\n<p>One of the most common sources of invalid A/B test results is sample ratio mismatch (SRM), where the observed ratio of users across variants deviates significantly from the intended allocation ratios. SRM typically indicates problems with the randomization mechanism, bot traffic, or technical implementation issues.</p>\n<p>The significance calculation engine automatically performs SRM detection using chi-square goodness-of-fit tests:</p>\n<ol>\n<li><strong>Calculate Expected Counts</strong>: Multiply total sample size by intended variant allocations</li>\n<li><strong>Compute Chi-square Statistic</strong>: Sum of (observed - expected)² / expected across all variants</li>\n<li><strong>Determine P-value</strong>: Compare test statistic to chi-square distribution</li>\n<li><strong>Flag SRM</strong>: Report mismatch if p-value falls below threshold (typically 0.001)</li>\n</ol>\n<p>When SRM is detected, the system automatically flags the experiment results as potentially invalid and recommends investigation before making product decisions based on the data.</p>\n<h3 id=\"common-pitfalls\">Common Pitfalls</h3>\n<p>⚠️ <strong>Pitfall: Peeking at Results Early</strong>\nTeams frequently check experiment results before reaching statistical significance, then stop experiments when they see favorable trends. This &quot;peeking&quot; problem dramatically inflates false positive rates because teams essentially perform multiple statistical tests without correcting for multiple comparisons. <strong>Solution</strong>: Use sequential testing methods with proper stopping boundaries, or commit to fixed experiment durations with single final analysis.</p>\n<p>⚠️ <strong>Pitfall: Ignoring Sample Ratio Mismatch</strong>\nWhen variant assignment ratios don&#39;t match the intended allocation (e.g., 45%/55% instead of 50%/50%), teams often proceed with analysis anyway, assuming the mismatch is minor. However, SRM usually indicates systematic bias in user assignment that invalidates statistical assumptions. <strong>Solution</strong>: Always check for SRM using chi-square tests and investigate the root cause before trusting experiment results.</p>\n<p>⚠️ <strong>Pitfall: Confusing Statistical and Practical Significance</strong>\nLarge sample sizes can make tiny differences statistically significant even when they&#39;re not practically meaningful. A 0.01% conversion rate improvement might have p &lt; 0.05 but generate less revenue than the engineering cost to implement. <strong>Solution</strong>: Always define minimum detectable effect sizes during experiment design and consider business impact alongside statistical significance.</p>\n<p>⚠️ <strong>Pitfall: Multiple Comparison Problems</strong>\nWhen testing multiple metrics or multiple variants simultaneously, the probability of false positives increases dramatically. Testing 20 metrics at α = 0.05 gives about a 64% chance of at least one false positive. <strong>Solution</strong>: Apply multiple comparison corrections (Bonferroni, FDR) or designate a single primary metric for decision-making with secondary metrics for insights only.</p>\n<p>⚠️ <strong>Pitfall: Survivorship Bias in Analysis</strong>\nAnalyzing only users who remained active throughout the entire experiment duration can bias results toward variants that retain users better. This survivorship bias can make harmful variants appear beneficial if they selectively retain certain user types. <strong>Solution</strong>: Use intent-to-treat analysis that includes all assigned users in the final calculation, regardless of their subsequent engagement.</p>\n<p>⚠️ <strong>Pitfall: Inconsistent Assignment Tracking</strong>\nIf user variant assignments change during an experiment (due to hash function changes, targeting rule modifications, or cache inconsistencies), the statistical analysis becomes meaningless. Users who experience multiple variants contaminate both variant groups. <strong>Solution</strong>: Persist user assignments at first exposure and enforce assignment consistency throughout the experiment duration.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The analytics and experimentation system requires careful integration of high-throughput event processing, statistical computation, and data persistence. This implementation guidance provides the foundational infrastructure needed to support production-scale A/B testing.</p>\n<p><strong>Technology Recommendations</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Event Queue</td>\n<td>Go channels with file persistence</td>\n<td>Apache Kafka or AWS Kinesis</td>\n</tr>\n<tr>\n<td>Analytics Database</td>\n<td>PostgreSQL with time-series tables</td>\n<td>ClickHouse or Apache Druid</td>\n</tr>\n<tr>\n<td>Statistical Computing</td>\n<td>Go math/stats with custom functions</td>\n<td>R integration via Rserve</td>\n</tr>\n<tr>\n<td>Real-time Aggregation</td>\n<td>In-memory maps with periodic persistence</td>\n<td>Apache Flink or Spark Streaming</td>\n</tr>\n<tr>\n<td>Dashboards</td>\n<td>Static HTML with JSON API</td>\n<td>Grafana or custom React frontend</td>\n</tr>\n</tbody></table>\n<p><strong>Recommended File Structure</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>internal/analytics/\n  exposure/\n    tracker.go              ← FlagExposure recording and queuing\n    tracker_test.go         ← Exposure tracking tests\n    aggregator.go           ← Real-time aggregation pipeline\n  experiments/\n    experiment.go           ← Experiment lifecycle management\n    experiment_test.go      ← Experiment framework tests\n    assignment.go           ← User assignment persistence\n  statistics/\n    significance.go         ← Statistical significance calculation\n    significance_test.go    ← Statistics computation tests\n    power.go                ← Sample size and power analysis\n  storage/\n    schema.sql              ← Database schema for analytics tables\n    migrations/             ← Database migration scripts</code></pre></div>\n\n<p><strong>Exposure Tracking Infrastructure</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// ExposureTracker manages the asynchronous recording of flag evaluation events</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> ExposureTracker</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    queue       </span><span style=\"color:#F97583\">chan</span><span style=\"color:#B392F0\"> FlagExposure</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    batchSize   </span><span style=\"color:#F97583\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    flushPeriod </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    storage     </span><span style=\"color:#B392F0\">ExposureStorage</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    aggregator  </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">RealTimeAggregator</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    shutdown    </span><span style=\"color:#F97583\">chan</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\">{}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    wg          </span><span style=\"color:#B392F0\">sync</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">WaitGroup</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// FlagExposure represents a single flag evaluation event for analytics</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> FlagExposure</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    EventID      </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"event_id\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    FlagKey      </span><span style=\"color:#B392F0\">FlagKey</span><span style=\"color:#9ECBFF\">     `json:\"flag_key\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    UserID       </span><span style=\"color:#B392F0\">UserID</span><span style=\"color:#9ECBFF\">      `json:\"user_id\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Variant      </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"variant\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Value        </span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{} </span><span style=\"color:#9ECBFF\">`json:\"value\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    UserContext  </span><span style=\"color:#B392F0\">UserContext</span><span style=\"color:#9ECBFF\"> `json:\"user_context\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Timestamp    </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">   `json:\"timestamp\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Source       </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"source\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Reason       </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"reason\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ExperimentID </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"experiment_id,omitempty\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    SessionID    </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"session_id,omitempty\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    RequestID    </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"request_id,omitempty\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// RecordExposure submits a flag evaluation event to the analytics pipeline</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">et </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">ExposureTracker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">RecordExposure</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">exposure</span><span style=\"color:#B392F0\"> FlagExposure</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Generate unique event ID and timestamp if not provided</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Validate exposure data (required fields, valid flag key, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Submit exposure to queue channel (non-blocking with timeout)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Return error if queue is full or tracker is shutting down</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use select with default case to avoid blocking on full queue</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// StartProcessing begins the background exposure processing pipeline</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">et </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">ExposureTracker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">StartProcessing</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Start goroutine for batch processing from queue</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Collect exposures into batches based on count and time</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Write batches to persistent storage with retry logic</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Update real-time aggregations for dashboard queries</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Handle graceful shutdown when shutdown channel is closed</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Experiment Framework Core</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// ExperimentManager handles A/B test lifecycle and statistical analysis</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> ExperimentManager</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    storage     </span><span style=\"color:#B392F0\">ExperimentStorage</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    assignments </span><span style=\"color:#B392F0\">AssignmentStorage</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    calculator  </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">SignificanceCalculator</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    mu          </span><span style=\"color:#B392F0\">sync</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">RWMutex</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Experiment represents a controlled A/B test with statistical parameters</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> Experiment</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ExperimentID      </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">              `json:\"experiment_id\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Name              </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">              `json:\"name\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Hypothesis        </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">              `json:\"hypothesis\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    FlagKey           </span><span style=\"color:#B392F0\">FlagKey</span><span style=\"color:#9ECBFF\">             `json:\"flag_key\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Variants          []</span><span style=\"color:#B392F0\">ExperimentVariant</span><span style=\"color:#9ECBFF\"> `json:\"variants\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PrimaryMetric     </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">              `json:\"primary_metric\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    SecondaryMetrics  []</span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">            `json:\"secondary_metrics\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    StartDate         </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">           `json:\"start_date\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    EndDate           </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">          `json:\"end_date,omitempty\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    MinSampleSize     </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">                 `json:\"min_sample_size\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    SignificanceLevel </span><span style=\"color:#F97583\">float64</span><span style=\"color:#9ECBFF\">             `json:\"significance_level\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PowerLevel        </span><span style=\"color:#F97583\">float64</span><span style=\"color:#9ECBFF\">             `json:\"power_level\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    TargetingRules    []</span><span style=\"color:#B392F0\">TargetingRule</span><span style=\"color:#9ECBFF\">     `json:\"targeting_rules\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Status            </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">              `json:\"status\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ExperimentVariant defines a treatment condition within an A/B test</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> ExperimentVariant</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Key           </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"key\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Name          </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"name\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Description   </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"description\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Allocation    </span><span style=\"color:#F97583\">float64</span><span style=\"color:#9ECBFF\">     `json:\"allocation\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Configuration </span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{} </span><span style=\"color:#9ECBFF\">`json:\"configuration\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    IsControl     </span><span style=\"color:#F97583\">bool</span><span style=\"color:#9ECBFF\">        `json:\"is_control\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// CreateExperiment initializes a new A/B test with statistical validation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">em </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">ExperimentManager</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">CreateExperiment</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">experiment</span><span style=\"color:#B392F0\"> Experiment</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Validate experiment configuration (allocation sum = 1.0, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Perform power analysis to determine required sample sizes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Check that associated flag exists and is compatible</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Create experiment record with \"draft\" status</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Generate experiment assignment hash seed for consistency</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// AssignUserToVariant determines which variant a user should see</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">em </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">ExperimentManager</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">AssignUserToVariant</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">experimentID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">userID</span><span style=\"color:#B392F0\"> UserID</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">context</span><span style=\"color:#B392F0\"> UserContext</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Check if user has existing assignment for this experiment</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: If no existing assignment, check experiment eligibility rules</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Use consistent hashing to assign user to variant</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Persist assignment record for consistency</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Return assigned variant key</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Statistical Significance Calculator</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// SignificanceCalculator performs statistical analysis of experiment results</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> SignificanceCalculator</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    storage </span><span style=\"color:#B392F0\">ExperimentStorage</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// SignificanceResult contains complete statistical analysis of an experiment</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> SignificanceResult</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ExperimentID        </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">                `json:\"experiment_id\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    MetricName          </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">                `json:\"metric_name\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    AnalysisTime        </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">             `json:\"analysis_time\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    VariantResults      []</span><span style=\"color:#B392F0\">VariantStatistics</span><span style=\"color:#9ECBFF\">   `json:\"variant_results\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Comparisons         []</span><span style=\"color:#B392F0\">PairwiseComparison</span><span style=\"color:#9ECBFF\">  `json:\"comparisons\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    OverallSignificant  </span><span style=\"color:#F97583\">bool</span><span style=\"color:#9ECBFF\">                  `json:\"overall_significant\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    RecommendedAction   </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">                `json:\"recommended_action\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    SampleSizeAdequate  </span><span style=\"color:#F97583\">bool</span><span style=\"color:#9ECBFF\">                  `json:\"sample_size_adequate\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    SampleRatioMismatch </span><span style=\"color:#F97583\">bool</span><span style=\"color:#9ECBFF\">                  `json:\"sample_ratio_mismatch\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ConfidenceLevel     </span><span style=\"color:#F97583\">float64</span><span style=\"color:#9ECBFF\">               `json:\"confidence_level\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    AnalysisMethod      </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">                `json:\"analysis_method\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// VariantStatistics provides detailed statistical measures for a single variant</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> VariantStatistics</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Variant              </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">            `json:\"variant\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    SampleSize           </span><span style=\"color:#F97583\">int64</span><span style=\"color:#9ECBFF\">             `json:\"sample_size\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ConversionCount      </span><span style=\"color:#F97583\">int64</span><span style=\"color:#9ECBFF\">             `json:\"conversion_count\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ConversionRate       </span><span style=\"color:#F97583\">float64</span><span style=\"color:#9ECBFF\">           `json:\"conversion_rate\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    StandardError        </span><span style=\"color:#F97583\">float64</span><span style=\"color:#9ECBFF\">           `json:\"standard_error\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ConfidenceInterval   </span><span style=\"color:#B392F0\">ConfidenceInterval</span><span style=\"color:#9ECBFF\"> `json:\"confidence_interval\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ZScore               </span><span style=\"color:#F97583\">float64</span><span style=\"color:#9ECBFF\">           `json:\"z_score\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    RelativeImprovement  </span><span style=\"color:#F97583\">float64</span><span style=\"color:#9ECBFF\">           `json:\"relative_improvement\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// CalculateSignificance performs complete statistical analysis of experiment results</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">sc </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">SignificanceCalculator</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">CalculateSignificance</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">experimentID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#B392F0\">SignificanceResult</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Retrieve experiment configuration and current sample sizes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Check for sample ratio mismatch using chi-square test</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Calculate conversion rates and confidence intervals per variant</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Perform pairwise significance tests between variants</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Apply multiple comparison corrections if needed</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Generate actionable recommendations based on results</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use z-test for conversion rate comparisons</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// DetectSampleRatioMismatch checks if variant assignments match intended ratios</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">sc </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">SignificanceCalculator</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">DetectSampleRatioMismatch</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">experimentID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">float64</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Get intended allocation ratios from experiment configuration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Count actual user assignments per variant</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Calculate expected counts based on total sample and ratios</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Compute chi-square test statistic</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Return mismatch flag and p-value</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Chi-square = Σ((observed - expected)² / expected)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Database Schema</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">sql</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">-- Flag exposure events for detailed analytics</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">CREATE</span><span style=\"color:#F97583\"> TABLE</span><span style=\"color:#B392F0\"> flag_exposures</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    event_id </span><span style=\"color:#F97583\">VARCHAR</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">36</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">PRIMARY KEY</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    flag_key </span><span style=\"color:#F97583\">VARCHAR</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">255</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">NOT NULL</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    user_id </span><span style=\"color:#F97583\">VARCHAR</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">255</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">NOT NULL</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    variant </span><span style=\"color:#F97583\">VARCHAR</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">255</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">NOT NULL</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    value</span><span style=\"color:#E1E4E8\"> JSONB,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    user_context JSONB </span><span style=\"color:#F97583\">NOT NULL</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    timestamp</span><span style=\"color:#F97583\"> TIMESTAMP WITH TIME ZONE</span><span style=\"color:#F97583\"> NOT NULL</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    source </span><span style=\"color:#F97583\">VARCHAR</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">50</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">NOT NULL</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    reason </span><span style=\"color:#F97583\">VARCHAR</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">255</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">NOT NULL</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    experiment_id </span><span style=\"color:#F97583\">VARCHAR</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">36</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    session_id </span><span style=\"color:#F97583\">VARCHAR</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">255</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    request_id </span><span style=\"color:#F97583\">VARCHAR</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">255</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    INDEX</span><span style=\"color:#E1E4E8\"> idx_flag_exposures_flag_time (flag_key, </span><span style=\"color:#F97583\">timestamp</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    INDEX</span><span style=\"color:#E1E4E8\"> idx_flag_exposures_user_time (user_id, </span><span style=\"color:#F97583\">timestamp</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    INDEX</span><span style=\"color:#E1E4E8\"> idx_flag_exposures_experiment (experiment_id, </span><span style=\"color:#F97583\">timestamp</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">-- Experiment definitions and configuration</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">CREATE</span><span style=\"color:#F97583\"> TABLE</span><span style=\"color:#B392F0\"> experiments</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    experiment_id </span><span style=\"color:#F97583\">VARCHAR</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">36</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">PRIMARY KEY</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    name</span><span style=\"color:#F97583\"> VARCHAR</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">255</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">NOT NULL</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    hypothesis </span><span style=\"color:#F97583\">TEXT</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    flag_key </span><span style=\"color:#F97583\">VARCHAR</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">255</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">NOT NULL</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    variants JSONB </span><span style=\"color:#F97583\">NOT NULL</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    primary_metric </span><span style=\"color:#F97583\">VARCHAR</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">255</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">NOT NULL</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    secondary_metrics JSONB,</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    start_date</span><span style=\"color:#F97583\"> TIMESTAMP WITH TIME ZONE</span><span style=\"color:#F97583\"> NOT NULL</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    end_date </span><span style=\"color:#F97583\">TIMESTAMP WITH TIME ZONE</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    min_sample_size </span><span style=\"color:#F97583\">INTEGER</span><span style=\"color:#F97583\"> NOT NULL</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    significance_level </span><span style=\"color:#F97583\">DECIMAL</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">4</span><span style=\"color:#E1E4E8\">,</span><span style=\"color:#79B8FF\">3</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">NOT NULL</span><span style=\"color:#F97583\"> DEFAULT</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#79B8FF\">05</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    power_level </span><span style=\"color:#F97583\">DECIMAL</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">4</span><span style=\"color:#E1E4E8\">,</span><span style=\"color:#79B8FF\">3</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">NOT NULL</span><span style=\"color:#F97583\"> DEFAULT</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#79B8FF\">8</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    targeting_rules JSONB,</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    status</span><span style=\"color:#F97583\"> VARCHAR</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">50</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">NOT NULL</span><span style=\"color:#F97583\"> DEFAULT</span><span style=\"color:#9ECBFF\"> 'draft'</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    created_at </span><span style=\"color:#F97583\">TIMESTAMP WITH TIME ZONE</span><span style=\"color:#F97583\"> DEFAULT</span><span style=\"color:#E1E4E8\"> CURRENT_TIMESTAMP,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    updated_at </span><span style=\"color:#F97583\">TIMESTAMP WITH TIME ZONE</span><span style=\"color:#F97583\"> DEFAULT</span><span style=\"color:#E1E4E8\"> CURRENT_TIMESTAMP</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">-- Persistent user variant assignments for experiments</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">CREATE</span><span style=\"color:#F97583\"> TABLE</span><span style=\"color:#B392F0\"> experiment_assignments</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    experiment_id </span><span style=\"color:#F97583\">VARCHAR</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">36</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">NOT NULL</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    user_id </span><span style=\"color:#F97583\">VARCHAR</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">255</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">NOT NULL</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    variant </span><span style=\"color:#F97583\">VARCHAR</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">255</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">NOT NULL</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    assignment_time </span><span style=\"color:#F97583\">TIMESTAMP WITH TIME ZONE</span><span style=\"color:#F97583\"> NOT NULL</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    first_exposure </span><span style=\"color:#F97583\">TIMESTAMP WITH TIME ZONE</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    last_exposure </span><span style=\"color:#F97583\">TIMESTAMP WITH TIME ZONE</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    exposure_count </span><span style=\"color:#F97583\">INTEGER</span><span style=\"color:#F97583\"> DEFAULT</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    PRIMARY KEY</span><span style=\"color:#E1E4E8\"> (experiment_id, user_id),</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    INDEX</span><span style=\"color:#E1E4E8\"> idx_assignments_experiment_variant (experiment_id, variant),</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    INDEX</span><span style=\"color:#E1E4E8\"> idx_assignments_user (user_id, assignment_time)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">);</span></span></code></pre></div>\n\n<p><strong>Milestone Checkpoint</strong></p>\n<p>After implementing the analytics and A/B testing framework:</p>\n<ol>\n<li><p><strong>Test Exposure Tracking</strong>: </p>\n<ul>\n<li>Run flag evaluations and verify exposure events appear in the database</li>\n<li>Check that exposure events contain complete context information</li>\n<li>Confirm that high evaluation throughput doesn&#39;t block on analytics</li>\n</ul>\n</li>\n<li><p><strong>Validate Experiment Assignment</strong>:</p>\n<ul>\n<li>Create an experiment with 50/50 allocation between two variants</li>\n<li>Assign 1000 test users and verify the allocation ratio is approximately correct</li>\n<li>Confirm that users receive the same variant on repeat assignments</li>\n</ul>\n</li>\n<li><p><strong>Verify Statistical Calculations</strong>:</p>\n<ul>\n<li>Generate synthetic experiment data with known effect sizes</li>\n<li>Run significance calculations and verify they detect the expected differences</li>\n<li>Test sample ratio mismatch detection with intentionally skewed allocations</li>\n</ul>\n</li>\n</ol>\n<p>Expected behavior: The system should handle thousands of exposure events per second while maintaining assignment consistency and producing accurate statistical analysis. Dashboard queries should complete in under 500ms even with millions of exposure events.</p>\n<h2 id=\"interactions-and-data-flow\">Interactions and Data Flow</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section spans all three milestones by describing the communication patterns and data flows that connect the Flag Evaluation Engine (Milestone 1), Real-time Flag Updates (Milestone 2), and Flag Analytics &amp; Experiments (Milestone 3) into a cohesive system.</p>\n</blockquote>\n<p>Think of the feature flag system as <strong>a sophisticated air traffic control tower</strong> managing multiple types of aircraft movements simultaneously. The evaluation flow is like guiding incoming flights through a series of checkpoints—checking flight credentials, runway availability, and weather conditions—before assigning them to specific gates. The update propagation flow resembles broadcasting critical weather updates or runway changes to all aircraft in the system, ensuring they adjust their flight plans in real-time. Just as air traffic control maintains constant communication between the control tower, radar systems, and aircraft, our feature flag system orchestrates seamless interactions between the management interface, evaluation engine, real-time update service, and distributed client SDKs.</p>\n<p>The interactions and data flow represent the <strong>nervous system</strong> of the feature flag platform, connecting decision-making components with data sources and ensuring consistent behavior across all system boundaries. Understanding these flows is crucial because feature flags must provide both <strong>immediate consistency</strong> for flag evaluations and <strong>eventual consistency</strong> for configuration updates, while maintaining high availability and low latency under varying load conditions.</p>\n<p>This section examines two critical interaction patterns that define the system&#39;s operational behavior: the <strong>flag evaluation flow</strong> that processes individual user requests and returns targeted variants, and the <strong>update propagation flow</strong> that distributes configuration changes across all connected clients. These flows represent the primary data pathways through which the system delivers its core value proposition of controlled feature rollouts and real-time configuration management.</p>\n<p><img src=\"/api/project/feature-flags/architecture-doc/asset?path=diagrams%2Fevaluation-flow.svg\" alt=\"Flag Evaluation Sequence\"></p>\n<p><img src=\"/api/project/feature-flags/architecture-doc/asset?path=diagrams%2Fupdate-propagation.svg\" alt=\"Flag Update Propagation\"></p>\n<h3 id=\"flag-evaluation-flow\">Flag Evaluation Flow</h3>\n<p>The flag evaluation flow represents the <strong>critical path</strong> through which user requests are processed and appropriate feature variants are assigned. This flow must operate with <strong>sub-millisecond latency</strong> while maintaining consistency guarantees and supporting complex targeting logic. Think of this process as a <strong>sophisticated sorting machine</strong> that examines each user request through multiple lenses—user attributes, segment membership, percentage allocations, and experimental assignments—before directing them to the appropriate feature experience.</p>\n<p>The evaluation flow begins when a client SDK receives a request to evaluate a specific flag for a given user context. This triggers a carefully orchestrated sequence of operations that balance <strong>performance requirements</strong> with <strong>correctness guarantees</strong>. The flow must handle scenarios ranging from simple boolean toggles to complex multi-variate experiments with intricate targeting rules, all while ensuring that users receive consistent assignments across multiple evaluations.</p>\n<p>Understanding the evaluation flow is essential for implementing proper <strong>caching strategies</strong>, <strong>fallback mechanisms</strong>, and <strong>performance optimizations</strong>. The flow also establishes the foundation for flag analytics by generating exposure events that track which users see which variants under what conditions. Every step in this flow represents a potential <strong>decision point</strong> where the system must choose between different variants, making the logic both critically important and inherently complex.</p>\n<h4 id=\"step-by-step-evaluation-process\">Step-by-Step Evaluation Process</h4>\n<p>The flag evaluation process follows a deterministic sequence that ensures consistent results while accommodating various edge cases and error conditions. Each step in this process serves a specific purpose in the overall targeting and assignment logic:</p>\n<ol>\n<li><p><strong>Request Validation and Context Preparation</strong>: The client SDK receives an evaluation request containing a <code>FlagKey</code> and <code>UserContext</code>. The SDK validates that the user context contains required fields (<code>UserID</code> is non-empty, <code>Attributes</code> map is properly formatted) and enriches the context with any cached segment memberships or computed attributes. Invalid contexts trigger immediate fallback value returns with appropriate error reasons.</p>\n</li>\n<li><p><strong>Cache Lookup and Freshness Verification</strong>: The evaluation engine attempts to retrieve the flag definition from its local cache using <code>GetFlag(flagKey)</code>. The cache lookup includes timestamp verification to ensure the cached definition hasn&#39;t exceeded its time-to-live threshold. Cache hits proceed directly to rule evaluation, while cache misses trigger background refresh operations but continue with stale data if available to maintain low latency.</p>\n</li>\n<li><p><strong>Flag Existence and Status Verification</strong>: If the flag definition is found, the engine verifies that the flag is in an active state and hasn&#39;t been archived or deleted. Inactive flags return their configured default values with an appropriate reason code. This step also checks for any flag prerequisites or dependencies that must be satisfied before evaluation can proceed.</p>\n</li>\n<li><p><strong>User Context Enrichment and Segment Resolution</strong>: The engine enhances the provided user context with any missing segment memberships by evaluating segment rules against user attributes. This step is <strong>computationally expensive</strong> but can be optimized through pre-computed segment caches or background segment resolution processes. The enriched context becomes the input for subsequent targeting rule evaluation.</p>\n</li>\n<li><p><strong>Targeting Rule Evaluation with Precedence Ordering</strong>: The engine processes targeting rules in priority order using <code>evaluateTargetingRules(rules, context)</code>. Each rule consists of conditions that are evaluated using <code>evaluateRuleConditions(conditions, operator, context)</code> with proper AND/OR logic. The first rule that matches determines the variant assignment, making rule ordering critically important for correct behavior.</p>\n</li>\n<li><p><strong>Percentage Rollout Processing with Consistent Hashing</strong>: If no targeting rules match, the engine falls back to percentage rollout logic. It calculates the user&#39;s bucket assignment using <code>calculateUserBucket(userID, flagKey)</code> and determines which variant allocation range contains that bucket. This ensures that users receive consistent assignments across multiple evaluations while respecting the configured percentage distributions.</p>\n</li>\n<li><p><strong>Variant Value Resolution and Type Coercion</strong>: Once the target variant is determined, the engine resolves the actual variant value from the flag definition. This may involve type coercion (converting stored JSON values to appropriate types), template variable substitution, or other value transformation logic depending on the flag type and configuration.</p>\n</li>\n<li><p><strong>Exposure Event Generation and Analytics Tracking</strong>: The successful evaluation triggers the creation of a <code>FlagExposure</code> event that captures all relevant context about the evaluation decision. This event is queued for asynchronous processing using <code>RecordExposure(exposure)</code> to avoid impacting evaluation latency while ensuring comprehensive analytics tracking.</p>\n</li>\n<li><p><strong>Result Packaging and Return</strong>: The engine constructs an <code>EvaluationResult</code> containing the resolved value, selected variant key, evaluation reason (which rule matched or percentage allocation), and source attribution. This result is returned to the client SDK and may be cached locally for subsequent evaluations of the same flag-user combination.</p>\n</li>\n</ol>\n<blockquote>\n<p><strong>Design Insight</strong>: The evaluation flow prioritizes <strong>deterministic behavior</strong> over performance optimization. Each step produces predictable outputs for given inputs, ensuring that debugging and troubleshooting can trace exactly why a user received a specific variant. This determinism is crucial for maintaining trust in feature rollouts and experiment validity.</p>\n</blockquote>\n<h4 id=\"caching-and-performance-optimization\">Caching and Performance Optimization</h4>\n<p>The evaluation flow incorporates <strong>multi-level caching</strong> to achieve target latency requirements while maintaining data consistency. The caching strategy must balance fresh data with performance, particularly for high-traffic applications where flag evaluations occur thousands of times per second.</p>\n<p><strong>Flag Definition Caching</strong> represents the first level of optimization, where complete flag configurations are cached in memory after retrieval from the primary data store. These caches use <strong>time-based expiration</strong> combined with <strong>event-driven invalidation</strong> to ensure reasonable freshness while avoiding excessive database queries. The cache maintains version timestamps that enable <strong>optimistic locking</strong> when updates occur.</p>\n<p><strong>User Context Caching</strong> provides the second optimization layer by storing computed segment memberships and derived attributes for frequently seen users. Since segment evaluation can be computationally expensive (requiring multiple attribute checks and rule processing), caching these results significantly improves evaluation performance. The cache uses <strong>LRU eviction</strong> to manage memory consumption while prioritizing recently active users.</p>\n<p><strong>Evaluation Result Caching</strong> represents an optional third layer where complete evaluation results are cached for specific flag-user combinations. This optimization is most effective for <strong>low-variance flags</strong> (where most users receive the same result) but must be carefully managed to avoid serving stale results when flag configurations change. Result caches require <strong>immediate invalidation</strong> when flag definitions are updated.</p>\n<p>The caching architecture includes <strong>cache warming</strong> mechanisms that pre-populate frequently accessed flags and user contexts during application startup or low-traffic periods. This warming process reduces <strong>cold start penalties</strong> and ensures consistent performance during traffic spikes.</p>\n<h4 id=\"error-handling-and-fallback-logic\">Error Handling and Fallback Logic</h4>\n<p>The evaluation flow must handle various error conditions gracefully while maintaining system availability and providing meaningful feedback for debugging purposes. The error handling strategy emphasizes <strong>fail-safe behavior</strong> where evaluation errors result in sensible default values rather than complete request failures.</p>\n<p><strong>Network and Service Failures</strong> are handled through <strong>graceful degradation</strong> where the evaluation engine continues operating with cached data even when the primary flag management service becomes unavailable. The engine maintains <strong>staleness indicators</strong> that help clients understand the freshness of cached data and make appropriate decisions about feature behavior.</p>\n<p><strong>Malformed Flag Definitions</strong> trigger <strong>validation errors</strong> that prevent the flag from being cached or evaluated, but don&#39;t impact other flags in the system. The validation process includes <strong>schema checking</strong>, <strong>circular dependency detection</strong>, and <strong>rule consistency verification</strong> to catch configuration errors before they affect user experiences.</p>\n<p><strong>User Context Errors</strong> (missing required attributes, invalid data types, or malformed segment references) are handled through <strong>context sanitization</strong> and <strong>default value substitution</strong>. The evaluation engine attempts to proceed with available context information while logging detailed error information for debugging purposes.</p>\n<p><strong>Targeting Rule Failures</strong> that occur during evaluation (such as division by zero in percentage calculations or invalid regular expressions in condition matching) cause the specific rule to be skipped and evaluation to continue with subsequent rules. This <strong>rule-level isolation</strong> prevents individual misconfigured rules from breaking entire flag evaluations.</p>\n<h4 id=\"common-pitfalls-in-evaluation-flow\">Common Pitfalls in Evaluation Flow</h4>\n<p>⚠️ <strong>Pitfall: Inconsistent User Bucket Calculations</strong>\nMany implementations suffer from <strong>bucket assignment drift</strong> where users flip between different variants due to inconsistent hashing algorithms or input normalization. This occurs when the bucketing logic uses floating-point arithmetic with rounding errors, includes unstable user attributes in the hash input, or fails to normalize string attributes consistently. To avoid this issue, use <strong>integer-based consistent hashing</strong> with stable, normalized inputs that include only the user ID and flag key. Implement comprehensive tests that verify bucket assignments remain stable across multiple evaluation calls.</p>\n<p>⚠️ <strong>Pitfall: Cache Invalidation Race Conditions</strong>\nRace conditions in cache invalidation can cause <strong>temporary inconsistencies</strong> where some evaluation requests use old flag definitions while others use updated definitions. This typically happens when cache invalidation events arrive out of order or when multiple cache layers aren&#39;t updated atomically. Implement <strong>versioned caching</strong> with <strong>optimistic concurrency control</strong> where each cache entry includes a version timestamp, and invalidation events specify the minimum version that should be evicted.</p>\n<p>⚠️ <strong>Pitfall: Context Pollution from Previous Evaluations</strong>\nReusing <code>UserContext</code> objects across multiple evaluations can lead to <strong>context pollution</strong> where computed values (like resolved segment memberships) from previous evaluations influence subsequent ones. This creates subtle bugs where flag evaluations appear to depend on the order of previous evaluations. Always <strong>deep copy</strong> or <strong>reset</strong> user context objects between evaluations, and clearly separate provided attributes from computed values.</p>\n<h3 id=\"update-propagation-flow\">Update Propagation Flow</h3>\n<p>The update propagation flow represents the <strong>distribution backbone</strong> that ensures flag configuration changes reach all connected clients promptly and consistently. Think of this flow as a <strong>sophisticated broadcast network</strong> similar to how emergency alert systems simultaneously notify all receivers of critical updates—the system must deliver messages quickly, handle network partitions gracefully, and ensure no client is left with outdated information that could impact user experiences.</p>\n<p>The update propagation flow begins when flag configurations are modified through the management interface and concludes when all connected client SDKs have applied the new configuration and invalidated relevant caches. This flow must handle scenarios ranging from simple flag toggles that need immediate deployment to complex targeting rule changes that require careful coordination across distributed client populations.</p>\n<p>The propagation flow serves as the <strong>consistency mechanism</strong> that prevents the system from exhibiting different behaviors across different clients or geographic regions. Without proper update propagation, users could experience <strong>inconsistent feature experiences</strong> where the same action produces different results depending on which server handles their request or which SDK version they&#39;re using. This consistency is particularly critical for experiment integrity and user experience quality.</p>\n<p>Understanding the update propagation flow is essential for implementing proper <strong>change management</strong>, <strong>rollback capabilities</strong>, and <strong>deployment strategies</strong>. The flow establishes the foundation for <strong>operational safety</strong> by ensuring that configuration changes can be applied, monitored, and reverted in a controlled manner across the entire distributed system.</p>\n<h4 id=\"propagation-sequence-and-timing\">Propagation Sequence and Timing</h4>\n<p>The update propagation process follows a carefully orchestrated sequence designed to minimize <strong>inconsistency windows</strong> while maintaining system performance and reliability. Each stage in the propagation process serves specific purposes in the overall change management strategy:</p>\n<ol>\n<li><p><strong>Change Validation and Staging</strong>: When a flag modification is submitted through the management API using <code>UpdateFlag(flag)</code>, the system performs comprehensive validation including schema verification, rule consistency checking, and dependency analysis. The validated change is staged in a <strong>pending state</strong> before being committed to the primary data store, allowing for additional approval workflows or automated safety checks.</p>\n</li>\n<li><p><strong>Primary Storage Update with Versioning</strong>: The validated flag configuration is committed to the primary data store with an incremented version number and change metadata. This update is performed atomically to ensure that partial updates don&#39;t create inconsistent states. The storage layer generates a <strong>change event</strong> that includes the flag key, change type (create, update, delete), and version information.</p>\n</li>\n<li><p><strong>Change Event Broadcasting via Real-time Service</strong>: The real-time update service detects the storage change and generates a <code>FlagUpdateEvent</code> that is broadcast to all connected clients using <code>BroadcastFlagUpdate(flagKey, payload, changeType)</code>. The broadcast uses <strong>Server-Sent Events</strong> or <strong>WebSocket connections</strong> to deliver the change notification with minimal latency, typically within 100-500 milliseconds of the original modification.</p>\n</li>\n<li><p><strong>Client-side Change Reception and Validation</strong>: Connected client SDKs receive the update notification through their persistent connections and validate the change event format and version information. Clients verify that the received change is newer than their current cached version to prevent <strong>regression issues</strong> where older changes overwrite newer ones due to network delays or message reordering.</p>\n</li>\n<li><p><strong>Local Cache Invalidation and Refresh</strong>: Each client SDK applies the received update using <code>ApplyFlagUpdate(event)</code>, which invalidates the locally cached flag definition and either applies the new configuration immediately or marks it for <strong>lazy loading</strong> on the next evaluation request. The invalidation process must handle <strong>concurrent evaluations</strong> that might be using the old cached data.</p>\n</li>\n<li><p><strong>Background Refresh and Verification</strong>: Clients that don&#39;t have persistent connections (such as mobile applications or batch processing systems) discover changes through <strong>background polling</strong> or <strong>SDK initialization</strong> processes. These clients compare their cached flag versions with the current server versions and fetch updated configurations as needed, ensuring eventual consistency even without real-time connections.</p>\n</li>\n<li><p><strong>Propagation Confirmation and Monitoring</strong>: The update service tracks which clients have acknowledged receipt of change notifications and maintains <strong>propagation metrics</strong> that indicate how quickly changes are spreading through the client population. This monitoring enables <strong>rollback decisions</strong> if propagation failures or adverse effects are detected during the rollout process.</p>\n</li>\n<li><p><strong>Stale Cache Detection and Cleanup</strong>: The system includes <strong>background processes</strong> that identify clients serving stale flag configurations (perhaps due to persistent connection failures or implementation bugs) and takes corrective action such as forcing cache invalidation or alerting operations teams about potentially inconsistent deployments.</p>\n</li>\n</ol>\n<blockquote>\n<p><strong>Design Insight</strong>: The propagation flow implements <strong>optimistic consistency</strong> where changes are applied immediately to the primary store and distributed asynchronously to clients. This approach minimizes <strong>write latency</strong> for flag modifications while accepting brief <strong>read inconsistency</strong> windows during propagation. The trade-off favors operational agility over perfect consistency, which aligns with feature flag use cases where brief inconsistencies are generally acceptable.</p>\n</blockquote>\n<h4 id=\"connection-management-and-message-delivery\">Connection Management and Message Delivery</h4>\n<p>The update propagation system must maintain <strong>persistent connections</strong> with potentially thousands of client SDKs while handling network instabilities, client failures, and varying connection qualities. The connection management strategy balances <strong>resource efficiency</strong> with <strong>delivery reliability</strong> to ensure that critical flag changes reach all intended recipients.</p>\n<p><strong>Connection Lifecycle Management</strong> begins when client SDKs establish connections to the real-time update service using <code>Connect(ctx)</code> with <strong>exponential backoff</strong> retry logic. Each connection is assigned a unique client identifier and tracked in the service&#39;s connection registry. The service monitors connection health through <strong>heartbeat mechanisms</strong> and <strong>activity tracking</strong> to detect failed or stale connections that should be cleaned up.</p>\n<p><strong>Message Buffering and Replay</strong> ensures that clients reconnecting after network interruptions receive any flag changes that occurred during their absence. The update service maintains a <strong>sliding window buffer</strong> of recent change events using <code>sendReplayEvents(client)</code> to deliver missed updates when clients reconnect. The buffer size and retention period are configurable based on system requirements and client reconnection patterns.</p>\n<p><strong>Delivery Confirmation and Retry Logic</strong> provides <strong>at-least-once delivery</strong> guarantees for critical flag changes. Clients send <strong>acknowledgment messages</strong> when they successfully apply flag updates, allowing the service to track delivery success rates and identify problematic connections or clients. Failed deliveries trigger <strong>retry attempts</strong> with appropriate backoff delays to avoid overwhelming struggling clients.</p>\n<p><strong>Load Balancing and Scaling</strong> accommodates varying client populations by distributing connections across multiple update service instances. The system uses <strong>consistent hashing</strong> or <strong>connection affinity</strong> strategies to ensure that clients maintain connections with specific service instances while supporting <strong>graceful failover</strong> when instances become unavailable.</p>\n<p><strong>Message Ordering and Deduplication</strong> prevents <strong>out-of-order updates</strong> that could cause clients to apply older flag configurations after newer ones. Each change event includes <strong>sequence numbers</strong> and <strong>version timestamps</strong> that clients use to detect and discard outdated messages. The system also implements <strong>deduplication logic</strong> to prevent clients from processing the same change multiple times due to retry mechanisms.</p>\n<h4 id=\"network-partition-and-recovery-handling\">Network Partition and Recovery Handling</h4>\n<p>The update propagation system must continue operating effectively during <strong>network partitions</strong>, <strong>service outages</strong>, and <strong>client isolation events</strong> that prevent normal real-time communication. The recovery handling strategy ensures that system consistency is eventually restored without requiring manual intervention or complex reconciliation procedures.</p>\n<p><strong>Partition Detection and Isolation</strong> occurs when the update service loses connectivity with client populations due to network infrastructure failures or geographic connectivity issues. The service detects these partitions through <strong>connection monitoring</strong>, <strong>heartbeat timeouts</strong>, and <strong>message delivery failure patterns</strong>. Isolated client populations continue operating with their cached flag configurations while the partition persists.</p>\n<p><strong>Autonomous Client Operation</strong> enables client SDKs to continue providing flag evaluation services using their <strong>local flag caches</strong> even when disconnected from the update service. Clients maintain <strong>cache timestamps</strong> and <strong>staleness indicators</strong> that help application code make informed decisions about whether cached flag data is still reliable for business-critical features.</p>\n<p><strong>Reconciliation After Recovery</strong> involves <strong>state synchronization</strong> processes that execute when network connectivity is restored after partition events. Clients compare their cached flag versions with current server versions using <strong>bulk version check</strong> APIs and download updated configurations for any flags that changed during the partition. This reconciliation process uses <strong>batching</strong> and <strong>rate limiting</strong> to avoid overwhelming the service during mass reconnection events.</p>\n<p><strong>Conflict Resolution and Consistency Repair</strong> addresses scenarios where <strong>configuration conflicts</strong> or <strong>inconsistent states</strong> are detected during recovery processes. The system implements <strong>server-authoritative</strong> conflict resolution where server-side flag configurations always take precedence over client-side cached data, ensuring that inconsistencies are resolved in favor of the most recent management decisions.</p>\n<p><strong>Progressive Rollout During Recovery</strong> provides <strong>controlled recovery</strong> mechanisms that gradually restore normal operation rather than immediately resuming full-scale update propagation. The service can implement <strong>traffic shaping</strong> and <strong>connection throttling</strong> to prevent <strong>thundering herd</strong> effects when large client populations attempt to reconnect simultaneously after widespread network issues.</p>\n<h4 id=\"change-impact-analysis-and-safety-mechanisms\">Change Impact Analysis and Safety Mechanisms</h4>\n<p>The update propagation flow includes <strong>safety mechanisms</strong> and <strong>impact analysis</strong> capabilities that help prevent problematic flag changes from causing widespread system issues or user experience degradation. These mechanisms provide <strong>operational safety nets</strong> that enable confident flag management even in complex, high-stakes environments.</p>\n<p><strong>Pre-propagation Impact Assessment</strong> analyzes proposed flag changes to estimate their <strong>blast radius</strong> and potential system impact before changes are propagated to client populations. This analysis considers factors such as the number of users affected, the scope of feature changes, and dependencies on other system components to help operations teams make informed rollout decisions.</p>\n<p><strong>Gradual Propagation and Circuit Breakers</strong> enable <strong>controlled rollouts</strong> where flag changes are initially propagated to small subsets of the client population before broader deployment. The system monitors <strong>error rates</strong>, <strong>performance metrics</strong>, and <strong>user experience indicators</strong> during initial propagation phases and can <strong>halt or rollback</strong> the propagation process if adverse effects are detected.</p>\n<p><strong>Automatic Rollback Triggers</strong> provide <strong>fail-safe mechanisms</strong> that automatically revert flag changes when predefined <strong>safety thresholds</strong> are exceeded. These triggers might include error rate spikes, performance degradation beyond acceptable limits, or explicit user experience metrics that indicate negative impact from the flag change.</p>\n<p><strong>Change Approval and Gating</strong> implements <strong>workflow controls</strong> that require appropriate approvals before high-impact flag changes are propagated to production client populations. The approval process can include <strong>automated testing</strong>, <strong>peer review</strong>, <strong>stakeholder sign-off</strong>, and <strong>deployment scheduling</strong> to ensure that changes are applied safely and with appropriate coordination.</p>\n<p><strong>Propagation Monitoring and Alerting</strong> provides <strong>real-time visibility</strong> into the change distribution process, enabling operations teams to detect and respond to propagation issues quickly. The monitoring includes <strong>delivery success rates</strong>, <strong>client acknowledgment patterns</strong>, <strong>error distributions</strong>, and <strong>consistency metrics</strong> that indicate the health and effectiveness of the update propagation system.</p>\n<h4 id=\"common-pitfalls-in-update-propagation\">Common Pitfalls in Update Propagation</h4>\n<p>⚠️ <strong>Pitfall: Thundering Herd During Mass Reconnection</strong>\nWhen many clients lose connectivity and then reconnect simultaneously (such as during network outages or service restarts), they can overwhelm the update service with <strong>concurrent connection attempts</strong> and <strong>bulk update requests</strong>. This creates a <strong>thundering herd effect</strong> that can cause the service to become unavailable, preventing successful reconnection and creating a cascade failure. Implement <strong>exponential backoff with jitter</strong> using <code>calculateBackoffDelay()</code> where each client waits a randomized delay before attempting reconnection, and use <strong>connection rate limiting</strong> on the server side to control the maximum concurrent connection establishment rate.</p>\n<p>⚠️ <strong>Pitfall: Message Ordering Violations During High Load</strong>\nUnder high load or during network congestion, flag update messages can arrive <strong>out of order</strong> at client SDKs, causing them to apply older flag configurations after newer ones. This creates <strong>temporal inconsistency</strong> where clients regress to previous flag states unpredictably. Implement <strong>sequence number validation</strong> where each update message includes a monotonically increasing sequence number using <code>generateEventID()</code>, and clients discard any messages with sequence numbers lower than the most recently processed message.</p>\n<p>⚠️ <strong>Pitfall: Infinite Propagation Loops from Circular Dependencies</strong>\nWhen flag changes trigger other flag changes (through computed dependencies or automated reactions), the system can enter <strong>infinite propagation loops</strong> that overwhelm the update infrastructure and prevent normal operation. This often occurs when <strong>A/B testing flags</strong> automatically trigger <strong>feature flags</strong> that in turn influence <strong>configuration flags</strong> in circular patterns. Implement <strong>propagation depth limits</strong> and <strong>change cycle detection</strong> that tracks the <strong>causal chain</strong> of flag changes and prevents updates that would create circular dependencies or exceed reasonable propagation depths.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The interactions and data flow implementation requires careful coordination between multiple system components while maintaining performance and reliability guarantees. The following guidance provides practical approaches for implementing robust evaluation and propagation flows.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Evaluation Engine</td>\n<td>In-memory map with RWMutex (sync.RWMutex)</td>\n<td>Distributed cache with Redis Cluster</td>\n</tr>\n<tr>\n<td>Real-time Updates</td>\n<td>Server-Sent Events with net/http</td>\n<td>WebSocket with gorilla/websocket + message queuing</td>\n</tr>\n<tr>\n<td>Message Serialization</td>\n<td>JSON with encoding/json</td>\n<td>Protocol Buffers with gogo/protobuf</td>\n</tr>\n<tr>\n<td>Connection Management</td>\n<td>Basic HTTP keepalive</td>\n<td>Connection pooling with circuit breakers</td>\n</tr>\n<tr>\n<td>Event Streaming</td>\n<td>Simple broadcast to all clients</td>\n<td>Pub/sub with message persistence (NATS, Apache Kafka)</td>\n</tr>\n<tr>\n<td>Cache Layer</td>\n<td>Local in-memory cache</td>\n<td>Multi-tier with Redis + local LRU</td>\n</tr>\n<tr>\n<td>Metrics Collection</td>\n<td>Basic counters with expvar</td>\n<td>Prometheus metrics with custom collectors</td>\n</tr>\n<tr>\n<td>Background Processing</td>\n<td>Simple goroutines</td>\n<td>Worker pool with github.com/gammazero/workerpool</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>internal/\n  evaluation/\n    engine.go              ← Core evaluation logic\n    engine_test.go         ← Evaluation flow tests\n    cache.go               ← Multi-level caching implementation\n    context.go             ← User context handling\n    bucket.go              ← Consistent hashing logic\n  realtime/\n    server.go              ← SSE/WebSocket server\n    client.go              ← Client connection management\n    broadcast.go           ← Update propagation logic\n    reconnect.go           ← Recovery and retry logic\n  analytics/\n    tracker.go             ← Exposure event tracking\n    aggregator.go          ← Real-time metrics aggregation\n  flows/\n    evaluation_flow.go     ← Complete evaluation orchestration\n    propagation_flow.go    ← Update distribution coordination\n    flows_test.go          ← Integration tests for complete flows</code></pre></div>\n\n<h4 id=\"evaluation-flow-infrastructure\">Evaluation Flow Infrastructure</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> flows</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">context</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">fmt</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">sync</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">github.com/your-org/flagsystem/internal/evaluation</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">github.com/your-org/flagsystem/internal/analytics</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// EvaluationOrchestrator coordinates the complete flag evaluation flow</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> EvaluationOrchestrator</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    engine       </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">evaluation</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Engine</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cache        </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">evaluation</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">FlagCache</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    tracker      </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">analytics</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">ExposureTracker</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    validator    </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">evaluation</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">ContextValidator</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    mu           </span><span style=\"color:#B392F0\">sync</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">RWMutex</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    metrics      </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">EvaluationMetrics</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// EvaluationMetrics tracks performance and behavior of evaluation flows</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> EvaluationMetrics</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    TotalEvaluations    </span><span style=\"color:#F97583\">int64</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CacheHits          </span><span style=\"color:#F97583\">int64</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CacheMisses        </span><span style=\"color:#F97583\">int64</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    EvaluationLatency  </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ErrorCount         </span><span style=\"color:#F97583\">int64</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    mu                 </span><span style=\"color:#B392F0\">sync</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">RWMutex</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// NewEvaluationOrchestrator creates a complete evaluation flow handler</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewEvaluationOrchestrator</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">engine</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">evaluation</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Engine</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">cache</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">evaluation</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">FlagCache</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">tracker</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">analytics</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">ExposureTracker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">EvaluationOrchestrator</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">EvaluationOrchestrator</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        engine:    engine,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        cache:     cache,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        tracker:   tracker,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        validator: evaluation.</span><span style=\"color:#B392F0\">NewContextValidator</span><span style=\"color:#E1E4E8\">(),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        metrics:   </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#B392F0\">EvaluationMetrics</span><span style=\"color:#E1E4E8\">{},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ProcessEvaluationRequest handles the complete evaluation flow from request to response</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">e </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">EvaluationOrchestrator</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">ProcessEvaluationRequest</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">flagKey</span><span style=\"color:#B392F0\"> FlagKey</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">userCtx</span><span style=\"color:#B392F0\"> UserContext</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">EvaluationResult</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    startTime </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> time.</span><span style=\"color:#B392F0\">Now</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#F97583\"> func</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        e.metrics.mu.</span><span style=\"color:#B392F0\">Lock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        e.metrics.TotalEvaluations</span><span style=\"color:#F97583\">++</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        e.metrics.EvaluationLatency </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.</span><span style=\"color:#B392F0\">Since</span><span style=\"color:#E1E4E8\">(startTime)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        e.metrics.mu.</span><span style=\"color:#B392F0\">Unlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Validate user context using e.validator.ValidateUserContext(userCtx)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Attempt cache lookup using e.cache.GetFlag(flagKey)  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: If cache miss, fetch from primary store and update cache</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Enrich user context with segment memberships</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Execute core evaluation using e.engine.EvaluateFlag(flagKey, enrichedCtx)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Generate exposure event and queue using e.tracker.RecordExposure()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Update evaluation metrics and return result</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Placeholder return - implement the actual flow</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">EvaluationResult</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        FlagKey: flagKey,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Value:   </span><span style=\"color:#79B8FF\">false</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Variant: </span><span style=\"color:#9ECBFF\">\"default\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Reason:  </span><span style=\"color:#9ECBFF\">\"not_implemented\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Source:  </span><span style=\"color:#9ECBFF\">\"cache\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }, </span><span style=\"color:#79B8FF\">nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"real-time-update-infrastructure\">Real-time Update Infrastructure</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> realtime</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">encoding/json</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">fmt</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">net/http</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">sync</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// UpdatePropagationService manages the complete update distribution flow</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> UpdatePropagationService</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    sseServer     </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">SSEServer</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    clients       </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">ClientConnection</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    eventBuffer   []</span><span style=\"color:#B392F0\">FlagUpdateEvent</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    bufferSize    </span><span style=\"color:#F97583\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    mu            </span><span style=\"color:#B392F0\">sync</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">RWMutex</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    metrics       </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">PropagationMetrics</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// PropagationMetrics tracks update distribution performance</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> PropagationMetrics</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ActiveConnections    </span><span style=\"color:#F97583\">int64</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    MessagesSent        </span><span style=\"color:#F97583\">int64</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    DeliveryFailures    </span><span style=\"color:#F97583\">int64</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ReconnectionCount   </span><span style=\"color:#F97583\">int64</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PropagationLatency  </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ClientConnection represents a connected SDK client</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> ClientConnection</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ID            </span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LastSeen      </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Connection    </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">SSEClient</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PendingAcks   </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    mu            </span><span style=\"color:#B392F0\">sync</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Mutex</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// NewUpdatePropagationService creates the complete propagation flow handler</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewUpdatePropagationService</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">bufferSize</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">UpdatePropagationService</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">UpdatePropagationService</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        sseServer:   </span><span style=\"color:#B392F0\">NewSSEServer</span><span style=\"color:#E1E4E8\">(),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        clients:     </span><span style=\"color:#B392F0\">make</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">ClientConnection</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        eventBuffer: </span><span style=\"color:#B392F0\">make</span><span style=\"color:#E1E4E8\">([]</span><span style=\"color:#B392F0\">FlagUpdateEvent</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, bufferSize),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        bufferSize:  bufferSize,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        metrics:     </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#B392F0\">PropagationMetrics</span><span style=\"color:#E1E4E8\">{},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// PropagateChange handles the complete flow from flag change to client delivery</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">u </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">UpdatePropagationService</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">PropagateChange</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">flagKey</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">changeType</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">payload</span><span style=\"color:#F97583\"> interface</span><span style=\"color:#E1E4E8\">{}) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    startTime </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> time.</span><span style=\"color:#B392F0\">Now</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Create FlagUpdateEvent with unique ID and timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Add event to buffer for replay to reconnecting clients</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Broadcast to all active connections using u.sseServer.BroadcastFlagUpdate()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Track delivery confirmations and retry failed deliveries</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Update propagation metrics with timing and success rates</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Handle buffer overflow by removing oldest events</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    event </span><span style=\"color:#F97583\">:=</span><span style=\"color:#B392F0\"> FlagUpdateEvent</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        EventType:   </span><span style=\"color:#9ECBFF\">\"flag_update\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        EventID:     u.</span><span style=\"color:#B392F0\">generateEventID</span><span style=\"color:#E1E4E8\">(),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Timestamp:   time.</span><span style=\"color:#B392F0\">Now</span><span style=\"color:#E1E4E8\">(),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        FlagKey:     flagKey,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Payload:     payload,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ChangeType:  changeType,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Placeholder implementation - complete the propagation logic</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    u.mu.</span><span style=\"color:#B392F0\">Lock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> u.mu.</span><span style=\"color:#B392F0\">Unlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    u.eventBuffer </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> append</span><span style=\"color:#E1E4E8\">(u.eventBuffer, event)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    u.metrics.PropagationLatency </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.</span><span style=\"color:#B392F0\">Since</span><span style=\"color:#E1E4E8\">(startTime)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// HandleClientConnection manages the complete connection lifecycle</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">u </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">UpdatePropagationService</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">HandleClientConnection</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">w</span><span style=\"color:#B392F0\"> http</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">ResponseWriter</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">r</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">http</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Request</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    clientID </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> r.Header.</span><span style=\"color:#B392F0\">Get</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Client-ID\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> clientID </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        http.</span><span style=\"color:#B392F0\">Error</span><span style=\"color:#E1E4E8\">(w, </span><span style=\"color:#9ECBFF\">\"Client-ID header required\"</span><span style=\"color:#E1E4E8\">, http.StatusBadRequest)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Establish SSE connection with proper headers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Register client in connection registry</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Send buffered events for any missed updates</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Start heartbeat monitoring for connection health</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Handle connection cleanup on client disconnect</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Placeholder - implement complete connection handling</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    fmt.</span><span style=\"color:#B392F0\">Fprintf</span><span style=\"color:#E1E4E8\">(w, </span><span style=\"color:#9ECBFF\">\"data: {</span><span style=\"color:#79B8FF\">\\\"</span><span style=\"color:#9ECBFF\">type</span><span style=\"color:#79B8FF\">\\\"</span><span style=\"color:#9ECBFF\">:</span><span style=\"color:#79B8FF\">\\\"</span><span style=\"color:#9ECBFF\">connected</span><span style=\"color:#79B8FF\">\\\"</span><span style=\"color:#9ECBFF\">,</span><span style=\"color:#79B8FF\">\\\"</span><span style=\"color:#9ECBFF\">client_id</span><span style=\"color:#79B8FF\">\\\"</span><span style=\"color:#9ECBFF\">:</span><span style=\"color:#79B8FF\">\\\"%s\\\"</span><span style=\"color:#9ECBFF\">}</span><span style=\"color:#79B8FF\">\\n\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, clientID)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">u </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">UpdatePropagationService</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">generateEventID</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Implement monotonic event ID generation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Sprintf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, time.</span><span style=\"color:#B392F0\">Now</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#B392F0\">UnixNano</span><span style=\"color:#E1E4E8\">())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"core-evaluation-logic-skeleton\">Core Evaluation Logic Skeleton</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> evaluation</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Engine implements the core flag evaluation logic with caching and consistency</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> Engine</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    storage   </span><span style=\"color:#B392F0\">FlagStorage</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cache     </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FlagCache</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    hasher    </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">ConsistentHasher</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    validator </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">ContextValidator</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// EvaluateFlag processes the complete evaluation flow for a single flag</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">e </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Engine</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">EvaluateFlag</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">flagKey</span><span style=\"color:#B392F0\"> FlagKey</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">context</span><span style=\"color:#B392F0\"> UserContext</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">EvaluationResult</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Retrieve flag definition from cache or storage</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Validate flag is active and not archived</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Check for prerequisite flag dependencies</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Enrich context with computed segment memberships</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Evaluate targeting rules in priority order</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Fall back to percentage rollout if no rules match</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Resolve variant value and perform type coercion</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 8: Return comprehensive evaluation result with reason</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#B392F0\"> EvaluationResult</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        FlagKey: flagKey,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Value:   </span><span style=\"color:#79B8FF\">nil</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Variant: </span><span style=\"color:#9ECBFF\">\"default\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Reason:  </span><span style=\"color:#9ECBFF\">\"not_implemented\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Source:  </span><span style=\"color:#9ECBFF\">\"engine\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// evaluateTargetingRules processes rules with proper precedence and logic</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">e </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Engine</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">evaluateTargetingRules</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">rules</span><span style=\"color:#E1E4E8\"> []</span><span style=\"color:#B392F0\">TargetingRule</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">context</span><span style=\"color:#B392F0\"> UserContext</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{}, </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Sort rules by priority (highest first)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Iterate through rules and evaluate conditions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: For matching rule, return its variant and value</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Handle AND/OR logic properly within rule conditions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Return detailed reason for debugging</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">nil</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"no_matching_rules\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">false</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// calculateUserBucket provides consistent user assignment to percentage buckets</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">e </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Engine</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">calculateUserBucket</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">userID</span><span style=\"color:#B392F0\"> UserID</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">flagKey</span><span style=\"color:#B392F0\"> FlagKey</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Create hash input from userID and flagKey</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Apply consistent hashing algorithm</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Convert hash to bucket number (0-99)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Ensure deterministic results for same inputs</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#6A737D\"> // Placeholder</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoint-evaluation-flow\">Milestone Checkpoint: Evaluation Flow</h4>\n<p>After implementing the evaluation flow, verify the following behavior:</p>\n<p><strong>Test Command</strong>: <code>go test ./internal/flows/ -v -run TestEvaluationFlow</code></p>\n<p><strong>Expected Behavior</strong>:</p>\n<ul>\n<li>Flag evaluations complete within 5ms for cached flags</li>\n<li>User bucket assignments remain stable across multiple evaluations</li>\n<li>Targeting rules are evaluated in correct priority order</li>\n<li>Cache hits/misses are properly tracked and reported</li>\n<li>Exposure events are generated for all successful evaluations</li>\n</ul>\n<p><strong>Manual Verification</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Start the flag service</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> run</span><span style=\"color:#9ECBFF\"> cmd/server/main.go</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test flag evaluation endpoint</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">curl</span><span style=\"color:#79B8FF\"> -X</span><span style=\"color:#9ECBFF\"> POST</span><span style=\"color:#9ECBFF\"> http://localhost:8080/api/v1/evaluate</span><span style=\"color:#79B8FF\"> \\</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">  -H</span><span style=\"color:#9ECBFF\"> \"Content-Type: application/json\"</span><span style=\"color:#79B8FF\"> \\</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">  -d</span><span style=\"color:#9ECBFF\"> '{</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"flag_key\": \"test-flag\",</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"user_context\": {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">      \"user_id\": \"user123\",</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">      \"attributes\": {\"beta_user\": true}</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    }</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">  }'</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected response includes variant, value, and evaluation reason</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Check logs for exposure event generation</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoint-update-propagation\">Milestone Checkpoint: Update Propagation</h4>\n<p>After implementing the update propagation flow, verify the following behavior:</p>\n<p><strong>Test Command</strong>: <code>go test ./internal/realtime/ -v -run TestPropagation</code></p>\n<p><strong>Expected Behavior</strong>:</p>\n<ul>\n<li>Flag changes propagate to connected clients within 500ms</li>\n<li>Clients reconnect automatically after network interruptions</li>\n<li>Buffered events are replayed to reconnecting clients</li>\n<li>Connection counts and delivery metrics are accurate</li>\n<li>No message duplication or ordering violations occur</li>\n</ul>\n<p><strong>Manual Verification</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Start update service and connect test client</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> run</span><span style=\"color:#9ECBFF\"> cmd/server/main.go</span><span style=\"color:#E1E4E8\"> &#x26;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> run</span><span style=\"color:#9ECBFF\"> examples/test-client/main.go</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Update a flag through management API</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">curl</span><span style=\"color:#79B8FF\"> -X</span><span style=\"color:#9ECBFF\"> PUT</span><span style=\"color:#9ECBFF\"> http://localhost:8080/api/v1/flags/test-flag</span><span style=\"color:#79B8FF\"> \\</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">  -H</span><span style=\"color:#9ECBFF\"> \"Content-Type: application/json\"</span><span style=\"color:#79B8FF\"> \\</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">  -d</span><span style=\"color:#9ECBFF\"> '{\"enabled\": true, \"variants\": [...]}'</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Verify client receives update within 500ms</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test reconnection by restarting client</span></span></code></pre></div>\n\n<h4 id=\"debugging-tips\">Debugging Tips</h4>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Users flip between variants</td>\n<td>Inconsistent bucket calculation</td>\n<td>Check hash inputs and normalization</td>\n<td>Use stable, normalized user ID and flag key only</td>\n</tr>\n<tr>\n<td>Flag updates take minutes to propagate</td>\n<td>Connection failures or buffering issues</td>\n<td>Check SSE connection health and event buffer</td>\n<td>Implement connection monitoring and retry logic</td>\n</tr>\n<tr>\n<td>Evaluation errors during flag updates</td>\n<td>Cache invalidation race conditions</td>\n<td>Check concurrent access to cache during updates</td>\n<td>Use versioned caching with proper locking</td>\n</tr>\n<tr>\n<td>High evaluation latency</td>\n<td>Cache misses or expensive segment resolution</td>\n<td>Monitor cache hit rates and segment computation time</td>\n<td>Implement cache warming and segment pre-computation</td>\n</tr>\n<tr>\n<td>Missing exposure events</td>\n<td>Async queue overflows or processing failures</td>\n<td>Check exposure queue depths and error logs</td>\n<td>Implement backpressure and queue monitoring</td>\n</tr>\n</tbody></table>\n<h2 id=\"error-handling-and-edge-cases\">Error Handling and Edge Cases</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section applies to all three milestones by ensuring robust error handling and graceful degradation across the Flag Evaluation Engine (Milestone 1), Real-time Flag Updates (Milestone 2), and Flag Analytics &amp; Experiments (Milestone 3).</p>\n</blockquote>\n<p>Think of error handling in feature flag systems like building a suspension bridge with multiple safety systems. Just as bridges have primary cables, backup cables, and emergency procedures for various failure scenarios, feature flag systems require layered safety mechanisms. When the primary evaluation service fails, the system should seamlessly fall back to cached data. When the real-time update connection drops, clients should continue operating with their last known state while attempting reconnection. When analytics services are unavailable, flag evaluations should continue uninterrupted. The key insight is that feature flags control critical business functionality, so the system must be designed to fail gracefully rather than catastrophically.</p>\n<p>Building a resilient feature flag system requires anticipating every possible failure mode and designing appropriate responses. Unlike traditional applications where failures might cause user-facing errors, feature flag failures can silently corrupt A/B test results, cause inconsistent user experiences, or even break critical business features. The challenge is maintaining system reliability while preserving the performance characteristics that make feature flags practical for high-traffic applications.</p>\n<h3 id=\"fallback-and-degradation-strategies\">Fallback and Degradation Strategies</h3>\n<p>The foundation of resilient feature flag systems lies in <strong>graceful degradation</strong> - the ability to provide reduced but functional service when components fail. This requires establishing clear fallback hierarchies and ensuring that each layer can operate independently when upstream dependencies become unavailable.</p>\n<blockquote>\n<p><strong>Decision: Multi-Layer Fallback Architecture</strong></p>\n<ul>\n<li><strong>Context</strong>: Feature flag evaluations must continue even when various system components fail, but maintaining consistency and performance during degradation is challenging</li>\n<li><strong>Options Considered</strong>: Single cache fallback, distributed cache with local backup, hierarchical fallback with offline capability</li>\n<li><strong>Decision</strong>: Implement hierarchical fallback with memory cache, local storage, and hardcoded defaults</li>\n<li><strong>Rationale</strong>: Provides maximum availability while maintaining predictable performance characteristics and allowing for offline operation</li>\n<li><strong>Consequences</strong>: Increases complexity but ensures evaluation requests never fail completely, though may serve stale data during extended outages</li>\n</ul>\n</blockquote>\n<p>The fallback hierarchy follows a clear precedence order that balances freshness with availability:</p>\n<table>\n<thead>\n<tr>\n<th>Fallback Level</th>\n<th>Data Source</th>\n<th>Freshness</th>\n<th>Availability</th>\n<th>Latency</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Primary</td>\n<td>Flag Management API</td>\n<td>Real-time</td>\n<td>Network dependent</td>\n<td>50-200ms</td>\n</tr>\n<tr>\n<td>Secondary</td>\n<td>Memory Cache</td>\n<td>Minutes old</td>\n<td>High</td>\n<td>&lt;1ms</td>\n</tr>\n<tr>\n<td>Tertiary</td>\n<td>Local Storage</td>\n<td>Hours old</td>\n<td>Very High</td>\n<td>1-5ms</td>\n</tr>\n<tr>\n<td>Ultimate</td>\n<td>Default Values</td>\n<td>Static</td>\n<td>Guaranteed</td>\n<td>&lt;1ms</td>\n</tr>\n</tbody></table>\n<p><strong>Memory Cache Fallback Strategy</strong></p>\n<p>When the primary Flag Management API becomes unavailable, the evaluation engine immediately switches to its in-memory cache. This cache maintains a complete copy of all flag definitions with their targeting rules and variant configurations. The cache includes metadata about when each flag was last updated, allowing the system to make informed decisions about data freshness.</p>\n<p>The memory cache fallback operates transparently to client applications. Flag evaluations continue with identical response formats and performance characteristics. However, the <code>EvaluationResult</code> includes a <code>Source</code> field that indicates &quot;cache&quot; rather than &quot;api&quot;, allowing downstream systems to understand they may be receiving stale data.</p>\n<p>Cache invalidation during fallback mode presents unique challenges. Since the system cannot receive real-time updates from the management API, it must implement intelligent cache refresh strategies. The system attempts periodic background refreshes with exponential backoff, but never blocks evaluation requests on these refresh attempts.</p>\n<p><strong>Local Storage Persistence</strong></p>\n<p>For extended outages that exceed memory cache retention policies, the system falls back to persistent local storage. This storage layer maintains a complete snapshot of flag definitions along with evaluation metadata. The local storage uses a simple key-value structure where flag keys map to serialized <code>FlagDefinition</code> objects.</p>\n<p>Local storage fallback occurs automatically when memory cache misses indicate that cached data has been evicted. The system logs these fallback events with appropriate severity levels to alert operations teams about degraded service quality. Despite using local storage, evaluation performance remains acceptable because modern storage systems provide sub-millisecond read access for small objects.</p>\n<p>The local storage layer requires careful consideration of disk space management. Flag definitions can accumulate over time, especially for systems managing thousands of flags across multiple environments. The system implements a least-recently-used eviction policy that maintains the most actively evaluated flags while removing obsolete definitions.</p>\n<p><strong>Default Value Resolution</strong></p>\n<p>The ultimate fallback mechanism relies on default values embedded directly in flag definitions. These defaults are hardcoded values that require no external dependencies and guarantee that evaluation requests never fail completely. Default values represent the &quot;safe&quot; configuration - typically the existing behavior before a feature flag was introduced.</p>\n<p>Default value fallback must be carefully designed to avoid breaking critical business functionality. For boolean flags controlling new features, the default should typically be <code>false</code> to maintain existing behavior. For configuration flags that modify system parameters, defaults should represent well-tested values that maintain system stability.</p>\n<p>The system provides clear visibility into default value usage through comprehensive logging and metrics. When evaluations fall back to default values, this indicates a significant service degradation that requires immediate attention. Operations teams should treat extended default value usage as a high-priority incident.</p>\n<p><strong>Fallback Decision Logic</strong></p>\n<p>The fallback decision process follows a deterministic algorithm that ensures consistent behavior across all system components:</p>\n<ol>\n<li><strong>Primary Evaluation Attempt</strong>: The system first attempts to retrieve the flag definition from the Flag Management API with a short timeout (typically 100-200ms)</li>\n<li><strong>Connection Health Check</strong>: If the API request fails, the system checks connection health metrics to distinguish between temporary network issues and service outages</li>\n<li><strong>Cache Consultation</strong>: For failed API requests, the system immediately checks the memory cache for a cached flag definition</li>\n<li><strong>Freshness Assessment</strong>: If cached data exists, the system evaluates whether the data is fresh enough based on configured staleness tolerance</li>\n<li><strong>Local Storage Query</strong>: For cache misses or excessively stale data, the system queries persistent local storage</li>\n<li><strong>Default Value Selection</strong>: If no stored data is available, the system returns the hardcoded default value from the flag definition</li>\n<li><strong>Circuit Breaker Update</strong>: The system updates circuit breaker state based on the success or failure of each fallback attempt</li>\n</ol>\n<p><strong>Performance During Degradation</strong></p>\n<p>Maintaining acceptable performance during degraded operation requires careful attention to timeout configuration and resource management. The system uses aggressive timeouts for fallback decisions to prevent cascade failures where slow upstream services cause downstream performance degradation.</p>\n<p>Circuit breakers play a crucial role in performance preservation. Once a circuit breaker opens due to repeated API failures, the system immediately routes evaluation requests to cached data without attempting API calls. This prevents the accumulated latency of failed network requests from affecting user-facing performance.</p>\n<p>Resource isolation ensures that fallback mechanisms don&#39;t compete with primary evaluation paths for system resources. Memory caches use separate allocation pools from real-time processing, and local storage operations use dedicated I/O queues that don&#39;t interfere with network communication.</p>\n<p><strong>Consistency Guarantees During Fallback</strong></p>\n<p>While fallback mechanisms prioritize availability over consistency, the system provides clear guarantees about what level of consistency clients can expect during degraded operation. These guarantees help application developers make appropriate decisions about feature flag usage in critical code paths.</p>\n<p>During memory cache fallback, the system guarantees that all evaluation requests for the same user context will return identical results within the cache retention window. This ensures that user experiences remain consistent even during service outages.</p>\n<p>Local storage fallback provides weaker consistency guarantees because data may be hours or days old. However, the system guarantees that it will return the same result for identical evaluation requests until fresh data becomes available. This prevents situations where users experience inconsistent behavior due to non-deterministic fallback logic.</p>\n<p>Default value fallback provides the strongest consistency guarantee - all evaluation requests for a given flag will return identical results regardless of system state. This predictability allows applications to implement critical business logic with confidence that behavior will remain consistent during outages.</p>\n<p><img src=\"/api/project/feature-flags/architecture-doc/asset?path=diagrams%2Ferror-handling-flow.svg\" alt=\"Error Handling and Fallback Flow\"></p>\n<h3 id=\"edge-cases-and-corner-scenarios\">Edge Cases and Corner Scenarios</h3>\n<p>Feature flag systems encounter numerous edge cases that can cause subtle bugs or system instability if not handled properly. These scenarios often arise from the complex interactions between targeting rules, user contexts, and system constraints under unusual operating conditions.</p>\n<p><strong>Malformed Targeting Rules</strong></p>\n<p>Invalid or malformed targeting rules represent one of the most common edge cases in feature flag systems. These can result from manual configuration errors, automated rule generation bugs, or data corruption during storage or transmission.</p>\n<p>The system must validate all rule components during flag definition creation and updates. Rule validation includes checking operator compatibility with attribute types, ensuring percentage allocations sum to valid ranges, and verifying that referenced user segments exist in the system.</p>\n<table>\n<thead>\n<tr>\n<th>Validation Type</th>\n<th>Check Description</th>\n<th>Error Response</th>\n<th>Recovery Action</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Operator Compatibility</td>\n<td>Ensure operators match attribute types</td>\n<td>Return validation error</td>\n<td>Reject flag update</td>\n</tr>\n<tr>\n<td>Percentage Range</td>\n<td>Verify allocations are 0-100%</td>\n<td>Return validation error</td>\n<td>Apply automatic normalization</td>\n</tr>\n<tr>\n<td>Segment References</td>\n<td>Check referenced segments exist</td>\n<td>Return validation error</td>\n<td>Remove invalid references</td>\n</tr>\n<tr>\n<td>Circular Dependencies</td>\n<td>Detect prerequisite cycles</td>\n<td>Return validation error</td>\n<td>Reject flag update</td>\n</tr>\n<tr>\n<td>Rule Complexity</td>\n<td>Limit nested condition depth</td>\n<td>Return validation error</td>\n<td>Flatten rule structure</td>\n</tr>\n</tbody></table>\n<p>When malformed rules are detected during evaluation rather than creation, the system applies safe fallback behavior. Rather than throwing exceptions that could break application functionality, the evaluation engine logs detailed error information and returns default values with clear indication of the evaluation failure in the response metadata.</p>\n<p><strong>Circular Flag Dependencies</strong></p>\n<p>Feature flags can reference other flags as prerequisites, creating dependency relationships that must be evaluated in proper order. Circular dependencies occur when flags reference each other either directly (A depends on B, B depends on A) or indirectly through longer chains (A→B→C→A).</p>\n<p>Circular dependency detection uses depth-first search traversal of the flag dependency graph during flag creation and update operations. The system maintains an in-memory representation of all flag dependencies and validates that new dependency additions don&#39;t create cycles.</p>\n<p>The detection algorithm maintains a visited set and a recursion stack during graph traversal:</p>\n<ol>\n<li><strong>Initialize Traversal</strong>: Start from the flag being updated and mark it as visited</li>\n<li><strong>Follow Dependencies</strong>: For each prerequisite flag, recursively traverse its dependencies</li>\n<li><strong>Cycle Detection</strong>: If a flag is encountered that&#39;s already in the current recursion stack, a cycle exists</li>\n<li><strong>Path Recording</strong>: Maintain the dependency path to provide detailed error messages about cycle location</li>\n<li><strong>Validation Result</strong>: Return success only if no cycles are detected in the complete dependency graph</li>\n</ol>\n<p>When cycles are detected during flag updates, the system rejects the update with detailed error information including the complete cycle path. This helps flag administrators understand the dependency chain that would be violated and make appropriate corrections.</p>\n<p><strong>Extreme Load Conditions</strong></p>\n<p>High-traffic applications can generate evaluation request volumes that exceed normal system capacity, especially during traffic spikes or when new flags are introduced that affect large user populations. The system must maintain functionality and prevent cascade failures under these extreme conditions.</p>\n<p>Load shedding mechanisms activate when evaluation request rates exceed configured thresholds. Rather than accepting all requests and potentially causing system-wide failures, the system selectively drops requests using consistent criteria that minimize impact on critical functionality.</p>\n<table>\n<thead>\n<tr>\n<th>Load Level</th>\n<th>Threshold</th>\n<th>Response Strategy</th>\n<th>Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Normal</td>\n<td>&lt;1000 req/sec</td>\n<td>Standard evaluation</td>\n<td>No impact</td>\n</tr>\n<tr>\n<td>Elevated</td>\n<td>1000-5000 req/sec</td>\n<td>Enable additional caching</td>\n<td>Slight staleness increase</td>\n</tr>\n<tr>\n<td>High</td>\n<td>5000-10000 req/sec</td>\n<td>Aggressive cache utilization</td>\n<td>Moderate staleness</td>\n</tr>\n<tr>\n<td>Critical</td>\n<td>&gt;10000 req/sec</td>\n<td>Load shedding activation</td>\n<td>Some requests dropped</td>\n</tr>\n</tbody></table>\n<p>Request prioritization during load shedding considers multiple factors including flag importance, user segment membership, and evaluation complexity. Critical flags that control core business functionality receive higher priority than experimental flags used for A/B testing. Authenticated users may receive priority over anonymous users for personalized features.</p>\n<p><strong>Inconsistent User Context Data</strong></p>\n<p>User context objects can contain malformed, missing, or inconsistent attribute data that complicates targeting rule evaluation. These issues often arise from client-side data collection errors, integration bugs, or schema evolution without proper migration.</p>\n<p>Type coercion handles cases where attribute values don&#39;t match expected types in targeting rules. The system attempts intelligent conversion between compatible types (string to number, boolean to string) while maintaining evaluation consistency.</p>\n<p>Missing attribute handling requires careful consideration of rule semantics. When a targeting rule references an attribute that&#39;s not present in the user context, the system must decide whether this should cause rule evaluation to fail or continue with default assumptions.</p>\n<table>\n<thead>\n<tr>\n<th>Missing Attribute Scenario</th>\n<th>Rule Type</th>\n<th>Behavior</th>\n<th>Rationale</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Required attribute absent</td>\n<td>Exact match (equals)</td>\n<td>Rule evaluates to false</td>\n<td>Cannot match without value</td>\n</tr>\n<tr>\n<td>Optional attribute absent</td>\n<td>Range check (greater_than)</td>\n<td>Rule evaluates to false</td>\n<td>Cannot compare without value</td>\n</tr>\n<tr>\n<td>Attribute type mismatch</td>\n<td>Contains check</td>\n<td>Attempt coercion, then false</td>\n<td>Graceful degradation</td>\n</tr>\n<tr>\n<td>Empty string/array</td>\n<td>Membership test (in)</td>\n<td>Rule evaluates to false</td>\n<td>Empty collections match nothing</td>\n</tr>\n</tbody></table>\n<p><strong>Database Connection Failures</strong></p>\n<p>Persistent storage failures can occur due to database outages, network partitions, or resource exhaustion. The system must handle these failures gracefully while maintaining evaluation capability and preserving data consistency when connectivity is restored.</p>\n<p>Connection pool management becomes critical during database failures. The system uses circuit breakers to detect database unavailability and prevent connection pool exhaustion from repeated failed connection attempts. Once a circuit opens, database operations immediately return cached or default data without attempting database access.</p>\n<p>Recovery procedures activate when database connectivity is restored. The system must carefully validate data consistency, replay any missed updates, and gradually restore normal operation without overwhelming the recovered database with reconnection attempts from all system components simultaneously.</p>\n<p><strong>Memory and Resource Exhaustion</strong></p>\n<p>Feature flag systems with large numbers of flags or complex targeting rules can encounter memory pressure, especially when maintaining comprehensive caches or processing high evaluation volumes. Resource exhaustion must be detected and handled before it affects system stability.</p>\n<p>Memory management includes both proactive monitoring and reactive cleanup mechanisms. The system monitors heap usage, cache sizes, and evaluation queue lengths to detect approaching resource limits. When thresholds are exceeded, the system activates resource reclamation procedures.</p>\n<p>Cache eviction policies become critical during memory pressure. The system uses intelligent eviction that considers flag evaluation frequency, data freshness, and flag importance. Rarely-used experimental flags are evicted before frequently-accessed production flags.</p>\n<p><strong>Network Partitions and Split-Brain Scenarios</strong></p>\n<p>Distributed feature flag systems can experience network partitions that isolate different components from each other. During partitions, different parts of the system may have inconsistent views of flag configurations, leading to different evaluation results for identical contexts.</p>\n<p>Partition detection relies on heartbeat mechanisms and consensus protocols where appropriate. Components that detect they&#39;re isolated from the majority of the system should enter a degraded mode that prioritizes consistency over availability.</p>\n<p>Split-brain prevention ensures that conflicting flag updates don&#39;t occur simultaneously in different partitions. The system uses techniques like majority quorums or designated master selection to ensure only one partition can make authoritative flag changes during network partitions.</p>\n<p><strong>Data Corruption and Consistency Violations</strong></p>\n<p>Storage corruption can cause flag definitions to contain invalid data that passes initial validation but causes evaluation errors. This can result from hardware failures, software bugs, or concurrent modification issues.</p>\n<p>Checksum validation protects against storage-level corruption by maintaining hash values for all flag definitions. Before evaluating a flag, the system verifies that the definition&#39;s checksum matches its stored content and falls back to cached or default data if corruption is detected.</p>\n<p>Consistency repair mechanisms activate when corruption is detected. The system can rebuild flag definitions from backup data, request fresh copies from authoritative sources, or temporarily disable corrupted flags until manual intervention restores proper data.</p>\n<p>⚠️ <strong>Pitfall: Insufficient Error Context</strong>\nMany implementations provide generic error messages like &quot;evaluation failed&quot; without sufficient context for debugging. This makes production issues extremely difficult to diagnose. Always include flag key, user context summary, error type, and fallback action taken in error messages and logs.</p>\n<p>⚠️ <strong>Pitfall: Synchronous Fallback Operations</strong>\nAttempting to perform expensive fallback operations (like local storage queries) synchronously during evaluation requests can cause timeout cascades. Implement asynchronous background processes for fallback data preparation and use in-memory structures for fast fallback decisions during request handling.</p>\n<p>⚠️ <strong>Pitfall: Inconsistent Error Handling</strong>\nDifferent system components handling the same error conditions in different ways can cause confusing behavior and difficult debugging. Establish consistent error handling patterns and ensure all components follow the same fallback hierarchies and timeout behaviors.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The error handling and fallback mechanisms require careful coordination between all system components. This implementation guidance provides the infrastructure and patterns needed to build robust error handling that maintains system reliability under various failure conditions.</p>\n<p><strong>Technology Recommendations</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Circuit Breaker</td>\n<td>Manual state tracking with counters</td>\n<td>go-kit/kit circuit breaker with metrics</td>\n</tr>\n<tr>\n<td>Error Tracking</td>\n<td>Standard Go error handling with logging</td>\n<td>Sentry or similar error aggregation service</td>\n</tr>\n<tr>\n<td>Fallback Storage</td>\n<td>Local file-based JSON storage</td>\n<td>Embedded database like BadgerDB or SQLite</td>\n</tr>\n<tr>\n<td>Health Monitoring</td>\n<td>HTTP health endpoints with basic checks</td>\n<td>Comprehensive metrics with Prometheus</td>\n</tr>\n<tr>\n<td>Configuration Validation</td>\n<td>JSON schema validation</td>\n<td>Custom validator with business rule checks</td>\n</tr>\n</tbody></table>\n<p><strong>Recommended File Structure</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>internal/\n  errors/\n    errors.go              ← Custom error types and handling utilities\n    fallback.go           ← Fallback hierarchy implementation\n    circuit_breaker.go    ← Circuit breaker for service dependencies\n    validation.go         ← Flag and context validation logic\n  storage/\n    local_cache.go        ← Memory cache with LRU eviction\n    local_storage.go      ← Persistent local storage interface\n    file_storage.go       ← File-based storage implementation\n  health/\n    checker.go            ← Health monitoring and metrics\n    recovery.go           ← Automatic recovery procedures</code></pre></div>\n\n<p><strong>Error Type Definitions</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> errors</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">fmt</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// FlagError represents all feature flag related errors with context</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> FlagError</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Type        </span><span style=\"color:#B392F0\">ErrorType</span><span style=\"color:#9ECBFF\">             `json:\"type\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    FlagKey     </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">               `json:\"flag_key,omitempty\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Message     </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">               `json:\"message\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Cause       </span><span style=\"color:#F97583\">error</span><span style=\"color:#9ECBFF\">                `json:\"-\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Context     </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{} </span><span style=\"color:#9ECBFF\">`json:\"context,omitempty\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Timestamp   </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">            `json:\"timestamp\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Recoverable </span><span style=\"color:#F97583\">bool</span><span style=\"color:#9ECBFF\">                 `json:\"recoverable\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">e </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FlagError</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Error</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Sprintf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"flag error [</span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">]: </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\"> (flag: </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">)\"</span><span style=\"color:#E1E4E8\">, e.Type, e.Message, e.FlagKey)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">e </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FlagError</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Unwrap</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> e.Cause</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ErrorType categorizes different failure modes for appropriate handling</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> ErrorType</span><span style=\"color:#F97583\"> string</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">const</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    ErrorTypeValidation</span><span style=\"color:#B392F0\">    ErrorType</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"validation\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    ErrorTypeNetwork</span><span style=\"color:#B392F0\">      ErrorType</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"network\"</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    ErrorTypeStorage</span><span style=\"color:#B392F0\">      ErrorType</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"storage\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    ErrorTypeEvaluation</span><span style=\"color:#B392F0\">   ErrorType</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"evaluation\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    ErrorTypeCircuit</span><span style=\"color:#B392F0\">      ErrorType</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"circuit_breaker\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    ErrorTypeDependency</span><span style=\"color:#B392F0\">   ErrorType</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"dependency\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    ErrorTypeResource</span><span style=\"color:#B392F0\">     ErrorType</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"resource_exhaustion\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p><strong>Circuit Breaker Implementation</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> errors</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">sync</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// CircuitBreaker prevents cascade failures by detecting repeated errors</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> CircuitBreaker</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    name           </span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    maxFailures    </span><span style=\"color:#F97583\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    resetTimeout   </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    state          </span><span style=\"color:#B392F0\">CircuitState</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    failures       </span><span style=\"color:#F97583\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    lastFailTime   </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    successCount   </span><span style=\"color:#F97583\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    mu            </span><span style=\"color:#B392F0\">sync</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">RWMutex</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> CircuitState</span><span style=\"color:#F97583\"> string</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">const</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    StateClosed</span><span style=\"color:#B392F0\">    CircuitState</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"closed\"</span><span style=\"color:#6A737D\">    // Normal operation</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    StateOpen</span><span style=\"color:#B392F0\">      CircuitState</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"open\"</span><span style=\"color:#6A737D\">      // Blocking all requests  </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    StateHalfOpen</span><span style=\"color:#B392F0\">  CircuitState</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"half_open\"</span><span style=\"color:#6A737D\"> // Testing recovery</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewCircuitBreaker</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">name</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">maxFailures</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">resetTimeout</span><span style=\"color:#B392F0\"> time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">CircuitBreaker</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">CircuitBreaker</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        name:         name,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        maxFailures:  maxFailures,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        resetTimeout: resetTimeout,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        state:        StateClosed,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Allow determines if a request should be processed or rejected</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">cb </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">CircuitBreaker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Allow</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Implement circuit breaker allow logic</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 1. Check current state under read lock</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 2. For StateClosed: always allow</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 3. For StateOpen: check if reset timeout has passed</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //    - If timeout passed, transition to StateHalfOpen and allow</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //    - Otherwise reject with circuit breaker error</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 4. For StateHalfOpen: allow (testing recovery)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// RecordResult updates circuit breaker state based on operation outcome</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">cb </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">CircuitBreaker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">RecordResult</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">err</span><span style=\"color:#F97583\"> error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Update circuit breaker state based on result</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 1. Acquire write lock for state modification</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 2. If err != nil: increment failure count and record timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //    - Check if failures exceed threshold and transition to StateOpen</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 3. If err == nil and state is StateHalfOpen: </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //    - Increment success count and check if should transition to StateClosed</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 4. If err == nil and state is StateClosed: reset failure count</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// State returns current circuit breaker state for monitoring</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">cb </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">CircuitBreaker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">State</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#B392F0\">CircuitState</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cb.mu.</span><span style=\"color:#B392F0\">RLock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> cb.mu.</span><span style=\"color:#B392F0\">RUnlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> cb.state</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Fallback Handler Infrastructure</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> errors</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">context</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// FallbackHandler manages the complete fallback hierarchy</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> FallbackHandler</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    primaryAPI    </span><span style=\"color:#B392F0\">FlagAPI</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    memoryCache   </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">MemoryCache</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    localStorage  </span><span style=\"color:#B392F0\">LocalStorage</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    circuitBreaker </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">CircuitBreaker</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    metrics       </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FallbackMetrics</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// FlagAPI interface for primary flag data source</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> FlagAPI</span><span style=\"color:#F97583\"> interface</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    GetFlag</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">flagKey</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FlagDefinition</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// FallbackMetrics tracks fallback usage for monitoring</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> FallbackMetrics</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    APIAttempts      </span><span style=\"color:#F97583\">int64</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CacheHits        </span><span style=\"color:#F97583\">int64</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LocalStorageHits </span><span style=\"color:#F97583\">int64</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    DefaultValueHits </span><span style=\"color:#F97583\">int64</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    mu              </span><span style=\"color:#B392F0\">sync</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">RWMutex</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewFallbackHandler</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">api</span><span style=\"color:#B392F0\"> FlagAPI</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">cache</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">MemoryCache</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">storage</span><span style=\"color:#B392F0\"> LocalStorage</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FallbackHandler</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">FallbackHandler</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        primaryAPI:     api,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        memoryCache:    cache,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        localStorage:   storage,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        circuitBreaker: </span><span style=\"color:#B392F0\">NewCircuitBreaker</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"flag-api\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">30</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">time.Second),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        metrics:       </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#B392F0\">FallbackMetrics</span><span style=\"color:#E1E4E8\">{},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// GetFlagWithFallback implements complete fallback hierarchy</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">fh </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FallbackHandler</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">GetFlagWithFallback</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">flagKey</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FlagDefinition</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Implement complete fallback sequence</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 1. Check circuit breaker - if open, skip API and go to cache</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 2. Try primary API with short timeout context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //    - If success: update cache, record success, return with source \"api\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //    - If failure: record failure, continue to fallback</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 3. Try memory cache</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //    - Check staleness tolerance before returning cached data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //    - If found and fresh: return with source \"cache\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 4. Try local storage</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //    - Load from persistent storage</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //    - If found: update memory cache, return with source \"storage\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 5. Return default value from flag definition with source \"default\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 6. Update metrics for monitoring</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"\"</span><span style=\"color:#E1E4E8\">, fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"not implemented\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Validation Framework</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> errors</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">fmt</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">strings</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ValidationErrors collects multiple validation failures</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> ValidationErrors</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Errors []</span><span style=\"color:#B392F0\">ValidationError</span><span style=\"color:#9ECBFF\"> `json:\"errors\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">ve </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">ValidationErrors</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Error</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    var</span><span style=\"color:#E1E4E8\"> messages []</span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> _, err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> range</span><span style=\"color:#E1E4E8\"> ve.Errors {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        messages </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> append</span><span style=\"color:#E1E4E8\">(messages, err.</span><span style=\"color:#B392F0\">Error</span><span style=\"color:#E1E4E8\">())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Sprintf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"validation failed: </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, strings.</span><span style=\"color:#B392F0\">Join</span><span style=\"color:#E1E4E8\">(messages, </span><span style=\"color:#9ECBFF\">\"; \"</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">ve </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">ValidationErrors</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Add</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">field</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">message</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ve.Errors </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> append</span><span style=\"color:#E1E4E8\">(ve.Errors, </span><span style=\"color:#B392F0\">ValidationError</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Field:   field,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Message: message,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    })</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">ve </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">ValidationErrors</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">HasErrors</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#B392F0\"> len</span><span style=\"color:#E1E4E8\">(ve.Errors) </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ValidationError represents a single validation failure</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> ValidationError</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Field   </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\"> `json:\"field\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Message </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\"> `json:\"message\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">ve </span><span style=\"color:#B392F0\">ValidationError</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Error</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Sprintf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"field '</span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">': </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, ve.Field, ve.Message)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ValidateFlagDefinition performs comprehensive flag validation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> ValidateFlagDefinition</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">flag</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">FlagDefinition</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Implement comprehensive flag validation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 1. Check flag key format and length</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 2. Validate default value matches flag type</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 3. For each targeting rule:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //    - Validate attribute references</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //    - Check operator compatibility with attribute types</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //    - Verify percentage allocations sum correctly</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //    - Validate segment references exist</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 4. Check for circular dependencies in prerequisites</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 5. Validate variant definitions match flag type</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 6. Ensure at least one variant or default value exists</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ValidateUserContext ensures context data meets requirements</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> ValidateUserContext</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">UserContext</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Validate user context structure</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 1. Check UserID is not empty</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 2. Validate attribute values are compatible types</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 3. Check segment names follow naming conventions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 4. Verify context size doesn't exceed limits</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Recovery and Health Monitoring</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> health</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">context</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">sync</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// HealthChecker monitors system component health and triggers recovery</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> HealthChecker</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    components </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#B392F0\">HealthComponent</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    status     </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#B392F0\">ComponentHealth</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    mu         </span><span style=\"color:#B392F0\">sync</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">RWMutex</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    interval   </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    stopCh     </span><span style=\"color:#F97583\">chan</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\">{}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> ComponentHealth</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Status      </span><span style=\"color:#B392F0\">HealthStatus</span><span style=\"color:#9ECBFF\">  `json:\"status\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LastCheck   </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">     `json:\"last_check\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LastError   </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">        `json:\"last_error,omitempty\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CheckCount  </span><span style=\"color:#F97583\">int64</span><span style=\"color:#9ECBFF\">         `json:\"check_count\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ErrorCount  </span><span style=\"color:#F97583\">int64</span><span style=\"color:#9ECBFF\">         `json:\"error_count\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> HealthStatus</span><span style=\"color:#F97583\"> string</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">const</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    HealthStatusHealthy</span><span style=\"color:#B392F0\">   HealthStatus</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"healthy\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    HealthStatusDegraded</span><span style=\"color:#B392F0\">  HealthStatus</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"degraded\"</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    HealthStatusUnhealthy</span><span style=\"color:#B392F0\"> HealthStatus</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"unhealthy\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> HealthComponent</span><span style=\"color:#F97583\"> interface</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    Name</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    Check</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    Recover</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewHealthChecker</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">interval</span><span style=\"color:#B392F0\"> time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">HealthChecker</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">HealthChecker</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        components: </span><span style=\"color:#B392F0\">make</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#B392F0\">HealthComponent</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        status:     </span><span style=\"color:#B392F0\">make</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#B392F0\">ComponentHealth</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        interval:   interval,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        stopCh:     </span><span style=\"color:#B392F0\">make</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">chan</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\">{}),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// StartMonitoring begins periodic health checks and automatic recovery</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">hc </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">HealthChecker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">StartMonitoring</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Implement health monitoring loop</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 1. Create ticker for periodic checks</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 2. For each component, run health check</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 3. Update component status based on check result</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 4. If component unhealthy, attempt recovery</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 5. Log health status changes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 6. Handle context cancellation for graceful shutdown</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Milestone Checkpoints</strong></p>\n<p><strong>After Milestone 1 - Flag Evaluation Engine:</strong></p>\n<ul>\n<li>Test flag evaluation with invalid rule conditions: <code>go test -run TestEvaluationWithInvalidRules</code></li>\n<li>Verify fallback to default values when rules are malformed</li>\n<li>Check that evaluation errors include proper context information</li>\n<li>Expected: Evaluation succeeds with clear indication of fallback usage</li>\n</ul>\n<p><strong>After Milestone 2 - Real-time Flag Updates:</strong>  </p>\n<ul>\n<li>Test connection failure scenarios: disconnect network and verify client behavior</li>\n<li>Check exponential backoff during reconnection attempts</li>\n<li>Verify circuit breaker opens after repeated connection failures</li>\n<li>Expected: Clients continue operating with cached data during outages</li>\n</ul>\n<p><strong>After Milestone 3 - Flag Analytics &amp; Experiments:</strong></p>\n<ul>\n<li>Test analytics service failure during flag evaluation</li>\n<li>Verify that exposure tracking failures don&#39;t affect flag evaluation</li>\n<li>Check that experiment assignment continues when analytics are unavailable</li>\n<li>Expected: Flag evaluations continue normally even when analytics fail</li>\n</ul>\n<p><strong>Debugging Checklist</strong></p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Evaluations always return defaults</td>\n<td>Circuit breaker stuck open</td>\n<td>Check circuit breaker state and error logs</td>\n<td>Reset circuit breaker or fix underlying service</td>\n</tr>\n<tr>\n<td>Inconsistent evaluation results</td>\n<td>Cache consistency issues</td>\n<td>Compare cache contents across instances</td>\n<td>Implement cache invalidation or restart services</td>\n</tr>\n<tr>\n<td>Memory leaks during errors</td>\n<td>Error context not being cleaned up</td>\n<td>Monitor heap usage during error scenarios</td>\n<td>Add proper cleanup in error handling paths</td>\n</tr>\n<tr>\n<td>Slow recovery after outages</td>\n<td>Thundering herd on reconnection</td>\n<td>Check connection attempt timing</td>\n<td>Add jittered exponential backoff</td>\n</tr>\n<tr>\n<td>Missing error context in logs</td>\n<td>Generic error handling</td>\n<td>Review error logging patterns</td>\n<td>Enhance errors with flag keys and user context</td>\n</tr>\n</tbody></table>\n<h2 id=\"testing-strategy\">Testing Strategy</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section applies to all three milestones by establishing comprehensive testing strategies for validating the Flag Evaluation Engine (Milestone 1), Real-time Flag Updates (Milestone 2), and Flag Analytics &amp; Experiments (Milestone 3).</p>\n</blockquote>\n<p>Testing a feature flag system requires a multi-layered approach that goes beyond traditional unit tests. Think of testing feature flags like <strong>stress-testing air traffic control systems</strong> — you need to verify that the system works correctly under normal conditions, handles edge cases gracefully, and maintains safety guarantees even when components fail. Just as air traffic controllers run emergency scenarios to ensure pilots can land safely during equipment failures, we must test that our feature flag system maintains consistent user experiences even when services are degraded.</p>\n<p>The testing strategy for a feature flag system faces unique challenges that don&#39;t exist in typical CRUD applications. Feature flags must maintain <strong>consistent user assignments</strong> across evaluations, ensure <strong>real-time updates propagate correctly</strong> without causing inconsistencies, and track <strong>statistically valid experiments</strong> without introducing bias. A single bug in consistent hashing could cause users to flip between variants, invalidating an entire A/B test. A race condition in update propagation could show users conflicting feature states within the same session.</p>\n<h3 id=\"milestone-validation-checkpoints\">Milestone Validation Checkpoints</h3>\n<p>Each milestone introduces distinct functionality that requires specific validation approaches. The checkpoints serve as <strong>quality gates</strong> that verify the system meets its acceptance criteria before proceeding to the next milestone. Think of these checkpoints like <strong>preflight inspections</strong> — systematically verifying each system component before allowing the next phase to begin.</p>\n<p><strong>Milestone 1: Flag Evaluation Engine Validation</strong></p>\n<p>The Flag Evaluation Engine validation focuses on correctness of targeting logic, consistency of user assignments, and performance under load. The core challenge is ensuring that complex targeting rules evaluate deterministically and that percentage rollouts assign users consistently across multiple evaluations.</p>\n<table>\n<thead>\n<tr>\n<th>Test Category</th>\n<th>What to Validate</th>\n<th>Expected Behavior</th>\n<th>Failure Indicators</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Basic Flag Evaluation</td>\n<td>Simple boolean flags return correct values</td>\n<td><code>EvaluateFlag(&quot;simple-toggle&quot;, userContext)</code> returns <code>{Value: true, Variant: &quot;enabled&quot;, Reason: &quot;targeting_match&quot;}</code></td>\n<td>Wrong boolean value returned, missing variant information</td>\n</tr>\n<tr>\n<td>Targeting Rule Logic</td>\n<td>Complex AND/OR conditions evaluate correctly</td>\n<td>User matching <code>userType=premium AND region=us-east</code> gets correct variant</td>\n<td>Rule precedence violations, incorrect boolean logic</td>\n</tr>\n<tr>\n<td>Percentage Rollouts</td>\n<td>Consistent user assignment to percentage buckets</td>\n<td>Same user gets same variant across multiple evaluations</td>\n<td>User assignment changes between calls, incorrect bucket distribution</td>\n</tr>\n<tr>\n<td>Rule Precedence</td>\n<td>Higher priority rules override lower priority ones</td>\n<td>Targeting rules evaluated before default percentage rollout</td>\n<td>Lower priority rules incorrectly taking precedence</td>\n</tr>\n<tr>\n<td>Context Validation</td>\n<td>Invalid user contexts are handled gracefully</td>\n<td>Missing required attributes cause fallback to default value</td>\n<td>System crashes on malformed context, silent failures</td>\n</tr>\n<tr>\n<td>Performance Baseline</td>\n<td>Evaluation latency meets requirements</td>\n<td>Single flag evaluation completes under 1ms, 10k evaluations/sec sustained</td>\n<td>High latency, memory leaks, CPU spikes</td>\n</tr>\n</tbody></table>\n<p>The <strong>consistent hashing validation</strong> is particularly critical for Milestone 1. Create test scenarios with the same user evaluating the same flag thousands of times — the variant assignment must never change. Additionally, test that percentage allocations distribute users correctly by evaluating flags for large user populations and measuring actual distribution against expected percentages.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Validation Command: go test ./internal/evaluation/... -v -race\nExpected Output: All tests pass, no race conditions detected\nManual Verification: Start evaluation server, send 1000 requests for same user/flag, verify identical responses</code></pre></div>\n\n<p><strong>Milestone 2: Real-time Flag Updates Validation</strong></p>\n<p>Real-time updates introduce complexity around connection management, message ordering, and cache consistency. The validation must ensure that flag changes propagate to all connected clients within acceptable time bounds and that clients handle connection failures gracefully.</p>\n<table>\n<thead>\n<tr>\n<th>Test Category</th>\n<th>What to Validate</th>\n<th>Expected Behavior</th>\n<th>Failure Indicators</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Update Propagation</td>\n<td>Flag changes reach all connected clients</td>\n<td>Change broadcast within 100ms to all SSE connections</td>\n<td>Clients not receiving updates, significant propagation delays</td>\n</tr>\n<tr>\n<td>Connection Recovery</td>\n<td>Clients reconnect after network interruption</td>\n<td>Exponential backoff, replay missed events, resume normal operation</td>\n<td>Infinite retry loops, missed updates after reconnection</td>\n</tr>\n<tr>\n<td>Message Ordering</td>\n<td>Updates arrive in correct sequence</td>\n<td>Event sequence numbers increment monotonically, no gaps</td>\n<td>Out-of-order delivery, duplicate or missing events</td>\n</tr>\n<tr>\n<td>Cache Invalidation</td>\n<td>Stale flag data is replaced promptly</td>\n<td>Local cache updated within propagation timeout</td>\n<td>Clients serving stale data after update notification</td>\n</tr>\n<tr>\n<td>Connection Limits</td>\n<td>System handles connection scaling gracefully</td>\n<td>Support target number of concurrent SSE connections</td>\n<td>Memory exhaustion, connection drops under load</td>\n</tr>\n<tr>\n<td>Fallback Behavior</td>\n<td>Clients function when update service unavailable</td>\n<td>Fall back to cached data, continue flag evaluations</td>\n<td>Service unavailable causes client failures</td>\n</tr>\n</tbody></table>\n<p>The <strong>connection state machine validation</strong> requires simulating various network conditions. Test clients connecting, disconnecting, experiencing intermittent failures, and recovering. Verify that the <code>ConnectionState</code> transitions correctly through <code>StateDisconnected</code>, <code>StateConnecting</code>, <code>StateConnected</code>, and <code>StateReconnecting</code> states based on network events.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Validation Command: go test ./internal/realtime/... -v -timeout 30s\nExpected Output: Connection state transitions verified, no goroutine leaks\nManual Verification: Start server with 100 concurrent clients, toggle flag via API, verify all clients receive update</code></pre></div>\n\n<p><strong>Milestone 3: Flag Analytics &amp; Experiments Validation</strong></p>\n<p>Analytics and experimentation validation focuses on data accuracy, statistical correctness, and performance of the tracking pipeline. The challenge is ensuring that exposure events are captured reliably and that statistical calculations produce valid results.</p>\n<table>\n<thead>\n<tr>\n<th>Test Category</th>\n<th>What to Validate</th>\n<th>Expected Behavior</th>\n<th>Failure Indicators</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Exposure Tracking</td>\n<td>All flag evaluations are logged accurately</td>\n<td>Each <code>EvaluateFlag</code> call generates corresponding <code>FlagExposure</code> event</td>\n<td>Missing exposure events, incorrect exposure data</td>\n</tr>\n<tr>\n<td>Statistical Calculations</td>\n<td>Significance tests produce correct results</td>\n<td>Known experiment data yields expected p-values and confidence intervals</td>\n<td>Wrong statistical results, confidence intervals don&#39;t match</td>\n</tr>\n<tr>\n<td>Sample Ratio Detection</td>\n<td>Mismatch between intended and actual allocations detected</td>\n<td>50/50 split with 60/40 actual triggers <code>SampleRatioMismatch</code> flag</td>\n<td>Sample ratio mismatches not detected, false positives</td>\n</tr>\n<tr>\n<td>Experiment Assignment</td>\n<td>Users consistently assigned to same variant</td>\n<td>Same user gets same experiment variant across sessions</td>\n<td>User variant assignments change over time</td>\n</tr>\n<tr>\n<td>Performance Pipeline</td>\n<td>High-volume exposure tracking without data loss</td>\n<td>Process 10k exposures/sec without dropping events</td>\n<td>Event queue overflow, processing delays, data loss</td>\n</tr>\n<tr>\n<td>Analytics Aggregation</td>\n<td>Real-time metrics accurately reflect exposure data</td>\n<td>Conversion rates match raw exposure data calculations</td>\n<td>Aggregation errors, metrics don&#39;t match raw data</td>\n</tr>\n</tbody></table>\n<p>The <strong>statistical significance validation</strong> requires test datasets with known ground truth. Create synthetic experiment data where variant A has a 5% conversion rate and variant B has a 6% conversion rate, then verify that your <code>CalculateSignificance</code> function produces the expected p-values and confidence intervals for different sample sizes.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Validation Command: go test ./internal/analytics/... -v -bench=BenchmarkExposureTracking\nExpected Output: Statistical calculations match expected values, throughput targets achieved\nManual Verification: Run synthetic A/B test, compare calculated significance to external statistical tool</code></pre></div>\n\n<p><strong>Cross-Milestone Integration Validation</strong></p>\n<p>The final validation step verifies that all three milestones work together correctly. This integration testing simulates realistic usage patterns where clients evaluate flags, receive real-time updates, and generate analytics data simultaneously.</p>\n<table>\n<thead>\n<tr>\n<th>Integration Scenario</th>\n<th>Validation Steps</th>\n<th>Success Criteria</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Flag Update During Active Experiment</td>\n<td>Modify flag while experiment running, verify exposure tracking continues</td>\n<td>No gaps in exposure data, users maintain variant assignments</td>\n</tr>\n<tr>\n<td>High-Load Mixed Operations</td>\n<td>Concurrent flag evaluations, updates, and analytics queries</td>\n<td>All operations succeed, no degradation in any component</td>\n</tr>\n<tr>\n<td>Partial Service Degradation</td>\n<td>Disable analytics service, verify flag evaluation continues</td>\n<td>Flag evaluation unaffected, analytics queue buffers data</td>\n</tr>\n</tbody></table>\n<h3 id=\"property-based-testing\">Property-based Testing</h3>\n<p>Property-based testing is particularly valuable for feature flag systems because it can discover edge cases that traditional example-based tests miss. Instead of testing specific inputs and outputs, property-based tests verify <strong>mathematical invariants</strong> that should hold regardless of the specific input values. Think of property-based testing like <strong>physics laws</strong> — just as gravity always pulls objects downward regardless of their mass or composition, certain properties of your feature flag system should always hold true regardless of the specific flags, users, or configurations involved.</p>\n<p>Property-based testing excels at finding the subtle bugs that can destroy user trust in feature flags. A traditional unit test might verify that user &quot;alice&quot; gets variant &quot;treatment&quot; for flag &quot;checkout-flow&quot;, but a property-based test would verify that ANY user gets the SAME variant every time they&#39;re evaluated for ANY flag. This approach discovers bugs like hash function inconsistencies, floating-point precision issues in percentage calculations, and race conditions in concurrent access patterns.</p>\n<p><strong>Consistent Hashing Stability Properties</strong></p>\n<p>The most critical property to test is <strong>deterministic user assignment</strong> — the same user must always receive the same variant for a given flag configuration, regardless of when or how many times the evaluation occurs. This property is foundational to user experience and experiment validity.</p>\n<table>\n<thead>\n<tr>\n<th>Property</th>\n<th>Description</th>\n<th>Test Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Assignment Stability</td>\n<td>Same user + same flag + same config = same variant</td>\n<td>Generate random users and flags, evaluate multiple times, assert all results identical</td>\n</tr>\n<tr>\n<td>Percentage Distribution</td>\n<td>Large user populations distribute according to percentage allocations</td>\n<td>Generate 10k random users, evaluate against 50/50 split, assert 45-55% in each bucket</td>\n</tr>\n<tr>\n<td>Independence Across Flags</td>\n<td>User&#39;s variant for one flag doesn&#39;t influence variant for other flags</td>\n<td>Generate user + multiple flags, assert variant assignments are uncorrelated</td>\n</tr>\n<tr>\n<td>Hash Function Uniformity</td>\n<td>User IDs distribute evenly across bucket space</td>\n<td>Generate 10k sequential user IDs, assert bucket assignments don&#39;t cluster</td>\n</tr>\n</tbody></table>\n<p>The <strong>assignment stability property</strong> can be implemented using property-based testing frameworks by generating random <code>UserID</code> and <code>FlagKey</code> combinations, then evaluating the same combination multiple times and asserting that the <code>EvaluationResult.Variant</code> never changes. This test should run with thousands of random inputs to discover edge cases like specific user ID patterns that cause hash collisions.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// Property: Same user + same flag = same variant (always)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> TestAssignmentStability</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">t</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">testing</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">T</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Generate random UserID and FlagKey</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Create FlagDefinition with percentage rollout</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Call EvaluateFlag 100 times with same inputs</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Assert all results have identical Variant field</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Repeat with 1000 different random user/flag combinations</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Rule Evaluation Determinism Properties</strong></p>\n<p>Complex targeting rules with AND/OR operators and multiple conditions must evaluate deterministically regardless of the order in which conditions are processed or the internal representation of the rule tree.</p>\n<table>\n<thead>\n<tr>\n<th>Property</th>\n<th>Description</th>\n<th>Test Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Boolean Logic Correctness</td>\n<td>AND/OR operators follow mathematical laws (associativity, commutativity)</td>\n<td>Generate random rule combinations, verify against truth tables</td>\n</tr>\n<tr>\n<td>Condition Order Independence</td>\n<td>Same conditions in different orders produce same result</td>\n<td>Generate rule with multiple conditions, test all permutations</td>\n</tr>\n<tr>\n<td>Context Attribute Type Safety</td>\n<td>Same logical value in different types produces same result</td>\n<td>Test string &quot;true&quot; vs boolean true, integer 1 vs string &quot;1&quot;</td>\n</tr>\n<tr>\n<td>Rule Precedence Consistency</td>\n<td>Higher priority rules always override lower priority ones</td>\n<td>Generate rules with random priorities, assert highest priority determines result</td>\n</tr>\n</tbody></table>\n<p><strong>Cache Consistency Properties</strong></p>\n<p>Real-time flag updates must maintain consistency between cached and authoritative flag definitions. Cache inconsistencies can cause the same user to see different feature behavior within a short time window, creating poor user experience.</p>\n<table>\n<thead>\n<tr>\n<th>Property</th>\n<th>Description</th>\n<th>Test Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Read-After-Write Consistency</td>\n<td>Flag reads return updated value after write completes</td>\n<td>Write flag update, immediately read from cache, assert new value returned</td>\n</tr>\n<tr>\n<td>Invalidation Completeness</td>\n<td>Cache invalidation removes ALL stale entries</td>\n<td>Update flag, trigger invalidation, assert no cache level returns old value</td>\n</tr>\n<tr>\n<td>Concurrent Access Safety</td>\n<td>Multiple threads reading/writing cache don&#39;t corrupt data</td>\n<td>Generate concurrent read/write operations, assert no race conditions</td>\n</tr>\n<tr>\n<td>TTL Enforcement</td>\n<td>Expired cache entries are not served</td>\n<td>Set short TTL, wait for expiration, assert cache miss triggers refresh</td>\n</tr>\n</tbody></table>\n<p><strong>Statistical Analysis Properties</strong></p>\n<p>A/B test analysis must produce mathematically correct results that match established statistical formulas. Incorrect statistical calculations can lead to false conclusions about feature effectiveness.</p>\n<table>\n<thead>\n<tr>\n<th>Property</th>\n<th>Description</th>\n<th>Test Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Significance Calculation Accuracy</td>\n<td>P-values and confidence intervals match statistical formulas</td>\n<td>Generate synthetic data with known ground truth, verify calculations</td>\n</tr>\n<tr>\n<td>Sample Size Monotonicity</td>\n<td>Larger samples never decrease statistical power</td>\n<td>Generate data with increasing sample sizes, assert power never decreases</td>\n</tr>\n<tr>\n<td>Alpha Level Consistency</td>\n<td>Significance threshold correctly applied across all tests</td>\n<td>Test data at boundary conditions, verify alpha=0.05 behaves correctly</td>\n</tr>\n<tr>\n<td>Effect Size Calculation</td>\n<td>Effect size measures correctly reflect practical significance</td>\n<td>Generate data with known effect sizes, verify calculated values</td>\n</tr>\n</tbody></table>\n<p>The <strong>significance calculation accuracy</strong> property can be tested by generating synthetic experiment data using known statistical distributions, then verifying that your <code>CalculateSignificance</code> function produces results that match calculations from established statistical libraries like R or Python&#39;s scipy.stats.</p>\n<p><strong>Implementation Strategy for Property-based Tests</strong></p>\n<p>Property-based testing frameworks like Go&#39;s <code>gopter</code> or <code>testing/quick</code> generate hundreds or thousands of random test cases automatically. The key is designing property functions that encode the mathematical invariants your system must maintain.</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Property Function Signature</th>\n<th>Random Generators Needed</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Evaluation Engine</td>\n<td><code>func TestAssignmentStability(user UserID, flag FlagKey) bool</code></td>\n<td>UserID generator, FlagKey generator, percentage generator</td>\n</tr>\n<tr>\n<td>Rule Engine</td>\n<td><code>func TestRuleDeterminism(rules []TargetingRule, ctx UserContext) bool</code></td>\n<td>Rule generator, condition generator, context generator</td>\n</tr>\n<tr>\n<td>Cache Layer</td>\n<td><code>func TestCacheConsistency(operations []CacheOperation) bool</code></td>\n<td>Cache operation generator, flag definition generator</td>\n</tr>\n<tr>\n<td>Statistics</td>\n<td><code>func TestSignificanceAccuracy(experimentData ExperimentData) bool</code></td>\n<td>Conversion rate generator, sample size generator</td>\n</tr>\n</tbody></table>\n<p>Each property function should return <code>true</code> if the invariant holds and <code>false</code> if it&#39;s violated. The testing framework automatically shrinks failing test cases to find minimal examples that violate the property, making debugging much easier than trying to reproduce complex failure scenarios manually.</p>\n<blockquote>\n<p><strong>Design Insight</strong>: Property-based testing is particularly valuable for feature flag systems because bugs often manifest only under specific combinations of user attributes, flag configurations, or timing conditions that are difficult to anticipate when writing example-based tests.</p>\n</blockquote>\n<p><strong>Common Property-based Testing Pitfalls</strong></p>\n<p>⚠️ <strong>Pitfall: Testing Implementation Details Instead of Business Properties</strong></p>\n<p>Many developers write property-based tests that verify implementation details like &quot;hash function returns 32-bit integer&quot; rather than business properties like &quot;user assignment remains stable&quot;. This leads to brittle tests that break when implementation changes but don&#39;t catch real bugs that affect users.</p>\n<p><strong>Why it&#39;s wrong</strong>: Implementation details can change without affecting system behavior. Testing them creates maintenance burden without providing confidence in system correctness.</p>\n<p><strong>How to fix</strong>: Focus on observable behavior and business invariants. Test that &quot;users get consistent variants&quot; rather than &quot;hash function returns specific values&quot;.</p>\n<p>⚠️ <strong>Pitfall: Insufficient Random Data Generation</strong></p>\n<p>Property-based tests are only as good as the random data they generate. Tests that generate only simple, well-formed inputs miss edge cases like empty strings, special characters, extreme numeric values, or unusual data combinations.</p>\n<p><strong>Why it&#39;s wrong</strong>: Real-world data contains edge cases that simple generators miss. Bugs often lurk in boundary conditions and unusual input combinations.</p>\n<p><strong>How to fix</strong>: Design generators that produce edge cases: empty collections, null values, extreme numbers, special characters, and boundary conditions relevant to your domain.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p><strong>A. Technology Recommendations:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Testing Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Property-based Testing</td>\n<td><code>testing/quick</code> (Go stdlib)</td>\n<td><code>gopter</code> with custom generators</td>\n</tr>\n<tr>\n<td>Load Testing</td>\n<td><code>go test -bench</code> with table tests</td>\n<td><code>k6</code> with realistic traffic patterns</td>\n</tr>\n<tr>\n<td>Integration Testing</td>\n<td><code>httptest</code> with test servers</td>\n<td><code>testcontainers</code> with real dependencies</td>\n</tr>\n<tr>\n<td>Statistical Validation</td>\n<td>Manual calculation verification</td>\n<td><code>gonum/stat</code> for reference implementations</td>\n</tr>\n<tr>\n<td>Test Data Management</td>\n<td>JSON fixtures in <code>testdata/</code></td>\n<td><code>factory_bot</code> style builders with randomization</td>\n</tr>\n<tr>\n<td>Milestone Validation</td>\n<td><code>make test</code> with milestone-specific tags</td>\n<td>CI pipeline with environment-specific test suites</td>\n</tr>\n</tbody></table>\n<p><strong>B. Recommended Test Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>internal/\n  evaluation/\n    evaluation.go\n    evaluation_test.go           ← unit tests\n    evaluation_property_test.go  ← property-based tests\n    evaluation_integration_test.go ← integration scenarios\n  realtime/\n    realtime_test.go\n    realtime_load_test.go        ← connection scaling tests\n  analytics/\n    analytics_test.go\n    analytics_statistical_test.go ← statistical accuracy tests\ntest/\n  fixtures/                      ← test data\n    flags.json\n    users.json\n    experiments.json\n  integration/                   ← cross-component tests\n    milestone_1_test.go\n    milestone_2_test.go\n    milestone_3_test.go\n  property/                      ← property-based test generators\n    generators.go                ← random data generation\n    properties.go                ← invariant definitions</code></pre></div>\n\n<p><strong>C. Test Data Generators (Complete Implementation):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> property</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">math/rand</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">testing/quick</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// UserGenerator creates realistic UserID values for property testing</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> UserGenerator</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">rand</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">rand</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Rand</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">size</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">reflect</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Value</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Generate mix of numeric IDs, UUIDs, and email-like strings</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    patterns </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> []</span><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        func</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\"> { </span><span style=\"color:#F97583\">return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Sprintf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"user_</span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, rand.</span><span style=\"color:#B392F0\">Intn</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">100000</span><span style=\"color:#E1E4E8\">)) },</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        func</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\"> { </span><span style=\"color:#F97583\">return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Sprintf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"test+</span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#9ECBFF\">@example.com\"</span><span style=\"color:#E1E4E8\">, rand.</span><span style=\"color:#B392F0\">Intn</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">10000</span><span style=\"color:#E1E4E8\">)) },</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        func</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\"> { </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Sprintf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">%08x</span><span style=\"color:#9ECBFF\">-</span><span style=\"color:#79B8FF\">%04x</span><span style=\"color:#9ECBFF\">-</span><span style=\"color:#79B8FF\">%04x</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                rand.</span><span style=\"color:#B392F0\">Uint32</span><span style=\"color:#E1E4E8\">(), rand.</span><span style=\"color:#B392F0\">Uint32</span><span style=\"color:#E1E4E8\">()</span><span style=\"color:#F97583\">&#x26;0x</span><span style=\"color:#79B8FF\">FFFF</span><span style=\"color:#E1E4E8\">, rand.</span><span style=\"color:#B392F0\">Uint32</span><span style=\"color:#E1E4E8\">()</span><span style=\"color:#F97583\">&#x26;0x</span><span style=\"color:#79B8FF\">FFFF</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        },</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    pattern </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> patterns[rand.</span><span style=\"color:#B392F0\">Intn</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">len</span><span style=\"color:#E1E4E8\">(patterns))]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> reflect.</span><span style=\"color:#B392F0\">ValueOf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">UserID</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">pattern</span><span style=\"color:#E1E4E8\">()))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// FlagGenerator creates realistic flag definitions for property testing</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> FlagGenerator</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">rand</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">rand</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Rand</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">size</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">reflect</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Value</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    flag </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">FlagDefinition</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Key:         </span><span style=\"color:#B392F0\">FlagKey</span><span style=\"color:#E1E4E8\">(fmt.</span><span style=\"color:#B392F0\">Sprintf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"test_flag_</span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, rand.</span><span style=\"color:#B392F0\">Intn</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">1000</span><span style=\"color:#E1E4E8\">))),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Name:        fmt.</span><span style=\"color:#B392F0\">Sprintf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Test Flag </span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, rand.</span><span style=\"color:#B392F0\">Intn</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">1000</span><span style=\"color:#E1E4E8\">)),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Description: </span><span style=\"color:#9ECBFF\">\"Generated for property testing\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Enabled:     rand.</span><span style=\"color:#B392F0\">Float32</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0.1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#6A737D\">// 90% enabled</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Variants: []</span><span style=\"color:#B392F0\">Variant</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            {Key: </span><span style=\"color:#9ECBFF\">\"control\"</span><span style=\"color:#E1E4E8\">, Value: </span><span style=\"color:#79B8FF\">false</span><span style=\"color:#E1E4E8\">, Weight: rand.</span><span style=\"color:#B392F0\">Intn</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">50</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 25</span><span style=\"color:#E1E4E8\">},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            {Key: </span><span style=\"color:#9ECBFF\">\"treatment\"</span><span style=\"color:#E1E4E8\">, Value: </span><span style=\"color:#79B8FF\">true</span><span style=\"color:#E1E4E8\">, Weight: rand.</span><span style=\"color:#B392F0\">Intn</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">50</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 25</span><span style=\"color:#E1E4E8\">},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        },</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Add random targeting rules 20% of the time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> rand.</span><span style=\"color:#B392F0\">Float32</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0.8</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        flag.TargetingRules </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> generateRandomRules</span><span style=\"color:#E1E4E8\">(rand, size)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> reflect.</span><span style=\"color:#B392F0\">ValueOf</span><span style=\"color:#E1E4E8\">(flag)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ContextGenerator creates diverse user contexts for testing</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> ContextGenerator</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">rand</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">rand</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Rand</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">size</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">reflect</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Value</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    attributes </span><span style=\"color:#F97583\">:=</span><span style=\"color:#B392F0\"> make</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{})</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Add common attribute types</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    attributes[</span><span style=\"color:#9ECBFF\">\"user_type\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">{</span><span style=\"color:#9ECBFF\">\"premium\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"basic\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"trial\"</span><span style=\"color:#E1E4E8\">}[rand.</span><span style=\"color:#B392F0\">Intn</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">3</span><span style=\"color:#E1E4E8\">)]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    attributes[</span><span style=\"color:#9ECBFF\">\"region\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">{</span><span style=\"color:#9ECBFF\">\"us-east\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"us-west\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"eu\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"asia\"</span><span style=\"color:#E1E4E8\">}[rand.</span><span style=\"color:#B392F0\">Intn</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">4</span><span style=\"color:#E1E4E8\">)]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    attributes[</span><span style=\"color:#9ECBFF\">\"account_age_days\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> rand.</span><span style=\"color:#B392F0\">Intn</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">1000</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    attributes[</span><span style=\"color:#9ECBFF\">\"is_beta_user\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> rand.</span><span style=\"color:#B392F0\">Float32</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0.7</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Add random attributes 30% of the time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> rand.</span><span style=\"color:#B392F0\">Float32</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0.7</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        randomKey </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Sprintf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"custom_</span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, rand.</span><span style=\"color:#B392F0\">Intn</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">100</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        attributes[randomKey] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Sprintf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"value_</span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, rand.</span><span style=\"color:#B392F0\">Intn</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">100</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> reflect.</span><span style=\"color:#B392F0\">ValueOf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">UserContext</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        UserID:     </span><span style=\"color:#B392F0\">UserID</span><span style=\"color:#E1E4E8\">(fmt.</span><span style=\"color:#B392F0\">Sprintf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"user_</span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, rand.</span><span style=\"color:#B392F0\">Intn</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">10000</span><span style=\"color:#E1E4E8\">))),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Attributes: attributes,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Segments:   </span><span style=\"color:#B392F0\">generateRandomSegments</span><span style=\"color:#E1E4E8\">(rand),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    })</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>D. Property Test Examples (Core Logic Skeletons):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// TestAssignmentStabilityProperty verifies consistent user assignment</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> TestAssignmentStabilityProperty</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">t</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">testing</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">T</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    property </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> func</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">user</span><span style=\"color:#B392F0\"> UserID</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">flag</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">FlagDefinition</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 1: Create evaluation engine with test configuration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 2: Build user context with consistent attributes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 3: Evaluate flag 100 times in tight loop</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 4: Verify all evaluations return identical variant</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 5: Return true if stable, false if any variation detected</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Hint: Store first result, compare all subsequent results</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Hint: Use reflect.DeepEqual for EvaluationResult comparison</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#6A737D\"> // Replace with actual stability check</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> quick.</span><span style=\"color:#B392F0\">Check</span><span style=\"color:#E1E4E8\">(property, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#B392F0\">quick</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Config</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        MaxCount: </span><span style=\"color:#79B8FF\">1000</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Rand:     rand.</span><span style=\"color:#B392F0\">New</span><span style=\"color:#E1E4E8\">(rand.</span><span style=\"color:#B392F0\">NewSource</span><span style=\"color:#E1E4E8\">(time.</span><span style=\"color:#B392F0\">Now</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#B392F0\">UnixNano</span><span style=\"color:#E1E4E8\">())),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }); err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        t.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Assignment stability property violated: </span><span style=\"color:#79B8FF\">%v</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// TestPercentageDistributionProperty verifies rollout percentages</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> TestPercentageDistributionProperty</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">t</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">testing</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">T</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    property </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> func</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">percentage</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Clamp percentage to valid range</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> percentage </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 5</span><span style=\"color:#F97583\"> ||</span><span style=\"color:#E1E4E8\"> percentage </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 95</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#6A737D\"> // Skip extreme values</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 1: Create flag with specified percentage allocation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 2: Generate 10,000 diverse user contexts</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 3: Evaluate flag for each user, count variant assignments</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 4: Calculate actual percentage distribution</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 5: Verify actual percentage within ±5% of expected</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Hint: Use chi-square test for distribution validation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Hint: Account for small sample variation in acceptance criteria</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#6A737D\"> // Replace with actual distribution check</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> quick.</span><span style=\"color:#B392F0\">Check</span><span style=\"color:#E1E4E8\">(property, </span><span style=\"color:#79B8FF\">nil</span><span style=\"color:#E1E4E8\">); err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        t.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Percentage distribution property violated: </span><span style=\"color:#79B8FF\">%v</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// TestStatisticalAccuracyProperty verifies significance calculations</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> TestStatisticalAccuracyProperty</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">t</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">testing</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">T</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    property </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> func</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">controlRate</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">treatmentRate</span><span style=\"color:#F97583\"> float64</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">sampleSize</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Validate input ranges</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> controlRate </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 0.01</span><span style=\"color:#F97583\"> ||</span><span style=\"color:#E1E4E8\"> controlRate </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0.99</span><span style=\"color:#F97583\"> ||</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">           treatmentRate </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 0.01</span><span style=\"color:#F97583\"> ||</span><span style=\"color:#E1E4E8\"> treatmentRate </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0.99</span><span style=\"color:#F97583\"> ||</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">           sampleSize </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 100</span><span style=\"color:#F97583\"> ||</span><span style=\"color:#E1E4E8\"> sampleSize </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 10000</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#6A737D\"> // Skip invalid inputs</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 1: Generate synthetic experiment data with known rates</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 2: Call CalculateSignificance with synthetic data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 3: Calculate expected p-value using reference implementation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 4: Verify calculated p-value within acceptable tolerance</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 5: Verify confidence intervals contain true effect size</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Hint: Use gonum/stat for reference statistical calculations</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Hint: Allow 1% tolerance for floating-point precision differences</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#6A737D\"> // Replace with actual accuracy verification</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> quick.</span><span style=\"color:#B392F0\">Check</span><span style=\"color:#E1E4E8\">(property, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#B392F0\">quick</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Config</span><span style=\"color:#E1E4E8\">{MaxCount: </span><span style=\"color:#79B8FF\">100</span><span style=\"color:#E1E4E8\">}); err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        t.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Statistical accuracy property violated: </span><span style=\"color:#79B8FF\">%v</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>E. Milestone Checkpoint Implementation:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// Milestone1ValidationSuite runs comprehensive validation for flag evaluation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> Milestone1ValidationSuite</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">t</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">testing</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">T</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    t.</span><span style=\"color:#B392F0\">Run</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"BasicFunctionality\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">t</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">testing</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">T</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 1: Start evaluation server on test port</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 2: Create simple boolean flag via API</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 3: Evaluate flag with test user context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 4: Verify response structure and timing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 5: Clean up test resources</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    })</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    t.</span><span style=\"color:#B392F0\">Run</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"LoadTesting\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">t</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">testing</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">T</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 1: Create flag with complex targeting rules</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 2: Generate 10,000 concurrent evaluation requests</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 3: Measure average response time and error rate</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 4: Verify all responses are deterministic</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 5: Check for memory leaks and resource cleanup</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    })</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    t.</span><span style=\"color:#B392F0\">Run</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"EdgeCases\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">t</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">testing</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">T</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 1: Test evaluation with malformed user context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 2: Test evaluation with non-existent flag key</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 3: Test evaluation with circular flag dependencies</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 4: Verify graceful degradation in all cases</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 5: Check error messages are informative</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    })</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// checkpoint command: go test -tags=milestone1 -v -timeout=60s ./test/integration/</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// expected: All subtests pass, load test achieves >1000 QPS, &#x3C;1ms avg latency</span></span></code></pre></div>\n\n<p><strong>F. Debugging Property Test Failures:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>Diagnosis Steps</th>\n<th>Resolution</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Property fails on specific input combination</td>\n<td>Edge case in evaluation logic</td>\n<td>Run failing case in debugger, examine intermediate values</td>\n<td>Add bounds checking, handle edge case explicitly</td>\n</tr>\n<tr>\n<td>Property fails intermittently</td>\n<td>Race condition or timing dependency</td>\n<td>Run with <code>-race</code> flag, add logging to identify timing issues</td>\n<td>Add proper synchronization, eliminate timing dependencies</td>\n</tr>\n<tr>\n<td>Property fails on large inputs only</td>\n<td>Performance degradation or resource exhaustion</td>\n<td>Profile memory and CPU usage during large input tests</td>\n<td>Optimize algorithms, add resource limits</td>\n</tr>\n<tr>\n<td>Statistical properties fail consistently</td>\n<td>Mathematical error in calculations</td>\n<td>Compare results with external statistical tools (R, Python)</td>\n<td>Verify formulas, check for floating-point precision issues</td>\n</tr>\n</tbody></table>\n<p>The property-based testing approach ensures your feature flag system maintains its mathematical guarantees under the full range of possible inputs, giving confidence that the system will behave correctly in production environments with diverse user bases and complex flag configurations.</p>\n<h2 id=\"debugging-guide\">Debugging Guide</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section applies to all three milestones by providing systematic debugging approaches for common issues encountered while implementing the Flag Evaluation Engine (Milestone 1), Real-time Flag Updates (Milestone 2), and Flag Analytics &amp; Experiments (Milestone 3).</p>\n</blockquote>\n<p>Think of debugging feature flags as being a detective investigating a mystery. Every incorrect flag evaluation or missed update is a clue pointing to deeper issues in the system. Unlike traditional debugging where you might see immediate crashes, feature flag bugs are often subtle - users getting the wrong variant, rules not evaluating correctly, or updates arriving out of order. These silent failures can impact user experience without triggering obvious error conditions, making systematic debugging approaches essential.</p>\n<p>The complexity of debugging feature flag systems stems from their distributed nature and the multiple layers of caching, networking, and evaluation logic. A single flag evaluation request touches the cache layer, rule evaluation engine, consistent hashing algorithm, and potentially real-time update mechanisms. When something goes wrong, the root cause could be anywhere in this chain, requiring structured approaches to isolate and identify the problem.</p>\n<p>This debugging guide provides systematic methodologies for diagnosing and resolving the most common issues encountered when implementing feature flag systems. Rather than exhaustive troubleshooting for every possible scenario, we focus on the patterns of problems that consistently trip up developers building these systems for the first time.</p>\n<h3 id=\"flag-evaluation-issues\">Flag Evaluation Issues</h3>\n<p>Flag evaluation problems manifest as users receiving unexpected variants, rules not behaving as configured, or inconsistent assignments across multiple evaluations. These issues often stem from incorrect rule precedence, flawed consistent hashing implementation, or mishandled user context processing.</p>\n<p><strong>Mental Model: CSI Investigation</strong>\nThink of debugging flag evaluation like a crime scene investigation. Each evaluation leaves &quot;evidence&quot; in the form of logs, metrics, and cached states. The key is systematically examining this evidence to reconstruct what happened during the evaluation process. Just as a detective follows the timeline of events, you need to trace the evaluation flow from user context input through rule processing to final variant assignment.</p>\n<p>The <code>EvaluationResult</code> structure includes a <code>Reason</code> field specifically designed for debugging - it should contain enough information to understand why a particular variant was chosen. When implementing the evaluation engine, ensure every code path that sets a variant also sets a descriptive reason explaining the decision.</p>\n<h4 id=\"rule-evaluation-problems\">Rule Evaluation Problems</h4>\n<p>Rule evaluation issues typically occur when targeting rules don&#39;t behave as expected, often due to incorrect condition logic, operator precedence problems, or context attribute handling errors.</p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Root Cause</th>\n<th>Investigation Steps</th>\n<th>Resolution</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Rule never matches despite correct user attributes</td>\n<td>Condition operator logic error or AND/OR precedence</td>\n<td>Check <code>EvaluationResult.Reason</code> for rule evaluation details, verify condition evaluation order</td>\n<td>Implement proper boolean expression parsing with parentheses support</td>\n</tr>\n<tr>\n<td>Rule matches wrong users</td>\n<td>Context attribute type mismatch or missing null checks</td>\n<td>Log user context before evaluation, verify attribute types match condition expectations</td>\n<td>Add type validation and safe type conversion in condition evaluation</td>\n</tr>\n<tr>\n<td>Inconsistent rule behavior across evaluations</td>\n<td>Race condition in rule evaluation or shared state mutation</td>\n<td>Test with concurrent evaluations, check for global variable modifications</td>\n<td>Ensure rule evaluation is stateless and thread-safe</td>\n</tr>\n<tr>\n<td>Rules evaluate in wrong order</td>\n<td>Incorrect rule precedence implementation</td>\n<td>Verify rule sorting logic, check for stable sort requirements</td>\n<td>Implement explicit rule priority with tie-breaking mechanisms</td>\n</tr>\n<tr>\n<td>Complex nested conditions fail</td>\n<td>Boolean logic parsing errors or stack overflow</td>\n<td>Test with progressively simpler conditions, check recursion depth</td>\n<td>Implement iterative condition parsing or increase recursion limits</td>\n</tr>\n</tbody></table>\n<p>⚠️ <strong>Pitfall: Forgetting Operator Precedence</strong>\nA common mistake is implementing condition evaluation without proper precedence rules. For example, <code>userAge &gt; 18 AND userCountry = &quot;US&quot; OR userCountry = &quot;CA&quot;</code> should evaluate as <code>(userAge &gt; 18 AND userCountry = &quot;US&quot;) OR userCountry = &quot;CA&quot;</code>, but naive left-to-right evaluation produces different results. Always implement proper boolean expression parsing with AND taking precedence over OR, or require explicit parentheses for complex conditions.</p>\n<p>The <code>evaluateRuleConditions</code> method should handle operator precedence correctly:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Rule Evaluation Algorithm:\n1. Parse conditions into expression tree respecting precedence\n2. Evaluate leaf conditions against user context\n3. Apply boolean operators bottom-up through the tree\n4. Return final boolean result with evaluation path for debugging</code></pre></div>\n\n<p>When debugging rule evaluation, examine the <code>UserContext.Attributes</code> map to ensure all required attributes are present and have the expected types. Missing attributes should be handled gracefully with configurable default behaviors rather than causing evaluation failures.</p>\n<blockquote>\n<p><strong>Design Insight</strong>: Rule evaluation debugging becomes much easier when each condition evaluation is logged with its inputs, operator, and result. This creates an audit trail showing exactly how complex boolean expressions were resolved.</p>\n</blockquote>\n<h4 id=\"consistent-hashing-assignment-problems\">Consistent Hashing Assignment Problems</h4>\n<p>Consistent hashing issues manifest as users receiving different variants across evaluations, percentage rollouts not matching expected distributions, or assignment instability when flag configurations change.</p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Root Cause</th>\n<th>Investigation Steps</th>\n<th>Resolution</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>User gets different variants on repeated evaluations</td>\n<td>Non-deterministic hashing or salt inconsistency</td>\n<td>Test same user/flag combination multiple times, verify hash input construction</td>\n<td>Use stable hash algorithm with consistent salt generation</td>\n</tr>\n<tr>\n<td>Percentage rollout doesn&#39;t match configured allocation</td>\n<td>Bucket calculation error or range assignment logic</td>\n<td>Analyze actual assignment distribution, check bucket boundary calculations</td>\n<td>Verify bucket ranges sum to 100% and boundaries are exclusive</td>\n</tr>\n<tr>\n<td>Assignment changes when unrelated flags modified</td>\n<td>Using unstable hash inputs or global state in bucket calculation</td>\n<td>Test assignment stability when other flags change, verify hash input dependencies</td>\n<td>Ensure hash inputs only include user ID and flag key</td>\n</tr>\n<tr>\n<td>Some users never see certain variants</td>\n<td>Biased hash function or incorrect bucket range mapping</td>\n<td>Check hash output distribution, verify variant allocation math</td>\n<td>Use cryptographic hash function and validate bucket range calculations</td>\n</tr>\n<tr>\n<td>A/B test assignments skewed heavily toward one variant</td>\n<td>Incorrect weight interpretation or cumulative percentage error</td>\n<td>Compare intended vs actual allocation percentages, check weight summation</td>\n<td>Implement proper cumulative percentage calculation for variant selection</td>\n</tr>\n</tbody></table>\n<p>⚠️ <strong>Pitfall: Using Unstable Hash Inputs</strong>\nIncluding volatile data like timestamps, session IDs, or request IDs in the hash calculation causes users to flip between variants unpredictably. The hash input should only include stable identifiers like <code>UserID</code> and <code>FlagKey</code>. Even adding seemingly stable data like user email can cause problems if users change their email addresses.</p>\n<p>The <code>calculateUserBucket</code> function should use a deterministic approach:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Bucket Calculation Algorithm:\n1. Construct hash input from stable user ID and flag key only\n2. Apply cryptographic hash function (SHA-256 or similar)\n3. Convert hash output to integer in range [0, 99]\n4. Map integer to variant based on cumulative weight ranges\n5. Log bucket value and selected variant for debugging</code></pre></div>\n\n<p>Debugging consistent hashing requires examining the actual bucket values assigned to users. Implement logging that shows the hash input, computed bucket, and variant assignment reasoning. This data helps identify patterns in assignment problems and validates that the hashing algorithm produces the expected distribution.</p>\n<blockquote>\n<p><strong>Architecture Decision: Hash Algorithm Selection</strong></p>\n<ul>\n<li><strong>Context</strong>: Need consistent user assignment to variants across evaluations</li>\n<li><strong>Options</strong>: CRC32 checksum, MD5 hash, SHA-256 hash</li>\n<li><strong>Decision</strong>: SHA-256 with user ID + flag key input</li>\n<li><strong>Rationale</strong>: Cryptographic hash ensures uniform distribution, flag key inclusion prevents correlation between different flags</li>\n<li><strong>Consequences</strong>: Higher computation cost but better assignment quality and debuggability</li>\n</ul>\n</blockquote>\n<h4 id=\"context-and-segmentation-issues\">Context and Segmentation Issues</h4>\n<p>User context and segment membership problems cause targeting rules to fail when they should match, or match when they shouldn&#39;t. These issues often arise from context validation problems, segment calculation errors, or attribute type mismatches.</p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Root Cause</th>\n<th>Investigation Steps</th>\n<th>Resolution</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Segment targeting doesn&#39;t work</td>\n<td>Segment membership calculation error or stale segment data</td>\n<td>Verify segment membership computation, check segment cache freshness</td>\n<td>Implement real-time segment recalculation or cache invalidation</td>\n</tr>\n<tr>\n<td>Attribute-based targeting fails</td>\n<td>Missing attributes in context or type conversion errors</td>\n<td>Log complete user context, verify attribute presence and types</td>\n<td>Add context validation with helpful error messages</td>\n</tr>\n<tr>\n<td>Geographic targeting inconsistent</td>\n<td>IP geolocation service issues or timezone problems</td>\n<td>Test with known IP addresses, verify geolocation data accuracy</td>\n<td>Implement geolocation service fallbacks and result caching</td>\n</tr>\n<tr>\n<td>Demographic targeting unreliable</td>\n<td>Outdated user profile data or attribute synchronization lag</td>\n<td>Check user profile data freshness, verify attribute update mechanisms</td>\n<td>Add user profile versioning and change tracking</td>\n</tr>\n<tr>\n<td>Multi-attribute rules fail unexpectedly</td>\n<td>Context parsing errors or attribute name mismatches</td>\n<td>Compare expected vs actual context structure, check attribute naming consistency</td>\n<td>Standardize context schema validation and attribute naming</td>\n</tr>\n</tbody></table>\n<p>⚠️ <strong>Pitfall: Assuming Attribute Availability</strong>\nRules often fail because they assume certain user attributes will always be present. For example, a rule checking <code>userAge &gt; 21</code> fails if the <code>UserContext</code> doesn&#39;t contain an age attribute. Always implement graceful handling for missing attributes with configurable default behaviors.</p>\n<p>The <code>ValidateUserContext</code> function should verify that all required attributes for active targeting rules are present and properly typed:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Context Validation Algorithm:\n1. Extract all attributes referenced by active targeting rules\n2. Verify each required attribute exists in user context\n3. Validate attribute types match rule expectations\n4. Check segment membership data is current and complete\n5. Log any validation warnings or missing data</code></pre></div>\n\n<p>Debugging context issues requires comprehensive logging of the user context data alongside evaluation results. Include the complete <code>UserContext.Attributes</code> map and <code>Segments</code> list in debug logs to verify that targeting rules have access to the expected data.</p>\n<h3 id=\"real-time-update-issues\">Real-time Update Issues</h3>\n<p>Real-time update problems manifest as clients not receiving flag changes, receiving updates out of order, or experiencing connection instability. These issues often stem from connection management problems, event ordering bugs, or cache synchronization failures.</p>\n<p><strong>Mental Model: Television Broadcasting</strong>\nThink of real-time updates like a television broadcast system. The server acts as a broadcast tower sending the same signal to many receivers (client SDKs). When clients don&#39;t receive updates, it could be due to poor signal quality (network issues), wrong channel tuning (connection configuration), or interference (caching problems). Just as TV systems have fallback mechanisms like cable when over-the-air fails, flag update systems need robust fallback hierarchies.</p>\n<p>The key insight for debugging real-time updates is understanding the distinction between connection-level problems (can&#39;t establish or maintain the stream) versus data-level problems (receiving wrong or stale data). These require different diagnostic approaches and solutions.</p>\n<h4 id=\"connection-management-and-reliability\">Connection Management and Reliability</h4>\n<p>Connection problems typically involve clients failing to establish SSE connections, frequent disconnections, or exponential backoff not working correctly.</p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Root Cause</th>\n<th>Investigation Steps</th>\n<th>Resolution</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Clients can&#39;t establish SSE connection</td>\n<td>CORS configuration, proxy blocking SSE, or endpoint not found</td>\n<td>Check browser developer tools network tab, verify SSE endpoint accessibility</td>\n<td>Configure proper CORS headers and proxy SSE support</td>\n</tr>\n<tr>\n<td>Frequent connection drops</td>\n<td>Keep-alive timeout mismatch or network infrastructure issues</td>\n<td>Monitor connection duration patterns, check load balancer timeout settings</td>\n<td>Implement heartbeat mechanism with configurable intervals</td>\n</tr>\n<tr>\n<td>Exponential backoff not working</td>\n<td>Incorrect backoff calculation or missing jitter implementation</td>\n<td>Log actual retry delays, verify backoff formula includes randomization</td>\n<td>Add jitter to prevent thundering herd on reconnection</td>\n</tr>\n<tr>\n<td>Clients stuck in reconnecting state</td>\n<td>Server rejecting connections or client retry logic bug</td>\n<td>Check server logs for connection rejections, verify retry state transitions</td>\n<td>Implement connection state debugging and maximum retry limits</td>\n</tr>\n<tr>\n<td>SSE events not reaching clients</td>\n<td>Server not flushing events or client event parsing errors</td>\n<td>Verify server-side flush calls, check client event handler registration</td>\n<td>Ensure proper SSE message formatting and flushing</td>\n</tr>\n</tbody></table>\n<p>⚠️ <strong>Pitfall: Forgetting SSE Connection Flushing</strong>\nServer-Sent Events require explicit flushing after writing each event, or messages may buffer indefinitely. The <code>SSEServer.BroadcastFlagUpdate</code> method must call <code>Flush()</code> on each client&#39;s response writer after sending the event data. Without flushing, clients appear connected but never receive updates.</p>\n<p>The connection management debugging process should examine both client and server state:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Connection Debugging Algorithm:\n1. Verify SSE endpoint responds with correct Content-Type and headers\n2. Check client connection state transitions in logs\n3. Examine server-side client registry for connected clients\n4. Test connection with curl or browser dev tools\n5. Monitor network layer for connection resets or timeouts</code></pre></div>\n\n<p>Implementing comprehensive connection state logging helps diagnose problems. The <code>ConnectionState</code> should be logged whenever it changes, along with the triggering event and any error details.</p>\n<blockquote>\n<p><strong>Design Insight</strong>: Connection problems often cascade - a single network hiccup can cause mass reconnections if exponential backoff isn&#39;t implemented correctly. Always include jitter in backoff calculations to prevent thundering herd scenarios.</p>\n</blockquote>\n<h4 id=\"event-ordering-and-delivery\">Event Ordering and Delivery</h4>\n<p>Event ordering problems cause clients to process flag updates out of sequence, leading to inconsistent state or missed updates. These issues typically stem from concurrent update broadcasting or improper sequence number handling.</p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Root Cause</th>\n<th>Investigation Steps</th>\n<th>Resolution</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Clients receive events out of order</td>\n<td>Concurrent broadcasting without sequence numbers or race conditions</td>\n<td>Check event sequence numbers in client logs, verify server broadcasting is serialized</td>\n<td>Implement monotonic sequence numbers and client-side ordering</td>\n</tr>\n<tr>\n<td>Some flag updates never arrive at clients</td>\n<td>Event broadcasting failure or client disconnection during update</td>\n<td>Compare server broadcast logs with client received events, check connection status during updates</td>\n<td>Add event acknowledgment mechanism and retry logic</td>\n</tr>\n<tr>\n<td>Clients process duplicate events</td>\n<td>Reconnection replay overlap or at-least-once delivery without deduplication</td>\n<td>Monitor for duplicate sequence numbers, check replay boundary calculation</td>\n<td>Implement client-side deduplication using sequence numbers</td>\n</tr>\n<tr>\n<td>Flag updates arrive but aren&#39;t applied</td>\n<td>Client update processing errors or cache update failures</td>\n<td>Check client-side update processing logs, verify cache invalidation logic</td>\n<td>Add update processing error handling and retry mechanisms</td>\n</tr>\n<tr>\n<td>Bulk flag updates overwhelm clients</td>\n<td>Large payload size or high update frequency without throttling</td>\n<td>Monitor event payload sizes and frequency, check client processing performance</td>\n<td>Implement update batching and client-side throttling</td>\n</tr>\n</tbody></table>\n<p>⚠️ <strong>Pitfall: Race Conditions in Event Broadcasting</strong>\nBroadcasting flag updates concurrently can cause events to arrive out of order at clients. If multiple flag changes occur simultaneously, clients might receive the second change before the first, resulting in inconsistent state. Always serialize flag update broadcasting or use sequence numbers to enable client-side ordering.</p>\n<p>The event ordering debugging approach should trace events from creation through delivery:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Event Ordering Debugging Algorithm:\n1. Generate unique sequence numbers for each flag update event\n2. Log event creation with sequence number and timestamp\n3. Trace event broadcasting to all connected clients\n4. Monitor client event reception with sequence verification\n5. Check for gaps or duplicates in client event sequences</code></pre></div>\n\n<p>Debugging event delivery requires correlation between server broadcast logs and client reception logs. Implement request IDs or trace IDs that span from flag update through client processing to enable end-to-end tracking.</p>\n<h4 id=\"cache-synchronization-problems\">Cache Synchronization Problems</h4>\n<p>Cache synchronization issues cause clients to serve stale flag data despite receiving updates, or fail to invalidate cached values when flags change. These problems often involve cache layer bugs or update processing failures.</p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Root Cause</th>\n<th>Investigation Steps</th>\n<th>Resolution</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Clients serve stale flag values after updates</td>\n<td>Cache invalidation not triggered or cache hierarchy inconsistency</td>\n<td>Check cache invalidation logs, verify update event processing triggers cache refresh</td>\n<td>Ensure update handlers call cache invalidation for affected flags</td>\n</tr>\n<tr>\n<td>Cache updates fail silently</td>\n<td>Storage errors or validation failures during cache write</td>\n<td>Check cache operation error logs, verify storage layer health</td>\n<td>Add cache operation error handling and fallback mechanisms</td>\n</tr>\n<tr>\n<td>Inconsistent cache state across instances</td>\n<td>Race conditions in cache updates or distributed cache synchronization issues</td>\n<td>Compare cache contents across client instances, check update ordering</td>\n<td>Implement cache versioning and conflict resolution</td>\n</tr>\n<tr>\n<td>Memory cache grows unbounded</td>\n<td>Missing cache eviction or TTL not enforced</td>\n<td>Monitor cache size and memory usage, verify eviction policies</td>\n<td>Implement proper cache size limits and LRU eviction</td>\n</tr>\n<tr>\n<td>Local storage cache corruption</td>\n<td>Disk write errors or concurrent access without locking</td>\n<td>Check local storage integrity, verify file locking mechanisms</td>\n<td>Add local storage validation and repair mechanisms</td>\n</tr>\n</tbody></table>\n<p>⚠️ <strong>Pitfall: Ignoring Cache Update Failures</strong>\nWhen real-time flag updates fail to update the local cache, clients continue serving stale data without indication of the problem. The <code>ApplyFlagUpdate</code> method should handle cache update errors gracefully and potentially trigger a full cache refresh if individual updates fail consistently.</p>\n<p>Cache synchronization debugging requires examining the cache hierarchy and update propagation:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Cache Synchronization Debugging Algorithm:\n1. Check memory cache state before and after update events\n2. Verify local storage persistence of cache changes\n3. Compare cache timestamps with server flag modification times\n4. Test cache invalidation triggers from update events\n5. Validate cache consistency across multiple SDK instances</code></pre></div>\n\n<p>Effective cache debugging requires visibility into cache hit rates, invalidation events, and synchronization status. The <code>CacheStats</code> structure should be monitored to identify cache performance issues and synchronization problems.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>This section provides concrete implementation approaches for building debugging capabilities into the feature flag system, focusing on observability, error tracking, and systematic problem resolution.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Error Tracking</td>\n<td>Log to stdout with structured format</td>\n<td>Distributed tracing with OpenTelemetry</td>\n</tr>\n<tr>\n<td>Metrics Collection</td>\n<td>In-memory counters with periodic dumps</td>\n<td>Prometheus metrics with Grafana dashboards</td>\n</tr>\n<tr>\n<td>Debug Logging</td>\n<td>Standard library logger with levels</td>\n<td>Structured logging with correlation IDs</td>\n</tr>\n<tr>\n<td>Health Monitoring</td>\n<td>HTTP endpoint returning component status</td>\n<td>Continuous health checks with alerting</td>\n</tr>\n<tr>\n<td>Performance Profiling</td>\n<td>Built-in Go profiler endpoints</td>\n<td>Continuous profiling with pprof integration</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>internal/debug/\n├── instrumentation.go      ← Debug logging and metrics\n├── health_check.go         ← Component health monitoring\n├── error_classification.go ← Error type classification\n├── evaluation_tracer.go    ← Flag evaluation debugging\n├── connection_monitor.go   ← Real-time connection debugging\n├── cache_inspector.go      ← Cache state examination\n└── debug_test.go          ← Debug functionality tests</code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p>Complete error classification system for categorizing flag system errors:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> debug</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">context</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">fmt</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">sync</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// FlagError represents a categorized error in the flag system</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> FlagError</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Type        </span><span style=\"color:#B392F0\">ErrorType</span><span style=\"color:#9ECBFF\">                `json:\"type\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    FlagKey     </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">                   `json:\"flag_key,omitempty\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Message     </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">                   `json:\"message\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Cause       </span><span style=\"color:#F97583\">error</span><span style=\"color:#9ECBFF\">                   `json:\"cause,omitempty\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Context     </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{}   </span><span style=\"color:#9ECBFF\">`json:\"context,omitempty\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Timestamp   </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">               `json:\"timestamp\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Recoverable </span><span style=\"color:#F97583\">bool</span><span style=\"color:#9ECBFF\">                    `json:\"recoverable\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> ErrorType</span><span style=\"color:#F97583\"> string</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">const</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    ErrorTypeValidation</span><span style=\"color:#B392F0\"> ErrorType</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"validation\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    ErrorTypeNetwork</span><span style=\"color:#B392F0\">    ErrorType</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"network\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    ErrorTypeStorage</span><span style=\"color:#B392F0\">    ErrorType</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"storage\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    ErrorTypeEvaluation</span><span style=\"color:#B392F0\"> ErrorType</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"evaluation\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    ErrorTypeCircuit</span><span style=\"color:#B392F0\">    ErrorType</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"circuit\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    ErrorTypeDependency</span><span style=\"color:#B392F0\"> ErrorType</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"dependency\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    ErrorTypeResource</span><span style=\"color:#B392F0\">   ErrorType</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"resource\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Error implements the error interface</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">e </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FlagError</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Error</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> e.FlagKey </span><span style=\"color:#F97583\">!=</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Sprintf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"[</span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">:</span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">] </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, e.Type, e.FlagKey, e.Message)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Sprintf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"[</span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">] </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, e.Type, e.Message)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Unwrap returns the underlying error for error chain compatibility</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">e </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FlagError</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Unwrap</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> e.Cause</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// NewFlagError creates a new categorized flag error</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewFlagError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">errorType</span><span style=\"color:#B392F0\"> ErrorType</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">flagKey</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">message</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">cause</span><span style=\"color:#F97583\"> error</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FlagError</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">FlagError</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Type:        errorType,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        FlagKey:     flagKey,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Message:     message,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Cause:       cause,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Context:     </span><span style=\"color:#B392F0\">make</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{}),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Timestamp:   time.</span><span style=\"color:#B392F0\">Now</span><span style=\"color:#E1E4E8\">(),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Recoverable: </span><span style=\"color:#B392F0\">isRecoverable</span><span style=\"color:#E1E4E8\">(errorType),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// AddContext adds debugging context to the error</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">e </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FlagError</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">AddContext</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">key</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">value</span><span style=\"color:#F97583\"> interface</span><span style=\"color:#E1E4E8\">{}) </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FlagError</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> e.Context </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        e.Context </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> make</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{})</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    e.Context[key] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> value</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> e</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// isRecoverable determines if an error type typically allows recovery</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> isRecoverable</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">errorType</span><span style=\"color:#B392F0\"> ErrorType</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    switch</span><span style=\"color:#E1E4E8\"> errorType {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    case</span><span style=\"color:#E1E4E8\"> ErrorTypeNetwork, ErrorTypeResource, ErrorTypeCircuit:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> true</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    case</span><span style=\"color:#E1E4E8\"> ErrorTypeValidation, ErrorTypeDependency:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> false</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    case</span><span style=\"color:#E1E4E8\"> ErrorTypeStorage, ErrorTypeEvaluation:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#6A737D\"> // Usually recoverable with retry or fallback</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    default</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> false</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// CircuitBreaker provides failure detection and recovery coordination</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> CircuitBreaker</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    name          </span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    maxFailures   </span><span style=\"color:#F97583\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    resetTimeout  </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    state         </span><span style=\"color:#B392F0\">CircuitState</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    failures      </span><span style=\"color:#F97583\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    lastFailTime  </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    successCount  </span><span style=\"color:#F97583\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    mu           </span><span style=\"color:#B392F0\">sync</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">RWMutex</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> CircuitState</span><span style=\"color:#F97583\"> string</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">const</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    StateClosed</span><span style=\"color:#B392F0\">   CircuitState</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"closed\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    StateOpen</span><span style=\"color:#B392F0\">     CircuitState</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"open\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    StateHalfOpen</span><span style=\"color:#B392F0\"> CircuitState</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"half_open\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Allow checks if the circuit breaker permits a request</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">cb </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">CircuitBreaker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Allow</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cb.mu.</span><span style=\"color:#B392F0\">Lock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> cb.mu.</span><span style=\"color:#B392F0\">Unlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    switch</span><span style=\"color:#E1E4E8\"> cb.state {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    case</span><span style=\"color:#E1E4E8\"> StateClosed:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    case</span><span style=\"color:#E1E4E8\"> StateOpen:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> time.</span><span style=\"color:#B392F0\">Since</span><span style=\"color:#E1E4E8\">(cb.lastFailTime) </span><span style=\"color:#F97583\">></span><span style=\"color:#E1E4E8\"> cb.resetTimeout {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            cb.state </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> StateHalfOpen</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#B392F0\"> NewFlagError</span><span style=\"color:#E1E4E8\">(ErrorTypeCircuit, </span><span style=\"color:#9ECBFF\">\"\"</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            fmt.</span><span style=\"color:#B392F0\">Sprintf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"circuit breaker </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\"> is open\"</span><span style=\"color:#E1E4E8\">, cb.name), </span><span style=\"color:#79B8FF\">nil</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    case</span><span style=\"color:#E1E4E8\"> StateHalfOpen:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    default</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#B392F0\"> NewFlagError</span><span style=\"color:#E1E4E8\">(ErrorTypeCircuit, </span><span style=\"color:#9ECBFF\">\"\"</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            fmt.</span><span style=\"color:#B392F0\">Sprintf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"unknown circuit breaker state: </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, cb.state), </span><span style=\"color:#79B8FF\">nil</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// RecordResult updates circuit breaker state based on operation result</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">cb </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">CircuitBreaker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">RecordResult</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">err</span><span style=\"color:#F97583\"> error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cb.mu.</span><span style=\"color:#B392F0\">Lock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> cb.mu.</span><span style=\"color:#B392F0\">Unlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        cb.failures</span><span style=\"color:#F97583\">++</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        cb.lastFailTime </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.</span><span style=\"color:#B392F0\">Now</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        cb.successCount </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> cb.failures </span><span style=\"color:#F97583\">>=</span><span style=\"color:#E1E4E8\"> cb.maxFailures {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            cb.state </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> StateOpen</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    } </span><span style=\"color:#F97583\">else</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        cb.failures </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        cb.successCount</span><span style=\"color:#F97583\">++</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> cb.state </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> StateHalfOpen </span><span style=\"color:#F97583\">&#x26;&#x26;</span><span style=\"color:#E1E4E8\"> cb.successCount </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> 3</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            cb.state </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> StateClosed</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// State returns the current circuit breaker state</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">cb </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">CircuitBreaker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">State</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#B392F0\">CircuitState</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cb.mu.</span><span style=\"color:#B392F0\">RLock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> cb.mu.</span><span style=\"color:#B392F0\">RUnlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> cb.state</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// NewCircuitBreaker creates a circuit breaker with specified parameters</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewCircuitBreaker</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">name</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">maxFailures</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">resetTimeout</span><span style=\"color:#B392F0\"> time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">CircuitBreaker</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">CircuitBreaker</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        name:         name,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        maxFailures:  maxFailures,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        resetTimeout: resetTimeout,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        state:        StateClosed,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p>Complete health monitoring system for tracking component status:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// ComponentHealth tracks the health status of system components</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> ComponentHealth</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Status     </span><span style=\"color:#B392F0\">HealthStatus</span><span style=\"color:#9ECBFF\"> `json:\"status\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LastCheck  </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">   `json:\"last_check\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LastError  </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"last_error,omitempty\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CheckCount </span><span style=\"color:#F97583\">int64</span><span style=\"color:#9ECBFF\">       `json:\"check_count\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ErrorCount </span><span style=\"color:#F97583\">int64</span><span style=\"color:#9ECBFF\">       `json:\"error_count\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> HealthStatus</span><span style=\"color:#F97583\"> string</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">const</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    HealthStatusHealthy</span><span style=\"color:#B392F0\">   HealthStatus</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"healthy\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    HealthStatusDegraded</span><span style=\"color:#B392F0\">  HealthStatus</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"degraded\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    HealthStatusUnhealthy</span><span style=\"color:#B392F0\"> HealthStatus</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"unhealthy\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// HealthComponent defines interface for health-checkable components</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> HealthComponent</span><span style=\"color:#F97583\"> interface</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    Name</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    Check</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    Recover</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// HealthChecker monitors component health and coordinates recovery</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> HealthChecker</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    components </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#B392F0\">HealthComponent</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    status     </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#B392F0\">ComponentHealth</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    mu         </span><span style=\"color:#B392F0\">sync</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">RWMutex</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    interval   </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    stopCh     </span><span style=\"color:#F97583\">chan</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\">{}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// StartMonitoring begins the health monitoring loop</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">hc </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">HealthChecker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">StartMonitoring</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ticker </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> time.</span><span style=\"color:#B392F0\">NewTicker</span><span style=\"color:#E1E4E8\">(hc.interval)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> ticker.</span><span style=\"color:#B392F0\">Stop</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        select</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        case</span><span style=\"color:#F97583\"> &#x3C;-</span><span style=\"color:#E1E4E8\">ticker.C:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            hc.</span><span style=\"color:#B392F0\">checkAllComponents</span><span style=\"color:#E1E4E8\">(ctx)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        case</span><span style=\"color:#F97583\"> &#x3C;-</span><span style=\"color:#E1E4E8\">hc.stopCh:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        case</span><span style=\"color:#F97583\"> &#x3C;-</span><span style=\"color:#E1E4E8\">ctx.</span><span style=\"color:#B392F0\">Done</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// checkAllComponents performs health checks on all registered components</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">hc </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">HealthChecker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">checkAllComponents</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    hc.mu.</span><span style=\"color:#B392F0\">Lock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> hc.mu.</span><span style=\"color:#B392F0\">Unlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> name, component </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> range</span><span style=\"color:#E1E4E8\"> hc.components {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        health </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> hc.status[name]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        health.CheckCount</span><span style=\"color:#F97583\">++</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        health.LastCheck </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.</span><span style=\"color:#B392F0\">Now</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> component.</span><span style=\"color:#B392F0\">Check</span><span style=\"color:#E1E4E8\">(ctx); err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            health.ErrorCount</span><span style=\"color:#F97583\">++</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            health.LastError </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> err.</span><span style=\"color:#B392F0\">Error</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // Determine health status based on error rate</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            errorRate </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> float64</span><span style=\"color:#E1E4E8\">(health.ErrorCount) </span><span style=\"color:#F97583\">/</span><span style=\"color:#F97583\"> float64</span><span style=\"color:#E1E4E8\">(health.CheckCount)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> errorRate </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0.5</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                health.Status </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> HealthStatusUnhealthy</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                // Attempt recovery for unhealthy components</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> recoverErr </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> component.</span><span style=\"color:#B392F0\">Recover</span><span style=\"color:#E1E4E8\">(ctx); recoverErr </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    health.LastError </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Sprintf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"recovery failed: </span><span style=\"color:#79B8FF\">%v</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, recoverErr)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            } </span><span style=\"color:#F97583\">else</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> errorRate </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0.2</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                health.Status </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> HealthStatusDegraded</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        } </span><span style=\"color:#F97583\">else</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            health.Status </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> HealthStatusHealthy</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            health.LastError </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        hc.status[name] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> health</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeleton-code\">Core Logic Skeleton Code</h4>\n<p>Debug-enhanced flag evaluation that provides comprehensive debugging information:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// EvaluateFlag performs flag evaluation with comprehensive debugging support</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">e </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Evaluator</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">EvaluateFlag</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">flagKey</span><span style=\"color:#B392F0\"> FlagKey</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">userContext</span><span style=\"color:#B392F0\"> UserContext</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">EvaluationResult</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Start evaluation trace with unique trace ID for debugging</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Validate user context and flag key, return descriptive errors for invalid input</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Retrieve flag definition with cache hit/miss logging</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Check flag prerequisites and dependency chain with cycle detection</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Evaluate targeting rules with detailed condition logging</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Perform consistent hashing with bucket calculation details</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Select variant based on percentage allocation with weight verification</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 8: Record evaluation metrics and exposure events</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 9: Return evaluation result with complete reasoning chain</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use structured logging with trace IDs to correlate debugging information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Include evaluation timing metrics to identify performance bottlenecks</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Log cache hit/miss ratio to optimize caching strategy</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// PropagateChange handles flag update distribution with connection tracking</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">u </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">UpdateService</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">PropagateChange</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">flagKey</span><span style=\"color:#B392F0\"> FlagKey</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">changeType</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">payload</span><span style=\"color:#F97583\"> interface</span><span style=\"color:#E1E4E8\">{}) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Validate change payload and generate unique event ID</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Create flag update event with sequence number for ordering</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Broadcast to all connected clients with failure tracking</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Handle broadcasting failures with retry mechanism</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Update propagation metrics and connection health status</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Log successful and failed deliveries for debugging</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Track per-client delivery status to identify problematic connections</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Implement exponential backoff for failed broadcast retries</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Monitor propagation latency to detect performance issues</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ApplyFlagUpdate processes incoming flag changes with cache synchronization</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Client</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">ApplyFlagUpdate</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">event</span><span style=\"color:#B392F0\"> FlagUpdateEvent</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Validate event sequence number and detect out-of-order delivery</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Parse flag update payload with comprehensive error handling</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Update memory cache with version tracking</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Persist to local storage with integrity verification</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Invalidate dependent caches and derived data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Record update processing metrics and cache statistics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Implement sequence number gaps detection for missed updates</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Add cache consistency verification after updates</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Log cache invalidation cascades for debugging dependency issues</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"language-specific-debugging-hints\">Language-Specific Debugging Hints</h4>\n<p><strong>Go-Specific Debugging Techniques:</strong></p>\n<ol>\n<li><p><strong>Use <code>context.Context</code> for Request Tracing</strong>: Pass context through all evaluation calls to maintain trace IDs and enable request correlation across logs.</p>\n</li>\n<li><p><strong>Leverage <code>sync.RWMutex</code> for Safe Concurrent Access</strong>: Use read locks for flag evaluation and write locks for cache updates to prevent race conditions.</p>\n</li>\n<li><p><strong>Implement <code>fmt.Stringer</code> for Complex Types</strong>: Add String() methods to <code>UserContext</code>, <code>EvaluationResult</code>, and other debug types for readable log output.</p>\n</li>\n<li><p><strong>Use <code>testing.T.Logf()</code> for Test Debugging</strong>: In unit tests, use <code>t.Logf()</code> to output debugging information only when tests fail.</p>\n</li>\n<li><p><strong>Add <code>//go:build debug</code> Tags</strong>: Create debug-only code paths that provide extra logging and validation in development builds.</p>\n</li>\n</ol>\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p><strong>Milestone 1 Validation - Flag Evaluation Engine:</strong></p>\n<ul>\n<li>Run <code>go test -v ./internal/evaluation/...</code> - all tests should pass with detailed evaluation logs</li>\n<li>Test flag evaluation with debug logging enabled - should see rule-by-rule evaluation traces</li>\n<li>Verify consistent hashing stability - same user/flag combination should always return same variant</li>\n<li>Expected output: Detailed evaluation logs showing rule matching, bucket calculation, and variant selection reasoning</li>\n</ul>\n<p><strong>Milestone 2 Validation - Real-time Flag Updates:</strong></p>\n<ul>\n<li>Run SSE connection test with <code>curl -N -H &quot;Accept: text/event-stream&quot; http://localhost:8080/flags/stream</code></li>\n<li>Monitor connection logs during network interruption and recovery</li>\n<li>Verify event ordering with sequence numbers in client logs</li>\n<li>Expected output: SSE events received in correct order with reconnection handling and no duplicate processing</li>\n</ul>\n<p><strong>Milestone 3 Validation - Flag Analytics &amp; Experiments:</strong></p>\n<ul>\n<li>Generate test experiment data and verify statistical calculations</li>\n<li>Check exposure event logging for completeness and accuracy</li>\n<li>Validate significance testing with known statistical outcomes</li>\n<li>Expected output: Accurate statistical significance calculations and comprehensive exposure tracking logs</li>\n</ul>\n<p><img src=\"/api/project/feature-flags/architecture-doc/asset?path=diagrams%2Ferror-handling-flow.svg\" alt=\"Error Handling and Fallback Flow\"></p>\n<p>The error handling flow diagram illustrates the decision points and fallback mechanisms that debugging tools must account for when diagnosing system issues. Understanding these flows helps identify where problems originate and which debugging approaches will be most effective.</p>\n<h2 id=\"future-extensions\">Future Extensions</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section provides forward-looking enhancements that build upon the foundation established by all three milestones, extending the Flag Evaluation Engine (Milestone 1), Real-time Flag Updates (Milestone 2), and Flag Analytics &amp; Experiments (Milestone 3) with advanced capabilities for production-scale deployments.</p>\n</blockquote>\n<p>Think of the feature flag system we&#39;ve built as a <strong>city&#39;s traffic infrastructure</strong>. We&#39;ve constructed the core roads (evaluation engine), traffic lights (real-time updates), and monitoring systems (analytics). Now we&#39;re ready to expand our city with highways (multi-environment support), advanced traffic management (sophisticated targeting), and interconnected transportation networks (flag dependencies). Just as a growing city needs these advanced systems to handle increasing complexity and scale, our feature flag system can evolve to support more sophisticated use cases while maintaining the solid foundation we&#39;ve established.</p>\n<p>The design we&#39;ve implemented follows an <strong>evaluation-first architecture</strong> that prioritizes performance and consistency in the core flag evaluation path. This architectural foundation naturally accommodates the extensions described in this section without requiring fundamental changes to the evaluation engine, data model, or real-time update mechanisms. Each extension builds upon existing components while introducing new capabilities that enhance the system&#39;s flexibility and power.</p>\n<h3 id=\"advanced-targeting-and-segmentation\">Advanced Targeting and Segmentation</h3>\n<p>Modern feature flag systems require increasingly sophisticated targeting capabilities beyond basic user attributes and percentage rollouts. Advanced targeting enables product teams to create nuanced user experiences by combining multiple data sources, temporal conditions, and contextual information.</p>\n<p><strong>Dynamic Segment Computation</strong> represents a significant evolution from the static segment membership we implemented in our user context model. Instead of pre-computed segment assignments stored in the <code>UserContext</code>, dynamic segments evaluate membership criteria in real-time during flag evaluation. This approach enables targeting based on live user behavior, current application state, or external system data.</p>\n<p>The dynamic segmentation system would extend our existing <code>TargetingRule</code> structure with new condition types that support external data lookups and computed values. For example, a segment might target &quot;users who made a purchase in the last 7 days&quot; by querying an external analytics service during flag evaluation. While this introduces latency considerations, the evaluation engine&#39;s caching mechanisms and circuit breaker patterns provide natural resilience.</p>\n<blockquote>\n<p><strong>Decision: Real-time vs. Pre-computed Segmentation</strong></p>\n<ul>\n<li><strong>Context</strong>: Advanced targeting requires access to frequently changing user data that may be expensive to pre-compute</li>\n<li><strong>Options Considered</strong>: <ul>\n<li>Pre-compute all segments periodically and store in user context</li>\n<li>Evaluate segments dynamically during flag evaluation with caching</li>\n<li>Hybrid approach with both static and dynamic segments</li>\n</ul>\n</li>\n<li><strong>Decision</strong>: Hybrid approach supporting both static segments (in UserContext) and dynamic segments (evaluated on-demand)</li>\n<li><strong>Rationale</strong>: Maintains backward compatibility while enabling real-time targeting; caching and circuit breakers mitigate performance concerns</li>\n<li><strong>Consequences</strong>: Increased evaluation latency for dynamic segments, but greater targeting flexibility and real-time accuracy</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Segmentation Type</th>\n<th>Evaluation Timing</th>\n<th>Data Freshness</th>\n<th>Performance Impact</th>\n<th>Use Cases</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Static Segments</td>\n<td>Pre-computed</td>\n<td>Batch update intervals</td>\n<td>Low latency</td>\n<td>Demographic targeting, subscription tiers</td>\n</tr>\n<tr>\n<td>Dynamic Segments</td>\n<td>Real-time</td>\n<td>Always current</td>\n<td>Higher latency</td>\n<td>Recent behavior, live metrics, external data</td>\n</tr>\n<tr>\n<td>Cached Dynamic</td>\n<td>First access + TTL refresh</td>\n<td>TTL-bounded</td>\n<td>Moderate latency</td>\n<td>Frequently accessed behavioral segments</td>\n</tr>\n</tbody></table>\n<p><strong>Contextual Targeting</strong> extends the <code>UserContext</code> model to include environmental and situational information beyond user attributes. This includes device characteristics, network conditions, application version, geographic location precision, time-based conditions, and integration with external systems. The evaluation engine&#39;s consistent hashing mechanism ensures that users with identical contexts receive consistent variant assignments even as context information becomes more detailed.</p>\n<p><strong>Multi-dimensional Rollouts</strong> enhance percentage-based targeting by supporting multiple allocation dimensions simultaneously. Instead of a single percentage rollout, flags could allocate users across orthogonal dimensions like geographic region, device type, and user tenure. This enables sophisticated rollout strategies like &quot;10% of mobile users in North America&quot; while maintaining the deterministic assignment properties of our consistent hashing implementation.</p>\n<h3 id=\"flag-dependencies-and-prerequisites\">Flag Dependencies and Prerequisites</h3>\n<p>Complex applications often require coordinated feature rollouts where one feature depends on another being enabled. Flag dependencies create controlled activation sequences and prevent inconsistent feature combinations that could break user experiences.</p>\n<p><strong>Dependency Graph Management</strong> builds upon the cycle detection validation we implemented in the flag evaluation engine. The system would maintain a directed acyclic graph of flag relationships, with each <code>FlagDefinition</code> containing a prerequisites field listing required flags and their states. The evaluation engine extends its processing to check prerequisite satisfaction before applying targeting rules.</p>\n<p>Consider a scenario where a new payment flow (Flag A) depends on updated user authentication (Flag B) and enhanced fraud detection (Flag C). The dependency system ensures Flag A only activates for users who have access to both prerequisites, preventing broken payment experiences.</p>\n<blockquote>\n<p><strong>Key Design Insight</strong>: Flag dependencies should fail safe by defaulting to the most restrictive state. If any prerequisite fails evaluation, the dependent flag should return its default value rather than attempting partial activation.</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Dependency Type</th>\n<th>Description</th>\n<th>Evaluation Impact</th>\n<th>Common Patterns</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Hard Prerequisites</td>\n<td>Required flags must be enabled</td>\n<td>Blocks dependent flag if prerequisites disabled</td>\n<td>Infrastructure changes, breaking API updates</td>\n</tr>\n<tr>\n<td>Soft Dependencies</td>\n<td>Preferred but not required</td>\n<td>Logs warnings but allows evaluation</td>\n<td>UI enhancements, optional integrations</td>\n</tr>\n<tr>\n<td>Mutual Exclusions</td>\n<td>Flags cannot be active simultaneously</td>\n<td>Disables conflicting flags automatically</td>\n<td>A/B test variants, alternative implementations</td>\n</tr>\n<tr>\n<td>Version Dependencies</td>\n<td>Specific versions of prerequisite flags</td>\n<td>Checks version compatibility during evaluation</td>\n<td>API versioning, graduated feature rollouts</td>\n</tr>\n</tbody></table>\n<p><strong>Prerequisite Evaluation Order</strong> requires careful consideration to maintain evaluation performance. The evaluation engine processes dependencies in topological order, caching prerequisite results to avoid repeated evaluation within a single request. The <code>EvaluationResult</code> extends to include dependency information for debugging complex activation scenarios.</p>\n<p><strong>Circular Dependency Prevention</strong> leverages the validation framework established in our flag management system. The dependency validator performs depth-first traversal during flag updates, rejecting configurations that would create cycles. This validation runs during both flag creation and updates, ensuring the dependency graph remains acyclic.</p>\n<h3 id=\"multi-environment-support\">Multi-Environment Support</h3>\n<p>Production feature flag systems must support multiple deployment environments (development, staging, production) with independent configuration management while maintaining operational consistency.</p>\n<p><strong>Environment Isolation</strong> extends the data model with environment-scoped flag definitions. Each <code>FlagDefinition</code> includes an environment identifier, and the flag management API enforces environment-based access controls. This isolation prevents accidental cross-environment configuration changes while allowing controlled promotion workflows.</p>\n<p>The evaluation engine remains environment-agnostic, receiving flag definitions through the same interfaces established in our architecture. Environment-specific configuration occurs at the data layer, with separate storage namespaces or database schemas for each environment. This design maintains evaluation performance while providing complete configuration isolation.</p>\n<blockquote>\n<p><strong>Decision: Environment Configuration Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Multiple environments need independent flag configurations with promotion capabilities</li>\n<li><strong>Options Considered</strong>:<ul>\n<li>Single database with environment field in all records</li>\n<li>Separate databases/schemas per environment</li>\n<li>Environment-specific configuration files</li>\n</ul>\n</li>\n<li><strong>Decision</strong>: Separate storage namespaces with cross-environment promotion API</li>\n<li><strong>Rationale</strong>: Complete isolation prevents accidental changes; promotion API enables controlled configuration flow; maintains existing data model</li>\n<li><strong>Consequences</strong>: Additional operational complexity but maximum safety and flexibility</li>\n</ul>\n</blockquote>\n<p><strong>Configuration Promotion Workflows</strong> enable controlled advancement of flag configurations through environment stages. The system provides promotion APIs that copy flag definitions between environments while maintaining audit trails and validation checkpoints. This builds upon our flag change tracking mechanisms to provide complete configuration lifecycle management.</p>\n<p><strong>Environment-Specific Analytics</strong> extends the experiment framework to segment results by environment, enabling teams to validate feature performance in staging before production rollouts. The <code>FlagExposure</code> model includes environment context, and the significance calculation engine can filter results by environment for isolated analysis.</p>\n<h3 id=\"advanced-analytics-and-machine-learning-integration\">Advanced Analytics and Machine Learning Integration</h3>\n<p>The analytics foundation established in our A/B testing framework naturally extends to support machine learning-driven optimization and predictive analytics capabilities.</p>\n<p><strong>Automated Flag Optimization</strong> uses machine learning models to recommend optimal variant allocations based on observed user behavior and conversion patterns. The system analyzes historical <code>FlagExposure</code> data to identify user segments with different variant preferences, automatically suggesting targeting rules that maximize desired outcomes.</p>\n<p>This capability builds upon our existing significance calculation framework by extending the <code>SignificanceCalculator</code> with predictive models. Instead of only reporting experiment results, the system recommends actions like &quot;increase allocation for mobile users in the high-engagement variant&quot; based on statistical evidence.</p>\n<p><strong>Predictive User Segmentation</strong> applies clustering algorithms to flag exposure and conversion data to identify previously unknown user segments with distinct behavior patterns. These discovered segments become available as targeting criteria in the dynamic segmentation system, creating a feedback loop between analytics insights and flag targeting capabilities.</p>\n<p><strong>Anomaly Detection</strong> monitors flag performance metrics in real-time, automatically alerting teams when conversion rates, error rates, or user engagement metrics deviate significantly from historical patterns. This extends our health monitoring framework to include business-metric monitoring alongside system health checks.</p>\n<table>\n<thead>\n<tr>\n<th>ML Capability</th>\n<th>Data Requirements</th>\n<th>Algorithmic Approach</th>\n<th>Integration Point</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Automated Optimization</td>\n<td>Flag exposures, conversion events</td>\n<td>Multi-armed bandits, Bayesian optimization</td>\n<td>Significance calculator extension</td>\n</tr>\n<tr>\n<td>Predictive Segmentation</td>\n<td>User behavior, attribute data</td>\n<td>K-means clustering, collaborative filtering</td>\n<td>Dynamic segment engine</td>\n</tr>\n<tr>\n<td>Anomaly Detection</td>\n<td>Time-series metrics, baseline data</td>\n<td>Statistical process control, outlier detection</td>\n<td>Health monitoring system</td>\n</tr>\n<tr>\n<td>Causal Impact Analysis</td>\n<td>Pre/post experiment data</td>\n<td>Difference-in-differences, synthetic control</td>\n<td>Experiment results framework</td>\n</tr>\n</tbody></table>\n<h3 id=\"global-distribution-and-edge-computing\">Global Distribution and Edge Computing</h3>\n<p>Large-scale applications require feature flag evaluation at global scale with minimal latency, necessitating edge computing integration and distributed caching strategies.</p>\n<p><strong>Edge Evaluation Nodes</strong> deploy lightweight versions of the evaluation engine to edge locations worldwide. These nodes maintain cached flag definitions synchronized through our real-time update system, enabling sub-millisecond flag evaluation anywhere in the world. The edge nodes implement the same evaluation algorithms and consistent hashing mechanisms as the central system, ensuring globally consistent user assignments.</p>\n<p>The distributed architecture maintains the same API interfaces while adding geographic routing intelligence. Client SDKs automatically discover and connect to the nearest edge node, falling back to central evaluation during edge node failures. This builds upon our existing fallback hierarchy patterns while adding geographic distribution.</p>\n<p><strong>Conflict-Free Replicated Data Types (CRDTs)</strong> provide eventual consistency for flag configurations across distributed edge nodes. Flag updates propagate through the real-time update system while CRDT properties ensure all nodes converge to identical configuration states despite network partitions or update ordering differences.</p>\n<p><strong>Regional Compliance and Data Sovereignty</strong> extends the multi-environment architecture to support regulatory requirements like GDPR data locality. Flag configurations and user context data remain within specified geographic boundaries while maintaining global evaluation consistency through federated architectures.</p>\n<h3 id=\"enterprise-integration-capabilities\">Enterprise Integration Capabilities</h3>\n<p>Production deployments require integration with existing enterprise systems for authentication, authorization, audit logging, and workflow management.</p>\n<p><strong>Single Sign-On (SSO) Integration</strong> extends the flag management API with pluggable authentication providers supporting SAML, OAuth 2.0, and OpenID Connect. The system maintains role-based access controls for flag management while delegating authentication to enterprise identity providers.</p>\n<p><strong>Audit and Compliance Logging</strong> enhances our flag change tracking to meet enterprise audit requirements. Every flag modification, user assignment, and experiment result includes comprehensive audit metadata suitable for compliance reporting. The system supports audit log export in standard formats and integrates with Security Information and Event Management (SIEM) systems.</p>\n<p><strong>Workflow Integration</strong> connects flag lifecycle management with existing development and deployment workflows. This includes integration with source control systems for configuration-as-code, continuous integration pipelines for automated flag validation, and project management tools for feature delivery tracking.</p>\n<p><strong>API Gateway Integration</strong> enables centralized feature flag evaluation within API gateway infrastructure, providing flag-based request routing, rate limiting, and access control. This architectural pattern reduces evaluation latency by embedding flag logic directly in the request processing pipeline.</p>\n<h3 id=\"performance-optimization-extensions\">Performance Optimization Extensions</h3>\n<p>As usage scales, the system benefits from advanced performance optimization techniques that maintain the evaluation-first design principles while handling extreme throughput requirements.</p>\n<p><strong>Evaluation Result Caching</strong> extends beyond our current flag definition caching to cache evaluation results for identical user contexts. This optimization particularly benefits scenarios with repeated evaluations for the same users, though it requires careful cache invalidation when flag configurations change.</p>\n<p><strong>Batch Evaluation APIs</strong> support evaluating multiple flags simultaneously for a single user context, reducing network overhead and enabling optimizations like shared rule evaluation across flags. This maintains the deterministic evaluation properties while improving throughput for SDK implementations.</p>\n<p><strong>Asynchronous Evaluation Pipelines</strong> separate flag evaluation from result delivery for use cases where immediate responses aren&#39;t required. This enables advanced optimizations like speculative evaluation and result pre-computation based on predicted user behavior patterns.</p>\n<p><strong>Memory-Efficient Data Structures</strong> replace standard hash tables and trees with specialized data structures optimized for flag evaluation workloads. Techniques like compressed tries for rule matching and bloom filters for negative lookups reduce memory usage while maintaining evaluation speed.</p>\n<h3 id=\"integration-ecosystem-extensions\">Integration Ecosystem Extensions</h3>\n<p>The feature flag system becomes more valuable as part of a broader development and operations ecosystem, requiring integration capabilities that extend its utility without compromising core functionality.</p>\n<p><strong>Observability Platform Integration</strong> connects flag evaluation metrics with distributed tracing systems, application performance monitoring, and log aggregation platforms. Every flag evaluation becomes observable within the broader application context, enabling correlation analysis between feature flags and system behavior.</p>\n<p><strong>Feature Management Lifecycle Tools</strong> extend beyond flag evaluation to support the complete feature development lifecycle. This includes feature planning tools that integrate with flag definitions, deployment tracking that correlates flag changes with application releases, and technical debt management that identifies obsolete flags for cleanup.</p>\n<p><strong>Developer Experience Enhancements</strong> improve the day-to-day interaction with the feature flag system through IDE plugins, command-line tools, and local development environment integration. These tools build upon our existing SDK architecture while providing development-time conveniences that encourage proper flag usage.</p>\n<h3 id=\"scalability-architecture-enhancements\">Scalability Architecture Enhancements</h3>\n<p>Supporting massive scale requires architectural enhancements that maintain the system&#39;s reliability and performance characteristics while handling orders of magnitude more traffic.</p>\n<p><strong>Horizontal Evaluation Scaling</strong> distributes flag evaluation across multiple server instances using consistent hashing for request distribution. This maintains user assignment consistency while enabling linear scaling of evaluation throughput. The architecture builds upon our existing load balancing and health monitoring capabilities.</p>\n<p><strong>Event Streaming Architecture</strong> replaces direct database interactions with event-driven patterns using systems like Apache Kafka. Flag changes become events in the stream, enabling multiple consumers to process updates for real-time propagation, analytics processing, and audit logging without impacting evaluation performance.</p>\n<p><strong>Polyglot Storage Strategies</strong> optimize data storage by matching storage technologies to access patterns. Flag definitions might live in document stores for flexible schema evolution, while evaluation results use time-series databases optimized for analytics queries. The abstraction layers in our architecture facilitate these storage technology choices without affecting client interfaces.</p>\n<h3 id=\"future-proofing-considerations\">Future-Proofing Considerations</h3>\n<p>The extensions described maintain compatibility with our core architectural decisions while providing natural evolution paths as requirements continue expanding.</p>\n<p><strong>API Versioning Strategy</strong> ensures backward compatibility as new capabilities add to existing interfaces. The REST API design accommodates feature additions through optional parameters and response fields, while SDK interfaces use extensible patterns that don&#39;t break existing client code.</p>\n<p><strong>Configuration Schema Evolution</strong> supports adding new flag types, targeting criteria, and evaluation modes without requiring system-wide updates. The validation framework accommodates schema versioning, enabling gradual rollout of new capabilities across distributed deployments.</p>\n<p><strong>Telemetry and Instrumentation</strong> provides comprehensive visibility into system behavior as complexity increases. This builds upon our health monitoring foundation while adding detailed metrics for capacity planning, performance optimization, and operational decision-making.</p>\n<blockquote>\n<p><strong>Critical Insight</strong>: Each extension maintains the evaluation-first design principle by ensuring core flag evaluation performance doesn&#39;t degrade as new capabilities are added. Complex features are implemented as optional enhancements rather than fundamental changes to the evaluation path.</p>\n</blockquote>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The extensions described can be implemented incrementally without disrupting existing functionality. The modular architecture established in our original design provides natural extension points for these capabilities.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Extension Category</th>\n<th>Simple Approach</th>\n<th>Advanced Approach</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Dynamic Segmentation</td>\n<td>HTTP calls to external APIs with caching</td>\n<td>Event-driven segment computation with stream processing</td>\n</tr>\n<tr>\n<td>Edge Distribution</td>\n<td>CDN with API caching</td>\n<td>Dedicated edge computing platform with custom evaluation nodes</td>\n</tr>\n<tr>\n<td>ML Integration</td>\n<td>Periodic batch analysis with manual recommendations</td>\n<td>Real-time ML inference with automated optimization</td>\n</tr>\n<tr>\n<td>Enterprise Integration</td>\n<td>Basic RBAC with API keys</td>\n<td>Full SSO integration with enterprise workflow systems</td>\n</tr>\n<tr>\n<td>Advanced Analytics</td>\n<td>Extended PostgreSQL with time-series tables</td>\n<td>Dedicated analytics database with specialized query engines</td>\n</tr>\n</tbody></table>\n<h4 id=\"extension-implementation-strategy\">Extension Implementation Strategy</h4>\n<p>When implementing these extensions, follow a <strong>capability-driven approach</strong> that adds new functionality without modifying core evaluation logic. Each extension should:</p>\n<ol>\n<li><p><strong>Maintain Interface Compatibility</strong>: New capabilities extend existing interfaces rather than replacing them, ensuring client SDKs continue working without modification.</p>\n</li>\n<li><p><strong>Preserve Performance Characteristics</strong>: Extensions shouldn&#39;t degrade evaluation latency or throughput. Performance-impacting features like dynamic segmentation include circuit breakers and caching mechanisms.</p>\n</li>\n<li><p><strong>Support Gradual Rollout</strong>: New capabilities can be enabled incrementally, allowing validation in development and staging environments before production deployment.</p>\n</li>\n<li><p><strong>Provide Operational Visibility</strong>: Each extension includes monitoring, logging, and health checking capabilities that integrate with existing operational tools.</p>\n</li>\n</ol>\n<p>The architectural foundation we&#39;ve established provides natural extension points through:</p>\n<ul>\n<li>Plugin interfaces for new evaluation criteria and segment types</li>\n<li>Event streaming capabilities for real-time data integration</li>\n<li>Caching abstractions that support new data sources</li>\n<li>Health monitoring frameworks that accommodate new component types</li>\n</ul>\n<h4 id=\"development-priorities\">Development Priorities</h4>\n<p>When choosing which extensions to implement first, consider business value and architectural complexity:</p>\n<p><strong>High Value, Low Complexity</strong>: Multi-environment support and basic flag dependencies provide immediate operational benefits with minimal architectural changes.</p>\n<p><strong>High Value, High Complexity</strong>: Advanced targeting and ML-driven optimization deliver significant capabilities but require careful implementation to maintain performance.</p>\n<p><strong>Foundation Building</strong>: Edge distribution and enterprise integration create platforms for future capabilities while providing immediate value for large-scale deployments.</p>\n<p>The modular architecture ensures that implementing one extension doesn&#39;t preclude others, allowing development teams to prioritize based on immediate business needs while maintaining long-term architectural flexibility.</p>\n<h2 id=\"glossary\">Glossary</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section provides comprehensive definitions for terminology used across all three milestones, ensuring consistent understanding of concepts throughout the Flag Evaluation Engine (Milestone 1), Real-time Flag Updates (Milestone 2), and Flag Analytics &amp; Experiments (Milestone 3) implementation.</p>\n</blockquote>\n<p>The feature flag system introduces numerous specialized terms and concepts that span multiple domains including distributed systems, statistical analysis, real-time communication, and software release management. This glossary serves as the authoritative reference for understanding the precise meaning of each term as used within our system&#39;s context.</p>\n<h3 id=\"core-system-concepts\">Core System Concepts</h3>\n<p><strong>Feature Flags</strong> are runtime toggles that control feature availability without requiring code deployment. Think of feature flags as smart light switches in a building automation system - they can be controlled remotely, scheduled to activate at specific times, and configured with complex rules about who can access them. Unlike simple boolean toggles, our feature flags support multiple variants, percentage rollouts, and sophisticated targeting rules.</p>\n<p><strong>Air Traffic Control</strong> serves as our mental model for coordinating software releases. Just as air traffic controllers manage multiple aircraft approaching an airport with different priorities, weather conditions, and landing capabilities, feature flags coordinate the rollout of multiple features to different user segments with varying risk tolerances and business requirements. The control tower (flag management system) maintains a real-time view of all active &quot;flights&quot; (feature rollouts) and can adjust their &quot;flight paths&quot; (targeting rules) or &quot;landing sequences&quot; (rollout percentages) based on current conditions.</p>\n<p><strong>Consistent Hashing</strong> is the deterministic algorithm that ensures users receive the same variants across evaluations. This functions like a deterministic seating assignment system - given a user ID and flag key, the algorithm always assigns the same &quot;seat&quot; (variant) to that user, regardless of when or where the assignment occurs. This prevents users from experiencing jarring transitions between different feature variants.</p>\n<p><strong>Graceful Degradation</strong> describes how the system maintains functionality during partial failures. Like a commercial building&#39;s backup power systems, the feature flag system includes multiple fallback layers: memory cache, local storage, and default values. When the primary flag service becomes unavailable, the system automatically switches to increasingly stale but still functional data sources.</p>\n<p><strong>Flag Debt</strong> represents the accumulation of obsolete feature flags in the codebase. Similar to technical debt, flag debt compounds over time as old flags remain in code long after their experiments conclude. Each unused flag increases cognitive load, creates potential security risks through unintended code paths, and complicates system maintenance.</p>\n<h3 id=\"evaluation-and-targeting\">Evaluation and Targeting</h3>\n<p><strong>Evaluation Flow</strong> describes the step-by-step process from client request to variant assignment. The flow begins when a client SDK requests a flag evaluation, continues through rule processing and consistent hashing, and concludes with variant assignment and exposure logging. Each step includes error handling and fallback mechanisms to ensure reliable operation.</p>\n<p><strong>Targeting Rules</strong> are conditions that determine user variant assignment based on user context and environmental factors. These rules function like sophisticated email filters that can examine multiple user attributes, combine conditions with boolean logic, and apply percentage-based allocations. Rules are evaluated in priority order until a match is found.</p>\n<p><strong>Percentage Rollout</strong> enables gradual feature exposure using allocation buckets. Think of this as a controlled water release from a dam - you can gradually open the gates (increase percentage) to allow more water (users) through while monitoring downstream effects (metrics). The bucket ranges are calculated using consistent hashing to ensure stable user assignment.</p>\n<p><strong>User Context</strong> provides comprehensive user information for targeting decisions. This includes stable identifiers, demographic attributes, behavioral data, and environmental context like geographic location or device type. The context serves as the input to targeting rule evaluation and consistent hashing calculations.</p>\n<p><strong>Segment Membership</strong> represents pre-computed group classifications for efficient targeting. Rather than evaluating complex conditions for each flag request, segments allow for efficient &quot;user is in premium_customers segment&quot; checks. Segments can be static (manually managed) or dynamic (automatically computed based on user attributes).</p>\n<p><strong>Dynamic Segmentation</strong> performs real-time evaluation of user segment membership during flag evaluation. While pre-computed segments optimize performance for stable user groups, dynamic segmentation enables targeting based on real-time context like current session behavior or time-sensitive conditions.</p>\n<h3 id=\"data-structures-and-types\">Data Structures and Types</h3>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Description</th>\n<th>Key Fields</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>FlagKey</code></td>\n<td>String identifier uniquely identifying a feature flag across the system</td>\n<td>-</td>\n</tr>\n<tr>\n<td><code>UserID</code></td>\n<td>Stable identifier for a user that remains consistent across sessions and evaluations</td>\n<td>-</td>\n</tr>\n<tr>\n<td><code>Variant</code></td>\n<td>Represents a possible flag outcome with its configuration and traffic allocation</td>\n<td>Key, Value, Weight</td>\n</tr>\n<tr>\n<td><code>UserContext</code></td>\n<td>Comprehensive user information used for targeting and segmentation</td>\n<td>UserID, Attributes, Segments</td>\n</tr>\n<tr>\n<td><code>EvaluationResult</code></td>\n<td>Complete outcome of flag evaluation including value, reason, and audit trail</td>\n<td>FlagKey, Value, Variant, Reason, Source</td>\n</tr>\n<tr>\n<td><code>FlagDefinition</code></td>\n<td>Complete specification of a feature flag including all rules and variants</td>\n<td>FlagKey, Name, Description, Variants, DefaultVariant, Rules, Dependencies</td>\n</tr>\n<tr>\n<td><code>TargetingRule</code></td>\n<td>Individual targeting condition with associated variant allocation</td>\n<td>Conditions, Operator, Allocation</td>\n</tr>\n<tr>\n<td><code>AttributeValue</code></td>\n<td>Type-safe wrapper for user attributes supporting multiple data types</td>\n<td>-</td>\n</tr>\n</tbody></table>\n<h3 id=\"real-time-communication\">Real-time Communication</h3>\n<p><strong>Server-Sent Events</strong> provide unidirectional streaming protocol for real-time updates from server to client. SSE functions like a radio broadcast where the server (radio station) transmits updates to all listening clients (radios). Unlike bidirectional protocols like WebSocket, SSE maintains simplicity by focusing solely on server-to-client communication with built-in reconnection handling.</p>\n<p><strong>Cache Invalidation</strong> describes updating cached flag definitions when configurations change. Like a content delivery network pushing updated website assets, the flag system must coordinate cache updates across all client instances to prevent serving stale flag configurations.</p>\n<p><strong>Connection Management</strong> handles the establishment, maintenance, and recovery of streaming connections between clients and the update service. This includes implementing exponential backoff for reconnection attempts, maintaining connection state, and gracefully handling network partitions.</p>\n<p><strong>Thundering Herd</strong> occurs when mass simultaneous connection attempts overwhelm the service. This typically happens when many clients lose connection simultaneously (due to server restart or network issue) and all attempt to reconnect immediately. The system prevents this through randomized backoff delays.</p>\n<p><strong>Exponential Backoff</strong> implements progressively longer retry delays with randomization to prevent overwhelming failed services. Starting with a short delay (e.g., 100ms), each retry doubles the delay (200ms, 400ms, 800ms) while adding jitter to prevent synchronized retries across multiple clients.</p>\n<h3 id=\"statistical-and-experimental-concepts\">Statistical and Experimental Concepts</h3>\n<p><strong>Flag Analytics</strong> encompasses comprehensive tracking and analysis of feature flag usage and performance. This includes exposure tracking, conversion attribution, performance monitoring, and business impact measurement. Analytics enable data-driven decisions about feature rollouts and business value assessment.</p>\n<p><strong>Exposure Events</strong> are recorded instances of users encountering specific flag variants. Each exposure captures the complete context of the evaluation including user attributes, variant assigned, timestamp, and evaluation reason. These events form the foundation for all subsequent analysis.</p>\n<p><strong>A/B Testing Framework</strong> provides systematic approach to controlled feature experimentation. The framework manages experiment lifecycle from setup through analysis, ensuring proper randomization, statistical power, and unbiased result interpretation.</p>\n<p><strong>Statistical Significance</strong> represents mathematical confidence that observed differences between variants are not due to random chance. The system uses established statistical tests (chi-square for categorical outcomes, t-tests for continuous metrics) with appropriate corrections for multiple comparisons.</p>\n<p><strong>Sample Ratio Mismatch</strong> occurs when the actual variant allocation ratios deviate significantly from intended ratios. This can indicate implementation bugs, biased assignment logic, or data collection issues. The system continuously monitors for SRM and alerts when detected.</p>\n<p><strong>Intent-to-treat Analysis</strong> analyzes all assigned users regardless of actual exposure to the feature. This approach prevents bias from users who opt out or experience technical issues that prevent feature loading, providing a more conservative but unbiased estimate of feature impact.</p>\n<p><strong>Sequential Testing</strong> enables valid interim analysis of experiments without inflating false positive rates. Unlike traditional fixed-sample tests, sequential methods allow peeking at results during the experiment using appropriate statistical boundaries.</p>\n<p><strong>Power Analysis</strong> calculates the sample size needed for reliable effect detection given expected effect size, significance level, and desired statistical power. This prevents underpowered experiments that fail to detect meaningful effects.</p>\n<p><strong>Survivorship Bias</strong> represents analytical error from excluding users who dropped out during the experiment. For example, analyzing only users who completed a multi-step flow ignores the impact on users who abandoned earlier steps.</p>\n<h3 id=\"system-architecture-and-operations\">System Architecture and Operations</h3>\n<p><strong>Evaluation-first Design</strong> prioritizes flag evaluation performance above all other system considerations. Like designing a race car where aerodynamics takes precedence over passenger comfort, our architecture optimizes for sub-millisecond evaluation latency even when this complicates other system aspects.</p>\n<p><strong>Fallback Hierarchy</strong> defines the ordered sequence of data sources used when primary sources become unavailable. The hierarchy typically flows from real-time service → memory cache → local storage → default values, with each layer providing increasingly stale but still functional flag data.</p>\n<p><strong>Circuit Breaker</strong> prevents cascade failures by temporarily stopping requests to failing services. When a dependent service experiences high error rates, the circuit breaker opens, immediately returning cached results instead of continuing to send requests to the failing service.</p>\n<p><strong>Load Shedding</strong> involves selectively dropping requests during high traffic to maintain service availability for critical operations. The system may prioritize flag evaluations over analytics ingestion or defer less critical operations when under extreme load.</p>\n<p><strong>Health Monitoring</strong> systematically checks component operational status to enable proactive issue detection and automated recovery. Each system component reports health metrics including response times, error rates, and resource utilization.</p>\n<h3 id=\"error-handling-and-resilience\">Error Handling and Resilience</h3>\n<table>\n<thead>\n<tr>\n<th>Error Type</th>\n<th>Description</th>\n<th>Recovery Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>ErrorTypeValidation</code></td>\n<td>Invalid flag definitions or user context</td>\n<td>Return validation errors with specific field information</td>\n</tr>\n<tr>\n<td><code>ErrorTypeNetwork</code></td>\n<td>Connection failures or timeouts</td>\n<td>Retry with exponential backoff, fallback to cache</td>\n</tr>\n<tr>\n<td><code>ErrorTypeStorage</code></td>\n<td>Database or persistence layer failures</td>\n<td>Switch to read-only mode, use cached data</td>\n</tr>\n<tr>\n<td><code>ErrorTypeEvaluation</code></td>\n<td>Rule processing errors or dependency cycles</td>\n<td>Return default variant with error logging</td>\n</tr>\n<tr>\n<td><code>ErrorTypeCircuit</code></td>\n<td>Circuit breaker preventing requests</td>\n<td>Return cached results, attempt periodic recovery</td>\n</tr>\n<tr>\n<td><code>ErrorTypeDependency</code></td>\n<td>Required services unavailable</td>\n<td>Activate fallback data sources</td>\n</tr>\n<tr>\n<td><code>ErrorTypeResource</code></td>\n<td>Memory or processing capacity exceeded</td>\n<td>Enable load shedding, scale horizontally</td>\n</tr>\n</tbody></table>\n<p><strong>Split-brain Scenario</strong> occurs during network partitions where different parts of the system operate independently with potentially conflicting state. The system prevents this through consistent leadership election and read-only fallback modes during partition events.</p>\n<p><strong>Optimistic Consistency</strong> allows immediate writes with asynchronous distribution to connected clients. While this may create temporary inconsistency across clients, it provides better user experience than waiting for global consensus on every flag change.</p>\n<p><strong>At-least-once Delivery</strong> guarantees message delivery with possible duplication. The system includes sequence numbers and idempotency checks to handle duplicate flag updates gracefully.</p>\n<h3 id=\"development-and-testing\">Development and Testing</h3>\n<p><strong>Property-based Testing</strong> validates system invariants using randomly generated inputs. Rather than testing specific scenarios, property tests verify that fundamental system properties (like assignment stability and rule determinism) hold across a wide range of inputs.</p>\n<p><strong>Milestone Validation</strong> provides quality gates between development phases. Each milestone includes specific acceptance criteria, test scenarios, and performance benchmarks that must be met before proceeding to subsequent development phases.</p>\n<p><strong>Assignment Stability</strong> ensures users receive the same variant consistently across evaluations. This property is critical for user experience and experiment validity - users should not flip between variants due to evaluation timing or system state.</p>\n<p><strong>Rule Evaluation Determinism</strong> guarantees that targeting rules evaluate consistently given identical input context. This property ensures reliable system behavior and simplifies debugging when evaluation outcomes don&#39;t match expectations.</p>\n<p><strong>Cache Consistency</strong> maintains alignment between cached data and authoritative sources. While temporary inconsistency is acceptable for performance, the system must eventually converge to consistent state across all cache levels.</p>\n<h3 id=\"advanced-concepts\">Advanced Concepts</h3>\n<p><strong>Prerequisite Flags</strong> are required flags that must be enabled before dependent flags activate. This creates a dependency graph that prevents invalid feature combinations - for example, a premium feature flag that depends on the user authentication flag being enabled.</p>\n<p><strong>Multi-environment Support</strong> provides independent flag configurations across development, staging, and production environments. Each environment maintains separate flag state while sharing common flag definitions and targeting rule templates.</p>\n<p><strong>Configuration Promotion</strong> enables controlled advancement of flag settings between environments. Changes typically flow from development → staging → production with appropriate testing and approval gates at each stage.</p>\n<p><strong>Edge Evaluation</strong> performs flag evaluation at geographically distributed nodes to reduce latency for global applications. This requires careful cache synchronization and fallback strategies to maintain consistency across edge locations.</p>\n<p><strong>Contextual Targeting</strong> extends basic user targeting to include environmental and situational factors like time of day, geographic location, device characteristics, or application version. This enables sophisticated targeting scenarios like &quot;show feature X only to mobile users in Pacific timezone during business hours.&quot;</p>\n<h3 id=\"performance-and-scalability\">Performance and Scalability</h3>\n<p><strong>Bucket Ranges</strong> represent deterministic allocation intervals for percentage splits. When implementing a 30%/70% split, users hash into buckets 0-29 (first variant) or 30-99 (second variant). The bucket assignment remains stable as percentages change.</p>\n<p><strong>Sequence Numbers</strong> provide monotonic identifiers that prevent out-of-order processing of flag updates. Each update includes a sequence number that clients use to detect and handle updates that arrive out of order due to network conditions.</p>\n<p><strong>Event Ordering</strong> ensures updates are processed in correct sequence even when network delivery occurs out of order. The system buffers out-of-order events and processes them when missing sequence numbers arrive.</p>\n<p><strong>Resource Exhaustion</strong> occurs when the system runs out of memory, file handles, or other critical resources. The system monitors resource usage and implements graceful degradation strategies like reducing cache sizes or limiting concurrent connections.</p>\n<p><strong>Dependency Graph</strong> represents the directed acyclic graph of flag prerequisite relationships. The system validates this graph to prevent circular dependencies and computes evaluation order to ensure prerequisite flags are evaluated before dependent flags.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The glossary definitions above establish the conceptual foundation needed to implement a robust feature flag system. Each term has been defined with sufficient precision to guide implementation decisions while remaining accessible to developers new to feature flag systems.</p>\n<p>When implementing system components, refer to these definitions to ensure consistent terminology and behavior across all modules. The data structure definitions provide the exact field specifications needed for implementation, while the conceptual terms establish the mental models for understanding system behavior.</p>\n<p>For debugging and troubleshooting, this glossary serves as a reference for understanding error messages, log entries, and system behavior descriptions. When encountering unfamiliar terms in documentation or code comments, this glossary provides the authoritative definition within the context of our feature flag system.</p>\n<p>The progression from basic concepts (feature flags, variants) through advanced topics (statistical significance, edge evaluation) reflects the learning journey developers will experience when implementing and operating the system. Mastering the foundational terms enables understanding of more sophisticated concepts as system requirements evolve.</p>\n","toc":[{"level":1,"text":"Feature Flag System: Design Document","id":"feature-flag-system-design-document"},{"level":2,"text":"Overview","id":"overview"},{"level":2,"text":"Context and Problem Statement","id":"context-and-problem-statement"},{"level":3,"text":"Mental Model: Software Release as Air Traffic Control","id":"mental-model-software-release-as-air-traffic-control"},{"level":3,"text":"Existing Approaches Comparison","id":"existing-approaches-comparison"},{"level":4,"text":"Configuration Files Approach","id":"configuration-files-approach"},{"level":4,"text":"Environment Variables Approach","id":"environment-variables-approach"},{"level":4,"text":"Database Toggle Approach","id":"database-toggle-approach"},{"level":4,"text":"Dedicated Feature Flag Services","id":"dedicated-feature-flag-services"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended Project Structure","id":"recommended-project-structure"},{"level":4,"text":"Core Type Definitions","id":"core-type-definitions"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Development Environment Setup","id":"development-environment-setup"},{"level":4,"text":"Milestone Checkpoint for Foundation","id":"milestone-checkpoint-for-foundation"},{"level":2,"text":"Goals and Non-Goals","id":"goals-and-non-goals"},{"level":3,"text":"Mental Model: Air Traffic Control Tower Responsibilities","id":"mental-model-air-traffic-control-tower-responsibilities"},{"level":3,"text":"Primary Goals","id":"primary-goals"},{"level":4,"text":"Goal 1: Reliable Flag Evaluation with Complex Targeting","id":"goal-1-reliable-flag-evaluation-with-complex-targeting"},{"level":4,"text":"Goal 2: Real-time Configuration Updates","id":"goal-2-real-time-configuration-updates"},{"level":4,"text":"Goal 3: Comprehensive Analytics and A/B Testing","id":"goal-3-comprehensive-analytics-and-ab-testing"},{"level":4,"text":"Goal 4: Production-Ready Reliability","id":"goal-4-production-ready-reliability"},{"level":3,"text":"Non-Goals","id":"non-goals"},{"level":4,"text":"Non-Goal 1: Advanced Infrastructure Management","id":"non-goal-1-advanced-infrastructure-management"},{"level":4,"text":"Non-Goal 2: Complex Business Logic Integration","id":"non-goal-2-complex-business-logic-integration"},{"level":4,"text":"Non-Goal 3: Advanced Machine Learning Features","id":"non-goal-3-advanced-machine-learning-features"},{"level":4,"text":"Non-Goal 4: Comprehensive Application Performance Monitoring","id":"non-goal-4-comprehensive-application-performance-monitoring"},{"level":3,"text":"Scope Boundaries and Integration Points","id":"scope-boundaries-and-integration-points"},{"level":4,"text":"Integration Philosophy","id":"integration-philosophy"},{"level":4,"text":"Client SDK Integration Requirements","id":"client-sdk-integration-requirements"},{"level":3,"text":"Architecture Decision Records","id":"architecture-decision-records"},{"level":4,"text":"Decision: Evaluation-First Design Priority","id":"decision-evaluation-first-design-priority"},{"level":4,"text":"Decision: Explicit Feature Scope Definition","id":"decision-explicit-feature-scope-definition"},{"level":3,"text":"Common Pitfalls in Goal Definition","id":"common-pitfalls-in-goal-definition"},{"level":3,"text":"Validation Criteria and Success Metrics","id":"validation-criteria-and-success-metrics"},{"level":4,"text":"Functional Validation Requirements","id":"functional-validation-requirements"},{"level":4,"text":"Non-Goal Compliance Validation","id":"non-goal-compliance-validation"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Selection Framework","id":"technology-selection-framework"},{"level":4,"text":"Project Structure Organization","id":"project-structure-organization"},{"level":4,"text":"Core Interface Definitions","id":"core-interface-definitions"},{"level":4,"text":"Milestone Validation Checkpoints","id":"milestone-validation-checkpoints"},{"level":4,"text":"Scope Enforcement Techniques","id":"scope-enforcement-techniques"},{"level":2,"text":"High-Level Architecture","id":"high-level-architecture"},{"level":3,"text":"Mental Model: Feature Flags as Air Traffic Control","id":"mental-model-feature-flags-as-air-traffic-control"},{"level":3,"text":"Component Overview","id":"component-overview"},{"level":4,"text":"Flag Management API","id":"flag-management-api"},{"level":4,"text":"Evaluation Engine","id":"evaluation-engine"},{"level":4,"text":"Real-time Update Service","id":"real-time-update-service"},{"level":4,"text":"Client SDKs","id":"client-sdks"},{"level":3,"text":"Project Structure and Organization","id":"project-structure-and-organization"},{"level":4,"text":"Core Internal Packages","id":"core-internal-packages"},{"level":4,"text":"Public SDK Package Structure","id":"public-sdk-package-structure"},{"level":4,"text":"Configuration and Deployment Structure","id":"configuration-and-deployment-structure"},{"level":3,"text":"Architecture Decision Records","id":"architecture-decision-records"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended Project Structure","id":"recommended-project-structure"},{"level":4,"text":"Core Type Definitions","id":"core-type-definitions"},{"level":4,"text":"Core Interface Definitions","id":"core-interface-definitions"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeletons","id":"core-logic-skeletons"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":2,"text":"Data Model","id":"data-model"},{"level":3,"text":"Flag Definition Structure","id":"flag-definition-structure"},{"level":3,"text":"User Context and Segmentation","id":"user-context-and-segmentation"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Flag Evaluation Engine","id":"flag-evaluation-engine"},{"level":3,"text":"Consistent User Assignment","id":"consistent-user-assignment"},{"level":3,"text":"Rule Evaluation Logic","id":"rule-evaluation-logic"},{"level":3,"text":"Architecture Decision Records","id":"architecture-decision-records"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Real-time Flag Updates","id":"real-time-flag-updates"},{"level":3,"text":"Streaming Protocol Design","id":"streaming-protocol-design"},{"level":4,"text":"SSE Message Format Design","id":"sse-message-format-design"},{"level":4,"text":"Event Ordering and Replay","id":"event-ordering-and-replay"},{"level":3,"text":"Connection Management and Recovery","id":"connection-management-and-recovery"},{"level":4,"text":"Connection State Machine","id":"connection-state-machine"},{"level":4,"text":"Exponential Backoff with Jitter","id":"exponential-backoff-with-jitter"},{"level":4,"text":"State Synchronization and Recovery","id":"state-synchronization-and-recovery"},{"level":3,"text":"Cache Invalidation Strategy","id":"cache-invalidation-strategy"},{"level":4,"text":"Multi-Level Cache Architecture","id":"multi-level-cache-architecture"},{"level":4,"text":"Event-Driven Invalidation","id":"event-driven-invalidation"},{"level":4,"text":"Graceful Degradation Patterns","id":"graceful-degradation-patterns"},{"level":4,"text":"Common Pitfalls","id":"common-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeleton Code","id":"core-logic-skeleton-code"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":4,"text":"Debugging Tips","id":"debugging-tips"},{"level":2,"text":"Flag Analytics and A/B Testing","id":"flag-analytics-and-ab-testing"},{"level":3,"text":"Flag Exposure Tracking","id":"flag-exposure-tracking"},{"level":3,"text":"A/B Testing Framework","id":"ab-testing-framework"},{"level":3,"text":"Statistical Significance Calculation","id":"statistical-significance-calculation"},{"level":3,"text":"Common Pitfalls","id":"common-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Interactions and Data Flow","id":"interactions-and-data-flow"},{"level":3,"text":"Flag Evaluation Flow","id":"flag-evaluation-flow"},{"level":4,"text":"Step-by-Step Evaluation Process","id":"step-by-step-evaluation-process"},{"level":4,"text":"Caching and Performance Optimization","id":"caching-and-performance-optimization"},{"level":4,"text":"Error Handling and Fallback Logic","id":"error-handling-and-fallback-logic"},{"level":4,"text":"Common Pitfalls in Evaluation Flow","id":"common-pitfalls-in-evaluation-flow"},{"level":3,"text":"Update Propagation Flow","id":"update-propagation-flow"},{"level":4,"text":"Propagation Sequence and Timing","id":"propagation-sequence-and-timing"},{"level":4,"text":"Connection Management and Message Delivery","id":"connection-management-and-message-delivery"},{"level":4,"text":"Network Partition and Recovery Handling","id":"network-partition-and-recovery-handling"},{"level":4,"text":"Change Impact Analysis and Safety Mechanisms","id":"change-impact-analysis-and-safety-mechanisms"},{"level":4,"text":"Common Pitfalls in Update Propagation","id":"common-pitfalls-in-update-propagation"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Evaluation Flow Infrastructure","id":"evaluation-flow-infrastructure"},{"level":4,"text":"Real-time Update Infrastructure","id":"real-time-update-infrastructure"},{"level":4,"text":"Core Evaluation Logic Skeleton","id":"core-evaluation-logic-skeleton"},{"level":4,"text":"Milestone Checkpoint: Evaluation Flow","id":"milestone-checkpoint-evaluation-flow"},{"level":4,"text":"Milestone Checkpoint: Update Propagation","id":"milestone-checkpoint-update-propagation"},{"level":4,"text":"Debugging Tips","id":"debugging-tips"},{"level":2,"text":"Error Handling and Edge Cases","id":"error-handling-and-edge-cases"},{"level":3,"text":"Fallback and Degradation Strategies","id":"fallback-and-degradation-strategies"},{"level":3,"text":"Edge Cases and Corner Scenarios","id":"edge-cases-and-corner-scenarios"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Testing Strategy","id":"testing-strategy"},{"level":3,"text":"Milestone Validation Checkpoints","id":"milestone-validation-checkpoints"},{"level":3,"text":"Property-based Testing","id":"property-based-testing"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Debugging Guide","id":"debugging-guide"},{"level":3,"text":"Flag Evaluation Issues","id":"flag-evaluation-issues"},{"level":4,"text":"Rule Evaluation Problems","id":"rule-evaluation-problems"},{"level":4,"text":"Consistent Hashing Assignment Problems","id":"consistent-hashing-assignment-problems"},{"level":4,"text":"Context and Segmentation Issues","id":"context-and-segmentation-issues"},{"level":3,"text":"Real-time Update Issues","id":"real-time-update-issues"},{"level":4,"text":"Connection Management and Reliability","id":"connection-management-and-reliability"},{"level":4,"text":"Event Ordering and Delivery","id":"event-ordering-and-delivery"},{"level":4,"text":"Cache Synchronization Problems","id":"cache-synchronization-problems"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeleton Code","id":"core-logic-skeleton-code"},{"level":4,"text":"Language-Specific Debugging Hints","id":"language-specific-debugging-hints"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":2,"text":"Future Extensions","id":"future-extensions"},{"level":3,"text":"Advanced Targeting and Segmentation","id":"advanced-targeting-and-segmentation"},{"level":3,"text":"Flag Dependencies and Prerequisites","id":"flag-dependencies-and-prerequisites"},{"level":3,"text":"Multi-Environment Support","id":"multi-environment-support"},{"level":3,"text":"Advanced Analytics and Machine Learning Integration","id":"advanced-analytics-and-machine-learning-integration"},{"level":3,"text":"Global Distribution and Edge Computing","id":"global-distribution-and-edge-computing"},{"level":3,"text":"Enterprise Integration Capabilities","id":"enterprise-integration-capabilities"},{"level":3,"text":"Performance Optimization Extensions","id":"performance-optimization-extensions"},{"level":3,"text":"Integration Ecosystem Extensions","id":"integration-ecosystem-extensions"},{"level":3,"text":"Scalability Architecture Enhancements","id":"scalability-architecture-enhancements"},{"level":3,"text":"Future-Proofing Considerations","id":"future-proofing-considerations"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Extension Implementation Strategy","id":"extension-implementation-strategy"},{"level":4,"text":"Development Priorities","id":"development-priorities"},{"level":2,"text":"Glossary","id":"glossary"},{"level":3,"text":"Core System Concepts","id":"core-system-concepts"},{"level":3,"text":"Evaluation and Targeting","id":"evaluation-and-targeting"},{"level":3,"text":"Data Structures and Types","id":"data-structures-and-types"},{"level":3,"text":"Real-time Communication","id":"real-time-communication"},{"level":3,"text":"Statistical and Experimental Concepts","id":"statistical-and-experimental-concepts"},{"level":3,"text":"System Architecture and Operations","id":"system-architecture-and-operations"},{"level":3,"text":"Error Handling and Resilience","id":"error-handling-and-resilience"},{"level":3,"text":"Development and Testing","id":"development-and-testing"},{"level":3,"text":"Advanced Concepts","id":"advanced-concepts"},{"level":3,"text":"Performance and Scalability","id":"performance-and-scalability"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"}],"title":"Feature Flag System: Design Document","markdown":"# Feature Flag System: Design Document\n\n\n## Overview\n\nA feature flag system that enables controlled feature rollouts, A/B testing, and real-time configuration updates. The key architectural challenge is building a low-latency evaluation engine that can process complex targeting rules while maintaining consistency across distributed clients and supporting real-time updates without overwhelming the infrastructure.\n\n\n> This guide is meant to help you understand the big picture before diving into each milestone. Refer back to it whenever you need context on how components connect.\n\n\n## Context and Problem Statement\n\n> **Milestone(s):** This section provides foundational context for all three milestones by establishing why feature flags are essential and the unique challenges they address.\n\n### Mental Model: Software Release as Air Traffic Control\n\nThink of modern software deployment as managing air traffic at a busy international airport. Without proper coordination, you have hundreds of flights trying to land simultaneously on the same runway—a recipe for disaster. Traditional software releases work exactly like this chaotic scenario: all features launch together at a predetermined time, with no ability to adjust course once the \"planes are in the air.\"\n\n**Feature flags transform your release process into a sophisticated air traffic control system.** Just as air traffic controllers can direct specific flights to different runways, adjust landing sequences based on weather conditions, and even redirect planes to alternate airports when problems arise, feature flags give you granular control over which users see which features and when.\n\nConsider how air traffic control handles a busy evening rush. Controllers don't just flip a switch and let all planes land at once. Instead, they carefully orchestrate arrivals: \"Flight 447, you're cleared for runway 24L. Flight 852, hold at 5,000 feet until weather clears. Flight 213, divert to the cargo runway for your oversized load.\" This is precisely what feature flags enable for software features—you can route different user \"flights\" to different feature \"runways\" based on their characteristics, current system conditions, and business requirements.\n\nThe air traffic control analogy extends beautifully to the technical challenges we face. Air traffic controllers need real-time weather data, aircraft positions, and runway status to make split-second decisions. Similarly, our feature flag system needs real-time user context, system health metrics, and business KPIs to make intelligent routing decisions. When a storm hits the airport, controllers can quickly reroute traffic to alternate runways. When a feature causes performance issues, feature flags let you instantly reroute users to the stable code path without any deployments or restarts.\n\n> **Key Insight**: Just as air traffic control systems must never fail (planes can't just \"hover indefinitely\"), feature flag systems require exceptional reliability with graceful degradation strategies. A feature flag outage shouldn't ground your entire application.\n\nThe complexity emerges when you realize that modern applications aren't managing just one airport—they're coordinating a global network of airports (distributed systems) where decisions made at one location affect traffic patterns everywhere else. A feature flag change in your recommendation engine doesn't just affect the users who see new recommendations; it impacts database load, cache hit rates, API response times, and downstream service capacity across your entire infrastructure.\n\nThis mental model helps us understand why building a feature flag system is more challenging than it initially appears. It's not enough to have a simple on/off switch. You need the equivalent of sophisticated radar systems (real-time monitoring), weather prediction models (A/B testing and analytics), emergency protocols (fallback strategies), and a control tower that never sleeps (24/7 reliability with real-time updates).\n\n### Existing Approaches Comparison\n\nBefore diving into our comprehensive solution, let's examine how teams typically handle feature toggles today and why each approach breaks down as systems scale. Understanding these limitations helps justify the complexity we're about to introduce.\n\n#### Configuration Files Approach\n\nThe simplest approach stores feature toggles in configuration files (YAML, JSON, or properties files) that are read at application startup. This feels natural because it leverages existing configuration management practices that most teams already understand.\n\n| Aspect | Description | Limitations |\n|--------|-------------|-------------|\n| **Implementation** | JSON/YAML files with boolean flags loaded at startup | Requires application restart for any flag change |\n| **Deployment** | Flags bundled with application code in the same deployment artifact | Cannot change flags without full deployment pipeline |\n| **Targeting** | Single global value per flag, no user-specific targeting | All users see the same flag state simultaneously |\n| **Rollback Speed** | 10-30 minutes (full deployment cycle) | Too slow for emergency feature disabling |\n| **Consistency** | Eventually consistent after all instances restart | Inconsistent during rolling deployments |\n| **A/B Testing** | Not supported without custom implementation | No statistical rigor or experiment tracking |\n\nThe configuration file approach works well for simple environment-specific settings (database URLs, API timeouts) but breaks down catastrophically for feature management. Imagine discovering a critical bug in your new checkout flow during Black Friday traffic. With configuration files, you're looking at a 20-minute deployment cycle to disable the feature—an eternity when you're losing thousands of dollars per minute.\n\n**Real-world failure scenario**: A major e-commerce platform used configuration files for feature flags. During a flash sale, their new inventory calculation feature caused database deadlocks. The 15-minute rollback time resulted in $2.3 million in lost sales and required manually switching to backup servers—a problem that feature flags with instant rollback could have resolved in under 30 seconds.\n\n#### Environment Variables Approach\n\nEnvironment variables offer slightly more flexibility than configuration files, especially in containerized environments where you can restart individual service instances without full redeployments.\n\n| Aspect | Description | Limitations |\n|--------|-------------|-------------|\n| **Implementation** | Feature flags stored as environment variables (FEATURE_X=true) | Still requires container/process restart for changes |\n| **Deployment** | Can be changed via orchestration platforms (Kubernetes, Docker Compose) | Rolling restart still takes several minutes |\n| **Targeting** | Global per environment, potentially per service instance | No user segmentation or gradual rollouts |\n| **Observability** | Difficult to track which features are active across the fleet | No centralized view of flag states |\n| **Type Safety** | String-based with manual parsing prone to errors | \"true\", \"TRUE\", \"1\", \"yes\" all need handling |\n| **Audit Trail** | Limited to orchestration platform logs | No feature-specific change history |\n\nEnvironment variables solve the bundling problem of configuration files but introduce new operational complexities. Managing dozens of feature flags across multiple services and environments quickly becomes unwieldy. Consider a microservices architecture with 20 services, each having 5-10 feature flags across development, staging, and production environments—you're now managing 300-600 individual environment variables with no central visibility.\n\n**Real-world failure scenario**: A fintech startup used environment variables for feature flags across their microservices. During a gradual rollout of a new fraud detection algorithm, they discovered the flag was accidentally enabled in production but disabled in staging—the opposite of their intent. The mismatch went undetected for three days, during which time their testing was validating the old algorithm while the new (buggy) algorithm was processing live transactions, resulting in 12% false positives and hundreds of customer complaints.\n\n#### Database Toggle Approach\n\nMany teams evolve from static configuration to storing feature flags in their application database, often starting with a simple `feature_flags` table with name and enabled columns. This approach provides runtime configurability without deployment cycles.\n\n| Aspect | Description | Limitations |\n|--------|-------------|-------------|\n| **Implementation** | Database table storing flag names, enabled state, optional targeting rules | Database becomes single point of failure for all features |\n| **Real-time Updates** | Requires polling or cache invalidation strategy | Polling creates database load; caching creates staleness |\n| **Performance** | Database query on every flag evaluation | Adds latency and load to primary database |\n| **Targeting** | Can store complex rules but evaluation logic mixed with business logic | Rule evaluation code scattered across application |\n| **Consistency** | Depends on database consistency model | Read replicas can serve stale flag states |\n| **Fallback** | Application breaks if database unavailable | No graceful degradation during database outages |\n\nThe database approach initially feels like a natural progression, but it introduces a fundamental architectural problem: your feature management system now shares fate with your primary application database. When your database is under heavy load or experiencing issues, your ability to disable problematic features disappears exactly when you need it most.\n\n**Performance implications**: Every flag evaluation requires a database query or cache lookup. For a high-traffic application evaluating flags on every request, this can easily add 50-100 million additional database queries per day. The irony is that the performance impact of your flagging system can become worse than the features you're trying to protect.\n\n**Real-world failure scenario**: A social media platform stored feature flags in their primary PostgreSQL database. During a traffic spike, database connections were exhausted, causing not only user-facing features to fail but also preventing them from disabling the problematic new timeline algorithm that was causing the load spike in the first place. The circular dependency meant their feature flags couldn't help them recover from the very problems they were designed to solve.\n\n#### Dedicated Feature Flag Services\n\nRecognizing the limitations of the previous approaches, many organizations turn to dedicated feature flag platforms (LaunchDarkly, Unleash, Flagsmith) or build custom services specifically for flag management.\n\n| Aspect | Description | Benefits |\n|--------|-------------|----------|\n| **Implementation** | Standalone service with API for flag evaluation and management | Purpose-built for feature flag requirements |\n| **Real-time Updates** | WebSocket or SSE connections for instant flag changes | Sub-second flag propagation across all clients |\n| **Targeting** | Sophisticated rule engines with user attributes, segments, and percentages | Gradual rollouts and A/B testing built-in |\n| **Performance** | Client-side SDKs with local caching and background sync | Flag evaluation in microseconds with fallbacks |\n| **Observability** | Rich analytics, audit logs, and experiment tracking | Data-driven feature decisions |\n| **Reliability** | Designed for high availability with graceful degradation | Feature flags available even during service outages |\n\nHowever, dedicated services introduce their own complexities and architectural decisions. The fundamental challenge is balancing the richness of targeting capabilities with the performance and reliability requirements of flag evaluation.\n\n> **Architecture Decision: Build vs Buy for Feature Flags**\n> \n> - **Context**: Teams must decide whether to use existing feature flag services or build custom solutions\n> - **Options Considered**:\n>   - **Third-party SaaS**: LaunchDarkly, Split, Optimizely\n>   - **Open-source hosted**: Unleash, Flagsmith, GrowthBook  \n>   - **Custom-built**: Internal feature flag service\n> - **Decision**: Build custom for learning purposes, but understand trade-offs\n> - **Rationale**: Commercial services offer mature ecosystems but limit customization and create vendor dependency. Building custom provides deep understanding of the technical challenges and architectural decisions involved.\n> - **Consequences**: Higher development effort but complete control over performance characteristics, data residency, and integration patterns.\n\n**Comparison of dedicated service approaches**:\n\n| Approach | Pros | Cons | Best For |\n|----------|------|------|----------|\n| **Third-party SaaS** | Mature features, no operational overhead, proven reliability | Vendor lock-in, data privacy concerns, recurring costs | Teams wanting to focus on core business features |\n| **Open-source hosted** | Full control, customizable, community support | Operational overhead, need internal expertise | Teams with strong infrastructure capabilities |\n| **Custom-built** | Complete customization, no vendor dependency, cost control | High development effort, need to solve hard problems | Organizations with unique requirements or learning goals |\n\nThe key insight from this comparison is that feature flags are deceptively complex. What starts as a simple boolean toggle quickly evolves into a distributed system with requirements for real-time updates, complex targeting logic, statistical analysis, and fault tolerance. This complexity explains why dedicated solutions exist and why building a robust feature flag system is a substantial engineering undertaking.\n\n**Common anti-patterns observed across all approaches**:\n\n⚠️ **Pitfall: Flag Evaluation in Critical Path**\nMany implementations put flag evaluation directly in their request processing path without proper caching or fallbacks. This creates latency and reliability problems where feature management becomes a bottleneck for core functionality. The fix is to always evaluate flags asynchronously with local caching and sensible defaults.\n\n⚠️ **Pitfall: No Flag Lifecycle Management** \nTeams often create feature flags without establishing processes for flag cleanup and removal. This leads to \"flag debt\" where codebases accumulate hundreds of obsolete flags that nobody dares to remove. The fix is to treat flags as temporary by default with expiration dates and regular cleanup processes.\n\n⚠️ **Pitfall: Inconsistent Flag Evaluation**\nWithout proper user identification and consistent hashing, users can flip-flop between different variants of a feature, creating confusing experiences and invalidating A/B test results. The fix is to ensure deterministic flag evaluation based on stable user identifiers.\n\nUnderstanding these existing approaches and their failure modes helps us appreciate why building a robust feature flag system requires careful attention to performance, reliability, and consistency challenges. Our design must address the fundamental problems that cause each approach to break down while providing the sophisticated targeting and real-time capabilities that modern applications demand.\n\nThe remainder of this design document will show how to build a feature flag system that combines the best aspects of each approach while avoiding their critical failure modes. We'll focus particularly on the three core challenges that distinguish robust feature flag systems from naive implementations: consistent flag evaluation under high load, real-time flag updates without infrastructure overload, and statistical rigor for A/B testing and gradual rollouts.\n\n### Implementation Guidance\n\nThis foundational section helps establish the technology choices and project structure that will support the sophisticated feature flag system we're building. Understanding these early decisions will inform how we approach the more complex challenges in subsequent milestones.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| **HTTP Framework** | Standard library `net/http` with JSON | Gin or Echo framework with middleware |\n| **Database** | SQLite for development, PostgreSQL for production | PostgreSQL with Redis for caching |\n| **Real-time Updates** | Server-Sent Events with `net/http` | WebSocket with Gorilla WebSocket library |\n| **User Context** | Simple JSON structures | Protocol Buffers for type safety |\n| **Configuration** | YAML with `gopkg.in/yaml.v3` | Viper for hierarchical configuration |\n| **Logging** | Standard library `log/slog` | Structured logging with `logrus` or `zap` |\n| **Testing** | Standard library `testing` | Testify for assertions, Ginkgo for BDD |\n\n**Language-Specific Considerations for Go**:\n\n- **Consistent Hashing**: Use `hash/fnv` for fast, stable hashing of user identifiers\n- **JSON Handling**: Leverage `encoding/json` for flag definitions and user context\n- **Concurrency**: Utilize Go's goroutines for handling real-time connections\n- **Error Handling**: Embrace explicit error returns for robust flag evaluation\n- **Interface Design**: Use interfaces to support multiple storage backends and update mechanisms\n\n#### Recommended Project Structure\n\nUnderstanding how to organize a feature flag system helps avoid common architectural mistakes where flag evaluation logic gets scattered throughout the application.\n\n```\nfeature-flag-system/\n├── cmd/\n│   ├── flagserver/           ← HTTP API server for flag management\n│   │   └── main.go\n│   ├── flagproxy/           ← Lightweight evaluation proxy\n│   │   └── main.go\n│   └── migrator/            ← Database migration tool\n│       └── main.go\n├── internal/\n│   ├── core/                ← Core domain logic (no external dependencies)\n│   │   ├── flag.go          ← Flag entity and business logic\n│   │   ├── evaluation.go    ← Evaluation engine\n│   │   ├── targeting.go     ← User targeting and segmentation\n│   │   └── experiment.go    ← A/B testing logic\n│   ├── storage/             ← Data persistence layer\n│   │   ├── interface.go     ← Storage abstraction\n│   │   ├── postgres/        ← PostgreSQL implementation\n│   │   └── memory/          ← In-memory for testing\n│   ├── realtime/            ← Real-time update service\n│   │   ├── sse.go          ← Server-Sent Events implementation\n│   │   ├── websocket.go    ← WebSocket implementation\n│   │   └── broadcaster.go   ← Update broadcasting logic\n│   ├── analytics/           ← Flag evaluation tracking and A/B analysis\n│   │   ├── collector.go     ← Event collection\n│   │   ├── aggregator.go    ← Metrics aggregation\n│   │   └── stats.go         ← Statistical analysis\n│   └── api/                 ← HTTP API layer\n│       ├── handlers/        ← HTTP request handlers\n│       ├── middleware/      ← Authentication, logging, CORS\n│       └── routes.go        ← Route definitions\n├── pkg/                     ← Public APIs (can be imported by other projects)\n│   ├── client/              ← Go SDK for consuming feature flags\n│   │   ├── sdk.go          ← Main SDK interface\n│   │   ├── cache.go        ← Local flag caching\n│   │   └── streaming.go    ← Real-time update handling\n│   └── types/               ← Shared types and interfaces\n│       ├── flag.go         ← Flag data structures\n│       ├── context.go      ← User context types\n│       └── events.go       ← Event and analytics types\n├── web/                     ← Web dashboard (optional)\n│   ├── static/             ← CSS, JavaScript assets\n│   └── templates/          ← HTML templates\n├── migrations/              ← Database schema migrations\n│   ├── 001_initial.sql\n│   ├── 002_add_experiments.sql\n│   └── 003_add_analytics.sql\n├── docs/                    ← Additional documentation\n│   ├── api.md              ← API documentation\n│   ├── sdk.md              ← SDK usage guide\n│   └── deployment.md       ← Deployment instructions\n└── docker-compose.yml       ← Local development environment\n```\n\n**Key organizational principles**:\n\n1. **Domain-Driven Structure**: The `internal/core` package contains pure business logic with no external dependencies, making it easy to unit test and reason about.\n\n2. **Interface Segregation**: Each major component (`storage`, `realtime`, `analytics`) defines its own interfaces, allowing for multiple implementations and easy testing with mocks.\n\n3. **Dependency Direction**: Dependencies flow inward toward the core domain logic. Storage implementations depend on core interfaces, not vice versa.\n\n4. **Client SDK Separation**: The `pkg/client` provides a clean API for applications consuming feature flags, with its own caching and connection management logic separate from the server implementation.\n\n#### Core Type Definitions\n\nThese fundamental types will be referenced throughout the implementation. Understanding them now will help you follow the more complex algorithms in later sections.\n\n```go\n// Package: pkg/types\n\n// FlagKey uniquely identifies a feature flag across the system\ntype FlagKey string\n\n// UserID represents a stable identifier for users in targeting decisions\ntype UserID string\n\n// Variant represents a specific variation of a feature flag\ntype Variant struct {\n    Key     string                 `json:\"key\"`\n    Value   interface{}           `json:\"value\"`\n    Weight  int                   `json:\"weight\"`  // For percentage rollouts\n}\n\n// UserContext contains attributes used for flag targeting decisions\ntype UserContext struct {\n    UserID     UserID                 `json:\"user_id\"`\n    Attributes map[string]interface{} `json:\"attributes\"`\n    Segments   []string              `json:\"segments\"`\n}\n\n// EvaluationResult contains the result of flag evaluation plus debugging info\ntype EvaluationResult struct {\n    FlagKey   FlagKey     `json:\"flag_key\"`\n    Value     interface{} `json:\"value\"`\n    Variant   string      `json:\"variant\"`\n    Reason    string      `json:\"reason\"`     // Why this variant was chosen\n    Source    string      `json:\"source\"`     // \"cache\", \"storage\", \"default\"\n}\n```\n\n#### Infrastructure Starter Code\n\nThis complete HTTP server foundation handles the basic web serving infrastructure so you can focus on the core feature flag logic:\n\n```go\n// cmd/flagserver/main.go\npackage main\n\nimport (\n    \"context\"\n    \"log/slog\"\n    \"net/http\"\n    \"os\"\n    \"os/signal\"\n    \"syscall\"\n    \"time\"\n\n    \"github.com/your-org/feature-flags/internal/api\"\n    \"github.com/your-org/feature-flags/internal/storage/postgres\"\n)\n\nfunc main() {\n    // Initialize structured logging\n    logger := slog.New(slog.NewJSONHandler(os.Stdout, &slog.HandlerOptions{\n        Level: slog.LevelInfo,\n    }))\n    \n    // Initialize storage layer\n    storage, err := postgres.NewStorage(\"postgres://localhost/flagdb?sslmode=disable\")\n    if err != nil {\n        logger.Error(\"Failed to initialize storage\", \"error\", err)\n        os.Exit(1)\n    }\n    defer storage.Close()\n    \n    // Initialize API server\n    server := api.NewServer(storage, logger)\n    \n    // Configure HTTP server with timeouts\n    httpServer := &http.Server{\n        Addr:         \":8080\",\n        Handler:      server.Routes(),\n        ReadTimeout:  15 * time.Second,\n        WriteTimeout: 15 * time.Second,\n        IdleTimeout:  60 * time.Second,\n    }\n    \n    // Start server in background\n    go func() {\n        logger.Info(\"Starting flag server\", \"addr\", httpServer.Addr)\n        if err := httpServer.ListenAndServe(); err != nil && err != http.ErrServerClosed {\n            logger.Error(\"HTTP server failed\", \"error\", err)\n            os.Exit(1)\n        }\n    }()\n    \n    // Wait for shutdown signal\n    stop := make(chan os.Signal, 1)\n    signal.Notify(stop, syscall.SIGINT, syscall.SIGTERM)\n    <-stop\n    \n    // Graceful shutdown\n    logger.Info(\"Shutting down server...\")\n    ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\n    defer cancel()\n    \n    if err := httpServer.Shutdown(ctx); err != nil {\n        logger.Error(\"Server shutdown failed\", \"error\", err)\n    } else {\n        logger.Info(\"Server shut down successfully\")\n    }\n}\n```\n\n#### Development Environment Setup\n\nComplete Docker Compose configuration for local development with all required dependencies:\n\n```yaml\n# docker-compose.yml\nversion: '3.8'\n\nservices:\n  postgres:\n    image: postgres:15\n    environment:\n      POSTGRES_DB: flagdb\n      POSTGRES_USER: flaguser\n      POSTGRES_PASSWORD: flagpass\n    ports:\n      - \"5432:5432\"\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n      - ./migrations:/docker-entrypoint-initdb.d\n\n  redis:\n    image: redis:7-alpine\n    ports:\n      - \"6379:6379\"\n    command: redis-server --appendonly yes\n    volumes:\n      - redis_data:/data\n\n  flagserver:\n    build: .\n    ports:\n      - \"8080:8080\"\n    environment:\n      DATABASE_URL: postgres://flaguser:flagpass@postgres:5432/flagdb?sslmode=disable\n      REDIS_URL: redis://redis:6379/0\n    depends_on:\n      - postgres\n      - redis\n    volumes:\n      - .:/app\n    working_dir: /app\n\nvolumes:\n  postgres_data:\n  redis_data:\n```\n\n#### Milestone Checkpoint for Foundation\n\nAfter setting up the project structure and basic infrastructure:\n\n**What to verify**:\n1. Run `go mod init github.com/your-org/feature-flags` to initialize the Go module\n2. Set up the directory structure as shown above\n3. Copy the starter code into the appropriate files\n4. Run `docker-compose up postgres redis` to start dependencies\n5. Run `go run cmd/flagserver/main.go` - server should start without errors\n6. Visit `http://localhost:8080/health` (you'll implement this endpoint) - should return 200 OK\n\n**Expected behavior**:\n- Server starts and listens on port 8080\n- Database connection succeeds (you'll see connection logs)\n- Graceful shutdown works with Ctrl+C\n- Project structure follows Go conventions with clear separation of concerns\n\n**Signs something is wrong**:\n- Import cycle errors indicate incorrect dependency structure\n- Database connection failures suggest configuration issues  \n- Server doesn't respond to shutdown signals cleanly\n\nThis foundation provides the scaffolding for implementing the three core milestones: the flag evaluation engine, real-time updates, and analytics. Each subsequent section will build upon this structure with specific components and algorithms needed for a production-quality feature flag system.\n\n\n## Goals and Non-Goals\n\n> **Milestone(s):** This section establishes the scope and boundaries for all three milestones, defining what functionality the Flag Evaluation Engine, Real-time Flag Updates, and Flag Analytics & Experiments will and will not include.\n\n### Mental Model: Air Traffic Control Tower Responsibilities\n\nThink of defining goals and non-goals for a feature flag system like establishing the responsibilities of an **air traffic control tower**. The tower has clear, well-defined duties: it guides aircraft safely to their destinations, manages takeoffs and landings, and coordinates flight paths to prevent collisions. However, the tower doesn't design aircraft engines, forecast weather patterns weeks in advance, or handle passenger boarding processes.\n\nSimilarly, our feature flag system must have crystal-clear boundaries. It will excel at its core mission—safely routing users to different feature experiences based on targeting rules—while explicitly avoiding responsibilities that belong to other systems. Just as air traffic controllers need reliable radar, communication systems, and weather updates to make split-second decisions, our feature flag system needs robust evaluation logic, real-time updates, and comprehensive analytics to guide software releases safely.\n\nThe key insight is that **scope creep** in feature flag systems is like asking air traffic controllers to also handle airline scheduling, aircraft maintenance, and passenger services. Each additional responsibility increases complexity exponentially and threatens the reliability of the core mission. By establishing clear goals and non-goals upfront, we create focused, maintainable software that excels at its intended purpose.\n\n### Primary Goals\n\nOur feature flag system will deliver four core capabilities that directly support the air traffic control analogy of coordinating software releases safely and efficiently.\n\n#### Goal 1: Reliable Flag Evaluation with Complex Targeting\n\nThe system will provide **deterministic, low-latency flag evaluation** that consistently assigns users to the correct variants based on sophisticated targeting rules. This is the fundamental responsibility—like air traffic control's primary duty of guiding aircraft to safe landing strips.\n\n| Capability | Description | Success Criteria |\n|------------|-------------|------------------|\n| **Multi-type Flag Support** | Boolean, string, number, and JSON flag values | All primitive types plus structured data variants |\n| **Complex Rule Logic** | AND/OR conditions with multiple user attributes | Nested boolean expressions with proper precedence |\n| **Percentage Rollouts** | Gradual feature exposure using consistent hashing | Stable user assignment across evaluations |\n| **User Segmentation** | Target specific user groups with attribute matching | Rule-based segments with real-time membership |\n| **Evaluation Reasoning** | Detailed explanation of why specific variant returned | Audit trail for debugging and compliance |\n| **Fallback Handling** | Default values when targeting rules fail or malfunction | Graceful degradation without service interruption |\n\nThe evaluation engine will process complex targeting scenarios like \"show new checkout flow to 25% of premium users in North America, but exclude users who signed up in the last 7 days.\" This requires sophisticated rule processing with proper precedence, consistent user bucketing, and comprehensive context matching.\n\n#### Goal 2: Real-time Configuration Updates\n\nThe system will deliver **sub-second flag changes** to all connected clients without requiring application restarts or deployments. This enables the rapid course corrections that make feature flags valuable for risk mitigation and experimentation.\n\n| Capability | Description | Success Criteria |\n|------------|-------------|------------------|\n| **Streaming Updates** | Server-Sent Events or WebSocket delivery | Flag changes reach clients within 2-3 seconds |\n| **Connection Recovery** | Automatic reconnection with exponential backoff | Clients reconnect after network disruption |\n| **State Synchronization** | Consistent flag values across all SDK instances | No client serves stale flags after updates |\n| **Offline Resilience** | Local caching with configurable TTL policies | Applications continue functioning during outages |\n| **Update Ordering** | Changes applied in correct chronological sequence | No race conditions between rapid flag modifications |\n| **Selective Updates** | Only changed flags transmitted to reduce bandwidth | Efficient delta updates rather than full snapshots |\n\nReal-time updates enable emergency scenarios like \"immediately disable the new payment processor for all users\" or \"increase checkout optimization rollout from 10% to 50% during peak traffic.\" The system must handle these critical configuration changes reliably across distributed deployments.\n\n#### Goal 3: Comprehensive Analytics and A/B Testing\n\nThe system will provide **statistical rigor** for controlled experiments and comprehensive visibility into flag performance. This transforms feature flags from simple toggles into a data-driven experimentation platform.\n\n| Capability | Description | Success Criteria |\n|------------|-------------|------------------|\n| **Flag Exposure Tracking** | Record every flag evaluation with user context | Complete audit trail of feature exposure |\n| **A/B Test Framework** | Controlled experiments with proper randomization | Statistical significance testing with confidence intervals |\n| **Metrics Collection** | Conversion and engagement tracking by variant | Real-time performance comparison across variants |\n| **Sample Size Calculation** | Required user counts for statistical power | Experiment duration estimates based on traffic |\n| **Sequential Analysis** | Early stopping with proper alpha spending | Avoid peeking problems while enabling early wins |\n| **Experiment Reports** | Automated analysis with actionable recommendations | Clear visualization of variant performance differences |\n\nThe analytics engine will detect scenarios like sample ratio mismatches that invalidate experiments, calculate required sample sizes for desired statistical power, and provide early stopping recommendations when variants show significant differences.\n\n#### Goal 4: Production-Ready Reliability\n\nThe system will demonstrate **enterprise-grade reliability** suitable for business-critical applications with proper error handling, monitoring, and operational support.\n\n| Capability | Description | Success Criteria |\n|------------|-------------|------------------|\n| **High Availability** | Multi-region deployment with failover capabilities | 99.9% uptime with sub-100ms P99 latency |\n| **Graceful Degradation** | Service continues with cached/default values during outages | No application failures due to flag service issues |\n| **Comprehensive Monitoring** | Detailed metrics, logging, and alerting integration | Proactive detection of performance degradation |\n| **Security Integration** | Authentication, authorization, and audit logging | Role-based access control with compliance support |\n| **Scalability** | Handle millions of flag evaluations per second | Linear scaling with horizontal infrastructure growth |\n| **Data Consistency** | ACID properties for critical flag configuration changes | No lost updates or corrupted flag definitions |\n\n### Non-Goals\n\nUnderstanding what our feature flag system will **not** include is equally important for maintaining focus and avoiding scope creep. These boundaries prevent the system from becoming an overly complex platform that fails at its core mission.\n\n#### Non-Goal 1: Advanced Infrastructure Management\n\nThe system will not provide comprehensive DevOps tooling or infrastructure orchestration capabilities that belong in specialized platforms.\n\n| Excluded Capability | Rationale | Alternative Approach |\n|---------------------|-----------|---------------------|\n| **Container Orchestration** | Kubernetes and Docker management requires specialized expertise | Deploy flag service using existing container platforms |\n| **Service Mesh Integration** | Complex networking concerns beyond flag evaluation scope | Use standard service mesh patterns for traffic management |\n| **Multi-Cloud Management** | Cloud provider abstractions add significant complexity | Deploy using cloud-specific infrastructure as code |\n| **Database Administration** | Schema migrations, backup/restore, performance tuning | Use managed database services with standard operational practices |\n| **Load Balancer Configuration** | Traffic routing policies beyond basic health checks | Integrate with existing load balancing infrastructure |\n\nThis boundary ensures the development team focuses on flag evaluation logic rather than becoming infrastructure specialists. Organizations should deploy the flag service using their existing DevOps toolchain and operational practices.\n\n#### Non-Goal 2: Complex Business Logic Integration\n\nThe system will not embed application-specific business rules or domain logic that belongs in individual applications.\n\n| Excluded Capability | Rationale | Alternative Approach |\n|---------------------|-----------|---------------------|\n| **Custom Business Rules** | Domain-specific logic creates tight coupling between flag service and applications | Applications implement business logic using flag values as inputs |\n| **Workflow Orchestration** | Multi-step business processes require specialized workflow engines | Use flag values to control workflow behavior in dedicated orchestration systems |\n| **Data Transformation** | Complex ETL operations belong in dedicated data processing pipelines | Flag service provides raw evaluation data; applications handle transformation |\n| **External API Orchestration** | Coordinating multiple external services creates reliability dependencies | Applications manage external integrations using flags for feature gating |\n| **Payment Processing** | Financial transactions require specialized compliance and security | Use flags to control payment feature availability, not process transactions |\n\nBy avoiding business logic integration, the flag service remains reusable across different applications and domains while maintaining clear separation of concerns.\n\n#### Non-Goal 3: Advanced Machine Learning Features\n\nThe system will not include sophisticated AI/ML capabilities that require specialized data science expertise and infrastructure.\n\n| Excluded Capability | Rationale | Alternative Approach |\n|---------------------|-----------|---------------------|\n| **Predictive Targeting** | User behavior prediction requires ML model training and maintenance | Use rule-based targeting with external ML insights as input attributes |\n| **Automated Flag Management** | AI-driven flag lifecycle management introduces unpredictable system behavior | Provide APIs for external automation tools to manage flags programmatically |\n| **Anomaly Detection** | Statistical outlier detection needs specialized algorithms and tuning | Integrate with existing monitoring tools that provide anomaly detection |\n| **Recommendation Engine** | Variant recommendations require complex user modeling and collaborative filtering | External recommendation systems can use flag values for A/B testing recommendations |\n| **Natural Language Processing** | Flag configuration from natural language requires NLP infrastructure | Provide structured APIs with clear documentation for programmatic flag management |\n\nOrganizations needing ML-powered feature management should integrate external ML platforms with the flag service through standard APIs rather than embedding ML capabilities directly.\n\n#### Non-Goal 4: Comprehensive Application Performance Monitoring\n\nThe system will not replace dedicated APM and observability platforms that provide comprehensive application monitoring.\n\n| Excluded Capability | Rationale | Alternative Approach |\n|---------------------|-----------|---------------------|\n| **Distributed Tracing** | Request tracing across microservices requires specialized instrumentation | Flag evaluations participate in existing distributed tracing systems |\n| **Application Metrics** | Business and technical metrics belong in dedicated monitoring infrastructure | Flag exposure events feed into existing metrics collection systems |\n| **Log Aggregation** | Centralized logging requires significant infrastructure and storage management | Flag service logs integrate with existing log aggregation platforms |\n| **Error Tracking** | Application error monitoring needs specialized error analysis and grouping | Flag-related errors report to existing error tracking systems |\n| **Performance Profiling** | Code-level performance analysis requires runtime instrumentation | Flag evaluation performance monitored through standard profiling tools |\n\nThe flag service will provide observability hooks and structured logging that integrate seamlessly with existing monitoring infrastructure rather than replacing specialized observability tools.\n\n### Scope Boundaries and Integration Points\n\nUnderstanding how our feature flag system integrates with existing infrastructure helps clarify responsibility boundaries and prevents architectural conflicts.\n\n#### Integration Philosophy\n\n> **Design Principle: Complementary System Integration**\n> \n> The feature flag system follows the **Unix philosophy** of doing one thing exceptionally well while providing clean interfaces for integration with other systems. Rather than replacing existing infrastructure, it enhances current development and operational workflows.\n\n| Integration Category | Flag System Responsibility | External System Responsibility |\n|----------------------|---------------------------|--------------------------------|\n| **User Authentication** | Accept authenticated user context for targeting | Provide user identity and session management |\n| **Metrics and Analytics** | Generate flag exposure events with structured metadata | Aggregate, visualize, and alert on flag usage patterns |\n| **Configuration Management** | Store and serve flag definitions with versioning | Manage application configuration, secrets, and environment variables |\n| **Deployment Pipeline** | Provide APIs for automated flag lifecycle management | Orchestrate deployments, run tests, and manage release processes |\n| **Service Discovery** | Register flag service endpoints for client SDK discovery | Provide service mesh, load balancing, and health checking |\n| **Data Storage** | Persist flag definitions, rules, and evaluation results | Provide database infrastructure, backup, and disaster recovery |\n\n#### Client SDK Integration Requirements\n\nThe flag system must provide lightweight, efficient client SDKs that minimize application impact while maximizing developer productivity.\n\n| SDK Capability | Design Requirements | Performance Constraints |\n|----------------|---------------------|-------------------------|\n| **Evaluation Latency** | Sub-millisecond flag evaluation using local cache | No network calls during normal flag evaluation |\n| **Memory Footprint** | Minimal memory usage for flag storage and evaluation context | Cache only active flags with efficient serialization |\n| **Startup Time** | Fast SDK initialization without blocking application startup | Asynchronous flag loading with sensible defaults |\n| **Error Isolation** | Flag evaluation failures never crash or block application code | Comprehensive fallback strategies with circuit breaker patterns |\n| **Async Updates** | Background flag updates without interrupting application threads | Non-blocking update processing with atomic configuration swaps |\n| **Observability** | Rich debugging information without performance penalty | Structured logging and metrics with configurable verbosity |\n\n### Architecture Decision Records\n\n#### Decision: Evaluation-First Design Priority\n\n> **Context**: Feature flag systems must balance multiple concerns including evaluation performance, real-time updates, analytics collection, and operational complexity. Different prioritization leads to fundamentally different architectures.\n> \n> **Options Considered**:\n> 1. **Analytics-First**: Optimize for comprehensive data collection and experiment analysis\n> 2. **Updates-First**: Optimize for real-time configuration changes and operational flexibility  \n> 3. **Evaluation-First**: Optimize for low-latency, high-throughput flag evaluation performance\n> \n> **Decision**: Evaluation-First design with analytics and updates as secondary concerns\n> \n> **Rationale**: Flag evaluation occurs orders of magnitude more frequently than configuration updates or analytics queries. A single application might evaluate flags thousands of times per request across millions of requests daily, but flag updates happen at most dozens of times per day. Poor evaluation performance directly impacts user experience and application scalability, while slower updates or analytics primarily affect developer productivity.\n> \n> **Consequences**: This prioritization enables sub-millisecond evaluation latency through aggressive local caching and optimized rule processing, but requires more sophisticated approaches for real-time updates and analytics collection that don't compromise evaluation performance.\n\n| Approach | Evaluation Latency | Update Latency | Analytics Richness | Operational Complexity |\n|----------|-------------------|----------------|--------------------|------------------------|\n| **Analytics-First** | 50-100ms (network calls) | 5-10 seconds | Comprehensive real-time | High (complex data pipeline) |\n| **Updates-First** | 10-50ms (cache misses) | Sub-second | Limited batch processing | Medium (event streaming) |\n| **Evaluation-First ✓** | Sub-millisecond (local) | 2-5 seconds | Rich but eventually consistent | Medium (caching complexity) |\n\n#### Decision: Explicit Feature Scope Definition\n\n> **Context**: Feature flag systems can evolve into comprehensive platforms handling everything from basic toggles to complex workflow orchestration, user management, and business intelligence. This scope expansion often leads to maintenance burden and reliability issues.\n> \n> **Options Considered**:\n> 1. **Platform Approach**: Build comprehensive feature management platform with extensive built-in capabilities\n> 2. **Minimal Approach**: Provide only basic boolean flags with simple on/off functionality\n> 3. **Focused Approach**: Provide sophisticated flag evaluation, updates, and analytics while avoiding peripheral features\n> \n> **Decision**: Focused Approach with explicit non-goals to prevent scope creep\n> \n> **Rationale**: Platform approaches often fail because they attempt to solve too many problems simultaneously, leading to suboptimal solutions for each concern. Minimal approaches lack the sophistication needed for production use cases like gradual rollouts and A/B testing. The focused approach enables excellence in core flag management while providing integration points for specialized external systems.\n> \n> **Consequences**: Development effort concentrates on flag evaluation excellence, real-time updates, and experiment analytics. External integration requirements are explicitly designed from the beginning rather than retrofitted later, leading to cleaner architecture and more reliable operation.\n\n### Common Pitfalls in Goal Definition\n\nUnderstanding common mistakes in feature flag system scoping helps avoid architectural decisions that lead to maintenance problems and reliability issues.\n\n⚠️ **Pitfall: Kitchen Sink Feature Creep**\n\nMany teams start with simple flag requirements but gradually add user management, complex workflow orchestration, custom business logic, and comprehensive monitoring capabilities. This transforms a focused flag service into a sprawling platform that's difficult to maintain and often unreliable.\n\n**Why it's Wrong**: Each additional feature domain requires different expertise, testing approaches, and operational considerations. A system optimized for microsecond flag evaluation has fundamentally different requirements than one optimized for complex data analytics or user interface workflows.\n\n**How to Fix**: Establish explicit non-goals documentation and review all feature requests against core system responsibilities. When teams request additional capabilities, provide integration APIs that allow external systems to handle peripheral concerns while leveraging flag data.\n\n⚠️ **Pitfall: Premature Optimization Boundaries**\n\nTeams sometimes define overly restrictive goals based on current performance requirements without considering reasonable growth scenarios. This leads to systems that can't handle obvious scaling needs or require complete rewrites when traffic increases.\n\n**Why it's Wrong**: Flag evaluation requirements often grow exponentially with application adoption. A system designed for 1,000 evaluations per second might face 100,000 evaluations per second within months. Similarly, simple boolean flags often evolve into complex multi-variant experiments as organizations mature their feature management practices.\n\n**How to Fix**: Define goals that accommodate 10x growth in evaluation volume and rule complexity without architectural changes. Plan for linear scaling through horizontal infrastructure rather than requiring fundamental design modifications.\n\n⚠️ **Pitfall: Integration Assumption Mismatch**\n\nDevelopment teams often assume their flag system will integrate seamlessly with existing infrastructure without explicitly designing integration points. This leads to architecture conflicts, performance problems, and operational complexity.\n\n**Why it's Wrong**: Different organizations have varying authentication systems, monitoring infrastructure, deployment pipelines, and data storage approaches. A flag system designed assuming specific external dependencies often requires significant modifications during deployment.\n\n**How to Fix**: Define explicit integration interfaces and assumptions in the goals documentation. Design abstraction layers for authentication, metrics, storage, and configuration that allow adaptation to different organizational infrastructure without core logic changes.\n\n### Validation Criteria and Success Metrics\n\nEstablishing measurable success criteria ensures the implemented system meets its defined goals while respecting non-goal boundaries.\n\n#### Functional Validation Requirements\n\n| Goal Category | Validation Method | Success Threshold | Measurement Approach |\n|---------------|-------------------|-------------------|----------------------|\n| **Flag Evaluation** | Load testing with complex rules | 99.9% evaluations complete within 1ms | Synthetic traffic with realistic user contexts |\n| **Real-time Updates** | Flag change propagation timing | 95% of clients receive updates within 3 seconds | Distributed update monitoring with client-side timestamps |\n| **A/B Testing** | Statistical accuracy validation | Experiment results within 2% of ground truth | Controlled experiments with known conversion differences |\n| **Reliability** | Chaos engineering and failure injection | No application failures due to flag service issues | Systematic infrastructure failure testing |\n\n#### Non-Goal Compliance Validation\n\n| Non-Goal Category | Validation Method | Compliance Criteria | Red Flag Indicators |\n|-------------------|-------------------|---------------------|---------------------|\n| **Infrastructure Scope** | Architecture review | Zero database administration or container orchestration features | Custom deployment scripts or database schema management |\n| **Business Logic Scope** | Code review | No domain-specific rules or workflow orchestration | Application-specific constants or business rule encoding |\n| **ML Feature Scope** | Dependency analysis | No machine learning libraries or model training capabilities | Statistical modeling or prediction algorithm implementations |\n| **APM Scope** | Integration testing | Flag service data flows to existing monitoring infrastructure | Custom metrics dashboards or log aggregation systems |\n\n### Implementation Guidance\n\nThe goals and non-goals established in this section provide the foundation for all implementation decisions throughout the project. Here's how to translate these scope boundaries into concrete development practices.\n\n#### Technology Selection Framework\n\nWhen choosing technologies and dependencies for each milestone, evaluate options against the established goals and explicitly reject solutions that violate non-goal boundaries.\n\n| Component Category | Evaluation Criteria | Recommended Approach | Red Flag Dependencies |\n|--------------------|-------------------|----------------------|----------------------|\n| **Flag Storage** | Evaluation latency priority, consistency guarantees | In-memory caching with persistent backing store | Complex ORM frameworks, heavy database abstraction layers |\n| **Real-time Updates** | Connection management, bandwidth efficiency | Server-Sent Events with JSON payloads | Complex message brokers, heavyweight pub/sub systems |\n| **Analytics Backend** | Statistical accuracy, query performance | Time-series database with statistical functions | Full-featured business intelligence or data warehouse platforms |\n| **Client SDK** | Minimal footprint, fast evaluation | Simple HTTP client with local caching | Complex frameworks, heavyweight serialization libraries |\n\n#### Project Structure Organization\n\nOrganize the codebase to reinforce goal boundaries and prevent scope creep through clear module separation:\n\n```\nfeature-flag-system/\n├── cmd/\n│   ├── flag-server/              ← Core flag evaluation and updates service\n│   └── analytics-processor/      ← Experiment analysis and reporting\n├── internal/\n│   ├── evaluation/               ← Flag evaluation engine (Goal 1)\n│   │   ├── engine.go\n│   │   ├── rules.go\n│   │   └── consistent_hash.go\n│   ├── realtime/                 ← Update streaming (Goal 2)\n│   │   ├── sse_handler.go\n│   │   └── connection_manager.go\n│   ├── analytics/                ← A/B testing framework (Goal 3)\n│   │   ├── experiment.go\n│   │   └── statistics.go\n│   └── storage/                  ← Data persistence abstraction\n│       ├── memory_store.go\n│       └── postgres_store.go\n├── pkg/\n│   └── sdk/                      ← Client SDK for applications\n│       ├── client.go\n│       └── cache.go\n└── examples/\n    ├── basic-usage/              ← Simple flag evaluation examples\n    └── ab-testing/               ← Experiment setup examples\n```\n\n#### Core Interface Definitions\n\nDefine clean interfaces that enforce goal boundaries and prevent feature creep:\n\n```go\n// FlagEvaluator handles core evaluation logic (Goal 1)\ntype FlagEvaluator interface {\n    // EvaluateFlag returns variant assignment with reasoning\n    EvaluateFlag(flagKey FlagKey, context UserContext) (EvaluationResult, error)\n    \n    // TODO: Implement consistent hashing for stable user assignment\n    // TODO: Process targeting rules with proper precedence\n    // TODO: Handle fallback values when rules don't match\n}\n\n// UpdateStreamer manages real-time flag changes (Goal 2)  \ntype UpdateStreamer interface {\n    // StreamUpdates sends flag changes to connected clients\n    StreamUpdates(clientID string) (<-chan FlagUpdate, error)\n    \n    // TODO: Implement SSE connection management\n    // TODO: Handle client reconnection with state recovery\n    // TODO: Broadcast updates to all connected clients\n}\n\n// ExperimentTracker handles A/B testing analytics (Goal 3)\ntype ExperimentTracker interface {\n    // RecordExposure logs flag evaluation for analysis\n    RecordExposure(exposure FlagExposure) error\n    \n    // CalculateSignificance computes experiment statistical results\n    CalculateSignificance(experimentID string) (SignificanceResult, error)\n    \n    // TODO: Implement exposure event collection\n    // TODO: Calculate statistical significance with proper methods\n    // TODO: Generate experiment reports with confidence intervals\n}\n```\n\n#### Milestone Validation Checkpoints\n\nAfter implementing each milestone, validate that the system meets its goals without violating non-goal boundaries:\n\n**Milestone 1 Checkpoint (Flag Evaluation Engine):**\n- Run `go test ./internal/evaluation/...` - all tests pass\n- Load test: 10,000 flag evaluations complete within 10ms total\n- Complex rule test: nested AND/OR conditions evaluate correctly\n- Consistency test: same user receives identical variants across multiple evaluations\n- Verify: No business logic hardcoded, no ML dependencies, no infrastructure management code\n\n**Milestone 2 Checkpoint (Real-time Updates):**\n- Start flag server: `go run cmd/flag-server/main.go`\n- Connect test client, modify flag via API, client receives update within 3 seconds\n- Network disruption test: disconnect/reconnect client, verify state synchronization\n- Verify: No complex message broker usage, no container orchestration, updates don't impact evaluation latency\n\n**Milestone 3 Checkpoint (Analytics & Experiments):**\n- Create A/B test with known 10% conversion difference\n- Run experiment with synthetic traffic for statistical significance\n- Verify: Statistical calculations accurate within 2%, no ML model training, no custom APM dashboard\n\n#### Scope Enforcement Techniques\n\nImplement these development practices to maintain goal focus and prevent scope creep:\n\n**Code Review Checklist:**\n- Does this change directly support one of the four primary goals?\n- Are we adding infrastructure management, business logic, ML features, or APM capabilities?\n- Do new dependencies align with evaluation-first performance priorities?\n- Are integration points cleanly separated from core flag logic?\n\n**Architecture Decision Template:**\nFor any significant design choice, explicitly evaluate against goals:\n- How does this support flag evaluation performance?\n- Does this compromise real-time update capabilities?\n- Will this enable or hinder A/B testing statistical accuracy?\n- Are we maintaining production reliability standards?\n- Which non-goals might this violate, and how do we prevent that?\n\n**Dependency Review Process:**\nBefore adding any external dependency:\n- Measure impact on flag evaluation latency\n- Verify alignment with focused system approach  \n- Confirm integration rather than replacement of existing infrastructure\n- Document why simpler alternatives are insufficient\n\nThis systematic approach to goal enforcement ensures the feature flag system delivers exceptional performance in its core mission while maintaining clean integration boundaries with existing organizational infrastructure.\n\n\n## High-Level Architecture\n\n> **Milestone(s):** This section provides the architectural foundation for all three milestones by defining the core components that support the Flag Evaluation Engine (Milestone 1), Real-time Flag Updates (Milestone 2), and Flag Analytics & Experiments (Milestone 3).\n\n### Mental Model: Feature Flags as Air Traffic Control\n\nThink of a feature flag system as an **air traffic control tower** managing the flow of software releases into production. Just as air traffic control coordinates aircraft approaches, assigns landing sequences, and manages emergency protocols, a feature flag system orchestrates which features reach which users under what conditions.\n\nThe air traffic control analogy illuminates several key architectural principles. The **control tower** (Flag Management API) provides centralized oversight and coordination, while **flight controllers** (Client SDKs) execute instructions at the ground level. **Radar systems** (Real-time Update Service) provide continuous situational awareness, and **flight plans** (flag configurations) define predetermined routes and conditions. **Emergency protocols** (fallback mechanisms) ensure safe operation when communication fails.\n\nThis mental model emphasizes why feature flag architecture must prioritize **reliability over performance**. A crashed air traffic control system grounds all flights; similarly, a failed flag evaluation system can block all feature rollouts or, worse, expose unstable features to production traffic. The architecture must embrace **graceful degradation** principles, where partial system failures reduce capability rather than causing complete outages.\n\nThe evaluation-first design principle emerges naturally from this analogy. Air traffic control systems prioritize rapid decision-making over comprehensive data collection—controllers need split-second aircraft positioning, not detailed historical flight patterns. Similarly, flag evaluation must complete in single-digit milliseconds, even if analytics data has eventual consistency.\n\n![System Architecture Overview](./diagrams/system-architecture.svg)\n\n### Component Overview\n\nThe feature flag system consists of four primary components that work together to provide fast, reliable flag evaluation with real-time updates and comprehensive analytics. Each component owns specific responsibilities and maintains clear boundaries to support independent scaling and deployment.\n\n#### Flag Management API\n\nThe **Flag Management API** serves as the central command center for all flag operations, similar to how air traffic control manages flight plans and clearances. This component handles the administrative lifecycle of feature flags while maintaining the authoritative state that drives evaluation decisions across all client SDKs.\n\nThe Flag Management API owns the complete flag definition lifecycle, from initial creation through rule updates to eventual flag retirement. It provides RESTful endpoints for creating flags, configuring targeting rules, setting up A/B experiments, and managing percentage rollouts. The API validates all flag configurations before persistence, ensuring that rule syntax is correct, percentage allocations sum appropriately, and dependency graphs remain acyclic.\n\n| Operation | Method | Endpoint | Description | Authentication |\n|-----------|--------|----------|-------------|----------------|\n| Create Flag | POST | `/api/flags` | Create new feature flag with targeting rules | Admin |\n| Update Flag | PUT | `/api/flags/{flagKey}` | Modify flag configuration or targeting | Admin |\n| Get Flag | GET | `/api/flags/{flagKey}` | Retrieve flag definition and current status | Admin/Read-Only |\n| List Flags | GET | `/api/flags` | List all flags with filtering and pagination | Admin/Read-Only |\n| Delete Flag | DELETE | `/api/flags/{flagKey}` | Archive flag and clean up references | Admin |\n| Create Experiment | POST | `/api/experiments` | Set up A/B test with statistical configuration | Admin |\n| Get Experiment Results | GET | `/api/experiments/{id}/results` | Retrieve experiment metrics and significance | Admin/Read-Only |\n\nThe API implements **optimistic concurrency control** using entity versioning to prevent conflicting updates from multiple administrators. Each flag definition includes a version number that increments with each modification. Update requests must specify the expected version, and the API rejects requests where the expected version doesn't match the current state.\n\n**Data consistency** across the system starts with the Flag Management API's write operations. When administrators modify flag configurations, the API immediately persists changes to the primary data store and broadcasts update notifications through the Real-time Update Service. This ensures that all client SDKs receive consistent flag definitions without requiring complex distributed consensus protocols.\n\nThe Flag Management API also serves as the **audit trail** for all flag-related changes, recording who made what changes when for compliance and debugging purposes. This audit log proves invaluable when investigating unexpected behavior or understanding the timeline of feature rollouts.\n\n> **Key Design Insight:** The Flag Management API prioritizes consistency and auditability over raw performance. Administrative operations are infrequent compared to flag evaluations, so we can afford stronger consistency guarantees and comprehensive validation at this layer.\n\n#### Evaluation Engine\n\nThe **Evaluation Engine** represents the high-performance core of the feature flag system, analogous to the split-second decision-making capabilities of air traffic controllers during peak operations. This component must process thousands of flag evaluation requests per second while maintaining consistent user assignments and respecting complex targeting rules.\n\nThe Evaluation Engine implements the `EvaluateFlag` function that takes a `FlagKey` and `UserContext` and returns an `EvaluationResult` containing the assigned variant, the computed value, and detailed reasoning for debugging purposes. The engine processes targeting rules in strict precedence order, applies percentage rollouts using consistent hashing, and returns appropriate fallback values when no rules match.\n\n| Evaluation Step | Input | Processing | Output | Performance Target |\n|-----------------|-------|------------|--------|-------------------|\n| Context Validation | `UserContext` | Validate required attributes present | Valid context or error | < 0.1ms |\n| Rule Matching | Flag rules + context | Evaluate conditions with AND/OR logic | Matching rule or none | < 0.5ms |\n| Percentage Allocation | User ID + rollout config | Apply consistent hashing algorithm | Variant assignment | < 0.1ms |\n| Value Resolution | Variant config | Lookup variant value and metadata | Resolved value | < 0.1ms |\n| Result Assembly | All previous outputs | Construct evaluation result with reason | `EvaluationResult` | < 0.1ms |\n\n**Consistent hashing** ensures that users receive the same variant assignment across multiple evaluations, even as flag configurations change. The engine combines the user's stable identifier with the flag key using a cryptographic hash function, then maps the hash output to variant buckets based on configured weight distributions. This approach prevents users from flip-flopping between variants when percentage rollouts expand or contract.\n\nThe evaluation engine maintains **in-memory flag caches** to avoid database lookups on every evaluation request. These caches update immediately when the Real-time Update Service broadcasts flag changes, ensuring sub-millisecond evaluation performance while maintaining data freshness. The cache implementation uses read-write locks to allow concurrent evaluations while blocking only during cache updates.\n\n**Rule evaluation** follows a deterministic precedence system where more specific targeting rules override general percentage rollouts. The engine evaluates user segment membership first, then individual user targeting, followed by attribute-based conditions, and finally percentage rollouts for the remaining population. This precedence system ensures predictable behavior when multiple rules could apply to the same user.\n\n> **Performance Guarantee:** The Evaluation Engine must complete flag evaluations in under 1 millisecond for 99% of requests. This strict performance requirement drives architectural decisions around caching, rule complexity limits, and fallback behaviors.\n\n#### Real-time Update Service\n\nThe **Real-time Update Service** functions as the radar and communication system of our air traffic control analogy, providing continuous situational awareness to all client SDKs about changing flag configurations. This component bridges the gap between administrative flag changes and their immediate propagation to production evaluation contexts.\n\nThe service maintains persistent connections to client SDKs using **Server-Sent Events (SSE)** for flag update streaming. SSE provides the right balance of simplicity and real-time performance for flag updates, avoiding the complexity of WebSocket bi-directional communication while maintaining sub-second update latency. The service can handle thousands of concurrent client connections while batching update notifications to minimize bandwidth usage.\n\n| Connection State | Allowed Operations | Automatic Actions | Client Behavior |\n|------------------|-------------------|-------------------|-----------------|\n| Connected | Receive updates, send heartbeats | Send flag changes immediately | Process updates, maintain cache |\n| Reconnecting | Buffer incoming requests | Apply exponential backoff | Use cached flags, attempt reconnect |\n| Disconnected | Use local cache only | Log connection attempts | Graceful degradation to cache |\n\n**Connection management** implements intelligent reconnection strategies with exponential backoff and jitter to prevent thundering herd problems when network connectivity returns after outages. The service tracks the last successful update timestamp for each client, enabling state synchronization when connections restore. Clients that reconnect after extended downtime receive complete flag configuration snapshots rather than incremental updates.\n\nThe Real-time Update Service implements **update deduplication** to handle rapid successive changes to the same flag. Rather than sending multiple update notifications within a short time window, the service batches changes and sends only the final flag state. This optimization reduces network traffic and client processing overhead during periods of intensive flag configuration changes.\n\n**Broadcasting efficiency** uses topic-based subscription patterns where clients can subscribe to specific flag changes rather than receiving all system updates. This selective subscription reduces bandwidth usage for deployments with hundreds of flags where individual services only need subsets of the total flag configuration.\n\nThe service maintains detailed **connection metrics** including client count, update delivery success rates, and reconnection patterns. These metrics provide visibility into update propagation performance and help identify clients experiencing connectivity issues that might be serving stale flag configurations.\n\n#### Client SDKs\n\nThe **Client SDKs** represent the ground-level flight controllers in our air traffic control system, executing flag evaluation decisions within application processes while maintaining connection to the central coordination infrastructure. These SDKs provide the developer-facing API that applications use to check flag values and record analytics events.\n\nClient SDKs implement **local evaluation** patterns where flag configurations are cached within the application process, enabling flag evaluations to complete without network round trips. This local evaluation approach ensures that flag checks remain fast even during network partitions or service outages, supporting the graceful degradation requirements of production systems.\n\n| SDK Component | Responsibility | Performance Impact | Fallback Behavior |\n|---------------|----------------|-------------------|-------------------|\n| Evaluation Cache | Store flag definitions locally | Enables sub-ms evaluations | Serves stale data during outages |\n| Update Client | Receive real-time flag changes | Minimal—async background updates | Continues with cached flags |\n| Analytics Buffer | Queue exposure events for batch upload | Minimal—async fire-and-forget | Drops events when buffer full |\n| Context Manager | Handle user context and segmentation | Minimal—in-memory operations | Uses empty context as fallback |\n\n**Cache management** within SDKs uses a two-tier approach with hot and warm flag storage. Frequently accessed flags remain in optimized in-memory structures for microsecond lookup times, while less active flags use more compact serialized representations. The SDK automatically promotes flags to hot storage based on evaluation frequency patterns.\n\n**Analytics integration** enables SDKs to record flag exposure events using the `RecordExposure` function without impacting evaluation performance. SDKs batch exposure events and upload them asynchronously, ensuring that analytics tracking doesn't slow down the application's critical path. When analytics services are unavailable, SDKs gracefully drop events rather than blocking flag evaluations.\n\nThe SDK provides **configuration options** for different deployment scenarios, including strict mode for development environments where flag evaluation failures should cause obvious errors, and permissive mode for production where graceful fallbacks maintain application stability.\n\n**Language-specific optimizations** allow SDKs to leverage platform capabilities like Go's lightweight goroutines for background updates or Java's concurrent data structures for thread-safe cache access. However, all SDKs maintain consistent evaluation semantics and API contracts across language boundaries.\n\n> **Design Trade-off:** Client SDKs prioritize evaluation speed and resilience over perfect consistency. They may serve flag values that are seconds out of date during network partitions, but they guarantee that applications continue functioning rather than failing due to flag service dependencies.\n\n### Project Structure and Organization\n\nThe feature flag system follows a **modular architecture** that separates concerns cleanly while supporting independent development and testing of each component. The project structure reflects the logical component boundaries and provides clear interfaces between subsystems.\n\n```\nflagsystem/\n├── cmd/                          # Application entry points\n│   ├── flagserver/               # Flag Management API server\n│   ├── updateservice/            # Real-time Update Service\n│   └── analytics/                # Analytics processing service\n├── internal/                     # Private application packages\n│   ├── evaluation/               # Core evaluation engine\n│   ├── storage/                  # Data persistence layer\n│   ├── realtime/                 # Update streaming infrastructure\n│   ├── analytics/                # Metrics and experiment analysis\n│   └── common/                   # Shared utilities and types\n├── pkg/                          # Public API packages\n│   ├── sdk/                      # Client SDK implementations\n│   ├── api/                      # API client libraries\n│   └── types/                    # Shared type definitions\n├── configs/                      # Configuration files\n├── migrations/                   # Database schema migrations\n├── deployments/                  # Deployment configurations\n└── docs/                         # Additional documentation\n```\n\n#### Core Internal Packages\n\nThe **internal/evaluation** package contains the flag evaluation engine and implements all rule processing logic. This package has no external dependencies beyond basic data structures, making it highly testable and portable across different deployment environments.\n\n| File | Purpose | Key Types | External Dependencies |\n|------|---------|-----------|----------------------|\n| `engine.go` | Core evaluation logic and `EvaluateFlag` implementation | `EvaluationEngine`, `EvaluationResult` | None |\n| `rules.go` | Targeting rule processing and precedence handling | `Rule`, `Condition`, `RuleEvaluator` | None |\n| `hashing.go` | Consistent hashing for user assignment | `UserHasher`, `BucketAllocator` | crypto/sha256 |\n| `cache.go` | In-memory flag definition caching | `FlagCache`, `CacheEntry` | sync |\n\nThe **internal/storage** package abstracts data persistence operations and provides interfaces that support multiple backend implementations. The package defines repository interfaces for flags, experiments, and analytics data while implementing concrete adapters for specific databases.\n\nThe **internal/realtime** package handles all streaming update functionality including SSE connection management, client tracking, and update broadcasting. This package integrates with the storage layer to detect flag changes and with the evaluation engine to validate update consistency.\n\n#### Public SDK Package Structure\n\nThe **pkg/sdk** package provides client libraries for different programming languages while maintaining consistent APIs and evaluation semantics. Each language implementation follows the same architectural patterns adapted to platform-specific idioms and performance characteristics.\n\n| Language | Package Structure | Key Files | Platform Optimizations |\n|----------|-------------------|-----------|------------------------|\n| Go | `pkg/sdk/go/` | `client.go`, `cache.go`, `types.go` | Goroutines for background updates |\n| Python | `pkg/sdk/python/` | `client.py`, `cache.py`, `types.py` | Asyncio for concurrent operations |\n| Java | `pkg/sdk/java/` | `Client.java`, `Cache.java`, `Types.java` | ExecutorService for thread management |\n\n#### Configuration and Deployment Structure\n\nThe **configs/** directory contains environment-specific configuration files using a hierarchical structure that supports local development, testing, staging, and production deployments. Configuration files use YAML format with clear sections for each system component.\n\nThe **deployments/** directory includes Docker configurations, Kubernetes manifests, and infrastructure-as-code definitions that support the feature flag system's deployment across different environments. The deployment configurations reflect the component architecture with separate services for the Flag Management API, Real-time Update Service, and analytics processing.\n\n> **Organizational Principle:** The project structure emphasizes **interface-driven development** where each package exports clear contracts through interface definitions. This approach supports testing with mock implementations and enables incremental migration to different storage or streaming technologies.\n\n### Architecture Decision Records\n\n> **Decision: Evaluation-First Architecture**\n> - **Context**: Feature flag systems must balance evaluation performance, update latency, administrative functionality, and analytics capabilities within resource constraints\n> - **Options Considered**: \n>   1. Admin-first: Comprehensive management UI with basic evaluation\n>   2. Analytics-first: Detailed experiment tracking with slower evaluation  \n>   3. Evaluation-first: Optimized flag checking with supporting services\n> - **Decision**: Build an evaluation-first architecture that prioritizes flag evaluation performance above other concerns\n> - **Rationale**: Flag evaluations occur orders of magnitude more frequently than administrative operations. A typical application performs thousands of evaluations per second but only updates flag configurations a few times per day. Slow evaluations directly impact user-facing application performance, while slower administrative interfaces only affect developer productivity\n> - **Consequences**: This architecture enables sub-millisecond flag evaluations through local caching and optimized rule processing, but requires more sophisticated real-time update mechanisms to maintain cache consistency across distributed clients\n\n| Approach | Evaluation Latency | Update Propagation | Administrative Features | Chosen? |\n|----------|-------------------|-------------------|------------------------|---------|\n| Admin-first | 10-50ms (DB per eval) | Immediate | Rich UI, complex workflows | ❌ |\n| Analytics-first | 5-20ms (logging overhead) | Eventual consistency | Basic admin, detailed metrics | ❌ |\n| Evaluation-first | <1ms (cached local eval) | <5 seconds via SSE | Functional admin, core metrics | ✅ |\n\n> **Decision: Server-Sent Events for Real-time Updates**\n> - **Context**: Client SDKs need real-time flag updates to maintain cache consistency while supporting thousands of concurrent connections efficiently\n> - **Options Considered**:\n>   1. Polling: Clients request updates on fixed intervals\n>   2. WebSockets: Full bidirectional communication channels\n>   3. Server-Sent Events: Unidirectional server-to-client streaming\n> - **Decision**: Use Server-Sent Events (SSE) for streaming flag updates to client SDKs\n> - **Rationale**: Flag updates are inherently unidirectional—the server pushes configuration changes to clients, but clients don't need to send data back through the same channel. SSE provides automatic reconnection, built-in event typing, and lower overhead than WebSockets. The protocol handles connection failures gracefully with exponential backoff, reducing server load during network instability\n> - **Consequences**: SSE enables sub-second update propagation with minimal server resources, but limits future bidirectional features like client-initiated flag requests or real-time debugging commands\n\n| Protocol | Connection Overhead | Reconnection Handling | Browser Support | Server Complexity | Chosen? |\n|----------|-------------------|----------------------|-----------------|-------------------|---------|\n| Polling | Low per request | Automatic | Universal | Minimal | ❌ |\n| WebSockets | High (persistent TCP) | Manual implementation | Good | High | ❌ |\n| SSE | Medium (HTTP streaming) | Automatic with backoff | Good | Medium | ✅ |\n\n> **Decision: In-Memory Flag Caching with Real-time Invalidation**\n> - **Context**: Flag evaluations must complete in under 1 millisecond while maintaining reasonable consistency when flag configurations change\n> - **Options Considered**:\n>   1. Direct database access: Query flag definitions on every evaluation\n>   2. Application-level caching: Cache flags with TTL-based expiration\n>   3. Real-time cache invalidation: Cache flags and invalidate immediately on changes\n> - **Decision**: Implement in-memory flag caching with real-time cache invalidation triggered by update notifications\n> - **Rationale**: Database queries add 5-50ms latency that violates performance requirements, while TTL-based caching can serve stale flag values for extended periods during rapid configuration changes. Real-time invalidation provides the best balance of performance and consistency by maintaining microsecond evaluation speeds while propagating changes within seconds\n> - **Consequences**: This approach enables target performance goals and ensures timely update propagation, but requires sophisticated cache management logic and increases system complexity through the real-time update infrastructure\n\n| Caching Strategy | Evaluation Latency | Consistency Guarantee | Implementation Complexity | Chosen? |\n|------------------|-------------------|----------------------|---------------------------|---------|\n| No caching | 5-50ms | Strong | Low | ❌ |\n| TTL-based | <1ms | Eventual (TTL period) | Medium | ❌ |\n| Real-time invalidation | <1ms | Near real-time (<5sec) | High | ✅ |\n\n### Implementation Guidance\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|----------------|\n| HTTP Server | `net/http` with `gorilla/mux` | `gin-gonic/gin` with middleware |\n| Database | PostgreSQL with `lib/pq` | PostgreSQL with `gorm` ORM |\n| Caching | In-memory `sync.Map` | Redis with `go-redis/redis` |\n| Real-time Updates | SSE with `net/http` flusher | Custom SSE library with reconnection |\n| Configuration | YAML files with `gopkg.in/yaml.v3` | Consul/etcd with `spf13/viper` |\n| Logging | Standard `log` package | `sirupsen/logrus` structured logging |\n| Testing | Built-in `testing` package | `testify/suite` with assertions |\n\n#### Recommended Project Structure\n\n```\nflagsystem/\n├── cmd/\n│   ├── flagserver/\n│   │   └── main.go                 # Flag Management API entry point\n│   ├── updateservice/\n│   │   └── main.go                 # Real-time Update Service entry point\n│   └── analytics/\n│       └── main.go                 # Analytics service entry point\n├── internal/\n│   ├── evaluation/\n│   │   ├── engine.go               # Core evaluation implementation\n│   │   ├── engine_test.go          # Evaluation engine tests\n│   │   ├── rules.go                # Rule processing logic\n│   │   ├── rules_test.go           # Rule evaluation tests\n│   │   ├── cache.go                # Flag definition caching\n│   │   └── hashing.go              # Consistent user assignment\n│   ├── storage/\n│   │   ├── interfaces.go           # Repository interfaces\n│   │   ├── postgres.go             # PostgreSQL implementation\n│   │   ├── memory.go               # In-memory implementation for testing\n│   │   └── migrations/             # Database schema migrations\n│   ├── realtime/\n│   │   ├── server.go               # SSE server implementation\n│   │   ├── connections.go          # Client connection management\n│   │   └── broadcaster.go          # Update broadcasting logic\n│   ├── api/\n│   │   ├── handlers.go             # HTTP request handlers\n│   │   ├── middleware.go           # Authentication and logging middleware\n│   │   └── validation.go           # Request validation logic\n│   ├── analytics/\n│   │   ├── collector.go            # Exposure event collection\n│   │   ├── experiments.go          # A/B testing logic\n│   │   └── statistics.go           # Statistical significance calculation\n│   └── common/\n│       ├── types.go                # Shared type definitions\n│       ├── errors.go               # Error types and handling\n│       └── config.go               # Configuration structures\n├── pkg/\n│   └── sdk/\n│       └── go/\n│           ├── client.go           # SDK client implementation\n│           ├── client_test.go      # SDK integration tests\n│           ├── cache.go            # Client-side flag caching\n│           └── types.go            # SDK-specific types\n├── configs/\n│   ├── development.yaml            # Development environment config\n│   ├── testing.yaml                # Testing environment config\n│   └── production.yaml             # Production environment config\n├── deployments/\n│   ├── docker-compose.yaml         # Local development setup\n│   ├── kubernetes/                 # Kubernetes manifests\n│   └── terraform/                  # Infrastructure as code\n├── docs/\n│   ├── api.md                      # API documentation\n│   └── deployment.md               # Deployment guide\n├── go.mod                          # Go module definition\n├── go.sum                          # Dependency checksums\n├── Makefile                        # Build and test automation\n└── README.md                       # Project overview and setup\n```\n\n#### Core Type Definitions\n\n```go\n// internal/common/types.go\npackage common\n\nimport \"time\"\n\n// Core identifier types for type safety\ntype FlagKey string\ntype UserID string\n\n// User context for flag evaluation targeting\ntype UserContext struct {\n    UserID     UserID                    `json:\"user_id\"`\n    Attributes map[string]interface{}    `json:\"attributes\"`\n    Segments   []string                  `json:\"segments\"`\n}\n\n// Flag variant definition with weighted allocation\ntype Variant struct {\n    Key    string      `json:\"key\"`\n    Value  interface{} `json:\"value\"`\n    Weight int         `json:\"weight\"`\n}\n\n// Result of flag evaluation with debugging information\ntype EvaluationResult struct {\n    FlagKey FlagKey     `json:\"flag_key\"`\n    Value   interface{} `json:\"value\"`\n    Variant string      `json:\"variant\"`\n    Reason  string      `json:\"reason\"`\n    Source  string      `json:\"source\"`\n}\n\n// Flag change notification for real-time updates\ntype FlagUpdate struct {\n    FlagKey   FlagKey   `json:\"flag_key\"`\n    Operation string    `json:\"operation\"` // \"create\", \"update\", \"delete\"\n    Timestamp time.Time `json:\"timestamp\"`\n    Version   int64     `json:\"version\"`\n}\n\n// Flag evaluation event for analytics\ntype FlagExposure struct {\n    FlagKey     FlagKey                `json:\"flag_key\"`\n    UserID      UserID                 `json:\"user_id\"`\n    Variant     string                 `json:\"variant\"`\n    Value       interface{}            `json:\"value\"`\n    Context     map[string]interface{} `json:\"context\"`\n    Timestamp   time.Time              `json:\"timestamp\"`\n    ExperimentID *string               `json:\"experiment_id,omitempty\"`\n}\n\n// Statistical significance calculation result\ntype SignificanceResult struct {\n    ExperimentID     string    `json:\"experiment_id\"`\n    ControlVariant   string    `json:\"control_variant\"`\n    TreatmentVariant string    `json:\"treatment_variant\"`\n    PValue           float64   `json:\"p_value\"`\n    Confidence       float64   `json:\"confidence\"`\n    Significant      bool      `json:\"significant\"`\n    CalculatedAt     time.Time `json:\"calculated_at\"`\n}\n```\n\n#### Core Interface Definitions\n\n```go\n// internal/evaluation/interfaces.go\npackage evaluation\n\n// Core flag evaluation interface\ntype Evaluator interface {\n    // EvaluateFlag processes targeting rules and returns appropriate variant\n    EvaluateFlag(flagKey FlagKey, context UserContext) EvaluationResult\n    \n    // UpdateFlags refreshes cached flag definitions\n    UpdateFlags(updates []FlagUpdate) error\n    \n    // GetFlags returns all currently cached flag keys\n    GetFlags() []FlagKey\n}\n\n// internal/realtime/interfaces.go\npackage realtime\n\n// Real-time update streaming interface\ntype UpdateStreamer interface {\n    // StreamUpdates provides real-time flag changes for specific client\n    StreamUpdates(clientID string) chan FlagUpdate\n    \n    // BroadcastUpdate sends flag changes to all connected clients\n    BroadcastUpdate(update FlagUpdate) error\n    \n    // DisconnectClient cleans up resources for disconnected client\n    DisconnectClient(clientID string) error\n}\n\n// internal/analytics/interfaces.go\npackage analytics\n\n// Analytics and experiment tracking interface\ntype AnalyticsCollector interface {\n    // RecordExposure logs flag evaluation event for analysis\n    RecordExposure(exposure FlagExposure) error\n    \n    // CalculateSignificance computes experiment statistical results\n    CalculateSignificance(experimentID string) SignificanceResult\n    \n    // GetExperimentMetrics returns aggregated experiment data\n    GetExperimentMetrics(experimentID string) (map[string]interface{}, error)\n}\n```\n\n#### Infrastructure Starter Code\n\n```go\n// internal/storage/memory.go - Complete in-memory storage for testing\npackage storage\n\nimport (\n    \"fmt\"\n    \"sync\"\n    \"time\"\n    \n    \"flagsystem/internal/common\"\n)\n\n// InMemoryFlagStore provides thread-safe in-memory flag storage\ntype InMemoryFlagStore struct {\n    flags  map[common.FlagKey]*FlagDefinition\n    mutex  sync.RWMutex\n    \n    // Audit trail for debugging\n    changes []FlagChange\n}\n\ntype FlagDefinition struct {\n    Key         common.FlagKey           `json:\"key\"`\n    Name        string                   `json:\"name\"`\n    Description string                   `json:\"description\"`\n    Enabled     bool                     `json:\"enabled\"`\n    Variants    []common.Variant         `json:\"variants\"`\n    Rules       []TargetingRule          `json:\"rules\"`\n    DefaultRule *PercentageRule          `json:\"default_rule\"`\n    Version     int64                    `json:\"version\"`\n    CreatedAt   time.Time                `json:\"created_at\"`\n    UpdatedAt   time.Time                `json:\"updated_at\"`\n}\n\ntype TargetingRule struct {\n    ID          string                   `json:\"id\"`\n    Name        string                   `json:\"name\"`\n    Conditions  []Condition              `json:\"conditions\"`\n    Operator    string                   `json:\"operator\"` // \"AND\" or \"OR\"\n    Allocation  []VariantAllocation      `json:\"allocation\"`\n    Enabled     bool                     `json:\"enabled\"`\n}\n\ntype Condition struct {\n    Attribute string      `json:\"attribute\"`\n    Operator  string      `json:\"operator\"` // \"equals\", \"in\", \"contains\", etc.\n    Value     interface{} `json:\"value\"`\n}\n\ntype VariantAllocation struct {\n    Variant    string `json:\"variant\"`\n    Percentage int    `json:\"percentage\"`\n}\n\ntype PercentageRule struct {\n    Allocations []VariantAllocation `json:\"allocations\"`\n}\n\ntype FlagChange struct {\n    FlagKey   common.FlagKey `json:\"flag_key\"`\n    Operation string         `json:\"operation\"`\n    Timestamp time.Time      `json:\"timestamp\"`\n    Version   int64          `json:\"version\"`\n}\n\n// NewInMemoryFlagStore creates a new in-memory flag store\nfunc NewInMemoryFlagStore() *InMemoryFlagStore {\n    return &InMemoryFlagStore{\n        flags:   make(map[common.FlagKey]*FlagDefinition),\n        changes: make([]FlagChange, 0),\n    }\n}\n\n// GetFlag retrieves a flag definition by key\nfunc (s *InMemoryFlagStore) GetFlag(key common.FlagKey) (*FlagDefinition, error) {\n    s.mutex.RLock()\n    defer s.mutex.RUnlock()\n    \n    flag, exists := s.flags[key]\n    if !exists {\n        return nil, fmt.Errorf(\"flag not found: %s\", key)\n    }\n    \n    // Return a copy to prevent external mutation\n    flagCopy := *flag\n    return &flagCopy, nil\n}\n\n// CreateFlag stores a new flag definition\nfunc (s *InMemoryFlagStore) CreateFlag(flag *FlagDefinition) error {\n    s.mutex.Lock()\n    defer s.mutex.Unlock()\n    \n    if _, exists := s.flags[flag.Key]; exists {\n        return fmt.Errorf(\"flag already exists: %s\", flag.Key)\n    }\n    \n    now := time.Now()\n    flag.Version = 1\n    flag.CreatedAt = now\n    flag.UpdatedAt = now\n    \n    // Store a copy to prevent external mutation\n    flagCopy := *flag\n    s.flags[flag.Key] = &flagCopy\n    \n    // Record change for audit trail\n    s.changes = append(s.changes, FlagChange{\n        FlagKey:   flag.Key,\n        Operation: \"create\",\n        Timestamp: now,\n        Version:   flag.Version,\n    })\n    \n    return nil\n}\n\n// UpdateFlag modifies an existing flag definition\nfunc (s *InMemoryFlagStore) UpdateFlag(flag *FlagDefinition) error {\n    s.mutex.Lock()\n    defer s.mutex.Unlock()\n    \n    existing, exists := s.flags[flag.Key]\n    if !exists {\n        return fmt.Errorf(\"flag not found: %s\", flag.Key)\n    }\n    \n    now := time.Now()\n    flag.Version = existing.Version + 1\n    flag.CreatedAt = existing.CreatedAt\n    flag.UpdatedAt = now\n    \n    // Store a copy to prevent external mutation\n    flagCopy := *flag\n    s.flags[flag.Key] = &flagCopy\n    \n    // Record change for audit trail\n    s.changes = append(s.changes, FlagChange{\n        FlagKey:   flag.Key,\n        Operation: \"update\",\n        Timestamp: now,\n        Version:   flag.Version,\n    })\n    \n    return nil\n}\n\n// ListFlags returns all flag definitions with optional filtering\nfunc (s *InMemoryFlagStore) ListFlags(enabledOnly bool) ([]*FlagDefinition, error) {\n    s.mutex.RLock()\n    defer s.mutex.RUnlock()\n    \n    flags := make([]*FlagDefinition, 0, len(s.flags))\n    \n    for _, flag := range s.flags {\n        if !enabledOnly || flag.Enabled {\n            // Return copies to prevent external mutation\n            flagCopy := *flag\n            flags = append(flags, &flagCopy)\n        }\n    }\n    \n    return flags, nil\n}\n\n// GetChangesSince returns flag changes after specified timestamp\nfunc (s *InMemoryFlagStore) GetChangesSince(since time.Time) ([]FlagChange, error) {\n    s.mutex.RLock()\n    defer s.mutex.RUnlock()\n    \n    changes := make([]FlagChange, 0)\n    \n    for _, change := range s.changes {\n        if change.Timestamp.After(since) {\n            changes = append(changes, change)\n        }\n    }\n    \n    return changes, nil\n}\n```\n\n#### Core Logic Skeletons\n\n```go\n// internal/evaluation/engine.go - Core evaluation logic to implement\npackage evaluation\n\nimport (\n    \"crypto/sha256\"\n    \"encoding/binary\"\n    \"fmt\"\n    \"math\"\n    \n    \"flagsystem/internal/common\"\n    \"flagsystem/internal/storage\"\n)\n\n// EvaluationEngine implements the core flag evaluation logic\ntype EvaluationEngine struct {\n    flagStore storage.FlagRepository\n    cache     *FlagCache\n}\n\n// NewEvaluationEngine creates a new evaluation engine\nfunc NewEvaluationEngine(flagStore storage.FlagRepository) *EvaluationEngine {\n    return &EvaluationEngine{\n        flagStore: flagStore,\n        cache:     NewFlagCache(),\n    }\n}\n\n// EvaluateFlag processes targeting rules and returns appropriate variant\nfunc (e *EvaluationEngine) EvaluateFlag(flagKey common.FlagKey, context common.UserContext) common.EvaluationResult {\n    // TODO 1: Validate input parameters - check flagKey is not empty, context has valid UserID\n    //         Return error result if validation fails\n    \n    // TODO 2: Retrieve flag definition from cache, falling back to storage if cache miss\n    //         Use e.cache.GetFlag(flagKey) first, then e.flagStore.GetFlag(flagKey) as fallback\n    \n    // TODO 3: Check if flag is enabled - if disabled, return default variant with reason \"flag_disabled\"\n    \n    // TODO 4: Evaluate targeting rules in precedence order using evaluateTargetingRules()\n    //         Rules should be processed from most specific to most general\n    \n    // TODO 5: If no targeting rules match, apply percentage rollout using consistent hashing\n    //         Call calculateUserBucket() to get user's bucket assignment\n    \n    // TODO 6: If no percentage rule matches, return default variant from flag definition\n    //         Include detailed reason explaining why this fallback was used\n    \n    // TODO 7: Construct and return EvaluationResult with variant key, resolved value, evaluation reason\n    \n    return common.EvaluationResult{\n        FlagKey: flagKey,\n        Value:   nil, // TODO: Replace with actual resolved value\n        Variant: \"\",  // TODO: Replace with selected variant key\n        Reason:  \"\",  // TODO: Replace with evaluation reason\n        Source:  \"evaluation_engine\",\n    }\n}\n\n// evaluateTargetingRules processes flag rules against user context\nfunc (e *EvaluationEngine) evaluateTargetingRules(rules []storage.TargetingRule, context common.UserContext) (string, interface{}, string, bool) {\n    // TODO 1: Iterate through rules in order (rules are pre-sorted by precedence)\n    \n    // TODO 2: For each rule, check if it's enabled - skip disabled rules\n    \n    // TODO 3: Evaluate rule conditions using evaluateRuleConditions()\n    //         Handle AND/OR operators correctly based on rule.Operator\n    \n    // TODO 4: If rule matches, apply percentage allocation within the rule\n    //         Use consistent hashing to select variant from rule's allocation\n    \n    // TODO 5: Return selected variant key, resolved value, and evaluation reason\n    //         Reason should indicate which rule matched (e.g., \"targeting_rule:user_segment\")\n    \n    return \"\", nil, \"\", false // TODO: Replace with actual values\n}\n\n// evaluateRuleConditions checks if user context satisfies rule conditions\nfunc (e *EvaluationEngine) evaluateRuleConditions(conditions []storage.Condition, operator string, context common.UserContext) bool {\n    // TODO 1: Handle empty conditions array (should return true - matches all users)\n    \n    // TODO 2: Evaluate each condition using evaluateCondition()\n    //         Store boolean result for each condition\n    \n    // TODO 3: Apply logical operator (AND/OR) to combine condition results\n    //         AND: all conditions must be true\n    //         OR: at least one condition must be true\n    \n    // TODO 4: Return final boolean result\n    \n    return false // TODO: Replace with actual logic\n}\n\n// evaluateCondition checks a single condition against user context\nfunc (e *EvaluationEngine) evaluateCondition(condition storage.Condition, context common.UserContext) bool {\n    // TODO 1: Get attribute value from context.Attributes using condition.Attribute\n    //         Handle missing attributes (return false for most operators)\n    \n    // TODO 2: Handle special attributes like \"user_id\" and \"segments\"\n    //         user_id should use context.UserID value\n    //         segments should check if condition.Value is in context.Segments\n    \n    // TODO 3: Apply condition operator:\n    //         \"equals\": attribute == condition.Value\n    //         \"not_equals\": attribute != condition.Value  \n    //         \"in\": attribute is in condition.Value (array)\n    //         \"not_in\": attribute is not in condition.Value (array)\n    //         \"contains\": string(attribute) contains string(condition.Value)\n    //         \"starts_with\": string(attribute) starts with string(condition.Value)\n    //         \"greater_than\": numeric comparison\n    //         \"less_than\": numeric comparison\n    \n    // TODO 4: Handle type conversions and edge cases gracefully\n    //         String comparisons should be case-sensitive\n    //         Numeric comparisons should handle int/float conversions\n    \n    return false // TODO: Replace with actual logic\n}\n\n// calculateUserBucket determines user's allocation bucket using consistent hashing\nfunc (e *EvaluationEngine) calculateUserBucket(userID common.UserID, flagKey common.FlagKey) int {\n    // TODO 1: Create hash input by combining userID and flagKey\n    //         Use format like \"userID:flagKey\" to ensure uniqueness across flags\n    \n    // TODO 2: Calculate SHA-256 hash of the input string\n    //         Use crypto/sha256 package for cryptographically secure hashing\n    \n    // TODO 3: Convert first 8 bytes of hash to uint64 using binary.BigEndian\n    //         This provides consistent numeric value from hash bytes\n    \n    // TODO 4: Map hash to percentage bucket (0-99) using modulo operation\n    //         Ensure uniform distribution across the 0-99 range\n    \n    // HINT: Consistent hashing ensures the same user always gets the same bucket\n    // for a given flag, even across multiple evaluation calls\n    \n    return 0 // TODO: Replace with calculated bucket\n}\n\n// resolveVariantValue gets the configured value for a variant key\nfunc (e *EvaluationEngine) resolveVariantValue(variants []common.Variant, variantKey string) (interface{}, error) {\n    // TODO 1: Search through variants array to find variant with matching Key\n    \n    // TODO 2: Return the variant's Value field if found\n    \n    // TODO 3: Return error if variant key not found in variants array\n    //         Include both the sought key and available keys in error message\n    \n    return nil, fmt.Errorf(\"variant not found: %s\", variantKey) // TODO: Replace with actual logic\n}\n```\n\n#### Milestone Checkpoints\n\n**After Milestone 1 (Flag Evaluation Engine):**\n- Run `go test ./internal/evaluation/...` - all tests should pass\n- Create a simple flag with boolean variants and percentage rollout\n- Verify that the same user ID always gets the same variant across multiple evaluations\n- Test rule evaluation with user segments and attribute conditions\n- Check that evaluation completes in under 1 millisecond for cached flags\n\n**After Milestone 2 (Real-time Flag Updates):**\n- Start the update service with `go run cmd/updateservice/main.go`\n- Connect a test client and verify SSE connection establishment\n- Update a flag configuration and confirm the change propagates within 5 seconds\n- Disconnect the client, update flags, reconnect, and verify state synchronization\n- Monitor connection metrics to ensure proper cleanup of disconnected clients\n\n**After Milestone 3 (Flag Analytics & Experiments):**\n- Run an A/B test with two variants and record exposure events\n- Generate test conversion data and verify statistical significance calculation\n- Check that exposure events are batched and uploaded without blocking evaluations\n- Verify experiment reports show confidence intervals and p-values\n- Test sample ratio mismatch detection with uneven traffic allocation\n\n\n## Data Model\n\n> **Milestone(s):** This section establishes the data structures for Milestone 1 (Flag Evaluation Engine), Milestone 2 (Real-time Flag Updates), and Milestone 3 (Flag Analytics & Experiments) by defining how flags, rules, user contexts, and experiments are modeled and stored.\n\nThink of the data model as the **blueprint for a sophisticated air traffic control system**. Just as air traffic control needs detailed information about each aircraft (flight number, destination, altitude, speed), weather conditions (wind patterns, visibility), and flight rules (priority levels, restricted airspace), our feature flag system needs comprehensive data structures to make intelligent routing decisions about which users receive which features.\n\n![Data Model Relationships](./diagrams/data-model.svg)\n\nThe air traffic control analogy extends to the relationships between data entities. Aircraft have dependencies on runways, weather affects multiple flights simultaneously, and control tower decisions must be logged for safety audits. Similarly, feature flags have complex relationships with targeting rules, user contexts affect multiple flag evaluations, and every flag decision must be tracked for analysis and compliance.\n\nOur data model must support three critical capabilities that parallel air traffic control operations. First, **real-time decision making** requires rich context about each \"aircraft\" (user) and current \"weather conditions\" (system state) to route traffic safely. Second, **historical tracking** demands comprehensive logging of every decision for post-incident analysis and performance optimization. Third, **predictive planning** needs structured experiment data to forecast the impact of routing changes before they affect live traffic.\n\n### Flag Definition Structure\n\nThe flag definition structure serves as the **master flight plan** for each feature, containing all the information needed to make consistent routing decisions across millions of users. Just as a flight plan specifies departure gates, flight paths, alternate routes, and emergency procedures, a flag definition specifies variants, targeting rules, fallback behavior, and operational metadata.\n\nThe core challenge in modeling flag definitions lies in supporting **flexible targeting without sacrificing evaluation performance**. Simple boolean flags might seem sufficient initially, but production systems quickly demand percentage rollouts, user segmentation, geographic targeting, and complex rule combinations. Our data model must accommodate this complexity while ensuring that flag evaluation remains fast enough for real-time request processing.\n\n> **Decision: Hierarchical Rule Structure with Explicit Precedence**\n> - **Context**: Flag targeting can involve multiple overlapping rules (user attributes, segments, percentage rollouts), and the order of evaluation affects which users receive which variants\n> - **Options Considered**: \n>   1. Flat rule list with implicit precedence\n>   2. Hierarchical rules with explicit priority numbers\n>   3. Single rule type with complex nested conditions\n> - **Decision**: Hierarchical rules with explicit precedence ordering\n> - **Rationale**: Explicit precedence prevents non-deterministic evaluation when rules overlap, hierarchical structure supports complex logic without performance penalties, and clear separation enables easier debugging and rule management\n> - **Consequences**: Enables predictable evaluation behavior and supports complex targeting scenarios, but requires careful precedence management and slightly more complex rule authoring\n\n| Rule Precedence | Rule Type | Purpose | Example Use Case |\n|---|---|---|---|\n| 1 (Highest) | User Override Rules | Target specific users or segments | Enable beta feature for internal team |\n| 2 | Attribute-Based Rules | Target based on user properties | Show premium features to paid users |\n| 3 | Percentage Rules | Gradual rollouts with consistent assignment | Release to 25% of users in US region |\n| 4 (Lowest) | Default Rule | Fallback when no other rules match | Disable feature for remaining users |\n\nThe `FlagDefinition` structure captures this hierarchical approach while maintaining evaluation efficiency. Each flag contains multiple rule layers that are processed in strict precedence order, ensuring deterministic outcomes regardless of rule complexity or user context variations.\n\n| Field | Type | Description |\n|---|---|---|\n| Key | FlagKey | Unique identifier for the flag across all environments |\n| Name | string | Human-readable name for management interface display |\n| Description | string | Purpose and context documentation for team collaboration |\n| Enabled | bool | Master switch to disable flag evaluation without deleting |\n| Type | string | Value type: \"boolean\", \"string\", \"number\", \"json\" |\n| Variants | []Variant | Available variants with keys, values, and allocation weights |\n| TargetingRules | []TargetingRule | Ordered list of conditional rules with explicit precedence |\n| PercentageRule | PercentageRule | Default percentage allocation when no targeting rules match |\n| DefaultVariant | string | Fallback variant key when all rules fail or flag is disabled |\n| Prerequisites | []FlagKey | Other flags that must be enabled before evaluating this flag |\n| CreatedAt | time.Time | Flag creation timestamp for audit trail |\n| UpdatedAt | time.Time | Last modification timestamp for cache invalidation |\n| CreatedBy | string | User identifier who created the flag |\n| UpdatedBy | string | User identifier who last modified the flag |\n| Tags | []string | Categorical labels for organization and filtering |\n| Archived | bool | Soft deletion marker for flags no longer in use |\n\nThe `Variant` structure represents each possible outcome of a flag evaluation, containing not just the value but also metadata needed for consistent allocation and debugging. Think of variants as different **flight destinations** that users can be routed to based on the evaluation rules.\n\n| Field | Type | Description |\n|---|---|---|\n| Key | string | Unique identifier for the variant within the flag |\n| Value | interface{} | Actual value returned to client (string, number, boolean, or JSON object) |\n| Weight | int | Relative weight for percentage allocation (higher numbers = larger allocation) |\n| Name | string | Human-readable name for management interface |\n| Description | string | Documentation of variant purpose and expected behavior |\n\nTargeting rules provide the **conditional logic engine** that determines which users receive which variants. Each rule represents a specific targeting strategy with its own conditions and variant allocation scheme.\n\n| Field | Type | Description |\n|---|---|---|\n| ID | string | Unique identifier for the rule within the flag |\n| Description | string | Human-readable explanation of rule purpose |\n| Conditions | []Condition | List of attribute-based conditions that must be satisfied |\n| ConditionOperator | string | Logical operator combining conditions: \"AND\" or \"OR\" |\n| VariantAllocations | []VariantAllocation | How to distribute users matching this rule across variants |\n| Enabled | bool | Switch to temporarily disable rule without deletion |\n\nIndividual conditions within targeting rules specify **attribute-based matching criteria** that are evaluated against the user context. The condition model supports various comparison operations to handle different attribute types and matching scenarios.\n\n| Field | Type | Description |\n|---|---|---|\n| Attribute | string | User context attribute name to evaluate (e.g., \"email\", \"plan\", \"region\") |\n| Operator | string | Comparison operator: \"equals\", \"in\", \"contains\", \"greater_than\", \"less_than\" |\n| Values | []interface{} | List of values to compare against (type matches operator requirements) |\n| Negate | bool | Whether to invert the condition result (NOT operation) |\n\nThe percentage rule provides **default allocation behavior** when no targeting rules match the user context. This ensures every user receives a variant assignment through consistent hashing, even when they don't match any specific targeting criteria.\n\n| Field | Type | Description |\n|---|---|---|\n| VariantAllocations | []VariantAllocation | Distribution of unmatched users across variants |\n| Enabled | bool | Whether to apply percentage rule or return default variant |\n\nVariant allocations specify how users matching a rule are distributed across available variants using **deterministic percentage splits**. The allocation system ensures stable assignment where users consistently receive the same variant across multiple evaluations.\n\n| Field | Type | Description |\n|---|---|---|\n| VariantKey | string | Key of variant to assign |\n| Percentage | int | Percentage of matched users to assign this variant (0-100) |\n| RangeStart | int | Starting bucket number for this allocation (computed from percentage) |\n| RangeEnd | int | Ending bucket number for this allocation (computed from percentage) |\n\n> The critical insight for percentage allocation is that percentages are converted to **bucket ranges** during flag creation, not during evaluation. This preprocessing enables fast evaluation by checking which bucket a user falls into rather than performing percentage calculations on every request.\n\n**Common Rule Modeling Pitfalls:**\n\n⚠️ **Pitfall: Overlapping Percentage Allocations**\nMany implementations allow variant allocations that sum to more or less than 100%, causing non-deterministic assignment or users falling through cracks. Always validate that percentages sum exactly to 100% within each rule and use bucket ranges to ensure complete coverage.\n\n⚠️ **Pitfall: Circular Flag Prerequisites**\nFlag A depends on Flag B which depends on Flag A, creating infinite loops during evaluation. Implement dependency graph validation during flag creation to detect cycles, and consider topological sorting for complex dependency chains.\n\n⚠️ **Pitfall: Implicit Rule Precedence**\nWithout explicit ordering, rules evaluated in database insertion order or hash map iteration order produce different results across system restarts. Always maintain explicit rule precedence and process rules in consistent order during evaluation.\n\n### User Context and Segmentation\n\nUser context serves as the **aircraft identification and flight characteristics** that enable intelligent routing decisions. Just as air traffic controllers need to know aircraft type, destination, fuel levels, and passenger count to make safe routing decisions, the feature flag system needs comprehensive user attributes to apply targeting rules effectively.\n\nThe challenge in context modeling lies in balancing **flexibility with performance**. User contexts must support arbitrary attributes for complex targeting scenarios, but evaluation latency requirements demand efficient attribute lookup and comparison operations. Additionally, contexts must accommodate both real-time attributes (current location, device type) and slowly-changing attributes (subscription plan, account creation date) without compromising evaluation consistency.\n\n> **Decision: Flat Attribute Map with Type Inference**\n> - **Context**: User contexts need to support arbitrary attributes with different data types, but complex nested structures slow down rule evaluation and serialization\n> - **Options Considered**:\n>   1. Strongly-typed context with predefined fields\n>   2. Nested JSON object with hierarchical attributes\n>   3. Flat map with runtime type inference\n> - **Decision**: Flat attribute map with interface{} values and runtime type inference\n> - **Rationale**: Flat structure enables fast attribute lookup, interface{} values support all JSON-serializable types, runtime inference handles type coercion for rule operators, and simple structure simplifies SDK integration\n> - **Consequences**: Supports arbitrary attributes without schema constraints and enables efficient evaluation, but requires careful type handling and limits nesting capabilities\n\nThe `UserContext` structure captures all information needed to evaluate targeting rules against a specific user. This context travels with every flag evaluation request and serves as the primary input to the rule matching engine.\n\n| Field | Type | Description |\n|---|---|---|\n| UserID | UserID | Stable user identifier for consistent variant assignment across sessions |\n| Attributes | map[string]interface{} | Key-value pairs representing user characteristics and properties |\n| Segments | []string | Pre-computed segment memberships for efficient group-based targeting |\n| RequestContext | map[string]interface{} | Request-specific attributes (IP address, user agent, timestamp) |\n| SessionID | string | Session identifier for request grouping and analytics attribution |\n| AnonymousID | string | Anonymous identifier for users without stable UserID |\n| CustomProperties | map[string]interface{} | Application-specific context not fitting standard categories |\n\nThe user ID serves as the **aircraft tail number** - a stable, unique identifier that ensures consistent variant assignment through the consistent hashing algorithm. This identifier must remain constant across user sessions and devices to prevent users from receiving different variants as they interact with the system.\n\nUser attributes provide the **flight characteristics and metadata** needed for sophisticated targeting scenarios. These attributes can represent user demographics, subscription details, behavioral data, device information, or any other criteria relevant for feature targeting decisions.\n\n| Attribute Category | Example Attributes | Typical Use Cases |\n|---|---|---|---|\n| Demographics | age, country, language, timezone | Geographic rollouts, localization features |\n| Subscription | plan, trial_end_date, payment_method | Premium feature access, billing experiments |\n| Behavioral | login_count, last_active, feature_usage | Engagement experiments, onboarding flows |\n| Technical | device_type, browser, app_version | Platform-specific features, compatibility testing |\n| Business | company_size, industry, account_tier | B2B feature targeting, enterprise experiments |\n\nUser segments represent **pre-computed group memberships** that enable efficient targeting of user cohorts without evaluating complex membership criteria on every flag request. Think of segments as **flight categories** (commercial, cargo, emergency) that group aircraft with similar handling requirements.\n\nSegments provide significant performance advantages over dynamic attribute-based targeting because segment membership is computed asynchronously and cached in the user context. This approach trades some real-time accuracy for substantial evaluation speed improvements, particularly important for high-traffic applications.\n\n| Segment Type | Computation Strategy | Update Frequency | Example Segments |\n|---|---|---|---|\n| Static Segments | Manual user assignment | On-demand updates | beta_users, internal_team, vip_customers |\n| Dynamic Segments | Batch computation from user attributes | Daily or hourly refresh | high_engagement, trial_expiring, mobile_users |\n| Real-time Segments | Streaming computation from user events | Continuous updates | recently_active, shopping_cart_abandoned |\n\nThe `UserContext` also captures request-specific information that affects flag evaluation but doesn't represent persistent user characteristics. This request context enables targeting based on current conditions rather than historical user properties.\n\nRequest context attributes include information like client IP address for geographic targeting, user agent for device detection, request timestamp for time-based experiments, and feature flags for cross-flag dependencies. These attributes have shorter lifespans than user attributes but play crucial roles in sophisticated targeting scenarios.\n\n> **Key Design Insight**: The distinction between user attributes and request context is critical for **caching strategy**. User attributes can be cached longer because they change infrequently, while request context must be computed fresh for each evaluation because it represents current conditions.\n\n**Context Integration Patterns:**\n\nThe user context integrates with the broader system through several key patterns that affect both performance and functionality. Understanding these patterns helps avoid common implementation mistakes and architectural issues.\n\n**Context Enrichment** involves augmenting basic user identification with additional attributes from user databases, analytics systems, or third-party services. This enrichment can happen synchronously during flag evaluation (trading latency for freshness) or asynchronously through background processes (trading freshness for performance).\n\n**Context Caching** stores enriched user contexts to avoid repeated database lookups during flag evaluation. Effective caching strategies must balance memory usage, cache hit rates, and data freshness while handling cache invalidation when user attributes change.\n\n**Context Versioning** addresses the challenge of evolving user schemas without breaking existing flag configurations. As applications add new user attributes or modify existing ones, the flag system must gracefully handle missing attributes and type mismatches in targeting rules.\n\n**Common Context Modeling Pitfalls:**\n\n⚠️ **Pitfall: Missing User ID Fallback Strategy**\nSystems that require stable user IDs for consistent hashing break when evaluating flags for anonymous users or during authentication failures. Always provide anonymous ID generation and graceful degradation when stable identifiers are unavailable.\n\n⚠️ **Pitfall: Context Attribute Type Confusion**\nStoring numeric values as strings breaks greater-than/less-than operators in targeting rules, while storing strings as numbers breaks substring matching. Implement consistent type inference and validation to prevent rule evaluation errors.\n\n⚠️ **Pitfall: Overly Large Context Objects**\nIncluding too many attributes or large nested objects in user context increases serialization overhead and network latency. Focus on attributes actually used in targeting rules and consider separate attribute fetching for rarely-used properties.\n\n⚠️ **Pitfall: Stale Segment Memberships**\nPre-computed segments that update infrequently can cause users to receive inappropriate variants when their characteristics change. Balance segment freshness requirements with computation overhead, and provide manual refresh capabilities for critical segments.\n\n### Implementation Guidance\n\nThe data model implementation requires careful attention to serialization, validation, and performance characteristics. The following guidance helps translate the conceptual data structures into efficient, maintainable code.\n\n**A. Technology Recommendations:**\n\n| Component | Simple Option | Advanced Option |\n|---|---|---|\n| Data Storage | SQLite with JSON columns | PostgreSQL with JSONB indexing |\n| Serialization | encoding/json with struct tags | Protocol Buffers with code generation |\n| Validation | Manual field checking | JSON Schema validation library |\n| Type Safety | interface{} with runtime checks | Generic types with constraints |\n\n**B. Recommended File Structure:**\n\n```\ninternal/\n  model/\n    flag.go              ← FlagDefinition and related structures\n    context.go           ← UserContext and attribute handling\n    evaluation.go        ← EvaluationResult and response types\n    experiment.go        ← Experiment and analytics structures\n    validation.go        ← Data validation and constraint checking\n    serialization.go     ← JSON marshaling and unmarshaling helpers\n  storage/\n    flag_store.go        ← Flag persistence interface and implementations\n    segment_store.go     ← User segment storage and retrieval\n```\n\n**C. Infrastructure Starter Code:**\n\nComplete validation framework for ensuring data integrity across all model structures:\n\n```go\npackage model\n\nimport (\n    \"fmt\"\n    \"strings\"\n    \"time\"\n)\n\n// ValidationError represents a data model validation failure\ntype ValidationError struct {\n    Field   string\n    Value   interface{}\n    Message string\n}\n\nfunc (e ValidationError) Error() string {\n    return fmt.Sprintf(\"validation failed for field %s: %s\", e.Field, e.Message)\n}\n\n// ValidationErrors aggregates multiple validation failures\ntype ValidationErrors []ValidationError\n\nfunc (e ValidationErrors) Error() string {\n    if len(e) == 0 {\n        return \"no validation errors\"\n    }\n    var messages []string\n    for _, err := range e {\n        messages = append(messages, err.Error())\n    }\n    return strings.Join(messages, \"; \")\n}\n\nfunc (e ValidationErrors) HasErrors() bool {\n    return len(e) > 0\n}\n\n// ValidateFlag performs comprehensive validation of flag definitions\nfunc ValidateFlag(flag *FlagDefinition) error {\n    var errors ValidationErrors\n    \n    // TODO: Implement validation logic\n    return nil\n}\n\n// ValidateUserContext ensures context structure meets requirements\nfunc ValidateUserContext(ctx *UserContext) error {\n    var errors ValidationErrors\n    \n    // TODO: Implement context validation\n    return nil\n}\n```\n\nComplete serialization helpers that handle type conversion and JSON marshaling:\n\n```go\npackage model\n\nimport (\n    \"encoding/json\"\n    \"reflect\"\n    \"strconv\"\n)\n\n// AttributeValue provides type-safe access to user context attributes\ntype AttributeValue struct {\n    raw interface{}\n}\n\nfunc NewAttributeValue(value interface{}) AttributeValue {\n    return AttributeValue{raw: value}\n}\n\nfunc (av AttributeValue) String() (string, bool) {\n    // TODO: Implement string conversion with type checking\n    return \"\", false\n}\n\nfunc (av AttributeValue) Int() (int64, bool) {\n    // TODO: Implement integer conversion with type checking\n    return 0, false\n}\n\nfunc (av AttributeValue) Float() (float64, bool) {\n    // TODO: Implement float conversion with type checking\n    return 0, false\n}\n\nfunc (av AttributeValue) Bool() (bool, bool) {\n    // TODO: Implement boolean conversion with type checking\n    return false, false\n}\n\nfunc (av AttributeValue) StringSlice() ([]string, bool) {\n    // TODO: Implement string slice conversion for \"in\" operator\n    return nil, false\n}\n```\n\n**D. Core Logic Skeleton Code:**\n\n```go\npackage model\n\n// ValidateFlag ensures flag definition meets all requirements\nfunc ValidateFlag(flag *FlagDefinition) error {\n    var errors ValidationErrors\n    \n    // TODO 1: Validate flag key is non-empty and follows naming conventions\n    // TODO 2: Ensure at least one variant is defined and default variant exists\n    // TODO 3: Validate all targeting rule conditions reference valid operators\n    // TODO 4: Check percentage allocations sum to 100% in each rule\n    // TODO 5: Detect circular dependencies in prerequisites\n    // TODO 6: Verify variant weights are positive integers\n    // TODO 7: Validate attribute names in conditions don't contain reserved characters\n    \n    if errors.HasErrors() {\n        return errors\n    }\n    return nil\n}\n\n// ValidateUserContext checks context structure and attribute types\nfunc ValidateUserContext(ctx *UserContext) error {\n    var errors ValidationErrors\n    \n    // TODO 1: Ensure either UserID or AnonymousID is present\n    // TODO 2: Validate attribute values are JSON-serializable types\n    // TODO 3: Check segment names follow naming conventions\n    // TODO 4: Verify request context doesn't contain oversized values\n    // TODO 5: Validate session ID format if present\n    \n    if errors.HasErrors() {\n        return errors\n    }\n    return nil\n}\n\n// DetectCircularDependencies finds cycles in flag prerequisite relationships\nfunc DetectCircularDependencies(flags map[FlagKey]*FlagDefinition) error {\n    // TODO 1: Build adjacency list representation of prerequisite graph\n    // TODO 2: Perform depth-first search from each flag node\n    // TODO 3: Track visited and recursion stack to detect back edges\n    // TODO 4: Return specific error identifying circular dependency path\n    // Hint: Use topological sorting or DFS with color marking\n    return nil\n}\n```\n\n**E. Language-Specific Hints:**\n\n- Use `json:\"-\"` struct tags to exclude sensitive fields from JSON serialization\n- Implement `json.Marshaler` and `json.Unmarshaler` interfaces for custom serialization logic\n- Use `reflect.TypeOf()` carefully for type checking - prefer type assertions when possible\n- Store percentage ranges as `[start, end)` intervals where start is inclusive and end is exclusive\n- Use `sync.RWMutex` for concurrent access to flag definitions if caching in memory\n- Consider `time.Time.UTC()` for consistent timezone handling in timestamps\n\n**F. Milestone Checkpoint:**\n\nAfter implementing the data model structures:\n\n1. **Validation Test**: Run `go test ./internal/model/...` - all validation functions should correctly reject invalid flags and accept valid configurations\n2. **Serialization Test**: Create a complex flag definition, marshal to JSON, unmarshal back, and verify all fields are preserved correctly\n3. **Type Conversion Test**: Create user context with mixed attribute types, verify AttributeValue conversions work for all supported operators\n4. **Dependency Detection**: Create flags with circular prerequisites, verify the detection algorithm identifies the cycle and provides helpful error messages\n\nExpected behavior after completion:\n- Flag definitions serialize to clean JSON suitable for storage and API responses\n- User contexts handle missing attributes gracefully during rule evaluation\n- Validation catches common configuration errors before flags are stored\n- Type conversion supports all comparison operators used in targeting rules\n\nSigns something is wrong:\n- Serialized flags lose information during round-trip JSON conversion\n- Validation allows invalid configurations that break evaluation engine\n- Type conversion produces inconsistent results for the same input values\n- Circular dependency detection has false positives or misses actual cycles\n\n\n## Flag Evaluation Engine\n\n> **Milestone(s):** This section covers Milestone 1 (Flag Evaluation Engine) by implementing the core flag evaluation logic with consistent user assignment, complex rule processing, and proper fallback handling.\n\nThe flag evaluation engine serves as the heart of the feature flag system, responsible for taking a user context and flag configuration and determining which variant that user should receive. Think of the evaluation engine as a **sophisticated restaurant host** - when a customer (user) arrives, the host considers their reservation details, party size, dietary restrictions, and membership status (user context) against the restaurant's current seating rules, special promotions, and capacity constraints (flag rules) to determine the best table assignment (variant) while ensuring repeat customers get consistent treatment.\n\nThe evaluation engine must balance several competing requirements: it needs to be extremely fast since it's called on every feature check, deterministic so users get consistent experiences, flexible enough to support complex targeting rules, and resilient enough to gracefully handle edge cases and partial failures. The architecture prioritizes **evaluation-first design**, meaning every component decision is optimized for the critical path of flag evaluation performance.\n\n![Flag Evaluation Sequence](./diagrams/evaluation-flow.svg)\n\nThe evaluation process follows a structured decision tree that processes rules in order of precedence, applies consistent hashing for percentage-based rollouts, and provides detailed reasoning for audit and debugging purposes. This deterministic approach ensures that the same user context always produces the same result, which is critical for maintaining consistent user experiences across multiple application instances.\n\n### Consistent User Assignment\n\nConsistent user assignment is the foundation that ensures users receive the same variant across multiple evaluations, even as flag configurations change or the system scales horizontally. Without consistency, users would experience jarring feature flip-flopping as they navigate through an application - imagine if a user's shopping cart suddenly changed its interface mid-checkout because they triggered a different variant.\n\nThe system achieves consistency through **consistent hashing**, which maps each user to a deterministic position in a virtual \"allocation space\" that remains stable regardless of when or where the evaluation occurs. Think of this allocation space as a circular dartboard numbered 0 to 99, where each user's `UserID` and `FlagKey` combination determines exactly where their dart lands, and the variant allocations define which sections of the dartboard correspond to which variants.\n\n| Hash Function Component | Purpose | Example Value |\n|------------------------|---------|---------------|\n| UserID | Stable user identifier ensuring same user gets same position | \"user_12345\" |\n| FlagKey | Flag-specific salt preventing correlation across flags | \"checkout_redesign\" |\n| Combined Input | Hash input ensuring flag-specific consistency | \"user_12345:checkout_redesign\" |\n| Hash Algorithm | CRC32 or SHA256 providing uniform distribution | CRC32 |\n| Bucket Number | Final position in 0-99 allocation space | 67 |\n\nThe `calculateUserBucket` function transforms a user's identity into a bucket number between 0 and 99, providing 1% granularity for percentage rollouts. This granularity strikes the optimal balance between precision and performance - finer granularity would provide minimal benefit while consuming more computation and memory.\n\n> **Design Insight:** Using both `UserID` and `FlagKey` in the hash input is crucial because it prevents users from being consistently assigned to the same relative position across all flags. Without the flag-specific salt, a user who falls into the \"early adopter\" bucket for one flag would fall into early adopter buckets for all flags, creating unwanted correlation effects.\n\n**Bucket Range Allocation** determines which bucket ranges correspond to each variant based on the configured weights. For a flag with variants A (weight: 30), B (weight: 20), and C (weight: 50), the system assigns buckets 0-29 to variant A, buckets 30-49 to variant B, and buckets 50-99 to variant C. This approach ensures that percentage changes affect users at the margins rather than causing random reassignments.\n\n| Variant | Weight | Bucket Range | Users Affected by 10% Increase |\n|---------|---------|--------------|-------------------------------|\n| Control | 50% | 0-49 | New users in buckets 50-59 |\n| Treatment | 40% | 50-89 | New users in buckets 90-99 |\n| Holdout | 10% | 90-99 | Users in buckets 90-99 reassigned |\n\nThe allocation algorithm processes variant weights in declaration order, ensuring deterministic bucket assignments even when weights don't sum to exactly 100%. If weights sum to less than 100%, the remaining users receive the flag's default value. If weights exceed 100%, the system normalizes proportionally and logs a warning for operational visibility.\n\n> **Critical Stability Property:** Once a user receives a variant assignment, they must continue receiving that assignment until explicitly moved through configuration changes. The consistent hashing approach guarantees this stability by ensuring the hash function remains deterministic across evaluations, even as the application restarts or scales.\n\nThe system handles several edge cases to maintain assignment stability:\n\n1. **Zero-weight variants** remain in the configuration but receive no bucket allocation, allowing for quick re-enablement without reassignment\n2. **Weight normalization** proportionally adjusts weights that exceed 100% while preserving relative ratios\n3. **Default fallback** handles users whose buckets fall outside allocated ranges due to configuration errors\n\n### Rule Evaluation Logic\n\nThe rule evaluation logic implements a sophisticated decision tree that processes targeting rules in strict precedence order, ensuring deterministic outcomes when multiple rules could potentially match a user. Think of rule evaluation as a **courthouse with multiple judges** - cases (user evaluations) are presented to judges (targeting rules) in order of seniority, and the first judge who claims jurisdiction (matching conditions) renders the final verdict (variant assignment).\n\n![Rule Evaluation Algorithm](./diagrams/evaluation-algorithm.svg)\n\nThe evaluation algorithm follows a waterfall approach with four distinct phases, each with specific responsibilities and fallback behavior:\n\n| Evaluation Phase | Purpose | Input Requirements | Success Criteria |\n|------------------|---------|-------------------|------------------|\n| Targeting Rules | User-specific overrides | UserContext with attributes | All rule conditions evaluate to true |\n| Percentage Rules | Gradual rollout control | UserID for consistent hashing | User bucket falls within variant range |\n| Default Value | Configuration fallback | Flag definition | Default value exists |\n| System Fallback | Emergency degradation | None | Always succeeds with false/null |\n\n**Targeting Rule Processing** begins with the highest-priority rule and evaluates each rule's conditions against the provided user context. Each `TargetingRule` contains a collection of `Condition` objects combined with either `AND` or `OR` logic, allowing for sophisticated user segmentation based on multiple attributes.\n\nThe `evaluateRuleConditions` function processes each condition within a rule, applying the specified logical operator to determine overall rule satisfaction. For `AND` operations, all conditions must evaluate to true; for `OR` operations, any single condition can satisfy the rule. This flexibility enables complex targeting scenarios like \"show premium features to users in the US OR Canada AND with subscription tier gold OR platinum\".\n\n| Condition Operator | Purpose | Example Usage | Type Requirements |\n|-------------------|---------|---------------|-------------------|\n| equals | Exact match comparison | country equals \"US\" | String, number, boolean |\n| in | Array membership testing | user_id in [\"admin1\", \"admin2\"] | Any type with array |\n| contains | Substring matching | email contains \"@company.com\" | String values only |\n| greater_than | Numeric comparison | account_age greater_than 30 | Numeric values only |\n| less_than | Numeric comparison | session_count less_than 5 | Numeric values only |\n\nThe `AttributeValue` wrapper provides type-safe access to user context attributes while handling the common problem of dynamic typing in user data. Each attribute access method returns both the converted value and a boolean indicating whether the conversion succeeded, allowing the evaluation logic to gracefully handle type mismatches without panicking.\n\n**Rule Precedence and Ordering** ensures deterministic evaluation when multiple rules could match the same user. Rules are processed in declaration order within the flag definition, with the first matching rule taking precedence. This approach provides predictable behavior and allows flag administrators to structure rules from specific to general, similar to firewall rule processing.\n\n```\nRule Evaluation Example:\n1. IF user_id in [\"beta_user_1\", \"beta_user_2\"] THEN variant=\"beta\"\n2. IF country equals \"US\" AND subscription=\"premium\" THEN variant=\"premium_us\" \n3. IF country equals \"US\" THEN variant=\"standard_us\"\n4. PERCENTAGE ROLLOUT: 20% get variant=\"treatment\", 80% get variant=\"control\"\n```\n\nIn this example, beta users always receive the beta variant regardless of location or subscription status, premium US users receive premium_us unless they're beta users, and other US users receive standard_us. Only users who don't match any targeting rule enter the percentage rollout phase.\n\n**Percentage Rule Evaluation** activates when no targeting rules match the user context. The system calculates the user's bucket using consistent hashing and determines which variant allocation range contains that bucket. This phase implements gradual rollouts and A/B testing by assigning users to variants based on stable, pseudorandom distribution.\n\nThe `PercentageRule` defines variant allocations as a list of `VariantAllocation` objects, each specifying a variant key and weight. The evaluation engine converts weights into cumulative bucket ranges, ensuring efficient lookup during evaluation.\n\n| Variant Allocation | Weight | Cumulative Weight | Bucket Range |\n|-------------------|---------|-------------------|---------------|\n| control | 60 | 60 | 0-59 |\n| treatment_a | 25 | 85 | 60-84 |\n| treatment_b | 15 | 100 | 85-99 |\n\n**Default Value Fallback** provides the safety net when both targeting rules and percentage rules fail to assign a variant. This situation occurs when targeting rules don't match and percentage rules have zero total weight or the user's bucket falls outside allocated ranges due to configuration errors.\n\nThe `EvaluationResult` includes a detailed `Reason` field that traces the evaluation path, enabling debugging and audit capabilities. Reason codes follow a structured format that indicates which evaluation phase produced the result and why.\n\n| Reason Code | Evaluation Path | Example Scenario |\n|-------------|----------------|------------------|\n| targeting_rule_match | Targeting rule satisfied | \"targeting_rule_match:rule_2\" |\n| percentage_rollout | Percentage allocation | \"percentage_rollout:treatment_20pct\" |\n| default_value | Fallback to default | \"default_value:no_rules_matched\" |\n| flag_not_found | Missing flag definition | \"flag_not_found:invalid_key\" |\n| evaluation_error | Processing failure | \"evaluation_error:invalid_context\" |\n\n### Architecture Decision Records\n\nThe flag evaluation engine embodies several critical architectural decisions that fundamentally shape system behavior, performance, and maintainability. Each decision represents a careful trade-off between competing requirements and establishes constraints that influence the entire system design.\n\n> **Decision: Consistent Hashing Algorithm Selection**\n> - **Context**: Users must receive consistent variant assignments across evaluations, but the hashing algorithm must balance performance, distribution quality, and collision resistance for production workloads.\n> - **Options Considered**: CRC32 for speed, SHA256 for cryptographic strength, MD5 for legacy compatibility\n> - **Decision**: CRC32 as the primary algorithm with SHA256 as a configurable alternative\n> - **Rationale**: CRC32 provides excellent distribution uniformity and high performance for non-adversarial inputs, while SHA256 offers cryptographic strength for compliance-sensitive environments at the cost of 3-4x slower computation\n> - **Consequences**: Enables sub-microsecond evaluation performance while maintaining uniform user distribution, but requires SHA256 fallback for environments with strict cryptographic requirements\n\n| Hash Algorithm | Performance | Distribution Quality | Collision Resistance | Chosen |\n|---------------|-------------|---------------------|---------------------|---------|\n| CRC32 | Excellent (ns) | Uniform for random inputs | Weak against adversaries | Primary |\n| SHA256 | Good (μs) | Cryptographically uniform | Strong against adversaries | Optional |\n| MD5 | Very Good (ns) | Good but deprecated | Weak against adversaries | No |\n\n> **Decision: Rule Evaluation Precedence Strategy**\n> - **Context**: Multiple targeting rules may match the same user, requiring a deterministic resolution strategy that balances flexibility with predictability.\n> - **Options Considered**: Priority scoring system, first-match-wins ordering, most-specific-rule-wins analysis\n> - **Decision**: First-match-wins with declaration order precedence\n> - **Rationale**: Declaration order provides intuitive, predictable behavior that mirrors firewall rules and allows administrators to structure rules from specific to general without complex priority calculations\n> - **Consequences**: Simplifies rule authoring and debugging at the cost of requiring careful rule ordering, with no automatic optimization of rule evaluation sequence\n\n| Precedence Strategy | Complexity | Predictability | Performance | Chosen |\n|-------------------|------------|----------------|-------------|---------|\n| Declaration Order | Low | High | Excellent | Yes |\n| Priority Scoring | Medium | Medium | Good | No |\n| Most Specific | High | Low | Poor | No |\n\n> **Decision: User Context Attribute Type System**\n> - **Context**: User attributes arrive as untyped JSON values but must support type-safe comparison operations across different programming languages and data sources.\n> - **Options Considered**: Dynamic typing with runtime coercion, strict typing with validation, hybrid approach with type-safe wrappers\n> - **Decision**: Hybrid approach using `AttributeValue` wrapper with explicit type conversion methods\n> - **Rationale**: Provides type safety during evaluation while accepting flexible input formats, preventing runtime panics from type mismatches and enabling graceful degradation when attributes don't match expected types\n> - **Consequences**: Adds wrapper overhead and API complexity but eliminates a major class of runtime evaluation failures and provides clear error reporting for type mismatches\n\n| Type System | Safety | Flexibility | Performance | Chosen |\n|-------------|--------|-------------|-------------|---------|\n| Dynamic | Low | High | Excellent | No |\n| Strict | High | Low | Good | No |\n| Hybrid Wrapper | High | Medium | Good | Yes |\n\n> **Decision: Evaluation Result Caching Strategy**\n> - **Context**: Flag evaluations may be called hundreds of times per request, but user context and flag definitions change infrequently, creating opportunities for performance optimization through caching.\n> - **Options Considered**: No caching for simplicity, request-scoped caching, time-based TTL caching\n> - **Decision**: Optional request-scoped caching with explicit cache invalidation\n> - **Rationale**: Request-scoped caching eliminates redundant evaluations within a single request while avoiding stale data issues across requests, providing significant performance benefits for evaluation-heavy code paths\n> - **Consequences**: Enables 10-100x performance improvement for repeated evaluations but requires careful integration with request lifecycle management and adds complexity to multi-threaded environments\n\n| Caching Strategy | Performance Gain | Consistency Risk | Implementation Complexity | Chosen |\n|-----------------|------------------|------------------|---------------------------|---------|\n| No Caching | None | None | Minimal | No |\n| Request-Scoped | High (10-100x) | Low | Medium | Yes |\n| TTL-Based | Very High | High | High | No |\n\n**Common Pitfalls in Evaluation Engine Implementation**\n\n⚠️ **Pitfall: Inconsistent Hash Input Formatting**\nThe most subtle and dangerous mistake involves inconsistent string formatting when constructing hash inputs. Using `fmt.Sprintf(\"%s:%s\", userID, flagKey)` versus `userID + \":\" + flagKey` can produce different results if format specifiers behave unexpectedly with special characters. Always use explicit string concatenation or a standardized formatting function with thorough unit tests covering edge cases like empty strings, unicode characters, and values containing the separator character.\n\n⚠️ **Pitfall: Floating Point Percentage Calculations**\nUsing floating-point arithmetic for percentage calculations introduces rounding errors that can cause users to \"fall through the cracks\" or be double-assigned. For example, three variants with 33.33% each don't sum to exactly 100%, leaving some bucket ranges unassigned. Always use integer arithmetic with bucket ranges (0-99 for 1% granularity) and handle remainder allocation explicitly rather than relying on floating-point precision.\n\n⚠️ **Pitfall: Rule Condition Short-Circuiting Bugs**\nWhen implementing `AND` and `OR` logic for rule conditions, developers often implement short-circuiting incorrectly, causing later conditions to be skipped even when they have side effects like logging or metrics collection. Ensure that all conditions are evaluated for observability purposes, or clearly document when short-circuiting behavior is intentional versus when complete evaluation is required.\n\n⚠️ **Pitfall: Missing User Context Validation**\nFailing to validate user context structure before evaluation can cause panic conditions when accessing nested attributes or applying type conversions. The evaluation engine must gracefully handle missing attributes, null values, and type mismatches by returning sensible defaults rather than failing the entire evaluation. Implement comprehensive input validation with detailed error logging for debugging purposes.\n\n⚠️ **Pitfall: Circular Dependency Detection**\nWhen flags support prerequisites (flag A depends on flag B being enabled), developers often forget to detect circular dependencies during flag creation or updates. A circular dependency can cause infinite recursion during evaluation, crashing the service. Implement dependency graph validation using depth-first search cycle detection before allowing flag modifications to be persisted.\n\n### Implementation Guidance\n\nThe flag evaluation engine requires careful attention to performance and correctness, as it sits in the critical path of every feature flag check. The implementation balances sophisticated rule processing capabilities with sub-millisecond evaluation performance.\n\n**Technology Recommendations:**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Hash Function | crypto/sha256 (built-in) | github.com/spaolacci/murmur3 (faster) |\n| JSON Parsing | encoding/json (built-in) | github.com/json-iterator/go (faster) |\n| Validation | Manual checks | github.com/go-playground/validator |\n| Logging | log package (built-in) | github.com/sirupsen/logrus (structured) |\n| Testing | testing package (built-in) | github.com/stretchr/testify (assertions) |\n\n**Recommended File Structure:**\n```\ninternal/evaluation/\n  engine.go                 ← Main evaluation logic and EvaluateFlag function\n  engine_test.go           ← Comprehensive evaluation test cases  \n  hashing.go              ← Consistent hashing implementation\n  hashing_test.go         ← Hash distribution and stability tests\n  rules.go                ← Rule and condition evaluation logic\n  rules_test.go           ← Rule precedence and condition tests\n  types.go                ← Core data structures and validation\n  validation.go           ← Input validation and error handling\n  validation_test.go      ← Validation edge case tests\n```\n\n**Core Data Structures (Complete Implementation):**\n```go\npackage evaluation\n\nimport (\n    \"crypto/sha256\"\n    \"encoding/json\"\n    \"fmt\"\n    \"hash/crc32\"\n    \"strconv\"\n    \"strings\"\n)\n\n// Core evaluation types with complete field definitions\ntype FlagKey string\ntype UserID string\n\n// Variant represents a single flag variation with its configuration\ntype Variant struct {\n    Key    string      `json:\"key\"`    // Unique variant identifier\n    Value  interface{} `json:\"value\"`  // The actual value returned to client\n    Weight int         `json:\"weight\"` // Allocation weight for percentage rollouts\n}\n\n// UserContext provides all user information needed for targeting decisions\ntype UserContext struct {\n    UserID     UserID                 `json:\"user_id\"`\n    Attributes map[string]interface{} `json:\"attributes\"`\n    Segments   []string              `json:\"segments\"`\n}\n\n// EvaluationResult contains the complete output of flag evaluation\ntype EvaluationResult struct {\n    FlagKey FlagKey     `json:\"flag_key\"` // Which flag was evaluated\n    Value   interface{} `json:\"value\"`    // The resolved variant value\n    Variant string      `json:\"variant\"`  // The variant key that was selected\n    Reason  string      `json:\"reason\"`   // Why this variant was chosen\n    Source  string      `json:\"source\"`   // Where the flag definition came from\n}\n\n// Complete flag configuration structure\ntype FlagDefinition struct {\n    Key             FlagKey          `json:\"key\"`\n    Enabled         bool             `json:\"enabled\"`\n    DefaultVariant  string           `json:\"default_variant\"`\n    Variants        []Variant        `json:\"variants\"`\n    TargetingRules  []TargetingRule  `json:\"targeting_rules\"`\n    PercentageRules PercentageRule   `json:\"percentage_rules\"`\n    Prerequisites   []string         `json:\"prerequisites\"`\n}\n\n// Rule structures for complex targeting\ntype TargetingRule struct {\n    Conditions []Condition `json:\"conditions\"`\n    Operator   string      `json:\"operator\"` // \"AND\" or \"OR\"\n    Variant    string      `json:\"variant\"`\n    Enabled    bool        `json:\"enabled\"`\n}\n\ntype Condition struct {\n    Attribute string      `json:\"attribute\"`\n    Operator  string      `json:\"operator\"`  \n    Value     interface{} `json:\"value\"`\n}\n\ntype PercentageRule struct {\n    Variants []VariantAllocation `json:\"variants\"`\n}\n\ntype VariantAllocation struct {\n    Variant string `json:\"variant\"`\n    Weight  int    `json:\"weight\"`\n}\n\n// Type-safe attribute access wrapper\ntype AttributeValue struct {\n    value interface{}\n}\n\nfunc NewAttributeValue(value interface{}) AttributeValue {\n    return AttributeValue{value: value}\n}\n\nfunc (av AttributeValue) String() (string, bool) {\n    if str, ok := av.value.(string); ok {\n        return str, true\n    }\n    return \"\", false\n}\n\nfunc (av AttributeValue) Int() (int64, bool) {\n    switch v := av.value.(type) {\n    case int64:\n        return v, true\n    case float64:\n        return int64(v), true\n    case string:\n        if i, err := strconv.ParseInt(v, 10, 64); err == nil {\n            return i, true\n        }\n    }\n    return 0, false\n}\n\nfunc (av AttributeValue) Float() (float64, bool) {\n    switch v := av.value.(type) {\n    case float64:\n        return v, true\n    case int64:\n        return float64(v), true\n    case string:\n        if f, err := strconv.ParseFloat(v, 64); err == nil {\n            return f, true\n        }\n    }\n    return 0, false\n}\n\nfunc (av AttributeValue) Bool() (bool, bool) {\n    if b, ok := av.value.(bool); ok {\n        return b, true\n    }\n    return false, false\n}\n\nfunc (av AttributeValue) StringSlice() ([]string, bool) {\n    if slice, ok := av.value.([]interface{}); ok {\n        result := make([]string, len(slice))\n        for i, item := range slice {\n            if str, ok := item.(string); ok {\n                result[i] = str\n            } else {\n                return nil, false\n            }\n        }\n        return result, true\n    }\n    return nil, false\n}\n\n// Validation and error types\ntype ValidationError struct {\n    Field   string `json:\"field\"`\n    Message string `json:\"message\"`\n}\n\nfunc (ve ValidationError) Error() string {\n    return fmt.Sprintf(\"%s: %s\", ve.Field, ve.Message)\n}\n\ntype ValidationErrors []ValidationError\n\nfunc (ve ValidationErrors) Error() string {\n    var messages []string\n    for _, err := range ve {\n        messages = append(messages, err.Error())\n    }\n    return strings.Join(messages, \"; \")\n}\n\n// Constants for operators and values\nconst (\n    // Logical operators\n    AND = \"AND\"\n    OR  = \"OR\"\n    \n    // Condition operators  \n    equals       = \"equals\"\n    in          = \"in\"\n    contains    = \"contains\"\n    greater_than = \"greater_than\"  \n    less_than   = \"less_than\"\n)\n```\n\n**Consistent Hashing Implementation (Complete):**\n```go\n// calculateUserBucket determines user's allocation bucket using consistent hashing\nfunc calculateUserBucket(userID UserID, flagKey FlagKey) int {\n    // TODO 1: Create hash input by combining userID and flagKey with separator\n    // TODO 2: Compute hash using CRC32 or SHA256 based on configuration  \n    // TODO 3: Convert hash to bucket number in range [0, 99]\n    // TODO 4: Return bucket ensuring same input always produces same bucket\n    \n    // Hint: Use fmt.Sprintf(\"%s:%s\", userID, flagKey) for consistent input format\n    // Hint: Use hash % 100 to get bucket, but handle negative values correctly\n}\n\n// Helper function for creating deterministic hash inputs\nfunc createHashInput(userID UserID, flagKey FlagKey) string {\n    return fmt.Sprintf(\"%s:%s\", string(userID), string(flagKey))\n}\n\n// Hash function that provides uniform distribution\nfunc hashToBucket(input string) int {\n    hasher := crc32.NewIEEE()\n    hasher.Write([]byte(input))\n    hashValue := hasher.Sum32()\n    return int(hashValue % 100)\n}\n```\n\n**Core Evaluation Engine Skeleton:**\n```go\n// EvaluateFlag performs complete flag evaluation with targeting and fallback\nfunc EvaluateFlag(flagKey FlagKey, context UserContext) EvaluationResult {\n    // TODO 1: Validate input parameters (flagKey not empty, context has UserID)\n    // TODO 2: Retrieve flag definition, return error result if not found\n    // TODO 3: Check if flag is enabled, return default if disabled\n    // TODO 4: Process targeting rules in order, return first match\n    // TODO 5: If no targeting rules match, evaluate percentage rules\n    // TODO 6: If no percentage allocation, return default variant\n    // TODO 7: Construct EvaluationResult with value, variant, and reason\n    // \n    // Hint: Use early returns for error cases to avoid deep nesting\n    // Hint: Always populate the Reason field for debugging\n}\n\n// evaluateTargetingRules processes user-specific override rules\nfunc evaluateTargetingRules(rules []TargetingRule, context UserContext) (string, interface{}, string, bool) {\n    // TODO 1: Iterate through rules in declaration order\n    // TODO 2: Skip disabled rules  \n    // TODO 3: Evaluate rule conditions using specified operator (AND/OR)\n    // TODO 4: Return variant info for first matching rule\n    // TODO 5: Return false if no rules match\n    //\n    // Hint: Call evaluateRuleConditions for each rule\n    // Hint: Short-circuit AND on first false, OR on first true\n}\n\n// evaluateRuleConditions checks if user context satisfies rule conditions  \nfunc evaluateRuleConditions(conditions []Condition, operator string, context UserContext) bool {\n    // TODO 1: Handle empty conditions list (should return true)\n    // TODO 2: For AND operator, all conditions must be true\n    // TODO 3: For OR operator, any condition can be true  \n    // TODO 4: Evaluate each condition using evaluateCondition helper\n    // TODO 5: Apply short-circuiting logic for performance\n    //\n    // Hint: Use a loop with early return for short-circuiting\n    // Hint: Default to false for unknown operators\n}\n\n// evaluateCondition checks single attribute condition\nfunc evaluateCondition(condition Condition, context UserContext) bool {\n    // TODO 1: Extract attribute value from context\n    // TODO 2: Handle missing attributes gracefully (return false)\n    // TODO 3: Apply condition operator (equals, in, contains, etc.)\n    // TODO 4: Use AttributeValue wrapper for type-safe comparisons\n    // TODO 5: Return comparison result\n    //\n    // Hint: Use NewAttributeValue(context.Attributes[condition.Attribute])\n    // Hint: Each operator has different type requirements\n}\n```\n\n**Milestone Checkpoint:**\nAfter implementing the evaluation engine, you should be able to:\n\n1. **Run unit tests**: `go test ./internal/evaluation/...` should show all tests passing\n2. **Test basic evaluation**: Create a simple flag with percentage rollout, verify users get consistent assignments\n3. **Test targeting rules**: Create rules with different operators, verify correct matching behavior  \n4. **Test hash distribution**: Generate 1000 user evaluations, verify roughly even distribution across variants\n5. **Test edge cases**: Verify graceful handling of missing flags, invalid context, malformed rules\n\n**Expected behavior:**\n- Same user + flag always returns same variant (consistency test)\n- Rule precedence works correctly (first matching rule wins)\n- Percentage rollouts distribute users evenly across variants  \n- Missing attributes cause conditions to fail gracefully\n- Detailed reason codes explain evaluation decisions\n\n**Common debugging steps:**\n- Check hash input format if users get inconsistent assignments\n- Verify rule order if wrong targeting rules match\n- Examine bucket calculations if percentage distributions look wrong\n- Review attribute types if conditions evaluate unexpectedly\n\n\n## Real-time Flag Updates\n\n> **Milestone(s):** This section covers Milestone 2 (Real-time Flag Updates) by implementing streaming protocols for instant flag propagation, connection management with automatic recovery, and intelligent caching strategies to ensure consistent flag state across all client SDKs.\n\nReal-time flag updates transform a feature flag system from a static configuration tool into a dynamic control plane for live applications. Think of this system as a **broadcast network for air traffic control** — when weather conditions change or new safety protocols are established, every pilot needs to receive these updates instantly and reliably. Similarly, when a feature flag is modified to disable a problematic feature or adjust a rollout percentage, all connected applications must receive this change within seconds to maintain consistent user experiences and operational safety.\n\nThe challenge lies in maintaining reliable, low-latency communication with potentially thousands of client SDKs while handling network interruptions, connection failures, and varying client capabilities. Unlike traditional request-response APIs, real-time updates require persistent connections, careful state management, and sophisticated fallback strategies to ensure flags remain available even during infrastructure failures.\n\nThis system must balance several competing requirements: minimizing latency for critical flag changes, avoiding overwhelming the infrastructure during mass reconnections, ensuring eventual consistency across all clients, and providing graceful degradation when real-time updates are unavailable. The architecture decisions we make here directly impact both the reliability of feature rollouts and the operational overhead of maintaining the flag system.\n\n### Streaming Protocol Design\n\nModern feature flag systems require sub-second flag propagation to support rapid incident response and real-time experimentation. The choice of streaming protocol fundamentally shapes the system's scalability, reliability, and operational characteristics. This decision affects everything from server resource usage to client SDK complexity and failure recovery strategies.\n\n**Mental Model: Television Broadcasting vs. Telephone Networks**\n\nThink of streaming protocols as the difference between television broadcasting and telephone networks. Server-Sent Events (SSE) work like television broadcasts — the server transmits updates to all connected clients simultaneously through a one-way channel, with clients passively receiving updates. WebSockets function like telephone networks, establishing bidirectional communication channels where both parties can initiate conversations. For feature flags, we typically need the broadcasting model since flag changes flow primarily from server to clients, but the choice impacts connection management, resource usage, and failure scenarios.\n\n> **Decision: Server-Sent Events for Flag Updates**\n> - **Context**: Feature flag systems need efficient one-way communication from server to multiple clients with standard HTTP infrastructure compatibility and simple client implementation.\n> - **Options Considered**: Server-Sent Events (SSE), WebSockets, HTTP Long Polling\n> - **Decision**: Server-Sent Events (SSE) as the primary streaming protocol with HTTP polling fallback\n> - **Rationale**: SSE provides automatic reconnection, works through HTTP proxies and load balancers, has lower server resource overhead than WebSockets for one-way communication, and offers built-in event ordering and message replay. WebSockets add unnecessary bidirectional complexity for predominantly unidirectional flag updates.\n> - **Consequences**: Enables simple client implementation with browser compatibility, reduces server connection overhead, but limits real-time client feedback and requires polling fallback for SSE-incompatible environments.\n\nThe following table compares streaming protocol options for feature flag updates:\n\n| Protocol Option | Latency | Resource Usage | HTTP Compatibility | Complexity | Reconnection |\n|----------------|---------|----------------|-------------------|------------|--------------|\n| **Server-Sent Events** | 100-500ms | Low memory/CPU | Full proxy support | Simple client | Automatic with Last-Event-ID |\n| WebSockets | 50-100ms | Higher memory | Proxy configuration required | Complex handshake | Manual reconnection logic |\n| HTTP Long Polling | 200-1000ms | High connection overhead | Full compatibility | Simple | Built-in with timeouts |\n\nServer-Sent Events provide the optimal balance for feature flag systems. The protocol naturally handles connection drops with automatic reconnection, includes built-in event identification for message replay, and works seamlessly with existing HTTP infrastructure. The slight latency increase compared to WebSockets (typically 50-200ms) is acceptable for feature flag use cases where sub-second updates are sufficient.\n\n#### SSE Message Format Design\n\nFeature flag updates require structured messages that convey not just the flag changes but also metadata necessary for proper client state management. Each SSE message must include enough information for clients to apply updates correctly, detect message loss, and maintain consistency during reconnection scenarios.\n\nThe core message structure contains several essential components:\n\n| Message Component | Type | Purpose | Example |\n|------------------|------|---------|---------|\n| Event Type | String | Categorizes update type for client routing | `flag_updated`, `flag_created`, `flag_deleted` |\n| Event ID | String | Unique sequence identifier for replay | `seq_12345_1640995200` |\n| Timestamp | ISO 8601 | Update occurrence time for ordering | `2024-01-15T10:30:00Z` |\n| Payload | JSON Object | Flag change details and metadata | Flag definition or change summary |\n\n**Complete Flag Updates vs. Delta Updates**\n\nThe system supports two update strategies depending on the nature of changes:\n\n1. **Complete Flag Definition Updates**: When targeting rules, variants, or core flag properties change, the server sends the entire updated `FlagDefinition` to ensure clients have complete context for evaluation. This approach eliminates potential inconsistencies from partial updates but increases message size.\n\n2. **Delta Updates**: For simple changes like enabling/disabling flags or adjusting rollout percentages, the server sends only the changed fields. This reduces bandwidth usage but requires more complex client-side merging logic.\n\nThe message format accommodates both strategies through a `change_type` field that instructs clients how to process the update:\n\n| Change Type | Description | Client Action | Message Size |\n|-------------|-------------|---------------|--------------|\n| `full_update` | Complete flag definition | Replace existing flag entirely | Large (1-5KB) |\n| `delta_update` | Specific field changes | Merge changes into existing flag | Small (100-500B) |\n| `flag_deleted` | Flag removal | Remove from local cache | Minimal (50B) |\n\n#### Event Ordering and Replay\n\nSSE's built-in event identification system enables reliable message ordering and replay during reconnection. Each event receives a unique, monotonically increasing identifier that clients include in reconnection requests via the `Last-Event-ID` header. The server maintains a bounded buffer of recent events (typically 1000-5000 events covering 1-24 hours) to support client reconnection without requiring full flag synchronization.\n\nEvent identifiers follow a structured format: `seq_{sequence_number}_{timestamp}`. This format enables both chronological ordering and efficient buffer management on the server side. When clients reconnect after network interruption, they automatically provide their last received event ID, and the server replays all subsequent events to restore consistency.\n\n> **Critical Design Insight**: Event replay must be bounded to prevent memory exhaustion from maintaining infinite event history. The replay buffer size represents a trade-off between supporting long-disconnected clients and server resource usage. Clients disconnected longer than the replay buffer require full flag synchronization via the REST API.\n\n### Connection Management and Recovery\n\nRobust connection management distinguishes production-ready feature flag systems from simple implementations. Client SDKs face numerous connectivity challenges: network interruptions, server restarts, load balancer changes, and varying network conditions across different environments. The connection management strategy must handle these scenarios gracefully while avoiding common pitfalls that can overwhelm infrastructure or create inconsistent flag states.\n\n**Mental Model: Cellular Network Roaming**\n\nConnection management resembles cellular network roaming systems. When your phone moves between cell towers or loses signal temporarily, it doesn't immediately give up — it systematically searches for connectivity using increasingly patient strategies. Similarly, feature flag clients must gracefully handle connection loss with intelligent retry patterns, maintaining local functionality while persistently attempting to restore real-time updates.\n\n#### Connection State Machine\n\nThe client SDK connection lifecycle follows a well-defined state machine that governs transitions between connectivity states and defines appropriate actions for each state:\n\n| Current State | Event | Next State | Actions Taken |\n|---------------|-------|------------|---------------|\n| **Disconnected** | `connect()` called | Connecting | Initiate SSE connection request |\n| **Connecting** | Connection established | Connected | Start receiving events, clear retry count |\n| **Connecting** | Connection failed | Reconnecting | Start exponential backoff timer |\n| **Connected** | Connection lost | Reconnecting | Begin reconnection attempt with backoff |\n| **Connected** | Explicit disconnect | Disconnected | Close connection cleanly |\n| **Reconnecting** | Retry timer expires | Connecting | Attempt reconnection with Last-Event-ID |\n| **Reconnecting** | Max retries exceeded | Disconnected | Enter degraded mode, log error |\n\n![Real-time Connection State Machine](./diagrams/realtime-state-machine.svg)\n\nEach state defines specific behaviors and responsibilities:\n\n**Connected State**: The client actively receives SSE events, applies flag updates to the local cache, and maintains a heartbeat mechanism to detect connection health. The client tracks the last received event ID for potential replay scenarios and monitors message timestamps to detect clock skew or processing delays.\n\n**Reconnecting State**: The client implements exponential backoff with jitter to avoid thundering herd problems during mass reconnections. Base retry intervals start at 1 second and increase exponentially (2s, 4s, 8s, 16s) up to a maximum of 300 seconds. Random jitter (±25% of the interval) prevents synchronized reconnection attempts from multiple clients.\n\n**Disconnected State**: The client operates in degraded mode, serving flags from local cache while optionally falling back to periodic HTTP polling for critical updates. This state indicates either intentional disconnection or exhausted retry attempts.\n\n#### Exponential Backoff with Jitter\n\nReconnection timing follows a carefully tuned exponential backoff algorithm that balances rapid recovery with infrastructure protection. The algorithm prevents thundering herd scenarios where thousands of clients simultaneously reconnect after a server restart or network partition.\n\nThe backoff calculation incorporates several factors:\n\n1. **Base Delay**: Starts at 1 second for the first retry attempt\n2. **Exponential Multiplier**: Doubles the delay after each failed attempt (2x multiplier)\n3. **Maximum Delay**: Caps at 300 seconds (5 minutes) to prevent indefinite delays\n4. **Jitter Factor**: Adds ±25% randomization to prevent synchronized retries\n5. **Success Reset**: Resets to base delay after successful connection\n\n**Backoff Implementation Algorithm**:\n\n1. Initialize retry count to zero and base delay to 1 second\n2. When connection attempt fails, increment retry count\n3. Calculate raw delay as `base_delay * (2 ^ retry_count)`\n4. Apply maximum delay cap: `min(raw_delay, max_delay)`\n5. Apply jitter: `final_delay = capped_delay * (0.75 + random(0.5))`\n6. Wait for final delay before next attempt\n7. Reset retry count to zero on successful connection\n\nThis approach distributes reconnection attempts over time while ensuring clients don't wait excessively long during brief network interruptions.\n\n#### State Synchronization and Recovery\n\nWhen clients reconnect after extended disconnection, they must efficiently synchronize their local flag state with the current server state. The synchronization strategy depends on the disconnection duration and available event replay history.\n\n**Replay-Based Recovery** (preferred for short disconnections):\n\n1. Client includes `Last-Event-ID` header in SSE reconnection request\n2. Server validates event ID exists in replay buffer\n3. Server replays all events since the specified ID\n4. Client applies events sequentially to update local cache\n5. Client resumes normal operation after replay completion\n\n**Full Synchronization Recovery** (required for long disconnections):\n\n1. Server responds with HTTP 204 (No Replay Available) if event ID is too old\n2. Client initiates full flag synchronization via REST API\n3. Client retrieves all active flags using `ListFlags(true)`\n4. Client replaces entire local cache with fresh flag definitions\n5. Client establishes new SSE connection without Last-Event-ID\n\n> **Critical Implementation Note**: Clients must handle partial replay scenarios where some events in the replay buffer are corrupted or out of order. The synchronization process should validate event sequence numbers and detect gaps that require full synchronization fallback.\n\nThe state synchronization process includes several validation checkpoints:\n\n| Checkpoint | Validation | Recovery Action |\n|------------|------------|-----------------|\n| Event Sequence | Verify sequential event IDs | Request full sync if gaps detected |\n| Flag Versions | Compare flag modification timestamps | Apply updates for newer versions only |\n| Cache Consistency | Validate flag references and dependencies | Rebuild dependency graph |\n| Targeting Rules | Ensure rule conditions are parseable | Mark invalid flags as disabled |\n\n### Cache Invalidation Strategy\n\nIntelligent caching enables feature flag clients to continue operating during network interruptions while maintaining reasonable freshness guarantees. The caching strategy must balance several competing requirements: minimizing evaluation latency, supporting offline scenarios, ensuring eventual consistency, and avoiding excessive memory usage. Cache invalidation represents the critical mechanism for maintaining correctness when flag definitions change.\n\n**Mental Model: Library Book System**\n\nThink of flag caching like a library book checkout system. Each client SDK has checked out copies of flag definitions to use locally (cache). When the library updates a book (flag change), it needs to notify everyone with checked-out copies to return them and get the new version (cache invalidation). However, if someone is reading offline, they can continue using their copy temporarily (graceful degradation) until they reconnect and synchronize.\n\n#### Multi-Level Cache Architecture\n\nThe caching system employs a hierarchical approach with different cache levels optimized for specific access patterns and consistency requirements:\n\n| Cache Level | Location | TTL | Update Mechanism | Purpose |\n|-------------|----------|-----|------------------|---------|\n| **Memory Cache** | Client SDK process | No TTL (event-driven) | SSE updates + invalidation | Ultra-fast flag evaluation |\n| **Local Storage Cache** | Client filesystem/database | 24 hours | Periodic refresh + SSE | Offline support and persistence |\n| **CDN Cache** | Edge locations | 60 seconds | Server-side invalidation | Global distribution and load reduction |\n\n**Memory Cache**: Provides microsecond flag evaluation latency by keeping all active flag definitions in process memory. Updates occur immediately upon receiving SSE events, ensuring memory cache reflects the most current server state. This cache has no TTL since real-time updates maintain freshness.\n\n**Local Storage Cache**: Supports offline scenarios by persisting flag definitions to local storage (filesystem, embedded database, or browser localStorage). This cache includes timestamps and ETags to support conditional requests during synchronization. Local storage cache serves as the fallback when memory cache is empty or during SDK initialization.\n\n**CDN Cache**: Reduces server load by caching flag responses at edge locations close to client SDKs. CDN cache enables geographic distribution of flag data while supporting rapid invalidation for critical updates.\n\n#### Event-Driven Invalidation\n\nReal-time flag updates trigger targeted cache invalidation events that maintain cache consistency without requiring full cache flushes. The invalidation strategy varies based on the type and scope of flag changes:\n\n**Individual Flag Updates**: When a single flag changes, the system sends targeted invalidation events containing the specific `FlagKey`. Clients remove or update only the affected flag, preserving the remainder of their cache. This approach minimizes cache rebuild overhead and maintains evaluation performance for unchanged flags.\n\n**Bulk Flag Updates**: Administrative operations that affect multiple flags (such as environment switches or emergency rollbacks) trigger batch invalidation events. These events contain arrays of affected flag keys or invalidation patterns (such as \"all flags for environment X\").\n\n**Dependency-Driven Invalidation**: When prerequisite flags change, the system must also invalidate any dependent flags to prevent evaluation inconsistencies. The server maintains a dependency graph and includes downstream flag keys in invalidation events.\n\nThe invalidation message structure provides clients with sufficient information to make intelligent caching decisions:\n\n| Invalidation Field | Type | Purpose | Example |\n|-------------------|------|---------|---------|\n| `invalidation_type` | String | Scope of invalidation | `single_flag`, `bulk_flags`, `full_cache` |\n| `affected_flags` | Array | List of flag keys requiring invalidation | `[\"feature_x\", \"experiment_abc\"]` |\n| `reason` | String | Cause of invalidation for debugging | `flag_updated`, `dependency_changed`, `emergency_rollback` |\n| `timestamp` | ISO 8601 | When invalidation was triggered | `2024-01-15T10:30:00Z` |\n\n#### Graceful Degradation Patterns\n\nWhen real-time updates become unavailable, the cache system must provide predictable degradation behavior that maintains application functionality while indicating reduced freshness guarantees. The degradation strategy follows a priority-based approach that preserves the most critical functionality while clearly communicating system state.\n\n**Degradation Priority Levels**:\n\n1. **Memory Cache Only**: Real-time updates unavailable, but memory cache remains valid. Evaluation continues normally with potentially stale data. This level supports minutes to hours of operation depending on flag change frequency.\n\n2. **Local Storage Fallback**: Memory cache becomes unreliable, system falls back to persisted local storage cache. Freshness guarantees reduce to hours or days, but core functionality remains available.\n\n3. **Default Values Only**: All cache levels are unavailable or corrupted, system serves only default values specified in flag definitions. This level maintains application stability but disables all dynamic flag behavior.\n\n4. **Fail-Safe Mode**: Even default values are unavailable, system returns conservative defaults (typically feature flags disabled, experiments off). This level prevents application crashes but may impact user experience.\n\n> **Operational Insight**: Each degradation level should emit distinct telemetry and logging to enable operations teams to understand system health and take appropriate remedial action. Clear degradation indicators help distinguish between minor connectivity issues and serious infrastructure failures.\n\nThe degradation strategy includes automatic recovery mechanisms:\n\n**Recovery Detection**: Clients periodically attempt to restore higher-priority cache levels by testing connectivity, validating cache consistency, and requesting fresh data. Recovery attempts follow exponential backoff similar to connection retry logic.\n\n**Cache Warming**: When recovering from degraded states, clients prioritize loading the most frequently evaluated flags first, ensuring critical application paths resume normal operation quickly. Less critical flags load in the background.\n\n**Consistency Verification**: During recovery, clients validate cache consistency by comparing local flag versions with server versions, ensuring degraded operation didn't introduce inconsistencies that could affect user experience.\n\n#### Common Pitfalls\n\n⚠️ **Pitfall: Thundering Herd on Reconnection**\nMass client reconnection after server restart can overwhelm infrastructure and cause cascading failures. This occurs when all clients lose connectivity simultaneously and attempt immediate reconnection without coordination. The result is thousands of concurrent connection attempts that exceed server capacity and connection limits.\n\n**Fix**: Implement exponential backoff with jitter for all reconnection attempts. Add connection rate limiting on the server side and consider connection queuing during startup periods. Monitor connection establishment rates and alert on unusual spikes.\n\n⚠️ **Pitfall: Infinite Event Replay Buffer**\nMaintaining unlimited event history for client replay consumes unbounded memory and can cause server crashes during high-throughput periods. Some implementations attempt to store every flag change indefinitely to support arbitrary client reconnection scenarios.\n\n**Fix**: Implement bounded replay buffers with configurable size limits (recommend 1000-5000 events). Clients requesting replay beyond buffer limits must perform full synchronization. Monitor buffer usage and tune size based on typical client disconnection patterns.\n\n⚠️ **Pitfall: Cache Corruption During Partial Updates**\nDelta updates can corrupt client cache if applied out of order or when base flag state is inconsistent. This manifests as clients serving incorrect flag values that don't match server state, leading to inconsistent user experiences.\n\n**Fix**: Include flag version numbers in all updates and validate version compatibility before applying changes. Implement cache consistency checksums and fallback to full synchronization when corruption is detected. Prefer complete flag updates over delta updates for complex changes.\n\n⚠️ **Pitfall: Blocking Evaluation During Cache Updates**\nApplying cache updates synchronously during flag evaluation can cause evaluation latency spikes and thread contention in multi-threaded applications. This particularly impacts high-throughput applications where flag evaluation occurs on critical request paths.\n\n**Fix**: Implement lock-free cache updates using atomic operations or copy-on-write semantics. Stage cache updates in background threads and atomically swap complete cache instances. Never block flag evaluation for cache maintenance operations.\n\n![Flag Update Propagation](./diagrams/update-propagation.svg)\n\n### Implementation Guidance\n\nThis section provides concrete implementation guidance for building real-time flag updates in Go, focusing on production-ready patterns that handle the complexities of streaming connections, intelligent caching, and graceful degradation.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|----------------|\n| **SSE Server** | `net/http` with `http.Flusher` | `gin-gonic/gin` with streaming middleware |\n| **Client HTTP** | `net/http` with `EventSource` pattern | `gorilla/websocket` for WebSocket fallback |\n| **Local Cache** | `sync.Map` with TTL cleanup | `patrickmn/go-cache` or `allegro/bigcache` |\n| **Persistent Storage** | JSON files with `os` package | `bolt/bbolt` embedded database |\n| **Backoff Logic** | Custom exponential calculation | `cenkalti/backoff` library |\n| **Event Serialization** | `encoding/json` | `vmihailenco/msgpack` for efficiency |\n\n#### Recommended File Structure\n\n```\ninternal/realtime/\n  server.go                 ← SSE server implementation\n  client.go                ← Client SDK with connection management\n  cache.go                 ← Multi-level cache implementation\n  backoff.go               ← Exponential backoff utilities\n  events.go                ← Event message definitions\n  connection_manager.go    ← Connection state machine\n  server_test.go          ← SSE server tests\n  client_test.go          ← Client connection tests\n  cache_test.go           ← Cache invalidation tests\ninternal/storage/\n  flag_store.go           ← Flag storage interface\n  memory_store.go         ← In-memory flag storage\npkg/sdk/\n  client.go               ← Public SDK interface\n  evaluation.go           ← Flag evaluation with caching\nexamples/\n  sse_server/main.go      ← Complete SSE server example\n  flag_client/main.go     ← Example client usage\n```\n\n#### Infrastructure Starter Code\n\n**Complete SSE Server Implementation**:\n\n```go\n// internal/realtime/server.go\npackage realtime\n\nimport (\n    \"context\"\n    \"encoding/json\"\n    \"fmt\"\n    \"log\"\n    \"net/http\"\n    \"strconv\"\n    \"sync\"\n    \"time\"\n)\n\n// FlagUpdateEvent represents a flag change notification\ntype FlagUpdateEvent struct {\n    EventType   string      `json:\"event_type\"`\n    EventID     string      `json:\"event_id\"`\n    Timestamp   time.Time   `json:\"timestamp\"`\n    FlagKey     string      `json:\"flag_key\"`\n    Payload     interface{} `json:\"payload\"`\n    ChangeType  string      `json:\"change_type\"`\n}\n\n// SSEServer manages Server-Sent Events for flag updates\ntype SSEServer struct {\n    clients      map[string]*SSEClient\n    eventBuffer  []FlagUpdateEvent\n    bufferSize   int\n    mu           sync.RWMutex\n    eventCounter int64\n}\n\n// SSEClient represents a connected client\ntype SSEClient struct {\n    ID           string\n    ResponseWriter http.ResponseWriter\n    Flusher      http.Flusher\n    LastEventID  string\n    Connected    bool\n    mu           sync.Mutex\n}\n\n// NewSSEServer creates a new SSE server with bounded event buffer\nfunc NewSSEServer(bufferSize int) *SSEServer {\n    return &SSEServer{\n        clients:     make(map[string]*SSEClient),\n        eventBuffer: make([]FlagUpdateEvent, 0, bufferSize),\n        bufferSize:  bufferSize,\n    }\n}\n\n// ServeHTTP handles SSE connection requests\nfunc (s *SSEServer) ServeHTTP(w http.ResponseWriter, r *http.Request) {\n    // Set SSE headers\n    w.Header().Set(\"Content-Type\", \"text/event-stream\")\n    w.Header().Set(\"Cache-Control\", \"no-cache\")\n    w.Header().Set(\"Connection\", \"keep-alive\")\n    w.Header().Set(\"Access-Control-Allow-Origin\", \"*\")\n\n    flusher, ok := w.(http.Flusher)\n    if !ok {\n        http.Error(w, \"Streaming unsupported\", http.StatusInternalServerError)\n        return\n    }\n\n    clientID := r.Header.Get(\"X-Client-ID\")\n    if clientID == \"\" {\n        clientID = fmt.Sprintf(\"client_%d\", time.Now().UnixNano())\n    }\n\n    client := &SSEClient{\n        ID:             clientID,\n        ResponseWriter: w,\n        Flusher:        flusher,\n        LastEventID:    r.Header.Get(\"Last-Event-ID\"),\n        Connected:      true,\n    }\n\n    s.mu.Lock()\n    s.clients[clientID] = client\n    s.mu.Unlock()\n\n    defer func() {\n        s.mu.Lock()\n        delete(s.clients, clientID)\n        s.mu.Unlock()\n    }()\n\n    // Send replay events if requested\n    if client.LastEventID != \"\" {\n        s.sendReplayEvents(client)\n    }\n\n    // Keep connection alive and detect disconnection\n    ctx := r.Context()\n    ticker := time.NewTicker(30 * time.Second)\n    defer ticker.Stop()\n\n    for {\n        select {\n        case <-ctx.Done():\n            return\n        case <-ticker.C:\n            if err := s.sendHeartbeat(client); err != nil {\n                log.Printf(\"Client %s disconnected: %v\", clientID, err)\n                return\n            }\n        }\n    }\n}\n\n// sendReplayEvents replays buffered events to reconnecting clients\nfunc (s *SSEServer) sendReplayEvents(client *SSEClient) {\n    s.mu.RLock()\n    defer s.mu.RUnlock()\n\n    lastEventNum := s.parseEventID(client.LastEventID)\n    if lastEventNum == -1 {\n        // Invalid event ID, client needs full sync\n        s.sendEvent(client, FlagUpdateEvent{\n            EventType: \"sync_required\",\n            EventID:   s.generateEventID(),\n            Timestamp: time.Now(),\n        })\n        return\n    }\n\n    // Find starting position in buffer\n    startIndex := -1\n    for i, event := range s.eventBuffer {\n        if s.parseEventID(event.EventID) > lastEventNum {\n            startIndex = i\n            break\n        }\n    }\n\n    if startIndex == -1 {\n        // No events to replay or event too old\n        return\n    }\n\n    // Send all events since last received\n    for i := startIndex; i < len(s.eventBuffer); i++ {\n        s.sendEvent(client, s.eventBuffer[i])\n    }\n}\n\n// sendHeartbeat sends keep-alive ping to client\nfunc (s *SSEServer) sendHeartbeat(client *SSEClient) error {\n    client.mu.Lock()\n    defer client.mu.Unlock()\n\n    if !client.Connected {\n        return fmt.Errorf(\"client disconnected\")\n    }\n\n    _, err := fmt.Fprintf(client.ResponseWriter, \": heartbeat\\n\\n\")\n    if err != nil {\n        client.Connected = false\n        return err\n    }\n\n    client.Flusher.Flush()\n    return nil\n}\n\n// BroadcastFlagUpdate sends flag change to all connected clients\nfunc (s *SSEServer) BroadcastFlagUpdate(flagKey string, payload interface{}, changeType string) {\n    event := FlagUpdateEvent{\n        EventType:  \"flag_updated\",\n        EventID:    s.generateEventID(),\n        Timestamp:  time.Now(),\n        FlagKey:    flagKey,\n        Payload:    payload,\n        ChangeType: changeType,\n    }\n\n    // Add to buffer for replay\n    s.mu.Lock()\n    s.eventBuffer = append(s.eventBuffer, event)\n    if len(s.eventBuffer) > s.bufferSize {\n        // Remove oldest event to maintain buffer size\n        s.eventBuffer = s.eventBuffer[1:]\n    }\n    clients := make([]*SSEClient, 0, len(s.clients))\n    for _, client := range s.clients {\n        clients = append(clients, client)\n    }\n    s.mu.Unlock()\n\n    // Broadcast to all clients\n    for _, client := range clients {\n        if err := s.sendEvent(client, event); err != nil {\n            log.Printf(\"Failed to send event to client %s: %v\", client.ID, err)\n        }\n    }\n}\n\n// sendEvent writes SSE event to client connection\nfunc (s *SSEServer) sendEvent(client *SSEClient, event FlagUpdateEvent) error {\n    client.mu.Lock()\n    defer client.mu.Unlock()\n\n    if !client.Connected {\n        return fmt.Errorf(\"client disconnected\")\n    }\n\n    data, err := json.Marshal(event)\n    if err != nil {\n        return err\n    }\n\n    _, err = fmt.Fprintf(client.ResponseWriter, \"id: %s\\nevent: %s\\ndata: %s\\n\\n\",\n        event.EventID, event.EventType, string(data))\n    if err != nil {\n        client.Connected = false\n        return err\n    }\n\n    client.Flusher.Flush()\n    return nil\n}\n\n// generateEventID creates unique sequential event identifier\nfunc (s *SSEServer) generateEventID() string {\n    s.eventCounter++\n    return fmt.Sprintf(\"seq_%d_%d\", s.eventCounter, time.Now().Unix())\n}\n\n// parseEventID extracts sequence number from event ID\nfunc (s *SSEServer) parseEventID(eventID string) int64 {\n    if eventID == \"\" {\n        return -1\n    }\n    \n    var seq int64\n    var timestamp int64\n    if _, err := fmt.Sscanf(eventID, \"seq_%d_%d\", &seq, &timestamp); err != nil {\n        return -1\n    }\n    return seq\n}\n```\n\n**Complete Connection Manager with State Machine**:\n\n```go\n// internal/realtime/connection_manager.go\npackage realtime\n\nimport (\n    \"bufio\"\n    \"context\"\n    \"fmt\"\n    \"math\"\n    \"math/rand\"\n    \"net/http\"\n    \"sync\"\n    \"time\"\n)\n\n// ConnectionState represents the current connection status\ntype ConnectionState int\n\nconst (\n    StateDisconnected ConnectionState = iota\n    StateConnecting\n    StateConnected\n    StateReconnecting\n)\n\n// ConnectionManager handles SSE connection lifecycle\ntype ConnectionManager struct {\n    serverURL      string\n    clientID       string\n    lastEventID    string\n    state          ConnectionState\n    retryCount     int\n    maxRetries     int\n    baseDelay      time.Duration\n    maxDelay       time.Duration\n    \n    eventHandler   func(FlagUpdateEvent)\n    errorHandler   func(error)\n    \n    cancelFunc     context.CancelFunc\n    mu             sync.RWMutex\n    stateChan      chan ConnectionState\n}\n\n// NewConnectionManager creates a new connection manager\nfunc NewConnectionManager(serverURL, clientID string) *ConnectionManager {\n    return &ConnectionManager{\n        serverURL:    serverURL,\n        clientID:     clientID,\n        state:        StateDisconnected,\n        maxRetries:   10,\n        baseDelay:    time.Second,\n        maxDelay:     5 * time.Minute,\n        stateChan:    make(chan ConnectionState, 10),\n    }\n}\n\n// Connect initiates SSE connection with automatic retry\nfunc (cm *ConnectionManager) Connect(ctx context.Context) error {\n    cm.mu.Lock()\n    defer cm.mu.Unlock()\n\n    if cm.state != StateDisconnected {\n        return fmt.Errorf(\"connection already active\")\n    }\n\n    connectCtx, cancel := context.WithCancel(ctx)\n    cm.cancelFunc = cancel\n    cm.setState(StateConnecting)\n\n    go cm.connectionLoop(connectCtx)\n    return nil\n}\n\n// connectionLoop manages the connection lifecycle with retry logic\nfunc (cm *ConnectionManager) connectionLoop(ctx context.Context) {\n    for {\n        select {\n        case <-ctx.Done():\n            cm.setState(StateDisconnected)\n            return\n        default:\n            if err := cm.attemptConnection(ctx); err != nil {\n                if cm.shouldRetry() {\n                    cm.setState(StateReconnecting)\n                    delay := cm.calculateBackoffDelay()\n                    \n                    select {\n                    case <-ctx.Done():\n                        cm.setState(StateDisconnected)\n                        return\n                    case <-time.After(delay):\n                        cm.retryCount++\n                        continue\n                    }\n                } else {\n                    cm.setState(StateDisconnected)\n                    if cm.errorHandler != nil {\n                        cm.errorHandler(fmt.Errorf(\"max retries exceeded\"))\n                    }\n                    return\n                }\n            } else {\n                // Connection successful, reset retry count\n                cm.retryCount = 0\n            }\n        }\n    }\n}\n\n// attemptConnection tries to establish SSE connection\nfunc (cm *ConnectionManager) attemptConnection(ctx context.Context) error {\n    req, err := http.NewRequestWithContext(ctx, \"GET\", cm.serverURL, nil)\n    if err != nil {\n        return err\n    }\n\n    // Set SSE headers\n    req.Header.Set(\"Accept\", \"text/event-stream\")\n    req.Header.Set(\"Cache-Control\", \"no-cache\")\n    req.Header.Set(\"X-Client-ID\", cm.clientID)\n\n    cm.mu.RLock()\n    if cm.lastEventID != \"\" {\n        req.Header.Set(\"Last-Event-ID\", cm.lastEventID)\n    }\n    cm.mu.RUnlock()\n\n    client := &http.Client{\n        Timeout: 0, // No timeout for streaming connection\n    }\n\n    resp, err := client.Do(req)\n    if err != nil {\n        return err\n    }\n    defer resp.Body.Close()\n\n    if resp.StatusCode != http.StatusOK {\n        return fmt.Errorf(\"SSE connection failed: %s\", resp.Status)\n    }\n\n    cm.setState(StateConnected)\n    return cm.processEventStream(ctx, resp)\n}\n\n// processEventStream reads and processes SSE events\nfunc (cm *ConnectionManager) processEventStream(ctx context.Context, resp *http.Response) error {\n    scanner := bufio.NewScanner(resp.Body)\n    var currentEvent FlagUpdateEvent\n    var eventID, eventType, eventData string\n\n    for scanner.Scan() {\n        line := scanner.Text()\n        \n        select {\n        case <-ctx.Done():\n            return ctx.Err()\n        default:\n        }\n\n        if line == \"\" {\n            // Empty line indicates end of event\n            if eventType != \"\" && eventData != \"\" {\n                // Parse and handle event\n                if err := cm.handleSSEEvent(eventID, eventType, eventData); err != nil {\n                    if cm.errorHandler != nil {\n                        cm.errorHandler(err)\n                    }\n                }\n                // Reset for next event\n                eventID, eventType, eventData = \"\", \"\", \"\"\n            }\n            continue\n        }\n\n        if len(line) > 5 && line[:3] == \"id:\" {\n            eventID = line[4:]\n        } else if len(line) > 7 && line[:6] == \"event:\" {\n            eventType = line[7:]\n        } else if len(line) > 6 && line[:5] == \"data:\" {\n            eventData = line[6:]\n        }\n    }\n\n    return scanner.Err()\n}\n\n// handleSSEEvent processes individual SSE events\nfunc (cm *ConnectionManager) handleSSEEvent(eventID, eventType, eventData string) error {\n    // Update last event ID for replay\n    cm.mu.Lock()\n    cm.lastEventID = eventID\n    cm.mu.Unlock()\n\n    // Skip heartbeat events\n    if eventData == \"\" {\n        return nil\n    }\n\n    // TODO: Parse eventData JSON into FlagUpdateEvent\n    // TODO: Call eventHandler with parsed event\n    // This is where learners implement the event parsing logic\n    \n    return nil\n}\n\n// calculateBackoffDelay computes exponential backoff with jitter\nfunc (cm *ConnectionManager) calculateBackoffDelay() time.Duration {\n    // Exponential backoff: baseDelay * (2 ^ retryCount)\n    delay := cm.baseDelay * time.Duration(math.Pow(2, float64(cm.retryCount)))\n    \n    // Apply maximum delay cap\n    if delay > cm.maxDelay {\n        delay = cm.maxDelay\n    }\n    \n    // Add jitter (±25%)\n    jitter := delay / 4\n    jitterAmount := time.Duration(rand.Int63n(int64(jitter*2))) - jitter\n    \n    return delay + jitterAmount\n}\n\n// shouldRetry determines if connection should be retried\nfunc (cm *ConnectionManager) shouldRetry() bool {\n    return cm.retryCount < cm.maxRetries\n}\n\n// setState updates connection state and notifies listeners\nfunc (cm *ConnectionManager) setState(newState ConnectionState) {\n    cm.state = newState\n    select {\n    case cm.stateChan <- newState:\n    default:\n        // Channel full, skip notification\n    }\n}\n\n// GetState returns current connection state\nfunc (cm *ConnectionManager) GetState() ConnectionState {\n    cm.mu.RLock()\n    defer cm.mu.RUnlock()\n    return cm.state\n}\n\n// Disconnect cleanly closes the connection\nfunc (cm *ConnectionManager) Disconnect() {\n    cm.mu.Lock()\n    defer cm.mu.Unlock()\n    \n    if cm.cancelFunc != nil {\n        cm.cancelFunc()\n        cm.cancelFunc = nil\n    }\n    cm.setState(StateDisconnected)\n}\n```\n\n#### Core Logic Skeleton Code\n\n**Flag Cache Implementation with Invalidation**:\n\n```go\n// internal/realtime/cache.go\npackage realtime\n\nimport (\n    \"encoding/json\"\n    \"sync\"\n    \"time\"\n)\n\n// FlagCache provides multi-level caching with real-time invalidation\ntype FlagCache struct {\n    memoryCache   map[string]*CachedFlag\n    localStorage  LocalStorage\n    mu            sync.RWMutex\n    stats         CacheStats\n}\n\n// CachedFlag wraps flag definition with metadata\ntype CachedFlag struct {\n    Definition  *FlagDefinition\n    Version     string\n    Timestamp   time.Time\n    Source      string  // \"memory\", \"local\", \"default\"\n}\n\n// CacheStats tracks cache performance metrics\ntype CacheStats struct {\n    Hits          int64\n    Misses        int64\n    Invalidations int64\n    mu            sync.RWMutex\n}\n\n// LocalStorage interface for persistent flag storage\ntype LocalStorage interface {\n    Store(key string, flag *FlagDefinition) error\n    Load(key string) (*FlagDefinition, error)\n    Delete(key string) error\n    List() ([]string, error)\n}\n\n// NewFlagCache creates a new multi-level cache\nfunc NewFlagCache(localStorage LocalStorage) *FlagCache {\n    return &FlagCache{\n        memoryCache:  make(map[string]*CachedFlag),\n        localStorage: localStorage,\n    }\n}\n\n// GetFlag retrieves flag from cache with fallback hierarchy\nfunc (c *FlagCache) GetFlag(flagKey string) (*FlagDefinition, error) {\n    // TODO 1: Check memory cache first for fastest access\n    // TODO 2: If not in memory, try local storage cache\n    // TODO 3: If not in local storage, return error for cache miss\n    // TODO 4: Update cache statistics (hits/misses)\n    // TODO 5: When loading from local storage, populate memory cache\n    // Hint: Use read lock for cache access, upgrade to write lock only when updating\n    \n    return nil, nil\n}\n\n// InvalidateFlag removes flag from all cache levels\nfunc (c *FlagCache) InvalidateFlag(flagKey string) error {\n    // TODO 1: Remove from memory cache using write lock\n    // TODO 2: Remove from local storage cache\n    // TODO 3: Update invalidation statistics\n    // TODO 4: Log invalidation event for debugging\n    // Hint: Always update statistics even if flag wasn't cached\n    \n    return nil\n}\n\n// UpdateFlag stores new flag version in cache\nfunc (c *FlagCache) UpdateFlag(flagKey string, flag *FlagDefinition, source string) error {\n    // TODO 1: Create CachedFlag wrapper with metadata (version, timestamp, source)\n    // TODO 2: Store in memory cache with write lock\n    // TODO 3: Persist to local storage for offline support\n    // TODO 4: Validate flag structure before caching\n    // TODO 5: Handle storage errors gracefully (memory cache still updates)\n    // Hint: Generate version string from flag content hash or timestamp\n    \n    return nil\n}\n\n// ApplyFlagUpdate processes real-time flag change events\nfunc (c *FlagCache) ApplyFlagUpdate(event FlagUpdateEvent) error {\n    // TODO 1: Parse event payload based on change_type\n    // TODO 2: For \"full_update\": replace entire flag definition\n    // TODO 3: For \"delta_update\": merge changes into existing flag\n    // TODO 4: For \"flag_deleted\": remove flag from all cache levels\n    // TODO 5: Validate update consistency (version numbers, timestamps)\n    // TODO 6: Handle update conflicts and version mismatches\n    // Hint: Delta updates should validate base flag exists and versions match\n    \n    return nil\n}\n\n// GetCacheStats returns current cache performance metrics\nfunc (c *FlagCache) GetCacheStats() CacheStats {\n    c.stats.mu.RLock()\n    defer c.stats.mu.RUnlock()\n    \n    return CacheStats{\n        Hits:          c.stats.Hits,\n        Misses:        c.stats.Misses,\n        Invalidations: c.stats.Invalidations,\n    }\n}\n\n// WarmCache preloads frequently used flags\nfunc (c *FlagCache) WarmCache(flagKeys []string) error {\n    // TODO 1: Load specified flags from local storage\n    // TODO 2: Populate memory cache with loaded flags\n    // TODO 3: Handle missing flags gracefully\n    // TODO 4: Load flags in priority order (most critical first)\n    // TODO 5: Report warming progress and errors\n    // Hint: Use goroutines for concurrent warming but limit concurrency\n    \n    return nil\n}\n\n// ValidateConsistency checks cache integrity\nfunc (c *FlagCache) ValidateConsistency() []string {\n    // TODO 1: Compare memory cache versions with local storage\n    // TODO 2: Detect corrupted or unparseable flag definitions  \n    // TODO 3: Find flags with invalid dependency references\n    // TODO 4: Return list of inconsistent flag keys\n    // TODO 5: Log detailed consistency issues for debugging\n    // Hint: This method helps detect cache corruption during degraded operation\n    \n    return nil\n}\n```\n\n#### Milestone Checkpoints\n\n**Checkpoint 1: SSE Server Basic Functionality**\n```bash\n# Start the SSE server\ngo run examples/sse_server/main.go\n\n# Test connection with curl\ncurl -N -H \"Accept: text/event-stream\" http://localhost:8080/stream\n\n# Expected: Heartbeat messages every 30 seconds\n# Expected: Connection remains open indefinitely\n# Expected: Server logs show client connection and heartbeat events\n```\n\n**Checkpoint 2: Event Replay and Reconnection**\n```bash\n# Connect client, then kill connection and reconnect\n# Client should automatically reconnect with exponential backoff\n# Server should replay missed events based on Last-Event-ID header\n\n# Test event replay\ncurl -N -H \"Accept: text/event-stream\" -H \"Last-Event-ID: seq_100_1640995200\" \\\n  http://localhost:8080/stream\n\n# Expected: Server replays events newer than specified ID\n# Expected: If ID too old, server sends sync_required event\n```\n\n**Checkpoint 3: Cache Invalidation Integration**\n```bash\n# Update a flag via management API\ncurl -X PUT http://localhost:8080/flags/test_flag \\\n  -d '{\"enabled\": true, \"variants\": [{\"key\": \"on\", \"value\": true}]}'\n\n# Verify SSE clients receive flag_updated event within 1 second\n# Verify client caches invalidate and serve new flag values\n# Test with multiple connected clients for broadcast verification\n```\n\n#### Debugging Tips\n\n| Symptom | Likely Cause | Diagnosis | Fix |\n|---------|--------------|-----------|-----|\n| **Clients never reconnect** | Missing exponential backoff or infinite retry loop | Check client logs for retry attempts and delays | Implement bounded retry with proper delay calculation |\n| **Thundering herd on server restart** | All clients reconnecting simultaneously | Monitor connection rate and server resource usage | Add jitter to backoff delays and connection rate limiting |\n| **Events delivered out of order** | Missing event sequencing or buffer overflow | Compare event IDs between server and client logs | Implement proper event ordering and sequence validation |\n| **Cache serves stale data** | Invalidation events not processed or lost | Check SSE connection status and event processing logs | Verify event handling and add cache TTL as backup |\n| **Memory leak in event buffer** | Unbounded event history storage | Monitor server memory usage over time | Implement fixed-size circular buffer with proper cleanup |\n| **Clients stuck in reconnecting state** | Network issues or server unavailability | Test network connectivity and server health endpoints | Add connection timeout and fallback to polling mode |\n\n\n## Flag Analytics and A/B Testing\n\n> **Milestone(s):** This section covers Milestone 3 (Flag Analytics & Experiments) by implementing flag exposure tracking, A/B testing framework, and statistical significance calculation for data-driven feature decisions.\n\nThink of **flag analytics** as the flight data recorder for your feature flags. Just as aviation authorities need detailed logs to understand what happened during a flight and whether aircraft systems performed correctly, product teams need comprehensive exposure tracking to understand how features are performing in the wild. The analytics system captures every flag evaluation event, much like how a black box records every instrument reading and pilot action throughout a flight.\n\nThe **A/B testing framework** extends this analogy to become your experimental flight test program. When aircraft manufacturers test new designs, they don't just throw them into commercial service—they run controlled experiments with careful measurement protocols, statistical analysis, and safety monitoring. Similarly, your A/B testing framework provides the rigorous experimental methodology needed to validate that new features actually improve user outcomes rather than just looking good in demos.\n\nThis analytics foundation transforms feature flags from simple configuration toggles into a sophisticated experimentation platform that enables evidence-based product development. Without proper analytics, feature flags become \"fire and forget\" deployments where teams never know whether their features succeeded or failed.\n\n![A/B Test Experiment Lifecycle](./diagrams/experiment-lifecycle.svg)\n\n### Flag Exposure Tracking\n\nFlag exposure tracking forms the observational backbone of the entire analytics system. Think of **exposure events** as the breadcrumbs that users leave behind as they navigate through your feature variations. Each time the evaluation engine determines which variant a user should see, the system records this decision along with the complete context that influenced it.\n\nThe core insight behind exposure tracking is that simply deploying a feature flag isn't enough—you need to know which users actually encountered each variant under what circumstances. This detailed record enables you to answer critical questions: Did the targeting rules work as expected? Are certain user segments seeing variants at different rates? Which environmental factors correlate with feature performance?\n\n> **Decision: Event-Based Exposure Recording**\n> - **Context**: Need to capture flag evaluations for analytics without impacting evaluation performance\n> - **Options Considered**: Synchronous database writes, asynchronous event queues, in-memory buffers with batch writes\n> - **Decision**: Asynchronous event queues with batch persistence\n> - **Rationale**: Removes database I/O from the critical evaluation path while ensuring reliable event capture\n> - **Consequences**: Enables high-throughput evaluation with complete audit trails but requires queue failure handling\n\nThe `FlagExposure` data structure captures every essential piece of information about a flag evaluation event:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `EventID` | `string` | Unique identifier for this specific exposure event |\n| `FlagKey` | `FlagKey` | The flag that was evaluated |\n| `UserID` | `UserID` | The user who received the variant |\n| `Variant` | `string` | The variant key that was assigned |\n| `Value` | `interface{}` | The actual value returned to the application |\n| `UserContext` | `UserContext` | Complete user attributes and segments at evaluation time |\n| `Timestamp` | `time.Time` | Precise moment when evaluation occurred |\n| `Source` | `string` | Evaluation source (cache, database, default) |\n| `Reason` | `string` | Why this variant was chosen (targeting rule, percentage, fallback) |\n| `ExperimentID` | `string` | Experiment identifier if flag is part of A/B test |\n| `SessionID` | `string` | User session to group related exposures |\n| `RequestID` | `string` | Request context for debugging and tracing |\n\nThe exposure tracking pipeline operates through several coordinated stages. When `EvaluateFlag` completes its variant assignment, it immediately calls `RecordExposure` with the complete evaluation result. This function packages the exposure data into a `FlagExposure` event and submits it to an asynchronous processing queue.\n\nThe queue consumer operates as a separate goroutine that batches exposure events and writes them to persistent storage in configurable intervals. This design prevents individual flag evaluations from blocking on database writes while ensuring that exposure data is captured reliably even under high load.\n\nHere's how the exposure tracking flow operates:\n\n1. The evaluation engine completes a flag evaluation and produces an `EvaluationResult`\n2. `RecordExposure` transforms the evaluation result into a `FlagExposure` event\n3. The event is submitted to the exposure queue with a unique event ID and timestamp\n4. The queue consumer batches events (typically 100-1000 events per batch)\n5. Batched events are written to the analytics database with error retry logic\n6. Successfully persisted events are removed from the queue buffer\n\n> The critical insight here is that exposure tracking must be completely decoupled from flag evaluation performance. A slow analytics database cannot be allowed to make feature flag evaluations slow, as this would defeat the entire purpose of having a responsive flagging system.\n\nThe system maintains exposure event ordering through sequential event IDs that enable gap detection and replay capabilities. If the analytics pipeline falls behind or experiences failures, operators can identify missing event ranges and trigger replay from the persistent queue storage.\n\n**Aggregation and Real-time Processing**\n\nRaw exposure events provide the granular audit trail, but most analytics queries require aggregated views. The system maintains several real-time aggregation tables that are updated as exposure events flow through the pipeline:\n\n| Aggregation Type | Granularity | Purpose |\n|------------------|-------------|---------|\n| Flag Summary | Flag + Day | Daily exposure counts per variant |\n| User Journey | User + Session | User's variant assignments across flags |\n| Segment Analysis | Segment + Flag + Hour | How targeting rules distribute users |\n| Experiment Metrics | Experiment + Variant + Hour | A/B test exposure tracking |\n\nThese aggregations enable fast dashboard queries without requiring full table scans of the raw exposure events. The aggregation logic runs as stream processing jobs that consume the same exposure event queue, ensuring consistency between raw events and summary tables.\n\n### A/B Testing Framework\n\nThe A/B testing framework transforms feature flags from simple configuration switches into rigorous experimental instruments. Think of **experiments** as controlled clinical trials for your product features. Just as medical researchers follow strict protocols to ensure their findings are statistically valid and not due to chance, the A/B testing framework provides the methodological rigor needed to distinguish genuine feature improvements from random variation.\n\nAn **experiment** represents a formal hypothesis test where you compare user behavior across different feature variants to determine which approach produces better outcomes. The framework handles the complex statistical machinery behind the scenes while presenting a clean interface for defining experiments, tracking metrics, and interpreting results.\n\n> **Decision: Experiment-Centric Design**\n> - **Context**: Need to support both simple feature flags and rigorous A/B testing\n> - **Options Considered**: Flag-first with experiment metadata, experiment-first with flag integration, separate systems\n> - **Decision**: Experiment-first design with automatic flag generation\n> - **Rationale**: Ensures experimental rigor by making statistical considerations primary rather than afterthoughts\n> - **Consequences**: More complex setup for simple flags but proper experimental design for A/B tests\n\nThe experiment data model extends the flag system with additional statistical metadata:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `ExperimentID` | `string` | Unique identifier for the experiment |\n| `Name` | `string` | Human-readable experiment name |\n| `Hypothesis` | `string` | Specific hypothesis being tested |\n| `FlagKey` | `FlagKey` | Associated feature flag for variant assignment |\n| `Variants` | `[]ExperimentVariant` | Available variants with allocation percentages |\n| `PrimaryMetric` | `string` | Key performance indicator for success measurement |\n| `SecondaryMetrics` | `[]string` | Additional metrics to track for insights |\n| `StartDate` | `time.Time` | When experiment began collecting data |\n| `EndDate` | `time.Time` | When experiment stopped (nil if running) |\n| `MinSampleSize` | `int` | Minimum users per variant for statistical power |\n| `SignificanceLevel` | `float64` | Required confidence level (typically 0.05) |\n| `PowerLevel` | `float64` | Statistical power target (typically 0.8) |\n| `TargetingRules` | `[]TargetingRule` | Conditions for experiment eligibility |\n| `Status` | `string` | Current state (draft, running, paused, completed) |\n\nEach `ExperimentVariant` defines a specific treatment condition within the experiment:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `Key` | `string` | Variant identifier (control, treatment_a, treatment_b) |\n| `Name` | `string` | Descriptive variant name |\n| `Description` | `string` | What this variant implements |\n| `Allocation` | `float64` | Percentage of users assigned to this variant |\n| `Configuration` | `interface{}` | Variant-specific feature configuration |\n| `IsControl` | `bool` | Whether this represents the baseline condition |\n\n**Experiment Lifecycle Management**\n\nExperiments progress through a carefully managed lifecycle that ensures statistical validity and prevents common experimental errors:\n\n1. **Draft Phase**: Experiment definition with power analysis and sample size calculation\n2. **Review Phase**: Statistical review of experimental design and success metrics\n3. **Launch Phase**: Begin user assignment and exposure tracking\n4. **Monitoring Phase**: Real-time tracking of sample ratio mismatch and metric collection\n5. **Analysis Phase**: Statistical significance testing and confidence interval calculation\n6. **Decision Phase**: Determine winning variant and plan rollout or rollback\n\nThe framework automatically enforces statistical best practices throughout this lifecycle. For example, it prevents \"peeking\" at results before reaching minimum sample sizes and warns when sample ratio mismatches indicate assignment problems.\n\n> The fundamental principle of rigorous A/B testing is that experimental parameters must be locked before data collection begins. Changing success metrics, variant allocations, or targeting rules after seeing preliminary results invalidates the statistical guarantees.\n\n**Sample Size and Power Analysis**\n\nBefore launching any experiment, the framework performs power analysis to determine the minimum sample size needed for reliable results. This calculation depends on several statistical parameters:\n\n| Parameter | Typical Value | Purpose |\n|-----------|---------------|---------|\n| Significance Level (α) | 0.05 | Maximum false positive rate |\n| Statistical Power (1-β) | 0.80 | Minimum true positive detection rate |\n| Effect Size | Varies | Minimum improvement worth detecting |\n| Baseline Conversion Rate | Historical | Current metric performance |\n\nThe power calculation ensures that experiments run long enough to detect meaningful differences while avoiding the costs of over-powered tests. Experiments that launch without proper power analysis often either run forever without reaching conclusions or declare false victories based on insufficient data.\n\n**Assignment Consistency and Tracking**\n\nThe experiment framework leverages the same consistent hashing mechanism used for percentage rollouts to ensure stable user assignment. However, experiments require additional tracking to maintain assignment consistency across the entire experiment duration.\n\nWhen a user first encounters an experiment flag, the system records their variant assignment in the experiment assignment table:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `ExperimentID` | `string` | Which experiment this assignment belongs to |\n| `UserID` | `UserID` | The assigned user |\n| `Variant` | `string` | Assigned variant key |\n| `AssignmentTime` | `time.Time` | When assignment first occurred |\n| `FirstExposure` | `time.Time` | When user first saw the variant |\n| `LastExposure` | `time.Time` | Most recent variant exposure |\n| `ExposureCount` | `int` | Total number of exposures |\n\nThis assignment persistence ensures that users see the same variant throughout the experiment duration, even if flag configurations change or targeting rules are modified. The assignment record also enables intent-to-treat analysis, which measures the effect of being assigned to a variant regardless of whether the user actually experienced it.\n\n### Statistical Significance Calculation\n\nStatistical significance calculation transforms raw exposure and conversion data into actionable insights about which variants actually perform better. Think of **significance testing** as the mathematical microscope that helps you distinguish genuine improvements from random noise. Just as a microscope reveals whether an apparent difference is real cellular structure or just optical artifacts, significance testing reveals whether an apparent performance difference represents true variant superiority or just random variation.\n\nThe statistical engine provides the mathematical rigor that prevents teams from making costly product decisions based on misleading data patterns. Without proper significance testing, teams often fall victim to false positives (celebrating improvements that don't exist) or false negatives (missing genuine improvements because they don't look dramatic enough).\n\n> **Decision: Frequentist Statistical Framework**\n> - **Context**: Need reliable statistical testing for experiment result interpretation\n> - **Options Considered**: Frequentist hypothesis testing, Bayesian analysis, non-parametric methods\n> - **Decision**: Classical frequentist testing with t-tests and chi-square tests\n> - **Rationale**: Well-understood methodology with clear decision criteria and wide industry acceptance\n> - **Consequences**: Provides definitive go/no-go decisions but requires careful interpretation of p-values\n\nThe `SignificanceResult` data structure encapsulates the complete statistical analysis for an experiment:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `ExperimentID` | `string` | Experiment being analyzed |\n| `MetricName` | `string` | Performance metric being tested |\n| `AnalysisTime` | `time.Time` | When this analysis was computed |\n| `VariantResults` | `[]VariantStatistics` | Statistical summary for each variant |\n| `Comparisons` | `[]PairwiseComparison` | Significance tests between variant pairs |\n| `OverallSignificant` | `bool` | Whether any variant shows significant difference |\n| `RecommendedAction` | `string` | Statistical recommendation (continue, stop, extend) |\n| `SampleSizeAdequate` | `bool` | Whether minimum sample requirements are met |\n| `SampleRatioMismatch` | `bool` | Whether variant assignments deviate from expected ratios |\n| `ConfidenceLevel` | `float64` | Statistical confidence level used |\n| `AnalysisMethod` | `string` | Statistical test applied (t-test, chi-square, etc.) |\n\nEach `VariantStatistics` entry provides detailed statistical measures for a single variant:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `Variant` | `string` | Variant identifier |\n| `SampleSize` | `int64` | Number of users assigned to this variant |\n| `ConversionCount` | `int64` | Number of users who performed the target action |\n| `ConversionRate` | `float64` | Conversion rate (conversions / sample size) |\n| `StandardError` | `float64` | Standard error of the conversion rate |\n| `ConfidenceInterval` | `ConfidenceInterval` | Upper and lower bounds for conversion rate |\n| `ZScore` | `float64` | Standardized test statistic |\n| `RelativeImprovement` | `float64` | Percentage change from control variant |\n\nThe `PairwiseComparison` structure captures the statistical test results between any two variants:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `VariantA` | `string` | First variant in comparison |\n| `VariantB` | `string` | Second variant in comparison |\n| `PValue` | `float64` | Probability of observing difference by chance |\n| `Significant` | `bool` | Whether difference exceeds significance threshold |\n| `TestStatistic` | `float64` | Calculated test statistic value |\n| `DegreesOfFreedom` | `int` | Degrees of freedom for the test |\n| `EffectSize` | `float64` | Magnitude of the observed difference |\n| `PowerAchieved` | `float64` | Statistical power achieved with current sample sizes |\n\n**Statistical Test Selection and Execution**\n\nThe significance calculation engine automatically selects appropriate statistical tests based on the metric type and data distribution characteristics:\n\n| Metric Type | Data Distribution | Statistical Test | Purpose |\n|-------------|------------------|------------------|---------|\n| Conversion Rate | Binomial | Two-proportion z-test | Compare success rates between variants |\n| Continuous Metric | Normal | Welch's t-test | Compare means with unequal variances |\n| Count Data | Poisson | Chi-square goodness of fit | Compare event frequencies |\n| Time-to-Event | Exponential | Log-rank test | Compare survival curves |\n\nThe statistical engine executes these tests through a standardized procedure:\n\n1. **Data Validation**: Verify sample sizes meet minimum requirements and check for data quality issues\n2. **Assumption Testing**: Validate statistical assumptions (normality, independence, equal variance)\n3. **Test Selection**: Choose appropriate statistical test based on metric type and data characteristics\n4. **Calculation**: Compute test statistics, p-values, and confidence intervals\n5. **Multiple Comparison Correction**: Apply Bonferroni or FDR correction for multiple variant tests\n6. **Interpretation**: Generate actionable recommendations based on statistical results\n\n> The critical insight in significance testing is that statistical significance doesn't automatically imply practical significance. A tiny improvement might be statistically significant with enough data but not worth implementing given engineering costs and opportunity costs.\n\n**Sequential Testing and Early Stopping**\n\nTraditional fixed-horizon testing requires pre-determining experiment duration and sample sizes, then waiting until completion before analyzing results. However, many business contexts require the ability to stop experiments early when results become conclusive or when variants show concerning negative effects.\n\nThe framework implements sequential testing procedures that allow valid statistical inference at multiple time points:\n\n| Method | Use Case | Advantages | Limitations |\n|--------|----------|------------|-------------|\n| Group Sequential | Pre-planned interim analyses | Maintains Type I error control | Requires predetermined stopping boundaries |\n| Alpha Spending | Flexible interim monitoring | Allows unplanned analyses | More complex boundary calculations |\n| Bayesian Sequential | Continuous monitoring | Natural probability interpretation | Requires prior specification |\n\nSequential testing maintains statistical validity while providing the operational flexibility that product teams require. However, these methods require careful implementation to avoid the statistical pitfalls of repeated testing.\n\n**Sample Ratio Mismatch Detection**\n\nOne of the most common sources of invalid A/B test results is sample ratio mismatch (SRM), where the observed ratio of users across variants deviates significantly from the intended allocation ratios. SRM typically indicates problems with the randomization mechanism, bot traffic, or technical implementation issues.\n\nThe significance calculation engine automatically performs SRM detection using chi-square goodness-of-fit tests:\n\n1. **Calculate Expected Counts**: Multiply total sample size by intended variant allocations\n2. **Compute Chi-square Statistic**: Sum of (observed - expected)² / expected across all variants\n3. **Determine P-value**: Compare test statistic to chi-square distribution\n4. **Flag SRM**: Report mismatch if p-value falls below threshold (typically 0.001)\n\nWhen SRM is detected, the system automatically flags the experiment results as potentially invalid and recommends investigation before making product decisions based on the data.\n\n### Common Pitfalls\n\n⚠️ **Pitfall: Peeking at Results Early**\nTeams frequently check experiment results before reaching statistical significance, then stop experiments when they see favorable trends. This \"peeking\" problem dramatically inflates false positive rates because teams essentially perform multiple statistical tests without correcting for multiple comparisons. **Solution**: Use sequential testing methods with proper stopping boundaries, or commit to fixed experiment durations with single final analysis.\n\n⚠️ **Pitfall: Ignoring Sample Ratio Mismatch**\nWhen variant assignment ratios don't match the intended allocation (e.g., 45%/55% instead of 50%/50%), teams often proceed with analysis anyway, assuming the mismatch is minor. However, SRM usually indicates systematic bias in user assignment that invalidates statistical assumptions. **Solution**: Always check for SRM using chi-square tests and investigate the root cause before trusting experiment results.\n\n⚠️ **Pitfall: Confusing Statistical and Practical Significance**\nLarge sample sizes can make tiny differences statistically significant even when they're not practically meaningful. A 0.01% conversion rate improvement might have p < 0.05 but generate less revenue than the engineering cost to implement. **Solution**: Always define minimum detectable effect sizes during experiment design and consider business impact alongside statistical significance.\n\n⚠️ **Pitfall: Multiple Comparison Problems**\nWhen testing multiple metrics or multiple variants simultaneously, the probability of false positives increases dramatically. Testing 20 metrics at α = 0.05 gives about a 64% chance of at least one false positive. **Solution**: Apply multiple comparison corrections (Bonferroni, FDR) or designate a single primary metric for decision-making with secondary metrics for insights only.\n\n⚠️ **Pitfall: Survivorship Bias in Analysis**\nAnalyzing only users who remained active throughout the entire experiment duration can bias results toward variants that retain users better. This survivorship bias can make harmful variants appear beneficial if they selectively retain certain user types. **Solution**: Use intent-to-treat analysis that includes all assigned users in the final calculation, regardless of their subsequent engagement.\n\n⚠️ **Pitfall: Inconsistent Assignment Tracking**\nIf user variant assignments change during an experiment (due to hash function changes, targeting rule modifications, or cache inconsistencies), the statistical analysis becomes meaningless. Users who experience multiple variants contaminate both variant groups. **Solution**: Persist user assignments at first exposure and enforce assignment consistency throughout the experiment duration.\n\n### Implementation Guidance\n\nThe analytics and experimentation system requires careful integration of high-throughput event processing, statistical computation, and data persistence. This implementation guidance provides the foundational infrastructure needed to support production-scale A/B testing.\n\n**Technology Recommendations**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Event Queue | Go channels with file persistence | Apache Kafka or AWS Kinesis |\n| Analytics Database | PostgreSQL with time-series tables | ClickHouse or Apache Druid |\n| Statistical Computing | Go math/stats with custom functions | R integration via Rserve |\n| Real-time Aggregation | In-memory maps with periodic persistence | Apache Flink or Spark Streaming |\n| Dashboards | Static HTML with JSON API | Grafana or custom React frontend |\n\n**Recommended File Structure**\n\n```\ninternal/analytics/\n  exposure/\n    tracker.go              ← FlagExposure recording and queuing\n    tracker_test.go         ← Exposure tracking tests\n    aggregator.go           ← Real-time aggregation pipeline\n  experiments/\n    experiment.go           ← Experiment lifecycle management\n    experiment_test.go      ← Experiment framework tests\n    assignment.go           ← User assignment persistence\n  statistics/\n    significance.go         ← Statistical significance calculation\n    significance_test.go    ← Statistics computation tests\n    power.go                ← Sample size and power analysis\n  storage/\n    schema.sql              ← Database schema for analytics tables\n    migrations/             ← Database migration scripts\n```\n\n**Exposure Tracking Infrastructure**\n\n```go\n// ExposureTracker manages the asynchronous recording of flag evaluation events\ntype ExposureTracker struct {\n    queue       chan FlagExposure\n    batchSize   int\n    flushPeriod time.Duration\n    storage     ExposureStorage\n    aggregator  *RealTimeAggregator\n    shutdown    chan struct{}\n    wg          sync.WaitGroup\n}\n\n// FlagExposure represents a single flag evaluation event for analytics\ntype FlagExposure struct {\n    EventID      string      `json:\"event_id\"`\n    FlagKey      FlagKey     `json:\"flag_key\"`\n    UserID       UserID      `json:\"user_id\"`\n    Variant      string      `json:\"variant\"`\n    Value        interface{} `json:\"value\"`\n    UserContext  UserContext `json:\"user_context\"`\n    Timestamp    time.Time   `json:\"timestamp\"`\n    Source       string      `json:\"source\"`\n    Reason       string      `json:\"reason\"`\n    ExperimentID string      `json:\"experiment_id,omitempty\"`\n    SessionID    string      `json:\"session_id,omitempty\"`\n    RequestID    string      `json:\"request_id,omitempty\"`\n}\n\n// RecordExposure submits a flag evaluation event to the analytics pipeline\nfunc (et *ExposureTracker) RecordExposure(exposure FlagExposure) error {\n    // TODO 1: Generate unique event ID and timestamp if not provided\n    // TODO 2: Validate exposure data (required fields, valid flag key, etc.)\n    // TODO 3: Submit exposure to queue channel (non-blocking with timeout)\n    // TODO 4: Return error if queue is full or tracker is shutting down\n    // Hint: Use select with default case to avoid blocking on full queue\n}\n\n// StartProcessing begins the background exposure processing pipeline\nfunc (et *ExposureTracker) StartProcessing() {\n    // TODO 1: Start goroutine for batch processing from queue\n    // TODO 2: Collect exposures into batches based on count and time\n    // TODO 3: Write batches to persistent storage with retry logic\n    // TODO 4: Update real-time aggregations for dashboard queries\n    // TODO 5: Handle graceful shutdown when shutdown channel is closed\n}\n```\n\n**Experiment Framework Core**\n\n```go\n// ExperimentManager handles A/B test lifecycle and statistical analysis\ntype ExperimentManager struct {\n    storage     ExperimentStorage\n    assignments AssignmentStorage\n    calculator  *SignificanceCalculator\n    mu          sync.RWMutex\n}\n\n// Experiment represents a controlled A/B test with statistical parameters\ntype Experiment struct {\n    ExperimentID      string              `json:\"experiment_id\"`\n    Name              string              `json:\"name\"`\n    Hypothesis        string              `json:\"hypothesis\"`\n    FlagKey           FlagKey             `json:\"flag_key\"`\n    Variants          []ExperimentVariant `json:\"variants\"`\n    PrimaryMetric     string              `json:\"primary_metric\"`\n    SecondaryMetrics  []string            `json:\"secondary_metrics\"`\n    StartDate         time.Time           `json:\"start_date\"`\n    EndDate           *time.Time          `json:\"end_date,omitempty\"`\n    MinSampleSize     int                 `json:\"min_sample_size\"`\n    SignificanceLevel float64             `json:\"significance_level\"`\n    PowerLevel        float64             `json:\"power_level\"`\n    TargetingRules    []TargetingRule     `json:\"targeting_rules\"`\n    Status            string              `json:\"status\"`\n}\n\n// ExperimentVariant defines a treatment condition within an A/B test\ntype ExperimentVariant struct {\n    Key           string      `json:\"key\"`\n    Name          string      `json:\"name\"`\n    Description   string      `json:\"description\"`\n    Allocation    float64     `json:\"allocation\"`\n    Configuration interface{} `json:\"configuration\"`\n    IsControl     bool        `json:\"is_control\"`\n}\n\n// CreateExperiment initializes a new A/B test with statistical validation\nfunc (em *ExperimentManager) CreateExperiment(experiment Experiment) error {\n    // TODO 1: Validate experiment configuration (allocation sum = 1.0, etc.)\n    // TODO 2: Perform power analysis to determine required sample sizes\n    // TODO 3: Check that associated flag exists and is compatible\n    // TODO 4: Create experiment record with \"draft\" status\n    // TODO 5: Generate experiment assignment hash seed for consistency\n}\n\n// AssignUserToVariant determines which variant a user should see\nfunc (em *ExperimentManager) AssignUserToVariant(experimentID string, userID UserID, context UserContext) (string, error) {\n    // TODO 1: Check if user has existing assignment for this experiment\n    // TODO 2: If no existing assignment, check experiment eligibility rules\n    // TODO 3: Use consistent hashing to assign user to variant\n    // TODO 4: Persist assignment record for consistency\n    // TODO 5: Return assigned variant key\n}\n```\n\n**Statistical Significance Calculator**\n\n```go\n// SignificanceCalculator performs statistical analysis of experiment results\ntype SignificanceCalculator struct {\n    storage ExperimentStorage\n}\n\n// SignificanceResult contains complete statistical analysis of an experiment\ntype SignificanceResult struct {\n    ExperimentID        string                `json:\"experiment_id\"`\n    MetricName          string                `json:\"metric_name\"`\n    AnalysisTime        time.Time             `json:\"analysis_time\"`\n    VariantResults      []VariantStatistics   `json:\"variant_results\"`\n    Comparisons         []PairwiseComparison  `json:\"comparisons\"`\n    OverallSignificant  bool                  `json:\"overall_significant\"`\n    RecommendedAction   string                `json:\"recommended_action\"`\n    SampleSizeAdequate  bool                  `json:\"sample_size_adequate\"`\n    SampleRatioMismatch bool                  `json:\"sample_ratio_mismatch\"`\n    ConfidenceLevel     float64               `json:\"confidence_level\"`\n    AnalysisMethod      string                `json:\"analysis_method\"`\n}\n\n// VariantStatistics provides detailed statistical measures for a single variant\ntype VariantStatistics struct {\n    Variant              string            `json:\"variant\"`\n    SampleSize           int64             `json:\"sample_size\"`\n    ConversionCount      int64             `json:\"conversion_count\"`\n    ConversionRate       float64           `json:\"conversion_rate\"`\n    StandardError        float64           `json:\"standard_error\"`\n    ConfidenceInterval   ConfidenceInterval `json:\"confidence_interval\"`\n    ZScore               float64           `json:\"z_score\"`\n    RelativeImprovement  float64           `json:\"relative_improvement\"`\n}\n\n// CalculateSignificance performs complete statistical analysis of experiment results\nfunc (sc *SignificanceCalculator) CalculateSignificance(experimentID string) (SignificanceResult, error) {\n    // TODO 1: Retrieve experiment configuration and current sample sizes\n    // TODO 2: Check for sample ratio mismatch using chi-square test\n    // TODO 3: Calculate conversion rates and confidence intervals per variant\n    // TODO 4: Perform pairwise significance tests between variants\n    // TODO 5: Apply multiple comparison corrections if needed\n    // TODO 6: Generate actionable recommendations based on results\n    // Hint: Use z-test for conversion rate comparisons\n}\n\n// DetectSampleRatioMismatch checks if variant assignments match intended ratios\nfunc (sc *SignificanceCalculator) DetectSampleRatioMismatch(experimentID string) (bool, float64, error) {\n    // TODO 1: Get intended allocation ratios from experiment configuration\n    // TODO 2: Count actual user assignments per variant\n    // TODO 3: Calculate expected counts based on total sample and ratios\n    // TODO 4: Compute chi-square test statistic\n    // TODO 5: Return mismatch flag and p-value\n    // Hint: Chi-square = Σ((observed - expected)² / expected)\n}\n```\n\n**Database Schema**\n\n```sql\n-- Flag exposure events for detailed analytics\nCREATE TABLE flag_exposures (\n    event_id VARCHAR(36) PRIMARY KEY,\n    flag_key VARCHAR(255) NOT NULL,\n    user_id VARCHAR(255) NOT NULL,\n    variant VARCHAR(255) NOT NULL,\n    value JSONB,\n    user_context JSONB NOT NULL,\n    timestamp TIMESTAMP WITH TIME ZONE NOT NULL,\n    source VARCHAR(50) NOT NULL,\n    reason VARCHAR(255) NOT NULL,\n    experiment_id VARCHAR(36),\n    session_id VARCHAR(255),\n    request_id VARCHAR(255),\n    INDEX idx_flag_exposures_flag_time (flag_key, timestamp),\n    INDEX idx_flag_exposures_user_time (user_id, timestamp),\n    INDEX idx_flag_exposures_experiment (experiment_id, timestamp)\n);\n\n-- Experiment definitions and configuration\nCREATE TABLE experiments (\n    experiment_id VARCHAR(36) PRIMARY KEY,\n    name VARCHAR(255) NOT NULL,\n    hypothesis TEXT,\n    flag_key VARCHAR(255) NOT NULL,\n    variants JSONB NOT NULL,\n    primary_metric VARCHAR(255) NOT NULL,\n    secondary_metrics JSONB,\n    start_date TIMESTAMP WITH TIME ZONE NOT NULL,\n    end_date TIMESTAMP WITH TIME ZONE,\n    min_sample_size INTEGER NOT NULL,\n    significance_level DECIMAL(4,3) NOT NULL DEFAULT 0.05,\n    power_level DECIMAL(4,3) NOT NULL DEFAULT 0.8,\n    targeting_rules JSONB,\n    status VARCHAR(50) NOT NULL DEFAULT 'draft',\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n);\n\n-- Persistent user variant assignments for experiments\nCREATE TABLE experiment_assignments (\n    experiment_id VARCHAR(36) NOT NULL,\n    user_id VARCHAR(255) NOT NULL,\n    variant VARCHAR(255) NOT NULL,\n    assignment_time TIMESTAMP WITH TIME ZONE NOT NULL,\n    first_exposure TIMESTAMP WITH TIME ZONE,\n    last_exposure TIMESTAMP WITH TIME ZONE,\n    exposure_count INTEGER DEFAULT 0,\n    PRIMARY KEY (experiment_id, user_id),\n    INDEX idx_assignments_experiment_variant (experiment_id, variant),\n    INDEX idx_assignments_user (user_id, assignment_time)\n);\n```\n\n**Milestone Checkpoint**\n\nAfter implementing the analytics and A/B testing framework:\n\n1. **Test Exposure Tracking**: \n   - Run flag evaluations and verify exposure events appear in the database\n   - Check that exposure events contain complete context information\n   - Confirm that high evaluation throughput doesn't block on analytics\n\n2. **Validate Experiment Assignment**:\n   - Create an experiment with 50/50 allocation between two variants\n   - Assign 1000 test users and verify the allocation ratio is approximately correct\n   - Confirm that users receive the same variant on repeat assignments\n\n3. **Verify Statistical Calculations**:\n   - Generate synthetic experiment data with known effect sizes\n   - Run significance calculations and verify they detect the expected differences\n   - Test sample ratio mismatch detection with intentionally skewed allocations\n\nExpected behavior: The system should handle thousands of exposure events per second while maintaining assignment consistency and producing accurate statistical analysis. Dashboard queries should complete in under 500ms even with millions of exposure events.\n\n\n## Interactions and Data Flow\n\n> **Milestone(s):** This section spans all three milestones by describing the communication patterns and data flows that connect the Flag Evaluation Engine (Milestone 1), Real-time Flag Updates (Milestone 2), and Flag Analytics & Experiments (Milestone 3) into a cohesive system.\n\nThink of the feature flag system as **a sophisticated air traffic control tower** managing multiple types of aircraft movements simultaneously. The evaluation flow is like guiding incoming flights through a series of checkpoints—checking flight credentials, runway availability, and weather conditions—before assigning them to specific gates. The update propagation flow resembles broadcasting critical weather updates or runway changes to all aircraft in the system, ensuring they adjust their flight plans in real-time. Just as air traffic control maintains constant communication between the control tower, radar systems, and aircraft, our feature flag system orchestrates seamless interactions between the management interface, evaluation engine, real-time update service, and distributed client SDKs.\n\nThe interactions and data flow represent the **nervous system** of the feature flag platform, connecting decision-making components with data sources and ensuring consistent behavior across all system boundaries. Understanding these flows is crucial because feature flags must provide both **immediate consistency** for flag evaluations and **eventual consistency** for configuration updates, while maintaining high availability and low latency under varying load conditions.\n\nThis section examines two critical interaction patterns that define the system's operational behavior: the **flag evaluation flow** that processes individual user requests and returns targeted variants, and the **update propagation flow** that distributes configuration changes across all connected clients. These flows represent the primary data pathways through which the system delivers its core value proposition of controlled feature rollouts and real-time configuration management.\n\n![Flag Evaluation Sequence](./diagrams/evaluation-flow.svg)\n\n![Flag Update Propagation](./diagrams/update-propagation.svg)\n\n### Flag Evaluation Flow\n\nThe flag evaluation flow represents the **critical path** through which user requests are processed and appropriate feature variants are assigned. This flow must operate with **sub-millisecond latency** while maintaining consistency guarantees and supporting complex targeting logic. Think of this process as a **sophisticated sorting machine** that examines each user request through multiple lenses—user attributes, segment membership, percentage allocations, and experimental assignments—before directing them to the appropriate feature experience.\n\nThe evaluation flow begins when a client SDK receives a request to evaluate a specific flag for a given user context. This triggers a carefully orchestrated sequence of operations that balance **performance requirements** with **correctness guarantees**. The flow must handle scenarios ranging from simple boolean toggles to complex multi-variate experiments with intricate targeting rules, all while ensuring that users receive consistent assignments across multiple evaluations.\n\nUnderstanding the evaluation flow is essential for implementing proper **caching strategies**, **fallback mechanisms**, and **performance optimizations**. The flow also establishes the foundation for flag analytics by generating exposure events that track which users see which variants under what conditions. Every step in this flow represents a potential **decision point** where the system must choose between different variants, making the logic both critically important and inherently complex.\n\n#### Step-by-Step Evaluation Process\n\nThe flag evaluation process follows a deterministic sequence that ensures consistent results while accommodating various edge cases and error conditions. Each step in this process serves a specific purpose in the overall targeting and assignment logic:\n\n1. **Request Validation and Context Preparation**: The client SDK receives an evaluation request containing a `FlagKey` and `UserContext`. The SDK validates that the user context contains required fields (`UserID` is non-empty, `Attributes` map is properly formatted) and enriches the context with any cached segment memberships or computed attributes. Invalid contexts trigger immediate fallback value returns with appropriate error reasons.\n\n2. **Cache Lookup and Freshness Verification**: The evaluation engine attempts to retrieve the flag definition from its local cache using `GetFlag(flagKey)`. The cache lookup includes timestamp verification to ensure the cached definition hasn't exceeded its time-to-live threshold. Cache hits proceed directly to rule evaluation, while cache misses trigger background refresh operations but continue with stale data if available to maintain low latency.\n\n3. **Flag Existence and Status Verification**: If the flag definition is found, the engine verifies that the flag is in an active state and hasn't been archived or deleted. Inactive flags return their configured default values with an appropriate reason code. This step also checks for any flag prerequisites or dependencies that must be satisfied before evaluation can proceed.\n\n4. **User Context Enrichment and Segment Resolution**: The engine enhances the provided user context with any missing segment memberships by evaluating segment rules against user attributes. This step is **computationally expensive** but can be optimized through pre-computed segment caches or background segment resolution processes. The enriched context becomes the input for subsequent targeting rule evaluation.\n\n5. **Targeting Rule Evaluation with Precedence Ordering**: The engine processes targeting rules in priority order using `evaluateTargetingRules(rules, context)`. Each rule consists of conditions that are evaluated using `evaluateRuleConditions(conditions, operator, context)` with proper AND/OR logic. The first rule that matches determines the variant assignment, making rule ordering critically important for correct behavior.\n\n6. **Percentage Rollout Processing with Consistent Hashing**: If no targeting rules match, the engine falls back to percentage rollout logic. It calculates the user's bucket assignment using `calculateUserBucket(userID, flagKey)` and determines which variant allocation range contains that bucket. This ensures that users receive consistent assignments across multiple evaluations while respecting the configured percentage distributions.\n\n7. **Variant Value Resolution and Type Coercion**: Once the target variant is determined, the engine resolves the actual variant value from the flag definition. This may involve type coercion (converting stored JSON values to appropriate types), template variable substitution, or other value transformation logic depending on the flag type and configuration.\n\n8. **Exposure Event Generation and Analytics Tracking**: The successful evaluation triggers the creation of a `FlagExposure` event that captures all relevant context about the evaluation decision. This event is queued for asynchronous processing using `RecordExposure(exposure)` to avoid impacting evaluation latency while ensuring comprehensive analytics tracking.\n\n9. **Result Packaging and Return**: The engine constructs an `EvaluationResult` containing the resolved value, selected variant key, evaluation reason (which rule matched or percentage allocation), and source attribution. This result is returned to the client SDK and may be cached locally for subsequent evaluations of the same flag-user combination.\n\n> **Design Insight**: The evaluation flow prioritizes **deterministic behavior** over performance optimization. Each step produces predictable outputs for given inputs, ensuring that debugging and troubleshooting can trace exactly why a user received a specific variant. This determinism is crucial for maintaining trust in feature rollouts and experiment validity.\n\n#### Caching and Performance Optimization\n\nThe evaluation flow incorporates **multi-level caching** to achieve target latency requirements while maintaining data consistency. The caching strategy must balance fresh data with performance, particularly for high-traffic applications where flag evaluations occur thousands of times per second.\n\n**Flag Definition Caching** represents the first level of optimization, where complete flag configurations are cached in memory after retrieval from the primary data store. These caches use **time-based expiration** combined with **event-driven invalidation** to ensure reasonable freshness while avoiding excessive database queries. The cache maintains version timestamps that enable **optimistic locking** when updates occur.\n\n**User Context Caching** provides the second optimization layer by storing computed segment memberships and derived attributes for frequently seen users. Since segment evaluation can be computationally expensive (requiring multiple attribute checks and rule processing), caching these results significantly improves evaluation performance. The cache uses **LRU eviction** to manage memory consumption while prioritizing recently active users.\n\n**Evaluation Result Caching** represents an optional third layer where complete evaluation results are cached for specific flag-user combinations. This optimization is most effective for **low-variance flags** (where most users receive the same result) but must be carefully managed to avoid serving stale results when flag configurations change. Result caches require **immediate invalidation** when flag definitions are updated.\n\nThe caching architecture includes **cache warming** mechanisms that pre-populate frequently accessed flags and user contexts during application startup or low-traffic periods. This warming process reduces **cold start penalties** and ensures consistent performance during traffic spikes.\n\n#### Error Handling and Fallback Logic\n\nThe evaluation flow must handle various error conditions gracefully while maintaining system availability and providing meaningful feedback for debugging purposes. The error handling strategy emphasizes **fail-safe behavior** where evaluation errors result in sensible default values rather than complete request failures.\n\n**Network and Service Failures** are handled through **graceful degradation** where the evaluation engine continues operating with cached data even when the primary flag management service becomes unavailable. The engine maintains **staleness indicators** that help clients understand the freshness of cached data and make appropriate decisions about feature behavior.\n\n**Malformed Flag Definitions** trigger **validation errors** that prevent the flag from being cached or evaluated, but don't impact other flags in the system. The validation process includes **schema checking**, **circular dependency detection**, and **rule consistency verification** to catch configuration errors before they affect user experiences.\n\n**User Context Errors** (missing required attributes, invalid data types, or malformed segment references) are handled through **context sanitization** and **default value substitution**. The evaluation engine attempts to proceed with available context information while logging detailed error information for debugging purposes.\n\n**Targeting Rule Failures** that occur during evaluation (such as division by zero in percentage calculations or invalid regular expressions in condition matching) cause the specific rule to be skipped and evaluation to continue with subsequent rules. This **rule-level isolation** prevents individual misconfigured rules from breaking entire flag evaluations.\n\n#### Common Pitfalls in Evaluation Flow\n\n⚠️ **Pitfall: Inconsistent User Bucket Calculations**\nMany implementations suffer from **bucket assignment drift** where users flip between different variants due to inconsistent hashing algorithms or input normalization. This occurs when the bucketing logic uses floating-point arithmetic with rounding errors, includes unstable user attributes in the hash input, or fails to normalize string attributes consistently. To avoid this issue, use **integer-based consistent hashing** with stable, normalized inputs that include only the user ID and flag key. Implement comprehensive tests that verify bucket assignments remain stable across multiple evaluation calls.\n\n⚠️ **Pitfall: Cache Invalidation Race Conditions**\nRace conditions in cache invalidation can cause **temporary inconsistencies** where some evaluation requests use old flag definitions while others use updated definitions. This typically happens when cache invalidation events arrive out of order or when multiple cache layers aren't updated atomically. Implement **versioned caching** with **optimistic concurrency control** where each cache entry includes a version timestamp, and invalidation events specify the minimum version that should be evicted.\n\n⚠️ **Pitfall: Context Pollution from Previous Evaluations**\nReusing `UserContext` objects across multiple evaluations can lead to **context pollution** where computed values (like resolved segment memberships) from previous evaluations influence subsequent ones. This creates subtle bugs where flag evaluations appear to depend on the order of previous evaluations. Always **deep copy** or **reset** user context objects between evaluations, and clearly separate provided attributes from computed values.\n\n### Update Propagation Flow\n\nThe update propagation flow represents the **distribution backbone** that ensures flag configuration changes reach all connected clients promptly and consistently. Think of this flow as a **sophisticated broadcast network** similar to how emergency alert systems simultaneously notify all receivers of critical updates—the system must deliver messages quickly, handle network partitions gracefully, and ensure no client is left with outdated information that could impact user experiences.\n\nThe update propagation flow begins when flag configurations are modified through the management interface and concludes when all connected client SDKs have applied the new configuration and invalidated relevant caches. This flow must handle scenarios ranging from simple flag toggles that need immediate deployment to complex targeting rule changes that require careful coordination across distributed client populations.\n\nThe propagation flow serves as the **consistency mechanism** that prevents the system from exhibiting different behaviors across different clients or geographic regions. Without proper update propagation, users could experience **inconsistent feature experiences** where the same action produces different results depending on which server handles their request or which SDK version they're using. This consistency is particularly critical for experiment integrity and user experience quality.\n\nUnderstanding the update propagation flow is essential for implementing proper **change management**, **rollback capabilities**, and **deployment strategies**. The flow establishes the foundation for **operational safety** by ensuring that configuration changes can be applied, monitored, and reverted in a controlled manner across the entire distributed system.\n\n#### Propagation Sequence and Timing\n\nThe update propagation process follows a carefully orchestrated sequence designed to minimize **inconsistency windows** while maintaining system performance and reliability. Each stage in the propagation process serves specific purposes in the overall change management strategy:\n\n1. **Change Validation and Staging**: When a flag modification is submitted through the management API using `UpdateFlag(flag)`, the system performs comprehensive validation including schema verification, rule consistency checking, and dependency analysis. The validated change is staged in a **pending state** before being committed to the primary data store, allowing for additional approval workflows or automated safety checks.\n\n2. **Primary Storage Update with Versioning**: The validated flag configuration is committed to the primary data store with an incremented version number and change metadata. This update is performed atomically to ensure that partial updates don't create inconsistent states. The storage layer generates a **change event** that includes the flag key, change type (create, update, delete), and version information.\n\n3. **Change Event Broadcasting via Real-time Service**: The real-time update service detects the storage change and generates a `FlagUpdateEvent` that is broadcast to all connected clients using `BroadcastFlagUpdate(flagKey, payload, changeType)`. The broadcast uses **Server-Sent Events** or **WebSocket connections** to deliver the change notification with minimal latency, typically within 100-500 milliseconds of the original modification.\n\n4. **Client-side Change Reception and Validation**: Connected client SDKs receive the update notification through their persistent connections and validate the change event format and version information. Clients verify that the received change is newer than their current cached version to prevent **regression issues** where older changes overwrite newer ones due to network delays or message reordering.\n\n5. **Local Cache Invalidation and Refresh**: Each client SDK applies the received update using `ApplyFlagUpdate(event)`, which invalidates the locally cached flag definition and either applies the new configuration immediately or marks it for **lazy loading** on the next evaluation request. The invalidation process must handle **concurrent evaluations** that might be using the old cached data.\n\n6. **Background Refresh and Verification**: Clients that don't have persistent connections (such as mobile applications or batch processing systems) discover changes through **background polling** or **SDK initialization** processes. These clients compare their cached flag versions with the current server versions and fetch updated configurations as needed, ensuring eventual consistency even without real-time connections.\n\n7. **Propagation Confirmation and Monitoring**: The update service tracks which clients have acknowledged receipt of change notifications and maintains **propagation metrics** that indicate how quickly changes are spreading through the client population. This monitoring enables **rollback decisions** if propagation failures or adverse effects are detected during the rollout process.\n\n8. **Stale Cache Detection and Cleanup**: The system includes **background processes** that identify clients serving stale flag configurations (perhaps due to persistent connection failures or implementation bugs) and takes corrective action such as forcing cache invalidation or alerting operations teams about potentially inconsistent deployments.\n\n> **Design Insight**: The propagation flow implements **optimistic consistency** where changes are applied immediately to the primary store and distributed asynchronously to clients. This approach minimizes **write latency** for flag modifications while accepting brief **read inconsistency** windows during propagation. The trade-off favors operational agility over perfect consistency, which aligns with feature flag use cases where brief inconsistencies are generally acceptable.\n\n#### Connection Management and Message Delivery\n\nThe update propagation system must maintain **persistent connections** with potentially thousands of client SDKs while handling network instabilities, client failures, and varying connection qualities. The connection management strategy balances **resource efficiency** with **delivery reliability** to ensure that critical flag changes reach all intended recipients.\n\n**Connection Lifecycle Management** begins when client SDKs establish connections to the real-time update service using `Connect(ctx)` with **exponential backoff** retry logic. Each connection is assigned a unique client identifier and tracked in the service's connection registry. The service monitors connection health through **heartbeat mechanisms** and **activity tracking** to detect failed or stale connections that should be cleaned up.\n\n**Message Buffering and Replay** ensures that clients reconnecting after network interruptions receive any flag changes that occurred during their absence. The update service maintains a **sliding window buffer** of recent change events using `sendReplayEvents(client)` to deliver missed updates when clients reconnect. The buffer size and retention period are configurable based on system requirements and client reconnection patterns.\n\n**Delivery Confirmation and Retry Logic** provides **at-least-once delivery** guarantees for critical flag changes. Clients send **acknowledgment messages** when they successfully apply flag updates, allowing the service to track delivery success rates and identify problematic connections or clients. Failed deliveries trigger **retry attempts** with appropriate backoff delays to avoid overwhelming struggling clients.\n\n**Load Balancing and Scaling** accommodates varying client populations by distributing connections across multiple update service instances. The system uses **consistent hashing** or **connection affinity** strategies to ensure that clients maintain connections with specific service instances while supporting **graceful failover** when instances become unavailable.\n\n**Message Ordering and Deduplication** prevents **out-of-order updates** that could cause clients to apply older flag configurations after newer ones. Each change event includes **sequence numbers** and **version timestamps** that clients use to detect and discard outdated messages. The system also implements **deduplication logic** to prevent clients from processing the same change multiple times due to retry mechanisms.\n\n#### Network Partition and Recovery Handling\n\nThe update propagation system must continue operating effectively during **network partitions**, **service outages**, and **client isolation events** that prevent normal real-time communication. The recovery handling strategy ensures that system consistency is eventually restored without requiring manual intervention or complex reconciliation procedures.\n\n**Partition Detection and Isolation** occurs when the update service loses connectivity with client populations due to network infrastructure failures or geographic connectivity issues. The service detects these partitions through **connection monitoring**, **heartbeat timeouts**, and **message delivery failure patterns**. Isolated client populations continue operating with their cached flag configurations while the partition persists.\n\n**Autonomous Client Operation** enables client SDKs to continue providing flag evaluation services using their **local flag caches** even when disconnected from the update service. Clients maintain **cache timestamps** and **staleness indicators** that help application code make informed decisions about whether cached flag data is still reliable for business-critical features.\n\n**Reconciliation After Recovery** involves **state synchronization** processes that execute when network connectivity is restored after partition events. Clients compare their cached flag versions with current server versions using **bulk version check** APIs and download updated configurations for any flags that changed during the partition. This reconciliation process uses **batching** and **rate limiting** to avoid overwhelming the service during mass reconnection events.\n\n**Conflict Resolution and Consistency Repair** addresses scenarios where **configuration conflicts** or **inconsistent states** are detected during recovery processes. The system implements **server-authoritative** conflict resolution where server-side flag configurations always take precedence over client-side cached data, ensuring that inconsistencies are resolved in favor of the most recent management decisions.\n\n**Progressive Rollout During Recovery** provides **controlled recovery** mechanisms that gradually restore normal operation rather than immediately resuming full-scale update propagation. The service can implement **traffic shaping** and **connection throttling** to prevent **thundering herd** effects when large client populations attempt to reconnect simultaneously after widespread network issues.\n\n#### Change Impact Analysis and Safety Mechanisms\n\nThe update propagation flow includes **safety mechanisms** and **impact analysis** capabilities that help prevent problematic flag changes from causing widespread system issues or user experience degradation. These mechanisms provide **operational safety nets** that enable confident flag management even in complex, high-stakes environments.\n\n**Pre-propagation Impact Assessment** analyzes proposed flag changes to estimate their **blast radius** and potential system impact before changes are propagated to client populations. This analysis considers factors such as the number of users affected, the scope of feature changes, and dependencies on other system components to help operations teams make informed rollout decisions.\n\n**Gradual Propagation and Circuit Breakers** enable **controlled rollouts** where flag changes are initially propagated to small subsets of the client population before broader deployment. The system monitors **error rates**, **performance metrics**, and **user experience indicators** during initial propagation phases and can **halt or rollback** the propagation process if adverse effects are detected.\n\n**Automatic Rollback Triggers** provide **fail-safe mechanisms** that automatically revert flag changes when predefined **safety thresholds** are exceeded. These triggers might include error rate spikes, performance degradation beyond acceptable limits, or explicit user experience metrics that indicate negative impact from the flag change.\n\n**Change Approval and Gating** implements **workflow controls** that require appropriate approvals before high-impact flag changes are propagated to production client populations. The approval process can include **automated testing**, **peer review**, **stakeholder sign-off**, and **deployment scheduling** to ensure that changes are applied safely and with appropriate coordination.\n\n**Propagation Monitoring and Alerting** provides **real-time visibility** into the change distribution process, enabling operations teams to detect and respond to propagation issues quickly. The monitoring includes **delivery success rates**, **client acknowledgment patterns**, **error distributions**, and **consistency metrics** that indicate the health and effectiveness of the update propagation system.\n\n#### Common Pitfalls in Update Propagation\n\n⚠️ **Pitfall: Thundering Herd During Mass Reconnection**\nWhen many clients lose connectivity and then reconnect simultaneously (such as during network outages or service restarts), they can overwhelm the update service with **concurrent connection attempts** and **bulk update requests**. This creates a **thundering herd effect** that can cause the service to become unavailable, preventing successful reconnection and creating a cascade failure. Implement **exponential backoff with jitter** using `calculateBackoffDelay()` where each client waits a randomized delay before attempting reconnection, and use **connection rate limiting** on the server side to control the maximum concurrent connection establishment rate.\n\n⚠️ **Pitfall: Message Ordering Violations During High Load**\nUnder high load or during network congestion, flag update messages can arrive **out of order** at client SDKs, causing them to apply older flag configurations after newer ones. This creates **temporal inconsistency** where clients regress to previous flag states unpredictably. Implement **sequence number validation** where each update message includes a monotonically increasing sequence number using `generateEventID()`, and clients discard any messages with sequence numbers lower than the most recently processed message.\n\n⚠️ **Pitfall: Infinite Propagation Loops from Circular Dependencies**\nWhen flag changes trigger other flag changes (through computed dependencies or automated reactions), the system can enter **infinite propagation loops** that overwhelm the update infrastructure and prevent normal operation. This often occurs when **A/B testing flags** automatically trigger **feature flags** that in turn influence **configuration flags** in circular patterns. Implement **propagation depth limits** and **change cycle detection** that tracks the **causal chain** of flag changes and prevents updates that would create circular dependencies or exceed reasonable propagation depths.\n\n### Implementation Guidance\n\nThe interactions and data flow implementation requires careful coordination between multiple system components while maintaining performance and reliability guarantees. The following guidance provides practical approaches for implementing robust evaluation and propagation flows.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Evaluation Engine | In-memory map with RWMutex (sync.RWMutex) | Distributed cache with Redis Cluster |\n| Real-time Updates | Server-Sent Events with net/http | WebSocket with gorilla/websocket + message queuing |\n| Message Serialization | JSON with encoding/json | Protocol Buffers with gogo/protobuf |\n| Connection Management | Basic HTTP keepalive | Connection pooling with circuit breakers |\n| Event Streaming | Simple broadcast to all clients | Pub/sub with message persistence (NATS, Apache Kafka) |\n| Cache Layer | Local in-memory cache | Multi-tier with Redis + local LRU |\n| Metrics Collection | Basic counters with expvar | Prometheus metrics with custom collectors |\n| Background Processing | Simple goroutines | Worker pool with github.com/gammazero/workerpool |\n\n#### Recommended File Structure\n\n```\ninternal/\n  evaluation/\n    engine.go              ← Core evaluation logic\n    engine_test.go         ← Evaluation flow tests\n    cache.go               ← Multi-level caching implementation\n    context.go             ← User context handling\n    bucket.go              ← Consistent hashing logic\n  realtime/\n    server.go              ← SSE/WebSocket server\n    client.go              ← Client connection management\n    broadcast.go           ← Update propagation logic\n    reconnect.go           ← Recovery and retry logic\n  analytics/\n    tracker.go             ← Exposure event tracking\n    aggregator.go          ← Real-time metrics aggregation\n  flows/\n    evaluation_flow.go     ← Complete evaluation orchestration\n    propagation_flow.go    ← Update distribution coordination\n    flows_test.go          ← Integration tests for complete flows\n```\n\n#### Evaluation Flow Infrastructure\n\n```go\npackage flows\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"sync\"\n    \"time\"\n    \n    \"github.com/your-org/flagsystem/internal/evaluation\"\n    \"github.com/your-org/flagsystem/internal/analytics\"\n)\n\n// EvaluationOrchestrator coordinates the complete flag evaluation flow\ntype EvaluationOrchestrator struct {\n    engine       *evaluation.Engine\n    cache        *evaluation.FlagCache\n    tracker      *analytics.ExposureTracker\n    validator    *evaluation.ContextValidator\n    mu           sync.RWMutex\n    metrics      *EvaluationMetrics\n}\n\n// EvaluationMetrics tracks performance and behavior of evaluation flows\ntype EvaluationMetrics struct {\n    TotalEvaluations    int64\n    CacheHits          int64\n    CacheMisses        int64\n    EvaluationLatency  time.Duration\n    ErrorCount         int64\n    mu                 sync.RWMutex\n}\n\n// NewEvaluationOrchestrator creates a complete evaluation flow handler\nfunc NewEvaluationOrchestrator(engine *evaluation.Engine, cache *evaluation.FlagCache, tracker *analytics.ExposureTracker) *EvaluationOrchestrator {\n    return &EvaluationOrchestrator{\n        engine:    engine,\n        cache:     cache,\n        tracker:   tracker,\n        validator: evaluation.NewContextValidator(),\n        metrics:   &EvaluationMetrics{},\n    }\n}\n\n// ProcessEvaluationRequest handles the complete evaluation flow from request to response\nfunc (e *EvaluationOrchestrator) ProcessEvaluationRequest(ctx context.Context, flagKey FlagKey, userCtx UserContext) (*EvaluationResult, error) {\n    startTime := time.Now()\n    defer func() {\n        e.metrics.mu.Lock()\n        e.metrics.TotalEvaluations++\n        e.metrics.EvaluationLatency = time.Since(startTime)\n        e.metrics.mu.Unlock()\n    }()\n    \n    // TODO 1: Validate user context using e.validator.ValidateUserContext(userCtx)\n    // TODO 2: Attempt cache lookup using e.cache.GetFlag(flagKey)  \n    // TODO 3: If cache miss, fetch from primary store and update cache\n    // TODO 4: Enrich user context with segment memberships\n    // TODO 5: Execute core evaluation using e.engine.EvaluateFlag(flagKey, enrichedCtx)\n    // TODO 6: Generate exposure event and queue using e.tracker.RecordExposure()\n    // TODO 7: Update evaluation metrics and return result\n    \n    // Placeholder return - implement the actual flow\n    return &EvaluationResult{\n        FlagKey: flagKey,\n        Value:   false,\n        Variant: \"default\",\n        Reason:  \"not_implemented\",\n        Source:  \"cache\",\n    }, nil\n}\n```\n\n#### Real-time Update Infrastructure\n\n```go\npackage realtime\n\nimport (\n    \"encoding/json\"\n    \"fmt\"\n    \"net/http\"\n    \"sync\"\n    \"time\"\n)\n\n// UpdatePropagationService manages the complete update distribution flow\ntype UpdatePropagationService struct {\n    sseServer     *SSEServer\n    clients       map[string]*ClientConnection\n    eventBuffer   []FlagUpdateEvent\n    bufferSize    int\n    mu            sync.RWMutex\n    metrics       *PropagationMetrics\n}\n\n// PropagationMetrics tracks update distribution performance\ntype PropagationMetrics struct {\n    ActiveConnections    int64\n    MessagesSent        int64\n    DeliveryFailures    int64\n    ReconnectionCount   int64\n    PropagationLatency  time.Duration\n}\n\n// ClientConnection represents a connected SDK client\ntype ClientConnection struct {\n    ID            string\n    LastSeen      time.Time\n    Connection    *SSEClient\n    PendingAcks   map[string]time.Time\n    mu            sync.Mutex\n}\n\n// NewUpdatePropagationService creates the complete propagation flow handler\nfunc NewUpdatePropagationService(bufferSize int) *UpdatePropagationService {\n    return &UpdatePropagationService{\n        sseServer:   NewSSEServer(),\n        clients:     make(map[string]*ClientConnection),\n        eventBuffer: make([]FlagUpdateEvent, 0, bufferSize),\n        bufferSize:  bufferSize,\n        metrics:     &PropagationMetrics{},\n    }\n}\n\n// PropagateChange handles the complete flow from flag change to client delivery\nfunc (u *UpdatePropagationService) PropagateChange(flagKey string, changeType string, payload interface{}) error {\n    startTime := time.Now()\n    \n    // TODO 1: Create FlagUpdateEvent with unique ID and timestamp\n    // TODO 2: Add event to buffer for replay to reconnecting clients\n    // TODO 3: Broadcast to all active connections using u.sseServer.BroadcastFlagUpdate()\n    // TODO 4: Track delivery confirmations and retry failed deliveries\n    // TODO 5: Update propagation metrics with timing and success rates\n    // TODO 6: Handle buffer overflow by removing oldest events\n    \n    event := FlagUpdateEvent{\n        EventType:   \"flag_update\",\n        EventID:     u.generateEventID(),\n        Timestamp:   time.Now(),\n        FlagKey:     flagKey,\n        Payload:     payload,\n        ChangeType:  changeType,\n    }\n    \n    // Placeholder implementation - complete the propagation logic\n    u.mu.Lock()\n    defer u.mu.Unlock()\n    \n    u.eventBuffer = append(u.eventBuffer, event)\n    u.metrics.PropagationLatency = time.Since(startTime)\n    \n    return nil\n}\n\n// HandleClientConnection manages the complete connection lifecycle\nfunc (u *UpdatePropagationService) HandleClientConnection(w http.ResponseWriter, r *http.Request) {\n    clientID := r.Header.Get(\"Client-ID\")\n    if clientID == \"\" {\n        http.Error(w, \"Client-ID header required\", http.StatusBadRequest)\n        return\n    }\n    \n    // TODO 1: Establish SSE connection with proper headers\n    // TODO 2: Register client in connection registry\n    // TODO 3: Send buffered events for any missed updates\n    // TODO 4: Start heartbeat monitoring for connection health\n    // TODO 5: Handle connection cleanup on client disconnect\n    \n    // Placeholder - implement complete connection handling\n    fmt.Fprintf(w, \"data: {\\\"type\\\":\\\"connected\\\",\\\"client_id\\\":\\\"%s\\\"}\\n\\n\", clientID)\n}\n\nfunc (u *UpdatePropagationService) generateEventID() string {\n    // TODO: Implement monotonic event ID generation\n    return fmt.Sprintf(\"%d\", time.Now().UnixNano())\n}\n```\n\n#### Core Evaluation Logic Skeleton\n\n```go\npackage evaluation\n\n// Engine implements the core flag evaluation logic with caching and consistency\ntype Engine struct {\n    storage   FlagStorage\n    cache     *FlagCache\n    hasher    *ConsistentHasher\n    validator *ContextValidator\n}\n\n// EvaluateFlag processes the complete evaluation flow for a single flag\nfunc (e *Engine) EvaluateFlag(flagKey FlagKey, context UserContext) EvaluationResult {\n    // TODO 1: Retrieve flag definition from cache or storage\n    // TODO 2: Validate flag is active and not archived\n    // TODO 3: Check for prerequisite flag dependencies\n    // TODO 4: Enrich context with computed segment memberships\n    // TODO 5: Evaluate targeting rules in priority order\n    // TODO 6: Fall back to percentage rollout if no rules match\n    // TODO 7: Resolve variant value and perform type coercion\n    // TODO 8: Return comprehensive evaluation result with reason\n    \n    return EvaluationResult{\n        FlagKey: flagKey,\n        Value:   nil,\n        Variant: \"default\",\n        Reason:  \"not_implemented\",\n        Source:  \"engine\",\n    }\n}\n\n// evaluateTargetingRules processes rules with proper precedence and logic\nfunc (e *Engine) evaluateTargetingRules(rules []TargetingRule, context UserContext) (string, interface{}, string, bool) {\n    // TODO 1: Sort rules by priority (highest first)\n    // TODO 2: Iterate through rules and evaluate conditions\n    // TODO 3: For matching rule, return its variant and value\n    // TODO 4: Handle AND/OR logic properly within rule conditions\n    // TODO 5: Return detailed reason for debugging\n    \n    return \"\", nil, \"no_matching_rules\", false\n}\n\n// calculateUserBucket provides consistent user assignment to percentage buckets\nfunc (e *Engine) calculateUserBucket(userID UserID, flagKey FlagKey) int {\n    // TODO 1: Create hash input from userID and flagKey\n    // TODO 2: Apply consistent hashing algorithm\n    // TODO 3: Convert hash to bucket number (0-99)\n    // TODO 4: Ensure deterministic results for same inputs\n    \n    return 0 // Placeholder\n}\n```\n\n#### Milestone Checkpoint: Evaluation Flow\n\nAfter implementing the evaluation flow, verify the following behavior:\n\n**Test Command**: `go test ./internal/flows/ -v -run TestEvaluationFlow`\n\n**Expected Behavior**:\n- Flag evaluations complete within 5ms for cached flags\n- User bucket assignments remain stable across multiple evaluations\n- Targeting rules are evaluated in correct priority order\n- Cache hits/misses are properly tracked and reported\n- Exposure events are generated for all successful evaluations\n\n**Manual Verification**:\n```bash\n# Start the flag service\ngo run cmd/server/main.go\n\n# Test flag evaluation endpoint\ncurl -X POST http://localhost:8080/api/v1/evaluate \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"flag_key\": \"test-flag\",\n    \"user_context\": {\n      \"user_id\": \"user123\",\n      \"attributes\": {\"beta_user\": true}\n    }\n  }'\n\n# Expected response includes variant, value, and evaluation reason\n# Check logs for exposure event generation\n```\n\n#### Milestone Checkpoint: Update Propagation\n\nAfter implementing the update propagation flow, verify the following behavior:\n\n**Test Command**: `go test ./internal/realtime/ -v -run TestPropagation`\n\n**Expected Behavior**:\n- Flag changes propagate to connected clients within 500ms\n- Clients reconnect automatically after network interruptions\n- Buffered events are replayed to reconnecting clients\n- Connection counts and delivery metrics are accurate\n- No message duplication or ordering violations occur\n\n**Manual Verification**:\n```bash\n# Start update service and connect test client\ngo run cmd/server/main.go &\ngo run examples/test-client/main.go\n\n# Update a flag through management API\ncurl -X PUT http://localhost:8080/api/v1/flags/test-flag \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"enabled\": true, \"variants\": [...]}'\n\n# Verify client receives update within 500ms\n# Test reconnection by restarting client\n```\n\n#### Debugging Tips\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|-----------------|-----|\n| Users flip between variants | Inconsistent bucket calculation | Check hash inputs and normalization | Use stable, normalized user ID and flag key only |\n| Flag updates take minutes to propagate | Connection failures or buffering issues | Check SSE connection health and event buffer | Implement connection monitoring and retry logic |\n| Evaluation errors during flag updates | Cache invalidation race conditions | Check concurrent access to cache during updates | Use versioned caching with proper locking |\n| High evaluation latency | Cache misses or expensive segment resolution | Monitor cache hit rates and segment computation time | Implement cache warming and segment pre-computation |\n| Missing exposure events | Async queue overflows or processing failures | Check exposure queue depths and error logs | Implement backpressure and queue monitoring |\n\n\n## Error Handling and Edge Cases\n\n> **Milestone(s):** This section applies to all three milestones by ensuring robust error handling and graceful degradation across the Flag Evaluation Engine (Milestone 1), Real-time Flag Updates (Milestone 2), and Flag Analytics & Experiments (Milestone 3).\n\nThink of error handling in feature flag systems like building a suspension bridge with multiple safety systems. Just as bridges have primary cables, backup cables, and emergency procedures for various failure scenarios, feature flag systems require layered safety mechanisms. When the primary evaluation service fails, the system should seamlessly fall back to cached data. When the real-time update connection drops, clients should continue operating with their last known state while attempting reconnection. When analytics services are unavailable, flag evaluations should continue uninterrupted. The key insight is that feature flags control critical business functionality, so the system must be designed to fail gracefully rather than catastrophically.\n\nBuilding a resilient feature flag system requires anticipating every possible failure mode and designing appropriate responses. Unlike traditional applications where failures might cause user-facing errors, feature flag failures can silently corrupt A/B test results, cause inconsistent user experiences, or even break critical business features. The challenge is maintaining system reliability while preserving the performance characteristics that make feature flags practical for high-traffic applications.\n\n### Fallback and Degradation Strategies\n\nThe foundation of resilient feature flag systems lies in **graceful degradation** - the ability to provide reduced but functional service when components fail. This requires establishing clear fallback hierarchies and ensuring that each layer can operate independently when upstream dependencies become unavailable.\n\n> **Decision: Multi-Layer Fallback Architecture**\n> - **Context**: Feature flag evaluations must continue even when various system components fail, but maintaining consistency and performance during degradation is challenging\n> - **Options Considered**: Single cache fallback, distributed cache with local backup, hierarchical fallback with offline capability\n> - **Decision**: Implement hierarchical fallback with memory cache, local storage, and hardcoded defaults\n> - **Rationale**: Provides maximum availability while maintaining predictable performance characteristics and allowing for offline operation\n> - **Consequences**: Increases complexity but ensures evaluation requests never fail completely, though may serve stale data during extended outages\n\nThe fallback hierarchy follows a clear precedence order that balances freshness with availability:\n\n| Fallback Level | Data Source | Freshness | Availability | Latency |\n|---|---|---|---|---|\n| Primary | Flag Management API | Real-time | Network dependent | 50-200ms |\n| Secondary | Memory Cache | Minutes old | High | <1ms |\n| Tertiary | Local Storage | Hours old | Very High | 1-5ms |\n| Ultimate | Default Values | Static | Guaranteed | <1ms |\n\n**Memory Cache Fallback Strategy**\n\nWhen the primary Flag Management API becomes unavailable, the evaluation engine immediately switches to its in-memory cache. This cache maintains a complete copy of all flag definitions with their targeting rules and variant configurations. The cache includes metadata about when each flag was last updated, allowing the system to make informed decisions about data freshness.\n\nThe memory cache fallback operates transparently to client applications. Flag evaluations continue with identical response formats and performance characteristics. However, the `EvaluationResult` includes a `Source` field that indicates \"cache\" rather than \"api\", allowing downstream systems to understand they may be receiving stale data.\n\nCache invalidation during fallback mode presents unique challenges. Since the system cannot receive real-time updates from the management API, it must implement intelligent cache refresh strategies. The system attempts periodic background refreshes with exponential backoff, but never blocks evaluation requests on these refresh attempts.\n\n**Local Storage Persistence**\n\nFor extended outages that exceed memory cache retention policies, the system falls back to persistent local storage. This storage layer maintains a complete snapshot of flag definitions along with evaluation metadata. The local storage uses a simple key-value structure where flag keys map to serialized `FlagDefinition` objects.\n\nLocal storage fallback occurs automatically when memory cache misses indicate that cached data has been evicted. The system logs these fallback events with appropriate severity levels to alert operations teams about degraded service quality. Despite using local storage, evaluation performance remains acceptable because modern storage systems provide sub-millisecond read access for small objects.\n\nThe local storage layer requires careful consideration of disk space management. Flag definitions can accumulate over time, especially for systems managing thousands of flags across multiple environments. The system implements a least-recently-used eviction policy that maintains the most actively evaluated flags while removing obsolete definitions.\n\n**Default Value Resolution**\n\nThe ultimate fallback mechanism relies on default values embedded directly in flag definitions. These defaults are hardcoded values that require no external dependencies and guarantee that evaluation requests never fail completely. Default values represent the \"safe\" configuration - typically the existing behavior before a feature flag was introduced.\n\nDefault value fallback must be carefully designed to avoid breaking critical business functionality. For boolean flags controlling new features, the default should typically be `false` to maintain existing behavior. For configuration flags that modify system parameters, defaults should represent well-tested values that maintain system stability.\n\nThe system provides clear visibility into default value usage through comprehensive logging and metrics. When evaluations fall back to default values, this indicates a significant service degradation that requires immediate attention. Operations teams should treat extended default value usage as a high-priority incident.\n\n**Fallback Decision Logic**\n\nThe fallback decision process follows a deterministic algorithm that ensures consistent behavior across all system components:\n\n1. **Primary Evaluation Attempt**: The system first attempts to retrieve the flag definition from the Flag Management API with a short timeout (typically 100-200ms)\n2. **Connection Health Check**: If the API request fails, the system checks connection health metrics to distinguish between temporary network issues and service outages\n3. **Cache Consultation**: For failed API requests, the system immediately checks the memory cache for a cached flag definition\n4. **Freshness Assessment**: If cached data exists, the system evaluates whether the data is fresh enough based on configured staleness tolerance\n5. **Local Storage Query**: For cache misses or excessively stale data, the system queries persistent local storage\n6. **Default Value Selection**: If no stored data is available, the system returns the hardcoded default value from the flag definition\n7. **Circuit Breaker Update**: The system updates circuit breaker state based on the success or failure of each fallback attempt\n\n**Performance During Degradation**\n\nMaintaining acceptable performance during degraded operation requires careful attention to timeout configuration and resource management. The system uses aggressive timeouts for fallback decisions to prevent cascade failures where slow upstream services cause downstream performance degradation.\n\nCircuit breakers play a crucial role in performance preservation. Once a circuit breaker opens due to repeated API failures, the system immediately routes evaluation requests to cached data without attempting API calls. This prevents the accumulated latency of failed network requests from affecting user-facing performance.\n\nResource isolation ensures that fallback mechanisms don't compete with primary evaluation paths for system resources. Memory caches use separate allocation pools from real-time processing, and local storage operations use dedicated I/O queues that don't interfere with network communication.\n\n**Consistency Guarantees During Fallback**\n\nWhile fallback mechanisms prioritize availability over consistency, the system provides clear guarantees about what level of consistency clients can expect during degraded operation. These guarantees help application developers make appropriate decisions about feature flag usage in critical code paths.\n\nDuring memory cache fallback, the system guarantees that all evaluation requests for the same user context will return identical results within the cache retention window. This ensures that user experiences remain consistent even during service outages.\n\nLocal storage fallback provides weaker consistency guarantees because data may be hours or days old. However, the system guarantees that it will return the same result for identical evaluation requests until fresh data becomes available. This prevents situations where users experience inconsistent behavior due to non-deterministic fallback logic.\n\nDefault value fallback provides the strongest consistency guarantee - all evaluation requests for a given flag will return identical results regardless of system state. This predictability allows applications to implement critical business logic with confidence that behavior will remain consistent during outages.\n\n![Error Handling and Fallback Flow](./diagrams/error-handling-flow.svg)\n\n### Edge Cases and Corner Scenarios\n\nFeature flag systems encounter numerous edge cases that can cause subtle bugs or system instability if not handled properly. These scenarios often arise from the complex interactions between targeting rules, user contexts, and system constraints under unusual operating conditions.\n\n**Malformed Targeting Rules**\n\nInvalid or malformed targeting rules represent one of the most common edge cases in feature flag systems. These can result from manual configuration errors, automated rule generation bugs, or data corruption during storage or transmission.\n\nThe system must validate all rule components during flag definition creation and updates. Rule validation includes checking operator compatibility with attribute types, ensuring percentage allocations sum to valid ranges, and verifying that referenced user segments exist in the system.\n\n| Validation Type | Check Description | Error Response | Recovery Action |\n|---|---|---|---|\n| Operator Compatibility | Ensure operators match attribute types | Return validation error | Reject flag update |\n| Percentage Range | Verify allocations are 0-100% | Return validation error | Apply automatic normalization |\n| Segment References | Check referenced segments exist | Return validation error | Remove invalid references |\n| Circular Dependencies | Detect prerequisite cycles | Return validation error | Reject flag update |\n| Rule Complexity | Limit nested condition depth | Return validation error | Flatten rule structure |\n\nWhen malformed rules are detected during evaluation rather than creation, the system applies safe fallback behavior. Rather than throwing exceptions that could break application functionality, the evaluation engine logs detailed error information and returns default values with clear indication of the evaluation failure in the response metadata.\n\n**Circular Flag Dependencies**\n\nFeature flags can reference other flags as prerequisites, creating dependency relationships that must be evaluated in proper order. Circular dependencies occur when flags reference each other either directly (A depends on B, B depends on A) or indirectly through longer chains (A→B→C→A).\n\nCircular dependency detection uses depth-first search traversal of the flag dependency graph during flag creation and update operations. The system maintains an in-memory representation of all flag dependencies and validates that new dependency additions don't create cycles.\n\nThe detection algorithm maintains a visited set and a recursion stack during graph traversal:\n\n1. **Initialize Traversal**: Start from the flag being updated and mark it as visited\n2. **Follow Dependencies**: For each prerequisite flag, recursively traverse its dependencies\n3. **Cycle Detection**: If a flag is encountered that's already in the current recursion stack, a cycle exists\n4. **Path Recording**: Maintain the dependency path to provide detailed error messages about cycle location\n5. **Validation Result**: Return success only if no cycles are detected in the complete dependency graph\n\nWhen cycles are detected during flag updates, the system rejects the update with detailed error information including the complete cycle path. This helps flag administrators understand the dependency chain that would be violated and make appropriate corrections.\n\n**Extreme Load Conditions**\n\nHigh-traffic applications can generate evaluation request volumes that exceed normal system capacity, especially during traffic spikes or when new flags are introduced that affect large user populations. The system must maintain functionality and prevent cascade failures under these extreme conditions.\n\nLoad shedding mechanisms activate when evaluation request rates exceed configured thresholds. Rather than accepting all requests and potentially causing system-wide failures, the system selectively drops requests using consistent criteria that minimize impact on critical functionality.\n\n| Load Level | Threshold | Response Strategy | Impact |\n|---|---|---|---|\n| Normal | <1000 req/sec | Standard evaluation | No impact |\n| Elevated | 1000-5000 req/sec | Enable additional caching | Slight staleness increase |\n| High | 5000-10000 req/sec | Aggressive cache utilization | Moderate staleness |\n| Critical | >10000 req/sec | Load shedding activation | Some requests dropped |\n\nRequest prioritization during load shedding considers multiple factors including flag importance, user segment membership, and evaluation complexity. Critical flags that control core business functionality receive higher priority than experimental flags used for A/B testing. Authenticated users may receive priority over anonymous users for personalized features.\n\n**Inconsistent User Context Data**\n\nUser context objects can contain malformed, missing, or inconsistent attribute data that complicates targeting rule evaluation. These issues often arise from client-side data collection errors, integration bugs, or schema evolution without proper migration.\n\nType coercion handles cases where attribute values don't match expected types in targeting rules. The system attempts intelligent conversion between compatible types (string to number, boolean to string) while maintaining evaluation consistency.\n\nMissing attribute handling requires careful consideration of rule semantics. When a targeting rule references an attribute that's not present in the user context, the system must decide whether this should cause rule evaluation to fail or continue with default assumptions.\n\n| Missing Attribute Scenario | Rule Type | Behavior | Rationale |\n|---|---|---|---|\n| Required attribute absent | Exact match (equals) | Rule evaluates to false | Cannot match without value |\n| Optional attribute absent | Range check (greater_than) | Rule evaluates to false | Cannot compare without value |\n| Attribute type mismatch | Contains check | Attempt coercion, then false | Graceful degradation |\n| Empty string/array | Membership test (in) | Rule evaluates to false | Empty collections match nothing |\n\n**Database Connection Failures**\n\nPersistent storage failures can occur due to database outages, network partitions, or resource exhaustion. The system must handle these failures gracefully while maintaining evaluation capability and preserving data consistency when connectivity is restored.\n\nConnection pool management becomes critical during database failures. The system uses circuit breakers to detect database unavailability and prevent connection pool exhaustion from repeated failed connection attempts. Once a circuit opens, database operations immediately return cached or default data without attempting database access.\n\nRecovery procedures activate when database connectivity is restored. The system must carefully validate data consistency, replay any missed updates, and gradually restore normal operation without overwhelming the recovered database with reconnection attempts from all system components simultaneously.\n\n**Memory and Resource Exhaustion**\n\nFeature flag systems with large numbers of flags or complex targeting rules can encounter memory pressure, especially when maintaining comprehensive caches or processing high evaluation volumes. Resource exhaustion must be detected and handled before it affects system stability.\n\nMemory management includes both proactive monitoring and reactive cleanup mechanisms. The system monitors heap usage, cache sizes, and evaluation queue lengths to detect approaching resource limits. When thresholds are exceeded, the system activates resource reclamation procedures.\n\nCache eviction policies become critical during memory pressure. The system uses intelligent eviction that considers flag evaluation frequency, data freshness, and flag importance. Rarely-used experimental flags are evicted before frequently-accessed production flags.\n\n**Network Partitions and Split-Brain Scenarios**\n\nDistributed feature flag systems can experience network partitions that isolate different components from each other. During partitions, different parts of the system may have inconsistent views of flag configurations, leading to different evaluation results for identical contexts.\n\nPartition detection relies on heartbeat mechanisms and consensus protocols where appropriate. Components that detect they're isolated from the majority of the system should enter a degraded mode that prioritizes consistency over availability.\n\nSplit-brain prevention ensures that conflicting flag updates don't occur simultaneously in different partitions. The system uses techniques like majority quorums or designated master selection to ensure only one partition can make authoritative flag changes during network partitions.\n\n**Data Corruption and Consistency Violations**\n\nStorage corruption can cause flag definitions to contain invalid data that passes initial validation but causes evaluation errors. This can result from hardware failures, software bugs, or concurrent modification issues.\n\nChecksum validation protects against storage-level corruption by maintaining hash values for all flag definitions. Before evaluating a flag, the system verifies that the definition's checksum matches its stored content and falls back to cached or default data if corruption is detected.\n\nConsistency repair mechanisms activate when corruption is detected. The system can rebuild flag definitions from backup data, request fresh copies from authoritative sources, or temporarily disable corrupted flags until manual intervention restores proper data.\n\n⚠️ **Pitfall: Insufficient Error Context**\nMany implementations provide generic error messages like \"evaluation failed\" without sufficient context for debugging. This makes production issues extremely difficult to diagnose. Always include flag key, user context summary, error type, and fallback action taken in error messages and logs.\n\n⚠️ **Pitfall: Synchronous Fallback Operations**\nAttempting to perform expensive fallback operations (like local storage queries) synchronously during evaluation requests can cause timeout cascades. Implement asynchronous background processes for fallback data preparation and use in-memory structures for fast fallback decisions during request handling.\n\n⚠️ **Pitfall: Inconsistent Error Handling**\nDifferent system components handling the same error conditions in different ways can cause confusing behavior and difficult debugging. Establish consistent error handling patterns and ensure all components follow the same fallback hierarchies and timeout behaviors.\n\n### Implementation Guidance\n\nThe error handling and fallback mechanisms require careful coordination between all system components. This implementation guidance provides the infrastructure and patterns needed to build robust error handling that maintains system reliability under various failure conditions.\n\n**Technology Recommendations**\n\n| Component | Simple Option | Advanced Option |\n|---|---|---|\n| Circuit Breaker | Manual state tracking with counters | go-kit/kit circuit breaker with metrics |\n| Error Tracking | Standard Go error handling with logging | Sentry or similar error aggregation service |\n| Fallback Storage | Local file-based JSON storage | Embedded database like BadgerDB or SQLite |\n| Health Monitoring | HTTP health endpoints with basic checks | Comprehensive metrics with Prometheus |\n| Configuration Validation | JSON schema validation | Custom validator with business rule checks |\n\n**Recommended File Structure**\n\n```\ninternal/\n  errors/\n    errors.go              ← Custom error types and handling utilities\n    fallback.go           ← Fallback hierarchy implementation\n    circuit_breaker.go    ← Circuit breaker for service dependencies\n    validation.go         ← Flag and context validation logic\n  storage/\n    local_cache.go        ← Memory cache with LRU eviction\n    local_storage.go      ← Persistent local storage interface\n    file_storage.go       ← File-based storage implementation\n  health/\n    checker.go            ← Health monitoring and metrics\n    recovery.go           ← Automatic recovery procedures\n```\n\n**Error Type Definitions**\n\n```go\npackage errors\n\nimport (\n    \"fmt\"\n    \"time\"\n)\n\n// FlagError represents all feature flag related errors with context\ntype FlagError struct {\n    Type        ErrorType             `json:\"type\"`\n    FlagKey     string               `json:\"flag_key,omitempty\"`\n    Message     string               `json:\"message\"`\n    Cause       error                `json:\"-\"`\n    Context     map[string]interface{} `json:\"context,omitempty\"`\n    Timestamp   time.Time            `json:\"timestamp\"`\n    Recoverable bool                 `json:\"recoverable\"`\n}\n\nfunc (e *FlagError) Error() string {\n    return fmt.Sprintf(\"flag error [%s]: %s (flag: %s)\", e.Type, e.Message, e.FlagKey)\n}\n\nfunc (e *FlagError) Unwrap() error {\n    return e.Cause\n}\n\n// ErrorType categorizes different failure modes for appropriate handling\ntype ErrorType string\n\nconst (\n    ErrorTypeValidation    ErrorType = \"validation\"\n    ErrorTypeNetwork      ErrorType = \"network\" \n    ErrorTypeStorage      ErrorType = \"storage\"\n    ErrorTypeEvaluation   ErrorType = \"evaluation\"\n    ErrorTypeCircuit      ErrorType = \"circuit_breaker\"\n    ErrorTypeDependency   ErrorType = \"dependency\"\n    ErrorTypeResource     ErrorType = \"resource_exhaustion\"\n)\n```\n\n**Circuit Breaker Implementation**\n\n```go\npackage errors\n\nimport (\n    \"sync\"\n    \"time\"\n)\n\n// CircuitBreaker prevents cascade failures by detecting repeated errors\ntype CircuitBreaker struct {\n    name           string\n    maxFailures    int\n    resetTimeout   time.Duration\n    state          CircuitState\n    failures       int\n    lastFailTime   time.Time\n    successCount   int\n    mu            sync.RWMutex\n}\n\ntype CircuitState string\n\nconst (\n    StateClosed    CircuitState = \"closed\"    // Normal operation\n    StateOpen      CircuitState = \"open\"      // Blocking all requests  \n    StateHalfOpen  CircuitState = \"half_open\" // Testing recovery\n)\n\nfunc NewCircuitBreaker(name string, maxFailures int, resetTimeout time.Duration) *CircuitBreaker {\n    return &CircuitBreaker{\n        name:         name,\n        maxFailures:  maxFailures,\n        resetTimeout: resetTimeout,\n        state:        StateClosed,\n    }\n}\n\n// Allow determines if a request should be processed or rejected\nfunc (cb *CircuitBreaker) Allow() error {\n    // TODO: Implement circuit breaker allow logic\n    // 1. Check current state under read lock\n    // 2. For StateClosed: always allow\n    // 3. For StateOpen: check if reset timeout has passed\n    //    - If timeout passed, transition to StateHalfOpen and allow\n    //    - Otherwise reject with circuit breaker error\n    // 4. For StateHalfOpen: allow (testing recovery)\n    return nil\n}\n\n// RecordResult updates circuit breaker state based on operation outcome\nfunc (cb *CircuitBreaker) RecordResult(err error) {\n    // TODO: Update circuit breaker state based on result\n    // 1. Acquire write lock for state modification\n    // 2. If err != nil: increment failure count and record timestamp\n    //    - Check if failures exceed threshold and transition to StateOpen\n    // 3. If err == nil and state is StateHalfOpen: \n    //    - Increment success count and check if should transition to StateClosed\n    // 4. If err == nil and state is StateClosed: reset failure count\n}\n\n// State returns current circuit breaker state for monitoring\nfunc (cb *CircuitBreaker) State() CircuitState {\n    cb.mu.RLock()\n    defer cb.mu.RUnlock()\n    return cb.state\n}\n```\n\n**Fallback Handler Infrastructure**\n\n```go\npackage errors\n\nimport (\n    \"context\"\n    \"time\"\n)\n\n// FallbackHandler manages the complete fallback hierarchy\ntype FallbackHandler struct {\n    primaryAPI    FlagAPI\n    memoryCache   *MemoryCache\n    localStorage  LocalStorage\n    circuitBreaker *CircuitBreaker\n    metrics       *FallbackMetrics\n}\n\n// FlagAPI interface for primary flag data source\ntype FlagAPI interface {\n    GetFlag(ctx context.Context, flagKey string) (*FlagDefinition, error)\n}\n\n// FallbackMetrics tracks fallback usage for monitoring\ntype FallbackMetrics struct {\n    APIAttempts      int64\n    CacheHits        int64\n    LocalStorageHits int64\n    DefaultValueHits int64\n    mu              sync.RWMutex\n}\n\nfunc NewFallbackHandler(api FlagAPI, cache *MemoryCache, storage LocalStorage) *FallbackHandler {\n    return &FallbackHandler{\n        primaryAPI:     api,\n        memoryCache:    cache,\n        localStorage:   storage,\n        circuitBreaker: NewCircuitBreaker(\"flag-api\", 5, 30*time.Second),\n        metrics:       &FallbackMetrics{},\n    }\n}\n\n// GetFlagWithFallback implements complete fallback hierarchy\nfunc (fh *FallbackHandler) GetFlagWithFallback(ctx context.Context, flagKey string) (*FlagDefinition, string, error) {\n    // TODO: Implement complete fallback sequence\n    // 1. Check circuit breaker - if open, skip API and go to cache\n    // 2. Try primary API with short timeout context\n    //    - If success: update cache, record success, return with source \"api\"\n    //    - If failure: record failure, continue to fallback\n    // 3. Try memory cache\n    //    - Check staleness tolerance before returning cached data\n    //    - If found and fresh: return with source \"cache\"\n    // 4. Try local storage\n    //    - Load from persistent storage\n    //    - If found: update memory cache, return with source \"storage\"\n    // 5. Return default value from flag definition with source \"default\"\n    // 6. Update metrics for monitoring\n    \n    return nil, \"\", fmt.Errorf(\"not implemented\")\n}\n```\n\n**Validation Framework**\n\n```go\npackage errors\n\nimport (\n    \"fmt\"\n    \"strings\"\n)\n\n// ValidationErrors collects multiple validation failures\ntype ValidationErrors struct {\n    Errors []ValidationError `json:\"errors\"`\n}\n\nfunc (ve *ValidationErrors) Error() string {\n    var messages []string\n    for _, err := range ve.Errors {\n        messages = append(messages, err.Error())\n    }\n    return fmt.Sprintf(\"validation failed: %s\", strings.Join(messages, \"; \"))\n}\n\nfunc (ve *ValidationErrors) Add(field, message string) {\n    ve.Errors = append(ve.Errors, ValidationError{\n        Field:   field,\n        Message: message,\n    })\n}\n\nfunc (ve *ValidationErrors) HasErrors() bool {\n    return len(ve.Errors) > 0\n}\n\n// ValidationError represents a single validation failure\ntype ValidationError struct {\n    Field   string `json:\"field\"`\n    Message string `json:\"message\"`\n}\n\nfunc (ve ValidationError) Error() string {\n    return fmt.Sprintf(\"field '%s': %s\", ve.Field, ve.Message)\n}\n\n// ValidateFlagDefinition performs comprehensive flag validation\nfunc ValidateFlagDefinition(flag *FlagDefinition) error {\n    // TODO: Implement comprehensive flag validation\n    // 1. Check flag key format and length\n    // 2. Validate default value matches flag type\n    // 3. For each targeting rule:\n    //    - Validate attribute references\n    //    - Check operator compatibility with attribute types\n    //    - Verify percentage allocations sum correctly\n    //    - Validate segment references exist\n    // 4. Check for circular dependencies in prerequisites\n    // 5. Validate variant definitions match flag type\n    // 6. Ensure at least one variant or default value exists\n    \n    return nil\n}\n\n// ValidateUserContext ensures context data meets requirements\nfunc ValidateUserContext(ctx *UserContext) error {\n    // TODO: Validate user context structure\n    // 1. Check UserID is not empty\n    // 2. Validate attribute values are compatible types\n    // 3. Check segment names follow naming conventions\n    // 4. Verify context size doesn't exceed limits\n    \n    return nil\n}\n```\n\n**Recovery and Health Monitoring**\n\n```go\npackage health\n\nimport (\n    \"context\"\n    \"sync\"\n    \"time\"\n)\n\n// HealthChecker monitors system component health and triggers recovery\ntype HealthChecker struct {\n    components map[string]HealthComponent\n    status     map[string]ComponentHealth\n    mu         sync.RWMutex\n    interval   time.Duration\n    stopCh     chan struct{}\n}\n\ntype ComponentHealth struct {\n    Status      HealthStatus  `json:\"status\"`\n    LastCheck   time.Time     `json:\"last_check\"`\n    LastError   string        `json:\"last_error,omitempty\"`\n    CheckCount  int64         `json:\"check_count\"`\n    ErrorCount  int64         `json:\"error_count\"`\n}\n\ntype HealthStatus string\n\nconst (\n    HealthStatusHealthy   HealthStatus = \"healthy\"\n    HealthStatusDegraded  HealthStatus = \"degraded\" \n    HealthStatusUnhealthy HealthStatus = \"unhealthy\"\n)\n\ntype HealthComponent interface {\n    Name() string\n    Check(ctx context.Context) error\n    Recover(ctx context.Context) error\n}\n\nfunc NewHealthChecker(interval time.Duration) *HealthChecker {\n    return &HealthChecker{\n        components: make(map[string]HealthComponent),\n        status:     make(map[string]ComponentHealth),\n        interval:   interval,\n        stopCh:     make(chan struct{}),\n    }\n}\n\n// StartMonitoring begins periodic health checks and automatic recovery\nfunc (hc *HealthChecker) StartMonitoring(ctx context.Context) {\n    // TODO: Implement health monitoring loop\n    // 1. Create ticker for periodic checks\n    // 2. For each component, run health check\n    // 3. Update component status based on check result\n    // 4. If component unhealthy, attempt recovery\n    // 5. Log health status changes\n    // 6. Handle context cancellation for graceful shutdown\n}\n```\n\n**Milestone Checkpoints**\n\n**After Milestone 1 - Flag Evaluation Engine:**\n- Test flag evaluation with invalid rule conditions: `go test -run TestEvaluationWithInvalidRules`\n- Verify fallback to default values when rules are malformed\n- Check that evaluation errors include proper context information\n- Expected: Evaluation succeeds with clear indication of fallback usage\n\n**After Milestone 2 - Real-time Flag Updates:**  \n- Test connection failure scenarios: disconnect network and verify client behavior\n- Check exponential backoff during reconnection attempts\n- Verify circuit breaker opens after repeated connection failures\n- Expected: Clients continue operating with cached data during outages\n\n**After Milestone 3 - Flag Analytics & Experiments:**\n- Test analytics service failure during flag evaluation\n- Verify that exposure tracking failures don't affect flag evaluation\n- Check that experiment assignment continues when analytics are unavailable\n- Expected: Flag evaluations continue normally even when analytics fail\n\n**Debugging Checklist**\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---|---|---|---|\n| Evaluations always return defaults | Circuit breaker stuck open | Check circuit breaker state and error logs | Reset circuit breaker or fix underlying service |\n| Inconsistent evaluation results | Cache consistency issues | Compare cache contents across instances | Implement cache invalidation or restart services |\n| Memory leaks during errors | Error context not being cleaned up | Monitor heap usage during error scenarios | Add proper cleanup in error handling paths |\n| Slow recovery after outages | Thundering herd on reconnection | Check connection attempt timing | Add jittered exponential backoff |\n| Missing error context in logs | Generic error handling | Review error logging patterns | Enhance errors with flag keys and user context |\n\n\n## Testing Strategy\n\n> **Milestone(s):** This section applies to all three milestones by establishing comprehensive testing strategies for validating the Flag Evaluation Engine (Milestone 1), Real-time Flag Updates (Milestone 2), and Flag Analytics & Experiments (Milestone 3).\n\nTesting a feature flag system requires a multi-layered approach that goes beyond traditional unit tests. Think of testing feature flags like **stress-testing air traffic control systems** — you need to verify that the system works correctly under normal conditions, handles edge cases gracefully, and maintains safety guarantees even when components fail. Just as air traffic controllers run emergency scenarios to ensure pilots can land safely during equipment failures, we must test that our feature flag system maintains consistent user experiences even when services are degraded.\n\nThe testing strategy for a feature flag system faces unique challenges that don't exist in typical CRUD applications. Feature flags must maintain **consistent user assignments** across evaluations, ensure **real-time updates propagate correctly** without causing inconsistencies, and track **statistically valid experiments** without introducing bias. A single bug in consistent hashing could cause users to flip between variants, invalidating an entire A/B test. A race condition in update propagation could show users conflicting feature states within the same session.\n\n### Milestone Validation Checkpoints\n\nEach milestone introduces distinct functionality that requires specific validation approaches. The checkpoints serve as **quality gates** that verify the system meets its acceptance criteria before proceeding to the next milestone. Think of these checkpoints like **preflight inspections** — systematically verifying each system component before allowing the next phase to begin.\n\n**Milestone 1: Flag Evaluation Engine Validation**\n\nThe Flag Evaluation Engine validation focuses on correctness of targeting logic, consistency of user assignments, and performance under load. The core challenge is ensuring that complex targeting rules evaluate deterministically and that percentage rollouts assign users consistently across multiple evaluations.\n\n| Test Category | What to Validate | Expected Behavior | Failure Indicators |\n|---------------|------------------|-------------------|-------------------|\n| Basic Flag Evaluation | Simple boolean flags return correct values | `EvaluateFlag(\"simple-toggle\", userContext)` returns `{Value: true, Variant: \"enabled\", Reason: \"targeting_match\"}` | Wrong boolean value returned, missing variant information |\n| Targeting Rule Logic | Complex AND/OR conditions evaluate correctly | User matching `userType=premium AND region=us-east` gets correct variant | Rule precedence violations, incorrect boolean logic |\n| Percentage Rollouts | Consistent user assignment to percentage buckets | Same user gets same variant across multiple evaluations | User assignment changes between calls, incorrect bucket distribution |\n| Rule Precedence | Higher priority rules override lower priority ones | Targeting rules evaluated before default percentage rollout | Lower priority rules incorrectly taking precedence |\n| Context Validation | Invalid user contexts are handled gracefully | Missing required attributes cause fallback to default value | System crashes on malformed context, silent failures |\n| Performance Baseline | Evaluation latency meets requirements | Single flag evaluation completes under 1ms, 10k evaluations/sec sustained | High latency, memory leaks, CPU spikes |\n\nThe **consistent hashing validation** is particularly critical for Milestone 1. Create test scenarios with the same user evaluating the same flag thousands of times — the variant assignment must never change. Additionally, test that percentage allocations distribute users correctly by evaluating flags for large user populations and measuring actual distribution against expected percentages.\n\n```\nValidation Command: go test ./internal/evaluation/... -v -race\nExpected Output: All tests pass, no race conditions detected\nManual Verification: Start evaluation server, send 1000 requests for same user/flag, verify identical responses\n```\n\n**Milestone 2: Real-time Flag Updates Validation**\n\nReal-time updates introduce complexity around connection management, message ordering, and cache consistency. The validation must ensure that flag changes propagate to all connected clients within acceptable time bounds and that clients handle connection failures gracefully.\n\n| Test Category | What to Validate | Expected Behavior | Failure Indicators |\n|---------------|------------------|-------------------|-------------------|\n| Update Propagation | Flag changes reach all connected clients | Change broadcast within 100ms to all SSE connections | Clients not receiving updates, significant propagation delays |\n| Connection Recovery | Clients reconnect after network interruption | Exponential backoff, replay missed events, resume normal operation | Infinite retry loops, missed updates after reconnection |\n| Message Ordering | Updates arrive in correct sequence | Event sequence numbers increment monotonically, no gaps | Out-of-order delivery, duplicate or missing events |\n| Cache Invalidation | Stale flag data is replaced promptly | Local cache updated within propagation timeout | Clients serving stale data after update notification |\n| Connection Limits | System handles connection scaling gracefully | Support target number of concurrent SSE connections | Memory exhaustion, connection drops under load |\n| Fallback Behavior | Clients function when update service unavailable | Fall back to cached data, continue flag evaluations | Service unavailable causes client failures |\n\nThe **connection state machine validation** requires simulating various network conditions. Test clients connecting, disconnecting, experiencing intermittent failures, and recovering. Verify that the `ConnectionState` transitions correctly through `StateDisconnected`, `StateConnecting`, `StateConnected`, and `StateReconnecting` states based on network events.\n\n```\nValidation Command: go test ./internal/realtime/... -v -timeout 30s\nExpected Output: Connection state transitions verified, no goroutine leaks\nManual Verification: Start server with 100 concurrent clients, toggle flag via API, verify all clients receive update\n```\n\n**Milestone 3: Flag Analytics & Experiments Validation**\n\nAnalytics and experimentation validation focuses on data accuracy, statistical correctness, and performance of the tracking pipeline. The challenge is ensuring that exposure events are captured reliably and that statistical calculations produce valid results.\n\n| Test Category | What to Validate | Expected Behavior | Failure Indicators |\n|---------------|------------------|-------------------|-------------------|\n| Exposure Tracking | All flag evaluations are logged accurately | Each `EvaluateFlag` call generates corresponding `FlagExposure` event | Missing exposure events, incorrect exposure data |\n| Statistical Calculations | Significance tests produce correct results | Known experiment data yields expected p-values and confidence intervals | Wrong statistical results, confidence intervals don't match |\n| Sample Ratio Detection | Mismatch between intended and actual allocations detected | 50/50 split with 60/40 actual triggers `SampleRatioMismatch` flag | Sample ratio mismatches not detected, false positives |\n| Experiment Assignment | Users consistently assigned to same variant | Same user gets same experiment variant across sessions | User variant assignments change over time |\n| Performance Pipeline | High-volume exposure tracking without data loss | Process 10k exposures/sec without dropping events | Event queue overflow, processing delays, data loss |\n| Analytics Aggregation | Real-time metrics accurately reflect exposure data | Conversion rates match raw exposure data calculations | Aggregation errors, metrics don't match raw data |\n\nThe **statistical significance validation** requires test datasets with known ground truth. Create synthetic experiment data where variant A has a 5% conversion rate and variant B has a 6% conversion rate, then verify that your `CalculateSignificance` function produces the expected p-values and confidence intervals for different sample sizes.\n\n```\nValidation Command: go test ./internal/analytics/... -v -bench=BenchmarkExposureTracking\nExpected Output: Statistical calculations match expected values, throughput targets achieved\nManual Verification: Run synthetic A/B test, compare calculated significance to external statistical tool\n```\n\n**Cross-Milestone Integration Validation**\n\nThe final validation step verifies that all three milestones work together correctly. This integration testing simulates realistic usage patterns where clients evaluate flags, receive real-time updates, and generate analytics data simultaneously.\n\n| Integration Scenario | Validation Steps | Success Criteria |\n|----------------------|------------------|------------------|\n| Flag Update During Active Experiment | Modify flag while experiment running, verify exposure tracking continues | No gaps in exposure data, users maintain variant assignments |\n| High-Load Mixed Operations | Concurrent flag evaluations, updates, and analytics queries | All operations succeed, no degradation in any component |\n| Partial Service Degradation | Disable analytics service, verify flag evaluation continues | Flag evaluation unaffected, analytics queue buffers data |\n\n### Property-based Testing\n\nProperty-based testing is particularly valuable for feature flag systems because it can discover edge cases that traditional example-based tests miss. Instead of testing specific inputs and outputs, property-based tests verify **mathematical invariants** that should hold regardless of the specific input values. Think of property-based testing like **physics laws** — just as gravity always pulls objects downward regardless of their mass or composition, certain properties of your feature flag system should always hold true regardless of the specific flags, users, or configurations involved.\n\nProperty-based testing excels at finding the subtle bugs that can destroy user trust in feature flags. A traditional unit test might verify that user \"alice\" gets variant \"treatment\" for flag \"checkout-flow\", but a property-based test would verify that ANY user gets the SAME variant every time they're evaluated for ANY flag. This approach discovers bugs like hash function inconsistencies, floating-point precision issues in percentage calculations, and race conditions in concurrent access patterns.\n\n**Consistent Hashing Stability Properties**\n\nThe most critical property to test is **deterministic user assignment** — the same user must always receive the same variant for a given flag configuration, regardless of when or how many times the evaluation occurs. This property is foundational to user experience and experiment validity.\n\n| Property | Description | Test Strategy |\n|----------|-------------|---------------|\n| Assignment Stability | Same user + same flag + same config = same variant | Generate random users and flags, evaluate multiple times, assert all results identical |\n| Percentage Distribution | Large user populations distribute according to percentage allocations | Generate 10k random users, evaluate against 50/50 split, assert 45-55% in each bucket |\n| Independence Across Flags | User's variant for one flag doesn't influence variant for other flags | Generate user + multiple flags, assert variant assignments are uncorrelated |\n| Hash Function Uniformity | User IDs distribute evenly across bucket space | Generate 10k sequential user IDs, assert bucket assignments don't cluster |\n\nThe **assignment stability property** can be implemented using property-based testing frameworks by generating random `UserID` and `FlagKey` combinations, then evaluating the same combination multiple times and asserting that the `EvaluationResult.Variant` never changes. This test should run with thousands of random inputs to discover edge cases like specific user ID patterns that cause hash collisions.\n\n```go\n// Property: Same user + same flag = same variant (always)\nfunc TestAssignmentStability(t *testing.T) {\n    // TODO 1: Generate random UserID and FlagKey\n    // TODO 2: Create FlagDefinition with percentage rollout\n    // TODO 3: Call EvaluateFlag 100 times with same inputs\n    // TODO 4: Assert all results have identical Variant field\n    // TODO 5: Repeat with 1000 different random user/flag combinations\n}\n```\n\n**Rule Evaluation Determinism Properties**\n\nComplex targeting rules with AND/OR operators and multiple conditions must evaluate deterministically regardless of the order in which conditions are processed or the internal representation of the rule tree.\n\n| Property | Description | Test Strategy |\n|----------|-------------|---------------|\n| Boolean Logic Correctness | AND/OR operators follow mathematical laws (associativity, commutativity) | Generate random rule combinations, verify against truth tables |\n| Condition Order Independence | Same conditions in different orders produce same result | Generate rule with multiple conditions, test all permutations |\n| Context Attribute Type Safety | Same logical value in different types produces same result | Test string \"true\" vs boolean true, integer 1 vs string \"1\" |\n| Rule Precedence Consistency | Higher priority rules always override lower priority ones | Generate rules with random priorities, assert highest priority determines result |\n\n**Cache Consistency Properties**\n\nReal-time flag updates must maintain consistency between cached and authoritative flag definitions. Cache inconsistencies can cause the same user to see different feature behavior within a short time window, creating poor user experience.\n\n| Property | Description | Test Strategy |\n|----------|-------------|---------------|\n| Read-After-Write Consistency | Flag reads return updated value after write completes | Write flag update, immediately read from cache, assert new value returned |\n| Invalidation Completeness | Cache invalidation removes ALL stale entries | Update flag, trigger invalidation, assert no cache level returns old value |\n| Concurrent Access Safety | Multiple threads reading/writing cache don't corrupt data | Generate concurrent read/write operations, assert no race conditions |\n| TTL Enforcement | Expired cache entries are not served | Set short TTL, wait for expiration, assert cache miss triggers refresh |\n\n**Statistical Analysis Properties**\n\nA/B test analysis must produce mathematically correct results that match established statistical formulas. Incorrect statistical calculations can lead to false conclusions about feature effectiveness.\n\n| Property | Description | Test Strategy |\n|----------|-------------|---------------|\n| Significance Calculation Accuracy | P-values and confidence intervals match statistical formulas | Generate synthetic data with known ground truth, verify calculations |\n| Sample Size Monotonicity | Larger samples never decrease statistical power | Generate data with increasing sample sizes, assert power never decreases |\n| Alpha Level Consistency | Significance threshold correctly applied across all tests | Test data at boundary conditions, verify alpha=0.05 behaves correctly |\n| Effect Size Calculation | Effect size measures correctly reflect practical significance | Generate data with known effect sizes, verify calculated values |\n\nThe **significance calculation accuracy** property can be tested by generating synthetic experiment data using known statistical distributions, then verifying that your `CalculateSignificance` function produces results that match calculations from established statistical libraries like R or Python's scipy.stats.\n\n**Implementation Strategy for Property-based Tests**\n\nProperty-based testing frameworks like Go's `gopter` or `testing/quick` generate hundreds or thousands of random test cases automatically. The key is designing property functions that encode the mathematical invariants your system must maintain.\n\n| Component | Property Function Signature | Random Generators Needed |\n|-----------|----------------------------|--------------------------|\n| Evaluation Engine | `func TestAssignmentStability(user UserID, flag FlagKey) bool` | UserID generator, FlagKey generator, percentage generator |\n| Rule Engine | `func TestRuleDeterminism(rules []TargetingRule, ctx UserContext) bool` | Rule generator, condition generator, context generator |\n| Cache Layer | `func TestCacheConsistency(operations []CacheOperation) bool` | Cache operation generator, flag definition generator |\n| Statistics | `func TestSignificanceAccuracy(experimentData ExperimentData) bool` | Conversion rate generator, sample size generator |\n\nEach property function should return `true` if the invariant holds and `false` if it's violated. The testing framework automatically shrinks failing test cases to find minimal examples that violate the property, making debugging much easier than trying to reproduce complex failure scenarios manually.\n\n> **Design Insight**: Property-based testing is particularly valuable for feature flag systems because bugs often manifest only under specific combinations of user attributes, flag configurations, or timing conditions that are difficult to anticipate when writing example-based tests.\n\n**Common Property-based Testing Pitfalls**\n\n⚠️ **Pitfall: Testing Implementation Details Instead of Business Properties**\n\nMany developers write property-based tests that verify implementation details like \"hash function returns 32-bit integer\" rather than business properties like \"user assignment remains stable\". This leads to brittle tests that break when implementation changes but don't catch real bugs that affect users.\n\n**Why it's wrong**: Implementation details can change without affecting system behavior. Testing them creates maintenance burden without providing confidence in system correctness.\n\n**How to fix**: Focus on observable behavior and business invariants. Test that \"users get consistent variants\" rather than \"hash function returns specific values\".\n\n⚠️ **Pitfall: Insufficient Random Data Generation**\n\nProperty-based tests are only as good as the random data they generate. Tests that generate only simple, well-formed inputs miss edge cases like empty strings, special characters, extreme numeric values, or unusual data combinations.\n\n**Why it's wrong**: Real-world data contains edge cases that simple generators miss. Bugs often lurk in boundary conditions and unusual input combinations.\n\n**How to fix**: Design generators that produce edge cases: empty collections, null values, extreme numbers, special characters, and boundary conditions relevant to your domain.\n\n### Implementation Guidance\n\n**A. Technology Recommendations:**\n\n| Testing Component | Simple Option | Advanced Option |\n|------------------|---------------|-----------------|\n| Property-based Testing | `testing/quick` (Go stdlib) | `gopter` with custom generators |\n| Load Testing | `go test -bench` with table tests | `k6` with realistic traffic patterns |\n| Integration Testing | `httptest` with test servers | `testcontainers` with real dependencies |\n| Statistical Validation | Manual calculation verification | `gonum/stat` for reference implementations |\n| Test Data Management | JSON fixtures in `testdata/` | `factory_bot` style builders with randomization |\n| Milestone Validation | `make test` with milestone-specific tags | CI pipeline with environment-specific test suites |\n\n**B. Recommended Test Structure:**\n\n```\ninternal/\n  evaluation/\n    evaluation.go\n    evaluation_test.go           ← unit tests\n    evaluation_property_test.go  ← property-based tests\n    evaluation_integration_test.go ← integration scenarios\n  realtime/\n    realtime_test.go\n    realtime_load_test.go        ← connection scaling tests\n  analytics/\n    analytics_test.go\n    analytics_statistical_test.go ← statistical accuracy tests\ntest/\n  fixtures/                      ← test data\n    flags.json\n    users.json\n    experiments.json\n  integration/                   ← cross-component tests\n    milestone_1_test.go\n    milestone_2_test.go\n    milestone_3_test.go\n  property/                      ← property-based test generators\n    generators.go                ← random data generation\n    properties.go                ← invariant definitions\n```\n\n**C. Test Data Generators (Complete Implementation):**\n\n```go\npackage property\n\nimport (\n    \"math/rand\"\n    \"time\"\n    \"testing/quick\"\n)\n\n// UserGenerator creates realistic UserID values for property testing\nfunc UserGenerator(rand *rand.Rand, size int) reflect.Value {\n    // Generate mix of numeric IDs, UUIDs, and email-like strings\n    patterns := []func() string{\n        func() string { return fmt.Sprintf(\"user_%d\", rand.Intn(100000)) },\n        func() string { return fmt.Sprintf(\"test+%d@example.com\", rand.Intn(10000)) },\n        func() string { \n            return fmt.Sprintf(\"%08x-%04x-%04x\", \n                rand.Uint32(), rand.Uint32()&0xFFFF, rand.Uint32()&0xFFFF)\n        },\n    }\n    pattern := patterns[rand.Intn(len(patterns))]\n    return reflect.ValueOf(UserID(pattern()))\n}\n\n// FlagGenerator creates realistic flag definitions for property testing\nfunc FlagGenerator(rand *rand.Rand, size int) reflect.Value {\n    flag := &FlagDefinition{\n        Key:         FlagKey(fmt.Sprintf(\"test_flag_%d\", rand.Intn(1000))),\n        Name:        fmt.Sprintf(\"Test Flag %d\", rand.Intn(1000)),\n        Description: \"Generated for property testing\",\n        Enabled:     rand.Float32() > 0.1, // 90% enabled\n        Variants: []Variant{\n            {Key: \"control\", Value: false, Weight: rand.Intn(50) + 25},\n            {Key: \"treatment\", Value: true, Weight: rand.Intn(50) + 25},\n        },\n    }\n    \n    // Add random targeting rules 20% of the time\n    if rand.Float32() > 0.8 {\n        flag.TargetingRules = generateRandomRules(rand, size)\n    }\n    \n    return reflect.ValueOf(flag)\n}\n\n// ContextGenerator creates diverse user contexts for testing\nfunc ContextGenerator(rand *rand.Rand, size int) reflect.Value {\n    attributes := make(map[string]interface{})\n    \n    // Add common attribute types\n    attributes[\"user_type\"] = []string{\"premium\", \"basic\", \"trial\"}[rand.Intn(3)]\n    attributes[\"region\"] = []string{\"us-east\", \"us-west\", \"eu\", \"asia\"}[rand.Intn(4)]\n    attributes[\"account_age_days\"] = rand.Intn(1000)\n    attributes[\"is_beta_user\"] = rand.Float32() > 0.7\n    \n    // Add random attributes 30% of the time\n    if rand.Float32() > 0.7 {\n        randomKey := fmt.Sprintf(\"custom_%d\", rand.Intn(100))\n        attributes[randomKey] = fmt.Sprintf(\"value_%d\", rand.Intn(100))\n    }\n    \n    return reflect.ValueOf(UserContext{\n        UserID:     UserID(fmt.Sprintf(\"user_%d\", rand.Intn(10000))),\n        Attributes: attributes,\n        Segments:   generateRandomSegments(rand),\n    })\n}\n```\n\n**D. Property Test Examples (Core Logic Skeletons):**\n\n```go\n// TestAssignmentStabilityProperty verifies consistent user assignment\nfunc TestAssignmentStabilityProperty(t *testing.T) {\n    property := func(user UserID, flag *FlagDefinition) bool {\n        // TODO 1: Create evaluation engine with test configuration\n        // TODO 2: Build user context with consistent attributes\n        // TODO 3: Evaluate flag 100 times in tight loop\n        // TODO 4: Verify all evaluations return identical variant\n        // TODO 5: Return true if stable, false if any variation detected\n        \n        // Hint: Store first result, compare all subsequent results\n        // Hint: Use reflect.DeepEqual for EvaluationResult comparison\n        return true // Replace with actual stability check\n    }\n    \n    if err := quick.Check(property, &quick.Config{\n        MaxCount: 1000,\n        Rand:     rand.New(rand.NewSource(time.Now().UnixNano())),\n    }); err != nil {\n        t.Errorf(\"Assignment stability property violated: %v\", err)\n    }\n}\n\n// TestPercentageDistributionProperty verifies rollout percentages\nfunc TestPercentageDistributionProperty(t *testing.T) {\n    property := func(percentage int) bool {\n        // Clamp percentage to valid range\n        if percentage < 5 || percentage > 95 {\n            return true // Skip extreme values\n        }\n        \n        // TODO 1: Create flag with specified percentage allocation\n        // TODO 2: Generate 10,000 diverse user contexts\n        // TODO 3: Evaluate flag for each user, count variant assignments\n        // TODO 4: Calculate actual percentage distribution\n        // TODO 5: Verify actual percentage within ±5% of expected\n        \n        // Hint: Use chi-square test for distribution validation\n        // Hint: Account for small sample variation in acceptance criteria\n        return true // Replace with actual distribution check\n    }\n    \n    if err := quick.Check(property, nil); err != nil {\n        t.Errorf(\"Percentage distribution property violated: %v\", err)\n    }\n}\n\n// TestStatisticalAccuracyProperty verifies significance calculations\nfunc TestStatisticalAccuracyProperty(t *testing.T) {\n    property := func(controlRate, treatmentRate float64, sampleSize int) bool {\n        // Validate input ranges\n        if controlRate < 0.01 || controlRate > 0.99 ||\n           treatmentRate < 0.01 || treatmentRate > 0.99 ||\n           sampleSize < 100 || sampleSize > 10000 {\n            return true // Skip invalid inputs\n        }\n        \n        // TODO 1: Generate synthetic experiment data with known rates\n        // TODO 2: Call CalculateSignificance with synthetic data\n        // TODO 3: Calculate expected p-value using reference implementation\n        // TODO 4: Verify calculated p-value within acceptable tolerance\n        // TODO 5: Verify confidence intervals contain true effect size\n        \n        // Hint: Use gonum/stat for reference statistical calculations\n        // Hint: Allow 1% tolerance for floating-point precision differences\n        return true // Replace with actual accuracy verification\n    }\n    \n    if err := quick.Check(property, &quick.Config{MaxCount: 100}); err != nil {\n        t.Errorf(\"Statistical accuracy property violated: %v\", err)\n    }\n}\n```\n\n**E. Milestone Checkpoint Implementation:**\n\n```go\n// Milestone1ValidationSuite runs comprehensive validation for flag evaluation\nfunc Milestone1ValidationSuite(t *testing.T) {\n    t.Run(\"BasicFunctionality\", func(t *testing.T) {\n        // TODO 1: Start evaluation server on test port\n        // TODO 2: Create simple boolean flag via API\n        // TODO 3: Evaluate flag with test user context\n        // TODO 4: Verify response structure and timing\n        // TODO 5: Clean up test resources\n    })\n    \n    t.Run(\"LoadTesting\", func(t *testing.T) {\n        // TODO 1: Create flag with complex targeting rules\n        // TODO 2: Generate 10,000 concurrent evaluation requests\n        // TODO 3: Measure average response time and error rate\n        // TODO 4: Verify all responses are deterministic\n        // TODO 5: Check for memory leaks and resource cleanup\n    })\n    \n    t.Run(\"EdgeCases\", func(t *testing.T) {\n        // TODO 1: Test evaluation with malformed user context\n        // TODO 2: Test evaluation with non-existent flag key\n        // TODO 3: Test evaluation with circular flag dependencies\n        // TODO 4: Verify graceful degradation in all cases\n        // TODO 5: Check error messages are informative\n    })\n}\n\n// checkpoint command: go test -tags=milestone1 -v -timeout=60s ./test/integration/\n// expected: All subtests pass, load test achieves >1000 QPS, <1ms avg latency\n```\n\n**F. Debugging Property Test Failures:**\n\n| Symptom | Likely Cause | Diagnosis Steps | Resolution |\n|---------|-------------|-----------------|------------|\n| Property fails on specific input combination | Edge case in evaluation logic | Run failing case in debugger, examine intermediate values | Add bounds checking, handle edge case explicitly |\n| Property fails intermittently | Race condition or timing dependency | Run with `-race` flag, add logging to identify timing issues | Add proper synchronization, eliminate timing dependencies |\n| Property fails on large inputs only | Performance degradation or resource exhaustion | Profile memory and CPU usage during large input tests | Optimize algorithms, add resource limits |\n| Statistical properties fail consistently | Mathematical error in calculations | Compare results with external statistical tools (R, Python) | Verify formulas, check for floating-point precision issues |\n\nThe property-based testing approach ensures your feature flag system maintains its mathematical guarantees under the full range of possible inputs, giving confidence that the system will behave correctly in production environments with diverse user bases and complex flag configurations.\n\n\n## Debugging Guide\n\n> **Milestone(s):** This section applies to all three milestones by providing systematic debugging approaches for common issues encountered while implementing the Flag Evaluation Engine (Milestone 1), Real-time Flag Updates (Milestone 2), and Flag Analytics & Experiments (Milestone 3).\n\nThink of debugging feature flags as being a detective investigating a mystery. Every incorrect flag evaluation or missed update is a clue pointing to deeper issues in the system. Unlike traditional debugging where you might see immediate crashes, feature flag bugs are often subtle - users getting the wrong variant, rules not evaluating correctly, or updates arriving out of order. These silent failures can impact user experience without triggering obvious error conditions, making systematic debugging approaches essential.\n\nThe complexity of debugging feature flag systems stems from their distributed nature and the multiple layers of caching, networking, and evaluation logic. A single flag evaluation request touches the cache layer, rule evaluation engine, consistent hashing algorithm, and potentially real-time update mechanisms. When something goes wrong, the root cause could be anywhere in this chain, requiring structured approaches to isolate and identify the problem.\n\nThis debugging guide provides systematic methodologies for diagnosing and resolving the most common issues encountered when implementing feature flag systems. Rather than exhaustive troubleshooting for every possible scenario, we focus on the patterns of problems that consistently trip up developers building these systems for the first time.\n\n### Flag Evaluation Issues\n\nFlag evaluation problems manifest as users receiving unexpected variants, rules not behaving as configured, or inconsistent assignments across multiple evaluations. These issues often stem from incorrect rule precedence, flawed consistent hashing implementation, or mishandled user context processing.\n\n**Mental Model: CSI Investigation**\nThink of debugging flag evaluation like a crime scene investigation. Each evaluation leaves \"evidence\" in the form of logs, metrics, and cached states. The key is systematically examining this evidence to reconstruct what happened during the evaluation process. Just as a detective follows the timeline of events, you need to trace the evaluation flow from user context input through rule processing to final variant assignment.\n\nThe `EvaluationResult` structure includes a `Reason` field specifically designed for debugging - it should contain enough information to understand why a particular variant was chosen. When implementing the evaluation engine, ensure every code path that sets a variant also sets a descriptive reason explaining the decision.\n\n#### Rule Evaluation Problems\n\nRule evaluation issues typically occur when targeting rules don't behave as expected, often due to incorrect condition logic, operator precedence problems, or context attribute handling errors.\n\n| Symptom | Likely Root Cause | Investigation Steps | Resolution |\n|---------|------------------|-------------------|------------|\n| Rule never matches despite correct user attributes | Condition operator logic error or AND/OR precedence | Check `EvaluationResult.Reason` for rule evaluation details, verify condition evaluation order | Implement proper boolean expression parsing with parentheses support |\n| Rule matches wrong users | Context attribute type mismatch or missing null checks | Log user context before evaluation, verify attribute types match condition expectations | Add type validation and safe type conversion in condition evaluation |\n| Inconsistent rule behavior across evaluations | Race condition in rule evaluation or shared state mutation | Test with concurrent evaluations, check for global variable modifications | Ensure rule evaluation is stateless and thread-safe |\n| Rules evaluate in wrong order | Incorrect rule precedence implementation | Verify rule sorting logic, check for stable sort requirements | Implement explicit rule priority with tie-breaking mechanisms |\n| Complex nested conditions fail | Boolean logic parsing errors or stack overflow | Test with progressively simpler conditions, check recursion depth | Implement iterative condition parsing or increase recursion limits |\n\n⚠️ **Pitfall: Forgetting Operator Precedence**\nA common mistake is implementing condition evaluation without proper precedence rules. For example, `userAge > 18 AND userCountry = \"US\" OR userCountry = \"CA\"` should evaluate as `(userAge > 18 AND userCountry = \"US\") OR userCountry = \"CA\"`, but naive left-to-right evaluation produces different results. Always implement proper boolean expression parsing with AND taking precedence over OR, or require explicit parentheses for complex conditions.\n\nThe `evaluateRuleConditions` method should handle operator precedence correctly:\n\n```\nRule Evaluation Algorithm:\n1. Parse conditions into expression tree respecting precedence\n2. Evaluate leaf conditions against user context\n3. Apply boolean operators bottom-up through the tree\n4. Return final boolean result with evaluation path for debugging\n```\n\nWhen debugging rule evaluation, examine the `UserContext.Attributes` map to ensure all required attributes are present and have the expected types. Missing attributes should be handled gracefully with configurable default behaviors rather than causing evaluation failures.\n\n> **Design Insight**: Rule evaluation debugging becomes much easier when each condition evaluation is logged with its inputs, operator, and result. This creates an audit trail showing exactly how complex boolean expressions were resolved.\n\n#### Consistent Hashing Assignment Problems\n\nConsistent hashing issues manifest as users receiving different variants across evaluations, percentage rollouts not matching expected distributions, or assignment instability when flag configurations change.\n\n| Symptom | Likely Root Cause | Investigation Steps | Resolution |\n|---------|------------------|-------------------|------------|\n| User gets different variants on repeated evaluations | Non-deterministic hashing or salt inconsistency | Test same user/flag combination multiple times, verify hash input construction | Use stable hash algorithm with consistent salt generation |\n| Percentage rollout doesn't match configured allocation | Bucket calculation error or range assignment logic | Analyze actual assignment distribution, check bucket boundary calculations | Verify bucket ranges sum to 100% and boundaries are exclusive |\n| Assignment changes when unrelated flags modified | Using unstable hash inputs or global state in bucket calculation | Test assignment stability when other flags change, verify hash input dependencies | Ensure hash inputs only include user ID and flag key |\n| Some users never see certain variants | Biased hash function or incorrect bucket range mapping | Check hash output distribution, verify variant allocation math | Use cryptographic hash function and validate bucket range calculations |\n| A/B test assignments skewed heavily toward one variant | Incorrect weight interpretation or cumulative percentage error | Compare intended vs actual allocation percentages, check weight summation | Implement proper cumulative percentage calculation for variant selection |\n\n⚠️ **Pitfall: Using Unstable Hash Inputs**\nIncluding volatile data like timestamps, session IDs, or request IDs in the hash calculation causes users to flip between variants unpredictably. The hash input should only include stable identifiers like `UserID` and `FlagKey`. Even adding seemingly stable data like user email can cause problems if users change their email addresses.\n\nThe `calculateUserBucket` function should use a deterministic approach:\n\n```\nBucket Calculation Algorithm:\n1. Construct hash input from stable user ID and flag key only\n2. Apply cryptographic hash function (SHA-256 or similar)\n3. Convert hash output to integer in range [0, 99]\n4. Map integer to variant based on cumulative weight ranges\n5. Log bucket value and selected variant for debugging\n```\n\nDebugging consistent hashing requires examining the actual bucket values assigned to users. Implement logging that shows the hash input, computed bucket, and variant assignment reasoning. This data helps identify patterns in assignment problems and validates that the hashing algorithm produces the expected distribution.\n\n> **Architecture Decision: Hash Algorithm Selection**\n> - **Context**: Need consistent user assignment to variants across evaluations\n> - **Options**: CRC32 checksum, MD5 hash, SHA-256 hash\n> - **Decision**: SHA-256 with user ID + flag key input\n> - **Rationale**: Cryptographic hash ensures uniform distribution, flag key inclusion prevents correlation between different flags\n> - **Consequences**: Higher computation cost but better assignment quality and debuggability\n\n#### Context and Segmentation Issues\n\nUser context and segment membership problems cause targeting rules to fail when they should match, or match when they shouldn't. These issues often arise from context validation problems, segment calculation errors, or attribute type mismatches.\n\n| Symptom | Likely Root Cause | Investigation Steps | Resolution |\n|---------|------------------|-------------------|------------|\n| Segment targeting doesn't work | Segment membership calculation error or stale segment data | Verify segment membership computation, check segment cache freshness | Implement real-time segment recalculation or cache invalidation |\n| Attribute-based targeting fails | Missing attributes in context or type conversion errors | Log complete user context, verify attribute presence and types | Add context validation with helpful error messages |\n| Geographic targeting inconsistent | IP geolocation service issues or timezone problems | Test with known IP addresses, verify geolocation data accuracy | Implement geolocation service fallbacks and result caching |\n| Demographic targeting unreliable | Outdated user profile data or attribute synchronization lag | Check user profile data freshness, verify attribute update mechanisms | Add user profile versioning and change tracking |\n| Multi-attribute rules fail unexpectedly | Context parsing errors or attribute name mismatches | Compare expected vs actual context structure, check attribute naming consistency | Standardize context schema validation and attribute naming |\n\n⚠️ **Pitfall: Assuming Attribute Availability**\nRules often fail because they assume certain user attributes will always be present. For example, a rule checking `userAge > 21` fails if the `UserContext` doesn't contain an age attribute. Always implement graceful handling for missing attributes with configurable default behaviors.\n\nThe `ValidateUserContext` function should verify that all required attributes for active targeting rules are present and properly typed:\n\n```\nContext Validation Algorithm:\n1. Extract all attributes referenced by active targeting rules\n2. Verify each required attribute exists in user context\n3. Validate attribute types match rule expectations\n4. Check segment membership data is current and complete\n5. Log any validation warnings or missing data\n```\n\nDebugging context issues requires comprehensive logging of the user context data alongside evaluation results. Include the complete `UserContext.Attributes` map and `Segments` list in debug logs to verify that targeting rules have access to the expected data.\n\n### Real-time Update Issues\n\nReal-time update problems manifest as clients not receiving flag changes, receiving updates out of order, or experiencing connection instability. These issues often stem from connection management problems, event ordering bugs, or cache synchronization failures.\n\n**Mental Model: Television Broadcasting**\nThink of real-time updates like a television broadcast system. The server acts as a broadcast tower sending the same signal to many receivers (client SDKs). When clients don't receive updates, it could be due to poor signal quality (network issues), wrong channel tuning (connection configuration), or interference (caching problems). Just as TV systems have fallback mechanisms like cable when over-the-air fails, flag update systems need robust fallback hierarchies.\n\nThe key insight for debugging real-time updates is understanding the distinction between connection-level problems (can't establish or maintain the stream) versus data-level problems (receiving wrong or stale data). These require different diagnostic approaches and solutions.\n\n#### Connection Management and Reliability\n\nConnection problems typically involve clients failing to establish SSE connections, frequent disconnections, or exponential backoff not working correctly.\n\n| Symptom | Likely Root Cause | Investigation Steps | Resolution |\n|---------|------------------|-------------------|------------|\n| Clients can't establish SSE connection | CORS configuration, proxy blocking SSE, or endpoint not found | Check browser developer tools network tab, verify SSE endpoint accessibility | Configure proper CORS headers and proxy SSE support |\n| Frequent connection drops | Keep-alive timeout mismatch or network infrastructure issues | Monitor connection duration patterns, check load balancer timeout settings | Implement heartbeat mechanism with configurable intervals |\n| Exponential backoff not working | Incorrect backoff calculation or missing jitter implementation | Log actual retry delays, verify backoff formula includes randomization | Add jitter to prevent thundering herd on reconnection |\n| Clients stuck in reconnecting state | Server rejecting connections or client retry logic bug | Check server logs for connection rejections, verify retry state transitions | Implement connection state debugging and maximum retry limits |\n| SSE events not reaching clients | Server not flushing events or client event parsing errors | Verify server-side flush calls, check client event handler registration | Ensure proper SSE message formatting and flushing |\n\n⚠️ **Pitfall: Forgetting SSE Connection Flushing**\nServer-Sent Events require explicit flushing after writing each event, or messages may buffer indefinitely. The `SSEServer.BroadcastFlagUpdate` method must call `Flush()` on each client's response writer after sending the event data. Without flushing, clients appear connected but never receive updates.\n\nThe connection management debugging process should examine both client and server state:\n\n```\nConnection Debugging Algorithm:\n1. Verify SSE endpoint responds with correct Content-Type and headers\n2. Check client connection state transitions in logs\n3. Examine server-side client registry for connected clients\n4. Test connection with curl or browser dev tools\n5. Monitor network layer for connection resets or timeouts\n```\n\nImplementing comprehensive connection state logging helps diagnose problems. The `ConnectionState` should be logged whenever it changes, along with the triggering event and any error details.\n\n> **Design Insight**: Connection problems often cascade - a single network hiccup can cause mass reconnections if exponential backoff isn't implemented correctly. Always include jitter in backoff calculations to prevent thundering herd scenarios.\n\n#### Event Ordering and Delivery\n\nEvent ordering problems cause clients to process flag updates out of sequence, leading to inconsistent state or missed updates. These issues typically stem from concurrent update broadcasting or improper sequence number handling.\n\n| Symptom | Likely Root Cause | Investigation Steps | Resolution |\n|---------|------------------|-------------------|------------|\n| Clients receive events out of order | Concurrent broadcasting without sequence numbers or race conditions | Check event sequence numbers in client logs, verify server broadcasting is serialized | Implement monotonic sequence numbers and client-side ordering |\n| Some flag updates never arrive at clients | Event broadcasting failure or client disconnection during update | Compare server broadcast logs with client received events, check connection status during updates | Add event acknowledgment mechanism and retry logic |\n| Clients process duplicate events | Reconnection replay overlap or at-least-once delivery without deduplication | Monitor for duplicate sequence numbers, check replay boundary calculation | Implement client-side deduplication using sequence numbers |\n| Flag updates arrive but aren't applied | Client update processing errors or cache update failures | Check client-side update processing logs, verify cache invalidation logic | Add update processing error handling and retry mechanisms |\n| Bulk flag updates overwhelm clients | Large payload size or high update frequency without throttling | Monitor event payload sizes and frequency, check client processing performance | Implement update batching and client-side throttling |\n\n⚠️ **Pitfall: Race Conditions in Event Broadcasting**\nBroadcasting flag updates concurrently can cause events to arrive out of order at clients. If multiple flag changes occur simultaneously, clients might receive the second change before the first, resulting in inconsistent state. Always serialize flag update broadcasting or use sequence numbers to enable client-side ordering.\n\nThe event ordering debugging approach should trace events from creation through delivery:\n\n```\nEvent Ordering Debugging Algorithm:\n1. Generate unique sequence numbers for each flag update event\n2. Log event creation with sequence number and timestamp\n3. Trace event broadcasting to all connected clients\n4. Monitor client event reception with sequence verification\n5. Check for gaps or duplicates in client event sequences\n```\n\nDebugging event delivery requires correlation between server broadcast logs and client reception logs. Implement request IDs or trace IDs that span from flag update through client processing to enable end-to-end tracking.\n\n#### Cache Synchronization Problems\n\nCache synchronization issues cause clients to serve stale flag data despite receiving updates, or fail to invalidate cached values when flags change. These problems often involve cache layer bugs or update processing failures.\n\n| Symptom | Likely Root Cause | Investigation Steps | Resolution |\n|---------|------------------|-------------------|------------|\n| Clients serve stale flag values after updates | Cache invalidation not triggered or cache hierarchy inconsistency | Check cache invalidation logs, verify update event processing triggers cache refresh | Ensure update handlers call cache invalidation for affected flags |\n| Cache updates fail silently | Storage errors or validation failures during cache write | Check cache operation error logs, verify storage layer health | Add cache operation error handling and fallback mechanisms |\n| Inconsistent cache state across instances | Race conditions in cache updates or distributed cache synchronization issues | Compare cache contents across client instances, check update ordering | Implement cache versioning and conflict resolution |\n| Memory cache grows unbounded | Missing cache eviction or TTL not enforced | Monitor cache size and memory usage, verify eviction policies | Implement proper cache size limits and LRU eviction |\n| Local storage cache corruption | Disk write errors or concurrent access without locking | Check local storage integrity, verify file locking mechanisms | Add local storage validation and repair mechanisms |\n\n⚠️ **Pitfall: Ignoring Cache Update Failures**\nWhen real-time flag updates fail to update the local cache, clients continue serving stale data without indication of the problem. The `ApplyFlagUpdate` method should handle cache update errors gracefully and potentially trigger a full cache refresh if individual updates fail consistently.\n\nCache synchronization debugging requires examining the cache hierarchy and update propagation:\n\n```\nCache Synchronization Debugging Algorithm:\n1. Check memory cache state before and after update events\n2. Verify local storage persistence of cache changes\n3. Compare cache timestamps with server flag modification times\n4. Test cache invalidation triggers from update events\n5. Validate cache consistency across multiple SDK instances\n```\n\nEffective cache debugging requires visibility into cache hit rates, invalidation events, and synchronization status. The `CacheStats` structure should be monitored to identify cache performance issues and synchronization problems.\n\n### Implementation Guidance\n\nThis section provides concrete implementation approaches for building debugging capabilities into the feature flag system, focusing on observability, error tracking, and systematic problem resolution.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|--------------|-----------------|\n| Error Tracking | Log to stdout with structured format | Distributed tracing with OpenTelemetry |\n| Metrics Collection | In-memory counters with periodic dumps | Prometheus metrics with Grafana dashboards |\n| Debug Logging | Standard library logger with levels | Structured logging with correlation IDs |\n| Health Monitoring | HTTP endpoint returning component status | Continuous health checks with alerting |\n| Performance Profiling | Built-in Go profiler endpoints | Continuous profiling with pprof integration |\n\n#### Recommended File Structure\n\n```\ninternal/debug/\n├── instrumentation.go      ← Debug logging and metrics\n├── health_check.go         ← Component health monitoring\n├── error_classification.go ← Error type classification\n├── evaluation_tracer.go    ← Flag evaluation debugging\n├── connection_monitor.go   ← Real-time connection debugging\n├── cache_inspector.go      ← Cache state examination\n└── debug_test.go          ← Debug functionality tests\n```\n\n#### Infrastructure Starter Code\n\nComplete error classification system for categorizing flag system errors:\n\n```go\npackage debug\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"sync\"\n    \"time\"\n)\n\n// FlagError represents a categorized error in the flag system\ntype FlagError struct {\n    Type        ErrorType                `json:\"type\"`\n    FlagKey     string                   `json:\"flag_key,omitempty\"`\n    Message     string                   `json:\"message\"`\n    Cause       error                   `json:\"cause,omitempty\"`\n    Context     map[string]interface{}   `json:\"context,omitempty\"`\n    Timestamp   time.Time               `json:\"timestamp\"`\n    Recoverable bool                    `json:\"recoverable\"`\n}\n\ntype ErrorType string\n\nconst (\n    ErrorTypeValidation ErrorType = \"validation\"\n    ErrorTypeNetwork    ErrorType = \"network\"\n    ErrorTypeStorage    ErrorType = \"storage\"\n    ErrorTypeEvaluation ErrorType = \"evaluation\"\n    ErrorTypeCircuit    ErrorType = \"circuit\"\n    ErrorTypeDependency ErrorType = \"dependency\"\n    ErrorTypeResource   ErrorType = \"resource\"\n)\n\n// Error implements the error interface\nfunc (e *FlagError) Error() string {\n    if e.FlagKey != \"\" {\n        return fmt.Sprintf(\"[%s:%s] %s\", e.Type, e.FlagKey, e.Message)\n    }\n    return fmt.Sprintf(\"[%s] %s\", e.Type, e.Message)\n}\n\n// Unwrap returns the underlying error for error chain compatibility\nfunc (e *FlagError) Unwrap() error {\n    return e.Cause\n}\n\n// NewFlagError creates a new categorized flag error\nfunc NewFlagError(errorType ErrorType, flagKey, message string, cause error) *FlagError {\n    return &FlagError{\n        Type:        errorType,\n        FlagKey:     flagKey,\n        Message:     message,\n        Cause:       cause,\n        Context:     make(map[string]interface{}),\n        Timestamp:   time.Now(),\n        Recoverable: isRecoverable(errorType),\n    }\n}\n\n// AddContext adds debugging context to the error\nfunc (e *FlagError) AddContext(key string, value interface{}) *FlagError {\n    if e.Context == nil {\n        e.Context = make(map[string]interface{})\n    }\n    e.Context[key] = value\n    return e\n}\n\n// isRecoverable determines if an error type typically allows recovery\nfunc isRecoverable(errorType ErrorType) bool {\n    switch errorType {\n    case ErrorTypeNetwork, ErrorTypeResource, ErrorTypeCircuit:\n        return true\n    case ErrorTypeValidation, ErrorTypeDependency:\n        return false\n    case ErrorTypeStorage, ErrorTypeEvaluation:\n        return true // Usually recoverable with retry or fallback\n    default:\n        return false\n    }\n}\n\n// CircuitBreaker provides failure detection and recovery coordination\ntype CircuitBreaker struct {\n    name          string\n    maxFailures   int\n    resetTimeout  time.Duration\n    state         CircuitState\n    failures      int\n    lastFailTime  time.Time\n    successCount  int\n    mu           sync.RWMutex\n}\n\ntype CircuitState string\n\nconst (\n    StateClosed   CircuitState = \"closed\"\n    StateOpen     CircuitState = \"open\"\n    StateHalfOpen CircuitState = \"half_open\"\n)\n\n// Allow checks if the circuit breaker permits a request\nfunc (cb *CircuitBreaker) Allow() error {\n    cb.mu.Lock()\n    defer cb.mu.Unlock()\n    \n    switch cb.state {\n    case StateClosed:\n        return nil\n    case StateOpen:\n        if time.Since(cb.lastFailTime) > cb.resetTimeout {\n            cb.state = StateHalfOpen\n            return nil\n        }\n        return NewFlagError(ErrorTypeCircuit, \"\", \n            fmt.Sprintf(\"circuit breaker %s is open\", cb.name), nil)\n    case StateHalfOpen:\n        return nil\n    default:\n        return NewFlagError(ErrorTypeCircuit, \"\", \n            fmt.Sprintf(\"unknown circuit breaker state: %s\", cb.state), nil)\n    }\n}\n\n// RecordResult updates circuit breaker state based on operation result\nfunc (cb *CircuitBreaker) RecordResult(err error) {\n    cb.mu.Lock()\n    defer cb.mu.Unlock()\n    \n    if err != nil {\n        cb.failures++\n        cb.lastFailTime = time.Now()\n        cb.successCount = 0\n        \n        if cb.failures >= cb.maxFailures {\n            cb.state = StateOpen\n        }\n    } else {\n        cb.failures = 0\n        cb.successCount++\n        \n        if cb.state == StateHalfOpen && cb.successCount >= 3 {\n            cb.state = StateClosed\n        }\n    }\n}\n\n// State returns the current circuit breaker state\nfunc (cb *CircuitBreaker) State() CircuitState {\n    cb.mu.RLock()\n    defer cb.mu.RUnlock()\n    return cb.state\n}\n\n// NewCircuitBreaker creates a circuit breaker with specified parameters\nfunc NewCircuitBreaker(name string, maxFailures int, resetTimeout time.Duration) *CircuitBreaker {\n    return &CircuitBreaker{\n        name:         name,\n        maxFailures:  maxFailures,\n        resetTimeout: resetTimeout,\n        state:        StateClosed,\n    }\n}\n```\n\nComplete health monitoring system for tracking component status:\n\n```go\n// ComponentHealth tracks the health status of system components\ntype ComponentHealth struct {\n    Status     HealthStatus `json:\"status\"`\n    LastCheck  time.Time   `json:\"last_check\"`\n    LastError  string      `json:\"last_error,omitempty\"`\n    CheckCount int64       `json:\"check_count\"`\n    ErrorCount int64       `json:\"error_count\"`\n}\n\ntype HealthStatus string\n\nconst (\n    HealthStatusHealthy   HealthStatus = \"healthy\"\n    HealthStatusDegraded  HealthStatus = \"degraded\"\n    HealthStatusUnhealthy HealthStatus = \"unhealthy\"\n)\n\n// HealthComponent defines interface for health-checkable components\ntype HealthComponent interface {\n    Name() string\n    Check(ctx context.Context) error\n    Recover(ctx context.Context) error\n}\n\n// HealthChecker monitors component health and coordinates recovery\ntype HealthChecker struct {\n    components map[string]HealthComponent\n    status     map[string]ComponentHealth\n    mu         sync.RWMutex\n    interval   time.Duration\n    stopCh     chan struct{}\n}\n\n// StartMonitoring begins the health monitoring loop\nfunc (hc *HealthChecker) StartMonitoring(ctx context.Context) {\n    ticker := time.NewTicker(hc.interval)\n    defer ticker.Stop()\n    \n    for {\n        select {\n        case <-ticker.C:\n            hc.checkAllComponents(ctx)\n        case <-hc.stopCh:\n            return\n        case <-ctx.Done():\n            return\n        }\n    }\n}\n\n// checkAllComponents performs health checks on all registered components\nfunc (hc *HealthChecker) checkAllComponents(ctx context.Context) {\n    hc.mu.Lock()\n    defer hc.mu.Unlock()\n    \n    for name, component := range hc.components {\n        health := hc.status[name]\n        health.CheckCount++\n        health.LastCheck = time.Now()\n        \n        if err := component.Check(ctx); err != nil {\n            health.ErrorCount++\n            health.LastError = err.Error()\n            \n            // Determine health status based on error rate\n            errorRate := float64(health.ErrorCount) / float64(health.CheckCount)\n            if errorRate > 0.5 {\n                health.Status = HealthStatusUnhealthy\n                // Attempt recovery for unhealthy components\n                if recoverErr := component.Recover(ctx); recoverErr != nil {\n                    health.LastError = fmt.Sprintf(\"recovery failed: %v\", recoverErr)\n                }\n            } else if errorRate > 0.2 {\n                health.Status = HealthStatusDegraded\n            }\n        } else {\n            health.Status = HealthStatusHealthy\n            health.LastError = \"\"\n        }\n        \n        hc.status[name] = health\n    }\n}\n```\n\n#### Core Logic Skeleton Code\n\nDebug-enhanced flag evaluation that provides comprehensive debugging information:\n\n```go\n// EvaluateFlag performs flag evaluation with comprehensive debugging support\nfunc (e *Evaluator) EvaluateFlag(flagKey FlagKey, userContext UserContext) (*EvaluationResult, error) {\n    // TODO 1: Start evaluation trace with unique trace ID for debugging\n    // TODO 2: Validate user context and flag key, return descriptive errors for invalid input\n    // TODO 3: Retrieve flag definition with cache hit/miss logging\n    // TODO 4: Check flag prerequisites and dependency chain with cycle detection\n    // TODO 5: Evaluate targeting rules with detailed condition logging\n    // TODO 6: Perform consistent hashing with bucket calculation details\n    // TODO 7: Select variant based on percentage allocation with weight verification\n    // TODO 8: Record evaluation metrics and exposure events\n    // TODO 9: Return evaluation result with complete reasoning chain\n    // Hint: Use structured logging with trace IDs to correlate debugging information\n    // Hint: Include evaluation timing metrics to identify performance bottlenecks\n    // Hint: Log cache hit/miss ratio to optimize caching strategy\n}\n\n// PropagateChange handles flag update distribution with connection tracking\nfunc (u *UpdateService) PropagateChange(flagKey FlagKey, changeType string, payload interface{}) error {\n    // TODO 1: Validate change payload and generate unique event ID\n    // TODO 2: Create flag update event with sequence number for ordering\n    // TODO 3: Broadcast to all connected clients with failure tracking\n    // TODO 4: Handle broadcasting failures with retry mechanism\n    // TODO 5: Update propagation metrics and connection health status\n    // TODO 6: Log successful and failed deliveries for debugging\n    // Hint: Track per-client delivery status to identify problematic connections\n    // Hint: Implement exponential backoff for failed broadcast retries\n    // Hint: Monitor propagation latency to detect performance issues\n}\n\n// ApplyFlagUpdate processes incoming flag changes with cache synchronization\nfunc (c *Client) ApplyFlagUpdate(event FlagUpdateEvent) error {\n    // TODO 1: Validate event sequence number and detect out-of-order delivery\n    // TODO 2: Parse flag update payload with comprehensive error handling\n    // TODO 3: Update memory cache with version tracking\n    // TODO 4: Persist to local storage with integrity verification\n    // TODO 5: Invalidate dependent caches and derived data\n    // TODO 6: Record update processing metrics and cache statistics\n    // Hint: Implement sequence number gaps detection for missed updates\n    // Hint: Add cache consistency verification after updates\n    // Hint: Log cache invalidation cascades for debugging dependency issues\n}\n```\n\n#### Language-Specific Debugging Hints\n\n**Go-Specific Debugging Techniques:**\n\n1. **Use `context.Context` for Request Tracing**: Pass context through all evaluation calls to maintain trace IDs and enable request correlation across logs.\n\n2. **Leverage `sync.RWMutex` for Safe Concurrent Access**: Use read locks for flag evaluation and write locks for cache updates to prevent race conditions.\n\n3. **Implement `fmt.Stringer` for Complex Types**: Add String() methods to `UserContext`, `EvaluationResult`, and other debug types for readable log output.\n\n4. **Use `testing.T.Logf()` for Test Debugging**: In unit tests, use `t.Logf()` to output debugging information only when tests fail.\n\n5. **Add `//go:build debug` Tags**: Create debug-only code paths that provide extra logging and validation in development builds.\n\n#### Milestone Checkpoints\n\n**Milestone 1 Validation - Flag Evaluation Engine:**\n- Run `go test -v ./internal/evaluation/...` - all tests should pass with detailed evaluation logs\n- Test flag evaluation with debug logging enabled - should see rule-by-rule evaluation traces\n- Verify consistent hashing stability - same user/flag combination should always return same variant\n- Expected output: Detailed evaluation logs showing rule matching, bucket calculation, and variant selection reasoning\n\n**Milestone 2 Validation - Real-time Flag Updates:**\n- Run SSE connection test with `curl -N -H \"Accept: text/event-stream\" http://localhost:8080/flags/stream`\n- Monitor connection logs during network interruption and recovery\n- Verify event ordering with sequence numbers in client logs\n- Expected output: SSE events received in correct order with reconnection handling and no duplicate processing\n\n**Milestone 3 Validation - Flag Analytics & Experiments:**\n- Generate test experiment data and verify statistical calculations\n- Check exposure event logging for completeness and accuracy\n- Validate significance testing with known statistical outcomes\n- Expected output: Accurate statistical significance calculations and comprehensive exposure tracking logs\n\n![Error Handling and Fallback Flow](./diagrams/error-handling-flow.svg)\n\nThe error handling flow diagram illustrates the decision points and fallback mechanisms that debugging tools must account for when diagnosing system issues. Understanding these flows helps identify where problems originate and which debugging approaches will be most effective.\n\n\n## Future Extensions\n\n> **Milestone(s):** This section provides forward-looking enhancements that build upon the foundation established by all three milestones, extending the Flag Evaluation Engine (Milestone 1), Real-time Flag Updates (Milestone 2), and Flag Analytics & Experiments (Milestone 3) with advanced capabilities for production-scale deployments.\n\nThink of the feature flag system we've built as a **city's traffic infrastructure**. We've constructed the core roads (evaluation engine), traffic lights (real-time updates), and monitoring systems (analytics). Now we're ready to expand our city with highways (multi-environment support), advanced traffic management (sophisticated targeting), and interconnected transportation networks (flag dependencies). Just as a growing city needs these advanced systems to handle increasing complexity and scale, our feature flag system can evolve to support more sophisticated use cases while maintaining the solid foundation we've established.\n\nThe design we've implemented follows an **evaluation-first architecture** that prioritizes performance and consistency in the core flag evaluation path. This architectural foundation naturally accommodates the extensions described in this section without requiring fundamental changes to the evaluation engine, data model, or real-time update mechanisms. Each extension builds upon existing components while introducing new capabilities that enhance the system's flexibility and power.\n\n### Advanced Targeting and Segmentation\n\nModern feature flag systems require increasingly sophisticated targeting capabilities beyond basic user attributes and percentage rollouts. Advanced targeting enables product teams to create nuanced user experiences by combining multiple data sources, temporal conditions, and contextual information.\n\n**Dynamic Segment Computation** represents a significant evolution from the static segment membership we implemented in our user context model. Instead of pre-computed segment assignments stored in the `UserContext`, dynamic segments evaluate membership criteria in real-time during flag evaluation. This approach enables targeting based on live user behavior, current application state, or external system data.\n\nThe dynamic segmentation system would extend our existing `TargetingRule` structure with new condition types that support external data lookups and computed values. For example, a segment might target \"users who made a purchase in the last 7 days\" by querying an external analytics service during flag evaluation. While this introduces latency considerations, the evaluation engine's caching mechanisms and circuit breaker patterns provide natural resilience.\n\n> **Decision: Real-time vs. Pre-computed Segmentation**\n> - **Context**: Advanced targeting requires access to frequently changing user data that may be expensive to pre-compute\n> - **Options Considered**: \n>   - Pre-compute all segments periodically and store in user context\n>   - Evaluate segments dynamically during flag evaluation with caching\n>   - Hybrid approach with both static and dynamic segments\n> - **Decision**: Hybrid approach supporting both static segments (in UserContext) and dynamic segments (evaluated on-demand)\n> - **Rationale**: Maintains backward compatibility while enabling real-time targeting; caching and circuit breakers mitigate performance concerns\n> - **Consequences**: Increased evaluation latency for dynamic segments, but greater targeting flexibility and real-time accuracy\n\n| Segmentation Type | Evaluation Timing | Data Freshness | Performance Impact | Use Cases |\n|-------------------|------------------|----------------|-------------------|-----------|\n| Static Segments | Pre-computed | Batch update intervals | Low latency | Demographic targeting, subscription tiers |\n| Dynamic Segments | Real-time | Always current | Higher latency | Recent behavior, live metrics, external data |\n| Cached Dynamic | First access + TTL refresh | TTL-bounded | Moderate latency | Frequently accessed behavioral segments |\n\n**Contextual Targeting** extends the `UserContext` model to include environmental and situational information beyond user attributes. This includes device characteristics, network conditions, application version, geographic location precision, time-based conditions, and integration with external systems. The evaluation engine's consistent hashing mechanism ensures that users with identical contexts receive consistent variant assignments even as context information becomes more detailed.\n\n**Multi-dimensional Rollouts** enhance percentage-based targeting by supporting multiple allocation dimensions simultaneously. Instead of a single percentage rollout, flags could allocate users across orthogonal dimensions like geographic region, device type, and user tenure. This enables sophisticated rollout strategies like \"10% of mobile users in North America\" while maintaining the deterministic assignment properties of our consistent hashing implementation.\n\n### Flag Dependencies and Prerequisites\n\nComplex applications often require coordinated feature rollouts where one feature depends on another being enabled. Flag dependencies create controlled activation sequences and prevent inconsistent feature combinations that could break user experiences.\n\n**Dependency Graph Management** builds upon the cycle detection validation we implemented in the flag evaluation engine. The system would maintain a directed acyclic graph of flag relationships, with each `FlagDefinition` containing a prerequisites field listing required flags and their states. The evaluation engine extends its processing to check prerequisite satisfaction before applying targeting rules.\n\nConsider a scenario where a new payment flow (Flag A) depends on updated user authentication (Flag B) and enhanced fraud detection (Flag C). The dependency system ensures Flag A only activates for users who have access to both prerequisites, preventing broken payment experiences.\n\n> **Key Design Insight**: Flag dependencies should fail safe by defaulting to the most restrictive state. If any prerequisite fails evaluation, the dependent flag should return its default value rather than attempting partial activation.\n\n| Dependency Type | Description | Evaluation Impact | Common Patterns |\n|-----------------|-------------|-------------------|-----------------|\n| Hard Prerequisites | Required flags must be enabled | Blocks dependent flag if prerequisites disabled | Infrastructure changes, breaking API updates |\n| Soft Dependencies | Preferred but not required | Logs warnings but allows evaluation | UI enhancements, optional integrations |\n| Mutual Exclusions | Flags cannot be active simultaneously | Disables conflicting flags automatically | A/B test variants, alternative implementations |\n| Version Dependencies | Specific versions of prerequisite flags | Checks version compatibility during evaluation | API versioning, graduated feature rollouts |\n\n**Prerequisite Evaluation Order** requires careful consideration to maintain evaluation performance. The evaluation engine processes dependencies in topological order, caching prerequisite results to avoid repeated evaluation within a single request. The `EvaluationResult` extends to include dependency information for debugging complex activation scenarios.\n\n**Circular Dependency Prevention** leverages the validation framework established in our flag management system. The dependency validator performs depth-first traversal during flag updates, rejecting configurations that would create cycles. This validation runs during both flag creation and updates, ensuring the dependency graph remains acyclic.\n\n### Multi-Environment Support\n\nProduction feature flag systems must support multiple deployment environments (development, staging, production) with independent configuration management while maintaining operational consistency.\n\n**Environment Isolation** extends the data model with environment-scoped flag definitions. Each `FlagDefinition` includes an environment identifier, and the flag management API enforces environment-based access controls. This isolation prevents accidental cross-environment configuration changes while allowing controlled promotion workflows.\n\nThe evaluation engine remains environment-agnostic, receiving flag definitions through the same interfaces established in our architecture. Environment-specific configuration occurs at the data layer, with separate storage namespaces or database schemas for each environment. This design maintains evaluation performance while providing complete configuration isolation.\n\n> **Decision: Environment Configuration Strategy**\n> - **Context**: Multiple environments need independent flag configurations with promotion capabilities\n> - **Options Considered**:\n>   - Single database with environment field in all records\n>   - Separate databases/schemas per environment\n>   - Environment-specific configuration files\n> - **Decision**: Separate storage namespaces with cross-environment promotion API\n> - **Rationale**: Complete isolation prevents accidental changes; promotion API enables controlled configuration flow; maintains existing data model\n> - **Consequences**: Additional operational complexity but maximum safety and flexibility\n\n**Configuration Promotion Workflows** enable controlled advancement of flag configurations through environment stages. The system provides promotion APIs that copy flag definitions between environments while maintaining audit trails and validation checkpoints. This builds upon our flag change tracking mechanisms to provide complete configuration lifecycle management.\n\n**Environment-Specific Analytics** extends the experiment framework to segment results by environment, enabling teams to validate feature performance in staging before production rollouts. The `FlagExposure` model includes environment context, and the significance calculation engine can filter results by environment for isolated analysis.\n\n### Advanced Analytics and Machine Learning Integration\n\nThe analytics foundation established in our A/B testing framework naturally extends to support machine learning-driven optimization and predictive analytics capabilities.\n\n**Automated Flag Optimization** uses machine learning models to recommend optimal variant allocations based on observed user behavior and conversion patterns. The system analyzes historical `FlagExposure` data to identify user segments with different variant preferences, automatically suggesting targeting rules that maximize desired outcomes.\n\nThis capability builds upon our existing significance calculation framework by extending the `SignificanceCalculator` with predictive models. Instead of only reporting experiment results, the system recommends actions like \"increase allocation for mobile users in the high-engagement variant\" based on statistical evidence.\n\n**Predictive User Segmentation** applies clustering algorithms to flag exposure and conversion data to identify previously unknown user segments with distinct behavior patterns. These discovered segments become available as targeting criteria in the dynamic segmentation system, creating a feedback loop between analytics insights and flag targeting capabilities.\n\n**Anomaly Detection** monitors flag performance metrics in real-time, automatically alerting teams when conversion rates, error rates, or user engagement metrics deviate significantly from historical patterns. This extends our health monitoring framework to include business-metric monitoring alongside system health checks.\n\n| ML Capability | Data Requirements | Algorithmic Approach | Integration Point |\n|---------------|------------------|---------------------|-------------------|\n| Automated Optimization | Flag exposures, conversion events | Multi-armed bandits, Bayesian optimization | Significance calculator extension |\n| Predictive Segmentation | User behavior, attribute data | K-means clustering, collaborative filtering | Dynamic segment engine |\n| Anomaly Detection | Time-series metrics, baseline data | Statistical process control, outlier detection | Health monitoring system |\n| Causal Impact Analysis | Pre/post experiment data | Difference-in-differences, synthetic control | Experiment results framework |\n\n### Global Distribution and Edge Computing\n\nLarge-scale applications require feature flag evaluation at global scale with minimal latency, necessitating edge computing integration and distributed caching strategies.\n\n**Edge Evaluation Nodes** deploy lightweight versions of the evaluation engine to edge locations worldwide. These nodes maintain cached flag definitions synchronized through our real-time update system, enabling sub-millisecond flag evaluation anywhere in the world. The edge nodes implement the same evaluation algorithms and consistent hashing mechanisms as the central system, ensuring globally consistent user assignments.\n\nThe distributed architecture maintains the same API interfaces while adding geographic routing intelligence. Client SDKs automatically discover and connect to the nearest edge node, falling back to central evaluation during edge node failures. This builds upon our existing fallback hierarchy patterns while adding geographic distribution.\n\n**Conflict-Free Replicated Data Types (CRDTs)** provide eventual consistency for flag configurations across distributed edge nodes. Flag updates propagate through the real-time update system while CRDT properties ensure all nodes converge to identical configuration states despite network partitions or update ordering differences.\n\n**Regional Compliance and Data Sovereignty** extends the multi-environment architecture to support regulatory requirements like GDPR data locality. Flag configurations and user context data remain within specified geographic boundaries while maintaining global evaluation consistency through federated architectures.\n\n### Enterprise Integration Capabilities\n\nProduction deployments require integration with existing enterprise systems for authentication, authorization, audit logging, and workflow management.\n\n**Single Sign-On (SSO) Integration** extends the flag management API with pluggable authentication providers supporting SAML, OAuth 2.0, and OpenID Connect. The system maintains role-based access controls for flag management while delegating authentication to enterprise identity providers.\n\n**Audit and Compliance Logging** enhances our flag change tracking to meet enterprise audit requirements. Every flag modification, user assignment, and experiment result includes comprehensive audit metadata suitable for compliance reporting. The system supports audit log export in standard formats and integrates with Security Information and Event Management (SIEM) systems.\n\n**Workflow Integration** connects flag lifecycle management with existing development and deployment workflows. This includes integration with source control systems for configuration-as-code, continuous integration pipelines for automated flag validation, and project management tools for feature delivery tracking.\n\n**API Gateway Integration** enables centralized feature flag evaluation within API gateway infrastructure, providing flag-based request routing, rate limiting, and access control. This architectural pattern reduces evaluation latency by embedding flag logic directly in the request processing pipeline.\n\n### Performance Optimization Extensions\n\nAs usage scales, the system benefits from advanced performance optimization techniques that maintain the evaluation-first design principles while handling extreme throughput requirements.\n\n**Evaluation Result Caching** extends beyond our current flag definition caching to cache evaluation results for identical user contexts. This optimization particularly benefits scenarios with repeated evaluations for the same users, though it requires careful cache invalidation when flag configurations change.\n\n**Batch Evaluation APIs** support evaluating multiple flags simultaneously for a single user context, reducing network overhead and enabling optimizations like shared rule evaluation across flags. This maintains the deterministic evaluation properties while improving throughput for SDK implementations.\n\n**Asynchronous Evaluation Pipelines** separate flag evaluation from result delivery for use cases where immediate responses aren't required. This enables advanced optimizations like speculative evaluation and result pre-computation based on predicted user behavior patterns.\n\n**Memory-Efficient Data Structures** replace standard hash tables and trees with specialized data structures optimized for flag evaluation workloads. Techniques like compressed tries for rule matching and bloom filters for negative lookups reduce memory usage while maintaining evaluation speed.\n\n### Integration Ecosystem Extensions\n\nThe feature flag system becomes more valuable as part of a broader development and operations ecosystem, requiring integration capabilities that extend its utility without compromising core functionality.\n\n**Observability Platform Integration** connects flag evaluation metrics with distributed tracing systems, application performance monitoring, and log aggregation platforms. Every flag evaluation becomes observable within the broader application context, enabling correlation analysis between feature flags and system behavior.\n\n**Feature Management Lifecycle Tools** extend beyond flag evaluation to support the complete feature development lifecycle. This includes feature planning tools that integrate with flag definitions, deployment tracking that correlates flag changes with application releases, and technical debt management that identifies obsolete flags for cleanup.\n\n**Developer Experience Enhancements** improve the day-to-day interaction with the feature flag system through IDE plugins, command-line tools, and local development environment integration. These tools build upon our existing SDK architecture while providing development-time conveniences that encourage proper flag usage.\n\n### Scalability Architecture Enhancements\n\nSupporting massive scale requires architectural enhancements that maintain the system's reliability and performance characteristics while handling orders of magnitude more traffic.\n\n**Horizontal Evaluation Scaling** distributes flag evaluation across multiple server instances using consistent hashing for request distribution. This maintains user assignment consistency while enabling linear scaling of evaluation throughput. The architecture builds upon our existing load balancing and health monitoring capabilities.\n\n**Event Streaming Architecture** replaces direct database interactions with event-driven patterns using systems like Apache Kafka. Flag changes become events in the stream, enabling multiple consumers to process updates for real-time propagation, analytics processing, and audit logging without impacting evaluation performance.\n\n**Polyglot Storage Strategies** optimize data storage by matching storage technologies to access patterns. Flag definitions might live in document stores for flexible schema evolution, while evaluation results use time-series databases optimized for analytics queries. The abstraction layers in our architecture facilitate these storage technology choices without affecting client interfaces.\n\n### Future-Proofing Considerations\n\nThe extensions described maintain compatibility with our core architectural decisions while providing natural evolution paths as requirements continue expanding.\n\n**API Versioning Strategy** ensures backward compatibility as new capabilities add to existing interfaces. The REST API design accommodates feature additions through optional parameters and response fields, while SDK interfaces use extensible patterns that don't break existing client code.\n\n**Configuration Schema Evolution** supports adding new flag types, targeting criteria, and evaluation modes without requiring system-wide updates. The validation framework accommodates schema versioning, enabling gradual rollout of new capabilities across distributed deployments.\n\n**Telemetry and Instrumentation** provides comprehensive visibility into system behavior as complexity increases. This builds upon our health monitoring foundation while adding detailed metrics for capacity planning, performance optimization, and operational decision-making.\n\n> **Critical Insight**: Each extension maintains the evaluation-first design principle by ensuring core flag evaluation performance doesn't degrade as new capabilities are added. Complex features are implemented as optional enhancements rather than fundamental changes to the evaluation path.\n\n### Implementation Guidance\n\nThe extensions described can be implemented incrementally without disrupting existing functionality. The modular architecture established in our original design provides natural extension points for these capabilities.\n\n#### Technology Recommendations\n\n| Extension Category | Simple Approach | Advanced Approach |\n|-------------------|------------------|-------------------|\n| Dynamic Segmentation | HTTP calls to external APIs with caching | Event-driven segment computation with stream processing |\n| Edge Distribution | CDN with API caching | Dedicated edge computing platform with custom evaluation nodes |\n| ML Integration | Periodic batch analysis with manual recommendations | Real-time ML inference with automated optimization |\n| Enterprise Integration | Basic RBAC with API keys | Full SSO integration with enterprise workflow systems |\n| Advanced Analytics | Extended PostgreSQL with time-series tables | Dedicated analytics database with specialized query engines |\n\n#### Extension Implementation Strategy\n\nWhen implementing these extensions, follow a **capability-driven approach** that adds new functionality without modifying core evaluation logic. Each extension should:\n\n1. **Maintain Interface Compatibility**: New capabilities extend existing interfaces rather than replacing them, ensuring client SDKs continue working without modification.\n\n2. **Preserve Performance Characteristics**: Extensions shouldn't degrade evaluation latency or throughput. Performance-impacting features like dynamic segmentation include circuit breakers and caching mechanisms.\n\n3. **Support Gradual Rollout**: New capabilities can be enabled incrementally, allowing validation in development and staging environments before production deployment.\n\n4. **Provide Operational Visibility**: Each extension includes monitoring, logging, and health checking capabilities that integrate with existing operational tools.\n\nThe architectural foundation we've established provides natural extension points through:\n- Plugin interfaces for new evaluation criteria and segment types\n- Event streaming capabilities for real-time data integration\n- Caching abstractions that support new data sources\n- Health monitoring frameworks that accommodate new component types\n\n#### Development Priorities\n\nWhen choosing which extensions to implement first, consider business value and architectural complexity:\n\n**High Value, Low Complexity**: Multi-environment support and basic flag dependencies provide immediate operational benefits with minimal architectural changes.\n\n**High Value, High Complexity**: Advanced targeting and ML-driven optimization deliver significant capabilities but require careful implementation to maintain performance.\n\n**Foundation Building**: Edge distribution and enterprise integration create platforms for future capabilities while providing immediate value for large-scale deployments.\n\nThe modular architecture ensures that implementing one extension doesn't preclude others, allowing development teams to prioritize based on immediate business needs while maintaining long-term architectural flexibility.\n\n\n## Glossary\n\n> **Milestone(s):** This section provides comprehensive definitions for terminology used across all three milestones, ensuring consistent understanding of concepts throughout the Flag Evaluation Engine (Milestone 1), Real-time Flag Updates (Milestone 2), and Flag Analytics & Experiments (Milestone 3) implementation.\n\nThe feature flag system introduces numerous specialized terms and concepts that span multiple domains including distributed systems, statistical analysis, real-time communication, and software release management. This glossary serves as the authoritative reference for understanding the precise meaning of each term as used within our system's context.\n\n### Core System Concepts\n\n**Feature Flags** are runtime toggles that control feature availability without requiring code deployment. Think of feature flags as smart light switches in a building automation system - they can be controlled remotely, scheduled to activate at specific times, and configured with complex rules about who can access them. Unlike simple boolean toggles, our feature flags support multiple variants, percentage rollouts, and sophisticated targeting rules.\n\n**Air Traffic Control** serves as our mental model for coordinating software releases. Just as air traffic controllers manage multiple aircraft approaching an airport with different priorities, weather conditions, and landing capabilities, feature flags coordinate the rollout of multiple features to different user segments with varying risk tolerances and business requirements. The control tower (flag management system) maintains a real-time view of all active \"flights\" (feature rollouts) and can adjust their \"flight paths\" (targeting rules) or \"landing sequences\" (rollout percentages) based on current conditions.\n\n**Consistent Hashing** is the deterministic algorithm that ensures users receive the same variants across evaluations. This functions like a deterministic seating assignment system - given a user ID and flag key, the algorithm always assigns the same \"seat\" (variant) to that user, regardless of when or where the assignment occurs. This prevents users from experiencing jarring transitions between different feature variants.\n\n**Graceful Degradation** describes how the system maintains functionality during partial failures. Like a commercial building's backup power systems, the feature flag system includes multiple fallback layers: memory cache, local storage, and default values. When the primary flag service becomes unavailable, the system automatically switches to increasingly stale but still functional data sources.\n\n**Flag Debt** represents the accumulation of obsolete feature flags in the codebase. Similar to technical debt, flag debt compounds over time as old flags remain in code long after their experiments conclude. Each unused flag increases cognitive load, creates potential security risks through unintended code paths, and complicates system maintenance.\n\n### Evaluation and Targeting\n\n**Evaluation Flow** describes the step-by-step process from client request to variant assignment. The flow begins when a client SDK requests a flag evaluation, continues through rule processing and consistent hashing, and concludes with variant assignment and exposure logging. Each step includes error handling and fallback mechanisms to ensure reliable operation.\n\n**Targeting Rules** are conditions that determine user variant assignment based on user context and environmental factors. These rules function like sophisticated email filters that can examine multiple user attributes, combine conditions with boolean logic, and apply percentage-based allocations. Rules are evaluated in priority order until a match is found.\n\n**Percentage Rollout** enables gradual feature exposure using allocation buckets. Think of this as a controlled water release from a dam - you can gradually open the gates (increase percentage) to allow more water (users) through while monitoring downstream effects (metrics). The bucket ranges are calculated using consistent hashing to ensure stable user assignment.\n\n**User Context** provides comprehensive user information for targeting decisions. This includes stable identifiers, demographic attributes, behavioral data, and environmental context like geographic location or device type. The context serves as the input to targeting rule evaluation and consistent hashing calculations.\n\n**Segment Membership** represents pre-computed group classifications for efficient targeting. Rather than evaluating complex conditions for each flag request, segments allow for efficient \"user is in premium_customers segment\" checks. Segments can be static (manually managed) or dynamic (automatically computed based on user attributes).\n\n**Dynamic Segmentation** performs real-time evaluation of user segment membership during flag evaluation. While pre-computed segments optimize performance for stable user groups, dynamic segmentation enables targeting based on real-time context like current session behavior or time-sensitive conditions.\n\n### Data Structures and Types\n\n| Term | Description | Key Fields |\n|------|-------------|------------|\n| `FlagKey` | String identifier uniquely identifying a feature flag across the system | - |\n| `UserID` | Stable identifier for a user that remains consistent across sessions and evaluations | - |\n| `Variant` | Represents a possible flag outcome with its configuration and traffic allocation | Key, Value, Weight |\n| `UserContext` | Comprehensive user information used for targeting and segmentation | UserID, Attributes, Segments |\n| `EvaluationResult` | Complete outcome of flag evaluation including value, reason, and audit trail | FlagKey, Value, Variant, Reason, Source |\n| `FlagDefinition` | Complete specification of a feature flag including all rules and variants | FlagKey, Name, Description, Variants, DefaultVariant, Rules, Dependencies |\n| `TargetingRule` | Individual targeting condition with associated variant allocation | Conditions, Operator, Allocation |\n| `AttributeValue` | Type-safe wrapper for user attributes supporting multiple data types | - |\n\n### Real-time Communication\n\n**Server-Sent Events** provide unidirectional streaming protocol for real-time updates from server to client. SSE functions like a radio broadcast where the server (radio station) transmits updates to all listening clients (radios). Unlike bidirectional protocols like WebSocket, SSE maintains simplicity by focusing solely on server-to-client communication with built-in reconnection handling.\n\n**Cache Invalidation** describes updating cached flag definitions when configurations change. Like a content delivery network pushing updated website assets, the flag system must coordinate cache updates across all client instances to prevent serving stale flag configurations.\n\n**Connection Management** handles the establishment, maintenance, and recovery of streaming connections between clients and the update service. This includes implementing exponential backoff for reconnection attempts, maintaining connection state, and gracefully handling network partitions.\n\n**Thundering Herd** occurs when mass simultaneous connection attempts overwhelm the service. This typically happens when many clients lose connection simultaneously (due to server restart or network issue) and all attempt to reconnect immediately. The system prevents this through randomized backoff delays.\n\n**Exponential Backoff** implements progressively longer retry delays with randomization to prevent overwhelming failed services. Starting with a short delay (e.g., 100ms), each retry doubles the delay (200ms, 400ms, 800ms) while adding jitter to prevent synchronized retries across multiple clients.\n\n### Statistical and Experimental Concepts\n\n**Flag Analytics** encompasses comprehensive tracking and analysis of feature flag usage and performance. This includes exposure tracking, conversion attribution, performance monitoring, and business impact measurement. Analytics enable data-driven decisions about feature rollouts and business value assessment.\n\n**Exposure Events** are recorded instances of users encountering specific flag variants. Each exposure captures the complete context of the evaluation including user attributes, variant assigned, timestamp, and evaluation reason. These events form the foundation for all subsequent analysis.\n\n**A/B Testing Framework** provides systematic approach to controlled feature experimentation. The framework manages experiment lifecycle from setup through analysis, ensuring proper randomization, statistical power, and unbiased result interpretation.\n\n**Statistical Significance** represents mathematical confidence that observed differences between variants are not due to random chance. The system uses established statistical tests (chi-square for categorical outcomes, t-tests for continuous metrics) with appropriate corrections for multiple comparisons.\n\n**Sample Ratio Mismatch** occurs when the actual variant allocation ratios deviate significantly from intended ratios. This can indicate implementation bugs, biased assignment logic, or data collection issues. The system continuously monitors for SRM and alerts when detected.\n\n**Intent-to-treat Analysis** analyzes all assigned users regardless of actual exposure to the feature. This approach prevents bias from users who opt out or experience technical issues that prevent feature loading, providing a more conservative but unbiased estimate of feature impact.\n\n**Sequential Testing** enables valid interim analysis of experiments without inflating false positive rates. Unlike traditional fixed-sample tests, sequential methods allow peeking at results during the experiment using appropriate statistical boundaries.\n\n**Power Analysis** calculates the sample size needed for reliable effect detection given expected effect size, significance level, and desired statistical power. This prevents underpowered experiments that fail to detect meaningful effects.\n\n**Survivorship Bias** represents analytical error from excluding users who dropped out during the experiment. For example, analyzing only users who completed a multi-step flow ignores the impact on users who abandoned earlier steps.\n\n### System Architecture and Operations\n\n**Evaluation-first Design** prioritizes flag evaluation performance above all other system considerations. Like designing a race car where aerodynamics takes precedence over passenger comfort, our architecture optimizes for sub-millisecond evaluation latency even when this complicates other system aspects.\n\n**Fallback Hierarchy** defines the ordered sequence of data sources used when primary sources become unavailable. The hierarchy typically flows from real-time service → memory cache → local storage → default values, with each layer providing increasingly stale but still functional flag data.\n\n**Circuit Breaker** prevents cascade failures by temporarily stopping requests to failing services. When a dependent service experiences high error rates, the circuit breaker opens, immediately returning cached results instead of continuing to send requests to the failing service.\n\n**Load Shedding** involves selectively dropping requests during high traffic to maintain service availability for critical operations. The system may prioritize flag evaluations over analytics ingestion or defer less critical operations when under extreme load.\n\n**Health Monitoring** systematically checks component operational status to enable proactive issue detection and automated recovery. Each system component reports health metrics including response times, error rates, and resource utilization.\n\n### Error Handling and Resilience\n\n| Error Type | Description | Recovery Strategy |\n|------------|-------------|------------------|\n| `ErrorTypeValidation` | Invalid flag definitions or user context | Return validation errors with specific field information |\n| `ErrorTypeNetwork` | Connection failures or timeouts | Retry with exponential backoff, fallback to cache |\n| `ErrorTypeStorage` | Database or persistence layer failures | Switch to read-only mode, use cached data |\n| `ErrorTypeEvaluation` | Rule processing errors or dependency cycles | Return default variant with error logging |\n| `ErrorTypeCircuit` | Circuit breaker preventing requests | Return cached results, attempt periodic recovery |\n| `ErrorTypeDependency` | Required services unavailable | Activate fallback data sources |\n| `ErrorTypeResource` | Memory or processing capacity exceeded | Enable load shedding, scale horizontally |\n\n**Split-brain Scenario** occurs during network partitions where different parts of the system operate independently with potentially conflicting state. The system prevents this through consistent leadership election and read-only fallback modes during partition events.\n\n**Optimistic Consistency** allows immediate writes with asynchronous distribution to connected clients. While this may create temporary inconsistency across clients, it provides better user experience than waiting for global consensus on every flag change.\n\n**At-least-once Delivery** guarantees message delivery with possible duplication. The system includes sequence numbers and idempotency checks to handle duplicate flag updates gracefully.\n\n### Development and Testing\n\n**Property-based Testing** validates system invariants using randomly generated inputs. Rather than testing specific scenarios, property tests verify that fundamental system properties (like assignment stability and rule determinism) hold across a wide range of inputs.\n\n**Milestone Validation** provides quality gates between development phases. Each milestone includes specific acceptance criteria, test scenarios, and performance benchmarks that must be met before proceeding to subsequent development phases.\n\n**Assignment Stability** ensures users receive the same variant consistently across evaluations. This property is critical for user experience and experiment validity - users should not flip between variants due to evaluation timing or system state.\n\n**Rule Evaluation Determinism** guarantees that targeting rules evaluate consistently given identical input context. This property ensures reliable system behavior and simplifies debugging when evaluation outcomes don't match expectations.\n\n**Cache Consistency** maintains alignment between cached data and authoritative sources. While temporary inconsistency is acceptable for performance, the system must eventually converge to consistent state across all cache levels.\n\n### Advanced Concepts\n\n**Prerequisite Flags** are required flags that must be enabled before dependent flags activate. This creates a dependency graph that prevents invalid feature combinations - for example, a premium feature flag that depends on the user authentication flag being enabled.\n\n**Multi-environment Support** provides independent flag configurations across development, staging, and production environments. Each environment maintains separate flag state while sharing common flag definitions and targeting rule templates.\n\n**Configuration Promotion** enables controlled advancement of flag settings between environments. Changes typically flow from development → staging → production with appropriate testing and approval gates at each stage.\n\n**Edge Evaluation** performs flag evaluation at geographically distributed nodes to reduce latency for global applications. This requires careful cache synchronization and fallback strategies to maintain consistency across edge locations.\n\n**Contextual Targeting** extends basic user targeting to include environmental and situational factors like time of day, geographic location, device characteristics, or application version. This enables sophisticated targeting scenarios like \"show feature X only to mobile users in Pacific timezone during business hours.\"\n\n### Performance and Scalability\n\n**Bucket Ranges** represent deterministic allocation intervals for percentage splits. When implementing a 30%/70% split, users hash into buckets 0-29 (first variant) or 30-99 (second variant). The bucket assignment remains stable as percentages change.\n\n**Sequence Numbers** provide monotonic identifiers that prevent out-of-order processing of flag updates. Each update includes a sequence number that clients use to detect and handle updates that arrive out of order due to network conditions.\n\n**Event Ordering** ensures updates are processed in correct sequence even when network delivery occurs out of order. The system buffers out-of-order events and processes them when missing sequence numbers arrive.\n\n**Resource Exhaustion** occurs when the system runs out of memory, file handles, or other critical resources. The system monitors resource usage and implements graceful degradation strategies like reducing cache sizes or limiting concurrent connections.\n\n**Dependency Graph** represents the directed acyclic graph of flag prerequisite relationships. The system validates this graph to prevent circular dependencies and computes evaluation order to ensure prerequisite flags are evaluated before dependent flags.\n\n### Implementation Guidance\n\nThe glossary definitions above establish the conceptual foundation needed to implement a robust feature flag system. Each term has been defined with sufficient precision to guide implementation decisions while remaining accessible to developers new to feature flag systems.\n\nWhen implementing system components, refer to these definitions to ensure consistent terminology and behavior across all modules. The data structure definitions provide the exact field specifications needed for implementation, while the conceptual terms establish the mental models for understanding system behavior.\n\nFor debugging and troubleshooting, this glossary serves as a reference for understanding error messages, log entries, and system behavior descriptions. When encountering unfamiliar terms in documentation or code comments, this glossary provides the authoritative definition within the context of our feature flag system.\n\nThe progression from basic concepts (feature flags, variants) through advanced topics (statistical significance, edge evaluation) reflects the learning journey developers will experience when implementing and operating the system. Mastering the foundational terms enables understanding of more sophisticated concepts as system requirements evolve.\n"}