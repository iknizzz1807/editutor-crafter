{"html":"<h1 id=\"distributed-job-scheduler-design-document\">Distributed Job Scheduler: Design Document</h1>\n<h2 id=\"overview\">Overview</h2>\n<p>A distributed job scheduler that executes tasks across multiple workers using cron expressions for timing, with priorities, retries, and fault-tolerant coordination. The key architectural challenge is maintaining consistency and preventing duplicate execution while ensuring high availability and fair job distribution across a dynamic cluster of workers.</p>\n<blockquote>\n<p>This guide is meant to help you understand the big picture before diving into each milestone. Refer back to it whenever you need context on how components connect.</p>\n</blockquote>\n<h2 id=\"context-and-problem-statement\">Context and Problem Statement</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section provides foundational understanding for all three milestones by establishing the need for distributed job scheduling and the technical challenges that inform our architectural decisions.</p>\n</blockquote>\n<h3 id=\"problem-overview\">Problem Overview</h3>\n<p>Think of distributed job scheduling as managing a city&#39;s public transportation system. Just as a city needs buses to run on time, reach every neighborhood, and continue operating even when some vehicles break down, modern applications need <strong>scheduled tasks</strong> to execute reliably across multiple machines, handle varying workloads, and maintain service availability despite individual server failures.</p>\n<p>In a traditional single-server environment, job scheduling is straightforward—you run a cron daemon on one machine, and it executes tasks at predetermined times. This works perfectly for simple scenarios, like a personal blog that generates a daily summary or a small business that backs up its database nightly. However, as systems scale and reliability requirements increase, this centralized approach reveals critical limitations.</p>\n<p>Consider an e-commerce platform that needs to process millions of scheduled tasks daily: sending abandoned cart reminders, generating analytics reports, processing subscription renewals, cleaning up temporary files, and synchronizing inventory across multiple warehouses. A single-server scheduler becomes a <strong>single point of failure</strong>—if that machine crashes, all scheduled work stops. Even worse, the machine might become overwhelmed by the sheer volume of tasks, leading to delays, missed schedules, and cascading failures throughout the system.</p>\n<p>The distributed job scheduler we&#39;re building addresses these challenges by spreading the work across multiple <strong>worker nodes</strong>, much like how a transit system uses multiple buses to serve a city. When one bus breaks down, others continue running their routes. When passenger demand increases in certain areas, the system can deploy additional buses to those routes. Similarly, our scheduler can distribute jobs across healthy workers, automatically reassign work from failed nodes, and scale capacity by adding more worker machines.</p>\n<p>The core insight is that <strong>reliable scheduling at scale requires coordination</strong>. Just as buses need a central dispatch system to prevent multiple buses from serving the same route simultaneously while ensuring no routes go unserved, distributed workers need coordination mechanisms to prevent duplicate job execution while guaranteeing that every scheduled task eventually runs.</p>\n<p>However, this coordination introduces complexity that doesn&#39;t exist in single-server systems. We must solve fundamental distributed systems problems: How do multiple workers agree on who should execute a specific job? How do we detect when a worker has failed and reassign its work? How do we ensure that a job runs exactly once, even when network partitions occur or workers crash mid-execution? These challenges form the technical foundation for our entire design.</p>\n<h3 id=\"existing-approaches\">Existing Approaches</h3>\n<p>The landscape of job scheduling solutions reflects different trade-offs between simplicity, reliability, and scalability. Understanding these existing approaches helps us appreciate why we need a custom distributed scheduler and informs our architectural decisions.</p>\n<table>\n<thead>\n<tr>\n<th>Approach</th>\n<th>Description</th>\n<th>Strengths</th>\n<th>Limitations</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Centralized Schedulers</strong></td>\n<td>Single coordinator manages all scheduling (cron, Jenkins, Airflow single-node)</td>\n<td>Simple to reason about, strong consistency guarantees, easy debugging</td>\n<td>Single point of failure, limited scalability, resource bottleneck</td>\n</tr>\n<tr>\n<td><strong>Message Queue Systems</strong></td>\n<td>Jobs queued in brokers, workers poll for tasks (RabbitMQ, AWS SQS + Lambda)</td>\n<td>High throughput, natural load distribution, proven reliability</td>\n<td>Limited scheduling flexibility, complex delay mechanisms, external dependencies</td>\n</tr>\n<tr>\n<td><strong>Database-Driven Polling</strong></td>\n<td>Jobs stored in DB tables, workers query for pending tasks</td>\n<td>Simple implementation, leverages existing infrastructure, transaction support</td>\n<td>Database becomes bottleneck, polling inefficiency, lock contention</td>\n</tr>\n<tr>\n<td><strong>Distributed Coordination</strong></td>\n<td>Multiple schedulers coordinate via consensus (Kubernetes CronJobs, distributed Quartz)</td>\n<td>High availability, horizontal scalability, fault tolerance</td>\n<td>Complex implementation, consensus overhead, split-brain risks</td>\n</tr>\n</tbody></table>\n<p><strong>Centralized schedulers</strong> like traditional cron or single-node Airflow offer the strongest consistency guarantees because there&#39;s only one decision-maker. When you schedule a job to run &quot;every day at 2 AM,&quot; you can be absolutely certain it won&#39;t run multiple times because only one scheduler exists. These systems are also easier to debug—you have one log file, one configuration, and one point of control. However, they fail catastrophically when the central coordinator goes down, and they cannot scale beyond the resources of a single machine.</p>\n<p><strong>Message queue approaches</strong> excel at handling high-throughput job processing by naturally distributing work across multiple consumer workers. Systems like RabbitMQ with delayed message plugins or AWS SQS with visibility timeouts provide reliable job delivery guarantees. However, they struggle with complex scheduling requirements. Implementing a job that runs &quot;every weekday at 9 AM except holidays&quot; requires external scheduling logic to enqueue messages at the right times, and advanced features like job dependencies or conditional execution become cumbersome.</p>\n<p><strong>Database-driven polling</strong> represents a common middle-ground approach where jobs are stored as database records with scheduling metadata, and workers periodically query for pending tasks. This leverages existing database infrastructure and provides ACID transaction support for job state transitions. However, the database becomes a bottleneck as worker counts increase, and frequent polling creates unnecessary load. Additionally, implementing fair job distribution and preventing race conditions requires careful lock management.</p>\n<p><strong>Distributed coordination approaches</strong> like Kubernetes CronJobs or clustered Quartz schedulers provide both high availability and scalability by running multiple scheduler instances that coordinate through consensus protocols. These systems can survive individual node failures and distribute load across multiple coordinators. However, they introduce significant complexity in consensus algorithms, leader election, and split-brain prevention.</p>\n<blockquote>\n<p><strong>Design Insight</strong>: Each approach optimizes for different priorities. Centralized systems prioritize correctness and simplicity. Message queues prioritize throughput and reliability. Database polling prioritizes implementation simplicity. Distributed coordination prioritizes availability and scalability. Our design must explicitly choose which properties matter most for our use case.</p>\n</blockquote>\n<p>Our distributed job scheduler combines elements from multiple approaches. We use <strong>distributed coordination</strong> for high availability and scalability, but implement our own lightweight consensus mechanism tailored to scheduling workloads rather than adopting heavyweight protocols like Raft. We incorporate <strong>message queue patterns</strong> for reliable job delivery between coordinators and workers, but maintain scheduling logic within the scheduler rather than pushing complexity to external systems. We leverage <strong>database storage</strong> for job persistence and atomic state transitions, but minimize polling overhead through event-driven notifications.</p>\n<blockquote>\n<p><strong>Decision: Hybrid Architecture with Custom Coordination</strong></p>\n<ul>\n<li><strong>Context</strong>: Existing solutions either sacrifice availability for simplicity or introduce unnecessary complexity for general-purpose consensus</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>Pure message queue with external scheduling (simple but limited scheduling flexibility)</li>\n<li>Database polling with advisory locks (simple but poor scaling characteristics)  </li>\n<li>Full Raft consensus for all scheduling decisions (robust but heavyweight for our use case)</li>\n<li>Custom coordination protocol optimized for scheduling workloads</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Hybrid architecture with custom coordination protocol</li>\n<li><strong>Rationale</strong>: Scheduling workloads have specific characteristics (time-based triggers, priority ordering, delayed execution) that allow for simpler coordination than general-purpose consensus while still maintaining availability and consistency</li>\n<li><strong>Consequences</strong>: We gain scheduling-optimized performance and can implement exactly-once execution guarantees, but must implement and maintain our own coordination logic</li>\n</ul>\n</blockquote>\n<h3 id=\"technical-challenges\">Technical Challenges</h3>\n<p>Building a distributed job scheduler requires solving three fundamental distributed systems problems: <strong>consensus</strong>, <strong>failure detection</strong>, and <strong>exactly-once execution</strong>. These challenges are interconnected—solving one affects how we approach the others—and their solutions form the core of our architectural design.</p>\n<h4 id=\"consensus-who-decides-what-jobs-run-when\">Consensus: Who Decides What Jobs Run When?</h4>\n<p>The consensus problem in distributed scheduling is like coordinating traffic at a busy intersection without traffic lights. Multiple scheduler nodes might simultaneously decide that a job scheduled for &quot;2:00 PM&quot; should execute now, leading to duplicate execution. Alternatively, in trying to avoid duplicates, all nodes might assume another node will handle the job, resulting in missed executions.</p>\n<p>Traditional consensus algorithms like Raft or PBFT provide strong consistency guarantees by ensuring all nodes agree on a single sequence of operations. However, these algorithms are designed for general-purpose state machine replication and carry significant overhead for our scheduling use case. Consider a job scheduled to run every hour—full consensus for each execution decision would require multiple round-trips between nodes, potentially taking longer than the job execution itself.</p>\n<p>Our scheduling workload has specific characteristics that allow for more efficient coordination:</p>\n<ol>\n<li><strong>Time-based triggers</strong>: Most decisions are triggered by time passage rather than external events</li>\n<li><strong>Predictable scheduling</strong>: Next execution times can be calculated in advance using cron expressions</li>\n<li><strong>Priority ordering</strong>: Jobs have explicit priority levels that provide natural ordering</li>\n<li><strong>Delayed execution</strong>: Jobs can wait in queues without immediate execution requirements</li>\n</ol>\n<p>These characteristics enable a <strong>leader-based coordination model</strong> where one scheduler node acts as the primary coordinator for job scheduling decisions, while other nodes remain in standby mode ready to take over during failures. This approach reduces coordination overhead during normal operation while maintaining availability through leader election during failures.</p>\n<table>\n<thead>\n<tr>\n<th>Consensus Challenge</th>\n<th>Traditional Approach</th>\n<th>Our Scheduling-Optimized Approach</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Job Execution Decisions</strong></td>\n<td>Full consensus on each job execution</td>\n<td>Leader decides, followers standby with leader election</td>\n</tr>\n<tr>\n<td><strong>Clock Synchronization</strong></td>\n<td>Complex vector clocks or logical timestamps</td>\n<td>NTP synchronization with tolerance windows</td>\n</tr>\n<tr>\n<td><strong>Schedule Conflicts</strong></td>\n<td>Distributed lock acquisition per job</td>\n<td>Centralized scheduling with atomic job claiming</td>\n</tr>\n<tr>\n<td><strong>Split-Brain Prevention</strong></td>\n<td>Quorum-based decisions requiring majority</td>\n<td>Lease-based leadership with automatic expiration</td>\n</tr>\n</tbody></table>\n<h4 id=\"failure-detection-when-has-a-worker-actually-failed\">Failure Detection: When Has a Worker Actually Failed?</h4>\n<p>Failure detection in distributed systems is notoriously difficult because there&#39;s no reliable way to distinguish between a slow worker and a failed worker. Network partitions can make healthy workers appear dead, while zombie processes can continue sending heartbeats despite being unable to process jobs. This is known as the <strong>failure detection impossibility</strong> in asynchronous distributed systems.</p>\n<p>In our job scheduler context, failure detection mistakes have serious consequences:</p>\n<ul>\n<li><strong>False positives</strong> (marking healthy workers as failed) lead to unnecessary job reassignment and potential duplicate execution</li>\n<li><strong>False negatives</strong> (not detecting actual failures) result in jobs being assigned to dead workers, causing missed executions and system-wide delays</li>\n</ul>\n<p>Consider a worker executing a long-running data analysis job that takes 45 minutes to complete. If our failure detection timeout is set to 30 minutes, we&#39;ll incorrectly mark the worker as failed and potentially start duplicate execution on another worker. Conversely, if we set the timeout to 90 minutes to accommodate long jobs, actual worker failures won&#39;t be detected quickly enough, leaving jobs stuck in limbo.</p>\n<p>Our approach uses a <strong>multi-layered failure detection strategy</strong> that combines multiple signals:</p>\n<ol>\n<li><strong>Heartbeat timeouts</strong>: Workers send periodic &quot;I&#39;m alive&quot; messages with configurable timeout thresholds</li>\n<li><strong>Job progress updates</strong>: Workers report intermediate progress on long-running jobs to prove they&#39;re actively processing</li>\n<li><strong>Lease-based job ownership</strong>: Jobs are assigned with time-bounded leases that automatically expire, enabling recovery without explicit failure detection</li>\n<li><strong>Graceful shutdown signaling</strong>: Workers announce their intention to shut down, allowing clean job handoff</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>Failure Detection Layer</th>\n<th>Purpose</th>\n<th>Timeout</th>\n<th>False Positive Risk</th>\n<th>False Negative Risk</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Heartbeat Messages</strong></td>\n<td>Basic liveness detection</td>\n<td>30 seconds</td>\n<td>Network partitions</td>\n<td>Process zombies</td>\n</tr>\n<tr>\n<td><strong>Job Progress Updates</strong></td>\n<td>Active processing verification</td>\n<td>5 minutes</td>\n<td>Long-running jobs</td>\n<td>Infinite loops</td>\n</tr>\n<tr>\n<td><strong>Lease Expiration</strong></td>\n<td>Automatic job recovery</td>\n<td>Job-specific</td>\n<td>Resource constraints</td>\n<td>Slow processing</td>\n</tr>\n<tr>\n<td><strong>Graceful Shutdown</strong></td>\n<td>Clean worker termination</td>\n<td>60 seconds</td>\n<td>None</td>\n<td>Sudden crashes</td>\n</tr>\n</tbody></table>\n<h4 id=\"exactly-once-execution-the-distributed-scheduling-holy-grail\">Exactly-Once Execution: The Distributed Scheduling Holy Grail</h4>\n<p>Exactly-once execution is the most challenging problem in distributed job scheduling. Unlike at-least-once delivery (where duplicates are acceptable) or at-most-once delivery (where job loss is acceptable), exactly-once requires that every scheduled job runs precisely once, despite worker failures, network partitions, and coordinator crashes.</p>\n<p>The fundamental challenge is that network failures can occur at any point during job execution, making it impossible to distinguish between these scenarios:</p>\n<ol>\n<li><strong>Job never started</strong>: The worker received the job assignment but crashed before beginning execution</li>\n<li><strong>Job started but didn&#39;t finish</strong>: The worker began execution but crashed mid-way through processing</li>\n<li><strong>Job finished but acknowledgment was lost</strong>: The worker completed the job successfully but the network failed before it could report completion</li>\n<li><strong>Job finished and reported</strong>: The worker completed the job and successfully reported completion, but a delayed retry caused duplicate assignment</li>\n</ol>\n<p>Each scenario requires different recovery actions, but they&#39;re indistinguishable from the coordinator&#39;s perspective. Traditional approaches use <strong>idempotency</strong> (making duplicate executions safe) or <strong>transactional semantics</strong> (rolling back partial executions), but these place significant burden on job implementations.</p>\n<p>Our scheduler implements exactly-once execution through a combination of techniques:</p>\n<p><strong>Job Leasing with Fencing Tokens</strong>: Each job assignment includes a unique, monotonically increasing fencing token. Workers must present valid tokens when reporting job results, preventing race conditions where slow workers report results after their jobs have been reassigned.</p>\n<p><strong>Execution State Tracking</strong>: Jobs progress through explicit states (<code>PENDING</code> → <code>CLAIMED</code> → <code>EXECUTING</code> → <code>COMPLETED</code>), with each transition recorded atomically in persistent storage. This provides a clear audit trail and enables precise recovery logic.</p>\n<p><strong>Idempotency Key Deduplication</strong>: Jobs include client-provided idempotency keys that prevent duplicate submissions. Even if the same cron schedule fires multiple times due to coordinator failures, duplicate jobs are silently ignored.</p>\n<p><strong>Timeout-Based Recovery</strong>: Jobs that remain in intermediate states (<code>CLAIMED</code>, <code>EXECUTING</code>) beyond their lease timeouts are automatically made available for reassignment, ensuring forward progress even when workers fail silently.</p>\n<table>\n<thead>\n<tr>\n<th>Exactly-Once Challenge</th>\n<th>Problem</th>\n<th>Our Solution</th>\n<th>Trade-offs</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Duplicate Submission</strong></td>\n<td>Same cron schedule triggers multiple times</td>\n<td>Idempotency key deduplication</td>\n<td>Requires deterministic key generation</td>\n</tr>\n<tr>\n<td><strong>Worker Failure Mid-Execution</strong></td>\n<td>Unknown whether job completed before crash</td>\n<td>Atomic state transitions + timeouts</td>\n<td>Jobs must be idempotent or resumable</td>\n</tr>\n<tr>\n<td><strong>Network Partition During Reporting</strong></td>\n<td>Coordinator can&#39;t distinguish completion from failure</td>\n<td>Fencing tokens prevent stale reports</td>\n<td>Adds complexity to job result handling</td>\n</tr>\n<tr>\n<td><strong>Coordinator Failure During Assignment</strong></td>\n<td>Job assignment state may be lost or duplicated</td>\n<td>Persistent job state + recovery scanning</td>\n<td>Requires durable storage for all state</td>\n</tr>\n</tbody></table>\n<p>⚠️ <strong>Pitfall: Assuming Network Reliability</strong></p>\n<p>A common mistake is designing the scheduler assuming that network operations either succeed completely or fail immediately. In reality, network operations can experience arbitrary delays, partial failures, or reordering. For example, a job assignment message might be delayed for several minutes due to network congestion, arriving after the job has already been reassigned to another worker due to timeout. This can lead to duplicate execution unless the system uses fencing tokens or similar disambiguation mechanisms.</p>\n<p>The solution is to design all inter-component communication as potentially unreliable and implement disambiguation mechanisms (like fencing tokens) that allow recipients to determine whether received messages are current or stale.</p>\n<blockquote>\n<p><strong>Critical Design Principle</strong>: Our distributed scheduler must degrade gracefully under various failure conditions. When consensus is impossible, we prefer conservative decisions (potentially missing a single job execution) over dangerous ones (definitely executing jobs multiple times). This bias toward safety over liveness reflects the reality that most scheduled jobs are periodic—missing one execution of an hourly job is recoverable, while duplicate executions often cause irreversible side effects.</p>\n</blockquote>\n<p>These three technical challenges—consensus, failure detection, and exactly-once execution—drive every major architectural decision in our distributed job scheduler. The solutions we choose for each problem must work together cohesively, as optimizing for one often creates constraints for the others.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>This foundational section doesn&#39;t include implementation code, but understanding the technical challenges above informs the technology choices we&#39;ll make throughout the project.</p>\n<h4 id=\"technology-recommendations-for-distributed-coordination\">Technology Recommendations for Distributed Coordination</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n<th>Trade-offs</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Consensus/Coordination</strong></td>\n<td>Redis with Lua scripts for atomic operations</td>\n<td>etcd with Raft consensus for leader election</td>\n<td>Redis simpler but less fault-tolerant; etcd more complex but industry-proven</td>\n</tr>\n<tr>\n<td><strong>Job Persistence</strong></td>\n<td>PostgreSQL with advisory locks</td>\n<td>Redis Streams with consumer groups</td>\n<td>PostgreSQL stronger consistency; Redis higher performance</td>\n</tr>\n<tr>\n<td><strong>Worker Communication</strong></td>\n<td>HTTP REST with polling</td>\n<td>gRPC with streaming for real-time updates</td>\n<td>REST simpler debugging; gRPC better performance</td>\n</tr>\n<tr>\n<td><strong>Time Synchronization</strong></td>\n<td>Basic system clock comparison</td>\n<td>NTP daemon with drift monitoring</td>\n<td>System clocks sufficient for most use cases; NTP required for tight timing</td>\n</tr>\n</tbody></table>\n<h4 id=\"key-architectural-decisions-to-make\">Key Architectural Decisions to Make</h4>\n<p>As we progress through the implementation milestones, we&#39;ll need to make several critical decisions that balance the trade-offs identified in this section:</p>\n<p><strong>Consistency vs. Availability</strong>: When network partitions occur, do we prioritize ensuring no duplicate job execution (consistency) or ensuring jobs continue to be scheduled (availability)? Our design leans toward consistency for safety.</p>\n<p><strong>Coordination Complexity</strong>: Do we implement full consensus for all decisions, or use simpler leader-based coordination with the risk of brief unavailability during failover? We choose leader-based coordination for performance.</p>\n<p><strong>Failure Detection Sensitivity</strong>: Do we use aggressive timeouts that quickly detect failures but risk false positives, or conservative timeouts that reduce false positives but slow failure recovery? We use configurable timeouts that can be tuned per deployment.</p>\n<p><strong>Storage Dependencies</strong>: Do we require external coordination services like etcd, or can we build coordination on top of simpler storage like Redis or PostgreSQL? We support multiple storage backends with different consistency guarantees.</p>\n<p>These decisions will become concrete as we implement each milestone, starting with the cron expression parser that must handle timezone-aware scheduling across distributed nodes.</p>\n<h2 id=\"goals-and-non-goals\">Goals and Non-Goals</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section establishes the scope and requirements for all three milestones by defining what the distributed job scheduler must accomplish and explicitly excluding complex enterprise features.</p>\n</blockquote>\n<p>Think of defining project goals like planning a city&#39;s public transportation system. You need to be crystal clear about what routes you&#39;ll serve (functional goals), how many passengers you can handle and how fast they&#39;ll get there (non-functional goals), and what services you explicitly won&#39;t provide like door-to-door limousine service (non-goals). Without this clarity, you&#39;ll either build something that doesn&#39;t meet user needs or get overwhelmed trying to solve every possible problem at once.</p>\n<p>The goals for our distributed job scheduler emerge from real-world requirements where organizations need to execute recurring tasks reliably across multiple machines. These goals directly map to our three milestones: parsing scheduling expressions, managing job priorities and queuing, and coordinating work across a cluster of machines. Equally important are the non-goals that keep this project feasible for implementation while still providing substantial learning value.</p>\n<h3 id=\"functional-goals\">Functional Goals</h3>\n<p>The functional goals define what the distributed job scheduler must actually do for users. These capabilities form the core user-facing behavior that determines whether the system succeeds or fails in practice.</p>\n<p><strong>Cron Expression Scheduling</strong> forms the foundation of time-based job execution. The scheduler must parse standard five-field cron expressions (<code>minute hour day-of-month month day-of-week</code>) and calculate the next execution time with perfect accuracy. This includes handling wildcards (<code>*</code>), ranges (<code>1-5</code>), step values (<code>*/15</code>), and specific lists (<code>1,3,5</code>). The system should also support common shorthand aliases like <code>@daily</code>, <code>@hourly</code>, and <code>@weekly</code> for user convenience.</p>\n<blockquote>\n<p><strong>Decision: Standard Five-Field Cron Support</strong></p>\n<ul>\n<li><strong>Context</strong>: Multiple cron formats exist, from traditional five fields to extended six-field versions with seconds</li>\n<li><strong>Options Considered</strong>: Five-field only, six-field with seconds, full Quartz-style expressions</li>\n<li><strong>Decision</strong>: Support standard five-field cron with common aliases</li>\n<li><strong>Rationale</strong>: Five-field cron covers 95% of real-world scheduling needs while keeping parsing complexity manageable for a learning project</li>\n<li><strong>Consequences</strong>: Users get familiar, well-documented syntax, but cannot schedule sub-minute tasks</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Cron Feature</th>\n<th>Supported</th>\n<th>Example</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Wildcards</td>\n<td>Yes</td>\n<td><code>* * * * *</code></td>\n<td>Every minute</td>\n</tr>\n<tr>\n<td>Specific Values</td>\n<td>Yes</td>\n<td><code>30 14 * * 1</code></td>\n<td>2:30 PM every Monday</td>\n</tr>\n<tr>\n<td>Ranges</td>\n<td>Yes</td>\n<td><code>0 9-17 * * 1-5</code></td>\n<td>Every hour during business days</td>\n</tr>\n<tr>\n<td>Step Values</td>\n<td>Yes</td>\n<td><code>*/15 * * * *</code></td>\n<td>Every 15 minutes</td>\n</tr>\n<tr>\n<td>Lists</td>\n<td>Yes</td>\n<td><code>0 8,12,18 * * *</code></td>\n<td>8 AM, noon, and 6 PM daily</td>\n</tr>\n<tr>\n<td>Aliases</td>\n<td>Yes</td>\n<td><code>@daily</code>, <code>@weekly</code></td>\n<td>Common scheduling shortcuts</td>\n</tr>\n</tbody></table>\n<p><strong>Priority-Based Job Queuing</strong> ensures that critical jobs execute before less important ones. The system must accept jobs with numeric priority levels (higher numbers indicate higher priority) and guarantee that a higher-priority job never waits behind a lower-priority job when workers are available. This requires a priority queue implementation that can handle thousands of pending jobs efficiently.</p>\n<p>The queuing system must also support <strong>delayed execution</strong> where jobs submitted now don&#39;t become eligible for execution until a future timestamp. This enables both one-time scheduled jobs and recurring jobs generated from cron expressions. Jobs should remain invisible to workers until their scheduled time arrives.</p>\n<p><strong>Deduplication</strong> prevents the same job from being queued multiple times within a configurable time window. Each job submission includes an idempotency key, and the system silently ignores submissions with duplicate keys that haven&#39;t expired. This protects against client retry logic accidentally flooding the queue with identical work.</p>\n<table>\n<thead>\n<tr>\n<th>Queue Operation</th>\n<th>Behavior</th>\n<th>Guarantees</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Enqueue</td>\n<td>Accept job with priority and schedule time</td>\n<td>Atomic insertion with deduplication check</td>\n</tr>\n<tr>\n<td>Dequeue</td>\n<td>Return highest-priority ready job</td>\n<td>Strict priority ordering among ready jobs</td>\n</tr>\n<tr>\n<td>Delayed Jobs</td>\n<td>Hold jobs until scheduled time</td>\n<td>Jobs become visible exactly at schedule time</td>\n</tr>\n<tr>\n<td>Deduplication</td>\n<td>Reject jobs with duplicate idempotency keys</td>\n<td>Configurable deduplication window (e.g., 1 hour)</td>\n</tr>\n</tbody></table>\n<p><strong>Multi-Worker Coordination</strong> distributes job execution across a cluster of worker machines while preventing duplicate execution. The system must implement distributed locking so that exactly one worker can claim each job. Workers use the <code>claimJob()</code> operation to atomically reserve a job for execution, receiving a unique fencing token that prevents stale operations from affecting job state.</p>\n<p>The coordination layer tracks worker health through periodic <code>heartbeat()</code> signals. When a worker fails to send heartbeats within the configured timeout, the system automatically reassigns that worker&#39;s in-progress jobs to healthy workers. This ensures jobs complete even when individual machines crash or become unresponsive.</p>\n<p><strong>Fault Tolerance</strong> keeps the scheduler operating despite individual component failures. The system must detect worker failures through missed heartbeats and reassign their jobs to healthy workers. Job state persists in durable storage (Redis or similar) so that scheduler restarts don&#39;t lose pending work. The leader election mechanism ensures exactly one coordinator node manages job assignment even if multiple scheduler instances are running.</p>\n<blockquote>\n<p><strong>Decision: At-Least-Once Job Execution</strong></p>\n<ul>\n<li><strong>Context</strong>: Distributed systems can guarantee at-most-once or at-least-once execution, but not exactly-once without significant complexity</li>\n<li><strong>Options Considered</strong>: At-most-once (jobs may be lost), at-least-once (jobs may run twice), exactly-once (complex)</li>\n<li><strong>Decision</strong>: Provide at-least-once execution with idempotency key support</li>\n<li><strong>Rationale</strong>: Most job types can be made idempotent, and losing jobs is worse than occasionally running them twice</li>\n<li><strong>Consequences</strong>: Job implementations must handle duplicate execution gracefully, but no jobs are lost due to failures</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Fault Tolerance Feature</th>\n<th>Recovery Time</th>\n<th>Detection Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Worker Failure</td>\n<td>30-60 seconds</td>\n<td>Missed heartbeat timeout</td>\n</tr>\n<tr>\n<td>Coordinator Failure</td>\n<td>10-30 seconds</td>\n<td>Leader election timeout</td>\n</tr>\n<tr>\n<td>Storage Failure</td>\n<td>Manual intervention</td>\n<td>Connection errors and timeouts</td>\n</tr>\n<tr>\n<td>Network Partition</td>\n<td>Variable</td>\n<td>Split-brain detection via consensus</td>\n</tr>\n</tbody></table>\n<h3 id=\"non-functional-goals\">Non-Functional Goals</h3>\n<p>The non-functional goals establish performance, scalability, and reliability targets that make the scheduler suitable for production-like workloads while remaining implementable as a learning project.</p>\n<p><strong>Performance Targets</strong> ensure the scheduler can handle realistic workloads without becoming a bottleneck. The system should support at least 1,000 jobs per minute throughput for job submissions and completions. Cron expression parsing should complete in under 1 millisecond per expression. Job queue operations (enqueue/dequeue) should complete in under 10 milliseconds at the 95th percentile when the queue contains up to 10,000 pending jobs.</p>\n<p><strong>Scalability Requirements</strong> allow the system to grow with organizational needs. The scheduler must support at least 10 concurrent worker nodes without performance degradation. The job queue should handle up to 100,000 pending jobs while maintaining sub-second dequeue times. Adding new workers should be as simple as starting a new process with the coordinator&#39;s address.</p>\n<table>\n<thead>\n<tr>\n<th>Scalability Dimension</th>\n<th>Target</th>\n<th>Measurement Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Concurrent Workers</td>\n<td>10-50 nodes</td>\n<td>Worker registration count</td>\n</tr>\n<tr>\n<td>Pending Jobs</td>\n<td>100,000 jobs</td>\n<td>Queue depth metrics</td>\n</tr>\n<tr>\n<td>Job Throughput</td>\n<td>1,000 jobs/minute</td>\n<td>Completed jobs per time window</td>\n</tr>\n<tr>\n<td>Cron Parsing</td>\n<td>&lt;1ms per expression</td>\n<td>Microbenchmark timing</td>\n</tr>\n<tr>\n<td>Queue Operations</td>\n<td>&lt;10ms p95 latency</td>\n<td>Operation timing histograms</td>\n</tr>\n</tbody></table>\n<p><strong>Reliability Standards</strong> ensure the scheduler operates dependably in production environments. The system should achieve 99.9% uptime, meaning no more than 8.76 hours of downtime per year. No jobs should be lost due to single-point failures like individual worker crashes or temporary network partitions. The system should gracefully degrade by continuing to execute jobs even if some workers become unavailable.</p>\n<p><strong>Resource Efficiency</strong> keeps the scheduler lightweight enough to run alongside other services. Memory usage should remain under 512 MB for a coordinator managing 10,000 jobs and 20 workers. CPU usage should stay under 25% on a modest server (2-4 cores) during normal operations. Network bandwidth should be minimal, with heartbeats and coordination messages consuming less than 1 MB/minute per worker.</p>\n<blockquote>\n<p>The key insight for non-functional goals is that they must be measurable and achievable within the project constraints. Setting targets like &quot;unlimited scalability&quot; or &quot;microsecond latency&quot; would make the project impossible to complete, while setting no targets at all would result in a system that doesn&#39;t work well enough to demonstrate the concepts effectively.</p>\n</blockquote>\n<p><strong>Operational Simplicity</strong> ensures the scheduler can be deployed and maintained without extensive infrastructure. The system should start with a single configuration file and require no external dependencies beyond Redis for job storage. Logs should provide enough information to diagnose common problems without requiring specialized monitoring tools. The entire system should be deployable on a developer&#39;s laptop for testing and development.</p>\n<h3 id=\"explicit-non-goals\">Explicit Non-Goals</h3>\n<p>The non-goals establish firm boundaries on what this scheduler will NOT include, preventing scope creep while acknowledging that these features exist in enterprise scheduling systems.</p>\n<p><strong>Job Dependencies and Workflows</strong> are explicitly excluded because they add significant complexity to both the data model and execution engine. Features like &quot;run Job B only after Job A completes successfully&quot; or &quot;run these five jobs in parallel, then run the final job&quot; require dependency graph resolution, deadlock detection, and complex state management. While valuable in production systems, these features would triple the implementation effort without providing proportional learning value about the core distributed systems concepts.</p>\n<p><strong>Resource-Aware Scheduling</strong> that considers CPU, memory, or disk constraints is not included. The scheduler treats all jobs as equivalent resource consumers and doesn&#39;t consider whether a worker has sufficient capacity for a specific job type. Real production schedulers often include features like &quot;only run this job on machines with 8+ GB RAM&quot; or &quot;don&#39;t run more than 2 CPU-intensive jobs per worker simultaneously.&quot; These features require resource modeling, capacity planning, and bin-packing algorithms that would shift focus away from distributed coordination.</p>\n<table>\n<thead>\n<tr>\n<th>Excluded Feature Category</th>\n<th>Specific Examples</th>\n<th>Why Excluded</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Job Dependencies</td>\n<td>Workflow orchestration, dependency graphs</td>\n<td>Complex state management distracts from core distributed systems learning</td>\n</tr>\n<tr>\n<td>Resource Constraints</td>\n<td>Memory limits, CPU quotas, disk space checks</td>\n<td>Requires sophisticated resource modeling beyond project scope</td>\n</tr>\n<tr>\n<td>Advanced Security</td>\n<td>Authentication, authorization, job isolation</td>\n<td>Security implementation would dominate development time</td>\n</tr>\n<tr>\n<td>Multi-Datacenter</td>\n<td>Cross-region replication, geo-distributed coordination</td>\n<td>Network complexity exceeds single-datacenter learning goals</td>\n</tr>\n<tr>\n<td>Job Artifacts</td>\n<td>Input/output file management, result storage</td>\n<td>File handling distracts from scheduling and coordination logic</td>\n</tr>\n</tbody></table>\n<p><strong>Authentication and Authorization</strong> are omitted to focus on the distributed systems challenges rather than security implementation. The scheduler assumes all job submissions are authorized and all workers are trusted. Production systems would include features like API keys, role-based access control, and job owner isolation, but implementing these would consume significant development time without advancing understanding of distributed coordination, consensus algorithms, or failure recovery.</p>\n<p><strong>Advanced Monitoring and Metrics</strong> beyond basic logging are not included. While production schedulers provide detailed dashboards showing job success rates, worker utilization, queue depth over time, and performance histograms, building these interfaces would shift effort away from the core distributed systems implementation. The system will log enough information for debugging, but won&#39;t include web dashboards or metrics exporters.</p>\n<blockquote>\n<p><strong>Decision: Focus on Core Distributed Systems Concepts</strong></p>\n<ul>\n<li><strong>Context</strong>: Distributed job schedulers in production include dozens of enterprise features for security, monitoring, resource management, and workflow orchestration</li>\n<li><strong>Options Considered</strong>: Include subset of enterprise features, build minimal viable scheduler, create full-featured system</li>\n<li><strong>Decision</strong>: Implement only features essential for demonstrating distributed coordination, consensus, and fault tolerance</li>\n<li><strong>Rationale</strong>: The learning value comes from solving distributed systems problems, not from building user interfaces or security layers</li>\n<li><strong>Consequences</strong>: The resulting scheduler demonstrates core concepts clearly but would need additional features for production use</li>\n</ul>\n</blockquote>\n<p><strong>Multi-Datacenter Deployment</strong> and geographic distribution are explicitly out of scope. The scheduler assumes all components (coordinators, workers, and storage) operate within a single datacenter with reliable, low-latency network connectivity. Cross-datacenter replication, split-brain resolution across WAN links, and geographic failover introduce network partition scenarios that are beyond the project&#39;s educational goals.</p>\n<p><strong>Job Result Storage and Artifact Management</strong> are not included. The scheduler tracks whether jobs completed successfully or failed, but doesn&#39;t store job output, intermediate files, or result artifacts. Workers report completion status through <code>reportCompletion()</code>, but any job-specific data management is the responsibility of the job implementation itself, not the scheduler infrastructure.</p>\n<p><strong>Dynamic Job Modification</strong> capabilities like updating cron expressions for running schedules, changing job priorities after submission, or canceling queued jobs are omitted. Once a job enters the system, it follows its original schedule and priority until completion. While useful for operational flexibility, these features require complex state transitions and conflict resolution that would complicate the core coordination logic.</p>\n<p>The explicit non-goals serve as a contract with implementers: these boundaries won&#39;t expand during development. When facing implementation challenges, the solution should work within these constraints rather than adding excluded features as &quot;quick fixes.&quot; This discipline ensures the project remains focused on its educational objectives while building a system sophisticated enough to demonstrate real distributed systems principles.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>This section provides practical direction for implementing the functional and non-functional goals using Go as the primary development language.</p>\n<p><strong>Technology Recommendations Table:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Job Queue Storage</td>\n<td>Redis with sorted sets</td>\n<td>Redis with custom Lua scripts</td>\n</tr>\n<tr>\n<td>Worker Coordination</td>\n<td>etcd for leader election</td>\n<td>Custom Raft implementation</td>\n</tr>\n<tr>\n<td>Cron Parsing</td>\n<td><code>github.com/robfig/cron/v3</code></td>\n<td>Custom parser with extended syntax</td>\n</tr>\n<tr>\n<td>Configuration</td>\n<td>YAML files with <code>gopkg.in/yaml.v3</code></td>\n<td>etcd-based dynamic configuration</td>\n</tr>\n<tr>\n<td>Logging</td>\n<td>Standard library <code>log/slog</code></td>\n<td>Structured logging with <code>logrus</code></td>\n</tr>\n<tr>\n<td>HTTP API</td>\n<td><code>net/http</code> with <code>gorilla/mux</code></td>\n<td>gRPC with Protocol Buffers</td>\n</tr>\n<tr>\n<td>Metrics</td>\n<td>Basic counters in memory</td>\n<td>Prometheus metrics export</td>\n</tr>\n<tr>\n<td>Testing</td>\n<td>Standard <code>testing</code> package</td>\n<td>Testcontainers for integration tests</td>\n</tr>\n</tbody></table>\n<p><strong>Recommended Project Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>distributed-job-scheduler/\n├── cmd/\n│   ├── coordinator/\n│   │   └── main.go              ← coordinator service entry point\n│   └── worker/\n│       └── main.go              ← worker service entry point\n├── internal/\n│   ├── coordinator/\n│   │   ├── coordinator.go       ← leader election and job assignment\n│   │   ├── coordinator_test.go\n│   │   └── heartbeat.go         ← worker health tracking\n│   ├── cron/\n│   │   ├── parser.go           ← cron expression parsing (Milestone 1)\n│   │   ├── parser_test.go\n│   │   └── schedule.go         ← next execution time calculation\n│   ├── queue/\n│   │   ├── priority_queue.go   ← job priority queue (Milestone 2)\n│   │   ├── priority_queue_test.go\n│   │   ├── deduplication.go    ← idempotency key handling\n│   │   └── delayed_jobs.go     ← scheduled job visibility\n│   ├── worker/\n│   │   ├── worker.go           ← job execution and heartbeat (Milestone 3)\n│   │   ├── worker_test.go\n│   │   └── job_executor.go     ← job execution engine\n│   └── models/\n│       ├── job.go              ← Job, Worker data structures\n│       ├── cron.go             ← CronExpression struct\n│       └── constants.go        ← PENDING, EXECUTING, etc.\n├── pkg/\n│   ├── api/\n│   │   └── client.go           ← HTTP client for job submission\n│   └── storage/\n│       └── redis.go            ← Redis connection and operations\n├── configs/\n│   ├── coordinator.yaml        ← coordinator configuration\n│   └── worker.yaml             ← worker configuration\n├── scripts/\n│   ├── start-coordinator.sh    ← development startup scripts\n│   └── start-worker.sh\n├── docker/\n│   ├── docker-compose.yml      ← local development environment\n│   └── Dockerfile              ← service container image\n└── docs/\n    └── api.md                  ← HTTP API documentation</code></pre></div>\n\n<p><strong>Core Data Structures (Complete Definitions):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> models</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Job represents a scheduled task with priority and execution metadata</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> Job</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ID              </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">            `json:\"id\" redis:\"id\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Name            </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">            `json:\"name\" redis:\"name\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CronExpression  </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">            `json:\"cron_expression\" redis:\"cron_expression\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Priority        </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">               `json:\"priority\" redis:\"priority\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Payload         </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\"> `json:\"payload\" redis:\"payload\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    IdempotencyKey  </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">            `json:\"idempotency_key\" redis:\"idempotency_key\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    State           </span><span style=\"color:#B392F0\">JobState</span><span style=\"color:#9ECBFF\">          `json:\"state\" redis:\"state\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    WorkerID        </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">            `json:\"worker_id,omitempty\" redis:\"worker_id\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    FencingToken    </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">            `json:\"fencing_token,omitempty\" redis:\"fencing_token\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ScheduledAt     </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">         `json:\"scheduled_at\" redis:\"scheduled_at\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ClaimedAt       </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">        `json:\"claimed_at,omitempty\" redis:\"claimed_at\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CompletedAt     </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">        `json:\"completed_at,omitempty\" redis:\"completed_at\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    RetryCount      </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">               `json:\"retry_count\" redis:\"retry_count\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    MaxRetries      </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">               `json:\"max_retries\" redis:\"max_retries\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CreatedAt       </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">         `json:\"created_at\" redis:\"created_at\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    UpdatedAt       </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">         `json:\"updated_at\" redis:\"updated_at\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Worker represents a node that executes jobs with capacity tracking</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> Worker</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ID              </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">            `json:\"id\" redis:\"id\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Address         </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">            `json:\"address\" redis:\"address\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Capacity        </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">               `json:\"capacity\" redis:\"capacity\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CurrentJobs     </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">               `json:\"current_jobs\" redis:\"current_jobs\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Capabilities    []</span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">          `json:\"capabilities\" redis:\"capabilities\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LastHeartbeat   </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">         `json:\"last_heartbeat\" redis:\"last_heartbeat\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    State           </span><span style=\"color:#B392F0\">WorkerState</span><span style=\"color:#9ECBFF\">       `json:\"state\" redis:\"state\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    StartedAt       </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">         `json:\"started_at\" redis:\"started_at\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Metadata        </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\"> `json:\"metadata\" redis:\"metadata\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// CronExpression holds parsed cron schedule with next execution calculation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> CronExpression</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Original    </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">        `json:\"original\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Minutes     []</span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">         `json:\"minutes\"`</span><span style=\"color:#6A737D\">     // 0-59</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Hours       []</span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">         `json:\"hours\"`</span><span style=\"color:#6A737D\">       // 0-23</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    DaysOfMonth []</span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">         `json:\"days_month\"`</span><span style=\"color:#6A737D\">  // 1-31</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Months      []</span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">         `json:\"months\"`</span><span style=\"color:#6A737D\">      // 1-12</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    DaysOfWeek  []</span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">         `json:\"days_week\"`</span><span style=\"color:#6A737D\">   // 0-6 (Sunday=0)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Timezone    </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Location</span><span style=\"color:#9ECBFF\"> `json:\"timezone\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// JobState constants for job lifecycle</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> JobState</span><span style=\"color:#F97583\"> string</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">const</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    PENDING</span><span style=\"color:#B392F0\">   JobState</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"PENDING\"</span><span style=\"color:#6A737D\">   // job queued, waiting for worker</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    CLAIMED</span><span style=\"color:#B392F0\">   JobState</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"CLAIMED\"</span><span style=\"color:#6A737D\">   // job assigned to worker, not yet started</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    EXECUTING</span><span style=\"color:#B392F0\"> JobState</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"EXECUTING\"</span><span style=\"color:#6A737D\"> // job currently running on worker</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    COMPLETED</span><span style=\"color:#B392F0\"> JobState</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"COMPLETED\"</span><span style=\"color:#6A737D\"> // job finished successfully</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    FAILED</span><span style=\"color:#B392F0\">    JobState</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"FAILED\"</span><span style=\"color:#6A737D\">    // job failed after all retries</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// WorkerState constants for worker lifecycle</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> WorkerState</span><span style=\"color:#F97583\"> string</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">const</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    AVAILABLE</span><span style=\"color:#B392F0\">   WorkerState</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"AVAILABLE\"</span><span style=\"color:#6A737D\">   // worker ready to accept jobs</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    BUSY</span><span style=\"color:#B392F0\">        WorkerState</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"BUSY\"</span><span style=\"color:#6A737D\">        // worker at capacity</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    UNAVAILABLE</span><span style=\"color:#B392F0\"> WorkerState</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"UNAVAILABLE\"</span><span style=\"color:#6A737D\"> // worker failed or shutdown</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p><strong>Configuration Management (Complete Implementation):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> config</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">fmt</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">gopkg.in/yaml.v3</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">os</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> CoordinatorConfig</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Server </span><span style=\"color:#F97583\">struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Port         </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">           `yaml:\"port\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ReadTimeout  </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#9ECBFF\"> `yaml:\"read_timeout\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        WriteTimeout </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#9ECBFF\"> `yaml:\"write_timeout\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    } </span><span style=\"color:#9ECBFF\">`yaml:\"server\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Redis </span><span style=\"color:#F97583\">struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Address  </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\"> `yaml:\"address\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Password </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\"> `yaml:\"password\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Database </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">    `yaml:\"database\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    } </span><span style=\"color:#9ECBFF\">`yaml:\"redis\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Coordinator </span><span style=\"color:#F97583\">struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        HeartbeatTimeout </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#9ECBFF\"> `yaml:\"heartbeat_timeout\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ElectionTimeout  </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#9ECBFF\"> `yaml:\"election_timeout\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        JobScanInterval  </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#9ECBFF\"> `yaml:\"job_scan_interval\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    } </span><span style=\"color:#9ECBFF\">`yaml:\"coordinator\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> WorkerConfig</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Worker </span><span style=\"color:#F97583\">struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ID           </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">        `yaml:\"id\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Capacity     </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">           `yaml:\"capacity\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Capabilities []</span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `yaml:\"capabilities\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        HeartbeatInterval </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#9ECBFF\"> `yaml:\"heartbeat_interval\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    } </span><span style=\"color:#9ECBFF\">`yaml:\"worker\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Coordinator </span><span style=\"color:#F97583\">struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Address </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\"> `yaml:\"address\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    } </span><span style=\"color:#9ECBFF\">`yaml:\"coordinator\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Redis </span><span style=\"color:#F97583\">struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Address  </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\"> `yaml:\"address\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Password </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\"> `yaml:\"password\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Database </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">    `yaml:\"database\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    } </span><span style=\"color:#9ECBFF\">`yaml:\"redis\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> LoadCoordinatorConfig</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">path</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">CoordinatorConfig</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    data, err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> os.</span><span style=\"color:#B392F0\">ReadFile</span><span style=\"color:#E1E4E8\">(path)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\">, fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"reading config file: </span><span style=\"color:#79B8FF\">%w</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    var</span><span style=\"color:#E1E4E8\"> config </span><span style=\"color:#B392F0\">CoordinatorConfig</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> yaml.</span><span style=\"color:#B392F0\">Unmarshal</span><span style=\"color:#E1E4E8\">(data, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">config); err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\">, fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"parsing config YAML: </span><span style=\"color:#79B8FF\">%w</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#E1E4E8\">config, </span><span style=\"color:#79B8FF\">nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> LoadWorkerConfig</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">path</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">WorkerConfig</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    data, err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> os.</span><span style=\"color:#B392F0\">ReadFile</span><span style=\"color:#E1E4E8\">(path)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\">, fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"reading config file: </span><span style=\"color:#79B8FF\">%w</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    var</span><span style=\"color:#E1E4E8\"> config </span><span style=\"color:#B392F0\">WorkerConfig</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> yaml.</span><span style=\"color:#B392F0\">Unmarshal</span><span style=\"color:#E1E4E8\">(data, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">config); err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\">, fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"parsing config YAML: </span><span style=\"color:#79B8FF\">%w</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#E1E4E8\">config, </span><span style=\"color:#79B8FF\">nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>HTTP API Infrastructure (Complete Implementation):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> api</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">encoding/json</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">net/http</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">github.com/gorilla/mux</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">distributed-job-scheduler/internal/models</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> JobSubmissionRequest</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Name           </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">            `json:\"name\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CronExpression </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">            `json:\"cron_expression\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Priority       </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">               `json:\"priority\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Payload        </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\"> `json:\"payload\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    IdempotencyKey </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">            `json:\"idempotency_key\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    MaxRetries     </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">               `json:\"max_retries\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> JobSubmissionResponse</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    JobID     </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">    `json:\"job_id\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Status    </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">    `json:\"status\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    NextRun   </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\"> `json:\"next_run,omitempty\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Message   </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">    `json:\"message,omitempty\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> ErrorResponse</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Error   </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\"> `json:\"error\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Code    </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\"> `json:\"code,omitempty\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Details </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\"> `json:\"details,omitempty\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// JobSubmissionHandler handles HTTP requests for job submission</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> JobSubmissionHandler</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">jobQueue</span><span style=\"color:#B392F0\"> JobQueue</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">http</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">HandlerFunc</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> func</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">w</span><span style=\"color:#B392F0\"> http</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">ResponseWriter</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">r</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">http</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Request</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO: Parse JSON request body into JobSubmissionRequest</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO: Validate cron expression using cron parser</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO: Generate unique job ID and fencing token</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO: Create Job struct with PENDING state</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO: Submit job to priority queue with deduplication check</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO: Calculate next execution time from cron expression</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO: Return JobSubmissionResponse with job details</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO: Handle errors with appropriate HTTP status codes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// WorkerHeartbeatHandler accepts heartbeat signals from workers</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> WorkerHeartbeatHandler</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">coordinator</span><span style=\"color:#B392F0\"> Coordinator</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">http</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">HandlerFunc</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> func</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">w</span><span style=\"color:#B392F0\"> http</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">ResponseWriter</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">r</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">http</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Request</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO: Extract worker ID from URL path or headers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO: Parse heartbeat payload with current job count and capabilities</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO: Update worker's last heartbeat timestamp in coordination store</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO: Return current job assignments or coordination commands</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO: Handle new worker registration if ID not found</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// SetupRoutes configures HTTP routes for the coordinator API</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> SetupRoutes</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">jobQueue</span><span style=\"color:#B392F0\"> JobQueue</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">coordinator</span><span style=\"color:#B392F0\"> Coordinator</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">mux</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Router</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    r </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> mux.</span><span style=\"color:#B392F0\">NewRouter</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Job management endpoints</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    r.</span><span style=\"color:#B392F0\">HandleFunc</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"/api/v1/jobs\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#B392F0\">JobSubmissionHandler</span><span style=\"color:#E1E4E8\">(jobQueue)).</span><span style=\"color:#B392F0\">Methods</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"POST\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    r.</span><span style=\"color:#B392F0\">HandleFunc</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"/api/v1/jobs\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#B392F0\">ListJobsHandler</span><span style=\"color:#E1E4E8\">(jobQueue)).</span><span style=\"color:#B392F0\">Methods</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"GET\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    r.</span><span style=\"color:#B392F0\">HandleFunc</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"/api/v1/jobs/{id}\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#B392F0\">GetJobHandler</span><span style=\"color:#E1E4E8\">(jobQueue)).</span><span style=\"color:#B392F0\">Methods</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"GET\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Worker coordination endpoints</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    r.</span><span style=\"color:#B392F0\">HandleFunc</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"/api/v1/workers/heartbeat\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#B392F0\">WorkerHeartbeatHandler</span><span style=\"color:#E1E4E8\">(coordinator)).</span><span style=\"color:#B392F0\">Methods</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"POST\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    r.</span><span style=\"color:#B392F0\">HandleFunc</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"/api/v1/workers\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#B392F0\">ListWorkersHandler</span><span style=\"color:#E1E4E8\">(coordinator)).</span><span style=\"color:#B392F0\">Methods</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"GET\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> r</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Helper function for JSON responses</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> WriteJSONResponse</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">w</span><span style=\"color:#B392F0\"> http</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">ResponseWriter</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">status</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">data</span><span style=\"color:#F97583\"> interface</span><span style=\"color:#E1E4E8\">{}) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    w.</span><span style=\"color:#B392F0\">Header</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#B392F0\">Set</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Content-Type\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"application/json\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    w.</span><span style=\"color:#B392F0\">WriteHeader</span><span style=\"color:#E1E4E8\">(status)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    json.</span><span style=\"color:#B392F0\">NewEncoder</span><span style=\"color:#E1E4E8\">(w).</span><span style=\"color:#B392F0\">Encode</span><span style=\"color:#E1E4E8\">(data)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Helper function for error responses</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> WriteErrorResponse</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">w</span><span style=\"color:#B392F0\"> http</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">ResponseWriter</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">status</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">message</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    response </span><span style=\"color:#F97583\">:=</span><span style=\"color:#B392F0\"> ErrorResponse</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Error: message,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Code:  http.</span><span style=\"color:#B392F0\">StatusText</span><span style=\"color:#E1E4E8\">(status),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    WriteJSONResponse</span><span style=\"color:#E1E4E8\">(w, status, response)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Redis Storage Interface (Complete Implementation):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> storage</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">context</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">encoding/json</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">fmt</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">github.com/go-redis/redis/v8</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">distributed-job-scheduler/internal/models</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> RedisClient</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    client </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">redis</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Client</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ctx    </span><span style=\"color:#B392F0\">context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewRedisClient</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">addr</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">password</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">db</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">RedisClient</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    rdb </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> redis.</span><span style=\"color:#B392F0\">NewClient</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#B392F0\">redis</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Options</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Addr:     addr,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Password: password,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        DB:       db,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    })</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">RedisClient</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        client: rdb,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ctx:    context.</span><span style=\"color:#B392F0\">Background</span><span style=\"color:#E1E4E8\">(),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Job storage operations</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">r </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">RedisClient</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">StoreJob</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">job</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">models</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    jobData, err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> json.</span><span style=\"color:#B392F0\">Marshal</span><span style=\"color:#E1E4E8\">(job)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"marshaling job: </span><span style=\"color:#79B8FF\">%w</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Store job data</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    jobKey </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Sprintf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"job:</span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, job.ID)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> r.client.</span><span style=\"color:#B392F0\">Set</span><span style=\"color:#E1E4E8\">(r.ctx, jobKey, jobData, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">).</span><span style=\"color:#B392F0\">Err</span><span style=\"color:#E1E4E8\">(); err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"storing job data: </span><span style=\"color:#79B8FF\">%w</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Add to priority queue with score = (priority &#x3C;&#x3C; 32) | scheduled_timestamp</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    score </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> float64</span><span style=\"color:#E1E4E8\">(job.Priority</span><span style=\"color:#F97583\">&#x3C;&#x3C;</span><span style=\"color:#79B8FF\">32</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">+</span><span style=\"color:#F97583\"> float64</span><span style=\"color:#E1E4E8\">(job.ScheduledAt.</span><span style=\"color:#B392F0\">Unix</span><span style=\"color:#E1E4E8\">())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    queueKey </span><span style=\"color:#F97583\">:=</span><span style=\"color:#9ECBFF\"> \"job_queue\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> r.client.</span><span style=\"color:#B392F0\">ZAdd</span><span style=\"color:#E1E4E8\">(r.ctx, queueKey, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#B392F0\">redis</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Z</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Score:  score,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Member: job.ID,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }).</span><span style=\"color:#B392F0\">Err</span><span style=\"color:#E1E4E8\">(); err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"adding to priority queue: </span><span style=\"color:#79B8FF\">%w</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">r </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">RedisClient</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">GetJob</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">jobID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">models</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    jobKey </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Sprintf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"job:</span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, jobID)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    data, err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> r.client.</span><span style=\"color:#B392F0\">Get</span><span style=\"color:#E1E4E8\">(r.ctx, jobKey).</span><span style=\"color:#B392F0\">Result</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\">, fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"getting job data: </span><span style=\"color:#79B8FF\">%w</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    var</span><span style=\"color:#E1E4E8\"> job </span><span style=\"color:#B392F0\">models</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Job</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> json.</span><span style=\"color:#B392F0\">Unmarshal</span><span style=\"color:#E1E4E8\">([]</span><span style=\"color:#F97583\">byte</span><span style=\"color:#E1E4E8\">(data), </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">job); err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\">, fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"unmarshaling job: </span><span style=\"color:#79B8FF\">%w</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#E1E4E8\">job, </span><span style=\"color:#79B8FF\">nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Worker registration and heartbeat operations</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">r </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">RedisClient</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">RegisterWorker</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">worker</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">models</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Worker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    workerData, err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> json.</span><span style=\"color:#B392F0\">Marshal</span><span style=\"color:#E1E4E8\">(worker)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"marshaling worker: </span><span style=\"color:#79B8FF\">%w</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    workerKey </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Sprintf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"worker:</span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, worker.ID)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> r.client.</span><span style=\"color:#B392F0\">Set</span><span style=\"color:#E1E4E8\">(r.ctx, workerKey, workerData, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">).</span><span style=\"color:#B392F0\">Err</span><span style=\"color:#E1E4E8\">(); err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"storing worker data: </span><span style=\"color:#79B8FF\">%w</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Add to active workers set</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    activeWorkersKey </span><span style=\"color:#F97583\">:=</span><span style=\"color:#9ECBFF\"> \"active_workers\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> r.client.</span><span style=\"color:#B392F0\">SAdd</span><span style=\"color:#E1E4E8\">(r.ctx, activeWorkersKey, worker.ID).</span><span style=\"color:#B392F0\">Err</span><span style=\"color:#E1E4E8\">(); err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"adding to active workers: </span><span style=\"color:#79B8FF\">%w</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">r </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">RedisClient</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">UpdateWorkerHeartbeat</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">workerID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">timestamp</span><span style=\"color:#B392F0\"> time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    workerKey </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Sprintf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"worker:</span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, workerID)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Update heartbeat timestamp using hash field</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> r.client.</span><span style=\"color:#B392F0\">HSet</span><span style=\"color:#E1E4E8\">(r.ctx, workerKey, </span><span style=\"color:#9ECBFF\">\"last_heartbeat\"</span><span style=\"color:#E1E4E8\">, timestamp.</span><span style=\"color:#B392F0\">Unix</span><span style=\"color:#E1E4E8\">()).</span><span style=\"color:#B392F0\">Err</span><span style=\"color:#E1E4E8\">(); err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"updating heartbeat: </span><span style=\"color:#79B8FF\">%w</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Atomic job claiming operation using Lua script</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">const</span><span style=\"color:#79B8FF\"> claimJobScript</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> `</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">local job_id = ARGV[1]</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">local worker_id = ARGV[2]</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">local fencing_token = ARGV[3]</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">local current_time = ARGV[4]</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">local job_key = \"job:\" .. job_id</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">local job_data = redis.call(\"GET\", job_key)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">if not job_data then</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    return {err = \"Job not found\"}</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">end</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">local job = cjson.decode(job_data)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">if job.state ~= \"PENDING\" then</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    return {err = \"Job not in PENDING state\"}</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">end</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">-- Update job state to CLAIMED</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">job.state = \"CLAIMED\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">job.worker_id = worker_id</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">job.fencing_token = fencing_token</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">job.claimed_at = current_time</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">local updated_data = cjson.encode(job)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">redis.call(\"SET\", job_key, updated_data)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">-- Remove from general queue, add to worker's queue</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">redis.call(\"ZREM\", \"job_queue\", job_id)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">redis.call(\"LPUSH\", \"worker_jobs:\" .. worker_id, job_id)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">return {ok = \"Job claimed successfully\"}</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">`</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">r </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">RedisClient</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">ClaimJob</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">jobID</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">workerID</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">fencingToken</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    currentTime </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> time.</span><span style=\"color:#B392F0\">Now</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#B392F0\">Unix</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    result </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> r.client.</span><span style=\"color:#B392F0\">Eval</span><span style=\"color:#E1E4E8\">(r.ctx, claimJobScript, []</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">{}, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        jobID, workerID, fencingToken, currentTime)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> result.</span><span style=\"color:#B392F0\">Err</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"claiming job: </span><span style=\"color:#79B8FF\">%w</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, result.</span><span style=\"color:#B392F0\">Err</span><span style=\"color:#E1E4E8\">())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Milestone Verification Checkpoints:</strong></p>\n<p>After implementing each milestone, verify correct behavior using these specific tests:</p>\n<p><strong>Milestone 1 Checkpoint - Cron Parser:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Run cron parser tests</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> test</span><span style=\"color:#9ECBFF\"> ./internal/cron/...</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Manual verification</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> run</span><span style=\"color:#9ECBFF\"> cmd/test-cron/main.go</span><span style=\"color:#9ECBFF\"> \"0 9 * * 1-5\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected output: Next execution at 2024-01-08 09:00:00 UTC (next weekday at 9 AM)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> run</span><span style=\"color:#9ECBFF\"> cmd/test-cron/main.go</span><span style=\"color:#9ECBFF\"> \"*/15 * * * *\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected output: Next execution within 15 minutes of current time</span></span></code></pre></div>\n\n<p><strong>Milestone 2 Checkpoint - Priority Queue:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Run queue tests</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> test</span><span style=\"color:#9ECBFF\"> ./internal/queue/...</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Manual verification with Redis CLI</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">redis-cli</span><span style=\"color:#9ECBFF\"> ZADD</span><span style=\"color:#9ECBFF\"> test_queue</span><span style=\"color:#79B8FF\"> 100</span><span style=\"color:#9ECBFF\"> job1</span><span style=\"color:#79B8FF\"> 200</span><span style=\"color:#9ECBFF\"> job2</span><span style=\"color:#79B8FF\"> 150</span><span style=\"color:#9ECBFF\"> job3</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">redis-cli</span><span style=\"color:#9ECBFF\"> ZREVRANGE</span><span style=\"color:#9ECBFF\"> test_queue</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#79B8FF\"> -1</span><span style=\"color:#9ECBFF\"> WITHSCORES</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected: job2 (score 200), job3 (score 150), job1 (score 100)</span></span></code></pre></div>\n\n<p><strong>Milestone 3 Checkpoint - Worker Coordination:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Start coordinator</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> run</span><span style=\"color:#9ECBFF\"> cmd/coordinator/main.go</span><span style=\"color:#79B8FF\"> -config</span><span style=\"color:#9ECBFF\"> configs/coordinator.yaml</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Start worker in another terminal</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> run</span><span style=\"color:#9ECBFF\"> cmd/worker/main.go</span><span style=\"color:#79B8FF\"> -config</span><span style=\"color:#9ECBFF\"> configs/worker.yaml</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Submit test job via HTTP</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">curl</span><span style=\"color:#79B8FF\"> -X</span><span style=\"color:#9ECBFF\"> POST</span><span style=\"color:#9ECBFF\"> http://localhost:8080/api/v1/jobs</span><span style=\"color:#79B8FF\"> \\</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">  -H</span><span style=\"color:#9ECBFF\"> \"Content-Type: application/json\"</span><span style=\"color:#79B8FF\"> \\</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">  -d</span><span style=\"color:#9ECBFF\"> '{\"name\":\"test\",\"cron_expression\":\"* * * * *\",\"priority\":100,\"payload\":{\"command\":\"echo hello\"}}'</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected: Job appears in worker logs within 60 seconds</span></span></code></pre></div>\n\n<p><strong>Language-Specific Implementation Tips:</strong></p>\n<ol>\n<li><strong>Time Handling</strong>: Use <code>time.Time</code> in UTC for all internal calculations, convert to local timezone only for display</li>\n<li><strong>Concurrency</strong>: Use <code>sync.RWMutex</code> for protecting shared data structures like worker registry</li>\n<li><strong>Context Cancellation</strong>: Pass <code>context.Context</code> through all long-running operations for graceful shutdown</li>\n<li><strong>Error Wrapping</strong>: Use <code>fmt.Errorf(&quot;operation: %w&quot;, err)</code> for error context without losing original error</li>\n<li><strong>JSON Tags</strong>: Include both <code>json</code> and <code>redis</code> struct tags for serialization to different stores</li>\n<li><strong>Configuration</strong>: Use <code>gopkg.in/yaml.v3</code> for human-readable config files</li>\n<li><strong>Testing</strong>: Use <code>testcontainers-go</code> for integration tests that need real Redis instances</li>\n<li><strong>Logging</strong>: Use structured logging with fields: <code>slog.Info(&quot;job claimed&quot;, &quot;jobID&quot;, job.ID, &quot;workerID&quot;, worker.ID)</code></li>\n</ol>\n<h2 id=\"high-level-architecture\">High-Level Architecture</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section provides the architectural foundation for all three milestones by establishing the core components and their interactions that enable cron expression parsing (Milestone 1), priority job queuing (Milestone 2), and worker coordination (Milestone 3).</p>\n</blockquote>\n<p>The distributed job scheduler architecture can be understood through a mental model of a sophisticated <strong>orchestra with multiple conductors and musicians</strong>. Just as an orchestra needs sheet music (cron expressions), a conductor to coordinate timing (scheduler service), musicians with different capabilities (workers), and a system to distribute music sheets fairly (job queue), our distributed scheduler coordinates the execution of jobs across multiple machines while maintaining consistency and fault tolerance.</p>\n<p>The architecture consists of four primary layers that work together to provide reliable, distributed job scheduling. The <strong>coordination layer</strong> acts as the nervous system, managing leader election and maintaining cluster state. The <strong>scheduler service</strong> serves as the brain, parsing cron expressions and making job assignment decisions. The <strong>job queue</strong> functions as the memory, storing pending jobs with priorities and timing information. Finally, the <strong>worker pool</strong> represents the muscles, executing the actual job payloads while reporting status back to the coordination layer.</p>\n<h3 id=\"system-components\">System Components</h3>\n<p>The distributed job scheduler is composed of several core components, each with distinct responsibilities that collectively enable fault-tolerant job execution across a cluster of machines.</p>\n<p><img src=\"/api/project/job-scheduler/architecture-doc/asset?path=diagrams%2Fsystem-architecture.svg\" alt=\"System Architecture Overview\"></p>\n<h4 id=\"scheduler-service-components\">Scheduler Service Components</h4>\n<p>The <strong>Scheduler Service</strong> acts as the central orchestrator, responsible for transforming cron expressions into executable jobs and coordinating their distribution to workers. This service embodies the &quot;conductor&quot; role in our orchestra analogy, ensuring that each job plays at precisely the right time.</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Responsibility</th>\n<th>Key Operations</th>\n<th>Failure Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Cron Engine</td>\n<td>Parse cron expressions and calculate next execution times</td>\n<td><code>parseExpression()</code>, <code>calculateNext()</code>, <code>validateTimezone()</code></td>\n<td>Jobs stop being scheduled until recovery</td>\n</tr>\n<tr>\n<td>Job Scheduler</td>\n<td>Create job instances from recurring schedules</td>\n<td><code>createJobFromSchedule()</code>, <code>applyPriority()</code>, <code>setIdempotencyKey()</code></td>\n<td>New job instances not created, existing jobs continue</td>\n</tr>\n<tr>\n<td>Assignment Manager</td>\n<td>Distribute jobs to available workers based on capacity</td>\n<td><code>selectWorker()</code>, <code>assignJob()</code>, <code>trackAssignments()</code></td>\n<td>Jobs queue up but don&#39;t execute until recovery</td>\n</tr>\n<tr>\n<td>Heartbeat Monitor</td>\n<td>Track worker health and detect failures</td>\n<td><code>processHeartbeat()</code>, <code>detectFailures()</code>, <code>triggerRecovery()</code></td>\n<td>Failed workers not detected, jobs may be stuck</td>\n</tr>\n</tbody></table>\n<p>The Scheduler Service maintains several critical data structures to coordinate job execution:</p>\n<table>\n<thead>\n<tr>\n<th>Data Structure</th>\n<th>Purpose</th>\n<th>Key Fields</th>\n<th>Update Frequency</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Active Schedules Map</td>\n<td>Track all registered cron schedules</td>\n<td><code>scheduleID</code>, <code>cronExpression</code>, <code>nextRun</code>, <code>lastRun</code></td>\n<td>Every job creation</td>\n</tr>\n<tr>\n<td>Worker Registry</td>\n<td>Maintain current worker status and capacity</td>\n<td><code>workerID</code>, <code>capacity</code>, <code>currentLoad</code>, <code>capabilities</code></td>\n<td>Every heartbeat (30s)</td>\n</tr>\n<tr>\n<td>Job Assignments</td>\n<td>Track which worker owns which job</td>\n<td><code>jobID</code>, <code>workerID</code>, <code>claimedAt</code>, <code>fencingToken</code></td>\n<td>Every job claim/completion</td>\n</tr>\n<tr>\n<td>Failed Workers Set</td>\n<td>Workers pending cleanup and job recovery</td>\n<td><code>workerID</code>, <code>failedAt</code>, <code>assignedJobs</code></td>\n<td>On heartbeat timeout</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Design Insight:</strong> The Scheduler Service is designed to be stateless except for in-memory caches. All persistent state lives in the coordination layer (etcd) or job queue (Redis), allowing multiple scheduler instances to run simultaneously with leader election determining which instance actively makes scheduling decisions.</p>\n</blockquote>\n<h4 id=\"job-queue-infrastructure\">Job Queue Infrastructure</h4>\n<p>The <strong>Job Queue</strong> serves as the system&#39;s durable memory, implementing a sophisticated priority queue with delayed execution capabilities. Think of it as a <strong>hospital emergency room triage system</strong> - jobs arrive with different priority levels, some must wait until a specific time (delayed execution), and the system ensures the most critical jobs are handled first while preventing duplicate treatment of the same patient.</p>\n<table>\n<thead>\n<tr>\n<th>Queue Component</th>\n<th>Purpose</th>\n<th>Implementation</th>\n<th>Scalability Limit</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Priority Heap</td>\n<td>Order jobs by priority and scheduled time</td>\n<td>Redis sorted sets with score-based ordering</td>\n<td>~10M jobs per Redis instance</td>\n</tr>\n<tr>\n<td>Delayed Job Timer</td>\n<td>Hold jobs until their execution time arrives</td>\n<td>Redis key expiration notifications</td>\n<td>Limited by Redis memory</td>\n</tr>\n<tr>\n<td>Deduplication Store</td>\n<td>Prevent duplicate job submissions</td>\n<td>Redis hash with idempotency keys</td>\n<td>~100M unique keys</td>\n</tr>\n<tr>\n<td>Dead Letter Queue</td>\n<td>Store permanently failed jobs for analysis</td>\n<td>Separate Redis list with TTL</td>\n<td>Manual cleanup required</td>\n</tr>\n</tbody></table>\n<p>The queue implements several sophisticated algorithms to ensure fair job distribution:</p>\n<ol>\n<li><p><strong>Priority Resolution</strong>: When multiple jobs have the same priority level, the queue uses scheduled time as a secondary sort key, ensuring first-in-first-out behavior within priority bands.</p>\n</li>\n<li><p><strong>Delayed Visibility</strong>: Jobs with future scheduled times are stored in a separate &quot;delayed&quot; namespace and moved to the active queue through Redis key expiration events, providing precise timing control.</p>\n</li>\n<li><p><strong>Atomic Job Claims</strong>: Workers claim jobs using Redis Lua scripts that atomically check job availability, update job state to <code>CLAIMED</code>, and set a fencing token to prevent duplicate processing.</p>\n</li>\n<li><p><strong>Deduplication Windows</strong>: The system maintains idempotency keys for a configurable time window (default 24 hours), allowing clients to safely retry job submissions without creating duplicates.</p>\n</li>\n</ol>\n<blockquote>\n<p><strong>Architecture Decision: Redis vs Database for Job Queue</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to choose storage backend for job queue with priority ordering and atomic operations</li>\n<li><strong>Options Considered</strong>: <ul>\n<li>PostgreSQL with indexed priority columns</li>\n<li>Redis with sorted sets and Lua scripts  </li>\n<li>In-memory Go data structures with clustering</li>\n</ul>\n</li>\n<li><strong>Decision</strong>: Redis with sorted sets</li>\n<li><strong>Rationale</strong>: Redis sorted sets provide O(log N) priority ordering natively, Lua scripts enable atomic multi-operation commands, and pub/sub supports real-time job notifications. PostgreSQL would require complex locking for atomic job claims, while in-memory structures lose durability.</li>\n<li><strong>Consequences</strong>: Introduces Redis as a dependency but provides superior performance for queue operations. Limits job metadata size due to Redis memory constraints.</li>\n</ul>\n</blockquote>\n<h4 id=\"worker-pool-management\">Worker Pool Management</h4>\n<p>The <strong>Worker Pool</strong> represents the distributed execution layer, where actual job processing occurs. Workers function like <strong>specialized craftspeople in a guild</strong> - each worker registers their capabilities, maintains their tools (execution environment), and communicates regularly with the guild master (coordinator) about their availability and current projects.</p>\n<p>Workers operate through a well-defined lifecycle that ensures reliable job execution:</p>\n<table>\n<thead>\n<tr>\n<th>Worker State</th>\n<th>Description</th>\n<th>Valid Transitions</th>\n<th>Trigger Conditions</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>REGISTERING</code></td>\n<td>Initial state during startup</td>\n<td>→ <code>AVAILABLE</code>, → <code>UNAVAILABLE</code></td>\n<td>Successful/failed coordinator registration</td>\n</tr>\n<tr>\n<td><code>AVAILABLE</code></td>\n<td>Ready to accept new jobs</td>\n<td>→ <code>BUSY</code>, → <code>UNAVAILABLE</code></td>\n<td>Job assignment or failure detection</td>\n</tr>\n<tr>\n<td><code>BUSY</code></td>\n<td>At capacity, cannot accept more jobs</td>\n<td>→ <code>AVAILABLE</code>, → <code>UNAVAILABLE</code></td>\n<td>Job completion or failure</td>\n</tr>\n<tr>\n<td><code>UNAVAILABLE</code></td>\n<td>Failed or shutting down</td>\n<td>→ <code>AVAILABLE</code> (recovery only)</td>\n<td>Heartbeat timeout or explicit shutdown</td>\n</tr>\n</tbody></table>\n<p>Each worker maintains comprehensive metadata to support intelligent job assignment:</p>\n<table>\n<thead>\n<tr>\n<th>Worker Metadata</th>\n<th>Type</th>\n<th>Purpose</th>\n<th>Update Trigger</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>ID</code></td>\n<td>string</td>\n<td>Unique worker identifier across cluster</td>\n<td>At registration</td>\n</tr>\n<tr>\n<td><code>Address</code></td>\n<td>string</td>\n<td>Network endpoint for direct communication</td>\n<td>At registration</td>\n</tr>\n<tr>\n<td><code>Capacity</code></td>\n<td>int</td>\n<td>Maximum concurrent jobs this worker can handle</td>\n<td>At registration, capacity changes</td>\n</tr>\n<tr>\n<td><code>CurrentJobs</code></td>\n<td>int</td>\n<td>Number of jobs currently executing</td>\n<td>Job claim/completion</td>\n</tr>\n<tr>\n<td><code>Capabilities</code></td>\n<td>[]string</td>\n<td>Job types this worker can execute</td>\n<td>At registration</td>\n</tr>\n<tr>\n<td><code>LastHeartbeat</code></td>\n<td>time.Time</td>\n<td>Most recent health check timestamp</td>\n<td>Every heartbeat interval</td>\n</tr>\n<tr>\n<td><code>Metadata</code></td>\n<td>map[string]string</td>\n<td>Custom worker attributes for job matching</td>\n<td>At registration, periodic updates</td>\n</tr>\n</tbody></table>\n<p>Workers implement a robust heartbeat mechanism that serves multiple purposes beyond simple health checking:</p>\n<ol>\n<li><p><strong>Capacity Reporting</strong>: Each heartbeat includes current job count and available capacity, enabling intelligent load balancing.</p>\n</li>\n<li><p><strong>Capability Updates</strong>: Workers can dynamically advertise new capabilities or remove support for job types during runtime.</p>\n</li>\n<li><p><strong>Graceful Shutdown Signaling</strong>: Workers use heartbeat metadata to indicate planned shutdown, allowing coordinators to stop assigning new jobs while existing jobs complete.</p>\n</li>\n<li><p><strong>Performance Metrics</strong>: Heartbeats carry job execution statistics that help coordinators optimize future job assignments.</p>\n</li>\n</ol>\n<blockquote>\n<p><strong>Common Pitfall: Heartbeat Frequency vs Job Duration</strong></p>\n<p>⚠️ <strong>Pitfall: Setting heartbeat timeout shorter than maximum job duration</strong></p>\n<p>If heartbeat timeout is 60 seconds but jobs can run for 10 minutes, the coordinator will incorrectly mark workers as failed while they&#39;re executing long jobs. This causes job reassignment and potential duplicate execution.</p>\n<p><strong>Solution</strong>: Set heartbeat timeout to at least 2x the maximum expected job duration, or implement job-specific timeout extensions where workers can request longer heartbeat intervals for long-running jobs.</p>\n</blockquote>\n<h4 id=\"coordination-layer-architecture\">Coordination Layer Architecture</h4>\n<p>The <strong>Coordination Layer</strong> provides the distributed systems infrastructure that enables multiple scheduler instances and workers to operate as a unified cluster. This layer implements consensus protocols and distributed locking mechanisms that prevent the chaos that would result from multiple coordinators making conflicting decisions simultaneously.</p>\n<p>The coordination layer is built around <strong>etcd</strong> as the primary consensus store, chosen for its strong consistency guarantees and proven reliability in production distributed systems:</p>\n<table>\n<thead>\n<tr>\n<th>Coordination Service</th>\n<th>Purpose</th>\n<th>Data Stored</th>\n<th>Consistency Requirements</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Leader Election</td>\n<td>Ensure single active scheduler</td>\n<td>Current leader ID, lease expiration</td>\n<td>Strong consistency, linearizable reads</td>\n</tr>\n<tr>\n<td>Worker Discovery</td>\n<td>Maintain cluster member registry</td>\n<td>Worker metadata, health status</td>\n<td>Eventually consistent</td>\n</tr>\n<tr>\n<td>Configuration Management</td>\n<td>Distribute cluster-wide settings</td>\n<td>Cron schedules, retry policies</td>\n<td>Strong consistency for updates</td>\n</tr>\n<tr>\n<td>Distributed Locking</td>\n<td>Coordinate job recovery operations</td>\n<td>Lock owner, expiration time</td>\n<td>Strong consistency, exclusive access</td>\n</tr>\n</tbody></table>\n<p>The leader election algorithm follows a lease-based approach that prevents split-brain scenarios:</p>\n<ol>\n<li><p><strong>Candidate Announcement</strong>: Scheduler instances announce candidacy by attempting to create a leader key in etcd with a TTL lease.</p>\n</li>\n<li><p><strong>Lease Renewal</strong>: The current leader continuously renews its lease every 10 seconds (with 30-second TTL) to maintain leadership.</p>\n</li>\n<li><p><strong>Leadership Transfer</strong>: When a leader fails to renew its lease, the key expires and other candidates immediately compete for leadership.</p>\n</li>\n<li><p><strong>Graceful Handoff</strong>: During planned shutdown, leaders can explicitly transfer leadership by deleting their key and allowing immediate re-election.</p>\n</li>\n</ol>\n<blockquote>\n<p><strong>Architecture Decision: etcd vs Consul vs Zookeeper for Coordination</strong></p>\n<ul>\n<li><strong>Context</strong>: Need distributed coordination service for leader election and configuration management</li>\n<li><strong>Options Considered</strong>:<ul>\n<li>etcd with Raft consensus</li>\n<li>Consul with Raft consensus  </li>\n<li>Apache Zookeeper with ZAB protocol</li>\n</ul>\n</li>\n<li><strong>Decision</strong>: etcd</li>\n<li><strong>Rationale</strong>: etcd provides simpler HTTP/gRPC APIs compared to Zookeeper&#39;s complex protocol, has excellent Go client libraries, and offers strong consistency guarantees. Consul focuses more on service discovery and less on general-purpose coordination. etcd is proven in Kubernetes and other large-scale systems.</li>\n<li><strong>Consequences</strong>: Requires etcd cluster deployment and management, but provides reliable foundation for all coordination needs with excellent operational tooling.</li>\n</ul>\n</blockquote>\n<h3 id=\"deployment-model\">Deployment Model</h3>\n<p>The distributed job scheduler is designed for deployment across multiple machines in a cluster configuration, with each component type running on dedicated or shared infrastructure based on operational requirements and scale.</p>\n<h4 id=\"physical-deployment-topology\">Physical Deployment Topology</h4>\n<p>The recommended deployment follows a <strong>three-tier architecture</strong> that separates coordination, scheduling, and execution concerns while maintaining high availability and fault tolerance:</p>\n<table>\n<thead>\n<tr>\n<th>Tier</th>\n<th>Components</th>\n<th>Minimum Nodes</th>\n<th>Recommended Sizing</th>\n<th>Network Requirements</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Coordination Tier</td>\n<td>etcd cluster, Redis cluster</td>\n<td>3 etcd, 3 Redis</td>\n<td>2 CPU, 4GB RAM per node</td>\n<td>Low latency, high bandwidth between nodes</td>\n</tr>\n<tr>\n<td>Control Tier</td>\n<td>Scheduler services</td>\n<td>2 active/standby</td>\n<td>4 CPU, 8GB RAM per node</td>\n<td>Low latency to coordination tier</td>\n</tr>\n<tr>\n<td>Worker Tier</td>\n<td>Worker processes</td>\n<td>Variable</td>\n<td>Based on job requirements</td>\n<td>Moderate latency acceptable</td>\n</tr>\n</tbody></table>\n<p><strong>Coordination Tier Deployment</strong>: The coordination tier forms the backbone of cluster consensus and must be deployed with careful attention to fault tolerance. The etcd cluster should span multiple availability zones with odd numbers of nodes (3 or 5) to maintain quorum during failures. Redis deployment can follow either clustering or master/replica patterns depending on job throughput requirements.</p>\n<p><strong>Control Tier Deployment</strong>: Scheduler services run in active/standby configuration with leader election determining which instance actively schedules jobs. Multiple scheduler instances can run simultaneously, but only the elected leader performs job creation and assignment. This design allows for instant failover when the current leader fails.</p>\n<p><strong>Worker Tier Deployment</strong>: Workers can be deployed flexibly based on job execution requirements. CPU-intensive jobs might require dedicated worker nodes, while I/O-bound jobs could share nodes with other services. Workers automatically register with the coordination tier on startup and can be added or removed dynamically without affecting system operation.</p>\n<h4 id=\"network-communication-patterns\">Network Communication Patterns</h4>\n<p>The scheduler implements multiple communication patterns optimized for different types of cluster coordination:</p>\n<table>\n<thead>\n<tr>\n<th>Communication Type</th>\n<th>Protocol</th>\n<th>Frequency</th>\n<th>Failure Handling</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Scheduler → etcd</td>\n<td>gRPC</td>\n<td>Continuous (leader election)</td>\n<td>Exponential backoff, multiple endpoints</td>\n</tr>\n<tr>\n<td>Scheduler → Redis</td>\n<td>Redis protocol</td>\n<td>Per job operation</td>\n<td>Connection pooling, failover</td>\n</tr>\n<tr>\n<td>Worker → Scheduler</td>\n<td>HTTP/JSON</td>\n<td>30-second heartbeats</td>\n<td>Retry with jitter, graceful degradation</td>\n</tr>\n<tr>\n<td>Scheduler → Worker</td>\n<td>HTTP/JSON</td>\n<td>Job assignments only</td>\n<td>Timeout and reassignment</td>\n</tr>\n</tbody></table>\n<p>The system is designed to gracefully handle network partitions and intermittent connectivity issues. Workers continue executing assigned jobs even during network partitions, reporting completion when connectivity resumes. Schedulers detect worker failures through heartbeat timeouts and reassign jobs to healthy workers.</p>\n<h4 id=\"scaling-and-resource-planning\">Scaling and Resource Planning</h4>\n<p>Resource planning should consider both steady-state operation and peak load scenarios:</p>\n<p><strong>Scheduler Service Scaling</strong>: A single scheduler instance can typically handle 10,000+ active schedules and coordinate 100+ workers. The primary bottleneck is usually etcd throughput for leader election heartbeats and worker registration updates.</p>\n<p><strong>Job Queue Scaling</strong>: Redis memory requirements scale linearly with queue depth. Estimate 1KB per queued job for metadata, with additional memory for deduplication tracking. A single Redis instance can typically handle 100,000+ queued jobs.</p>\n<p><strong>Worker Scaling</strong>: Workers scale horizontally without limits. Each worker&#39;s capacity depends on job types - CPU-bound jobs might allow 1-2 concurrent executions per core, while I/O-bound jobs could handle 10-20 concurrent executions.</p>\n<blockquote>\n<p><strong>Deployment Insight</strong>: The scheduler is designed as a &quot;shared-nothing&quot; architecture where all persistent state lives in external stores (etcd, Redis). This enables sophisticated deployment patterns like blue/green deployments, rolling updates, and cross-datacenter replication without complex data migration procedures.</p>\n</blockquote>\n<h3 id=\"recommended-file-structure\">Recommended File Structure</h3>\n<p>The Go module organization follows domain-driven design principles, separating concerns by functional area while maintaining clear dependency boundaries between components. This structure supports the three-milestone development approach by organizing code into coherent packages that can be developed and tested independently.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>distributed-job-scheduler/\n├── cmd/                              # Application entry points\n│   ├── scheduler/                    # Scheduler service binary\n│   │   └── main.go                   # Service initialization and configuration\n│   ├── worker/                       # Worker service binary  \n│   │   └── main.go                   # Worker startup and registration\n│   └── cli/                          # Administrative command-line tools\n│       └── main.go                   # Job submission, cluster status\n├── internal/                         # Private application packages\n│   ├── coordinator/                  # Milestone 3: Worker coordination\n│   │   ├── coordinator.go            # Leader election and job assignment\n│   │   ├── heartbeat.go             # Worker health monitoring\n│   │   ├── recovery.go              # Failed job recovery logic\n│   │   └── coordinator_test.go      # Coordination integration tests\n│   ├── cron/                        # Milestone 1: Cron expression parsing\n│   │   ├── parser.go                # Cron syntax parsing and validation\n│   │   ├── calculator.go            # Next execution time calculation\n│   │   ├── timezone.go              # Timezone handling and DST logic\n│   │   └── parser_test.go           # Comprehensive parsing test suite\n│   ├── queue/                       # Milestone 2: Priority job queue\n│   │   ├── priority_queue.go        # Priority-based job ordering\n│   │   ├── delayed_queue.go         # Scheduled job timing management\n│   │   ├── deduplication.go         # Idempotency key handling\n│   │   ├── redis_backend.go         # Redis storage implementation\n│   │   └── queue_test.go            # Queue operation tests\n│   ├── worker/                      # Worker execution engine\n│   │   ├── worker.go                # Job execution and lifecycle management\n│   │   ├── executor.go              # Job payload processing interface\n│   │   ├── heartbeat_client.go      # Coordinator communication\n│   │   └── worker_test.go           # Worker behavior tests\n│   ├── models/                      # Shared data structures\n│   │   ├── job.go                   # Job struct and state management\n│   │   ├── worker.go                # Worker struct and capability tracking\n│   │   ├── schedule.go              # Schedule definitions and metadata\n│   │   └── cron_expression.go       # Parsed cron expression representation\n│   └── storage/                     # Storage layer abstractions\n│       ├── etcd/                    # etcd coordination client\n│       │   ├── client.go            # Connection management and operations\n│       │   ├── leader_election.go   # Leader election implementation\n│       │   └── watcher.go           # Configuration change notifications\n│       ├── redis/                   # Redis queue client\n│       │   ├── client.go            # Connection pooling and commands\n│       │   ├── lua_scripts.go       # Atomic operation scripts\n│       │   └── pubsub.go            # Job notification handling\n│       └── interfaces.go            # Storage interface definitions\n├── pkg/                             # Public API packages\n│   ├── api/                         # HTTP REST API definitions\n│   │   ├── handlers/                # Request handlers for job management\n│   │   ├── middleware/              # Authentication, logging, metrics\n│   │   └── types/                   # API request/response structures\n│   ├── client/                      # Go client library for job submission\n│   │   ├── scheduler_client.go      # High-level client interface\n│   │   └── retry.go                 # Client-side retry and backoff\n│   └── metrics/                     # Observability and monitoring\n│       ├── prometheus.go            # Prometheus metrics integration\n│       └── tracing.go               # Distributed tracing support\n├── configs/                         # Configuration files and templates\n│   ├── scheduler.yaml               # Scheduler service configuration\n│   ├── worker.yaml                  # Worker service configuration\n│   └── docker-compose.yml           # Local development environment\n├── deployments/                     # Deployment manifests and scripts\n│   ├── kubernetes/                  # Kubernetes YAML manifests\n│   ├── docker/                      # Dockerfile for containerization\n│   └── terraform/                   # Infrastructure as code\n├── docs/                           # Additional documentation\n├── scripts/                        # Development and deployment scripts\n└── tests/                          # Integration and end-to-end tests\n    ├── integration/                # Cross-component integration tests\n    ├── e2e/                       # Full system end-to-end tests\n    └── fixtures/                  # Test data and mock configurations</code></pre></div>\n\n<h4 id=\"package-dependency-guidelines\">Package Dependency Guidelines</h4>\n<p>The module structure enforces clear dependency boundaries that support milestone-based development:</p>\n<table>\n<thead>\n<tr>\n<th>Package</th>\n<th>Can Import</th>\n<th>Cannot Import</th>\n<th>Reasoning</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>internal/cron</code></td>\n<td><code>internal/models</code> only</td>\n<td>Other internal packages</td>\n<td>Pure parsing logic, no external dependencies</td>\n</tr>\n<tr>\n<td><code>internal/queue</code></td>\n<td><code>internal/models</code>, <code>internal/storage/redis</code></td>\n<td><code>internal/coordinator</code>, <code>internal/worker</code></td>\n<td>Queue operations independent of coordination</td>\n</tr>\n<tr>\n<td><code>internal/coordinator</code></td>\n<td>All internal packages</td>\n<td>None</td>\n<td>Top-level orchestration needs access to all components</td>\n</tr>\n<tr>\n<td><code>internal/worker</code></td>\n<td><code>internal/models</code>, <code>pkg/client</code></td>\n<td><code>internal/coordinator</code></td>\n<td>Workers should not directly depend on coordination logic</td>\n</tr>\n</tbody></table>\n<h4 id=\"development-workflow-organization\">Development Workflow Organization</h4>\n<p>The file structure supports a natural development progression aligned with the project milestones:</p>\n<p><strong>Milestone 1 Development Focus</strong>: Developers start with <code>internal/cron</code> and <code>internal/models/cron_expression.go</code>, building and testing cron parsing logic in isolation. The clear separation allows comprehensive testing without external dependencies.</p>\n<p><strong>Milestone 2 Development Focus</strong>: Queue implementation in <code>internal/queue</code> can proceed independently, with Redis backend abstracted through interfaces in <code>internal/storage</code>. Mock implementations support testing without Redis infrastructure.</p>\n<p><strong>Milestone 3 Development Focus</strong>: Coordinator logic in <code>internal/coordinator</code> integrates all previous components, with worker coordination building on established queue and parsing functionality.</p>\n<blockquote>\n<p><strong>File Structure Insight</strong>: The separation of <code>internal/</code> and <code>pkg/</code> follows Go conventions where <code>internal/</code> packages cannot be imported by external projects, while <code>pkg/</code> provides stable public APIs. This structure supports future open-source distribution while protecting internal implementation details from external dependencies.</p>\n</blockquote>\n<p>The <code>cmd/</code> directory structure allows building separate binaries for different deployment scenarios - monolithic deployments can run scheduler and worker in the same process, while distributed deployments can deploy them separately. The shared <code>internal/</code> packages support both patterns without code duplication.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>This section provides concrete technology choices and starter code to help junior developers translate the architectural design into working Go code.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n<th>Trade-offs</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>HTTP Framework</td>\n<td><code>net/http</code> with <code>gorilla/mux</code></td>\n<td><code>gin-gonic/gin</code> with middleware</td>\n<td>Standard library vs performance optimized</td>\n</tr>\n<tr>\n<td>Configuration</td>\n<td><code>gopkg.in/yaml.v3</code></td>\n<td><code>spf13/viper</code> with env overrides</td>\n<td>Simple YAML vs dynamic configuration</td>\n</tr>\n<tr>\n<td>Logging</td>\n<td><code>log/slog</code> (Go 1.21+)</td>\n<td><code>sirupsen/logrus</code> with hooks</td>\n<td>Built-in structured logging vs ecosystem</td>\n</tr>\n<tr>\n<td>Metrics</td>\n<td><code>prometheus/client_golang</code></td>\n<td><code>prometheus/client_golang</code> + Grafana</td>\n<td>Industry standard, no simpler alternative</td>\n</tr>\n<tr>\n<td>etcd Client</td>\n<td><code>go.etcd.io/etcd/clientv3</code></td>\n<td>Same with custom retry wrapper</td>\n<td>Official client, wrap for convenience</td>\n</tr>\n<tr>\n<td>Redis Client</td>\n<td><code>go-redis/redis/v9</code></td>\n<td><code>go-redis/redis/v9</code> with cluster</td>\n<td>Mature library, cluster support when needed</td>\n</tr>\n<tr>\n<td>Testing</td>\n<td><code>testing</code> + <code>testify/assert</code></td>\n<td><code>testify/suite</code> + <code>testcontainers</code></td>\n<td>Simple assertions vs full test suites</td>\n</tr>\n</tbody></table>\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p><strong>etcd Client Wrapper</strong> (Complete implementation for coordination layer):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// internal/storage/etcd/client.go</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> etcd</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">context</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    clientv3 </span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#B392F0\">go.etcd.io/etcd/client/v3</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">go.etcd.io/etcd/client/v3/concurrency</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Client wraps etcd operations with retry logic and connection management</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> Client</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    client   </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">clientv3</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Client</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    session  </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">concurrency</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Session</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    timeout  </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// NewClient creates a new etcd client with recommended settings</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewClient</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">endpoints</span><span style=\"color:#E1E4E8\"> []</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Client</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    client, err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> clientv3.</span><span style=\"color:#B392F0\">New</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">clientv3</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Config</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Endpoints:   endpoints,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        DialTimeout: </span><span style=\"color:#79B8FF\">5</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\"> time.Second,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    })</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\">, err</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    session, err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> concurrency.</span><span style=\"color:#B392F0\">NewSession</span><span style=\"color:#E1E4E8\">(client, concurrency.</span><span style=\"color:#B392F0\">WithTTL</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">30</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        client.</span><span style=\"color:#B392F0\">Close</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\">, err</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">Client</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        client:  client,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        session: session,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        timeout: </span><span style=\"color:#79B8FF\">10</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\"> time.Second,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }, </span><span style=\"color:#79B8FF\">nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Campaign attempts to become leader for the given election key</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Client</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Campaign</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">election</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    e </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> concurrency.</span><span style=\"color:#B392F0\">NewElection</span><span style=\"color:#E1E4E8\">(c.session, election)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> e.</span><span style=\"color:#B392F0\">Campaign</span><span style=\"color:#E1E4E8\">(ctx, c.session.</span><span style=\"color:#B392F0\">Lease</span><span style=\"color:#E1E4E8\">())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// IsLeader checks if this client currently holds leadership</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Client</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">IsLeader</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">election</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    e </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> concurrency.</span><span style=\"color:#B392F0\">NewElection</span><span style=\"color:#E1E4E8\">(c.session, election)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    resp, err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> e.</span><span style=\"color:#B392F0\">Leader</span><span style=\"color:#E1E4E8\">(ctx)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">, err</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">(resp.Kvs[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">].Value) </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">(c.session.</span><span style=\"color:#B392F0\">Lease</span><span style=\"color:#E1E4E8\">()), </span><span style=\"color:#79B8FF\">nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Close releases all resources</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Client</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Close</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    c.session.</span><span style=\"color:#B392F0\">Close</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> c.client.</span><span style=\"color:#B392F0\">Close</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Redis Queue Backend</strong> (Complete implementation for job queue):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// internal/storage/redis/client.go</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> redis</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">context</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">encoding/json</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">github.com/redis/go-redis/v9</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Client wraps Redis operations for job queue management</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> Client</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    rdb </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">redis</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Client</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// NewClient creates Redis client with connection pooling</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewClient</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">addr</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">password</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">db</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Client</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    rdb </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> redis.</span><span style=\"color:#B392F0\">NewClient</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#B392F0\">redis</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Options</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Addr:     addr,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Password: password,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        DB:       db,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        PoolSize: </span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    })</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">Client</span><span style=\"color:#E1E4E8\">{rdb: rdb}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// EnqueueJob adds job to priority queue with deduplication</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Client</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">EnqueueJob</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">job</span><span style=\"color:#F97583\"> interface</span><span style=\"color:#E1E4E8\">{}, </span><span style=\"color:#FFAB70\">priority</span><span style=\"color:#F97583\"> float64</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">idempotencyKey</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Lua script for atomic enqueue with deduplication</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    script </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> redis.</span><span style=\"color:#B392F0\">NewScript</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">`</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        local key = KEYS[1]</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        local dedup_key = KEYS[2] </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        local job_data = ARGV[1]</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        local priority = ARGV[2]</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        local idempotency = ARGV[3]</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        if redis.call('EXISTS', dedup_key) == 1 then</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            return 0  -- Job already exists</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        end</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        redis.call('ZADD', key, priority, job_data)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        redis.call('SETEX', dedup_key, 86400, idempotency)  -- 24 hour dedup window</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        return 1</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    `</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    jobData, err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> json.</span><span style=\"color:#B392F0\">Marshal</span><span style=\"color:#E1E4E8\">(job)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> err</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    _, err </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> script.</span><span style=\"color:#B392F0\">Run</span><span style=\"color:#E1E4E8\">(ctx, c.rdb, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        []</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">{</span><span style=\"color:#9ECBFF\">\"jobs:pending\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"dedup:\"</span><span style=\"color:#F97583\"> +</span><span style=\"color:#E1E4E8\"> idempotencyKey},</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        string</span><span style=\"color:#E1E4E8\">(jobData), priority, idempotencyKey,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ).</span><span style=\"color:#B392F0\">Result</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> err</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// DequeueJob atomically claims highest priority job</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Client</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">DequeueJob</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">workerID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) ([]</span><span style=\"color:#F97583\">byte</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    script </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> redis.</span><span style=\"color:#B392F0\">NewScript</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">`</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        local pending_key = KEYS[1]</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        local claimed_key = KEYS[2]</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        local worker_id = ARGV[1]</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        local job = redis.call('ZPOPMIN', pending_key)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        if #job == 0 then</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            return nil  -- No jobs available</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        end</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        local job_data = job[1]</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        redis.call('HSET', claimed_key, job_data, worker_id)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        return job_data</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    `</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    result, err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> script.</span><span style=\"color:#B392F0\">Run</span><span style=\"color:#E1E4E8\">(ctx, c.rdb,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        []</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">{</span><span style=\"color:#9ECBFF\">\"jobs:pending\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"jobs:claimed\"</span><span style=\"color:#E1E4E8\">},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        workerID,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ).</span><span style=\"color:#B392F0\">Result</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#F97583\"> ||</span><span style=\"color:#E1E4E8\"> result </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\">, err</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> []</span><span style=\"color:#F97583\">byte</span><span style=\"color:#E1E4E8\">(result.(</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">)), </span><span style=\"color:#79B8FF\">nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Close releases Redis connection</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Client</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Close</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> c.rdb.</span><span style=\"color:#B392F0\">Close</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeleton-code\">Core Logic Skeleton Code</h4>\n<p><strong>Scheduler Service Main Logic</strong> (Skeleton for Milestone 3):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// internal/coordinator/coordinator.go</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> coordinator</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">context</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">sync</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">your-project/internal/models</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">your-project/internal/storage/etcd</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">your-project/internal/storage/redis</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Coordinator manages job scheduling and worker coordination</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> Coordinator</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    etcdClient  </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">etcd</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Client</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    redisClient </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">redis</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Client</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    workers     </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">models</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Worker</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    isLeader    </span><span style=\"color:#F97583\">bool</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    mu          </span><span style=\"color:#B392F0\">sync</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">RWMutex</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// NewCoordinator creates a new coordinator instance</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewCoordinator</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">etcdClient</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">etcd</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Client</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">redisClient</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">redis</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Client</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Coordinator</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">Coordinator</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        etcdClient:  etcdClient,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        redisClient: redisClient,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        workers:     </span><span style=\"color:#B392F0\">make</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">models</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Worker</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Start begins coordinator operations with leader election</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Coordinator</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Start</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Start leader election campaign in background goroutine</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Start worker heartbeat monitoring loop</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Start job assignment loop (only when leader)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Start job recovery scanner for failed workers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use ctx.Done() to gracefully shutdown all goroutines</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ProcessWorkerHeartbeat handles incoming worker health signals</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Coordinator</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">ProcessWorkerHeartbeat</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">workerID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">metadata</span><span style=\"color:#B392F0\"> models</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Worker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Validate worker metadata (capacity, capabilities)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Update worker's LastHeartbeat timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: If worker was marked UNAVAILABLE, transition to AVAILABLE</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Update worker's current job count and capacity</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use c.mu.Lock() for thread-safe worker map updates</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// AssignJobToWorker selects optimal worker and assigns job</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Coordinator</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">AssignJobToWorker</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">job</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">models</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Get list of AVAILABLE workers with matching capabilities</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Select worker with lowest current load (currentJobs/capacity ratio)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Atomically claim job in Redis with worker ID and fencing token</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Update worker's CurrentJobs count and state if at capacity</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use atomic operations to prevent race conditions in job claims</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// RecoverFailedWorkerJobs reassigns jobs from unresponsive workers</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Coordinator</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">RecoverFailedWorkerJobs</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">workerID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Query Redis for all jobs claimed by this worker</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: For each job, check if it's still executing (ping worker)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Reset job state from CLAIMED back to PENDING</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Clear worker assignment and increment retry count</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Remove worker from active registry</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use Lua scripts for atomic job state transitions</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Worker Service Core Logic</strong> (Skeleton for all milestones):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// internal/worker/worker.go  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> worker</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">context</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">your-project/internal/models</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">your-project/pkg/client</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Worker represents a job execution node in the cluster</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> Worker</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    id           </span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    capacity     </span><span style=\"color:#F97583\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    capabilities []</span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    currentJobs  </span><span style=\"color:#F97583\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    client       </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">client</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">SchedulerClient</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    executors    </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#B392F0\">JobExecutor</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// JobExecutor defines interface for job type handlers</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> JobExecutor</span><span style=\"color:#F97583\"> interface</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    Execute</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">payload</span><span style=\"color:#F97583\"> map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    GetTimeout</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Start begins worker operations with coordinator registration</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">w </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Worker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Start</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Register worker with coordinator (POST /workers)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Start heartbeat goroutine (every 30 seconds)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Start job polling loop </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Handle graceful shutdown on ctx.Done()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use sync.WaitGroup to coordinate goroutine shutdown</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// pollForJobs continuously requests jobs from coordinator</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">w </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Worker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">pollForJobs</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Call coordinator's claimJob() API endpoint</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: If job received, validate payload and find appropriate executor</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Execute job in separate goroutine with timeout context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Report completion or failure back to coordinator</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Handle job retry logic for transient failures</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Respect worker capacity - don't claim more jobs than can handle</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// executeJob runs job payload with timeout and error handling</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">w </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Worker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">executeJob</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">job</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">models</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Find executor for job type from capabilities</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Create timeout context based on job or executor limits</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Call executor.Execute() with job payload</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Handle context cancellation and timeout errors</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Update job metrics (execution time, success/failure)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use defer to ensure completion reporting even if job panics</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// sendHeartbeat reports worker status to coordinator</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">w </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Worker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">sendHeartbeat</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Collect current worker metrics (currentJobs, capacity)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Send heartbeat to coordinator (POST /heartbeat)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Handle coordinator response (job assignments, shutdown signals)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Update worker state based on coordinator instructions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Include worker capabilities in heartbeat for dynamic job routing</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"file-structure-commands\">File Structure Commands</h4>\n<p>To set up the recommended directory structure:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Create main directory structure</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">mkdir</span><span style=\"color:#79B8FF\"> -p</span><span style=\"color:#9ECBFF\"> cmd/{scheduler,worker,cli}</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">mkdir</span><span style=\"color:#79B8FF\"> -p</span><span style=\"color:#9ECBFF\"> internal/{coordinator,cron,queue,worker,models,storage/{etcd,redis}}</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">mkdir</span><span style=\"color:#79B8FF\"> -p</span><span style=\"color:#9ECBFF\"> pkg/{api/{handlers,middleware,types},client,metrics}</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">mkdir</span><span style=\"color:#79B8FF\"> -p</span><span style=\"color:#9ECBFF\"> configs</span><span style=\"color:#9ECBFF\"> deployments/{kubernetes,docker,terraform}</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">mkdir</span><span style=\"color:#79B8FF\"> -p</span><span style=\"color:#9ECBFF\"> tests/{integration,e2e,fixtures}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Initialize Go module</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> mod</span><span style=\"color:#9ECBFF\"> init</span><span style=\"color:#9ECBFF\"> distributed-job-scheduler</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Add essential dependencies</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> get</span><span style=\"color:#9ECBFF\"> go.etcd.io/etcd/client/v3@latest</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> get</span><span style=\"color:#9ECBFF\"> github.com/redis/go-redis/v9@latest</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> get</span><span style=\"color:#9ECBFF\"> github.com/gorilla/mux@latest</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> get</span><span style=\"color:#9ECBFF\"> github.com/stretchr/testify@latest</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> get</span><span style=\"color:#9ECBFF\"> gopkg.in/yaml.v3@latest</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p><strong>After Milestone 1 (Cron Parser)</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test cron parsing functionality</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">cd</span><span style=\"color:#9ECBFF\"> internal/cron</span><span style=\"color:#E1E4E8\"> &#x26;&#x26; </span><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> test</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected: All cron expression tests pass</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Manual verification: Create simple main.go that parses \"@daily\" and prints next 5 execution times</span></span></code></pre></div>\n\n<p><strong>After Milestone 2 (Priority Queue)</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test queue operations</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">cd</span><span style=\"color:#9ECBFF\"> internal/queue</span><span style=\"color:#E1E4E8\"> &#x26;&#x26; </span><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> test</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected: Priority ordering, deduplication, delayed execution tests pass</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Manual verification: Start Redis, enqueue jobs with different priorities, verify dequeue order</span></span></code></pre></div>\n\n<p><strong>After Milestone 3 (Worker Coordination)</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Integration test with all components</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> test</span><span style=\"color:#9ECBFF\"> ./tests/integration/...</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected: Multi-worker coordination, leader election, job recovery tests pass</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Manual verification: Start coordinator + 2 workers, kill one worker, verify job reassignment</span></span></code></pre></div>\n\n<h4 id=\"language-specific-go-hints\">Language-Specific Go Hints</h4>\n<ul>\n<li><strong>Graceful Shutdown</strong>: Use <code>context.Context</code> with <code>signal.NotifyContext()</code> for clean service shutdown</li>\n<li><strong>Atomic Operations</strong>: Use <code>sync/atomic</code> package for counters, avoid mutex overhead for simple increments  </li>\n<li><strong>Time Handling</strong>: Always use <code>time.UTC()</code> for cron calculations, convert to local time only for display</li>\n<li><strong>Error Wrapping</strong>: Use <code>fmt.Errorf(&quot;operation failed: %w&quot;, err)</code> to maintain error chains</li>\n<li><strong>JSON Marshaling</strong>: Implement custom <code>MarshalJSON()</code>/<code>UnmarshalJSON()</code> for complex types like <code>CronExpression</code></li>\n<li><strong>Testing</strong>: Use <code>testify/require</code> for test setup, <code>testify/assert</code> for verification - <code>require</code> stops on failure, <code>assert</code> continues</li>\n<li><strong>Redis Lua Scripts</strong>: Store scripts as constants and use <code>redis.NewScript()</code> for atomic multi-key operations</li>\n<li><strong>HTTP Clients</strong>: Set reasonable timeouts (<code>http.Client{Timeout: 30 * time.Second}</code>) to prevent hanging requests</li>\n</ul>\n<h2 id=\"data-model\">Data Model</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section defines the core data structures that underpin all three milestones - Job entities for Milestone 1&#39;s cron scheduling, Worker entities for Milestone 3&#39;s coordination, and Schedule models that tie everything together.</p>\n</blockquote>\n<p>The data model serves as the foundation for our distributed job scheduler, defining how jobs, workers, and schedules are represented, stored, and related to each other. Think of the data model as the blueprint for a city&#39;s infrastructure - it defines the roads (relationships), buildings (entities), and addressing system (identifiers) that allow all the traffic (data flow) to move efficiently and safely.</p>\n<p>A well-designed data model in a distributed system must balance several competing concerns: consistency across multiple nodes, performance under high load, and flexibility to support complex scheduling scenarios. Our model must also handle the temporal nature of scheduled jobs, where the same logical job may exist in multiple states across time, and the dynamic nature of worker nodes that can join, leave, or fail at any moment.</p>\n<p><img src=\"/api/project/job-scheduler/architecture-doc/asset?path=diagrams%2Fdata-model.svg\" alt=\"Data Model Relationships\"></p>\n<p>The core entities in our system form a triangle of relationships: Jobs represent work to be done, Workers represent compute capacity to execute that work, and Schedules represent the timing patterns that govern when jobs should run. Each entity has its own lifecycle, state management needs, and consistency requirements that we must carefully design.</p>\n<h3 id=\"job-definition\">Job Definition</h3>\n<p>The <code>Job</code> entity represents a unit of work to be executed by the distributed scheduler. Think of a job as a train ticket - it contains all the information needed to identify the passenger (job payload), determine the route (scheduling information), track the journey (execution state), and ensure the ticket isn&#39;t used twice (idempotency).</p>\n<p>Jobs in our system have a complex lifecycle that spans from creation through multiple execution attempts to final completion or failure. Unlike simple message queue systems where messages are consumed once, scheduled jobs may need to execute repeatedly on a cron schedule, require retry logic for transient failures, and maintain state across multiple worker nodes and coordinator failures.</p>\n<table>\n<thead>\n<tr>\n<th>Field Name</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>ID</td>\n<td>string</td>\n<td>Unique identifier for the job, typically a UUID to ensure global uniqueness across the distributed system</td>\n</tr>\n<tr>\n<td>Name</td>\n<td>string</td>\n<td>Human-readable name for the job, used for monitoring and debugging purposes</td>\n</tr>\n<tr>\n<td>CronExpression</td>\n<td>string</td>\n<td>Cron expression defining when this job should execute (e.g., &quot;0 9 * * MON&quot; for 9 AM every Monday)</td>\n</tr>\n<tr>\n<td>Priority</td>\n<td>int</td>\n<td>Numeric priority where higher values indicate higher priority (0 = lowest, 100 = highest)</td>\n</tr>\n<tr>\n<td>Payload</td>\n<td>map[string]string</td>\n<td>Key-value pairs containing the actual work parameters that workers need to execute the job</td>\n</tr>\n<tr>\n<td>IdempotencyKey</td>\n<td>string</td>\n<td>Client-provided key to prevent duplicate job submissions; jobs with the same key are deduplicated</td>\n</tr>\n<tr>\n<td>State</td>\n<td>JobState</td>\n<td>Current execution state of the job (PENDING, CLAIMED, EXECUTING, COMPLETED, FAILED)</td>\n</tr>\n<tr>\n<td>WorkerID</td>\n<td>string</td>\n<td>Identifier of the worker currently assigned to execute this job; empty if not yet claimed</td>\n</tr>\n<tr>\n<td>FencingToken</td>\n<td>string</td>\n<td>Unique token that prevents stale worker reports from affecting completed jobs</td>\n</tr>\n<tr>\n<td>ScheduledAt</td>\n<td>time.Time</td>\n<td>When this job instance should execute; calculated from cron expression for recurring jobs</td>\n</tr>\n<tr>\n<td>ClaimedAt</td>\n<td>*time.Time</td>\n<td>Timestamp when a worker claimed this job; nil if not yet claimed</td>\n</tr>\n<tr>\n<td>CompletedAt</td>\n<td>*time.Time</td>\n<td>Timestamp when job execution finished (successfully or failed); nil if still in progress</td>\n</tr>\n<tr>\n<td>RetryCount</td>\n<td>int</td>\n<td>Number of times this job has been retried after failure</td>\n</tr>\n<tr>\n<td>MaxRetries</td>\n<td>int</td>\n<td>Maximum number of retry attempts before marking the job as permanently failed</td>\n</tr>\n<tr>\n<td>CreatedAt</td>\n<td>time.Time</td>\n<td>Timestamp when this job was first created in the system</td>\n</tr>\n<tr>\n<td>UpdatedAt</td>\n<td>time.Time</td>\n<td>Timestamp of the last modification to this job record</td>\n</tr>\n</tbody></table>\n<p>The job state machine is central to ensuring exactly-once execution in our distributed environment. Each state transition represents a coordination point between the scheduler and workers, with careful attention to failure scenarios that could leave jobs in inconsistent states.</p>\n<table>\n<thead>\n<tr>\n<th>Current State</th>\n<th>Event</th>\n<th>Next State</th>\n<th>Actions Taken</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>PENDING</td>\n<td>Worker calls <code>claimJob()</code></td>\n<td>CLAIMED</td>\n<td>Set WorkerID, ClaimedAt timestamp, generate FencingToken</td>\n</tr>\n<tr>\n<td>CLAIMED</td>\n<td>Worker starts execution</td>\n<td>EXECUTING</td>\n<td>Update state, maintain heartbeat timeout</td>\n</tr>\n<tr>\n<td>EXECUTING</td>\n<td>Worker calls <code>reportCompletion()</code> with success</td>\n<td>COMPLETED</td>\n<td>Set CompletedAt, clear WorkerID, schedule next instance if recurring</td>\n</tr>\n<tr>\n<td>EXECUTING</td>\n<td>Worker calls <code>reportCompletion()</code> with failure</td>\n<td>FAILED or PENDING</td>\n<td>Increment RetryCount, reset for retry or mark failed if MaxRetries exceeded</td>\n</tr>\n<tr>\n<td>CLAIMED</td>\n<td>Claim timeout expires</td>\n<td>PENDING</td>\n<td>Clear WorkerID and ClaimedAt to allow re-assignment</td>\n</tr>\n<tr>\n<td>EXECUTING</td>\n<td>Worker heartbeat timeout</td>\n<td>PENDING</td>\n<td>Clear WorkerID, increment RetryCount, log recovery action</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Fencing Token Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Workers can crash, recover, or experience network delays that cause them to report completion for jobs that have already been reassigned to other workers</li>\n<li><strong>Options Considered</strong>: Monotonic sequence numbers, UUID-based tokens, timestamp-based tokens</li>\n<li><strong>Decision</strong>: UUID-based fencing tokens generated when jobs are claimed</li>\n<li><strong>Rationale</strong>: UUIDs provide uniqueness without requiring coordination between nodes, unlike sequence numbers that need centralized generation. They&#39;re also immune to clock skew issues that affect timestamp-based approaches</li>\n<li><strong>Consequences</strong>: Enables safe job recovery and prevents duplicate execution reports, but adds storage overhead and complexity to worker reporting logic</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Pros</th>\n<th>Cons</th>\n<th>Chosen?</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Sequence Numbers</td>\n<td>Simple ordering, small storage</td>\n<td>Requires coordinated counter, single point of failure</td>\n<td>No</td>\n</tr>\n<tr>\n<td>UUID Tokens</td>\n<td>No coordination needed, globally unique</td>\n<td>Larger storage, no natural ordering</td>\n<td><strong>Yes</strong></td>\n</tr>\n<tr>\n<td>Timestamps</td>\n<td>Natural ordering, human readable</td>\n<td>Clock skew issues, not guaranteed unique</td>\n<td>No</td>\n</tr>\n</tbody></table>\n<p>The idempotency key mechanism prevents clients from accidentally submitting the same job multiple times due to network retries or application bugs. When a job is submitted with an idempotency key that already exists, the scheduler returns the existing job instead of creating a duplicate. This is similar to how payment systems prevent double-charging when a customer clicks &quot;submit&quot; multiple times.</p>\n<p>The payload structure as a string map provides flexibility for different job types while maintaining simplicity for serialization and storage. More complex payload types can be JSON-encoded into string values, allowing the scheduler to remain agnostic about job content while still supporting rich data structures.</p>\n<blockquote>\n<p>The critical insight for job lifecycle management is that state transitions must be atomic and fenced. A job that transitions from EXECUTING to COMPLETED must never transition back to PENDING due to a delayed worker report, which is why fencing tokens are essential for correctness.</p>\n</blockquote>\n<p>⚠️ <strong>Pitfall: Race Condition Between Claim and Timeout</strong>\nWhen a worker claims a job but experiences a delay before starting execution, the coordinator might timeout the claim and reassign the job to another worker. Without proper fencing, both workers could execute the same job. The fencing token ensures that only the worker with the current token can successfully report completion, preventing this race condition.</p>\n<p>⚠️ <strong>Pitfall: Infinite Retry Loops</strong>\nJobs that fail due to permanent conditions (bad payload data, missing dependencies) will consume resources indefinitely if retry logic doesn&#39;t distinguish between transient and permanent failures. The MaxRetries field provides a circuit breaker, but job implementations should also return non-retryable error types for permanent failures.</p>\n<h3 id=\"worker-model\">Worker Model</h3>\n<p>The <code>Worker</code> entity represents a compute node capable of executing jobs in our distributed scheduler. Think of workers as delivery trucks in a logistics network - each truck has a capacity (how many packages it can carry), capabilities (refrigerated, oversized, hazardous materials), and a current location and status that the dispatch center needs to track for efficient job assignment.</p>\n<p>Workers in our system are dynamic entities that can join and leave the cluster at any time. Unlike static partitioning schemes, our model supports elastic scaling where workers can be added during peak load periods and removed when demand decreases. This requires careful state management to ensure that work isn&#39;t lost when workers disappear unexpectedly.</p>\n<table>\n<thead>\n<tr>\n<th>Field Name</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>ID</td>\n<td>string</td>\n<td>Unique identifier for the worker, typically combining hostname and process ID for easy debugging</td>\n</tr>\n<tr>\n<td>Address</td>\n<td>string</td>\n<td>Network address where the worker can be reached for job assignment and health checks (host:port format)</td>\n</tr>\n<tr>\n<td>Capacity</td>\n<td>int</td>\n<td>Maximum number of concurrent jobs this worker can execute, based on CPU cores and memory</td>\n</tr>\n<tr>\n<td>CurrentJobs</td>\n<td>int</td>\n<td>Number of jobs currently being executed by this worker</td>\n</tr>\n<tr>\n<td>Capabilities</td>\n<td>[]string</td>\n<td>List of job types or features this worker supports (e.g., [&quot;gpu&quot;, &quot;large-memory&quot;, &quot;secure-enclave&quot;])</td>\n</tr>\n<tr>\n<td>LastHeartbeat</td>\n<td>time.Time</td>\n<td>Timestamp of the most recent heartbeat signal from this worker</td>\n</tr>\n<tr>\n<td>State</td>\n<td>WorkerState</td>\n<td>Current operational state of the worker (AVAILABLE, BUSY, UNAVAILABLE)</td>\n</tr>\n<tr>\n<td>StartedAt</td>\n<td>time.Time</td>\n<td>When this worker first registered with the scheduler</td>\n</tr>\n<tr>\n<td>Metadata</td>\n<td>map[string]string</td>\n<td>Additional worker-specific information like version, region, instance type</td>\n</tr>\n</tbody></table>\n<p>The worker capacity model allows for load balancing based on actual resource utilization rather than simple round-robin assignment. Workers with higher capacity can accept more jobs, while workers approaching their limits are avoided for new assignments. This prevents overloading individual nodes while maximizing cluster utilization.</p>\n<table>\n<thead>\n<tr>\n<th>Current State</th>\n<th>Event</th>\n<th>Next State</th>\n<th>Actions Taken</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>AVAILABLE</td>\n<td>Job assigned and CurrentJobs &gt;= Capacity</td>\n<td>BUSY</td>\n<td>Stop offering jobs to this worker</td>\n</tr>\n<tr>\n<td>BUSY</td>\n<td>Job completed and CurrentJobs &lt; Capacity</td>\n<td>AVAILABLE</td>\n<td>Resume offering jobs to this worker</td>\n</tr>\n<tr>\n<td>AVAILABLE/BUSY</td>\n<td>Heartbeat timeout exceeded</td>\n<td>UNAVAILABLE</td>\n<td>Reassign all jobs, remove from assignment pool</td>\n</tr>\n<tr>\n<td>UNAVAILABLE</td>\n<td>Worker re-registers with <code>heartbeat()</code></td>\n<td>AVAILABLE</td>\n<td>Reset LastHeartbeat, set CurrentJobs to 0</td>\n</tr>\n</tbody></table>\n<p>Worker capabilities enable job affinity and constraint-based scheduling. Jobs can specify required capabilities (e.g., GPU access, specific software versions), and the scheduler ensures they&#39;re only assigned to compatible workers. This is essential for workloads that need specialized hardware or have security requirements.</p>\n<blockquote>\n<p><strong>Decision: Heartbeat-Based Health Monitoring</strong></p>\n<ul>\n<li><strong>Context</strong>: The scheduler needs to detect worker failures quickly to reassign jobs, but network partitions and temporary slowdowns shouldn&#39;t trigger false positives</li>\n<li><strong>Options Considered</strong>: Pull-based health checks, push-based heartbeats, hybrid approach with both</li>\n<li><strong>Decision</strong>: Push-based heartbeat mechanism where workers periodically call <code>heartbeat()</code></li>\n<li><strong>Rationale</strong>: Push-based heartbeats reduce coordinator overhead since workers contact the scheduler rather than the scheduler polling every worker. Workers can include status updates in heartbeat messages, providing richer information than simple ping responses</li>\n<li><strong>Consequences</strong>: Enables fast failure detection and efficient resource utilization tracking, but requires careful timeout tuning to balance false positives against detection latency</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Pros</th>\n<th>Cons</th>\n<th>Chosen?</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Pull-based Health Checks</td>\n<td>Coordinator controls timing, works through firewalls</td>\n<td>High coordinator overhead, delayed updates</td>\n<td>No</td>\n</tr>\n<tr>\n<td>Push-based Heartbeats</td>\n<td>Low coordinator overhead, real-time updates</td>\n<td>Requires worker initiative, complex timeout handling</td>\n<td><strong>Yes</strong></td>\n</tr>\n<tr>\n<td>Hybrid Approach</td>\n<td>Best of both worlds</td>\n<td>Complex implementation, potential conflicts</td>\n<td>No</td>\n</tr>\n</tbody></table>\n<p>The metadata field allows workers to provide context that helps with debugging and operational monitoring. For example, workers can report their software version, AWS instance type, or geographic region. This information doesn&#39;t affect scheduling logic but is invaluable for troubleshooting performance issues or ensuring compliance with data locality requirements.</p>\n<p>Worker address management handles the networking complexity of reaching workers for job assignment. In containerized environments, workers might have dynamic IP addresses or run behind load balancers. The address field accommodates these scenarios while providing a stable endpoint for coordinator communication.</p>\n<blockquote>\n<p>The key insight for worker lifecycle management is that workers are ephemeral resources that can disappear without notice, so the scheduler must be designed with failure as the default case rather than an exception. All worker state must be recoverable, and job assignments must include timeout mechanisms.</p>\n</blockquote>\n<p>⚠️ <strong>Pitfall: Heartbeat Timeout During Long Jobs</strong>\nWorkers executing long-running jobs might miss heartbeat deadlines not because they&#39;ve failed, but because they&#39;re busy processing. This can cause the coordinator to incorrectly mark them as unavailable and reassign their jobs. The heartbeat mechanism should be implemented as a separate goroutine that continues signaling even while jobs are executing.</p>\n<p>⚠️ <strong>Pitfall: Worker State Inconsistency</strong>\nIf a worker&#39;s CurrentJobs count becomes inconsistent with reality (due to bugs or missed completion reports), it might permanently remain in BUSY state even when idle. Periodic reconciliation between the worker&#39;s actual job count and the coordinator&#39;s records prevents this deadlock scenario.</p>\n<h3 id=\"schedule-model\">Schedule Model</h3>\n<p>The <code>Schedule</code> model represents the temporal patterns that govern when jobs execute in our distributed scheduler. Think of schedules as the conductor&#39;s score in an orchestra - they define not just when each instrument (job) should play, but also how the timing coordinates with other schedules to create a harmonious system-wide performance.</p>\n<p>Schedules in our system bridge the gap between human-readable cron expressions and the precise timing calculations needed by the distributed coordinator. They handle the complexity of timezone conversions, daylight saving time transitions, and edge cases like February 29th or &quot;the 31st of every month&quot; in months that only have 30 days.</p>\n<table>\n<thead>\n<tr>\n<th>Field Name</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Original</td>\n<td>string</td>\n<td>The exact cron expression as provided by the user, preserved for debugging and display</td>\n</tr>\n<tr>\n<td>Minutes</td>\n<td>[]int</td>\n<td>Parsed minute values (0-59); empty slice means &quot;every minute&quot;, single value means specific minute</td>\n</tr>\n<tr>\n<td>Hours</td>\n<td>[]int</td>\n<td>Parsed hour values (0-23); supports ranges like 9-17 for business hours</td>\n</tr>\n<tr>\n<td>DaysOfMonth</td>\n<td>[]int</td>\n<td>Parsed day-of-month values (1-31); handles month boundaries and leap years</td>\n</tr>\n<tr>\n<td>Months</td>\n<td>[]int</td>\n<td>Parsed month values (1-12); supports seasonal scheduling patterns</td>\n</tr>\n<tr>\n<td>DaysOfWeek</td>\n<td>[]int</td>\n<td>Parsed day-of-week values (0-6, Sunday=0); handles weekly recurring patterns</td>\n</tr>\n<tr>\n<td>Timezone</td>\n<td>*time.Location</td>\n<td>Time zone for interpreting the cron expression; nil defaults to UTC</td>\n</tr>\n</tbody></table>\n<p>The parsed field arrays enable efficient next-time calculation without repeatedly parsing the cron expression string. Each array contains the specific values when execution should occur, making the calculation algorithm a matter of finding the next valid combination across all dimensions.</p>\n<p>Cron expression parsing handles several complex scenarios that naive implementations often miss. The interaction between day-of-month and day-of-week fields follows cron&#39;s &quot;OR&quot; semantics - a job scheduled for &quot;15 * * * MON&quot; runs both on the 15th of every month AND every Monday, not just Mondays that fall on the 15th.</p>\n<blockquote>\n<p><strong>Decision: Pre-parsed Field Arrays vs. Runtime Parsing</strong></p>\n<ul>\n<li><strong>Context</strong>: Next execution time calculation happens frequently as the scheduler evaluates which jobs are ready to run</li>\n<li><strong>Options Considered</strong>: Parse cron expression on every calculation, parse once and store parsed format, hybrid caching approach</li>\n<li><strong>Decision</strong>: Parse cron expressions once during job creation and store the parsed field arrays</li>\n<li><strong>Rationale</strong>: Parsing is computationally expensive and involves string manipulation and regex matching. Pre-parsing moves this cost to job creation time, which happens much less frequently than schedule evaluation</li>\n<li><strong>Consequences</strong>: Faster schedule evaluation and reduced CPU overhead during peak scheduling periods, but increases storage requirements and complicates cron expression updates</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Pros</th>\n<th>Cons</th>\n<th>Chosen?</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Runtime Parsing</td>\n<td>Low memory usage, handles dynamic changes</td>\n<td>High CPU overhead, repeated work</td>\n<td>No</td>\n</tr>\n<tr>\n<td>Pre-parsed Storage</td>\n<td>Fast evaluation, one-time parsing cost</td>\n<td>Higher storage, complex updates</td>\n<td><strong>Yes</strong></td>\n</tr>\n<tr>\n<td>Hybrid Caching</td>\n<td>Balance of speed and memory</td>\n<td>Complex cache invalidation, potential consistency issues</td>\n<td>No</td>\n</tr>\n</tbody></table>\n<p>Timezone handling is one of the most complex aspects of schedule management. A job scheduled for &quot;9 AM daily&quot; in New York should execute at different UTC times throughout the year due to daylight saving time transitions. The Timezone field enables accurate local time interpretation while the coordinator operates on UTC internally.</p>\n<p>The next execution time calculation algorithm works by finding the earliest future time that satisfies all the cron field constraints simultaneously:</p>\n<ol>\n<li><strong>Start with the current time</strong> rounded up to the next minute boundary (since cron expressions have minute-level granularity)</li>\n<li><strong>Iterate through years</strong> starting from the current year, but limit the search to prevent infinite loops for impossible expressions</li>\n<li><strong>For each valid year, iterate through the months</strong> specified in the Months array</li>\n<li><strong>For each valid month, calculate candidate days</strong> that satisfy either the DaysOfMonth constraint OR the DaysOfWeek constraint (cron&#39;s OR semantics)</li>\n<li><strong>For each candidate day, iterate through the hours</strong> specified in the Hours array</li>\n<li><strong>For each valid hour, iterate through the minutes</strong> specified in the Minutes array</li>\n<li><strong>Return the first combination</strong> that represents a time after the current time</li>\n<li><strong>Handle timezone conversion</strong> if the schedule specifies a non-UTC timezone</li>\n</ol>\n<p>The algorithm must handle several edge cases that can cause infinite loops or incorrect results:</p>\n<ul>\n<li><strong>Impossible dates</strong>: &quot;31 * * 2 *&quot; (February 31st) should never match any date</li>\n<li><strong>Leap year handling</strong>: &quot;29 * * 2 *&quot; should only match in leap years</li>\n<li><strong>Daylight saving transitions</strong>: 2:30 AM might not exist on spring-forward days</li>\n<li><strong>Year boundaries</strong>: Ensure the search eventually terminates for expressions that have no valid future dates</li>\n</ul>\n<blockquote>\n<p>The critical insight for schedule calculation is that cron expressions define constraints rather than sequences. Unlike simple interval timers, cron schedules require constraint satisfaction across multiple temporal dimensions, making the calculation algorithm fundamentally a search problem.</p>\n</blockquote>\n<p>Timezone support requires careful coordination between the schedule representation and the execution coordinator. The CronExpression stores timezone information and handles local-to-UTC conversion, but the rest of the system operates purely in UTC to avoid consistency issues across distributed nodes that might be running in different timezones.</p>\n<p>⚠️ <strong>Pitfall: Daylight Saving Time Transitions</strong>\nDuring spring-forward transitions, times like 2:30 AM simply don&#39;t exist in local time zones that observe daylight saving time. A naive implementation might either throw an error or calculate an incorrect UTC time. The correct approach is to detect these non-existent times and advance to the next valid time slot.</p>\n<p>⚠️ <strong>Pitfall: Day-of-Month vs Day-of-Week Confusion</strong>\nMany developers expect cron&#39;s day-of-month and day-of-week fields to work with AND semantics (both must be satisfied), but the actual cron standard uses OR semantics (either can be satisfied). A job scheduled for &quot;0 9 15 * MON&quot; runs at 9 AM both on the 15th of every month AND every Monday, not just Mondays that fall on the 15th.</p>\n<p>⚠️ <strong>Pitfall: Infinite Loop on Impossible Expressions</strong>\nCron expressions like &quot;0 0 30 2 *&quot; (February 30th) will never have a valid execution time. The calculation algorithm must detect these impossible expressions and either reject them during parsing or terminate the search after a reasonable number of iterations to prevent infinite loops.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The data model implementation serves as the foundation for all three milestones, providing the type definitions and persistence layer that enable cron parsing, job queuing, and worker coordination. Think of this as building the database schema and entity classes that everything else will depend on.</p>\n<p><strong>A. Technology Recommendations:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Data Storage</td>\n<td>JSON files with file locking</td>\n<td>Redis with persistence enabled</td>\n</tr>\n<tr>\n<td>Serialization</td>\n<td><code>encoding/json</code> with struct tags</td>\n<td>Protocol Buffers with code generation</td>\n</tr>\n<tr>\n<td>Time Handling</td>\n<td><code>time.Time</code> with UTC normalization</td>\n<td><code>time.Time</code> with timezone-aware helpers</td>\n</tr>\n<tr>\n<td>Validation</td>\n<td>Manual field validation</td>\n<td>Struct validation library (go-playground/validator)</td>\n</tr>\n</tbody></table>\n<p><strong>B. Recommended File Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>project-root/\n  internal/model/\n    job.go              ← Job struct and methods\n    worker.go           ← Worker struct and methods  \n    schedule.go         ← CronExpression parsing and calculation\n    storage.go          ← Data persistence interface\n    types.go            ← Enums and constants\n  internal/storage/\n    redis.go            ← Redis storage implementation\n    memory.go           ← In-memory storage for testing\n  cmd/scheduler/\n    main.go             ← Entry point</code></pre></div>\n\n<p><strong>C. Complete Infrastructure Starter Code:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// internal/model/types.go</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> model</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// JobState represents the current execution state of a job</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> JobState</span><span style=\"color:#F97583\"> int</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">const</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    PENDING</span><span style=\"color:#B392F0\"> JobState</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> iota</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    CLAIMED</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    EXECUTING</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    COMPLETED</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    FAILED</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">s </span><span style=\"color:#B392F0\">JobState</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">String</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    switch</span><span style=\"color:#E1E4E8\"> s {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    case</span><span style=\"color:#E1E4E8\"> PENDING:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> \"pending\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    case</span><span style=\"color:#E1E4E8\"> CLAIMED:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> \"claimed\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    case</span><span style=\"color:#E1E4E8\"> EXECUTING:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> \"executing\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    case</span><span style=\"color:#E1E4E8\"> COMPLETED:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> \"completed\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    case</span><span style=\"color:#E1E4E8\"> FAILED:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> \"failed\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    default</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> \"unknown\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// WorkerState represents the current operational state of a worker</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> WorkerState</span><span style=\"color:#F97583\"> int</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">const</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    AVAILABLE</span><span style=\"color:#B392F0\"> WorkerState</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> iota</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    BUSY</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    UNAVAILABLE</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">s </span><span style=\"color:#B392F0\">WorkerState</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">String</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    switch</span><span style=\"color:#E1E4E8\"> s {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    case</span><span style=\"color:#E1E4E8\"> AVAILABLE:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> \"available\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    case</span><span style=\"color:#E1E4E8\"> BUSY:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> \"busy\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    case</span><span style=\"color:#E1E4E8\"> UNAVAILABLE:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> \"unavailable\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    default</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> \"unknown\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Storage interface for persisting scheduler entities</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> Storage</span><span style=\"color:#F97583\"> interface</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Job operations</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    CreateJob</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">job</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    GetJob</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">id</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    UpdateJob</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">job</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    ListJobs</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">state</span><span style=\"color:#B392F0\"> JobState</span><span style=\"color:#E1E4E8\">) ([]</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Worker operations  </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    RegisterWorker</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">worker</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">Worker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    GetWorker</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">id</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Worker</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    UpdateWorker</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">worker</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">Worker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    ListWorkers</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">state</span><span style=\"color:#B392F0\"> WorkerState</span><span style=\"color:#E1E4E8\">) ([]</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Worker</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Cleanup operations</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    DeleteJob</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">id</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    UnregisterWorker</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">id</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// internal/storage/memory.go</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> storage</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">fmt</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">sync</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">github.com/yourorg/scheduler/internal/model</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// MemoryStorage provides in-memory storage for testing</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> MemoryStorage</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    mu      </span><span style=\"color:#B392F0\">sync</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">RWMutex</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    jobs    </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">model</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Job</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    workers </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">model</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Worker</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewMemoryStorage</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">MemoryStorage</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">MemoryStorage</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        jobs:    </span><span style=\"color:#B392F0\">make</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">model</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        workers: </span><span style=\"color:#B392F0\">make</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">model</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Worker</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">s </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">MemoryStorage</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">CreateJob</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">job</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">model</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    s.mu.</span><span style=\"color:#B392F0\">Lock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> s.mu.</span><span style=\"color:#B392F0\">Unlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> _, exists </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> s.jobs[job.ID]; exists {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"job </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\"> already exists\"</span><span style=\"color:#E1E4E8\">, job.ID)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Deep copy to prevent external modifications</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    jobCopy </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\">job</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    s.jobs[job.ID] </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#E1E4E8\">jobCopy</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">s </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">MemoryStorage</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">GetJob</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">id</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">model</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    s.mu.</span><span style=\"color:#B392F0\">RLock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> s.mu.</span><span style=\"color:#B392F0\">RUnlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    job, exists </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> s.jobs[id]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> !</span><span style=\"color:#E1E4E8\">exists {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\">, fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"job </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\"> not found\"</span><span style=\"color:#E1E4E8\">, id)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Deep copy to prevent external modifications</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    jobCopy </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\">job</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#E1E4E8\">jobCopy, </span><span style=\"color:#79B8FF\">nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">s </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">MemoryStorage</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">UpdateJob</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">job</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">model</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    s.mu.</span><span style=\"color:#B392F0\">Lock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> s.mu.</span><span style=\"color:#B392F0\">Unlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> _, exists </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> s.jobs[job.ID]; </span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">exists {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"job </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\"> not found\"</span><span style=\"color:#E1E4E8\">, job.ID)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Deep copy to prevent external modifications</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    jobCopy </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\">job</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    s.jobs[job.ID] </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#E1E4E8\">jobCopy</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">s </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">MemoryStorage</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">ListJobs</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">state</span><span style=\"color:#B392F0\"> model</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">JobState</span><span style=\"color:#E1E4E8\">) ([]</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">model</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    s.mu.</span><span style=\"color:#B392F0\">RLock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> s.mu.</span><span style=\"color:#B392F0\">RUnlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    var</span><span style=\"color:#E1E4E8\"> jobs []</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">model</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Job</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> _, job </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> range</span><span style=\"color:#E1E4E8\"> s.jobs {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> job.State </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> state {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            jobCopy </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\">job</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            jobs </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> append</span><span style=\"color:#E1E4E8\">(jobs, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">jobCopy)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> jobs, </span><span style=\"color:#79B8FF\">nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Implement remaining Storage interface methods for workers...</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// (Similar pattern to job methods)</span></span></code></pre></div>\n\n<p><strong>D. Core Logic Skeleton Code:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// internal/model/job.go</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> model</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">github.com/google/uuid</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Job represents a unit of work to be executed by the distributed scheduler</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> Job</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ID              </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">            `json:\"id\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Name            </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">            `json:\"name\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CronExpression  </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">            `json:\"cron_expression\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Priority        </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">               `json:\"priority\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Payload         </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\"> `json:\"payload\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    IdempotencyKey  </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">            `json:\"idempotency_key\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    State           </span><span style=\"color:#B392F0\">JobState</span><span style=\"color:#9ECBFF\">          `json:\"state\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    WorkerID        </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">            `json:\"worker_id,omitempty\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    FencingToken    </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">            `json:\"fencing_token,omitempty\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ScheduledAt     </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">         `json:\"scheduled_at\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ClaimedAt       </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">        `json:\"claimed_at,omitempty\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CompletedAt     </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">        `json:\"completed_at,omitempty\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    RetryCount      </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">               `json:\"retry_count\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    MaxRetries      </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">               `json:\"max_retries\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CreatedAt       </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">         `json:\"created_at\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    UpdatedAt       </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">         `json:\"updated_at\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// NewJob creates a new job with default values and validation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewJob</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">name</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">cronExpr</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">priority</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">payload</span><span style=\"color:#F97583\"> map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Validate cron expression using CronExpression.Parse()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Generate unique ID using uuid.New().String()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Calculate initial ScheduledAt time from cron expression</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Set CreatedAt and UpdatedAt to current time</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Initialize State to PENDING, RetryCount to 0</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Set MaxRetries to default value (e.g., 3)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use time.Now().UTC() for consistent timezone handling</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ClaimForWorker atomically claims this job for the specified worker</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">j </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">ClaimForWorker</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">workerID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Check if job is in PENDING state, return error if not</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Generate new fencing token using uuid.New().String()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Set WorkerID, FencingToken, and ClaimedAt timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Transition State to CLAIMED</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Update the UpdatedAt timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Caller must persist the job after claiming</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// MarkExecuting transitions job to executing state with validation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">j </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">MarkExecuting</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">workerID</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">fencingToken</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Validate that WorkerID matches the claimer</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Validate that fencingToken matches current token  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Check that current State is CLAIMED</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Transition State to EXECUTING</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Update the UpdatedAt timestamp</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ReportCompletion handles job completion or failure reporting</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">j </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">ReportCompletion</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">workerID</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">fencingToken</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">success</span><span style=\"color:#F97583\"> bool</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">errorMsg</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Validate workerID and fencingToken match current assignment</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Check that current State is EXECUTING</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Set CompletedAt timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: If success, transition to COMPLETED state</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: If failure and retries available, increment RetryCount and reset to PENDING</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: If failure and no retries left, transition to FAILED state</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Clear WorkerID and FencingToken</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 8: Update the UpdatedAt timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Store errorMsg in Metadata field for debugging</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// internal/model/worker.go  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> model</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Worker represents a compute node capable of executing jobs</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> Worker</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ID            </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">            `json:\"id\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Address       </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">            `json:\"address\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Capacity      </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">               `json:\"capacity\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CurrentJobs   </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">               `json:\"current_jobs\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Capabilities  []</span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">          `json:\"capabilities\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LastHeartbeat </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">         `json:\"last_heartbeat\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    State         </span><span style=\"color:#B392F0\">WorkerState</span><span style=\"color:#9ECBFF\">       `json:\"state\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    StartedAt     </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">         `json:\"started_at\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Metadata      </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\"> `json:\"metadata\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// NewWorker creates a new worker with validation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewWorker</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">id</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">address</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">capacity</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">capabilities</span><span style=\"color:#E1E4E8\"> []</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Worker</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Validate that ID is non-empty and unique format</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Validate that address is valid host:port format</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Validate that capacity is positive integer</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Set State to AVAILABLE and CurrentJobs to 0</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Set StartedAt and LastHeartbeat to current time</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Initialize Metadata map and copy capabilities slice</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use net.ResolveTCPAddr() to validate address format</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// UpdateHeartbeat records a heartbeat and updates worker state</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">w </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Worker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">UpdateHeartbeat</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">currentJobs</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Update LastHeartbeat to current time</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Update CurrentJobs to the reported value</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Update State based on capacity: AVAILABLE if under capacity, BUSY if at/over capacity</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Validate that currentJobs is non-negative and not greater than realistic limits</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Consider adding validation for currentJobs > Capacity (might indicate bug)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// IsHealthy checks if worker is responding within timeout</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">w </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Worker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">IsHealthy</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">timeout</span><span style=\"color:#B392F0\"> time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Calculate time since LastHeartbeat</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Return true if within timeout and State is not UNAVAILABLE</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Return false if timeout exceeded or worker marked unavailable</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// CanAcceptJob checks if worker can accept a new job</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">w </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Worker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">CanAcceptJob</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">requiredCapabilities</span><span style=\"color:#E1E4E8\"> []</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Check if State is AVAILABLE (not BUSY or UNAVAILABLE)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Check if CurrentJobs &#x3C; Capacity</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Check if worker has all required capabilities</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Return true only if all conditions are met</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use string comparison to check capability matching</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// internal/model/schedule.go</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> model</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">strings</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// CronExpression represents a parsed cron expression with timezone support</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> CronExpression</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Original     </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">         `json:\"original\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Minutes      []</span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">          `json:\"minutes\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Hours        []</span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">          `json:\"hours\"`</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    DaysOfMonth  []</span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">          `json:\"days_of_month\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Months       []</span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">          `json:\"months\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    DaysOfWeek   []</span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">          `json:\"days_of_week\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Timezone     </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Location</span><span style=\"color:#9ECBFF\"> `json:\"timezone,omitempty\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ParseCronExpression parses a cron expression string into structured format</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> ParseCronExpression</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">expr</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">CronExpression</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Split expression into fields (space-separated)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Validate field count (5 or 6 fields supported)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Parse each field using parseField() helper</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Handle special expressions like @daily, @hourly</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Set timezone to UTC if not specified</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Store original expression for debugging</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use strings.Fields() to split on whitespace</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// NextExecutionTime calculates when this cron expression should next run</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">CronExpression</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">NextExecutionTime</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">from</span><span style=\"color:#B392F0\"> time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Convert from time to the cron expression's timezone</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Round up to next minute boundary (cron has minute precision)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Iterate through years, months, days to find next valid time</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Check both day-of-month and day-of-week constraints (OR semantics)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Handle edge cases like February 29, month boundaries</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Convert result back to UTC before returning</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Return error if no valid time found within reasonable range (2 years)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use time.Date() to construct candidate times and check validity</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// parseField parses a single cron field (minutes, hours, etc.) into integer slice</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> parseField</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">field</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">min</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">max</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\">) ([]</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Handle wildcard \"*\" - return all values in range</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Handle step values like \"*/15\" or \"2-10/3\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Handle ranges like \"9-17\" </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Handle lists like \"1,15,30\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Handle single values like \"5\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Validate all values are within min-max range</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Sort and deduplicate the result slice</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use strconv.Atoi() for string to int conversion</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>E. Language-Specific Hints:</strong></p>\n<ul>\n<li><strong>Time Handling</strong>: Always use <code>time.Now().UTC()</code> for consistency across distributed nodes. Use <code>time.LoadLocation()</code> for timezone parsing in cron expressions.</li>\n<li><strong>JSON Serialization</strong>: Add <code>json</code> struct tags with <code>omitempty</code> for optional fields like <code>ClaimedAt *time.Time</code>.</li>\n<li><strong>UUID Generation</strong>: Use <code>github.com/google/uuid</code> package for generating job IDs and fencing tokens.</li>\n<li><strong>Validation</strong>: Consider using <code>github.com/go-playground/validator/v10</code> for struct validation with tags like <code>validate:&quot;required,min=1,max=100&quot;</code>.</li>\n<li><strong>Concurrency</strong>: Use <code>sync.RWMutex</code> for storage implementations to allow concurrent reads while protecting writes.</li>\n</ul>\n<p><strong>F. Milestone Checkpoint:</strong></p>\n<p>After implementing the data model:</p>\n<ul>\n<li>Run <code>go test ./internal/model/...</code> - should pass basic struct creation and validation tests</li>\n<li>Create a job with <code>NewJob()</code> and verify all fields are populated correctly</li>\n<li>Parse a simple cron expression like <code>&quot;0 9 * * MON&quot;</code> and verify the parsed fields match expected values</li>\n<li>Test worker heartbeat updates and verify state transitions between AVAILABLE and BUSY</li>\n<li>Verify that job state transitions follow the documented state machine (can&#39;t go from COMPLETED back to EXECUTING)</li>\n</ul>\n<p>Expected output when testing cron parsing:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Expression: &quot;0 9 * * 1&quot;\nMinutes: [0]\nHours: [9] \nDaysOfMonth: [1,2,3,...,31]\nMonths: [1,2,3,...,12]\nDaysOfWeek: [1]\nNext execution: 2024-01-08 09:00:00 UTC (next Monday at 9 AM)</code></pre></div>\n\n<p>Signs that something is wrong:</p>\n<ul>\n<li>Job IDs are not unique across multiple calls to <code>NewJob()</code></li>\n<li>Cron parsing returns incorrect field arrays (e.g., <code>*</code> doesn&#39;t expand to full range)</li>\n<li>Worker state doesn&#39;t change when <code>CurrentJobs</code> exceeds <code>Capacity</code></li>\n<li>Time calculations are inconsistent across different system timezones</li>\n</ul>\n<h2 id=\"cron-expression-parser\">Cron Expression Parser</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Milestone 1 - Cron Expression Parser. This section implements the core scheduling logic that parses cron expressions and calculates next execution times with timezone support.</p>\n</blockquote>\n<h3 id=\"mental-model-understanding-cron-as-a-calendar-pattern-matching-system\">Mental Model: Understanding cron as a calendar pattern matching system</h3>\n<p>Think of cron expressions as a sophisticated calendar filter that answers the question: &quot;When should this job run next?&quot; Imagine you&#39;re a personal assistant managing a complex schedule for an executive. Instead of writing down specific dates and times, you create rules like &quot;every Monday at 9 AM&quot; or &quot;the 15th of every month at noon.&quot; Cron expressions work exactly the same way - they define patterns that match against the calendar to determine when jobs should execute.</p>\n<p>The power of cron lies in its ability to express complex recurring patterns with simple field-based notation. Each field acts like a filter that constrains when execution can occur. When all five (or six) filters align - meaning the current time matches all specified constraints - the job becomes eligible for execution. This pattern-matching approach makes cron expressions incredibly flexible while remaining human-readable.</p>\n<p>Consider the analogy of a combination lock. Just as a combination lock only opens when all tumblers align to the correct positions, a cron job only executes when the current time matches all field constraints simultaneously. The minute field must match, AND the hour field must match, AND the day constraints must be satisfied, and so on. This intersection-based logic is the fundamental principle underlying cron scheduling.</p>\n<p>However, unlike simple calendar entries, cron expressions must handle edge cases that don&#39;t occur in human scheduling. What happens when you schedule a job for the 31st of every month, but February only has 28 days? How do you handle timezone transitions during daylight saving time? These complexities make cron parsing more challenging than it initially appears, requiring careful consideration of calendar arithmetic and timezone handling.</p>\n<p>The <code>CronExpression</code> structure captures this pattern-matching concept by breaking down the textual cron expression into structured field lists. Instead of repeatedly parsing the string &quot;0 9 * * 1&quot;, the parser converts it once into a format where minutes=[0], hours=[9], and daysOfWeek=[1], making subsequent time calculations much more efficient.</p>\n<h3 id=\"parsing-algorithm-field-by-field-validation-and-range-expansion-for-cron-expressions\">Parsing Algorithm: Field-by-field validation and range expansion for cron expressions</h3>\n<p>The cron parsing algorithm transforms a textual cron expression into a structured representation that enables efficient time calculations. This process involves tokenization, field validation, and range expansion to handle the various syntactic features that cron expressions support.</p>\n<blockquote>\n<p><strong>Decision: Five-field vs Six-field Cron Support</strong></p>\n<ul>\n<li><strong>Context</strong>: Standard Unix cron uses five fields (minute, hour, day-of-month, month, day-of-week), but many modern schedulers support a six-field format that includes seconds.</li>\n<li><strong>Options Considered</strong>: Support only five-field format for simplicity, support only six-field format for precision, support both formats with auto-detection.</li>\n<li><strong>Decision</strong>: Support both formats with auto-detection based on field count.</li>\n<li><strong>Rationale</strong>: This provides maximum compatibility with existing cron expressions while enabling sub-minute scheduling precision when needed. Auto-detection eliminates the need for users to specify the format explicitly.</li>\n<li><strong>Consequences</strong>: Parsing logic becomes slightly more complex, but the scheduler can handle both traditional Unix cron expressions and modern high-precision scheduling requirements.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Format Type</th>\n<th>Field Count</th>\n<th>Fields</th>\n<th>Use Case</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Traditional</td>\n<td>5</td>\n<td>minute, hour, day-of-month, month, day-of-week</td>\n<td>Standard Unix cron compatibility</td>\n</tr>\n<tr>\n<td>Extended</td>\n<td>6</td>\n<td>second, minute, hour, day-of-month, month, day-of-week</td>\n<td>Sub-minute scheduling precision</td>\n</tr>\n</tbody></table>\n<p>The parsing process follows a systematic approach that validates each field and expands shorthand notations into explicit value lists. The algorithm begins by tokenizing the input string on whitespace boundaries, then determines the format based on the number of fields detected. This auto-detection prevents users from having to specify the format explicitly while ensuring backward compatibility with existing cron expressions.</p>\n<p><strong>Field Parsing Algorithm:</strong></p>\n<ol>\n<li><p><strong>Tokenization</strong>: Split the input string on whitespace to extract individual field values, handling multiple consecutive spaces and tab characters gracefully.</p>\n</li>\n<li><p><strong>Format Detection</strong>: Count the number of fields to determine whether this is a five-field or six-field expression, adjusting field positions accordingly.</p>\n</li>\n<li><p><strong>Shorthand Expansion</strong>: Check for special shorthand expressions like @yearly, @monthly, @daily, @hourly, and @reboot, converting them to their equivalent standard field representations.</p>\n</li>\n<li><p><strong>Field-by-Field Processing</strong>: For each field position, validate the syntax and expand ranges, lists, and step values into explicit integer lists.</p>\n</li>\n<li><p><strong>Range Validation</strong>: Ensure all expanded values fall within valid ranges for each field type (0-59 for minutes, 1-31 for day-of-month, etc.).</p>\n</li>\n<li><p><strong>Semantic Validation</strong>: Check for semantic errors like invalid day-of-month values for specific months or conflicting day-of-week specifications.</p>\n</li>\n</ol>\n<p>Each field supports multiple syntactic forms that must be parsed and normalized into integer lists. The wildcard character (<em>) represents all valid values for that field. Ranges (1-5) specify inclusive spans of values. Lists (1,3,5) enumerate specific values explicitly. Step values (</em>/5 or 2-10/3) generate arithmetic progressions within specified ranges.</p>\n<table>\n<thead>\n<tr>\n<th>Syntax Type</th>\n<th>Example</th>\n<th>Expansion</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Wildcard</td>\n<td>*</td>\n<td>All valid values</td>\n<td>Matches every possible value for this field</td>\n</tr>\n<tr>\n<td>Specific Value</td>\n<td>15</td>\n<td>[15]</td>\n<td>Matches exactly one value</td>\n</tr>\n<tr>\n<td>Range</td>\n<td>1-5</td>\n<td>[1,2,3,4,5]</td>\n<td>Matches all values in inclusive range</td>\n</tr>\n<tr>\n<td>List</td>\n<td>1,3,5</td>\n<td>[1,3,5]</td>\n<td>Matches explicitly enumerated values</td>\n</tr>\n<tr>\n<td>Step (wildcard)</td>\n<td>*/5</td>\n<td>[0,5,10,15,...]</td>\n<td>Every 5th value starting from minimum</td>\n</tr>\n<tr>\n<td>Step (range)</td>\n<td>10-20/3</td>\n<td>[10,13,16,19]</td>\n<td>Every 3rd value within range</td>\n</tr>\n</tbody></table>\n<p>The range expansion logic handles edge cases carefully. When processing step values, the algorithm starts from the range minimum (or field minimum for wildcards) and increments by the step size until exceeding the range maximum. This ensures consistent behavior regardless of whether the step divides evenly into the range size.</p>\n<p>Field validation enforces both syntactic and semantic constraints. Syntactic validation ensures proper format (no invalid characters, correct range syntax), while semantic validation checks domain-specific rules (no 31st day in February, valid timezone names). The validator maintains separate error lists for each category to provide detailed feedback about parsing failures.</p>\n<blockquote>\n<p>The critical insight in cron parsing is that expansion happens once at parse time, not at every time calculation. Converting &quot;*/5&quot; to [0,5,10,15,20,25,30,35,40,45,50,55] during parsing makes subsequent time calculations much faster, since they only need to check membership in pre-computed lists.</p>\n</blockquote>\n<p><strong>Common Edge Cases in Parsing:</strong></p>\n<p>The parser must handle several edge cases that frequently cause issues in cron implementations. Day-of-month and day-of-week interaction follows Unix cron semantics where both constraints are OR&#39;ed together rather than AND&#39;ed. This means &quot;0 9 15 * 1&quot; runs at 9 AM on the 15th of every month OR every Monday, not just on Mondays that fall on the 15th.</p>\n<p>Timezone specifications can appear as suffixes to cron expressions in extended formats. The parser must extract timezone information and validate it against the system&#39;s timezone database before storing it in the <code>CronExpression</code> structure. Invalid timezone names should cause parsing failures with clear error messages.</p>\n<p>Range boundaries require careful validation. Day-of-month ranges that include 31 are valid during parsing but may not match certain months during execution. The parser accepts these ranges but the time calculation algorithm must handle month-specific limitations appropriately.</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Valid Range</th>\n<th>Special Cases</th>\n<th>Common Errors</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Second</td>\n<td>0-59</td>\n<td>N/A</td>\n<td>Using 60 for leap seconds</td>\n</tr>\n<tr>\n<td>Minute</td>\n<td>0-59</td>\n<td>N/A</td>\n<td>Using 60 instead of 0</td>\n</tr>\n<tr>\n<td>Hour</td>\n<td>0-23</td>\n<td>N/A</td>\n<td>Using 24 instead of 0</td>\n</tr>\n<tr>\n<td>Day-of-Month</td>\n<td>1-31</td>\n<td>Month-dependent validity</td>\n<td>Using 0, assuming all months have 31 days</td>\n</tr>\n<tr>\n<td>Month</td>\n<td>1-12</td>\n<td>N/A</td>\n<td>Using 0-11 instead of 1-12</td>\n</tr>\n<tr>\n<td>Day-of-Week</td>\n<td>0-7</td>\n<td>Both 0 and 7 represent Sunday</td>\n<td>Confusion about Sunday representation</td>\n</tr>\n</tbody></table>\n<h3 id=\"next-time-calculation-algorithm-for-finding-the-next-valid-execution-time-from-current-timestamp\">Next Time Calculation: Algorithm for finding the next valid execution time from current timestamp</h3>\n<p>The next execution time calculation is the most complex part of cron processing because it must handle calendar arithmetic, timezone transitions, and the interaction between day-of-month and day-of-week constraints. The algorithm starts from the current timestamp and incrementally advances through time units until finding a moment that satisfies all field constraints simultaneously.</p>\n<p>Think of this process like solving a multi-dimensional constraint satisfaction problem. Each cron field represents a constraint that the target timestamp must satisfy. The algorithm works by advancing time in the smallest possible increments - typically one minute for five-field expressions or one second for six-field expressions - and checking whether the current time satisfies all constraints.</p>\n<blockquote>\n<p><strong>Decision: Incremental vs Mathematical Next Time Calculation</strong></p>\n<ul>\n<li><strong>Context</strong>: There are two approaches to finding the next execution time - incrementally advancing time units until constraints are satisfied, or mathematically calculating the next valid time directly.</li>\n<li><strong>Options Considered</strong>: Pure incremental approach (simple but potentially slow), pure mathematical approach (fast but complex), hybrid approach that uses math for simple cases and incremental for complex ones.</li>\n<li><strong>Decision</strong>: Implement a hybrid approach that uses mathematical shortcuts for simple patterns but falls back to incremental advancement for complex constraints.</li>\n<li><strong>Rationale</strong>: Simple patterns like &quot;every hour&quot; or &quot;daily at 3 AM&quot; can be calculated directly using modular arithmetic, providing excellent performance. Complex patterns involving multiple constraints or day-of-week/day-of-month interactions require incremental checking to handle edge cases correctly.</li>\n<li><strong>Consequences</strong>: Provides optimal performance for common scheduling patterns while maintaining correctness for complex expressions. Code complexity is moderate since the mathematical shortcuts are optional optimizations.</li>\n</ul>\n</blockquote>\n<p><strong>Next Time Calculation Algorithm:</strong></p>\n<ol>\n<li><p><strong>Normalization</strong>: Convert the current timestamp to the target timezone and truncate to the appropriate precision (minute or second boundary based on expression format).</p>\n</li>\n<li><p><strong>Constraint Checking</strong>: Evaluate whether the current time satisfies all field constraints, returning immediately if it matches exactly.</p>\n</li>\n<li><p><strong>Increment Strategy</strong>: Choose the appropriate time increment based on which constraints are failing - advance by seconds, minutes, hours, days, or months as appropriate.</p>\n</li>\n<li><p><strong>Calendar Advancement</strong>: Increment the time by the chosen amount, handling month boundaries, leap years, and other calendar complexities correctly.</p>\n</li>\n<li><p><strong>Constraint Re-evaluation</strong>: Check the new timestamp against all field constraints, repeating the process until a matching time is found.</p>\n</li>\n<li><p><strong>Infinite Loop Protection</strong>: Implement safeguards to prevent infinite loops when no valid execution time exists within a reasonable future window.</p>\n</li>\n</ol>\n<p>The algorithm optimizes performance by choosing the largest possible time increment at each step. If the current hour doesn&#39;t match the hour constraint, there&#39;s no point in checking individual minutes - the algorithm can jump directly to the next valid hour. This coarse-grained advancement significantly reduces the number of iterations required.</p>\n<table>\n<thead>\n<tr>\n<th>Failed Constraint</th>\n<th>Increment Strategy</th>\n<th>Next Check Point</th>\n<th>Optimization Benefit</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Second</td>\n<td>+1 second</td>\n<td>Next second</td>\n<td>Minimal (baseline increment)</td>\n</tr>\n<tr>\n<td>Minute</td>\n<td>Advance to next valid minute</td>\n<td>Start of target minute</td>\n<td>60x faster than second-by-second</td>\n</tr>\n<tr>\n<td>Hour</td>\n<td>Advance to next valid hour</td>\n<td>Start of target hour</td>\n<td>3600x faster than second-by-second</td>\n</tr>\n<tr>\n<td>Day-of-Month</td>\n<td>Advance to next valid day</td>\n<td>Start of target day</td>\n<td>Up to 86400x faster</td>\n</tr>\n<tr>\n<td>Month</td>\n<td>Advance to next valid month</td>\n<td>Start of target month</td>\n<td>Up to 2.6M x faster</td>\n</tr>\n</tbody></table>\n<p><strong>Day-of-Week and Day-of-Month Interaction:</strong></p>\n<p>The most complex aspect of cron time calculation is handling the interaction between day-of-month and day-of-week constraints when both are specified (neither is a wildcard). Unix cron semantics dictate that this creates an OR condition - the job runs if EITHER constraint is satisfied, not only when BOTH are satisfied simultaneously.</p>\n<p>This means the expression &quot;0 9 15 * 1&quot; (9 AM on the 15th or on Mondays) has two separate series of execution times that must be computed and merged. The algorithm handles this by calculating next execution times for each constraint independently, then selecting the earliest result.</p>\n<p>Consider a concrete example: if today is Wednesday, March 10th, and we&#39;re looking for the next execution of &quot;0 9 15 * 1&quot;:</p>\n<ul>\n<li>Next 15th: March 15th at 9 AM (5 days from now)</li>\n<li>Next Monday: March 14th at 9 AM (4 days from now)  </li>\n<li>Result: March 14th at 9 AM (earlier of the two)</li>\n</ul>\n<p><strong>Calendar Arithmetic and Edge Cases:</strong></p>\n<p>The algorithm must handle numerous calendar edge cases that don&#39;t occur in typical application development. Month lengths vary (28, 29, 30, or 31 days), requiring leap year calculations for February. When advancing from January 31st to February, the algorithm must recognize that February 31st doesn&#39;t exist and adjust accordingly.</p>\n<p>Timezone transitions during daylight saving time create additional complexity. When clocks &quot;spring forward,&quot; certain times don&#39;t exist (2:30 AM might be skipped entirely). When clocks &quot;fall back,&quot; certain times occur twice. The algorithm must handle these transitions gracefully, typically by selecting the first occurrence of ambiguous times and skipping non-existent times.</p>\n<table>\n<thead>\n<tr>\n<th>Edge Case</th>\n<th>Scenario</th>\n<th>Algorithm Behavior</th>\n<th>Example</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Missing day</td>\n<td>Job scheduled for 31st, current month has 30 days</td>\n<td>Advance to next month with sufficient days</td>\n<td>April 31st → May 31st</td>\n</tr>\n<tr>\n<td>Leap year</td>\n<td>February 29th in non-leap year</td>\n<td>Skip to next valid occurrence</td>\n<td>Feb 29th 2023 → Feb 29th 2024</td>\n</tr>\n<tr>\n<td>DST spring forward</td>\n<td>2:30 AM doesn&#39;t exist</td>\n<td>Skip to next valid time after transition</td>\n<td>2:30 AM → 3:30 AM</td>\n</tr>\n<tr>\n<td>DST fall back</td>\n<td>2:30 AM occurs twice</td>\n<td>Use first occurrence only</td>\n<td>2:30 AM (standard time)</td>\n</tr>\n<tr>\n<td>Year boundary</td>\n<td>December → January transition</td>\n<td>Handle year increment correctly</td>\n<td>Dec 31st → Jan 1st (next year)</td>\n</tr>\n</tbody></table>\n<p><strong>Performance Optimization Strategies:</strong></p>\n<p>For frequently-used cron expressions, the scheduler can implement caching strategies that pre-compute next execution times. Simple patterns like &quot;every hour&quot; or &quot;daily at midnight&quot; benefit from mathematical shortcuts that avoid iterative time advancement entirely.</p>\n<p>The algorithm maintains an upper bound on search iterations to prevent infinite loops when no valid execution time exists. This can occur with malformed expressions or edge cases involving leap years and month boundaries. After exceeding the iteration limit, the algorithm returns an error rather than consuming infinite CPU time.</p>\n<p>For expressions with large gaps between executions (like &quot;every February 29th&quot;), the algorithm uses month-level advancement to avoid checking individual days unnecessarily. This optimization is particularly important for expressions that match infrequently, where naive day-by-day advancement would be prohibitively expensive.</p>\n<h3 id=\"timezone-handling-utc-normalization-and-daylight-saving-time-considerations\">Timezone Handling: UTC normalization and daylight saving time considerations</h3>\n<p>Timezone handling in distributed job schedulers requires careful consideration of where timezone conversions occur and how daylight saving time transitions are managed. The fundamental principle is to store all timestamps in UTC internally while supporting timezone-aware scheduling for user convenience.</p>\n<p>Think of timezone handling like international conference call scheduling. Participants specify their local times (&quot;let&#39;s meet at 3 PM my time&quot;), but the calendar system converts everything to a common reference (UTC) for storage and comparison. When displaying times back to users, the system converts from UTC to their local timezone. This normalization approach prevents confusion and ensures consistent behavior across different scheduler nodes.</p>\n<blockquote>\n<p><strong>Decision: Timezone Storage and Conversion Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Cron expressions can specify timezone information, but the scheduler must coordinate across multiple nodes that may be in different timezones.</li>\n<li><strong>Options Considered</strong>: Store all times in local timezone (simple but brittle), store all times in UTC (consistent but requires conversion), store times with timezone information (flexible but complex).</li>\n<li><strong>Decision</strong>: Store all absolute timestamps in UTC, but preserve timezone information in cron expressions for calculation purposes.</li>\n<li><strong>Rationale</strong>: UTC storage ensures consistency across scheduler nodes regardless of their local timezone configuration. Preserving timezone information in cron expressions allows proper handling of daylight saving time transitions and user-friendly scheduling.</li>\n<li><strong>Consequences</strong>: Requires timezone conversion at job scheduling time and display time, but provides robust behavior during timezone transitions and distributed deployment.</li>\n</ul>\n</blockquote>\n<p>The <code>CronExpression</code> structure includes a <code>Timezone</code> field that specifies the timezone for interpreting the cron schedule. When this field is nil, the expression uses UTC. When specified, the timezone affects how the cron expression is evaluated against wall-clock time in that timezone, while the calculated execution times are still converted to UTC for storage.</p>\n<p><strong>UTC Normalization Process:</strong></p>\n<ol>\n<li><p><strong>Parse Timezone</strong>: Extract timezone information from the cron expression or use system default if not specified.</p>\n</li>\n<li><p><strong>Calculate in Local Time</strong>: Perform next time calculation in the specified timezone to handle daylight saving transitions correctly.</p>\n</li>\n<li><p><strong>Convert to UTC</strong>: Transform the calculated local time to UTC for storage in job queues and execution tracking.</p>\n</li>\n<li><p><strong>Validate Conversion</strong>: Ensure the conversion is unambiguous (handles DST transition edge cases).</p>\n</li>\n<li><p><strong>Store UTC Timestamp</strong>: Persist the UTC timestamp while retaining timezone information for future calculations.</p>\n</li>\n</ol>\n<p>This normalization process ensures that jobs scheduled in different timezones execute at the correct absolute times, even when scheduler nodes are distributed across multiple geographic regions.</p>\n<p><strong>Daylight Saving Time Transition Handling:</strong></p>\n<p>Daylight saving time transitions create two types of temporal anomalies that cron schedulers must handle gracefully. During &quot;spring forward&quot; transitions, certain times don&#39;t exist (clocks jump from 1:59 AM directly to 3:00 AM). During &quot;fall back&quot; transitions, certain times occur twice (2:30 AM happens once in daylight time, then again in standard time).</p>\n<p>For jobs scheduled during non-existent times, the algorithm applies a forward adjustment strategy. If a job is scheduled for 2:30 AM during a spring forward transition, it executes at the next valid time (typically 3:30 AM after the transition). This ensures jobs don&#39;t get permanently stuck waiting for a time that will never occur.</p>\n<table>\n<thead>\n<tr>\n<th>Transition Type</th>\n<th>Problem</th>\n<th>Algorithm Behavior</th>\n<th>Example</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Spring Forward</td>\n<td>Scheduled time doesn&#39;t exist</td>\n<td>Execute at next valid time</td>\n<td>2:30 AM → 3:30 AM</td>\n</tr>\n<tr>\n<td>Fall Back</td>\n<td>Scheduled time occurs twice</td>\n<td>Execute only during first occurrence</td>\n<td>2:30 AM (DST), skip 2:30 AM (Standard)</td>\n</tr>\n<tr>\n<td>Timezone Change</td>\n<td>Historical timezone rules</td>\n<td>Use timezone rules active at execution time</td>\n<td>Job scheduled before rule change</td>\n</tr>\n</tbody></table>\n<p>For jobs scheduled during ambiguous times (times that occur twice), the scheduler executes the job only during the first occurrence. This prevents duplicate execution while maintaining predictable behavior. The algorithm achieves this by checking whether the calculated local time, when converted back to UTC, produces the expected UTC timestamp.</p>\n<p><strong>Cross-Timezone Coordination:</strong></p>\n<p>In distributed deployments where scheduler nodes run in different timezones, UTC normalization becomes critical for preventing duplicate job execution. Consider a scenario where one scheduler node runs in New York and another in Los Angeles. Without UTC normalization, both nodes might claim responsibility for executing a job scheduled for &quot;3 AM Eastern Time&quot; because their local time calculations would differ.</p>\n<p>The solution is to perform all coordination and locking operations using UTC timestamps. When a scheduler node calculates that a job should execute at &quot;3 AM Eastern Time,&quot; it converts this to a UTC timestamp (8 AM UTC during standard time, 7 AM UTC during daylight time) and uses this UTC value for all distributed coordination operations.</p>\n<blockquote>\n<p>The key insight for timezone handling is that scheduling calculations must happen in the target timezone to respect local rules like daylight saving time, but all coordination and storage must use UTC to ensure consistency across distributed nodes.</p>\n</blockquote>\n<p><strong>Common Timezone Pitfalls:</strong></p>\n<p>⚠️ <strong>Pitfall: Storing Local Timestamps</strong><br>Storing execution times in local timezone format makes the scheduler vulnerable to system timezone changes and creates inconsistencies in distributed deployments. Always convert calculated execution times to UTC before storage.</p>\n<p>⚠️ <strong>Pitfall: Ignoring DST Transitions</strong><br>Calculating next execution times without considering daylight saving transitions can result in jobs running at unexpected times or not running at all. Always perform time calculations in the target timezone before converting to UTC.</p>\n<p>⚠️ <strong>Pitfall: Assuming Fixed UTC Offsets</strong><br>Timezone offsets change throughout the year due to daylight saving time. Never hard-code UTC offsets; always use proper timezone libraries that handle historical and future timezone rule changes.</p>\n<p>⚠️ <strong>Pitfall: Invalid Timezone Names</strong><br>Accepting arbitrary timezone names without validation can cause runtime errors during time calculations. Validate timezone names against the system&#39;s timezone database during cron expression parsing.</p>\n<p>The scheduler should maintain a configurable policy for handling timezone-related errors. Options include failing the job submission, defaulting to UTC, or using the system&#39;s local timezone. The choice depends on whether the scheduler prioritizes safety (fail fast) or availability (best-effort execution).</p>\n<table>\n<thead>\n<tr>\n<th>Error Condition</th>\n<th>Conservative Behavior</th>\n<th>Permissive Behavior</th>\n<th>Recommended</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Invalid timezone name</td>\n<td>Reject job submission</td>\n<td>Default to UTC</td>\n<td>Conservative</td>\n</tr>\n<tr>\n<td>Ambiguous DST time</td>\n<td>Reject job submission</td>\n<td>Use first occurrence</td>\n<td>Permissive</td>\n</tr>\n<tr>\n<td>Non-existent DST time</td>\n<td>Reject job submission</td>\n<td>Adjust to next valid time</td>\n<td>Permissive</td>\n</tr>\n<tr>\n<td>Timezone rule changes</td>\n<td>Require job resubmission</td>\n<td>Apply new rules automatically</td>\n<td>Depends on use case</td>\n</tr>\n</tbody></table>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The cron expression parser implementation requires careful attention to timezone handling, calendar arithmetic, and performance optimization. Go&#39;s time package provides excellent support for timezone-aware calculations, making it the ideal choice for implementing robust cron functionality.</p>\n<p><strong>Technology Recommendations:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Cron Parsing</td>\n<td>Custom parser with string splitting</td>\n<td>Third-party library like robfig/cron</td>\n</tr>\n<tr>\n<td>Time Calculations</td>\n<td>Go&#39;s time package with manual arithmetic</td>\n<td>Specialized calendar library</td>\n</tr>\n<tr>\n<td>Timezone Data</td>\n<td>Go&#39;s built-in time/tzdata</td>\n<td>External timezone database</td>\n</tr>\n<tr>\n<td>Performance</td>\n<td>Naive incremental time advancement</td>\n<td>Optimized mathematical shortcuts</td>\n</tr>\n</tbody></table>\n<p><strong>Recommended File Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>internal/cron/\n  parser.go              ← CronExpression parsing logic\n  parser_test.go         ← Comprehensive parsing tests\n  calculator.go          ← Next time calculation algorithms\n  calculator_test.go     ← Time calculation test cases\n  timezone.go            ← Timezone handling utilities\n  timezone_test.go       ← DST transition test cases\n  expression.go          ← CronExpression data structures\n  errors.go              ← Cron-specific error types</code></pre></div>\n\n<p><strong>Core Data Structures:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// CronExpression represents a parsed cron expression with timezone support.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Fields contain expanded integer lists for efficient time matching.</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> CronExpression</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Original contains the unparsed cron expression string for debugging</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Original </span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Time field constraints as expanded integer lists</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Seconds      []</span><span style=\"color:#F97583\">int</span><span style=\"color:#6A737D\">  // 0-59, nil for 5-field expressions</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Minutes      []</span><span style=\"color:#F97583\">int</span><span style=\"color:#6A737D\">  // 0-59</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Hours        []</span><span style=\"color:#F97583\">int</span><span style=\"color:#6A737D\">  // 0-23</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    DaysOfMonth  []</span><span style=\"color:#F97583\">int</span><span style=\"color:#6A737D\">  // 1-31</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Months       []</span><span style=\"color:#F97583\">int</span><span style=\"color:#6A737D\">  // 1-12</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    DaysOfWeek   []</span><span style=\"color:#F97583\">int</span><span style=\"color:#6A737D\">  // 0-7 (both 0 and 7 represent Sunday)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Timezone specifies the timezone for schedule evaluation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // nil means UTC</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Timezone </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Location</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ParseResult contains parsing outcome with detailed error information</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> ParseResult</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Expression </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">CronExpression</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Errors     []</span><span style=\"color:#B392F0\">ParseError</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Warnings   []</span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ParseError provides specific information about parsing failures</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> ParseError</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Field    </span><span style=\"color:#F97583\">string</span><span style=\"color:#6A737D\">  // Which field caused the error</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Value    </span><span style=\"color:#F97583\">string</span><span style=\"color:#6A737D\">  // The problematic value</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Position </span><span style=\"color:#F97583\">int</span><span style=\"color:#6A737D\">     // Character position in original string</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Message  </span><span style=\"color:#F97583\">string</span><span style=\"color:#6A737D\">  // Human-readable error description</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Cron Expression Parser Implementation:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// ParseCronExpression parses a cron expression string into structured format.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Supports both 5-field (minute hour day month weekday) and 6-field </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// (second minute hour day month weekday) formats with automatic detection.</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> ParseCronExpression</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">expr</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">CronExpression</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Trim whitespace and validate non-empty input</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Check for shorthand expressions (@yearly, @monthly, @daily, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // and convert to standard field format</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Split expression on whitespace to extract individual fields</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Determine format (5-field vs 6-field) based on field count</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Parse each field according to its position and constraints</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Use parseField() helper for each field type</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Validate semantic constraints (day-of-month vs month compatibility)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Extract timezone information if present (typically as suffix)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 8: Create and populate CronExpression struct with parsed values</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">nil</span><span style=\"color:#6A737D\"> // Replace with actual implementation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// parseField parses a single cron field and returns the expanded integer list.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Handles wildcards (*), ranges (1-5), lists (1,3,5), and steps (*/2, 1-10/3).</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> parseField</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">field</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">min</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">max</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\">) ([]</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Handle wildcard (*) - return all values in range</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Split on commas to handle lists (1,3,5,7-10)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: For each list item, check for step syntax (value/step)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Parse ranges (start-end) and individual values</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Expand step values within ranges</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Validate all values are within min/max bounds</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Sort and deduplicate the final value list</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">nil</span><span style=\"color:#6A737D\"> // Replace with actual implementation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Next Time Calculation Implementation:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// NextExecutionTime calculates the next time this cron expression should execute</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// after the given timestamp. Returns time in UTC regardless of expression timezone.</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">CronExpression</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">NextExecutionTime</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">after</span><span style=\"color:#B392F0\"> time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Convert 'after' timestamp to expression timezone for calculation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Truncate to appropriate precision (second or minute boundary)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Check if current time already matches all constraints</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Implement main calculation loop with increment strategy:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //   - Determine which constraint is failing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //   - Choose appropriate time increment (second, minute, hour, day, month)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //   - Advance time by chosen increment</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //   - Re-check all constraints</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Handle day-of-week and day-of-month interaction (OR logic)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Implement infinite loop protection (max iterations limit)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Convert final result back to UTC before returning</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#B392F0\"> time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#E1E4E8\">{}, </span><span style=\"color:#79B8FF\">nil</span><span style=\"color:#6A737D\"> // Replace with actual implementation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// matchesConstraints checks if the given timestamp satisfies all cron field constraints.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Time should be provided in the expression's timezone for accurate evaluation.</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">CronExpression</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">matchesConstraints</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">t</span><span style=\"color:#B392F0\"> time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Extract time components (second, minute, hour, day, month, weekday)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Check each field constraint using contains() helper</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Handle special day-of-week/day-of-month logic:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //   - If both are specified (not wildcards), use OR logic</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    //   - If only one is specified, use normal AND logic</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Return true only if all applicable constraints are satisfied</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#6A737D\"> // Replace with actual implementation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// contains checks if a value exists in an integer slice (field constraint list)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> contains</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">slice</span><span style=\"color:#E1E4E8\"> []</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">value</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> _, v </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> range</span><span style=\"color:#E1E4E8\"> slice {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> v </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> value {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> true</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> false</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Timezone Handling Utilities:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// parseTimezone extracts timezone information from a cron expression.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Supports timezone suffixes like \"0 9 * * * America/New_York\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> parseTimezone</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">expr</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Location</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Check for timezone suffix patterns (common timezone name formats)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Validate timezone name against time.LoadLocation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Return parsed timezone and expression with timezone removed</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> time.UTC, expr, </span><span style=\"color:#79B8FF\">nil</span><span style=\"color:#6A737D\"> // Replace with actual implementation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// convertToTimezone safely converts a UTC timestamp to the specified timezone,</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// handling DST transitions and invalid times appropriately.</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> convertToTimezone</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">utc</span><span style=\"color:#B392F0\"> time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">tz</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Location</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> tz </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> utc</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> utc.</span><span style=\"color:#B392F0\">In</span><span style=\"color:#E1E4E8\">(tz)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// convertToUTC converts a timezone-aware timestamp to UTC, handling</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ambiguous times during DST transitions consistently.</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> convertToUTC</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">local</span><span style=\"color:#B392F0\"> time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> local.</span><span style=\"color:#B392F0\">UTC</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Milestone Checkpoint:</strong></p>\n<p>After implementing the cron expression parser, you should be able to:</p>\n<ol>\n<li><p><strong>Parse Valid Expressions</strong>: <code>ParseCronExpression(&quot;0 9 * * 1&quot;)</code> returns a valid CronExpression with Minutes=[0], Hours=[9], DaysOfWeek=[1].</p>\n</li>\n<li><p><strong>Handle Extended Syntax</strong>: <code>ParseCronExpression(&quot;30 0 9 * * 1-5&quot;)</code> correctly parses the 6-field format with seconds.</p>\n</li>\n<li><p><strong>Calculate Next Times</strong>: For expression &quot;0 9 * * *&quot; at timestamp 2024-01-15 10:00:00 UTC, NextExecutionTime returns 2024-01-16 09:00:00 UTC.</p>\n</li>\n<li><p><strong>Manage Timezones</strong>: Expression &quot;0 9 * * * America/New_York&quot; correctly adjusts for EST/EDT transitions.</p>\n</li>\n</ol>\n<p><strong>Test Commands:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> test</span><span style=\"color:#9ECBFF\"> ./internal/cron/...</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> test</span><span style=\"color:#9ECBFF\"> ./internal/cron/...</span><span style=\"color:#79B8FF\"> -run</span><span style=\"color:#9ECBFF\"> TestDSTTransitions</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> test</span><span style=\"color:#9ECBFF\"> ./internal/cron/...</span><span style=\"color:#79B8FF\"> -run</span><span style=\"color:#9ECBFF\"> TestComplexExpressions</span></span></code></pre></div>\n\n<p><strong>Expected Behavior:</strong></p>\n<ul>\n<li>All parsing tests pass, including edge cases like February 29th and invalid timezone names</li>\n<li>Next time calculations handle month boundaries and leap years correctly  </li>\n<li>DST transition tests verify proper handling of spring forward and fall back scenarios</li>\n<li>Performance benchmarks show sub-millisecond parsing times for typical expressions</li>\n</ul>\n<p><strong>Common Implementation Issues:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Jobs run twice during DST</td>\n<td>Ambiguous time handling</td>\n<td>Check logs during DST transition</td>\n<td>Use first occurrence only</td>\n</tr>\n<tr>\n<td>Jobs missing on 31st</td>\n<td>Month boundary logic error</td>\n<td>Test with expressions like &quot;0 0 31 * *&quot;</td>\n<td>Skip months without target day</td>\n</tr>\n<tr>\n<td>Parser panics on invalid input</td>\n<td>Missing input validation</td>\n<td>Test with malformed expressions</td>\n<td>Add comprehensive input validation</td>\n</tr>\n<tr>\n<td>Wrong timezone conversions</td>\n<td>Hard-coded UTC offsets</td>\n<td>Test around DST transitions</td>\n<td>Use time.Location for all conversions</td>\n</tr>\n</tbody></table>\n<p><img src=\"/api/project/job-scheduler/architecture-doc/asset?path=diagrams%2Fcron-parsing-flow.svg\" alt=\"Cron Expression Parsing\"></p>\n<h2 id=\"priority-job-queue\">Priority Job Queue</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Milestone 2 - Job Queue with Priorities. This section implements a distributed priority queue system that orders jobs by priority levels, supports delayed execution for scheduled jobs, and prevents duplicate submissions through idempotency keys.</p>\n</blockquote>\n<h3 id=\"mental-model-priority-queue-as-a-hospital-triage-system\">Mental Model: Priority Queue as a Hospital Triage System</h3>\n<p>Think of the priority job queue as a hospital emergency room triage system. When patients arrive, they don&#39;t get treated in first-come-first-served order. Instead, a triage nurse evaluates each patient and assigns a priority level based on urgency - heart attack patients go straight to the front, while someone with a minor cut waits longer. The triage system also handles scheduled appointments (delayed execution) and prevents the same patient from being registered multiple times if they&#39;re brought in by both an ambulance and a family member (deduplication).</p>\n<p>The priority job queue works similarly. Jobs arrive with different priority levels, and the system ensures that high-priority jobs get executed before low-priority ones, even if they arrived later. Some jobs are &quot;scheduled appointments&quot; that shouldn&#39;t be processed until a specific time, like a daily backup that runs at 3 AM. The deduplication mechanism prevents the same job from being queued multiple times if a client retries a submission or if multiple systems try to schedule the same recurring task.</p>\n<p>This mental model helps understand why we need more than a simple FIFO queue. Real-world job scheduling requires sophisticated ordering, timing controls, and duplicate prevention - just like a hospital needs more than a simple waiting line to handle the complexity of medical care prioritization.</p>\n<h3 id=\"priority-mechanism-numeric-priority-levels-and-heap-based-ordering\">Priority Mechanism: Numeric Priority Levels and Heap-Based Ordering</h3>\n<p>The priority mechanism forms the core ordering logic of our job queue. Jobs are assigned numeric priority values where lower numbers indicate higher priority - similar to airline boarding groups where Group 1 boards before Group 5. This convention aligns with common computer science practice where priority 0 represents the highest urgency.</p>\n<p><img src=\"/api/project/job-scheduler/architecture-doc/asset?path=diagrams%2Fjob-priority-queue.svg\" alt=\"Priority Queue Structure\"></p>\n<p>The priority system uses five standard levels, though the implementation supports any integer value:</p>\n<table>\n<thead>\n<tr>\n<th>Priority Level</th>\n<th>Numeric Value</th>\n<th>Description</th>\n<th>Example Use Cases</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Critical</td>\n<td>0</td>\n<td>System-critical operations that must execute immediately</td>\n<td>Security patches, critical alerts, system recovery</td>\n</tr>\n<tr>\n<td>High</td>\n<td>100</td>\n<td>Important business operations with tight deadlines</td>\n<td>Payment processing, customer notifications, data backups</td>\n</tr>\n<tr>\n<td>Normal</td>\n<td>500</td>\n<td>Standard business operations with moderate timing requirements</td>\n<td>Report generation, data synchronization, maintenance tasks</td>\n</tr>\n<tr>\n<td>Low</td>\n<td>1000</td>\n<td>Background operations that can be delayed</td>\n<td>Log cleanup, cache warming, analytics processing</td>\n</tr>\n<tr>\n<td>Bulk</td>\n<td>2000</td>\n<td>Large batch operations that should yield to other work</td>\n<td>Data imports, bulk exports, archive operations</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Numeric Priority with Lower-is-Higher Convention</strong></p>\n<ul>\n<li><strong>Context</strong>: Need a priority system that supports both predefined levels and custom priorities for specialized use cases</li>\n<li><strong>Options Considered</strong>: <ul>\n<li>Enum-based priorities (CRITICAL, HIGH, NORMAL, LOW)</li>\n<li>Numeric priorities with higher-is-higher (1-10 scale)</li>\n<li>Numeric priorities with lower-is-higher (0-N scale)</li>\n</ul>\n</li>\n<li><strong>Decision</strong>: Numeric priorities with lower-is-higher convention</li>\n<li><strong>Rationale</strong>: Numeric values allow infinite granularity for custom priorities between standard levels. Lower-is-higher convention matches Unix process priorities and min-heap data structures, reducing cognitive overhead for systems programmers.</li>\n<li><strong>Consequences</strong>: Enables priority 150 jobs to run between High (100) and Normal (500). Requires documentation to clarify that 0 is highest priority, not lowest.</li>\n</ul>\n</blockquote>\n<p>The queue implementation uses a min-heap data structure to maintain priority ordering efficiently. When jobs are inserted, the heap automatically positions them based on their priority value, ensuring that <code>Pop()</code> operations always return the highest-priority job in O(log n) time.</p>\n<p><strong>Priority Comparison Algorithm:</strong></p>\n<p>The system compares jobs using a multi-level comparison that considers both priority and timing:</p>\n<ol>\n<li><strong>Primary Comparison</strong>: Compare numeric priority values (lower wins)</li>\n<li><strong>Secondary Comparison</strong>: If priorities are equal, compare scheduled execution times (earlier wins)</li>\n<li><strong>Tertiary Comparison</strong>: If both priority and timing are equal, compare creation timestamps (older wins)</li>\n<li><strong>Final Tiebreaker</strong>: If all other fields are equal, compare job IDs lexicographically for deterministic ordering</li>\n</ol>\n<p>This comparison ensures that within each priority level, jobs execute in temporal order, providing predictable behavior for jobs with identical priorities.</p>\n<p><strong>Priority Inheritance and Boosting:</strong></p>\n<p>The system supports priority boosting for jobs that have been waiting beyond acceptable thresholds. This prevents priority inversion where high-priority work depends on completion of lower-priority tasks:</p>\n<table>\n<thead>\n<tr>\n<th>Boost Condition</th>\n<th>Wait Time Threshold</th>\n<th>Priority Adjustment</th>\n<th>Rationale</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Age-based boost</td>\n<td>30 minutes</td>\n<td>Increase priority by 50 points</td>\n<td>Prevents starvation of normal-priority jobs</td>\n</tr>\n<tr>\n<td>Dependency boost</td>\n<td>Immediate</td>\n<td>Inherit dependent job&#39;s priority</td>\n<td>Ensures dependency chains don&#39;t create bottlenecks</td>\n</tr>\n<tr>\n<td>Resource boost</td>\n<td>15 minutes</td>\n<td>Increase priority by 25 points</td>\n<td>Prioritizes jobs holding scarce resources</td>\n</tr>\n</tbody></table>\n<h3 id=\"delayed-execution-visibility-timeout-pattern-for-scheduled-jobs\">Delayed Execution: Visibility Timeout Pattern for Scheduled Jobs</h3>\n<p>Delayed execution enables jobs to remain invisible in the queue until their designated execution time arrives. This mechanism supports both one-time scheduled jobs (&quot;run this backup at 3 AM tomorrow&quot;) and recurring jobs managed by the cron expression parser (&quot;run this report every Monday at 9 AM&quot;).</p>\n<p>The implementation uses the <strong>visibility timeout pattern</strong> borrowed from message queue systems like Amazon SQS. Jobs exist in the queue data structure but remain invisible to workers until their <code>ScheduledAt</code> timestamp passes. This approach provides several advantages over alternative designs:</p>\n<blockquote>\n<p><strong>Decision: Visibility Timeout Pattern vs Separate Timer Service</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to store jobs that shouldn&#39;t execute until a future time without requiring separate infrastructure</li>\n<li><strong>Options Considered</strong>: <ul>\n<li>External timer service that inserts jobs at scheduled time</li>\n<li>Separate &quot;delayed jobs&quot; storage with timer-based promotion</li>\n<li>Visibility timeout within single queue structure</li>\n</ul>\n</li>\n<li><strong>Decision</strong>: Visibility timeout within single queue structure</li>\n<li><strong>Rationale</strong>: Single queue eliminates coordination complexity between timer service and queue. Visibility timeout pattern is well-understood from message queues. Redis native support reduces implementation complexity.</li>\n<li><strong>Consequences</strong>: Requires queue scanning to find eligible jobs, but Redis sorted sets make this efficient. Eliminates race conditions between timer service and queue operations.</li>\n</ul>\n</blockquote>\n<p><strong>Delayed Job States and Transitions:</strong></p>\n<p>Jobs progress through distinct visibility states as they approach their execution time:</p>\n<table>\n<thead>\n<tr>\n<th>State</th>\n<th>Description</th>\n<th>Worker Visibility</th>\n<th>Queue Location</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Scheduled</td>\n<td>Job exists but execution time is future</td>\n<td>Invisible</td>\n<td>Delayed jobs sorted set</td>\n</tr>\n<tr>\n<td>Eligible</td>\n<td>Execution time has passed</td>\n<td>Visible</td>\n<td>Priority queue heap</td>\n</tr>\n<tr>\n<td>Claimed</td>\n<td>Worker has claimed job for processing</td>\n<td>Invisible to other workers</td>\n<td>Worker&#39;s active jobs set</td>\n</tr>\n<tr>\n<td>Executing</td>\n<td>Worker is actively processing job</td>\n<td>Invisible</td>\n<td>Worker&#39;s executing jobs set</td>\n</tr>\n</tbody></table>\n<p><strong>Visibility Promotion Algorithm:</strong></p>\n<p>The queue periodically scans for delayed jobs whose execution time has arrived and promotes them to visible status:</p>\n<ol>\n<li><strong>Scan Trigger</strong>: Every 30 seconds, or when queue becomes empty, or on explicit promotion request</li>\n<li><strong>Time Range Query</strong>: Query delayed jobs sorted set for entries with <code>ScheduledAt &lt;= current_time</code></li>\n<li><strong>Batch Promotion</strong>: Move up to 100 eligible jobs from delayed set to priority queue in single transaction</li>\n<li><strong>Priority Insertion</strong>: Insert each promoted job into priority queue heap based on its priority value</li>\n<li><strong>Atomic Cleanup</strong>: Remove promoted jobs from delayed set using Redis pipeline for atomicity</li>\n</ol>\n<p>The batch promotion strategy balances responsiveness with efficiency. Promoting too few jobs creates unnecessary scanning overhead, while promoting too many jobs at once can cause latency spikes.</p>\n<p><strong>Scheduling Precision and Drift:</strong></p>\n<p>The visibility timeout pattern provides <strong>eventual consistency</strong> for job scheduling rather than real-time precision. Jobs become eligible within the scan interval (30 seconds by default) of their scheduled time:</p>\n<table>\n<thead>\n<tr>\n<th>Precision Requirement</th>\n<th>Scan Interval</th>\n<th>Use Case Suitability</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>±30 seconds</td>\n<td>30 seconds (default)</td>\n<td>Most business operations, reports, backups</td>\n</tr>\n<tr>\n<td>±5 seconds</td>\n<td>5 seconds</td>\n<td>Time-sensitive notifications, monitoring alerts</td>\n</tr>\n<tr>\n<td>±1 second</td>\n<td>1 second</td>\n<td>Real-time processing, financial transactions</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p>The system prioritizes operational simplicity over microsecond precision. For use cases requiring sub-second scheduling accuracy, consider dedicated real-time job scheduling systems rather than distributed queue-based approaches.</p>\n</blockquote>\n<h3 id=\"deduplication-strategy-idempotency-keys-and-hash-based-detection\">Deduplication Strategy: Idempotency Keys and Hash-Based Detection</h3>\n<p>Deduplication prevents the same logical job from being queued multiple times, which commonly occurs when clients retry failed submissions, when multiple systems attempt to schedule the same recurring job, or when network issues cause duplicate messages. The system uses <strong>idempotency keys</strong> provided by job submitters combined with hash-based detection for automatic duplicate prevention.</p>\n<p><strong>Idempotency Key Design:</strong></p>\n<p>Each job submission includes an <code>IdempotencyKey</code> field that uniquely identifies the logical operation. When clients submit jobs with identical idempotency keys, only the first submission creates a queue entry - subsequent submissions return the original job information without creating duplicates.</p>\n<table>\n<thead>\n<tr>\n<th>Idempotency Scope</th>\n<th>Key Format</th>\n<th>Example</th>\n<th>Deduplication Window</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Global unique</td>\n<td>UUID v4</td>\n<td><code>550e8400-e29b-41d4-a716-446655440000</code></td>\n<td>Permanent</td>\n</tr>\n<tr>\n<td>Operation-based</td>\n<td><code>operation:params:timestamp</code></td>\n<td><code>backup:user-db:20240315</code></td>\n<td>24 hours</td>\n</tr>\n<tr>\n<td>Client-scoped</td>\n<td><code>client-id:sequence</code></td>\n<td><code>payment-service:12345</code></td>\n<td>1 hour</td>\n</tr>\n<tr>\n<td>Content-based</td>\n<td>SHA-256 of normalized payload</td>\n<td><code>sha256:a1b2c3...</code></td>\n<td>1 hour</td>\n</tr>\n</tbody></table>\n<p>The deduplication window determines how long the system remembers previous submissions. Permanent deduplication works for globally unique operations, while time-bounded deduplication suits operations that legitimately repeat after certain intervals.</p>\n<p><strong>Hash-Based Automatic Detection:</strong></p>\n<p>Beyond explicit idempotency keys, the system automatically detects duplicates by computing content hashes of job payloads. This catches duplicates even when clients don&#39;t provide idempotency keys or use different keys for identical operations.</p>\n<p>The content hash includes normalized versions of key job fields:</p>\n<ol>\n<li><strong>Normalized Job Name</strong>: Converted to lowercase, whitespace trimmed</li>\n<li><strong>Sorted Payload Keys</strong>: Payload map keys sorted alphabetically for consistent hashing</li>\n<li><strong>Canonical Cron Expression</strong>: Cron expressions parsed and reformatted in standard form</li>\n<li><strong>Priority Level</strong>: Included to distinguish identical payloads with different priorities</li>\n</ol>\n<p><strong>Deduplication Storage and Cleanup:</strong></p>\n<p>The system maintains deduplication state in Redis using multiple data structures for efficient lookups and automatic cleanup:</p>\n<table>\n<thead>\n<tr>\n<th>Storage Structure</th>\n<th>Purpose</th>\n<th>Key Pattern</th>\n<th>Expiration</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Idempotency map</td>\n<td>Explicit key tracking</td>\n<td><code>dedup:key:{idempotency-key}</code></td>\n<td>Configurable (1-24 hours)</td>\n</tr>\n<tr>\n<td>Content hash set</td>\n<td>Automatic duplicate detection</td>\n<td><code>dedup:hash:{content-hash}</code></td>\n<td>1 hour default</td>\n</tr>\n<tr>\n<td>Job reference map</td>\n<td>Links dedup entries to job IDs</td>\n<td><code>dedup:job:{job-id}</code></td>\n<td>Same as job TTL</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Redis-Based Deduplication vs In-Memory Cache</strong></p>\n<ul>\n<li><strong>Context</strong>: Need persistent deduplication that survives service restarts and works across multiple queue service instances</li>\n<li><strong>Options Considered</strong>: <ul>\n<li>In-memory LRU cache with configurable size</li>\n<li>Redis with TTL-based automatic cleanup</li>\n<li>Database table with periodic cleanup job</li>\n</ul>\n</li>\n<li><strong>Decision</strong>: Redis with TTL-based automatic cleanup  </li>\n<li><strong>Rationale</strong>: Redis TTL provides automatic cleanup without manual intervention. Shared state across service instances prevents duplicates even during deployments. Redis performance characteristics suit high-frequency deduplication checks.</li>\n<li><strong>Consequences</strong>: Requires Redis infrastructure dependency. Network latency for every deduplication check. Memory usage grows with deduplication window size.</li>\n</ul>\n</blockquote>\n<p><strong>Deduplication Algorithm:</strong></p>\n<p>The complete deduplication check follows this sequence:</p>\n<ol>\n<li><strong>Extract Idempotency Key</strong>: Check if job submission includes explicit <code>IdempotencyKey</code></li>\n<li><strong>Check Explicit Deduplication</strong>: Query Redis for existing entry with same idempotency key</li>\n<li><strong>Early Return</strong>: If idempotency key matches, return existing job ID without creating duplicate</li>\n<li><strong>Compute Content Hash</strong>: Calculate normalized hash of job name, payload, cron expression, and priority</li>\n<li><strong>Check Content Deduplication</strong>: Query Redis for existing entry with same content hash</li>\n<li><strong>Hash Match Handling</strong>: If content hash matches, compare full job details to confirm true duplicate vs hash collision</li>\n<li><strong>Create New Entry</strong>: If no duplicates found, create new job and store both idempotency key and content hash mappings</li>\n<li><strong>Atomic Transaction</strong>: Use Redis MULTI/EXEC to ensure deduplication state and job creation happen atomically</li>\n</ol>\n<p><strong>Edge Cases and Collision Handling:</strong></p>\n<p>The deduplication system handles several edge cases that can cause incorrect behavior:</p>\n<p>⚠️ <strong>Pitfall: Hash Collisions Causing False Duplicates</strong>\nHash collisions can cause the system to incorrectly identify distinct jobs as duplicates. While SHA-256 collisions are extremely rare, they can occur with crafted inputs or in high-volume systems processing billions of jobs.</p>\n<p><strong>Detection</strong>: Jobs with different payloads are rejected as duplicates during submission.</p>\n<p><strong>Fix</strong>: When content hashes match, perform full job comparison including all payload fields. Only treat as duplicate if complete job specifications match exactly. Log hash collisions for monitoring.</p>\n<p>⚠️ <strong>Pitfall: Race Conditions During Concurrent Submission</strong>\nMultiple clients submitting identical jobs simultaneously can create duplicates if deduplication checks happen before job creation completes.</p>\n<p><strong>Detection</strong>: Multiple jobs exist with identical idempotency keys or content hashes.</p>\n<p><strong>Fix</strong>: Use Redis transactions (MULTI/EXEC) to make deduplication check and job creation atomic. Implement exponential backoff retry for clients when deduplication conflicts occur.</p>\n<p>⚠️ <strong>Pitfall: Stale Deduplication Entries After Job Deletion</strong>\nWhen jobs are deleted or expire, their deduplication entries may remain, preventing legitimate resubmission of the same operation.</p>\n<p><strong>Detection</strong>: Job submissions rejected for non-existent jobs referenced in deduplication entries.</p>\n<p><strong>Fix</strong>: Link deduplication entries to job TTL using Redis key expiration. Clean up orphaned deduplication entries during periodic maintenance.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>This subsection provides the Go-specific implementation details for building the priority job queue with Redis backing store and atomic operations.</p>\n<p><strong>Technology Recommendations:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Queue Storage</td>\n<td>Redis with Go-Redis client</td>\n<td>Redis Cluster with sentinel failover</td>\n</tr>\n<tr>\n<td>Priority Queue</td>\n<td>Go container/heap interface</td>\n<td>Custom heap with batch operations</td>\n</tr>\n<tr>\n<td>Serialization</td>\n<td>JSON with encoding/json</td>\n<td>MessagePack with vmihailenco/msgpack</td>\n</tr>\n<tr>\n<td>Time Handling</td>\n<td>time.Time with UTC normalization</td>\n<td>Dedicated time library like jinzhu/now</td>\n</tr>\n<tr>\n<td>Deduplication</td>\n<td>SHA-256 with crypto/sha256</td>\n<td>xxHash for performance-critical paths</td>\n</tr>\n<tr>\n<td>Atomic Operations</td>\n<td>Redis transactions (MULTI/EXEC)</td>\n<td>Redis Lua scripts for complex operations</td>\n</tr>\n</tbody></table>\n<p><strong>Recommended File Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>internal/queue/\n  queue.go                    ← PriorityQueue interface and Redis implementation\n  queue_test.go              ← Unit tests for queue operations\n  job.go                     ← Job struct and methods (NewJob, validation)\n  job_test.go                ← Job creation and state transition tests\n  deduplication.go           ← Idempotency and hash-based duplicate detection\n  deduplication_test.go      ← Deduplication logic tests\n  heap.go                    ← Go heap.Interface implementation for priorities\n  redis_client.go            ← Redis connection management and health checks\n  redis_scripts.go           ← Lua scripts for atomic Redis operations\n  types.go                   ← JobState enum, configuration structs\ninternal/storage/\n  interface.go               ← Storage interface for queue persistence\n  redis_storage.go           ← Redis-specific storage implementation\ncmd/queue-service/\n  main.go                    ← Queue service entry point\n  config.go                  ← Configuration loading and validation</code></pre></div>\n\n<p><strong>Infrastructure Starter Code:</strong></p>\n<p><strong>Redis Client Setup (<code>internal/queue/redis_client.go</code>):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> queue</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">context</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">fmt</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">github.com/go-redis/redis/v8</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// RedisConfig holds Redis connection configuration</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> RedisConfig</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Address         </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">        `json:\"address\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Password        </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">        `json:\"password\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Database        </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">           `json:\"database\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    MaxRetries      </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">           `json:\"max_retries\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PoolSize        </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">           `json:\"pool_size\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ConnectTimeout  </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#9ECBFF\"> `json:\"connect_timeout\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ReadTimeout     </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#9ECBFF\"> `json:\"read_timeout\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    WriteTimeout    </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#9ECBFF\"> `json:\"write_timeout\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// NewRedisClient creates configured Redis client with health checking</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewRedisClient</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">config</span><span style=\"color:#B392F0\"> RedisConfig</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">redis</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Client</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    client </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> redis.</span><span style=\"color:#B392F0\">NewClient</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#B392F0\">redis</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Options</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Addr:         config.Address,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Password:     config.Password,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        DB:           config.Database,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        MaxRetries:   config.MaxRetries,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        PoolSize:     config.PoolSize,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        DialTimeout:  config.ConnectTimeout,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ReadTimeout:  config.ReadTimeout,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        WriteTimeout: config.WriteTimeout,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    })</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Test connection</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ctx, cancel </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> context.</span><span style=\"color:#B392F0\">WithTimeout</span><span style=\"color:#E1E4E8\">(context.</span><span style=\"color:#B392F0\">Background</span><span style=\"color:#E1E4E8\">(), </span><span style=\"color:#79B8FF\">5</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">time.Second)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#B392F0\"> cancel</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> client.</span><span style=\"color:#B392F0\">Ping</span><span style=\"color:#E1E4E8\">(ctx).</span><span style=\"color:#B392F0\">Err</span><span style=\"color:#E1E4E8\">(); err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\">, fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"failed to connect to Redis: </span><span style=\"color:#79B8FF\">%w</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> client, </span><span style=\"color:#79B8FF\">nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// HealthCheck verifies Redis connectivity</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">RedisClient</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">HealthCheck</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> c.client.</span><span style=\"color:#B392F0\">Ping</span><span style=\"color:#E1E4E8\">(ctx).</span><span style=\"color:#B392F0\">Err</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Close gracefully shuts down Redis connection</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">RedisClient</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Close</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> c.client.</span><span style=\"color:#B392F0\">Close</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Job State Management (<code>internal/queue/types.go</code>):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> queue</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">fmt</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// JobState represents current execution state of a job</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> JobState</span><span style=\"color:#F97583\"> string</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">const</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    PENDING</span><span style=\"color:#B392F0\">   JobState</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"pending\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    CLAIMED</span><span style=\"color:#B392F0\">   JobState</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"claimed\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    EXECUTING</span><span style=\"color:#B392F0\"> JobState</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"executing\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    COMPLETED</span><span style=\"color:#B392F0\"> JobState</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"completed\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    FAILED</span><span style=\"color:#B392F0\">    JobState</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"failed\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// String implements Stringer interface for JobState</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">js </span><span style=\"color:#B392F0\">JobState</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">String</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">(js)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// IsValid checks if job state is one of defined values</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">js </span><span style=\"color:#B392F0\">JobState</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">IsValid</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    switch</span><span style=\"color:#E1E4E8\"> js {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    case</span><span style=\"color:#E1E4E8\"> PENDING, CLAIMED, EXECUTING, COMPLETED, FAILED:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> true</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    default</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> false</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// CanTransitionTo checks if state transition is valid</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">js </span><span style=\"color:#B392F0\">JobState</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">CanTransitionTo</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">next</span><span style=\"color:#B392F0\"> JobState</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    transitions </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#B392F0\">JobState</span><span style=\"color:#E1E4E8\">][]</span><span style=\"color:#B392F0\">JobState</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        PENDING:   {CLAIMED, FAILED},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        CLAIMED:   {EXECUTING, PENDING, FAILED},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        EXECUTING: {COMPLETED, FAILED, PENDING},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        COMPLETED: {},  </span><span style=\"color:#6A737D\">// Terminal state</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        FAILED:    {},  </span><span style=\"color:#6A737D\">// Terminal state</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    allowed, exists </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> transitions[js]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> !</span><span style=\"color:#E1E4E8\">exists {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> false</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> _, allowedNext </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> range</span><span style=\"color:#E1E4E8\"> allowed {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> allowedNext </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> next {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> true</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> false</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// QueueConfig holds priority queue configuration</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> QueueConfig</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ScanInterval        </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#9ECBFF\"> `json:\"scan_interval\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    BatchPromotionSize  </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">           `json:\"batch_promotion_size\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    DefaultJobTTL       </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#9ECBFF\"> `json:\"default_job_ttl\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    DeduplicationWindow </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#9ECBFF\"> `json:\"deduplication_window\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    MaxRetries          </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">           `json:\"max_retries\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PriorityBoostAge    </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#9ECBFF\"> `json:\"priority_boost_age\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PriorityBoostAmount </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">           `json:\"priority_boost_amount\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// DefaultQueueConfig returns sensible defaults</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> DefaultQueueConfig</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#B392F0\">QueueConfig</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#B392F0\"> QueueConfig</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ScanInterval:        </span><span style=\"color:#79B8FF\">30</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\"> time.Second,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        BatchPromotionSize:  </span><span style=\"color:#79B8FF\">100</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        DefaultJobTTL:       </span><span style=\"color:#79B8FF\">24</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\"> time.Hour,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        DeduplicationWindow: </span><span style=\"color:#79B8FF\">1</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\"> time.Hour,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        MaxRetries:          </span><span style=\"color:#79B8FF\">3</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        PriorityBoostAge:    </span><span style=\"color:#79B8FF\">30</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\"> time.Minute,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        PriorityBoostAmount: </span><span style=\"color:#79B8FF\">50</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Core Logic Skeleton Code:</strong></p>\n<p><strong>Priority Queue Interface (<code>internal/queue/queue.go</code>):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> queue</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">context</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// PriorityQueue defines interface for priority-based job queue</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> PriorityQueue</span><span style=\"color:#F97583\"> interface</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // SubmitJob adds job to queue with deduplication check</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    SubmitJob</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">job</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // ClaimJob atomically assigns highest priority job to worker</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    ClaimJob</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">workerID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // CompleteJob marks job as successfully completed</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    CompleteJob</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">jobID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">result</span><span style=\"color:#F97583\"> map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // FailJob marks job as failed and handles retry logic</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    FailJob</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">jobID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">reason</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // PromoteDelayedJobs moves eligible delayed jobs to active queue</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    PromoteDelayedJobs</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // GetQueueStats returns current queue statistics</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    GetQueueStats</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#B392F0\">QueueStats</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// SubmitJob adds new job to queue with comprehensive deduplication</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">pq </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">RedisPriorityQueue</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">SubmitJob</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">job</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Validate job fields - check required fields, validate cron expression, verify priority range</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Check idempotency key deduplication - query Redis for existing job with same IdempotencyKey</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: If idempotency match found, return existing job without creating duplicate</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Compute content hash for automatic deduplication - normalize payload, hash job content</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Check content hash deduplication - query Redis for jobs with same content hash</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: If content hash matches, compare full job details to handle hash collisions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Create new job with generated ID, timestamps, and initial PENDING state</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 8: Store job in appropriate queue - delayed queue if ScheduledAt is future, priority queue if immediate</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 9: Create deduplication entries atomically using Redis transaction</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 10: Return created job with populated metadata</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use Redis MULTI/EXEC for atomic job creation and deduplication storage</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ClaimJob atomically assigns highest priority available job to worker</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">pq </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">RedisPriorityQueue</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">ClaimJob</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">workerID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Promote any eligible delayed jobs to active queue</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Get highest priority job from priority queue (lowest numeric priority value)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Check if job is already claimed or expired - validate job state and TTL</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Atomically claim job for worker using Redis transaction with job state transition</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Set job ClaimedAt timestamp and WorkerID, transition state to CLAIMED</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Generate unique fencing token to prevent stale worker operations</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Add job to worker's active jobs set for tracking</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 8: Set visibility timeout for job claim to handle worker failures</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 9: Return claimed job with worker metadata populated</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use Redis Lua script for atomic priority queue pop and claim operations</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Deduplication Implementation (<code>internal/queue/deduplication.go</code>):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> queue</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">context</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">crypto/sha256</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">encoding/hex</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">encoding/json</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">fmt</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">sort</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">strings</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// DeduplicationChecker handles job duplicate detection</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> DeduplicationChecker</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    client </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">redis</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Client</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    config </span><span style=\"color:#B392F0\">QueueConfig</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// CheckDuplicate performs comprehensive deduplication check</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">dc </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">DeduplicationChecker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">CheckDuplicate</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">job</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Check explicit idempotency key if provided by client</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Query Redis for existing deduplication entry with same IdempotencyKey</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: If idempotency match found, retrieve and return existing job details</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Compute normalized content hash of job payload and metadata</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Query Redis for existing jobs with same content hash</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: For content hash matches, perform full job comparison to handle hash collisions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Return existing job if true duplicate found, nil if unique job</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use Redis pipelining for efficient multiple key lookups</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// computeContentHash creates deterministic hash of job content</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">dc </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">DeduplicationChecker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">computeContentHash</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">job</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Create normalized representation of job for consistent hashing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Sort payload map keys alphabetically for deterministic ordering</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Include job name (normalized), cron expression (canonical), priority level</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Serialize normalized job data to JSON with consistent field ordering</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Compute SHA-256 hash of serialized data and return hex encoding</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use json.Marshal with sorted maps for consistent serialization</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// StoreDeduplicationEntry creates deduplication tracking entries</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">dc </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">DeduplicationChecker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">StoreDeduplicationEntry</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">job</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Create idempotency key mapping if IdempotencyKey is provided</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Create content hash mapping for automatic duplicate detection</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Set appropriate TTL on deduplication entries based on configuration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Use Redis transaction to create all deduplication entries atomically</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Handle Redis errors and retry transient failures</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use Redis SETEX for TTL-based automatic cleanup of deduplication entries</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Heap Implementation for Priority Ordering (<code>internal/queue/heap.go</code>):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> queue</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">container/heap</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// JobHeap implements heap.Interface for priority-ordered jobs</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> JobHeap</span><span style=\"color:#E1E4E8\"> []</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Job</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Len returns number of jobs in heap</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">jh </span><span style=\"color:#B392F0\">JobHeap</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Len</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#B392F0\"> len</span><span style=\"color:#E1E4E8\">(jh)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Less compares two jobs for priority ordering (lower priority number = higher priority)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">jh </span><span style=\"color:#B392F0\">JobHeap</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Less</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">i</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">j</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Compare priority values - lower numeric priority means higher priority</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: If priorities equal, compare scheduled execution times - earlier time wins</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: If priority and time equal, compare creation timestamps - older jobs first</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Final tiebreaker using job IDs for deterministic ordering</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Return true if job i should be popped before job j</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Swap exchanges two jobs in heap</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">jh </span><span style=\"color:#B392F0\">JobHeap</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Swap</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">i</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">j</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    jh[i], jh[j] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> jh[j], jh[i]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Push adds job to heap (called by heap.Push)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">jh </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">JobHeap</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Push</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">x</span><span style=\"color:#F97583\"> interface</span><span style=\"color:#E1E4E8\">{}) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    *</span><span style=\"color:#E1E4E8\">jh </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> append</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">jh, x.(</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Pop removes highest priority job from heap (called by heap.Pop)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">jh </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">JobHeap</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Pop</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{} {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    old </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\">jh</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    n </span><span style=\"color:#F97583\">:=</span><span style=\"color:#B392F0\"> len</span><span style=\"color:#E1E4E8\">(old)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    job </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> old[n</span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    *</span><span style=\"color:#E1E4E8\">jh </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> old[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\"> : n</span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> job</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// NewJobHeap creates initialized job heap</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewJobHeap</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">JobHeap</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    jh </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">JobHeap</span><span style=\"color:#E1E4E8\">{}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    heap.</span><span style=\"color:#B392F0\">Init</span><span style=\"color:#E1E4E8\">(jh)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> jh</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Redis Lua Scripts for Atomic Operations (<code>internal/queue/redis_scripts.go</code>):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> queue</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Lua script for atomic job claim operation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">const</span><span style=\"color:#79B8FF\"> claimJobScript</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> `</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">local priority_queue_key = KEYS[1]</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">local worker_jobs_key = KEYS[2]</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">local job_key = KEYS[3]</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">local worker_id = ARGV[1]</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">local claim_timeout = ARGV[2]</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">local current_time = ARGV[3]</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">-- Get highest priority job from priority queue</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">local job_data = redis.call('ZPOPMIN', priority_queue_key, 1)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">if #job_data == 0 then</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    return nil  -- No jobs available</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">end</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">local job_id = job_data[1]</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">local job_info = redis.call('HGETALL', job_key .. job_id)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">-- Check if job is still claimable</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">local job_state = job_info['state'] or 'unknown'</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">if job_state ~= 'pending' then</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    return {'error', 'job_not_claimable', job_state}</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">end</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">-- Atomically claim job for worker</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">redis.call('HSET', job_key .. job_id, </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    'state', 'claimed',</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    'worker_id', worker_id,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    'claimed_at', current_time)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">-- Add to worker's active jobs</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">redis.call('SADD', worker_jobs_key, job_id)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">redis.call('EXPIRE', worker_jobs_key, claim_timeout)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">return {job_id, job_info}</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">`</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Additional Lua scripts for batch promotion, cleanup, etc.</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">const</span><span style=\"color:#79B8FF\"> promoteDelayedJobsScript</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> `</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">-- Script for promoting delayed jobs to active queue</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">-- TODO: Implement batch delayed job promotion logic</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">`</span></span></code></pre></div>\n\n<p><strong>Language-Specific Hints:</strong></p>\n<ul>\n<li>Use <code>go-redis/redis/v8</code> for Redis client with context support and connection pooling</li>\n<li>Implement <code>container/heap</code> interface for efficient priority queue operations in memory</li>\n<li>Use <code>crypto/sha256</code> for content hashing with hex encoding for Redis key compatibility  </li>\n<li>Handle Redis pipeline operations for efficient batch deduplication checks</li>\n<li>Use <code>time.Time.UTC()</code> for consistent timestamp normalization across timezones</li>\n<li>Implement exponential backoff with <code>time.Sleep()</code> for Redis retry logic</li>\n<li>Use Redis transactions (<code>MULTI/EXEC</code>) for atomic job state transitions</li>\n<li>Consider Redis Lua scripts for complex atomic operations that require multiple commands</li>\n</ul>\n<p><strong>Milestone Checkpoint:</strong></p>\n<p>After implementing the priority queue foundation:</p>\n<ol>\n<li><strong>Unit Test Verification</strong>: Run <code>go test ./internal/queue/...</code> - all tests should pass</li>\n<li><strong>Priority Ordering Test</strong>: Submit jobs with priorities 100, 500, 100, 200 - claim order should be 100, 100, 200, 500  </li>\n<li><strong>Deduplication Test</strong>: Submit identical jobs with same idempotency key - only first submission should create queue entry</li>\n<li><strong>Delayed Execution Test</strong>: Submit job with <code>ScheduledAt</code> 30 seconds in future - job should not be claimable until promotion scan runs</li>\n<li><strong>Redis Persistence Test</strong>: Restart queue service - submitted jobs should still exist in Redis and be claimable</li>\n</ol>\n<p><strong>Expected Behavior Verification:</strong></p>\n<ul>\n<li>Queue service starts without errors and connects to Redis successfully</li>\n<li>Job submission via REST API returns job ID and confirmation</li>\n<li>Duplicate job submissions return original job ID instead of creating new entries</li>\n<li>Priority ordering is maintained across service restarts</li>\n<li>Delayed jobs become claimable after their scheduled time passes</li>\n</ul>\n<p><strong>Debugging Signs:</strong></p>\n<ul>\n<li>Jobs claimed out of priority order → Check heap Less() implementation and Redis ZPOPMIN usage</li>\n<li>Duplicate jobs created despite idempotency keys → Verify atomic Redis transactions and key formats  </li>\n<li>Delayed jobs never become eligible → Check promotion scan interval and Redis key expiration</li>\n<li>Memory leaks in long-running tests → Ensure proper Redis connection cleanup and heap memory management</li>\n</ul>\n<h2 id=\"worker-coordination\">Worker Coordination</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Milestone 3 - Worker Coordination. This section implements distributed worker management that enables fault-tolerant job execution across multiple worker nodes through leader election, heartbeat monitoring, and automatic job recovery when workers fail.</p>\n</blockquote>\n<p>The worker coordination layer transforms our job scheduler from a single-node system into a truly distributed platform capable of scaling across multiple machines while maintaining consistency and fault tolerance. This coordination system ensures that jobs are fairly distributed across available workers, prevents duplicate execution through distributed locking, and automatically recovers from worker failures without losing work.</p>\n<h3 id=\"mental-model-worker-coordination-as-an-orchestra-with-conductor-and-failure-recovery\">Mental Model: Worker coordination as an orchestra with conductor and failure recovery</h3>\n<p>Think of worker coordination like a symphony orchestra performing a complex musical piece. The <strong>conductor</strong> (coordinator node) stands at the front, directing the performance by assigning musical parts to different musicians (workers) based on their instruments and current availability. Each musician must periodically make eye contact with the conductor (heartbeat) to receive cues and confirm they&#39;re still playing their assigned part.</p>\n<p>When a violinist suddenly becomes ill and leaves mid-performance, the conductor notices immediately because they stopped responding to cues. The conductor then quickly reassigns that violinist&#39;s remaining musical phrases to other available violinists who have the same instrument and capacity. The audience (job submitters) never notices the disruption because the music continues seamlessly.</p>\n<p>The critical insight is that coordination requires both <strong>active leadership</strong> (one conductor making assignment decisions) and <strong>continuous monitoring</strong> (heartbeats to detect failures). Without the conductor, musicians would play over each other chaotically. Without heartbeats, the conductor couldn&#39;t detect when musicians fail and need replacement.</p>\n<p>Just as an orchestra has backup conductors ready to step in if the primary conductor collapses, our distributed system uses <strong>leader election</strong> to ensure exactly one coordinator is making decisions at any time, with other coordinator candidates ready to take over instantly upon failure.</p>\n<p><img src=\"/api/project/job-scheduler/architecture-doc/asset?path=diagrams%2Fworker-state-machine.svg\" alt=\"Worker State Machine\"></p>\n<h3 id=\"leader-election-raft-like-consensus-for-scheduler-leadership-and-split-brain-prevention\">Leader Election: Raft-like consensus for scheduler leadership and split-brain prevention</h3>\n<p><strong>Leader election</strong> is the process by which multiple coordinator nodes agree on a single leader responsible for job assignment and worker management. This prevents the catastrophic <strong>split-brain</strong> scenario where multiple coordinators simultaneously make conflicting job assignments, leading to duplicate execution or worker thrashing.</p>\n<p><img src=\"/api/project/job-scheduler/architecture-doc/asset?path=diagrams%2Fleader-election-flow.svg\" alt=\"Leader Election Process\"></p>\n<blockquote>\n<p><strong>Decision: etcd-based Leader Election with Lease Mechanism</strong></p>\n<ul>\n<li><strong>Context</strong>: Multiple coordinator nodes need to agree on a single leader for job assignment decisions, with fast failover when the leader crashes</li>\n<li><strong>Options Considered</strong>: Database-based locking, Redis-based election, etcd lease-based election</li>\n<li><strong>Decision</strong>: etcd lease-based leader election with automatic renewal</li>\n<li><strong>Rationale</strong>: etcd provides strong consistency guarantees through Raft consensus, built-in lease expiration for fast failure detection, and watch mechanisms for immediate leadership change notifications</li>\n<li><strong>Consequences</strong>: Requires etcd as additional infrastructure dependency, but provides robust consensus with sub-second failover times</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Election Component</th>\n<th>Purpose</th>\n<th>Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>Leadership Lease</code></td>\n<td>Time-bounded leadership claim</td>\n<td>Coordinator holds renewable lease; leadership expires if not renewed</td>\n</tr>\n<tr>\n<td><code>Election Key</code></td>\n<td>Distributed lock for leadership</td>\n<td>Single etcd key that only one coordinator can hold at a time</td>\n</tr>\n<tr>\n<td><code>Candidate Registration</code></td>\n<td>Discovery of potential leaders</td>\n<td>All coordinator nodes register as candidates with their addresses</td>\n</tr>\n<tr>\n<td><code>Lease Renewal</code></td>\n<td>Maintain active leadership</td>\n<td>Leader continuously renews lease every heartbeat interval</td>\n</tr>\n<tr>\n<td><code>Watch Mechanism</code></td>\n<td>Fast failure detection</td>\n<td>Non-leader candidates watch election key for leadership changes</td>\n</tr>\n</tbody></table>\n<p>The leader election algorithm follows these steps:</p>\n<ol>\n<li><strong>Candidate Registration</strong>: Each coordinator node attempts to create an etcd lease with a TTL of 30 seconds and writes its node ID and address to the leadership election key with that lease</li>\n<li><strong>Leadership Determination</strong>: The first node to successfully write to the election key becomes the leader; subsequent attempts fail due to key already existing</li>\n<li><strong>Leadership Announcement</strong>: The new leader broadcasts its leadership to all workers and begins accepting job assignment responsibilities</li>\n<li><strong>Lease Renewal Loop</strong>: The leader continuously renews its lease every 10 seconds (one-third of TTL) to maintain leadership</li>\n<li><strong>Failure Detection</strong>: If the leader fails to renew within the TTL window, etcd automatically deletes the election key, triggering immediate re-election</li>\n<li><strong>Candidate Notification</strong>: All candidate coordinators watch the election key; when it&#39;s deleted, they immediately attempt to claim leadership</li>\n<li><strong>Split-Brain Prevention</strong>: etcd&#39;s strong consistency ensures only one node can hold the election key, making simultaneous leadership impossible</li>\n</ol>\n<blockquote>\n<p>The critical insight is that <strong>lease expiration</strong> provides both failure detection and automatic cleanup. A crashed leader doesn&#39;t need to explicitly release leadership - the lease simply expires, triggering immediate failover.</p>\n</blockquote>\n<p><strong>Leadership Responsibilities:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Responsibility</th>\n<th>Leader Action</th>\n<th>Non-Leader Action</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Job Assignment</td>\n<td>Assigns jobs from queue to available workers</td>\n<td>Rejects assignment requests, returns leader address</td>\n</tr>\n<tr>\n<td>Worker Health Monitoring</td>\n<td>Processes heartbeats, detects failed workers</td>\n<td>Ignores heartbeat messages</td>\n</tr>\n<tr>\n<td>Job Recovery</td>\n<td>Reassigns jobs from failed workers</td>\n<td>Does not perform recovery operations</td>\n</tr>\n<tr>\n<td>Schedule Management</td>\n<td>Evaluates cron expressions, creates scheduled jobs</td>\n<td>Passive; waits for leadership</td>\n</tr>\n<tr>\n<td>Worker Registration</td>\n<td>Accepts new worker registrations</td>\n<td>Redirects to current leader</td>\n</tr>\n</tbody></table>\n<h4 id=\"common-pitfalls\">Common Pitfalls</h4>\n<p>⚠️ <strong>Pitfall: Lease TTL Too Short Causes Leadership Thrashing</strong>\nSetting the lease TTL too aggressively (e.g., 5 seconds) can cause false failovers during temporary network hiccups or garbage collection pauses. The leader temporarily cannot renew its lease, loses leadership, then immediately reclaims it, causing workers to experience multiple leadership changes.</p>\n<p><strong>Solution</strong>: Use a lease TTL of 30 seconds with renewal every 10 seconds, providing tolerance for temporary failures while maintaining sub-30-second failover times.</p>\n<p>⚠️ <strong>Pitfall: Stale Leadership Claims After Network Partition</strong>\nA coordinator that was partitioned from etcd but can still communicate with workers might continue acting as leader, unaware that its lease expired and another node claimed leadership.</p>\n<p><strong>Solution</strong>: Implement <strong>fencing tokens</strong> - the leader includes a monotonically increasing token in all job assignments. Workers reject assignments with tokens lower than the highest they&#39;ve seen, preventing stale leaders from making assignments.</p>\n<h3 id=\"worker-registration-dynamic-worker-discovery-capacity-reporting-and-capability-matching\">Worker Registration: Dynamic worker discovery, capacity reporting, and capability matching</h3>\n<p><strong>Worker registration</strong> enables dynamic scaling by allowing new workers to join the cluster and existing workers to report their current capacity and capabilities. This creates a live inventory that the coordinator uses for intelligent job assignment decisions.</p>\n<p>The <code>Worker</code> data model captures all information needed for coordination:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>ID</code></td>\n<td><code>string</code></td>\n<td>Unique worker identifier (typically hostname + UUID)</td>\n</tr>\n<tr>\n<td><code>Address</code></td>\n<td><code>string</code></td>\n<td>Network address for direct communication (host:port)</td>\n</tr>\n<tr>\n<td><code>Capacity</code></td>\n<td><code>int</code></td>\n<td>Maximum number of concurrent jobs this worker can execute</td>\n</tr>\n<tr>\n<td><code>CurrentJobs</code></td>\n<td><code>int</code></td>\n<td>Number of jobs currently executing on this worker</td>\n</tr>\n<tr>\n<td><code>Capabilities</code></td>\n<td><code>[]string</code></td>\n<td>Tags indicating job types this worker can handle</td>\n</tr>\n<tr>\n<td><code>LastHeartbeat</code></td>\n<td><code>time.Time</code></td>\n<td>Timestamp of most recent heartbeat received</td>\n</tr>\n<tr>\n<td><code>State</code></td>\n<td><code>WorkerState</code></td>\n<td>Current operational state of the worker</td>\n</tr>\n<tr>\n<td><code>StartedAt</code></td>\n<td><code>time.Time</code></td>\n<td>When this worker initially registered</td>\n</tr>\n<tr>\n<td><code>Metadata</code></td>\n<td><code>map[string]string</code></td>\n<td>Additional worker-specific information</td>\n</tr>\n</tbody></table>\n<p><strong>Worker States:</strong></p>\n<table>\n<thead>\n<tr>\n<th>State</th>\n<th>Meaning</th>\n<th>Transition Triggers</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>AVAILABLE</code></td>\n<td>Ready to accept new job assignments</td>\n<td>Heartbeat received, job completed</td>\n</tr>\n<tr>\n<td><code>BUSY</code></td>\n<td>At capacity, cannot accept new jobs</td>\n<td><code>CurrentJobs &gt;= Capacity</code></td>\n</tr>\n<tr>\n<td><code>UNAVAILABLE</code></td>\n<td>Failed or gracefully shutting down</td>\n<td>Heartbeat timeout, explicit shutdown</td>\n</tr>\n</tbody></table>\n<p><strong>Registration Process:</strong></p>\n<ol>\n<li><strong>Initial Registration</strong>: Worker sends registration request to coordinator with its capabilities and capacity</li>\n<li><strong>Capability Validation</strong>: Coordinator validates that worker capabilities match known job types</li>\n<li><strong>Worker ID Assignment</strong>: Coordinator assigns unique ID and records worker in coordination storage</li>\n<li><strong>Heartbeat Initiation</strong>: Worker begins sending periodic heartbeats to maintain registration</li>\n<li><strong>Job Eligibility</strong>: Worker becomes eligible for job assignments once registration is confirmed</li>\n</ol>\n<blockquote>\n<p><strong>Decision: Pull-Based Job Assignment vs Push-Based Distribution</strong></p>\n<ul>\n<li><strong>Context</strong>: Workers need to receive job assignments, but network failures can cause assignments to be lost</li>\n<li><strong>Options Considered</strong>: Coordinator pushes jobs to workers, workers poll coordinator for jobs, hybrid push-pull with acknowledgment</li>\n<li><strong>Decision</strong>: Workers poll coordinator for job assignments (pull-based)</li>\n<li><strong>Rationale</strong>: Pull-based assignment is more fault-tolerant because workers control timing and can retry failed requests. Push-based requires complex acknowledgment and retry logic when workers are temporarily unreachable.</li>\n<li><strong>Consequences</strong>: Slightly higher latency for job assignment, but much simpler failure handling and worker autonomy</li>\n</ul>\n</blockquote>\n<p><strong>Capability Matching:</strong></p>\n<p>Jobs include a <code>RequiredCapabilities</code> field that must be matched against worker capabilities for assignment eligibility:</p>\n<table>\n<thead>\n<tr>\n<th>Matching Rule</th>\n<th>Example</th>\n<th>Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Exact Match</td>\n<td>Job requires <code>[&quot;python&quot;, &quot;gpu&quot;]</code>, Worker has <code>[&quot;python&quot;, &quot;gpu&quot;, &quot;docker&quot;]</code></td>\n<td>✅ Worker eligible</td>\n</tr>\n<tr>\n<td>Missing Capability</td>\n<td>Job requires <code>[&quot;python&quot;, &quot;gpu&quot;]</code>, Worker has <code>[&quot;python&quot;, &quot;docker&quot;]</code></td>\n<td>❌ Worker not eligible</td>\n</tr>\n<tr>\n<td>Subset Match</td>\n<td>Job requires <code>[&quot;python&quot;]</code>, Worker has <code>[&quot;python&quot;, &quot;gpu&quot;, &quot;docker&quot;]</code></td>\n<td>✅ Worker eligible</td>\n</tr>\n<tr>\n<td>No Requirements</td>\n<td>Job requires <code>[]</code>, Worker has any capabilities</td>\n<td>✅ Worker eligible</td>\n</tr>\n</tbody></table>\n<p><img src=\"/api/project/job-scheduler/architecture-doc/asset?path=diagrams%2Fjob-execution-sequence.svg\" alt=\"Job Execution Sequence\"></p>\n<h3 id=\"heartbeat-mechanism-failure-detection-through-periodic-health-checks-and-timeout-handling\">Heartbeat Mechanism: Failure detection through periodic health checks and timeout handling</h3>\n<p>The <strong>heartbeat mechanism</strong> provides continuous liveness monitoring that enables rapid failure detection and automatic job recovery. Workers send periodic heartbeat messages to prove they&#39;re operational and can continue executing assigned jobs.</p>\n<p><strong>Heartbeat Message Structure:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>WorkerID</code></td>\n<td><code>string</code></td>\n<td>Unique identifier of the sending worker</td>\n</tr>\n<tr>\n<td><code>Timestamp</code></td>\n<td><code>time.Time</code></td>\n<td>When this heartbeat was generated</td>\n</tr>\n<tr>\n<td><code>CurrentJobs</code></td>\n<td><code>int</code></td>\n<td>Number of jobs currently executing</td>\n</tr>\n<tr>\n<td><code>LoadAverage</code></td>\n<td><code>float64</code></td>\n<td>System load indicator (optional)</td>\n</tr>\n<tr>\n<td><code>FreeMemory</code></td>\n<td><code>int64</code></td>\n<td>Available memory in bytes (optional)</td>\n</tr>\n<tr>\n<td><code>Status</code></td>\n<td><code>string</code></td>\n<td>Worker status message or health indicator</td>\n</tr>\n</tbody></table>\n<p><strong>Heartbeat Timing Parameters:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Parameter</th>\n<th>Value</th>\n<th>Rationale</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Heartbeat Interval</td>\n<td>15 seconds</td>\n<td>Frequent enough for quick failure detection, infrequent enough to avoid network overhead</td>\n</tr>\n<tr>\n<td>Failure Threshold</td>\n<td>45 seconds</td>\n<td>Three missed heartbeats before declaring worker failed</td>\n</tr>\n<tr>\n<td>Grace Period</td>\n<td>60 seconds</td>\n<td>Additional time for job completion during graceful shutdown</td>\n</tr>\n</tbody></table>\n<p>The coordinator processes heartbeats through this algorithm:</p>\n<ol>\n<li><strong>Heartbeat Reception</strong>: Coordinator receives heartbeat message from worker</li>\n<li><strong>Worker Lookup</strong>: Verify worker ID exists in registered worker table</li>\n<li><strong>Timestamp Update</strong>: Update <code>LastHeartbeat</code> field with current time</li>\n<li><strong>State Transition</strong>: If worker was <code>UNAVAILABLE</code> due to timeout, transition back to <code>AVAILABLE</code></li>\n<li><strong>Load Tracking</strong>: Update <code>CurrentJobs</code> count for capacity management</li>\n<li><strong>Response Generation</strong>: Send acknowledgment with current coordinator fencing token</li>\n</ol>\n<p><strong>Failure Detection Process:</strong></p>\n<ol>\n<li><strong>Timeout Scanning</strong>: Coordinator runs background task every 10 seconds scanning all registered workers</li>\n<li><strong>Staleness Check</strong>: Calculate time since last heartbeat for each worker</li>\n<li><strong>Failure Declaration</strong>: Workers with heartbeats older than 45 seconds are marked <code>UNAVAILABLE</code></li>\n<li><strong>Job Recovery Trigger</strong>: Failed workers trigger immediate job reassignment process</li>\n<li><strong>Cleanup Scheduling</strong>: Failed workers are removed from registry after 24 hours of inactivity</li>\n</ol>\n<blockquote>\n<p>The failure detection algorithm must balance <strong>false positive rate</strong> (healthy workers marked failed due to network delays) against <strong>detection latency</strong> (time to detect actual failures). Our 45-second threshold tolerates temporary network issues while enabling recovery within one minute.</p>\n</blockquote>\n<p><strong>Graceful Shutdown Protocol:</strong></p>\n<p>When workers need to shut down (deployment updates, maintenance), they follow this graceful shutdown sequence:</p>\n<ol>\n<li><strong>Shutdown Signal</strong>: Worker receives SIGTERM or shutdown command</li>\n<li><strong>Stop Accepting Jobs</strong>: Worker stops polling coordinator for new job assignments</li>\n<li><strong>Completion Wait</strong>: Worker continues executing current jobs with configurable timeout</li>\n<li><strong>Status Broadcast</strong>: Worker sends heartbeat with status &quot;SHUTTING_DOWN&quot;</li>\n<li><strong>Final Heartbeat</strong>: After job completion, worker sends final heartbeat with status &quot;OFFLINE&quot;</li>\n<li><strong>Cleanup</strong>: Coordinator removes worker from active registry</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>Worker Method</th>\n<th>Parameters</th>\n<th>Returns</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>heartbeat()</code></td>\n<td><code>status string, metrics map[string]float64</code></td>\n<td><code>ack HeartbeatAck, err error</code></td>\n<td>Sends liveness signal with current status</td>\n</tr>\n<tr>\n<td><code>CanAcceptJob()</code></td>\n<td><code>capabilities []string</code></td>\n<td><code>bool</code></td>\n<td>Checks if worker can handle job with given requirements</td>\n</tr>\n<tr>\n<td><code>UpdateHeartbeat()</code></td>\n<td><code>timestamp time.Time, status string</code></td>\n<td><code>error</code></td>\n<td>Records heartbeat and updates worker state</td>\n</tr>\n<tr>\n<td><code>IsHealthy()</code></td>\n<td><code>timeout time.Duration</code></td>\n<td><code>bool</code></td>\n<td>Checks if worker heartbeat is within timeout window</td>\n</tr>\n</tbody></table>\n<h3 id=\"job-recovery-detecting-failed-workers-and-reassigning-their-in-progress-jobs\">Job Recovery: Detecting failed workers and reassigning their in-progress jobs</h3>\n<p><strong>Job recovery</strong> ensures that work is never lost when workers fail unexpectedly. When a worker becomes unavailable, all jobs it was executing must be identified and reassigned to healthy workers to maintain system reliability.</p>\n<p>The recovery process addresses several complex scenarios where workers fail at different stages of job execution:</p>\n<table>\n<thead>\n<tr>\n<th>Failure Scenario</th>\n<th>Job State</th>\n<th>Recovery Action</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Worker fails immediately after claiming job</td>\n<td><code>CLAIMED</code></td>\n<td>Reset to <code>PENDING</code>, make available for reassignment</td>\n</tr>\n<tr>\n<td>Worker fails during job execution</td>\n<td><code>EXECUTING</code></td>\n<td>Reset to <code>PENDING</code>, increment retry count</td>\n</tr>\n<tr>\n<td>Worker fails after completion but before reporting</td>\n<td><code>EXECUTING</code></td>\n<td>Check for side effects, potentially duplicate execution</td>\n</tr>\n<tr>\n<td>Worker recovers before timeout</td>\n<td>Any state</td>\n<td>Cancel recovery, allow worker to continue</td>\n</tr>\n</tbody></table>\n<p><strong>Recovery Algorithm:</strong></p>\n<ol>\n<li><strong>Failure Detection</strong>: Coordinator identifies worker as failed due to heartbeat timeout</li>\n<li><strong>Job Query</strong>: Query storage for all jobs with <code>WorkerID</code> matching failed worker</li>\n<li><strong>State Analysis</strong>: Examine each job&#39;s current state and execution progress</li>\n<li><strong>Fencing Check</strong>: Verify job hasn&#39;t completed using external side effect detection</li>\n<li><strong>Job Reset</strong>: Reset job state to <code>PENDING</code> and clear worker assignment</li>\n<li><strong>Retry Logic</strong>: Increment <code>RetryCount</code> and check against <code>MaxRetries</code> limit</li>\n<li><strong>Reassignment</strong>: Make jobs eligible for assignment to healthy workers</li>\n<li><strong>Monitoring</strong>: Log recovery actions for operational visibility</li>\n</ol>\n<blockquote>\n<p><strong>Decision: Optimistic Recovery vs Pessimistic Job Fencing</strong></p>\n<ul>\n<li><strong>Context</strong>: Workers might complete jobs after being declared failed, leading to duplicate execution if jobs are immediately reassigned</li>\n<li><strong>Options Considered</strong>: Immediate reassignment (optimistic), wait period before reassignment (pessimistic), external completion checking</li>\n<li><strong>Decision</strong>: Optimistic recovery with retry limits and idempotency requirements</li>\n<li><strong>Rationale</strong>: Most job failures occur before significant progress, and jobs should be designed for idempotent execution anyway. Waiting introduces unnecessary latency for legitimate failures.</li>\n<li><strong>Consequences</strong>: Possible duplicate execution in edge cases, but much faster recovery for genuine failures</li>\n</ul>\n</blockquote>\n<p><strong>Fencing Token Mechanism:</strong></p>\n<p>To prevent <strong>stale worker reports</strong> where a failed worker later reports job completion, the system uses fencing tokens:</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Token Usage</th>\n<th>Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Job Assignment</td>\n<td>Coordinator assigns incrementing token with job</td>\n<td>Token written to job record in storage</td>\n</tr>\n<tr>\n<td>Worker Execution</td>\n<td>Worker includes token in all status updates</td>\n<td>Token proves worker has legitimate claim</td>\n</tr>\n<tr>\n<td>Completion Reporting</td>\n<td>Worker provides token when reporting results</td>\n<td>Coordinator rejects reports with wrong token</td>\n</tr>\n<tr>\n<td>Recovery Process</td>\n<td>New assignment gets new token</td>\n<td>Previous worker&#39;s reports become invalid</td>\n</tr>\n</tbody></table>\n<p><strong>Recovery State Machine:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Current Job State</th>\n<th>Recovery Action</th>\n<th>Next State</th>\n<th>Reason</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>CLAIMED</code></td>\n<td>Reset assignment</td>\n<td><code>PENDING</code></td>\n<td>Worker failed before starting execution</td>\n</tr>\n<tr>\n<td><code>EXECUTING</code></td>\n<td>Check retry count</td>\n<td><code>PENDING</code> or <code>FAILED</code></td>\n<td>Worker failed during execution</td>\n</tr>\n<tr>\n<td><code>COMPLETING</code></td>\n<td>External verification</td>\n<td><code>COMPLETED</code> or <code>PENDING</code></td>\n<td>Worker may have finished before failure</td>\n</tr>\n</tbody></table>\n<p><img src=\"/api/project/job-scheduler/architecture-doc/asset?path=diagrams%2Ffailure-recovery-sequence.svg\" alt=\"Failure Recovery Sequence\"></p>\n<p><strong>Retry Logic During Recovery:</strong></p>\n<p>The recovery process must decide whether failed jobs should be retried or marked as permanently failed:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>if job.RetryCount &gt;= job.MaxRetries:\n    job.State = FAILED\n    job.FailureReason = &quot;Max retries exceeded after worker failure&quot;\nelse:\n    job.State = PENDING\n    job.RetryCount += 1\n    job.WorkerID = &quot;&quot;\n    job.FencingToken = generateNewToken()</code></pre></div>\n\n<p><strong>Recovery Metrics and Monitoring:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Metric</th>\n<th>Purpose</th>\n<th>Alert Threshold</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Jobs Recovered Per Hour</td>\n<td>Track system stability</td>\n<td>&gt; 100/hour indicates worker instability</td>\n</tr>\n<tr>\n<td>Recovery Latency</td>\n<td>Time from failure to reassignment</td>\n<td>&gt; 2 minutes indicates coordinator issues</td>\n</tr>\n<tr>\n<td>Duplicate Executions</td>\n<td>Count jobs run multiple times</td>\n<td>&gt; 1% indicates timing problems</td>\n</tr>\n<tr>\n<td>Recovery Success Rate</td>\n<td>Percentage of recovered jobs that complete</td>\n<td>&lt; 90% indicates job design issues</td>\n</tr>\n</tbody></table>\n<h4 id=\"common-pitfalls\">Common Pitfalls</h4>\n<p>⚠️ <strong>Pitfall: Race Condition Between Recovery and Worker Return</strong>\nA worker experiences temporary network partition, coordinator declares it failed and reassigns its jobs, then worker reconnects and tries to report completion of already-reassigned jobs.</p>\n<p><strong>Solution</strong>: Use strict fencing token validation. When jobs are reassigned during recovery, they receive new fencing tokens. The original worker&#39;s completion reports include the old token and are rejected.</p>\n<p>⚠️ <strong>Pitfall: Infinite Recovery Loop for Consistently Failing Jobs</strong>\nJobs that fail due to invalid input or missing dependencies get repeatedly reassigned to different workers, all of which fail for the same reason, creating an endless recovery cycle.</p>\n<p><strong>Solution</strong>: Implement exponential backoff for job reassignment after recovery. Jobs that fail multiple times across different workers should be delayed longer between retry attempts and eventually moved to a dead letter queue for manual inspection.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The worker coordination system requires careful orchestration of multiple Go services with strong consistency guarantees and efficient failure detection. The following implementation provides a production-ready foundation for distributed job scheduling.</p>\n<p><strong>Technology Recommendations:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Coordination Store</td>\n<td>etcd v3 client</td>\n<td>etcd with embedded proxy</td>\n</tr>\n<tr>\n<td>Leader Election</td>\n<td>etcd lease-based</td>\n<td>Raft implementation</td>\n</tr>\n<tr>\n<td>Inter-node Communication</td>\n<td>HTTP REST + JSON</td>\n<td>gRPC with Protocol Buffers</td>\n</tr>\n<tr>\n<td>Configuration Management</td>\n<td>YAML files + env vars</td>\n<td>etcd-based dynamic config</td>\n</tr>\n<tr>\n<td>Health Monitoring</td>\n<td>HTTP health endpoints</td>\n<td>Prometheus metrics + alerts</td>\n</tr>\n<tr>\n<td>Logging</td>\n<td>structured JSON logs</td>\n<td>Distributed tracing with Jaeger</td>\n</tr>\n</tbody></table>\n<p><strong>Recommended File Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>internal/coordinator/\n  coordinator.go           ← main coordinator logic and leader election\n  coordinator_test.go      ← coordinator unit tests\n  worker_manager.go        ← worker registration and heartbeat handling\n  worker_manager_test.go   ← worker management tests\n  job_recovery.go          ← failed worker job recovery logic\n  job_recovery_test.go     ← recovery logic tests\n  election.go              ← etcd-based leader election\n  election_test.go         ← leader election tests\n  fencing.go               ← token generation and validation\n  fencing_test.go          ← fencing mechanism tests\n\ninternal/worker/\n  worker.go                ← worker node implementation\n  worker_test.go           ← worker unit tests\n  heartbeat.go             ← heartbeat and health reporting\n  heartbeat_test.go        ← heartbeat mechanism tests\n  executor.go              ← job execution logic\n  executor_test.go         ← execution tests\n\ninternal/etcd/\n  client.go                ← etcd client wrapper with retries\n  client_test.go           ← etcd integration tests\n  lease.go                 ← lease management utilities\n  watch.go                 ← etcd watch helper functions\n\npkg/coordination/\n  types.go                 ← shared types for coordination messages\n  constants.go             ← timing constants and configuration</code></pre></div>\n\n<p><strong>Core Coordinator Infrastructure (COMPLETE):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> coordinator</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">context</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">encoding/json</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">fmt</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">log</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">sync</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    clientv3 </span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#B392F0\">go.etcd.io/etcd/client/v3</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">go.etcd.io/etcd/client/v3/concurrency</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ETCDConfig holds etcd connection configuration</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> ETCDConfig</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Endpoints   []</span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `yaml:\"endpoints\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    DialTimeout </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#9ECBFF\"> `yaml:\"dial_timeout\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Username    </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">        `yaml:\"username\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Password    </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">        `yaml:\"password\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// CoordinatorConfig holds coordinator configuration</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> CoordinatorConfig</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    NodeID              </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">        `yaml:\"node_id\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ElectionPrefix      </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">        `yaml:\"election_prefix\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LeaseTimeout        </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#9ECBFF\"> `yaml:\"lease_timeout\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HeartbeatInterval   </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#9ECBFF\"> `yaml:\"heartbeat_interval\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    FailureThreshold    </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#9ECBFF\"> `yaml:\"failure_threshold\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    RecoveryInterval    </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#9ECBFF\"> `yaml:\"recovery_interval\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Coordinator manages distributed job scheduling coordination</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> Coordinator</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    config       </span><span style=\"color:#B392F0\">CoordinatorConfig</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    etcdClient   </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">clientv3</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Client</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    session      </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">concurrency</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Session</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    election     </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">concurrency</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Election</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Leadership state</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    isLeader     </span><span style=\"color:#F97583\">bool</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    leaderMux    </span><span style=\"color:#B392F0\">sync</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">RWMutex</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    fencingToken </span><span style=\"color:#F97583\">int64</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Worker management</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    workers      </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Worker</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    workerMux    </span><span style=\"color:#B392F0\">sync</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">RWMutex</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Background tasks</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ctx          </span><span style=\"color:#B392F0\">context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cancel       </span><span style=\"color:#B392F0\">context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">CancelFunc</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    wg           </span><span style=\"color:#B392F0\">sync</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">WaitGroup</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// NewCoordinator creates a new coordinator instance with etcd backend</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewCoordinator</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">config</span><span style=\"color:#B392F0\"> CoordinatorConfig</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">etcdConfig</span><span style=\"color:#B392F0\"> ETCDConfig</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Coordinator</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    etcdClient, err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> clientv3.</span><span style=\"color:#B392F0\">New</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">clientv3</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Config</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Endpoints:   etcdConfig.Endpoints,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        DialTimeout: etcdConfig.DialTimeout,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Username:    etcdConfig.Username,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Password:    etcdConfig.Password,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    })</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\">, fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"failed to connect to etcd: </span><span style=\"color:#79B8FF\">%w</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    session, err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> concurrency.</span><span style=\"color:#B392F0\">NewSession</span><span style=\"color:#E1E4E8\">(etcdClient, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        concurrency.</span><span style=\"color:#B392F0\">WithTTL</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\">(config.LeaseTimeout.</span><span style=\"color:#B392F0\">Seconds</span><span style=\"color:#E1E4E8\">())))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\">, fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"failed to create etcd session: </span><span style=\"color:#79B8FF\">%w</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ctx, cancel </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> context.</span><span style=\"color:#B392F0\">WithCancel</span><span style=\"color:#E1E4E8\">(context.</span><span style=\"color:#B392F0\">Background</span><span style=\"color:#E1E4E8\">())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">Coordinator</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        config:     config,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        etcdClient: etcdClient,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        session:    session,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        election:   concurrency.</span><span style=\"color:#B392F0\">NewElection</span><span style=\"color:#E1E4E8\">(session, config.ElectionPrefix),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        workers:    </span><span style=\"color:#B392F0\">make</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Worker</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ctx:        ctx,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        cancel:     cancel,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }, </span><span style=\"color:#79B8FF\">nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Start begins coordinator operations including leader election</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Coordinator</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Start</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    log.</span><span style=\"color:#B392F0\">Printf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Starting coordinator </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, c.config.NodeID)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Start leader election</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    c.wg.</span><span style=\"color:#B392F0\">Add</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    go</span><span style=\"color:#E1E4E8\"> c.</span><span style=\"color:#B392F0\">runLeaderElection</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Start worker monitoring</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    c.wg.</span><span style=\"color:#B392F0\">Add</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    go</span><span style=\"color:#E1E4E8\"> c.</span><span style=\"color:#B392F0\">runWorkerMonitoring</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Start job recovery</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    c.wg.</span><span style=\"color:#B392F0\">Add</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    go</span><span style=\"color:#E1E4E8\"> c.</span><span style=\"color:#B392F0\">runJobRecovery</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Stop gracefully shuts down coordinator</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Coordinator</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Stop</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    log.</span><span style=\"color:#B392F0\">Printf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Stopping coordinator </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, c.config.NodeID)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    c.</span><span style=\"color:#B392F0\">cancel</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    c.wg.</span><span style=\"color:#B392F0\">Wait</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> c.session </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        c.session.</span><span style=\"color:#B392F0\">Close</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> c.etcdClient </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        c.etcdClient.</span><span style=\"color:#B392F0\">Close</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// IsLeader returns current leadership status</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Coordinator</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">IsLeader</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    c.leaderMux.</span><span style=\"color:#B392F0\">RLock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> c.leaderMux.</span><span style=\"color:#B392F0\">RUnlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> c.isLeader</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// GetFencingToken returns current fencing token for job assignments</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Coordinator</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">GetFencingToken</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">int64</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    c.leaderMux.</span><span style=\"color:#B392F0\">RLock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> c.leaderMux.</span><span style=\"color:#B392F0\">RUnlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> c.fencingToken</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Worker Heartbeat Infrastructure (COMPLETE):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> worker</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">context</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">encoding/json</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">fmt</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">log</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">net/http</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">sync</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// WorkerConfig holds worker configuration</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> WorkerConfig</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ID                 </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">            `yaml:\"id\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Address            </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">            `yaml:\"address\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Capacity           </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">               `yaml:\"capacity\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Capabilities       []</span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">          `yaml:\"capabilities\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CoordinatorAddress </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">            `yaml:\"coordinator_address\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HeartbeatInterval  </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#9ECBFF\">     `yaml:\"heartbeat_interval\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ShutdownTimeout    </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#9ECBFF\">     `yaml:\"shutdown_timeout\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Metadata           </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\"> `yaml:\"metadata\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Worker represents a job execution node</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> Worker</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    config        </span><span style=\"color:#B392F0\">WorkerConfig</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    httpClient    </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">http</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Client</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Job execution</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    currentJobs   </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Job</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    jobMux        </span><span style=\"color:#B392F0\">sync</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">RWMutex</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Lifecycle management</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ctx           </span><span style=\"color:#B392F0\">context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cancel        </span><span style=\"color:#B392F0\">context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">CancelFunc</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    wg            </span><span style=\"color:#B392F0\">sync</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">WaitGroup</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    isShuttingDown </span><span style=\"color:#F97583\">bool</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    shutdownMux   </span><span style=\"color:#B392F0\">sync</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">RWMutex</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// NewWorker creates a new worker instance</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewWorker</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">config</span><span style=\"color:#B392F0\"> WorkerConfig</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Worker</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ctx, cancel </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> context.</span><span style=\"color:#B392F0\">WithCancel</span><span style=\"color:#E1E4E8\">(context.</span><span style=\"color:#B392F0\">Background</span><span style=\"color:#E1E4E8\">())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">Worker</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        config: config,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        httpClient: </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#B392F0\">http</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Client</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            Timeout: </span><span style=\"color:#79B8FF\">30</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\"> time.Second,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        },</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        currentJobs: </span><span style=\"color:#B392F0\">make</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ctx:         ctx,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        cancel:      cancel,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Start begins worker operations including registration and heartbeating</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">w </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Worker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Start</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    log.</span><span style=\"color:#B392F0\">Printf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Starting worker </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, w.config.ID)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Register with coordinator</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> w.</span><span style=\"color:#B392F0\">registerWithCoordinator</span><span style=\"color:#E1E4E8\">(); err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"failed to register: </span><span style=\"color:#79B8FF\">%w</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Start heartbeat loop</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    w.wg.</span><span style=\"color:#B392F0\">Add</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    go</span><span style=\"color:#E1E4E8\"> w.</span><span style=\"color:#B392F0\">runHeartbeatLoop</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Start job polling loop</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    w.wg.</span><span style=\"color:#B392F0\">Add</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    go</span><span style=\"color:#E1E4E8\"> w.</span><span style=\"color:#B392F0\">runJobPollingLoop</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Stop gracefully shuts down worker</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">w </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Worker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Stop</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    log.</span><span style=\"color:#B392F0\">Printf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Stopping worker </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, w.config.ID)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    w.shutdownMux.</span><span style=\"color:#B392F0\">Lock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    w.isShuttingDown </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    w.shutdownMux.</span><span style=\"color:#B392F0\">Unlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Cancel context to stop background loops</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    w.</span><span style=\"color:#B392F0\">cancel</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Wait for current jobs to complete with timeout</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    done </span><span style=\"color:#F97583\">:=</span><span style=\"color:#B392F0\"> make</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">chan</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\">{})</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    go</span><span style=\"color:#F97583\"> func</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        w.wg.</span><span style=\"color:#B392F0\">Wait</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        close</span><span style=\"color:#E1E4E8\">(done)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    select</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    case</span><span style=\"color:#F97583\"> &#x3C;-</span><span style=\"color:#E1E4E8\">done:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        log.</span><span style=\"color:#B392F0\">Printf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Worker </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\"> stopped gracefully\"</span><span style=\"color:#E1E4E8\">, w.config.ID)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    case</span><span style=\"color:#F97583\"> &#x3C;-</span><span style=\"color:#E1E4E8\">time.</span><span style=\"color:#B392F0\">After</span><span style=\"color:#E1E4E8\">(w.config.ShutdownTimeout):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        log.</span><span style=\"color:#B392F0\">Printf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Worker </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\"> shutdown timeout, forcing stop\"</span><span style=\"color:#E1E4E8\">, w.config.ID)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// HeartbeatMessage represents worker heartbeat data</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> HeartbeatMessage</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    WorkerID     </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">            `json:\"worker_id\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Timestamp    </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">         `json:\"timestamp\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CurrentJobs  </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">               `json:\"current_jobs\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Status       </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">            `json:\"status\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Metadata     </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\"> `json:\"metadata\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// registerWithCoordinator sends initial registration request</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">w </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Worker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">registerWithCoordinator</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    registrationData </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{}{</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"worker_id\"</span><span style=\"color:#E1E4E8\">:    w.config.ID,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"address\"</span><span style=\"color:#E1E4E8\">:      w.config.Address,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"capacity\"</span><span style=\"color:#E1E4E8\">:     w.config.Capacity,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"capabilities\"</span><span style=\"color:#E1E4E8\">: w.config.Capabilities,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"metadata\"</span><span style=\"color:#E1E4E8\">:     w.config.Metadata,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Implementation continues with HTTP request to coordinator...</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// GetCurrentJobCount returns number of jobs currently executing</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">w </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Worker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">GetCurrentJobCount</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    w.jobMux.</span><span style=\"color:#B392F0\">RLock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> w.jobMux.</span><span style=\"color:#B392F0\">RUnlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#B392F0\"> len</span><span style=\"color:#E1E4E8\">(w.currentJobs)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// CanAcceptJob checks if worker can handle job with given requirements</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">w </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Worker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">CanAcceptJob</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">requiredCapabilities</span><span style=\"color:#E1E4E8\"> []</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    w.shutdownMux.</span><span style=\"color:#B392F0\">RLock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> w.shutdownMux.</span><span style=\"color:#B392F0\">RUnlock</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> w.isShuttingDown {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> false</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> w.</span><span style=\"color:#B392F0\">GetCurrentJobCount</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">>=</span><span style=\"color:#E1E4E8\"> w.config.Capacity {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> false</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Check capability matching</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    workerCaps </span><span style=\"color:#F97583\">:=</span><span style=\"color:#B392F0\"> make</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> _, cap </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> range</span><span style=\"color:#E1E4E8\"> w.config.Capabilities {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        workerCaps[cap] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> _, required </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> range</span><span style=\"color:#E1E4E8\"> requiredCapabilities {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> !</span><span style=\"color:#E1E4E8\">workerCaps[required] {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> false</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> true</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Core Logic Skeleton for Leader Election:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// runLeaderElection handles leader election and maintains leadership</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Coordinator</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">runLeaderElection</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> c.wg.</span><span style=\"color:#B392F0\">Done</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        select</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        case</span><span style=\"color:#F97583\"> &#x3C;-</span><span style=\"color:#E1E4E8\">c.ctx.</span><span style=\"color:#B392F0\">Done</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        default</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // TODO 1: Campaign for leadership using etcd election</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // Use: c.election.Campaign(c.ctx, c.config.NodeID)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // TODO 2: If campaign succeeds, set leadership state and generate new fencing token</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // Set: c.isLeader = true, c.fencingToken = time.Now().UnixNano()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // TODO 3: Start leadership maintenance loop</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // Monitor election key and renew session lease</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // TODO 4: Handle leadership loss detection</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // Watch for election key changes or session expiration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // TODO 5: Clean up leadership state when stepping down</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // Set: c.isLeader = false, clear cached state</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// runWorkerMonitoring periodically checks worker health and removes failed workers</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Coordinator</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">runWorkerMonitoring</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> c.wg.</span><span style=\"color:#B392F0\">Done</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ticker </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> time.</span><span style=\"color:#B392F0\">NewTicker</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">10</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\"> time.Second)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> ticker.</span><span style=\"color:#B392F0\">Stop</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        select</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        case</span><span style=\"color:#F97583\"> &#x3C;-</span><span style=\"color:#E1E4E8\">c.ctx.</span><span style=\"color:#B392F0\">Done</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        case</span><span style=\"color:#F97583\"> &#x3C;-</span><span style=\"color:#E1E4E8\">ticker.C:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // TODO 1: Check if this node is the leader</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // Skip monitoring if not leader to avoid conflicts</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // TODO 2: Iterate through all registered workers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // Get worker list from c.workers map with proper locking</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // TODO 3: Check each worker's last heartbeat timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // Compare time.Since(worker.LastHeartbeat) against c.config.FailureThreshold</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // TODO 4: Mark workers as UNAVAILABLE if heartbeat is stale</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // Update worker.State and log failure detection</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // TODO 5: Trigger job recovery for newly failed workers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // Call job recovery process for workers that just became unavailable</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ProcessWorkerHeartbeat handles incoming heartbeat from worker</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Coordinator</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">ProcessWorkerHeartbeat</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">heartbeat</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">HeartbeatMessage</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Validate heartbeat message fields</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Check that WorkerID is non-empty and timestamp is recent</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Acquire worker registry lock</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Use c.workerMux.Lock() for exclusive access</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Look up worker in registry</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Find worker by heartbeat.WorkerID in c.workers map</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Update worker heartbeat timestamp and status</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Set LastHeartbeat = time.Now(), update CurrentJobs count</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Transition worker state if it was previously UNAVAILABLE</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // If worker.State == UNAVAILABLE, set to AVAILABLE</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Return heartbeat acknowledgment with current fencing token</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Include c.GetFencingToken() in response for worker validation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Core Logic Skeleton for Job Recovery:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// runJobRecovery periodically checks for jobs from failed workers and reassigns them</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Coordinator</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">runJobRecovery</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> c.wg.</span><span style=\"color:#B392F0\">Done</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ticker </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> time.</span><span style=\"color:#B392F0\">NewTicker</span><span style=\"color:#E1E4E8\">(c.config.RecoveryInterval)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> ticker.</span><span style=\"color:#B392F0\">Stop</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        select</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        case</span><span style=\"color:#F97583\"> &#x3C;-</span><span style=\"color:#E1E4E8\">c.ctx.</span><span style=\"color:#B392F0\">Done</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        case</span><span style=\"color:#F97583\"> &#x3C;-</span><span style=\"color:#E1E4E8\">ticker.C:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // TODO 1: Check if this node is the leader</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // Only leader should perform job recovery</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // TODO 2: Find all jobs assigned to UNAVAILABLE workers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // Query storage for jobs where WorkerID matches failed workers</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // TODO 3: Group jobs by their current state</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // Handle CLAIMED, EXECUTING, and COMPLETING states differently</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // TODO 4: Reset job assignments and increment retry counts</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // Clear WorkerID, generate new FencingToken, increment RetryCount</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // TODO 5: Check retry limits and mark permanently failed jobs</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // If RetryCount >= MaxRetries, set State = FAILED</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // TODO 6: Make recovered jobs available for reassignment</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // Set State = PENDING for jobs that can be retried</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// RecoverJobsFromWorker handles job recovery when a specific worker fails</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Coordinator</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">RecoverJobsFromWorker</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">workerID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Query storage for all jobs assigned to this worker</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Use storage query: WHERE WorkerID = workerID AND State IN (CLAIMED, EXECUTING)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: For each job, determine recovery action based on current state</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // CLAIMED jobs can be immediately reset, EXECUTING jobs need retry logic</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Generate new fencing tokens for recovered jobs</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Use time.Now().UnixNano() + job sequence for uniqueness</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Update job records with recovery information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Clear WorkerID, set new FencingToken, increment RetryCount</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Log recovery actions for operational monitoring</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Include workerID, jobID, old state, new state in log messages</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Update job queue to make recovered jobs available</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Call priority queue methods to reinsert jobs for assignment</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ValidateFencingToken checks if worker has authority to report on job</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Coordinator</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">ValidateFencingToken</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">jobID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">workerID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">token</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) (</span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Look up current job record in storage</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Get job by jobID and check current WorkerID and FencingToken</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Verify worker ID matches job assignment</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Return false if job.WorkerID != workerID</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Compare provided token with stored token</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Return false if job.FencingToken != token</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Check if job is in a state that accepts worker reports</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Only CLAIMED and EXECUTING jobs should accept status updates</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Return validation result</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // true = worker has authority, false = stale or invalid token</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Language-Specific Implementation Hints:</strong></p>\n<ul>\n<li><strong>etcd Client</strong>: Use <code>go.etcd.io/etcd/client/v3</code> for robust etcd integration with automatic retries and connection pooling</li>\n<li><strong>Context Cancellation</strong>: Use <code>context.WithCancel()</code> for graceful shutdown coordination across all goroutines</li>\n<li><strong>Atomic Operations</strong>: Use <code>sync.RWMutex</code> for worker registry access and <code>sync.atomic</code> for fencing token generation</li>\n<li><strong>Time Handling</strong>: Always use <code>time.Now().UTC()</code> for consistent timestamps across distributed nodes</li>\n<li><strong>Error Wrapping</strong>: Use <code>fmt.Errorf(&quot;context: %w&quot;, err)</code> for error chain preservation in distributed debugging</li>\n<li><strong>Structured Logging</strong>: Use <code>log/slog</code> or similar for JSON-structured logs with correlation IDs across services</li>\n</ul>\n<p><strong>Milestone Checkpoint:</strong></p>\n<p>After implementing worker coordination, verify the system with these tests:</p>\n<ol>\n<li><strong>Leader Election Test</strong>: <code>go run cmd/coordinator/main.go</code> on three separate machines - exactly one should claim leadership, others should remain candidates</li>\n<li><strong>Worker Registration</strong>: Start workers with different capabilities - they should appear in coordinator logs as registered and healthy</li>\n<li><strong>Failure Detection</strong>: Kill a worker process - coordinator should detect failure within 60 seconds and log worker state change</li>\n<li><strong>Job Recovery</strong>: Submit jobs, kill workers mid-execution - jobs should be reassigned to healthy workers within recovery interval</li>\n<li><strong>Graceful Shutdown</strong>: Send SIGTERM to worker - it should complete current jobs before exiting, coordinator should clean up registration</li>\n</ol>\n<p>Expected behavior: Workers register successfully, heartbeats maintain registration, leader election produces exactly one leader, failed workers trigger job recovery within 2 minutes, graceful shutdown completes current work.</p>\n<h2 id=\"interactions-and-data-flow\">Interactions and Data Flow</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section synthesizes all three milestones by defining the communication patterns and message flows that connect the cron parser (Milestone 1), priority queue (Milestone 2), and worker coordination (Milestone 3) into a cohesive distributed system.</p>\n</blockquote>\n<h3 id=\"mental-model-orchestra-performance\">Mental Model: Orchestra Performance</h3>\n<p>Think of the distributed job scheduler&#39;s interactions like a symphony orchestra performance. The <strong>coordinator</strong> acts as the conductor, maintaining the tempo and ensuring all musicians (workers) play their parts harmoniously. <strong>Job submission</strong> is like sheet music being distributed to the orchestra - each piece has timing requirements (cron expressions), priority levels (solo vs. background), and specific instructions (job payload). The <strong>execution flow</strong> resembles the actual performance where musicians claim their parts, play them according to the conductor&#39;s timing, and signal completion. <strong>Coordination messages</strong> are the conductor&#39;s gestures and the musicians&#39; acknowledgments that keep everyone synchronized, detect when someone misses their cue, and recover gracefully from mistakes.</p>\n<p>Just as an orchestra must handle musicians arriving late, instruments breaking, or the conductor temporarily stepping away, our distributed scheduler must gracefully manage worker failures, network partitions, and leadership changes while ensuring the &quot;performance&quot; (job execution) continues without missing critical notes.</p>\n<h3 id=\"job-submission-flow\">Job Submission Flow</h3>\n<p>The job submission flow represents the journey from external job creation through validation, scheduling, and queue insertion. This flow must handle duplicate detection, priority assignment, and delayed scheduling while maintaining consistency across the distributed system.</p>\n<h4 id=\"submission-process-overview\">Submission Process Overview</h4>\n<p>The job submission process begins when an external client creates a job request and continues through multiple validation and enrichment stages before the job becomes eligible for worker assignment. The process involves three primary actors: the <strong>client</strong> (job submitter), the <strong>scheduler service</strong> (API gateway and validation), and the <strong>priority queue</strong> (storage and ordering).</p>\n<blockquote>\n<p><strong>Decision: Synchronous vs Asynchronous Submission API</strong></p>\n<ul>\n<li><strong>Context</strong>: Clients need feedback about job acceptance, but synchronous processing could create bottlenecks under high load</li>\n<li><strong>Options Considered</strong>: Fully synchronous processing, fire-and-forget async, async with acknowledgment</li>\n<li><strong>Decision</strong>: Synchronous validation and deduplication with asynchronous scheduling</li>\n<li><strong>Rationale</strong>: Clients get immediate feedback about validation errors and duplicates, but scheduling decisions happen asynchronously to prevent blocking</li>\n<li><strong>Consequences</strong>: Enables immediate error handling while maintaining high throughput; requires careful state management for partially processed jobs</li>\n</ul>\n</blockquote>\n<p>The submission flow follows this sequence of operations:</p>\n<ol>\n<li><p><strong>Client Request Validation</strong>: The scheduler service validates the incoming job request against schema requirements, checking that required fields are present and properly formatted.</p>\n</li>\n<li><p><strong>Cron Expression Parsing</strong>: The system parses and validates the cron expression using the parser from Milestone 1, calculating the initial <code>ScheduledAt</code> timestamp for the job&#39;s first execution.</p>\n</li>\n<li><p><strong>Idempotency Check</strong>: The deduplication system checks if a job with the same <code>IdempotencyKey</code> already exists, preventing duplicate submissions from causing redundant work.</p>\n</li>\n<li><p><strong>Job Enrichment</strong>: The system enriches the job with metadata including creation timestamps, generated unique IDs, and computed priority scores.</p>\n</li>\n<li><p><strong>Queue Insertion</strong>: The priority queue atomically inserts the job, positioning it correctly based on priority and scheduled execution time.</p>\n</li>\n<li><p><strong>Response Generation</strong>: The scheduler service returns confirmation to the client with the job ID and next execution time.</p>\n</li>\n</ol>\n<h4 id=\"submission-message-formats\">Submission Message Formats</h4>\n<table>\n<thead>\n<tr>\n<th>Message Type</th>\n<th>Direction</th>\n<th>Format</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>JobSubmissionRequest</td>\n<td>Client → Scheduler</td>\n<td>JSON over HTTP</td>\n<td>Contains job definition, cron expression, and metadata</td>\n</tr>\n<tr>\n<td>JobSubmissionResponse</td>\n<td>Scheduler → Client</td>\n<td>JSON over HTTP</td>\n<td>Returns job ID, validation status, and next execution time</td>\n</tr>\n<tr>\n<td>QueueInsertionMessage</td>\n<td>Scheduler → Queue</td>\n<td>Internal struct</td>\n<td>Enriched job data for priority queue insertion</td>\n</tr>\n<tr>\n<td>DeduplicationQuery</td>\n<td>Scheduler → Storage</td>\n<td>Redis command</td>\n<td>Idempotency key lookup for duplicate detection</td>\n</tr>\n</tbody></table>\n<p>The <code>JobSubmissionRequest</code> message contains all information necessary to create and schedule a job:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Required</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Name</td>\n<td>string</td>\n<td>Yes</td>\n<td>Human-readable job identifier</td>\n</tr>\n<tr>\n<td>CronExpression</td>\n<td>string</td>\n<td>Yes</td>\n<td>Valid cron timing specification</td>\n</tr>\n<tr>\n<td>Payload</td>\n<td>map[string]string</td>\n<td>Yes</td>\n<td>Job-specific execution parameters</td>\n</tr>\n<tr>\n<td>Priority</td>\n<td>int</td>\n<td>No</td>\n<td>Priority level (default: 0)</td>\n</tr>\n<tr>\n<td>IdempotencyKey</td>\n<td>string</td>\n<td>No</td>\n<td>Client-provided deduplication key</td>\n</tr>\n<tr>\n<td>MaxRetries</td>\n<td>int</td>\n<td>No</td>\n<td>Maximum retry attempts (default: 3)</td>\n</tr>\n<tr>\n<td>Capabilities</td>\n<td>[]string</td>\n<td>No</td>\n<td>Required worker capabilities</td>\n</tr>\n</tbody></table>\n<h4 id=\"deduplication-strategy-details\">Deduplication Strategy Details</h4>\n<p>The job submission flow implements sophisticated deduplication to prevent clients from accidentally creating duplicate work. The system uses a multi-layered approach combining idempotency keys and content hashing.</p>\n<blockquote>\n<p><strong>Decision: Idempotency Key vs Content Hash for Deduplication</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to prevent duplicate jobs while supporting both intentional and accidental resubmission scenarios</li>\n<li><strong>Options Considered</strong>: Client-provided keys only, automatic content hashing, hybrid approach</li>\n<li><strong>Decision</strong>: Primary idempotency keys with fallback content hashing</li>\n<li><strong>Rationale</strong>: Gives clients explicit control while providing automatic protection; content hashing catches unintentional duplicates</li>\n<li><strong>Consequences</strong>: More complex deduplication logic but better user experience and data integrity</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Deduplication Method</th>\n<th>When Applied</th>\n<th>Scope</th>\n<th>Duration</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Idempotency Key</td>\n<td>Client provides explicit key</td>\n<td>Exact key match</td>\n<td>Configurable TTL</td>\n</tr>\n<tr>\n<td>Content Hash</td>\n<td>Automatic for all jobs</td>\n<td>Identical payload + schedule</td>\n<td>24 hours default</td>\n</tr>\n<tr>\n<td>Name + Schedule</td>\n<td>Fallback protection</td>\n<td>Same name and cron pattern</td>\n<td>Until job completes</td>\n</tr>\n</tbody></table>\n<p>When deduplication detects an existing job, the system&#39;s response depends on the existing job&#39;s state:</p>\n<table>\n<thead>\n<tr>\n<th>Existing Job State</th>\n<th>Response Action</th>\n<th>HTTP Status</th>\n<th>Message to Client</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>PENDING or CLAIMED</td>\n<td>Return existing job</td>\n<td>200 OK</td>\n<td>Job already exists with ID</td>\n</tr>\n<tr>\n<td>EXECUTING</td>\n<td>Return existing job</td>\n<td>200 OK</td>\n<td>Job currently executing</td>\n</tr>\n<tr>\n<td>COMPLETED</td>\n<td>Create new job</td>\n<td>201 Created</td>\n<td>Previous job completed, created new</td>\n</tr>\n<tr>\n<td>FAILED</td>\n<td>Create new job</td>\n<td>201 Created</td>\n<td>Previous job failed, created retry</td>\n</tr>\n</tbody></table>\n<h4 id=\"error-handling-in-submission-flow\">Error Handling in Submission Flow</h4>\n<p>The submission flow must gracefully handle various error conditions while providing clear feedback to clients about what went wrong and how to fix it.</p>\n<table>\n<thead>\n<tr>\n<th>Error Condition</th>\n<th>Detection Point</th>\n<th>Recovery Action</th>\n<th>Client Response</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Invalid cron expression</td>\n<td>Parsing stage</td>\n<td>Reject with detailed error</td>\n<td>400 Bad Request with parse details</td>\n</tr>\n<tr>\n<td>Missing required fields</td>\n<td>Validation stage</td>\n<td>Reject with field list</td>\n<td>400 Bad Request with missing fields</td>\n</tr>\n<tr>\n<td>Storage unavailable</td>\n<td>Queue insertion</td>\n<td>Retry with backoff</td>\n<td>503 Service Unavailable</td>\n</tr>\n<tr>\n<td>Duplicate job detected</td>\n<td>Deduplication check</td>\n<td>Return existing job</td>\n<td>200 OK with existing job ID</td>\n</tr>\n<tr>\n<td>Priority out of range</td>\n<td>Validation stage</td>\n<td>Clamp to valid range</td>\n<td>200 OK with adjusted priority</td>\n</tr>\n</tbody></table>\n<h4 id=\"common-pitfalls-in-job-submission\">Common Pitfalls in Job Submission</h4>\n<p>⚠️ <strong>Pitfall: Race Condition in Deduplication</strong>\nDuring high-frequency submissions, two identical jobs might pass the deduplication check simultaneously if the check and insertion aren&#39;t atomic. This occurs because the deduplication query and queue insertion happen in separate operations, creating a window where duplicate jobs can both appear to be unique.</p>\n<p>The fix involves using atomic compare-and-set operations or database transactions to ensure the deduplication check and job insertion happen atomically. In Redis, this means using a Lua script that performs both operations as a single atomic unit.</p>\n<p>⚠️ <strong>Pitfall: Timezone Confusion in Scheduled Jobs</strong>\nClients often submit cron expressions assuming local timezone interpretation, but the scheduler stores everything in UTC. This causes jobs to run at unexpected times, especially around daylight saving time transitions.</p>\n<p>The solution requires explicit timezone handling in the submission API, either requiring clients to specify timezones explicitly or documenting that all times are treated as UTC. The cron parser should normalize all scheduled times to UTC immediately upon submission.</p>\n<h3 id=\"job-execution-flow\">Job Execution Flow</h3>\n<p>The job execution flow orchestrates the complex dance between coordinators and workers to ensure jobs run exactly once at the correct time with proper failure handling. This flow represents the core operational behavior of the distributed scheduler.</p>\n<p><img src=\"/api/project/job-scheduler/architecture-doc/asset?path=diagrams%2Fsystem-architecture.svg\" alt=\"System Architecture Overview\"></p>\n<p><img src=\"/api/project/job-scheduler/architecture-doc/asset?path=diagrams%2Fjob-execution-sequence.svg\" alt=\"Job Execution Sequence\"></p>\n<h4 id=\"execution-process-overview\">Execution Process Overview</h4>\n<p>Job execution involves four distinct phases: <strong>job readiness detection</strong>, <strong>worker assignment</strong>, <strong>execution monitoring</strong>, and <strong>completion handling</strong>. Each phase has specific responsibilities and failure modes that must be handled gracefully to maintain system reliability.</p>\n<p>The execution process operates continuously across multiple components:</p>\n<ol>\n<li><p><strong>Promotion Phase</strong>: The scheduler periodically scans for delayed jobs that have become eligible for execution, moving them from the delayed queue to the active priority queue.</p>\n</li>\n<li><p><strong>Assignment Phase</strong>: Available workers poll the coordinator for work, and the coordinator atomically assigns the highest-priority job to the most suitable worker.</p>\n</li>\n<li><p><strong>Execution Phase</strong>: The assigned worker executes the job while sending periodic heartbeats to maintain its lease on the work.</p>\n</li>\n<li><p><strong>Reporting Phase</strong>: The worker reports execution results back to the coordinator, which updates job state and triggers retry logic if necessary.</p>\n</li>\n</ol>\n<blockquote>\n<p><strong>Decision: Pull vs Push Job Assignment Model</strong></p>\n<ul>\n<li><strong>Context</strong>: Workers need job assignments, but the coordinator must maintain control over job distribution and prevent duplicate assignments</li>\n<li><strong>Options Considered</strong>: Coordinator pushes jobs to workers, workers pull jobs from coordinator, hybrid approach with notifications</li>\n<li><strong>Decision</strong>: Worker-initiated pull model with coordinator-managed assignment</li>\n<li><strong>Rationale</strong>: Pull model gives workers control over their capacity while preventing coordinator from overwhelming failed workers; atomic assignment prevents duplicates</li>\n<li><strong>Consequences</strong>: Requires worker polling but provides better load balancing and failure isolation; adds latency but improves reliability</li>\n</ul>\n</blockquote>\n<h4 id=\"job-state-machine-during-execution\">Job State Machine During Execution</h4>\n<p>Jobs transition through multiple states during the execution flow, with specific rules governing valid transitions and the actions triggered by each state change.</p>\n<table>\n<thead>\n<tr>\n<th>Current State</th>\n<th>Triggering Event</th>\n<th>Next State</th>\n<th>Actions Taken</th>\n<th>Responsible Component</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>PENDING</td>\n<td>Promotion timer fires</td>\n<td>PENDING</td>\n<td>Move to active queue</td>\n<td>Scheduler service</td>\n</tr>\n<tr>\n<td>PENDING</td>\n<td>Worker claims job</td>\n<td>CLAIMED</td>\n<td>Set WorkerID, ClaimedAt</td>\n<td>Priority queue</td>\n</tr>\n<tr>\n<td>CLAIMED</td>\n<td>Worker starts execution</td>\n<td>EXECUTING</td>\n<td>Set FencingToken</td>\n<td>Worker</td>\n</tr>\n<tr>\n<td>EXECUTING</td>\n<td>Worker reports success</td>\n<td>COMPLETED</td>\n<td>Set CompletedAt, cleanup</td>\n<td>Coordinator</td>\n</tr>\n<tr>\n<td>EXECUTING</td>\n<td>Worker reports failure</td>\n<td>FAILED</td>\n<td>Increment RetryCount</td>\n<td>Coordinator</td>\n</tr>\n<tr>\n<td>FAILED</td>\n<td>Retry available</td>\n<td>PENDING</td>\n<td>Reset state, new schedule</td>\n<td>Coordinator</td>\n</tr>\n<tr>\n<td>FAILED</td>\n<td>Max retries exceeded</td>\n<td>FAILED</td>\n<td>Final cleanup</td>\n<td>Coordinator</td>\n</tr>\n<tr>\n<td>CLAIMED/EXECUTING</td>\n<td>Worker heartbeat timeout</td>\n<td>PENDING</td>\n<td>Clear assignment</td>\n<td>Coordinator</td>\n</tr>\n</tbody></table>\n<h4 id=\"worker-job-claiming-process\">Worker Job Claiming Process</h4>\n<p>The job claiming process represents the critical handoff from the priority queue to an available worker. This process must be atomic to prevent duplicate assignments while being efficient enough to support high-throughput job processing.</p>\n<p>The claiming process follows these detailed steps:</p>\n<ol>\n<li><p><strong>Worker Availability Check</strong>: The worker evaluates its current capacity, checking that <code>CurrentJobs &lt; Capacity</code> and that it possesses any required capabilities for available jobs.</p>\n</li>\n<li><p><strong>Claim Request Submission</strong>: The worker sends a claim request to the coordinator containing its worker ID, current load information, and capability list.</p>\n</li>\n<li><p><strong>Coordinator Job Selection</strong>: The coordinator queries the priority queue for the highest-priority job that matches the worker&#39;s capabilities and hasn&#39;t exceeded its retry limits.</p>\n</li>\n<li><p><strong>Atomic Assignment</strong>: The coordinator uses a compare-and-swap operation to atomically assign the job to the worker, setting the <code>WorkerID</code> and generating a unique <code>FencingToken</code>.</p>\n</li>\n<li><p><strong>Lease Establishment</strong>: The system records the claim time and establishes a lease timeout, after which the job becomes eligible for reassignment if no progress is reported.</p>\n</li>\n<li><p><strong>Response Transmission</strong>: The coordinator returns the claimed job to the worker along with the fencing token that the worker must include in all subsequent operations on this job.</p>\n</li>\n</ol>\n<h4 id=\"fencing-token-mechanism\">Fencing Token Mechanism</h4>\n<p>The fencing token system prevents race conditions and ensures that only the legitimately assigned worker can report results for a job, even in the presence of network delays and worker failures.</p>\n<blockquote>\n<p><strong>Decision: Fencing Token Implementation Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Workers might report results after their lease has expired and the job has been reassigned to another worker</li>\n<li><strong>Options Considered</strong>: Monotonic sequence numbers, timestamp-based tokens, UUID-based tokens</li>\n<li><strong>Decision</strong>: Monotonic sequence numbers with coordinator-managed generation</li>\n<li><strong>Rationale</strong>: Sequence numbers provide clear ordering for conflict resolution; coordinator generation ensures uniqueness and prevents conflicts</li>\n<li><strong>Consequences</strong>: Requires coordinator state for token generation but provides strongest consistency guarantees</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Token Component</th>\n<th>Purpose</th>\n<th>Generation Strategy</th>\n<th>Validation Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Job ID</td>\n<td>Identifies specific job</td>\n<td>Client or system generated</td>\n<td>Database lookup</td>\n</tr>\n<tr>\n<td>Worker ID</td>\n<td>Identifies assigned worker</td>\n<td>Worker registration</td>\n<td>Active worker registry</td>\n</tr>\n<tr>\n<td>Sequence Number</td>\n<td>Prevents stale reports</td>\n<td>Monotonic increment</td>\n<td>Compare with stored value</td>\n</tr>\n<tr>\n<td>Assignment Time</td>\n<td>Establishes lease validity</td>\n<td>Coordinator timestamp</td>\n<td>Compare with current time</td>\n</tr>\n</tbody></table>\n<p>The fencing token validation process works as follows:</p>\n<ol>\n<li><strong>Token Extraction</strong>: The coordinator extracts the fencing token from the worker&#39;s completion report</li>\n<li><strong>Job State Verification</strong>: The system verifies that the job exists and is in a reportable state (<code>CLAIMED</code> or <code>EXECUTING</code>)</li>\n<li><strong>Worker Authority Check</strong>: The system confirms that the reporting worker matches the assigned worker ID</li>\n<li><strong>Sequence Validation</strong>: The system verifies that the sequence number matches the most recent assignment token</li>\n<li><strong>Lease Validity Check</strong>: The system confirms that the assignment hasn&#39;t expired based on the heartbeat timeout</li>\n</ol>\n<h4 id=\"execution-monitoring-and-heartbeats\">Execution Monitoring and Heartbeats</h4>\n<p>During job execution, the worker must maintain regular communication with the coordinator to prove it&#39;s making progress and hasn&#39;t failed. This monitoring system enables rapid detection of worker failures and prevents jobs from being lost.</p>\n<table>\n<thead>\n<tr>\n<th>Heartbeat Component</th>\n<th>Purpose</th>\n<th>Frequency</th>\n<th>Timeout Action</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Worker Liveness</td>\n<td>Proves worker is responsive</td>\n<td>Every 30 seconds</td>\n<td>Mark worker UNAVAILABLE</td>\n</tr>\n<tr>\n<td>Job Progress</td>\n<td>Shows execution is proceeding</td>\n<td>Every 60 seconds</td>\n<td>Reassign job to new worker</td>\n</tr>\n<tr>\n<td>Capacity Update</td>\n<td>Reports current job load</td>\n<td>With each heartbeat</td>\n<td>Update job assignment eligibility</td>\n</tr>\n<tr>\n<td>Capability Status</td>\n<td>Reports available features</td>\n<td>On change or every 5 minutes</td>\n<td>Update job matching criteria</td>\n</tr>\n</tbody></table>\n<p>The heartbeat message format includes comprehensive worker state information:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n<th>Required</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>WorkerID</td>\n<td>string</td>\n<td>Unique worker identifier</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>Timestamp</td>\n<td>time.Time</td>\n<td>When heartbeat was generated</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>CurrentJobs</td>\n<td>int</td>\n<td>Number of jobs currently executing</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>ExecutingJobIDs</td>\n<td>[]string</td>\n<td>List of job IDs in progress</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>Status</td>\n<td>string</td>\n<td>Worker operational status</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>Capabilities</td>\n<td>[]string</td>\n<td>Currently available worker capabilities</td>\n<td>No</td>\n</tr>\n<tr>\n<td>Metadata</td>\n<td>map[string]string</td>\n<td>Additional worker information</td>\n<td>No</td>\n</tr>\n</tbody></table>\n<h4 id=\"retry-logic-and-failure-handling\">Retry Logic and Failure Handling</h4>\n<p>When jobs fail or workers become unresponsive, the scheduler implements sophisticated retry logic that balances rapid recovery with system stability.</p>\n<blockquote>\n<p><strong>Decision: Exponential Backoff vs Fixed Interval Retries</strong></p>\n<ul>\n<li><strong>Context</strong>: Failed jobs need rescheduling, but immediate retries might overwhelm struggling resources</li>\n<li><strong>Options Considered</strong>: Immediate retry, fixed delay, exponential backoff, jittered exponential backoff</li>\n<li><strong>Decision</strong>: Jittered exponential backoff with maximum delay cap</li>\n<li><strong>Rationale</strong>: Exponential backoff reduces load on struggling resources; jitter prevents thundering herd; cap prevents indefinite delays</li>\n<li><strong>Consequences</strong>: More complex scheduling logic but better system stability and recovery characteristics</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Retry Attempt</th>\n<th>Delay Calculation</th>\n<th>Jitter Range</th>\n<th>Maximum Delay</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>2^1 = 2 seconds</td>\n<td>±50% (1-3 seconds)</td>\n<td>2 minutes</td>\n</tr>\n<tr>\n<td>2</td>\n<td>2^2 = 4 seconds</td>\n<td>±50% (2-6 seconds)</td>\n<td>2 minutes</td>\n</tr>\n<tr>\n<td>3</td>\n<td>2^3 = 8 seconds</td>\n<td>±50% (4-12 seconds)</td>\n<td>2 minutes</td>\n</tr>\n<tr>\n<td>4+</td>\n<td>2^4 = 16 seconds</td>\n<td>±50% (8-24 seconds)</td>\n<td>2 minutes</td>\n</tr>\n</tbody></table>\n<p>The retry system categorizes failures into different types with distinct handling strategies:</p>\n<table>\n<thead>\n<tr>\n<th>Failure Type</th>\n<th>Cause</th>\n<th>Retry Strategy</th>\n<th>Special Handling</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Transient Network</td>\n<td>Connection timeout</td>\n<td>Immediate retry</td>\n<td>None</td>\n</tr>\n<tr>\n<td>Resource Exhaustion</td>\n<td>Out of memory/disk</td>\n<td>Exponential backoff</td>\n<td>Route to different worker</td>\n</tr>\n<tr>\n<td>Logic Error</td>\n<td>Invalid job payload</td>\n<td>No retry</td>\n<td>Send to dead letter queue</td>\n</tr>\n<tr>\n<td>Worker Crash</td>\n<td>Process termination</td>\n<td>Exponential backoff</td>\n<td>Reassign to healthy worker</td>\n</tr>\n<tr>\n<td>Coordinator Failure</td>\n<td>Leadership change</td>\n<td>Wait for leader election</td>\n<td>Resume after new leader elected</td>\n</tr>\n</tbody></table>\n<h4 id=\"common-pitfalls-in-job-execution\">Common Pitfalls in Job Execution</h4>\n<p>⚠️ <strong>Pitfall: Duplicate Execution During Worker Recovery</strong>\nWhen a worker fails during job execution, the coordinator reassigns the job to a new worker. However, if the original worker recovers and completes the job, both workers might report completion, leading to duplicate processing or inconsistent state.</p>\n<p>This occurs because network partitions can make a worker appear failed when it&#39;s actually still processing. The worker continues execution while the coordinator reassigns the job elsewhere. The fencing token mechanism prevents this by ensuring only the worker with the current token can successfully report results.</p>\n<p>⚠️ <strong>Pitfall: Heartbeat Timeout During Long-Running Jobs</strong>\nJobs that take longer than the heartbeat timeout will be reassigned to new workers even though the original worker is still making progress. This creates wasteful duplicate work and can cause resource contention.</p>\n<p>The solution involves implementing job progress heartbeats separate from worker liveness heartbeats. Workers executing long jobs should send periodic progress updates that extend the job lease without requiring full job completion.</p>\n<p>⚠️ <strong>Pitfall: Lost Jobs During Coordinator Failover</strong>\nWhen the coordinator fails during job assignment, jobs might be claimed by workers but not properly recorded in the persistent store. These jobs exist only in coordinator memory and are lost during failover.</p>\n<p>Prevention requires ensuring all job state changes are persisted before sending responses to workers. The job assignment must be a transaction that atomically updates both the job state and the worker assignment records.</p>\n<h3 id=\"coordination-messages\">Coordination Messages</h3>\n<p>The coordination message system enables distributed operation by facilitating leader election, worker registration, failure detection, and job assignment across the scheduler cluster. These messages form the nervous system of the distributed scheduler.</p>\n<h4 id=\"message-categories-and-purposes\">Message Categories and Purposes</h4>\n<p>Coordination messages fall into four primary categories, each serving a specific aspect of distributed system management:</p>\n<table>\n<thead>\n<tr>\n<th>Category</th>\n<th>Purpose</th>\n<th>Frequency</th>\n<th>Reliability Requirements</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Leadership</td>\n<td>Leader election and status</td>\n<td>On leadership change</td>\n<td>Strong consistency required</td>\n</tr>\n<tr>\n<td>Registration</td>\n<td>Worker join/leave cluster</td>\n<td>On worker lifecycle events</td>\n<td>At-least-once delivery</td>\n</tr>\n<tr>\n<td>Heartbeat</td>\n<td>Failure detection and health monitoring</td>\n<td>Every 30-60 seconds</td>\n<td>Best-effort with timeout detection</td>\n</tr>\n<tr>\n<td>Assignment</td>\n<td>Job distribution and result reporting</td>\n<td>Per job execution</td>\n<td>Exactly-once with fencing</td>\n</tr>\n</tbody></table>\n<h4 id=\"leader-election-messages\">Leader Election Messages</h4>\n<p>Leader election messages coordinate the selection and maintenance of a single coordinator node responsible for job assignment and worker management. The election process must handle network partitions and prevent split-brain scenarios.</p>\n<blockquote>\n<p><strong>Decision: Raft vs ETCD vs Custom Leader Election</strong></p>\n<ul>\n<li><strong>Context</strong>: Need robust leader election that handles network partitions and prevents split-brain scenarios</li>\n<li><strong>Options Considered</strong>: Custom implementation, Raft consensus library, ETCD-based election</li>\n<li><strong>Decision</strong>: ETCD-based leader election with lease mechanism</li>\n<li><strong>Rationale</strong>: ETCD provides battle-tested consensus with lease-based leadership that automatically handles failures; reduces implementation complexity</li>\n<li><strong>Consequences</strong>: External dependency on ETCD but significantly more reliable than custom implementation; automatic failover and split-brain prevention</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Message Type</th>\n<th>Direction</th>\n<th>Trigger</th>\n<th>Contents</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>CandidateAnnouncement</td>\n<td>Node → ETCD</td>\n<td>Leadership vacancy</td>\n<td>Node ID, capabilities, priority</td>\n</tr>\n<tr>\n<td>LeadershipClaim</td>\n<td>ETCD → Nodes</td>\n<td>Election completion</td>\n<td>Leader node ID, lease expiration</td>\n</tr>\n<tr>\n<td>LeadershipRenewal</td>\n<td>Leader → ETCD</td>\n<td>Lease refresh</td>\n<td>Current leader ID, health status</td>\n</tr>\n<tr>\n<td>LeadershipTransfer</td>\n<td>Leader → ETCD</td>\n<td>Graceful shutdown</td>\n<td>New leader suggestion</td>\n</tr>\n</tbody></table>\n<p>The leader election process follows this sequence:</p>\n<ol>\n<li><strong>Vacancy Detection</strong>: Nodes detect leadership vacancy through ETCD watch mechanisms or lease expiration notifications</li>\n<li><strong>Candidate Registration</strong>: Eligible nodes register as candidates in ETCD with their capabilities and priority scores</li>\n<li><strong>Election Resolution</strong>: ETCD&#39;s consensus mechanism selects the leader based on predefined criteria (lowest node ID wins in case of ties)</li>\n<li><strong>Leadership Establishment</strong>: The elected leader establishes a lease and begins accepting job assignment responsibilities</li>\n<li><strong>Ongoing Maintenance</strong>: The leader periodically renews its lease while other nodes monitor for leadership changes</li>\n</ol>\n<h4 id=\"worker-registration-messages\">Worker Registration Messages</h4>\n<p>Worker registration messages handle the dynamic addition and removal of worker nodes from the cluster, enabling elastic scaling and graceful shutdown procedures.</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n<th>Validation Rules</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>WorkerID</td>\n<td>string</td>\n<td>Unique worker identifier</td>\n<td>Must be DNS-safe, 3-63 characters</td>\n</tr>\n<tr>\n<td>Address</td>\n<td>string</td>\n<td>Network address for communication</td>\n<td>Must be reachable from coordinator</td>\n</tr>\n<tr>\n<td>Capabilities</td>\n<td>[]string</td>\n<td>List of supported job types</td>\n<td>Each capability must match known types</td>\n</tr>\n<tr>\n<td>Capacity</td>\n<td>int</td>\n<td>Maximum concurrent jobs</td>\n<td>Must be positive integer</td>\n</tr>\n<tr>\n<td>Metadata</td>\n<td>map[string]string</td>\n<td>Additional worker information</td>\n<td>Optional key-value pairs</td>\n</tr>\n<tr>\n<td>StartedAt</td>\n<td>time.Time</td>\n<td>Worker startup timestamp</td>\n<td>Must be recent (within 5 minutes)</td>\n</tr>\n</tbody></table>\n<p>The worker registration process ensures new workers can join the cluster and contribute to job processing:</p>\n<ol>\n<li><strong>Initial Registration</strong>: New workers send registration messages to the current leader with their capabilities and capacity</li>\n<li><strong>Validation and Acceptance</strong>: The coordinator validates worker information and adds the worker to the active registry</li>\n<li><strong>Capability Matching</strong>: The system updates job assignment algorithms to consider the new worker&#39;s capabilities</li>\n<li><strong>Health Monitoring</strong>: The coordinator begins expecting regular heartbeats from the newly registered worker</li>\n<li><strong>Job Assignment Eligibility</strong>: The worker becomes eligible to receive job assignments based on its capacity and capabilities</li>\n</ol>\n<h4 id=\"heartbeat-message-protocol\">Heartbeat Message Protocol</h4>\n<p>The heartbeat protocol provides the foundation for failure detection and system health monitoring across the distributed cluster.</p>\n<table>\n<thead>\n<tr>\n<th>Message Component</th>\n<th>Size</th>\n<th>Purpose</th>\n<th>Update Frequency</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>WorkerID</td>\n<td>16 bytes</td>\n<td>Worker identification</td>\n<td>Never changes</td>\n</tr>\n<tr>\n<td>SequenceNumber</td>\n<td>8 bytes</td>\n<td>Message ordering</td>\n<td>Increments with each heartbeat</td>\n</tr>\n<tr>\n<td>Timestamp</td>\n<td>8 bytes</td>\n<td>Generation time</td>\n<td>Current time for each message</td>\n</tr>\n<tr>\n<td>JobStatus</td>\n<td>Variable</td>\n<td>Current job information</td>\n<td>Updates when jobs start/complete</td>\n</tr>\n<tr>\n<td>ResourceUsage</td>\n<td>32 bytes</td>\n<td>CPU, memory, disk usage</td>\n<td>Updated each heartbeat</td>\n</tr>\n</tbody></table>\n<p>The heartbeat message format provides comprehensive worker state information:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>HeartbeatMessage {\n    WorkerID: string\n    SequenceNumber: int64\n    Timestamp: time.Time\n    Status: WorkerState\n    CurrentJobs: int\n    ExecutingJobs: []JobProgress\n    ResourceUsage: ResourceMetrics\n    Capabilities: []string\n}\n\nJobProgress {\n    JobID: string\n    StartedAt: time.Time\n    Progress: float64  // 0.0 to 1.0\n    EstimatedCompletion: time.Time\n}\n\nResourceMetrics {\n    CPUPercent: float64\n    MemoryPercent: float64\n    DiskPercent: float64\n    NetworkBytesPerSecond: int64\n}</code></pre></div>\n\n<h4 id=\"job-assignment-messages\">Job Assignment Messages</h4>\n<p>Job assignment messages coordinate the handoff of work from the priority queue to available workers, including all necessary context for successful execution.</p>\n<blockquote>\n<p><strong>Decision: Message Format for Job Assignment</strong></p>\n<ul>\n<li><strong>Context</strong>: Job assignment must include complete execution context while minimizing network overhead</li>\n<li><strong>Options Considered</strong>: Full job serialization, reference-based with lookup, hybrid approach</li>\n<li><strong>Decision</strong>: Full job serialization with compressed payload</li>\n<li><strong>Rationale</strong>: Eliminates coordination dependencies during execution; worker has all necessary information locally</li>\n<li><strong>Consequences</strong>: Larger message size but better fault tolerance and simpler worker implementation</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Assignment Component</th>\n<th>Purpose</th>\n<th>Size Estimate</th>\n<th>Compression Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Job Metadata</td>\n<td>Identification and scheduling</td>\n<td>200 bytes</td>\n<td>None (small, structured)</td>\n</tr>\n<tr>\n<td>Execution Payload</td>\n<td>Job-specific parameters</td>\n<td>Variable</td>\n<td>gzip compression</td>\n</tr>\n<tr>\n<td>Worker Instructions</td>\n<td>Execution hints and requirements</td>\n<td>100 bytes</td>\n<td>None</td>\n</tr>\n<tr>\n<td>Fencing Information</td>\n<td>Authority and lease details</td>\n<td>64 bytes</td>\n<td>None</td>\n</tr>\n</tbody></table>\n<p>The complete job assignment message structure:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Required</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>JobID</td>\n<td>string</td>\n<td>Yes</td>\n<td>Unique job identifier</td>\n</tr>\n<tr>\n<td>FencingToken</td>\n<td>string</td>\n<td>Yes</td>\n<td>Authority token for this assignment</td>\n</tr>\n<tr>\n<td>WorkerID</td>\n<td>string</td>\n<td>Yes</td>\n<td>Target worker identifier</td>\n</tr>\n<tr>\n<td>JobDefinition</td>\n<td>Job</td>\n<td>Yes</td>\n<td>Complete job specification</td>\n</tr>\n<tr>\n<td>ExecutionHints</td>\n<td>map[string]string</td>\n<td>No</td>\n<td>Performance and resource hints</td>\n</tr>\n<tr>\n<td>LeaseExpiration</td>\n<td>time.Time</td>\n<td>Yes</td>\n<td>When assignment expires without progress</td>\n</tr>\n<tr>\n<td>RetryContext</td>\n<td>RetryInfo</td>\n<td>No</td>\n<td>Previous attempt information</td>\n</tr>\n</tbody></table>\n<p>The job assignment process ensures reliable work distribution:</p>\n<ol>\n<li><strong>Assignment Preparation</strong>: Coordinator selects highest-priority job and most suitable available worker</li>\n<li><strong>Token Generation</strong>: System generates unique fencing token linking job, worker, and assignment time</li>\n<li><strong>Atomic Assignment</strong>: Database transaction atomically assigns job and records assignment details</li>\n<li><strong>Message Transmission</strong>: Complete job assignment message sent to target worker</li>\n<li><strong>Acknowledgment Handling</strong>: Worker confirms receipt and begins execution preparation</li>\n<li><strong>Lease Monitoring</strong>: Coordinator tracks assignment lease and prepares for timeout handling</li>\n</ol>\n<h4 id=\"message-reliability-and-ordering\">Message Reliability and Ordering</h4>\n<p>The coordination message system must handle network failures, message loss, and out-of-order delivery while maintaining system correctness.</p>\n<table>\n<thead>\n<tr>\n<th>Message Type</th>\n<th>Delivery Guarantee</th>\n<th>Ordering Requirement</th>\n<th>Timeout Handling</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Leadership</td>\n<td>Exactly-once via ETCD</td>\n<td>Total ordering required</td>\n<td>ETCD manages timeouts</td>\n</tr>\n<tr>\n<td>Registration</td>\n<td>At-least-once</td>\n<td>No ordering requirement</td>\n<td>Retry with exponential backoff</td>\n</tr>\n<tr>\n<td>Heartbeat</td>\n<td>Best-effort</td>\n<td>Sequence number ordering</td>\n<td>Timeout triggers failure detection</td>\n</tr>\n<tr>\n<td>Assignment</td>\n<td>Exactly-once</td>\n<td>Per-job ordering only</td>\n<td>Reassignment after timeout</td>\n</tr>\n</tbody></table>\n<h4 id=\"common-pitfalls-in-coordination-messages\">Common Pitfalls in Coordination Messages</h4>\n<p>⚠️ <strong>Pitfall: Message Amplification During Network Partitions</strong>\nDuring network partitions, nodes might repeatedly retry coordination messages, creating message storms when connectivity is restored. This can overwhelm the coordination service and delay recovery.</p>\n<p>The solution involves implementing jittered exponential backoff for all coordination messages and rate limiting to prevent message storms. Additionally, nodes should use circuit breaker patterns to temporarily stop sending messages when the coordination service appears unavailable.</p>\n<p>⚠️ <strong>Pitfall: Stale Leadership Information</strong>\nWorkers might continue sending messages to a coordinator that has lost leadership, wasting resources and potentially missing important updates from the new leader.</p>\n<p>Prevention requires implementing leadership change notifications through ETCD watches, allowing workers to immediately redirect their coordination messages to the current leader. Workers should also include leadership generation numbers in messages to detect stale leadership.</p>\n<p>⚠️ <strong>Pitfall: Heartbeat Message Buildup</strong>\nIf the coordinator becomes temporarily unresponsive, heartbeat messages can accumulate in network buffers or message queues. When the coordinator recovers, processing this backlog can create false failure detections and unnecessary job reassignments.</p>\n<p>The fix involves implementing heartbeat message deduplication based on sequence numbers and timestamps. The coordinator should process only the most recent heartbeat from each worker and discard older messages to get an accurate view of current worker state.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Message Transport</td>\n<td>HTTP REST with JSON (net/http)</td>\n<td>gRPC with Protocol Buffers</td>\n</tr>\n<tr>\n<td>Message Queuing</td>\n<td>Direct HTTP calls with retries</td>\n<td>Redis pub/sub or Apache Kafka</td>\n</tr>\n<tr>\n<td>Coordination Store</td>\n<td>Redis with atomic operations</td>\n<td>ETCD with watches and leases</td>\n</tr>\n<tr>\n<td>Serialization</td>\n<td>JSON encoding/decoding</td>\n<td>Protocol Buffers or MessagePack</td>\n</tr>\n<tr>\n<td>Load Balancing</td>\n<td>Round-robin with health checks</td>\n<td>Weighted least-connections</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>internal/coordination/\n  coordinator.go           ← main coordinator logic\n  coordinator_test.go      ← coordinator unit tests\n  messages.go             ← message type definitions\n  election.go             ← leader election implementation\n  heartbeat.go            ← heartbeat handling logic\n  assignment.go           ← job assignment coordination\n  \ninternal/transport/\n  http_client.go          ← HTTP client wrapper\n  http_server.go          ← HTTP server with routing\n  grpc_client.go          ← gRPC client (optional)\n  grpc_server.go          ← gRPC server (optional)\n  \ninternal/messaging/\n  publisher.go            ← message publishing interface\n  subscriber.go           ← message subscription interface\n  redis_transport.go      ← Redis-based message transport\n  \ncmd/coordinator/\n  main.go                ← coordinator service entry point\n  \ncmd/worker/\n  main.go                ← worker service entry point</code></pre></div>\n\n<h4 id=\"core-message-handling-infrastructure\">Core Message Handling Infrastructure</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// Message transport abstraction for testing and flexibility</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> MessageTransport</span><span style=\"color:#F97583\"> interface</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    SendMessage</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">target</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">message</span><span style=\"color:#B392F0\"> Message</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    ReceiveMessages</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">handler</span><span style=\"color:#B392F0\"> MessageHandler</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    Subscribe</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">topic</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">handler</span><span style=\"color:#B392F0\"> MessageHandler</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    Close</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">error</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Base message interface implemented by all coordination messages</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> Message</span><span style=\"color:#F97583\"> interface</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    Type</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#B392F0\">MessageType</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    Target</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    Payload</span><span style=\"color:#E1E4E8\">() []</span><span style=\"color:#F97583\">byte</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    Validate</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">error</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// HTTP-based message transport implementation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> HTTPTransport</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    client    </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">http</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Client</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    server    </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">http</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Server</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    handlers  </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#B392F0\">MessageType</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#B392F0\">MessageHandler</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    logger    </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">log</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Logger</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewHTTPTransport</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">port</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">HTTPTransport</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">HTTPTransport</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        client: </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#B392F0\">http</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Client</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            Timeout: </span><span style=\"color:#79B8FF\">10</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\"> time.Second,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            Transport: </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#B392F0\">http</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Transport</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                MaxIdleConns:       </span><span style=\"color:#79B8FF\">100</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                IdleConnTimeout:    </span><span style=\"color:#79B8FF\">90</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\"> time.Second,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                DisableCompression: </span><span style=\"color:#79B8FF\">false</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            },</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        },</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        handlers: </span><span style=\"color:#B392F0\">make</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#B392F0\">MessageType</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#B392F0\">MessageHandler</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        logger:   log.</span><span style=\"color:#B392F0\">New</span><span style=\"color:#E1E4E8\">(os.Stdout, </span><span style=\"color:#9ECBFF\">\"[TRANSPORT] \"</span><span style=\"color:#E1E4E8\">, log.LstdFlags),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">t </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">HTTPTransport</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">SendMessage</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">target</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">message</span><span style=\"color:#B392F0\"> Message</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    payload </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> bytes.</span><span style=\"color:#B392F0\">NewBuffer</span><span style=\"color:#E1E4E8\">(message.</span><span style=\"color:#B392F0\">Payload</span><span style=\"color:#E1E4E8\">())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    req, err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> http.</span><span style=\"color:#B392F0\">NewRequestWithContext</span><span style=\"color:#E1E4E8\">(ctx, </span><span style=\"color:#9ECBFF\">\"POST\"</span><span style=\"color:#E1E4E8\">, target, payload)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"failed to create request: </span><span style=\"color:#79B8FF\">%w</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    req.Header.</span><span style=\"color:#B392F0\">Set</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Content-Type\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"application/json\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    req.Header.</span><span style=\"color:#B392F0\">Set</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Message-Type\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">(message.</span><span style=\"color:#B392F0\">Type</span><span style=\"color:#E1E4E8\">()))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    resp, err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> t.client.</span><span style=\"color:#B392F0\">Do</span><span style=\"color:#E1E4E8\">(req)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"failed to send message: </span><span style=\"color:#79B8FF\">%w</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> resp.Body.</span><span style=\"color:#B392F0\">Close</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> resp.StatusCode </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> 400</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        body, _ </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> io.</span><span style=\"color:#B392F0\">ReadAll</span><span style=\"color:#E1E4E8\">(resp.Body)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Errorf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"message rejected: status=</span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#9ECBFF\">, body=</span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, resp.StatusCode, </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">(body))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Message handler function type</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> MessageHandler</span><span style=\"color:#F97583\"> func</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">message</span><span style=\"color:#B392F0\"> Message</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Message routing and validation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">t </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">HTTPTransport</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">handleHTTPMessage</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">w</span><span style=\"color:#B392F0\"> http</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">ResponseWriter</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">r</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">http</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Request</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    msgType </span><span style=\"color:#F97583\">:=</span><span style=\"color:#B392F0\"> MessageType</span><span style=\"color:#E1E4E8\">(r.Header.</span><span style=\"color:#B392F0\">Get</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Message-Type\"</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    handler, exists </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> t.handlers[msgType]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> !</span><span style=\"color:#E1E4E8\">exists {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        http.</span><span style=\"color:#B392F0\">Error</span><span style=\"color:#E1E4E8\">(w, </span><span style=\"color:#9ECBFF\">\"Unknown message type\"</span><span style=\"color:#E1E4E8\">, http.StatusBadRequest)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    body, err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> io.</span><span style=\"color:#B392F0\">ReadAll</span><span style=\"color:#E1E4E8\">(r.Body)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        http.</span><span style=\"color:#B392F0\">Error</span><span style=\"color:#E1E4E8\">(w, </span><span style=\"color:#9ECBFF\">\"Failed to read body\"</span><span style=\"color:#E1E4E8\">, http.StatusBadRequest)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    message, err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#B392F0\"> DeserializeMessage</span><span style=\"color:#E1E4E8\">(msgType, body)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        http.</span><span style=\"color:#B392F0\">Error</span><span style=\"color:#E1E4E8\">(w, fmt.</span><span style=\"color:#B392F0\">Sprintf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Failed to deserialize: </span><span style=\"color:#79B8FF\">%v</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, err), http.StatusBadRequest)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> message.</span><span style=\"color:#B392F0\">Validate</span><span style=\"color:#E1E4E8\">(); err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        http.</span><span style=\"color:#B392F0\">Error</span><span style=\"color:#E1E4E8\">(w, fmt.</span><span style=\"color:#B392F0\">Sprintf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Invalid message: </span><span style=\"color:#79B8FF\">%v</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, err), http.StatusBadRequest)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ctx, cancel </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> context.</span><span style=\"color:#B392F0\">WithTimeout</span><span style=\"color:#E1E4E8\">(r.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">(), </span><span style=\"color:#79B8FF\">30</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">time.Second)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#B392F0\"> cancel</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#B392F0\"> handler</span><span style=\"color:#E1E4E8\">(ctx, message); err </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        t.logger.</span><span style=\"color:#B392F0\">Printf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Handler error: </span><span style=\"color:#79B8FF\">%v</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        http.</span><span style=\"color:#B392F0\">Error</span><span style=\"color:#E1E4E8\">(w, </span><span style=\"color:#9ECBFF\">\"Processing failed\"</span><span style=\"color:#E1E4E8\">, http.StatusInternalServerError)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    w.</span><span style=\"color:#B392F0\">WriteHeader</span><span style=\"color:#E1E4E8\">(http.StatusOK)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"job-assignment-message-implementation\">Job Assignment Message Implementation</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// Complete job assignment message structure</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> JobAssignmentMessage</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    MessageID      </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">                 `json:\"message_id\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    JobID          </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">                 `json:\"job_id\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    WorkerID       </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">                 `json:\"worker_id\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    FencingToken   </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">                 `json:\"fencing_token\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Job            </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">Job</span><span style=\"color:#9ECBFF\">                   `json:\"job\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ExecutionHints </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">      `json:\"execution_hints,omitempty\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LeaseExpiration </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">             `json:\"lease_expiration\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    RetryContext   </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">RetryInfo</span><span style=\"color:#9ECBFF\">             `json:\"retry_context,omitempty\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Timestamp      </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">              `json:\"timestamp\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">m </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">JobAssignmentMessage</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Type</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#B392F0\">MessageType</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> MessageTypeJobAssignment</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">m </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">JobAssignmentMessage</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Target</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> m.WorkerID  </span><span style=\"color:#6A737D\">// Message is targeted at specific worker</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">m </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">JobAssignmentMessage</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Payload</span><span style=\"color:#E1E4E8\">() []</span><span style=\"color:#F97583\">byte</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    data, _ </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> json.</span><span style=\"color:#B392F0\">Marshal</span><span style=\"color:#E1E4E8\">(m)  </span><span style=\"color:#6A737D\">// Handle error in production</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> data</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">m </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">JobAssignmentMessage</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Validate</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> m.JobID </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> errors.</span><span style=\"color:#B392F0\">New</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"job_id is required\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> m.WorkerID </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> errors.</span><span style=\"color:#B392F0\">New</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"worker_id is required\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> m.FencingToken </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> errors.</span><span style=\"color:#B392F0\">New</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"fencing_token is required\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> m.Job </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> nil</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> errors.</span><span style=\"color:#B392F0\">New</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"job definition is required\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> m.LeaseExpiration.</span><span style=\"color:#B392F0\">Before</span><span style=\"color:#E1E4E8\">(time.</span><span style=\"color:#B392F0\">Now</span><span style=\"color:#E1E4E8\">()) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> errors.</span><span style=\"color:#B392F0\">New</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"lease_expiration must be in the future\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Job assignment coordination logic</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> JobAssigner</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    transport    </span><span style=\"color:#B392F0\">MessageTransport</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    queue        </span><span style=\"color:#B392F0\">PriorityQueue</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    workers      </span><span style=\"color:#B392F0\">WorkerRegistry</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    tokenGen     </span><span style=\"color:#B392F0\">FencingTokenGenerator</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    logger       </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">log</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Logger</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">a </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">JobAssigner</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">AssignJobToWorker</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">workerID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Query priority queue for highest-priority job matching worker capabilities</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Generate unique fencing token for this assignment</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Atomically claim job and update state to CLAIMED</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Create job assignment message with complete job context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Send assignment message to target worker</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Record assignment in persistent storage for failure recovery</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Start lease expiration timer for automatic reassignment</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use database transactions to ensure atomic job claiming</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Include retry context if this job has failed before</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"heartbeat-protocol-implementation\">Heartbeat Protocol Implementation</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// Comprehensive heartbeat message structure</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> HeartbeatMessage</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    WorkerID        </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">             `json:\"worker_id\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    SequenceNumber  </span><span style=\"color:#F97583\">int64</span><span style=\"color:#9ECBFF\">              `json:\"sequence_number\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Timestamp       </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">          `json:\"timestamp\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Status          </span><span style=\"color:#B392F0\">WorkerState</span><span style=\"color:#9ECBFF\">        `json:\"status\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CurrentJobs     </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">                `json:\"current_jobs\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ExecutingJobs   []</span><span style=\"color:#B392F0\">JobProgress</span><span style=\"color:#9ECBFF\">      `json:\"executing_jobs\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ResourceUsage   </span><span style=\"color:#B392F0\">ResourceMetrics</span><span style=\"color:#9ECBFF\">    `json:\"resource_usage\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Capabilities    []</span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">           `json:\"capabilities\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Metadata        </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">  `json:\"metadata,omitempty\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> JobProgress</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    JobID               </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">     `json:\"job_id\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    StartedAt           </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">  `json:\"started_at\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Progress            </span><span style=\"color:#F97583\">float64</span><span style=\"color:#9ECBFF\">    `json:\"progress\"`</span><span style=\"color:#6A737D\">          // 0.0 to 1.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    EstimatedCompletion </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">  `json:\"estimated_completion\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Status              </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">     `json:\"status\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> ResourceMetrics</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CPUPercent            </span><span style=\"color:#F97583\">float64</span><span style=\"color:#9ECBFF\"> `json:\"cpu_percent\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    MemoryPercent         </span><span style=\"color:#F97583\">float64</span><span style=\"color:#9ECBFF\"> `json:\"memory_percent\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    DiskPercent           </span><span style=\"color:#F97583\">float64</span><span style=\"color:#9ECBFF\"> `json:\"disk_percent\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    NetworkBytesPerSecond </span><span style=\"color:#F97583\">int64</span><span style=\"color:#9ECBFF\">   `json:\"network_bytes_per_second\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">m </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">HeartbeatMessage</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Type</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#B392F0\">MessageType</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> MessageTypeHeartbeat</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">m </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">HeartbeatMessage</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Target</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#9ECBFF\"> \"coordinator\"</span><span style=\"color:#6A737D\">  // Always sent to current coordinator</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">m </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">HeartbeatMessage</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Payload</span><span style=\"color:#E1E4E8\">() []</span><span style=\"color:#F97583\">byte</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    data, _ </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> json.</span><span style=\"color:#B392F0\">Marshal</span><span style=\"color:#E1E4E8\">(m)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> data</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">m </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">HeartbeatMessage</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Validate</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> m.WorkerID </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> errors.</span><span style=\"color:#B392F0\">New</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"worker_id is required\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> m.SequenceNumber </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> errors.</span><span style=\"color:#B392F0\">New</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"sequence_number must be positive\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> time.</span><span style=\"color:#B392F0\">Since</span><span style=\"color:#E1E4E8\">(m.Timestamp) </span><span style=\"color:#F97583\">></span><span style=\"color:#E1E4E8\"> time.Minute {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> errors.</span><span style=\"color:#B392F0\">New</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"timestamp is too old\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> m.CurrentJobs </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> errors.</span><span style=\"color:#B392F0\">New</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"current_jobs cannot be negative\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Heartbeat handling on coordinator side</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> HeartbeatProcessor</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    workers     </span><span style=\"color:#B392F0\">WorkerRegistry</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    jobRecovery </span><span style=\"color:#B392F0\">JobRecoveryService</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    logger      </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">log</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Logger</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    mutex       </span><span style=\"color:#B392F0\">sync</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">RWMutex</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">p </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">HeartbeatProcessor</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">ProcessHeartbeat</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">message</span><span style=\"color:#B392F0\"> Message</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    heartbeat, ok </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> message.(</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">HeartbeatMessage</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> !</span><span style=\"color:#E1E4E8\">ok {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> errors.</span><span style=\"color:#B392F0\">New</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"invalid message type for heartbeat processor\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Validate heartbeat message format and freshness</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Look up worker in registry and check sequence number ordering</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Update worker state with current capacity and job information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Reset worker failure detection timer</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Update job progress information for executing jobs</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Check for any jobs that need progress updates</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Respond with any pending assignments or commands for worker</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use atomic operations when updating worker state</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Log sequence number gaps as potential message loss</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"message-flow-orchestration\">Message Flow Orchestration</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// End-to-end job execution flow coordinator</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> ExecutionFlowCoordinator</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    transport   </span><span style=\"color:#B392F0\">MessageTransport</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    queue       </span><span style=\"color:#B392F0\">PriorityQueue</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    workers     </span><span style=\"color:#B392F0\">WorkerRegistry</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    storage     </span><span style=\"color:#B392F0\">Storage</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    config      </span><span style=\"color:#B392F0\">CoordinatorConfig</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    logger      </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">log</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Logger</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">ExecutionFlowCoordinator</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">StartJobExecutionFlow</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Start goroutine for job promotion (delayed -> active queue)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Start goroutine for worker heartbeat monitoring</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Start goroutine for job assignment processing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Start goroutine for completion report handling</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Set up signal handling for graceful shutdown</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use context cancellation to coordinate shutdown</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Implement proper error handling and restart logic for each goroutine</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">c </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">ExecutionFlowCoordinator</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">handleJobCompletion</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">message</span><span style=\"color:#B392F0\"> Message</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    completion, ok </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> message.(</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">JobCompletionMessage</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> !</span><span style=\"color:#E1E4E8\">ok {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> errors.</span><span style=\"color:#B392F0\">New</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"invalid message type\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Validate fencing token to ensure worker authority</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Update job state based on completion result (success/failure)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Handle retry logic if job failed and retries remain</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Clean up worker assignment and update capacity</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Trigger next scheduled execution for recurring jobs</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Send completion notification to job submission client</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use database transactions for state updates</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Implement dead letter queue for jobs that exhaust retries</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p><strong>Checkpoint 1: Basic Message Transport</strong></p>\n<ul>\n<li>Run: <code>go test ./internal/transport/... -v</code></li>\n<li>Expected: All message serialization and HTTP transport tests pass</li>\n<li>Manual verification: Start coordinator and worker, send test heartbeat message</li>\n<li>Success indicator: Worker successfully registers and sends first heartbeat</li>\n</ul>\n<p><strong>Checkpoint 2: Job Assignment Flow</strong></p>\n<ul>\n<li>Run: <code>go test ./internal/coordination/... -v -run TestJobAssignment</code></li>\n<li>Expected: Job assignment messages are properly formatted and delivered</li>\n<li>Manual verification: Submit test job, verify worker receives assignment message</li>\n<li>Success indicator: Job transitions from PENDING to CLAIMED state</li>\n</ul>\n<p><strong>Checkpoint 3: End-to-End Execution</strong></p>\n<ul>\n<li>Run: <code>go run cmd/coordinator/main.go &amp; go run cmd/worker/main.go</code></li>\n<li>Expected: Complete job submission through execution and completion reporting</li>\n<li>Manual verification: Submit job via API, monitor logs for execution flow</li>\n<li>Success indicator: Job completes successfully and reports back to coordinator</li>\n</ul>\n<h2 id=\"error-handling-and-edge-cases\">Error Handling and Edge Cases</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section covers error handling patterns that apply across all three milestones - cron parsing failures (Milestone 1), queue operation failures (Milestone 2), and worker coordination failures (Milestone 3). The distributed nature of the system requires sophisticated failure detection and recovery mechanisms to maintain consistency and availability.</p>\n</blockquote>\n<p>The distributed job scheduler operates in an environment where failures are inevitable rather than exceptional. Like a city&#39;s emergency response system that must function despite individual component failures, our scheduler requires comprehensive error handling that prevents cascading failures and ensures graceful degradation. This section explores the failure modes inherent in distributed systems and establishes recovery strategies that maintain operational consistency while maximizing availability.</p>\n<h3 id=\"mental-model-emergency-response-coordination\">Mental Model: Emergency Response Coordination</h3>\n<p>Think of error handling in a distributed job scheduler as coordinating emergency services across a city. Just as fire departments, police, and hospitals must maintain service during equipment failures, network outages, and staff shortages, our scheduler must continue operating when workers crash, networks partition, or coordination services become unavailable. The key insight is that <strong>failure is not binary</strong> - systems fail partially, intermittently, and in complex combinations that require nuanced responses rather than simple retry logic.</p>\n<p>Emergency services use several principles that apply directly to our distributed scheduler: <strong>redundancy</strong> (multiple fire stations), <strong>failure detection</strong> (911 dispatch monitoring), <strong>resource reallocation</strong> (sending backup units when primary responds are unavailable), and <strong>graceful degradation</strong> (reduced service levels rather than complete shutdown). Our error handling strategy implements these same patterns through worker redundancy, heartbeat monitoring, job reassignment, and priority-based service reduction.</p>\n<h3 id=\"failure-modes\">Failure Modes</h3>\n<p>Distributed systems exhibit failure patterns that rarely occur in single-node applications. Understanding these failure modes enables us to design detection and recovery mechanisms that maintain system integrity despite component failures.</p>\n<blockquote>\n<p><strong>Decision: Failure Classification Taxonomy</strong></p>\n<ul>\n<li><strong>Context</strong>: Distributed job scheduler experiences various failure types requiring different detection and recovery strategies</li>\n<li><strong>Options Considered</strong>: Binary fail/success model, Component-level categorization, Impact-based classification</li>\n<li><strong>Decision</strong>: Multi-dimensional failure taxonomy based on scope, duration, and detectability</li>\n<li><strong>Rationale</strong>: Enables targeted recovery strategies and prevents over-engineering simple failure cases</li>\n<li><strong>Consequences</strong>: More complex error handling logic but much better system resilience and recovery times</li>\n</ul>\n</blockquote>\n<h4 id=\"network-partition-failures\">Network Partition Failures</h4>\n<p>Network partitions represent the most challenging failure mode because they create <strong>split-brain scenarios</strong> where different parts of the system have inconsistent views of reality. Unlike clean failures where components stop responding entirely, partitions create zones of connectivity where nodes within a zone can communicate but cannot reach nodes in other zones.</p>\n<table>\n<thead>\n<tr>\n<th>Partition Scenario</th>\n<th>Symptoms</th>\n<th>Impact</th>\n<th>Detection Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Coordinator-Worker Partition</td>\n<td>Workers cannot send heartbeats; coordinator sees mass worker failure</td>\n<td>Job assignment stops; workers continue executing claimed jobs</td>\n<td>Heartbeat timeout; workers cannot reach coordination service</td>\n</tr>\n<tr>\n<td>Inter-Worker Partition</td>\n<td>Workers isolated from each other but connected to coordinator</td>\n<td>Load balancing becomes ineffective; some workers overloaded</td>\n<td>Job claim patterns show uneven distribution</td>\n</tr>\n<tr>\n<td>Coordination Service Partition</td>\n<td>Cannot access etcd/Redis cluster</td>\n<td>All coordination stops; system freezes</td>\n<td>Connection timeouts to backing services</td>\n</tr>\n<tr>\n<td>Client-Scheduler Partition</td>\n<td>Job submission requests fail</td>\n<td>New jobs cannot be submitted</td>\n<td>HTTP/gRPC connection failures</td>\n</tr>\n</tbody></table>\n<p>The <strong>Byzantine nature</strong> of network partitions means that different components may observe different failure patterns simultaneously. A coordinator might lose connectivity to half its workers while maintaining connectivity to the coordination service, creating a scenario where the coordinator attempts to reassign jobs from healthy workers it cannot communicate with.</p>\n<p><strong>Partition detection</strong> relies on timeout-based mechanisms combined with <strong>fencing tokens</strong> to prevent stale operations. When a coordinator loses communication with a worker, it cannot immediately determine whether the worker failed or a network partition occurred. The coordinator must wait for a timeout period before declaring the worker failed and reassigning its jobs. However, if the worker is healthy but partitioned, it may complete its current job and attempt to report completion after the coordinator has already reassigned the job to another worker.</p>\n<h4 id=\"worker-crash-failures\">Worker Crash Failures</h4>\n<p>Worker failures manifest in several distinct patterns, each requiring different detection and recovery strategies. Unlike network partitions where the worker may still be processing jobs, crash failures represent complete worker unavailability.</p>\n<table>\n<thead>\n<tr>\n<th>Failure Type</th>\n<th>Characteristics</th>\n<th>Detection Latency</th>\n<th>Recovery Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Hard Crash</td>\n<td>Process terminates immediately</td>\n<td>Next heartbeat interval</td>\n<td>Immediate job reassignment</td>\n</tr>\n<tr>\n<td>Graceful Shutdown</td>\n<td>Worker completes current jobs before stopping</td>\n<td>Worker sends shutdown signal</td>\n<td>Allow completion, then reassign remaining</td>\n</tr>\n<tr>\n<td>Resource Exhaustion</td>\n<td>Worker becomes unresponsive due to memory/CPU limits</td>\n<td>Heartbeat timeout or health check failure</td>\n<td>Restart worker, reassign jobs</td>\n</tr>\n<tr>\n<td>Dependency Failure</td>\n<td>External service unavailable (database, API)</td>\n<td>Job execution failures</td>\n<td>Retry with backoff, possibly reassign</td>\n</tr>\n</tbody></table>\n<p><strong>Crash detection</strong> combines multiple signals to distinguish between different failure types. The primary mechanism is <strong>heartbeat timeout</strong>, where workers must send periodic liveness signals to the coordinator. However, heartbeat timeout alone cannot distinguish between a crashed worker and a temporarily overloaded worker that cannot send heartbeats promptly.</p>\n<p>The coordinator implements <strong>graduated failure detection</strong> that escalates response based on failure duration:</p>\n<ol>\n<li><strong>Initial timeout (30 seconds)</strong>: Mark worker as potentially unavailable, stop assigning new jobs</li>\n<li><strong>Extended timeout (2 minutes)</strong>: Attempt direct health check to worker endpoint</li>\n<li><strong>Failure confirmation (5 minutes)</strong>: Declare worker failed, begin job reassignment process</li>\n<li><strong>Cleanup timeout (10 minutes)</strong>: Remove worker from active pool, clean up metadata</li>\n</ol>\n<p>This graduated approach prevents <strong>flapping</strong>, where temporary network hiccups cause repeated job reassignments that waste resources and potentially violate exactly-once execution guarantees.</p>\n<h4 id=\"coordination-service-outages\">Coordination Service Outages</h4>\n<p>The coordination service (etcd or Redis cluster) represents a <strong>single point of failure</strong> for cluster-wide operations despite being internally distributed. While etcd and Redis provide their own fault tolerance, they can still become unavailable from the scheduler&#39;s perspective due to network issues, resource exhaustion, or configuration problems.</p>\n<table>\n<thead>\n<tr>\n<th>Service</th>\n<th>Outage Impact</th>\n<th>Mitigation Strategy</th>\n<th>Recovery Process</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>etcd Leader Election</td>\n<td>Cannot elect new coordinator; current coordinator continues</td>\n<td>Local coordinator state caching</td>\n<td>Retry election with exponential backoff</td>\n</tr>\n<tr>\n<td>etcd Job Metadata</td>\n<td>Cannot update job states</td>\n<td>Write-ahead logging to local storage</td>\n<td>Replay logs when connectivity restored</td>\n</tr>\n<tr>\n<td>Redis Priority Queue</td>\n<td>Cannot enqueue/dequeue jobs</td>\n<td>Local job buffer with overflow to disk</td>\n<td>Drain buffer to Redis when available</td>\n</tr>\n<tr>\n<td>Redis Deduplication</td>\n<td>Cannot prevent duplicate submissions</td>\n<td>Accept duplicates temporarily</td>\n<td>Post-recovery deduplication scan</td>\n</tr>\n</tbody></table>\n<p><strong>Coordination service failures</strong> require the scheduler to operate in <strong>degraded mode</strong> rather than stopping entirely. The system maintains local state and implements <strong>write-ahead logging</strong> to ensure that state changes during the outage can be replayed when connectivity is restored.</p>\n<p>The most critical challenge is <strong>preventing split-brain scenarios</strong> during coordination service outages. If the current coordinator leader loses connectivity to etcd but workers can still reach etcd, a new coordinator may be elected while the original coordinator continues operating. This scenario requires <strong>fencing tokens</strong> that increment with each leader election, ensuring that operations from stale coordinators are rejected.</p>\n<p>⚠️ <strong>Pitfall: Coordination Service Timeout Configuration</strong>\nSetting coordination service timeouts too aggressively causes false positives where temporary network delays trigger unnecessary failover procedures. However, setting timeouts too conservatively delays failure detection and prolongs service degradation. The timeout values must account for network latency variance, service processing time, and the cost of false positives versus false negatives. A common mistake is using the same timeout values for different operation types - leader election can tolerate longer timeouts than job state updates.</p>\n<h3 id=\"retry-strategies\">Retry Strategies</h3>\n<p>Retry logic in distributed systems requires sophisticated strategies that account for failure types, system load, and consistency requirements. Unlike simple HTTP retries, our job scheduler must implement <strong>differentiated retry strategies</strong> that prevent retry storms while ensuring forward progress.</p>\n<blockquote>\n<p><strong>Decision: Retry Strategy Framework</strong></p>\n<ul>\n<li><strong>Context</strong>: Different failure types require different retry approaches to balance reliability with system stability</li>\n<li><strong>Options Considered</strong>: Universal exponential backoff, Per-operation retry logic, Adaptive retry with feedback</li>\n<li><strong>Decision</strong>: Hierarchical retry framework with operation-specific strategies and system-wide backpressure</li>\n<li><strong>Rationale</strong>: Provides fine-grained control while preventing retry amplification and cascading failures</li>\n<li><strong>Consequences</strong>: More complex implementation but much better system stability under load</li>\n</ul>\n</blockquote>\n<h4 id=\"exponential-backoff-implementation\">Exponential Backoff Implementation</h4>\n<p><strong>Exponential backoff</strong> forms the foundation of our retry strategy but requires careful tuning to prevent <strong>retry amplification</strong> where multiple components retrying simultaneously create artificial load spikes that prevent recovery.</p>\n<table>\n<thead>\n<tr>\n<th>Retry Scenario</th>\n<th>Initial Delay</th>\n<th>Backoff Factor</th>\n<th>Max Delay</th>\n<th>Max Attempts</th>\n<th>Jitter</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Heartbeat Transmission</td>\n<td>1 second</td>\n<td>2.0</td>\n<td>30 seconds</td>\n<td>5</td>\n<td>±20%</td>\n</tr>\n<tr>\n<td>Job State Update</td>\n<td>100ms</td>\n<td>1.5</td>\n<td>10 seconds</td>\n<td>8</td>\n<td>±25%</td>\n</tr>\n<tr>\n<td>Worker Registration</td>\n<td>5 seconds</td>\n<td>2.0</td>\n<td>5 minutes</td>\n<td>3</td>\n<td>±30%</td>\n</tr>\n<tr>\n<td>Coordination Service Connection</td>\n<td>2 seconds</td>\n<td>1.8</td>\n<td>2 minutes</td>\n<td>10</td>\n<td>±15%</td>\n</tr>\n</tbody></table>\n<p>The <strong>jitter component</strong> prevents <strong>thundering herd</strong> scenarios where multiple workers retry simultaneously after a shared dependency recovers. Each retry delay includes random variation: <code>actual_delay = base_delay * (1 + jitter * random(-1, 1))</code>.</p>\n<p><strong>Backoff calculation</strong> follows the formula: <code>delay = min(initial_delay * (backoff_factor ^ attempt), max_delay)</code>. However, our implementation includes <strong>circuit breaker</strong> logic that suspends retries when failure rates exceed thresholds, preventing resources from being consumed by operations that are unlikely to succeed.</p>\n<p>The retry framework implements <strong>differentiated strategies</strong> based on operation criticality:</p>\n<ol>\n<li><strong>Critical operations</strong> (job completion reports): Aggressive retries with local persistence and manual intervention escalation</li>\n<li><strong>Important operations</strong> (heartbeats): Moderate retries with graceful degradation when max attempts exceeded</li>\n<li><strong>Best-effort operations</strong> (metrics reporting): Limited retries with silent failure after max attempts</li>\n<li><strong>Background operations</strong> (cleanup tasks): Infrequent retries with extended backoff periods</li>\n</ol>\n<h4 id=\"maximum-attempts-and-escalation\">Maximum Attempts and Escalation</h4>\n<p><strong>Maximum retry attempts</strong> prevent infinite retry loops while ensuring that temporary failures do not cause permanent data loss. However, different operation types require different escalation strategies when max attempts are exceeded.</p>\n<table>\n<thead>\n<tr>\n<th>Operation Type</th>\n<th>Max Attempts</th>\n<th>Escalation Strategy</th>\n<th>Manual Intervention Required</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Job Completion Report</td>\n<td>15</td>\n<td>Write to dead letter queue</td>\n<td>Yes - job state reconciliation</td>\n</tr>\n<tr>\n<td>Worker Heartbeat</td>\n<td>5</td>\n<td>Mark worker as failed</td>\n<td>No - automatic recovery</td>\n</tr>\n<tr>\n<td>Job Assignment</td>\n<td>8</td>\n<td>Return job to queue</td>\n<td>No - automatic retry</td>\n</tr>\n<tr>\n<td>Leader Election</td>\n<td>3</td>\n<td>Enter follower mode</td>\n<td>Possibly - configuration check</td>\n</tr>\n</tbody></table>\n<p><strong>Escalation procedures</strong> ensure that operations that cannot succeed through retries alone are handled appropriately rather than being lost. The dead letter queue serves as a <strong>last resort repository</strong> for operations that require manual intervention or extended retry periods.</p>\n<p>The system implements <strong>retry budgets</strong> that limit the total number of retries across all operations within a time window. This prevents scenarios where retry storms consume all available resources and prevent successful operations from completing. Each operation type has an allocated retry budget, and when the budget is exhausted, operations fail fast rather than queuing for later retry.</p>\n<p><strong>Exponential backoff state</strong> is maintained per operation type and target to ensure that repeated failures to the same destination use progressively longer delays. However, successful operations reset the backoff state, allowing rapid recovery when services become available.</p>\n<h4 id=\"dead-letter-queue-handling\">Dead Letter Queue Handling</h4>\n<p>The <strong>dead letter queue</strong> serves as a repository for operations that cannot be completed through normal retry mechanisms. Unlike simple failure logging, the dead letter queue enables <strong>recovery workflows</strong> that can resolve issues and replay failed operations.</p>\n<p>Dead letter queue entries include comprehensive context for later resolution:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Purpose</th>\n<th>Example Value</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Original Operation</td>\n<td>The operation that failed</td>\n<td>JobCompletionReport</td>\n</tr>\n<tr>\n<td>Failure Reason</td>\n<td>Why retries were exhausted</td>\n<td>&quot;Coordinator unreachable after 15 attempts&quot;</td>\n</tr>\n<tr>\n<td>Original Timestamp</td>\n<td>When operation was first attempted</td>\n<td>2024-01-15T10:30:00Z</td>\n</tr>\n<tr>\n<td>Context Data</td>\n<td>Information needed for replay</td>\n<td>Job ID, Worker ID, Execution Result</td>\n</tr>\n<tr>\n<td>Retry History</td>\n<td>Previous attempt timestamps and errors</td>\n<td>[attempt1: timeout, attempt2: connection refused]</td>\n</tr>\n<tr>\n<td>Manual Review Flag</td>\n<td>Whether human intervention is required</td>\n<td>true</td>\n</tr>\n</tbody></table>\n<p><strong>Dead letter processing</strong> includes both automated and manual resolution paths:</p>\n<ol>\n<li><strong>Automated recovery</strong>: Periodic replay of dead letter entries when target services become available</li>\n<li><strong>Batch reconciliation</strong>: Comparing dead letter entries against current system state to identify resolved operations</li>\n<li><strong>Manual intervention workflows</strong>: Administrative interfaces for resolving operations that require human judgment</li>\n<li><strong>Data consistency checks</strong>: Validation that replaying dead letter operations will not violate system invariants</li>\n</ol>\n<p>The dead letter queue implements <strong>aging policies</strong> that automatically archive entries older than configurable thresholds. However, critical operations like job completion reports are never automatically discarded, ensuring that job execution results are not lost even during extended outages.</p>\n<p>⚠️ <strong>Pitfall: Retry Strategy Coordination</strong>\nImplementing retry logic independently in each component can create <strong>retry amplification</strong> where failures cascade through the system as each component retries failed operations. For example, if the coordination service becomes temporarily unavailable, all workers may simultaneously retry heartbeats, creating a load spike when the service recovers that prevents successful recovery. Retry strategies must be coordinated across components with shared circuit breakers and backpressure mechanisms.</p>\n<h3 id=\"consistency-guarantees\">Consistency Guarantees</h3>\n<p>Distributed job scheduling must balance <strong>consistency</strong> with <strong>availability</strong> under the constraints of the CAP theorem. Our scheduler provides configurable consistency guarantees that can be tuned based on application requirements and operational priorities.</p>\n<blockquote>\n<p><strong>Decision: Consistency Model Selection</strong></p>\n<ul>\n<li><strong>Context</strong>: Job execution requires balancing exactly-once guarantees with system availability during failures</li>\n<li><strong>Options Considered</strong>: Exactly-once execution, At-least-once execution, At-most-once execution</li>\n<li><strong>Decision</strong>: Configurable consistency with at-least-once as default and exactly-once as optional mode</li>\n<li><strong>Rationale</strong>: Most applications can handle duplicate job execution better than missing job execution</li>\n<li><strong>Consequences</strong>: Simpler failure handling but requires idempotent job design</li>\n</ul>\n</blockquote>\n<h4 id=\"at-least-once-vs-exactly-once-execution\">At-Least-Once vs Exactly-Once Execution</h4>\n<p><strong>At-least-once execution</strong> guarantees that every submitted job will be executed at least once, but jobs may be executed multiple times due to failures and retries. <strong>Exactly-once execution</strong> guarantees that every job is executed exactly one time, but achieving this guarantee requires more complex coordination that can impact availability.</p>\n<table>\n<thead>\n<tr>\n<th>Consistency Model</th>\n<th>Guarantee</th>\n<th>Implementation Complexity</th>\n<th>Failure Recovery Time</th>\n<th>Use Cases</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>At-least-once</td>\n<td>Jobs never lost, may duplicate</td>\n<td>Low</td>\n<td>Fast (seconds)</td>\n<td>Idempotent operations, data processing</td>\n</tr>\n<tr>\n<td>Exactly-once</td>\n<td>Jobs executed precisely once</td>\n<td>High</td>\n<td>Slow (minutes)</td>\n<td>Financial transactions, state mutations</td>\n</tr>\n<tr>\n<td>At-most-once</td>\n<td>Jobs never duplicate, may be lost</td>\n<td>Medium</td>\n<td>Medium (30 seconds)</td>\n<td>Best-effort notifications, logging</td>\n</tr>\n</tbody></table>\n<p><strong>At-least-once implementation</strong> uses <strong>optimistic execution</strong> where workers claim jobs and begin execution immediately, reporting completion when finished. If a worker fails during execution, the job is reassigned to another worker after a timeout period. This approach prioritizes availability and fast recovery at the cost of potential duplicate execution.</p>\n<p><strong>Exactly-once implementation</strong> requires <strong>two-phase commit</strong> protocols where workers must confirm job completion before the job is marked as completed system-wide. This involves:</p>\n<ol>\n<li><strong>Execution phase</strong>: Worker claims job and executes it locally</li>\n<li><strong>Preparation phase</strong>: Worker reports execution completion but job remains in &quot;completing&quot; state</li>\n<li><strong>Commit phase</strong>: Coordinator confirms no other worker has claimed the job and marks it as completed</li>\n<li><strong>Cleanup phase</strong>: All replicas acknowledge the completion and remove local job state</li>\n</ol>\n<p>The exactly-once protocol introduces <strong>blocking periods</strong> where job completion is delayed while the coordinator verifies that no other worker has also executed the job. During network partitions or coordinator failures, jobs may remain in the &quot;completing&quot; state until consistency can be verified.</p>\n<h4 id=\"idempotency-requirements\">Idempotency Requirements</h4>\n<p><strong>Idempotency</strong> enables at-least-once execution patterns by ensuring that executing a job multiple times produces the same result as executing it once. However, achieving idempotency requires careful job design and system support for <strong>idempotency tracking</strong>.</p>\n<p>Job idempotency is implemented through several mechanisms:</p>\n<table>\n<thead>\n<tr>\n<th>Mechanism</th>\n<th>Scope</th>\n<th>Implementation</th>\n<th>Example</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Idempotency Key</td>\n<td>Per Job</td>\n<td>Client-provided unique identifier</td>\n<td>UUID generated at job submission</td>\n</tr>\n<tr>\n<td>Content Hash</td>\n<td>Per Execution</td>\n<td>Hash of normalized job payload</td>\n<td>SHA-256 of sorted job parameters</td>\n</tr>\n<tr>\n<td>External System State</td>\n<td>Per Side Effect</td>\n<td>Query before mutation</td>\n<td>Check if database record already exists</td>\n</tr>\n<tr>\n<td>Operation Sequencing</td>\n<td>Per Workflow</td>\n<td>Monotonic sequence numbers</td>\n<td>Process events in timestamp order</td>\n</tr>\n</tbody></table>\n<p><strong>Idempotency key enforcement</strong> prevents duplicate job submissions when clients retry job creation requests. The scheduler maintains a deduplication cache that maps idempotency keys to job identifiers, ensuring that submitting the same job multiple times results in a single job execution.</p>\n<p><strong>Content-based deduplication</strong> prevents duplicate jobs even when different idempotency keys are used. This addresses scenarios where multiple systems submit identical jobs independently, such as multiple monitoring systems detecting the same failure condition.</p>\n<p>The scheduler provides <strong>idempotency validation helpers</strong> that jobs can use to check whether their side effects have already been applied:</p>\n<ol>\n<li><strong>State query interfaces</strong>: Check external system state before applying mutations</li>\n<li><strong>Operation logging</strong>: Record intended operations before applying them</li>\n<li><strong>Result caching</strong>: Store operation results to avoid recomputation</li>\n<li><strong>Conditional execution</strong>: Use compare-and-swap operations for state mutations</li>\n</ol>\n<p>⚠️ <strong>Pitfall: False Idempotency Assumptions</strong>\nMany operations that appear idempotent actually have hidden side effects that violate idempotency. For example, sending an email notification may be considered idempotent because sending the same email twice is acceptable, but if the email system generates unique tracking identifiers or charges per message, duplicate execution creates unintended consequences. Jobs must be carefully designed to handle duplicate execution at the system level, not just at the application logic level.</p>\n<h4 id=\"fencing-tokens-and-split-brain-prevention\">Fencing Tokens and Split-Brain Prevention</h4>\n<p><strong>Fencing tokens</strong> provide a mechanism to prevent <strong>split-brain scenarios</strong> where multiple coordinators or workers believe they have authority over the same resources. Fencing tokens are monotonically increasing identifiers that accompany all operations, allowing the system to reject stale operations from previous epochs.</p>\n<table>\n<thead>\n<tr>\n<th>Token Type</th>\n<th>Scope</th>\n<th>Generation</th>\n<th>Validation</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Coordinator Token</td>\n<td>Cluster-wide</td>\n<td>Incremented at each leader election</td>\n<td>Coordination service validates before writes</td>\n</tr>\n<tr>\n<td>Worker Token</td>\n<td>Per Worker</td>\n<td>Generated at worker registration</td>\n<td>Coordinator validates before job assignment</td>\n</tr>\n<tr>\n<td>Job Token</td>\n<td>Per Job</td>\n<td>Generated at job assignment</td>\n<td>Worker validates before state updates</td>\n</tr>\n<tr>\n<td>Operation Token</td>\n<td>Per Operation</td>\n<td>Generated at operation start</td>\n<td>Target validates before applying changes</td>\n</tr>\n</tbody></table>\n<p><strong>Coordinator fencing</strong> prevents scenarios where a partitioned coordinator continues operating after a new coordinator has been elected. Each coordinator operation includes the current coordinator token, and the coordination service rejects operations with stale tokens. This ensures that only the current leader can modify cluster state.</p>\n<p><strong>Worker fencing</strong> prevents workers from reporting results for jobs that have been reassigned to other workers. When a coordinator reassigns a job due to worker failure, it generates a new job token. The original worker&#39;s completion report includes the old token and is rejected, preventing duplicate completion reporting.</p>\n<p><strong>Fencing token implementation</strong> requires atomic operations in the coordination service:</p>\n<ol>\n<li><strong>Token generation</strong>: Atomic increment operation that returns new token value</li>\n<li><strong>Token validation</strong>: Compare-and-swap operation that succeeds only if token is current</li>\n<li><strong>Token refresh</strong>: Periodic token update to maintain operation authority</li>\n<li><strong>Token revocation</strong>: Explicit invalidation of tokens during failure scenarios</li>\n</ol>\n<p>The fencing protocol ensures <strong>monotonic consistency</strong> where the system never moves backward in time or accepts operations from previous epochs. However, fencing introduces <strong>operational overhead</strong> as every distributed operation must include token validation.</p>\n<p>Fencing tokens are <strong>persisted durably</strong> in the coordination service to survive coordinator restarts and network partitions. During recovery scenarios, the new coordinator queries the coordination service to obtain the current token value and increments it to establish new epoch authority.</p>\n<blockquote>\n<p><strong>Critical Design Insight</strong>: Fencing tokens represent a fundamental trade-off between consistency and performance. Every operation becomes more expensive due to token validation, but this cost is essential for preventing data corruption during failure scenarios. Systems that skip fencing to improve performance inevitably encounter split-brain scenarios that require complex manual recovery procedures.</p>\n</blockquote>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The error handling and retry mechanisms require careful integration with Go&#39;s context cancellation and timeout systems to provide responsive failure detection without resource leaks.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Retry Framework</td>\n<td>Manual exponential backoff with time.Sleep</td>\n<td>github.com/cenkalti/backoff library</td>\n</tr>\n<tr>\n<td>Circuit Breaker</td>\n<td>Counter-based with mutex</td>\n<td>github.com/sony/gobreaker</td>\n</tr>\n<tr>\n<td>Timeout Management</td>\n<td>context.WithTimeout per operation</td>\n<td>Hierarchical timeout trees</td>\n</tr>\n<tr>\n<td>Error Classification</td>\n<td>Custom error types with Is/As</td>\n<td>github.com/pkg/errors wrapping</td>\n</tr>\n<tr>\n<td>Metrics Collection</td>\n<td>Prometheus counters/histograms</td>\n<td>OpenTelemetry with distributed tracing</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>internal/\n  errors/\n    retry.go              ← exponential backoff implementation\n    circuit_breaker.go    ← circuit breaker pattern\n    dead_letter.go        ← dead letter queue management\n    errors.go             ← custom error types\n  fencing/\n    tokens.go             ← fencing token generation/validation\n    coordinator.go        ← coordinator fencing logic\n    worker.go            ← worker fencing implementation\n  coordination/\n    failure_detector.go   ← heartbeat and failure detection\n    recovery.go          ← job recovery and reassignment\n    split_brain.go       ← split-brain prevention</code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// Package errors provides retry and error handling infrastructure</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> errors</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">context</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">fmt</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">math</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">math/rand</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// RetryConfig defines retry behavior for different operation types</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> RetryConfig</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    InitialDelay   </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    BackoffFactor  </span><span style=\"color:#F97583\">float64</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    MaxDelay       </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    MaxAttempts    </span><span style=\"color:#F97583\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    JitterPercent  </span><span style=\"color:#F97583\">float64</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// DefaultRetryConfigs provides sensible retry configurations</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">var</span><span style=\"color:#E1E4E8\"> DefaultRetryConfigs </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#B392F0\">RetryConfig</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"heartbeat\"</span><span style=\"color:#E1E4E8\">: {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        InitialDelay:  time.Second,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        BackoffFactor: </span><span style=\"color:#79B8FF\">2.0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        MaxDelay:      </span><span style=\"color:#79B8FF\">30</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\"> time.Second,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        MaxAttempts:   </span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        JitterPercent: </span><span style=\"color:#79B8FF\">0.2</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    },</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"job_state\"</span><span style=\"color:#E1E4E8\">: {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        InitialDelay:  </span><span style=\"color:#79B8FF\">100</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\"> time.Millisecond,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        BackoffFactor: </span><span style=\"color:#79B8FF\">1.5</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        MaxDelay:      </span><span style=\"color:#79B8FF\">10</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\"> time.Second,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        MaxAttempts:   </span><span style=\"color:#79B8FF\">8</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        JitterPercent: </span><span style=\"color:#79B8FF\">0.25</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    },</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// RetryableError indicates an operation can be retried</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> RetryableError</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Err       </span><span style=\"color:#F97583\">error</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Temporary </span><span style=\"color:#F97583\">bool</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Backoff   </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">e </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">RetryableError</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Error</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> fmt.</span><span style=\"color:#B392F0\">Sprintf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"retryable error (backoff=</span><span style=\"color:#79B8FF\">%v</span><span style=\"color:#9ECBFF\">): </span><span style=\"color:#79B8FF\">%v</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, e.Backoff, e.Err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// IsRetryable returns true if error should be retried</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> IsRetryable</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">err</span><span style=\"color:#F97583\"> error</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">bool</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    var</span><span style=\"color:#E1E4E8\"> retryableErr </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">RetryableError</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> errors.</span><span style=\"color:#B392F0\">As</span><span style=\"color:#E1E4E8\">(err, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">retryableErr)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// CircuitBreaker prevents cascade failures during sustained error conditions</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> CircuitBreaker</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    mu          </span><span style=\"color:#B392F0\">sync</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Mutex</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    state       </span><span style=\"color:#B392F0\">CircuitState</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    failures    </span><span style=\"color:#F97583\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    lastFailure </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    config      </span><span style=\"color:#B392F0\">CircuitConfig</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> CircuitState</span><span style=\"color:#F97583\"> int</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">const</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    CircuitClosed</span><span style=\"color:#B392F0\"> CircuitState</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> iota</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    CircuitOpen</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    CircuitHalfOpen</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> CircuitConfig</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    FailureThreshold </span><span style=\"color:#F97583\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    RecoveryTimeout  </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    TestRequests     </span><span style=\"color:#F97583\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Execute runs operation with circuit breaker protection</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">cb </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">CircuitBreaker</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Execute</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">operation</span><span style=\"color:#F97583\"> func</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Check circuit state and return fast failure if open</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Execute operation and record success/failure</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Update circuit state based on recent failure patterns</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Return appropriate error with circuit state information</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// DeadLetterQueue stores operations that failed all retry attempts</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> DeadLetterQueue</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    storage    </span><span style=\"color:#B392F0\">Storage</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    maxAge     </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    maxEntries </span><span style=\"color:#F97583\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> DeadLetterEntry</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ID              </span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    OriginalOp      </span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    FailureReason   </span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Context         </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    RetryHistory    []</span><span style=\"color:#B392F0\">RetryAttempt</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CreatedAt       </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    RequiresManual  </span><span style=\"color:#F97583\">bool</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> RetryAttempt</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Timestamp </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Error     </span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Duration  </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Add stores failed operation for later resolution</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">dlq </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">DeadLetterQueue</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Add</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">entry</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">DeadLetterEntry</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Validate entry has required fields</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Store entry in persistent storage</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Check if cleanup is needed for old entries</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Emit metrics for dead letter queue depth</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeleton-code\">Core Logic Skeleton Code</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// RetryWithBackoff executes operation with exponential backoff retry logic</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> RetryWithBackoff</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">config</span><span style=\"color:#B392F0\"> RetryConfig</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">operation</span><span style=\"color:#F97583\"> func</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Initialize attempt counter and current delay</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Loop until max attempts reached or context cancelled</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Execute operation and check if error is retryable</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Calculate next delay with jitter and backoff factor</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Sleep for calculated delay or return on context cancellation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Return last error if all attempts exhausted</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ValidateFencingToken checks if operation token is current and valid</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">f </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FencingManager</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">ValidateFencingToken</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">tokenType</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">token</span><span style=\"color:#F97583\"> int64</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Query coordination service for current token value</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Compare provided token with current token</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Return specific error if token is stale</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Update token validation metrics</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// DetectWorkerFailure monitors heartbeats and detects failed workers</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">fd </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">FailureDetector</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">DetectWorkerFailure</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">workerID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Check time since last heartbeat for worker</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Compare against graduated timeout thresholds</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Attempt direct health check if initial timeout exceeded</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Mark worker as failed if all checks fail</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Trigger job recovery process for failed worker</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// RecoverJobsFromFailedWorker reassigns jobs when worker becomes unavailable</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">r </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">JobRecovery</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">RecoverJobsFromFailedWorker</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">workerID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">reason</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Query all jobs currently assigned to failed worker</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Determine which jobs were executing vs pending</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Reset job states to allow reassignment</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Add jobs back to priority queue with appropriate priority</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Log recovery actions and update metrics</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"language-specific-hints\">Language-Specific Hints</h4>\n<ul>\n<li>Use <code>context.WithTimeout()</code> for operation-level timeouts and <code>context.WithCancel()</code> for graceful shutdown</li>\n<li>Implement custom error types with <code>errors.Is()</code> and <code>errors.As()</code> support for error classification</li>\n<li>Use <code>sync.Mutex</code> for circuit breaker state but consider <code>sync.RWMutex</code> for high-read scenarios</li>\n<li>Leverage <code>time.NewTimer()</code> for retry delays to avoid blocking goroutines during backoff periods</li>\n<li>Use <code>atomic</code> package for counters and flags that are accessed from multiple goroutines</li>\n<li>Implement graceful shutdown with <code>sync.WaitGroup</code> to ensure in-flight operations complete</li>\n</ul>\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p><strong>After implementing retry framework:</strong></p>\n<ul>\n<li>Run <code>go test ./internal/errors/...</code> - all retry tests should pass</li>\n<li>Test circuit breaker behavior: rapid failures should open circuit, recovery should close it</li>\n<li>Verify jitter prevents thundering herd: multiple concurrent retries should have different delays</li>\n</ul>\n<p><strong>After implementing fencing tokens:</strong></p>\n<ul>\n<li>Start coordinator, verify token increments with each leadership change</li>\n<li>Simulate split-brain: old coordinator operations should be rejected with stale token errors</li>\n<li>Test job assignment fencing: worker cannot complete job after reassignment</li>\n</ul>\n<p><strong>After implementing failure detection:</strong></p>\n<ul>\n<li>Stop worker heartbeats, verify coordinator detects failure within expected timeout</li>\n<li>Test graduated failure detection: temporary slowness should not trigger immediate failure</li>\n<li>Verify job recovery: jobs from failed worker should be reassigned to healthy workers</li>\n</ul>\n<h4 id=\"debugging-tips\">Debugging Tips</h4>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Jobs executed multiple times</td>\n<td>Worker failure during execution, job reassigned</td>\n<td>Check job execution logs for same job ID from multiple workers</td>\n<td>Implement idempotency keys, verify fencing tokens</td>\n</tr>\n<tr>\n<td>Retry storms overloading services</td>\n<td>All components retrying simultaneously</td>\n<td>Check retry metrics for spikes after service recovery</td>\n<td>Add jitter to retry delays, implement circuit breakers</td>\n</tr>\n<tr>\n<td>Split-brain job assignments</td>\n<td>Network partition with multiple active coordinators</td>\n<td>Check coordination service logs for multiple leaders</td>\n<td>Verify fencing token implementation, check leader election</td>\n</tr>\n<tr>\n<td>Dead letter queue growing rapidly</td>\n<td>Systemic failure with all retry attempts failing</td>\n<td>Analyze failure patterns in dead letter entries</td>\n<td>Fix underlying service issues, tune retry parameters</td>\n</tr>\n<tr>\n<td>Workers marked failed but still healthy</td>\n<td>Heartbeat timeouts too aggressive</td>\n<td>Compare heartbeat intervals with timeout thresholds</td>\n<td>Increase timeout values, check network latency patterns</td>\n</tr>\n</tbody></table>\n<p>The error handling implementation should focus on <strong>fail-fast for unrecoverable errors</strong> and <strong>intelligent retry for transient failures</strong>. The key is distinguishing between these categories correctly and implementing backpressure mechanisms that prevent retry storms from overwhelming recovering services.</p>\n<h2 id=\"testing-strategy\">Testing Strategy</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section covers testing approaches that verify the correct implementation across all three milestones - unit tests for isolated component validation (cron parsing, queue operations, coordination logic), integration tests for multi-component scenarios, and milestone-specific verification checkpoints that ensure proper functionality at each development stage.</p>\n</blockquote>\n<p>Building a comprehensive testing strategy for a distributed job scheduler is like designing quality assurance for a city&#39;s emergency response system. Just as emergency services must be tested at multiple levels - individual responder training, department coordination drills, and full-scale disaster simulations - our distributed scheduler requires unit tests for component isolation, integration tests for system-wide behavior, and milestone checkpoints for development validation. The complexity arises from testing distributed systems where timing, concurrency, and failure modes create non-deterministic behavior that traditional testing approaches struggle to handle.</p>\n<p>The testing strategy operates at three distinct levels, each addressing different aspects of system correctness. Unit testing focuses on algorithmic correctness and component isolation, ensuring individual pieces work correctly in controlled environments. Integration testing validates system-wide behavior under realistic conditions including network partitions, worker failures, and concurrent job execution. Milestone checkpoints provide development feedback loops that verify expected functionality at each implementation stage, preventing architectural drift and catching integration issues early.</p>\n<h3 id=\"unit-testing\">Unit Testing</h3>\n<p>Think of unit testing for a distributed scheduler like testing individual instruments in an orchestra before the full performance. Each component must demonstrate perfect execution in isolation before we can trust it to perform correctly when coordinated with other components under the unpredictable conditions of distributed operation.</p>\n<p>Unit testing in our distributed job scheduler focuses on three primary domains: <strong>cron expression parsing and scheduling logic</strong>, <strong>priority queue operations and deduplication mechanisms</strong>, and <strong>coordination algorithms including leader election and heartbeat processing</strong>. Each domain presents unique challenges that require specialized testing approaches to ensure correctness under all edge cases.</p>\n<h4 id=\"cron-expression-parsing-tests\">Cron Expression Parsing Tests</h4>\n<p>The cron expression parser represents pure algorithmic logic that transforms textual time patterns into structured execution schedules. Unit testing this component requires comprehensive coverage of cron syntax variations, timezone handling edge cases, and calendar arithmetic correctness across different temporal boundaries.</p>\n<p><strong>Cron Field Parsing Tests</strong> validate the <code>parseField()</code> method&#39;s ability to correctly interpret individual cron field syntax including wildcards, ranges, step values, and shorthand aliases. These tests use table-driven approaches to verify parsing accuracy across the full spectrum of valid and invalid inputs.</p>\n<table>\n<thead>\n<tr>\n<th>Test Category</th>\n<th>Input Examples</th>\n<th>Expected Behavior</th>\n<th>Edge Cases</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Wildcard Parsing</td>\n<td><code>*</code>, <code>*/5</code>, <code>*/15</code></td>\n<td>Expands to full range with step intervals</td>\n<td>Step values that don&#39;t divide evenly</td>\n</tr>\n<tr>\n<td>Range Parsing</td>\n<td><code>1-5</code>, <code>10-20</code>, <code>MON-FRI</code></td>\n<td>Expands to inclusive integer sequences</td>\n<td>Cross-boundary ranges like <code>23-1</code></td>\n</tr>\n<tr>\n<td>List Parsing</td>\n<td><code>1,3,5</code>, <code>MON,WED,FRI</code></td>\n<td>Expands to explicit value lists</td>\n<td>Duplicate values and unsorted lists</td>\n</tr>\n<tr>\n<td>Step Parsing</td>\n<td><code>*/2</code>, <code>1-10/3</code>, <code>MON-FRI/2</code></td>\n<td>Applies step intervals to base ranges</td>\n<td>Step larger than range span</td>\n</tr>\n<tr>\n<td>Alias Parsing</td>\n<td><code>@daily</code>, <code>@hourly</code>, <code>@weekly</code></td>\n<td>Converts to standard five-field format</td>\n<td>Invalid aliases and malformed syntax</td>\n</tr>\n</tbody></table>\n<p><strong>Next Execution Time Tests</strong> verify the <code>NextExecutionTime()</code> method&#39;s calendar arithmetic across temporal boundaries including month transitions, leap years, and daylight saving time adjustments. These tests require comprehensive coverage of edge cases that occur at calendar boundaries.</p>\n<table>\n<thead>\n<tr>\n<th>Boundary Type</th>\n<th>Test Scenarios</th>\n<th>Validation Points</th>\n<th>Common Failures</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Month Boundaries</td>\n<td>Jobs scheduled for day 31 in February</td>\n<td>Correctly skips to next valid month</td>\n<td>Infinite loops on impossible dates</td>\n</tr>\n<tr>\n<td>Leap Year Handling</td>\n<td>February 29 scheduling in non-leap years</td>\n<td>Proper year advancement logic</td>\n<td>Incorrect leap year detection</td>\n</tr>\n<tr>\n<td>DST Transitions</td>\n<td>Jobs scheduled during spring-forward/fall-back</td>\n<td>Maintains consistent UTC scheduling</td>\n<td>Duplicate or skipped executions</td>\n</tr>\n<tr>\n<td>Year Boundaries</td>\n<td>December to January transitions</td>\n<td>Correct year increment behavior</td>\n<td>Off-by-one errors in year calculation</td>\n</tr>\n<tr>\n<td>Week Boundaries</td>\n<td>Day-of-week constraints across month ends</td>\n<td>Proper week calculation logic</td>\n<td>Incorrect week number arithmetic</td>\n</tr>\n</tbody></table>\n<p><strong>Timezone Conversion Tests</strong> validate the timezone normalization logic that ensures consistent UTC storage while supporting local timezone interpretation. These tests verify correct conversion behavior across timezone boundaries and DST transitions.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Test Matrix: Timezone Conversion Validation\n- Standard Time Zones: EST, PST, GMT, UTC+5\n- DST Transitions: Spring forward, Fall back scenarios  \n- Edge Cases: Invalid timezones, missing location data\n- Boundary Conditions: Midnight crossings, leap seconds</code></pre></div>\n\n<h4 id=\"priority-queue-operation-tests\">Priority Queue Operation Tests</h4>\n<p>Priority queue testing validates the core job ordering and atomic operation logic that ensures correct job distribution under concurrent access patterns. The priority queue must maintain strict ordering guarantees while supporting delayed execution and deduplication features.</p>\n<p><strong>Priority Ordering Tests</strong> verify the <code>JobHeap</code> implementation maintains correct priority ordering under all insertion and removal operations. These tests validate both the heap property maintenance and the tie-breaking logic for jobs with identical priorities.</p>\n<table>\n<thead>\n<tr>\n<th>Test Scenario</th>\n<th>Setup</th>\n<th>Operation</th>\n<th>Expected Result</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Basic Priority Order</td>\n<td>Jobs with priorities 1, 5, 3, 2</td>\n<td>Pop all jobs</td>\n<td>Retrieved in order: 1, 2, 3, 5</td>\n</tr>\n<tr>\n<td>Identical Priority</td>\n<td>Multiple jobs with priority 3</td>\n<td>Pop with FIFO tie-breaking</td>\n<td>Oldest job retrieved first</td>\n</tr>\n<tr>\n<td>Mixed Priorities</td>\n<td>Interleaved high/low priority jobs</td>\n<td>Random insertions and removals</td>\n<td>Always returns highest priority</td>\n</tr>\n<tr>\n<td>Empty Queue</td>\n<td>No jobs present</td>\n<td>Pop operation</td>\n<td>Returns nil with appropriate error</td>\n</tr>\n<tr>\n<td>Single Job</td>\n<td>Queue with one job</td>\n<td>Pop followed by another pop</td>\n<td>First succeeds, second returns empty</td>\n</tr>\n</tbody></table>\n<p><strong>Delayed Execution Tests</strong> validate the visibility timeout pattern implementation that holds jobs until their scheduled execution time. These tests verify that delayed jobs remain invisible to <code>ClaimJob()</code> operations until promotion time arrives.</p>\n<table>\n<thead>\n<tr>\n<th>Timing Scenario</th>\n<th>Job Schedule</th>\n<th>Current Time</th>\n<th>Visibility Status</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Future Scheduled</td>\n<td>2024-01-01 12:00</td>\n<td>2024-01-01 11:30</td>\n<td>Hidden from claim operations</td>\n</tr>\n<tr>\n<td>Exact Time</td>\n<td>2024-01-01 12:00</td>\n<td>2024-01-01 12:00</td>\n<td>Becomes visible immediately</td>\n</tr>\n<tr>\n<td>Past Due</td>\n<td>2024-01-01 12:00</td>\n<td>2024-01-01 12:30</td>\n<td>Visible and claimable</td>\n</tr>\n<tr>\n<td>Promotion Batch</td>\n<td>100 delayed jobs</td>\n<td>Time advancement</td>\n<td>Batch promotion efficiency</td>\n</tr>\n</tbody></table>\n<p><strong>Deduplication Logic Tests</strong> verify the <code>CheckDuplicate()</code> method correctly identifies duplicate job submissions using both idempotency keys and content hashing. These tests ensure no duplicate jobs enter the execution pipeline while avoiding false positive deduplication.</p>\n<table>\n<thead>\n<tr>\n<th>Deduplication Type</th>\n<th>Primary Key</th>\n<th>Secondary Check</th>\n<th>Test Validation</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Idempotency Key</td>\n<td>Client-provided unique key</td>\n<td>Exact key match</td>\n<td>Same key prevents duplicate submission</td>\n</tr>\n<tr>\n<td>Content Hash</td>\n<td>Hash of normalized payload</td>\n<td>Deterministic hash comparison</td>\n<td>Identical content detected regardless of key</td>\n</tr>\n<tr>\n<td>Key Collision</td>\n<td>Different jobs, same key</td>\n<td>Payload comparison</td>\n<td>Content differs, both jobs accepted</td>\n</tr>\n<tr>\n<td>Hash Collision</td>\n<td>Different payloads, same hash</td>\n<td>Full payload comparison</td>\n<td>Rare hash collision handled correctly</td>\n</tr>\n</tbody></table>\n<p>⚠️ <strong>Pitfall: Non-Deterministic Hash Calculation</strong>\nA common testing mistake is creating content hashes that vary based on map iteration order or pointer values. The <code>computeContentHash()</code> function must produce identical hashes for semantically identical job payloads, requiring field normalization and sorted serialization. Test this by creating the same job payload multiple times and verifying hash consistency.</p>\n<h4 id=\"coordination-logic-tests\">Coordination Logic Tests</h4>\n<p>Coordination logic testing validates the distributed consensus and failure detection algorithms that enable fault-tolerant job execution across multiple worker nodes. These tests focus on algorithmic correctness rather than network behavior, using mock coordination backends to ensure deterministic test execution.</p>\n<p><strong>Leader Election Tests</strong> verify the consensus algorithm implementation that ensures exactly one coordinator node assumes leadership at any given time. These tests use controlled scenarios to validate election correctness under various failure and recovery patterns.</p>\n<table>\n<thead>\n<tr>\n<th>Election Scenario</th>\n<th>Node Configuration</th>\n<th>Expected Outcome</th>\n<th>Validation Points</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Clean Election</td>\n<td>3 healthy nodes, no previous leader</td>\n<td>Single winner elected</td>\n<td>All nodes agree on leader</td>\n</tr>\n<tr>\n<td>Leadership Change</td>\n<td>Current leader fails, 2 remaining nodes</td>\n<td>New leader elected promptly</td>\n<td>No split-brain condition</td>\n</tr>\n<tr>\n<td>Network Partition</td>\n<td>3 nodes split into 2+1 partitions</td>\n<td>Majority partition maintains leadership</td>\n<td>Minority partition steps down</td>\n</tr>\n<tr>\n<td>Simultaneous Startup</td>\n<td>All nodes start concurrently</td>\n<td>Deterministic leader selection</td>\n<td>Election completes in bounded time</td>\n</tr>\n</tbody></table>\n<p><strong>Heartbeat Processing Tests</strong> validate the failure detection logic that monitors worker health and triggers job recovery when workers become unresponsive. These tests verify correct timeout handling and state transitions.</p>\n<table>\n<thead>\n<tr>\n<th>Heartbeat Pattern</th>\n<th>Worker Behavior</th>\n<th>Expected Response</th>\n<th>Recovery Actions</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Regular Heartbeats</td>\n<td>Heartbeat every 10 seconds</td>\n<td>Worker marked healthy</td>\n<td>No recovery needed</td>\n</tr>\n<tr>\n<td>Missed Heartbeat</td>\n<td>Skip one heartbeat cycle</td>\n<td>Worker marked suspect</td>\n<td>Grace period activated</td>\n</tr>\n<tr>\n<td>Extended Silence</td>\n<td>No heartbeat for 60 seconds</td>\n<td>Worker marked failed</td>\n<td>Job recovery initiated</td>\n</tr>\n<tr>\n<td>Recovery Heartbeat</td>\n<td>Heartbeat after failure</td>\n<td>Worker re-registered</td>\n<td>Previous jobs reassigned</td>\n</tr>\n</tbody></table>\n<p><strong>Fencing Token Tests</strong> verify the token-based mechanism that prevents stale worker reports from corrupting job state. These tests validate that only the current job assignee can report completion or failure status.</p>\n<table>\n<thead>\n<tr>\n<th>Token Scenario</th>\n<th>Job Assignment Token</th>\n<th>Report Token</th>\n<th>Result</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Valid Token</td>\n<td>Token 12345</td>\n<td>Token 12345</td>\n<td>Report accepted</td>\n</tr>\n<tr>\n<td>Stale Token</td>\n<td>Token 12345</td>\n<td>Token 12344</td>\n<td>Report rejected</td>\n</tr>\n<tr>\n<td>No Token</td>\n<td>Token assigned</td>\n<td>No token provided</td>\n<td>Report rejected</td>\n</tr>\n<tr>\n<td>Token Mismatch</td>\n<td>Token for Job A</td>\n<td>Token for Job B</td>\n<td>Report rejected</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Critical Testing Insight</strong>: Unit tests for coordination logic must focus on algorithmic correctness rather than distributed system behavior. Use dependency injection and mock backends to create deterministic test scenarios that validate the decision-making logic without the complexity of actual network communication or timing dependencies.</p>\n</blockquote>\n<h3 id=\"integration-testing\">Integration Testing</h3>\n<p>Integration testing for distributed systems is like conducting full-scale emergency response drills where all departments must coordinate under realistic stress conditions. Unlike unit tests that isolate individual components, integration tests validate system-wide behavior including timing dependencies, network communication, and failure recovery patterns that only emerge when components interact in realistic deployment scenarios.</p>\n<p>Integration testing operates across three primary dimensions: <strong>multi-worker job distribution scenarios</strong>, <strong>failure injection and recovery validation</strong>, and <strong>end-to-end job execution flows</strong>. Each dimension addresses different aspects of distributed system correctness, ensuring the scheduler maintains consistency and availability despite the inherent challenges of distributed operation.</p>\n<h4 id=\"multi-worker-coordination-scenarios\">Multi-Worker Coordination Scenarios</h4>\n<p>Multi-worker scenarios validate the job distribution and coordination algorithms under realistic deployment conditions where multiple worker nodes compete for jobs while maintaining system consistency. These scenarios test the interaction between job queuing, worker registration, and coordination messaging.</p>\n<p><strong>Load Distribution Tests</strong> verify that jobs are distributed fairly across available workers based on their capacity and current load. These tests validate both the initial assignment algorithm and the rebalancing behavior when worker availability changes.</p>\n<table>\n<thead>\n<tr>\n<th>Test Scenario</th>\n<th>Worker Configuration</th>\n<th>Job Load</th>\n<th>Expected Distribution</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Equal Capacity</td>\n<td>3 workers, capacity 10 each</td>\n<td>15 jobs submitted</td>\n<td>5 jobs per worker</td>\n</tr>\n<tr>\n<td>Mixed Capacity</td>\n<td>Workers with capacity 5, 10, 15</td>\n<td>30 jobs submitted</td>\n<td>Proportional to capacity</td>\n</tr>\n<tr>\n<td>Dynamic Scaling</td>\n<td>Start 2 workers, add 2 more</td>\n<td>Continuous job stream</td>\n<td>Load rebalances to new workers</td>\n</tr>\n<tr>\n<td>Worker Removal</td>\n<td>4 workers, remove 2 gracefully</td>\n<td>Jobs in progress</td>\n<td>Completing jobs finish, new jobs redistribute</td>\n</tr>\n</tbody></table>\n<p><strong>Concurrent Job Claiming Tests</strong> validate the atomic job assignment mechanism prevents duplicate execution when multiple workers simultaneously attempt to claim available jobs. These tests stress-test the <code>ClaimJob()</code> operation under high concurrency.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Concurrency Test Pattern:\n1. Submit 100 jobs to priority queue\n2. Start 10 workers simultaneously  \n3. Each worker attempts to claim jobs concurrently\n4. Verify exactly 100 jobs are claimed (no duplicates)\n5. Verify no jobs are claimed by multiple workers\n6. Validate fencing token uniqueness across claims</code></pre></div>\n\n<p><strong>Capability Matching Tests</strong> verify that jobs requiring specific worker capabilities are assigned only to workers that advertise those capabilities. These tests validate the constraint satisfaction logic in the job assignment algorithm.</p>\n<table>\n<thead>\n<tr>\n<th>Job Requirements</th>\n<th>Available Workers</th>\n<th>Assignment Expectation</th>\n<th>Validation</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>[&quot;python&quot;, &quot;gpu&quot;]</code></td>\n<td>Worker A: <code>[&quot;python&quot;]</code>, Worker B: <code>[&quot;python&quot;, &quot;gpu&quot;]</code></td>\n<td>Assigned to Worker B</td>\n<td>Capability constraints satisfied</td>\n</tr>\n<tr>\n<td><code>[&quot;database&quot;]</code></td>\n<td>No workers with database capability</td>\n<td>Job remains unassigned</td>\n<td>Waits for capable worker</td>\n</tr>\n<tr>\n<td><code>[]</code> (no requirements)</td>\n<td>Any available worker</td>\n<td>Assigned to any worker</td>\n<td>No capability restrictions</td>\n</tr>\n</tbody></table>\n<h4 id=\"failure-injection-and-recovery\">Failure Injection and Recovery</h4>\n<p>Failure injection testing validates the system&#39;s resilience to various failure modes that occur in production distributed environments. These tests systematically introduce failures and verify that the system detects, isolates, and recovers from failures while maintaining data consistency.</p>\n<p><strong>Worker Failure Scenarios</strong> test the system&#39;s ability to detect unresponsive workers and reassign their jobs to healthy workers without data loss or duplicate execution.</p>\n<table>\n<thead>\n<tr>\n<th>Failure Type</th>\n<th>Injection Method</th>\n<th>Expected Detection</th>\n<th>Recovery Validation</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Sudden Worker Death</td>\n<td>Kill worker process</td>\n<td>Missed heartbeat detection</td>\n<td>Jobs reassigned within timeout</td>\n</tr>\n<tr>\n<td>Network Partition</td>\n<td>Block worker network access</td>\n<td>Heartbeat timeout</td>\n<td>Jobs recovered, worker isolated</td>\n</tr>\n<tr>\n<td>Slow Worker</td>\n<td>Introduce artificial delays</td>\n<td>Performance degradation detection</td>\n<td>Load rebalanced to faster workers</td>\n</tr>\n<tr>\n<td>Resource Exhaustion</td>\n<td>Consume worker memory/CPU</td>\n<td>Resource monitoring alerts</td>\n<td>Worker marked unavailable</td>\n</tr>\n</tbody></table>\n<p><strong>Coordinator Failure Tests</strong> validate the leader election and failover mechanisms that ensure continuous system operation despite coordinator node failures.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Coordinator Failover Test Sequence:\n1. Start 3-node coordinator cluster with elected leader\n2. Submit jobs and verify normal operation\n3. Kill current leader node abruptly\n4. Verify new leader election completes within SLA\n5. Confirm job scheduling continues without interruption\n6. Validate no jobs are lost or duplicated during transition</code></pre></div>\n\n<p><strong>Split-Brain Prevention Tests</strong> verify the coordination system prevents multiple nodes from simultaneously believing they are the leader, which could result in conflicting job assignments and data corruption.</p>\n<table>\n<thead>\n<tr>\n<th>Network Partition</th>\n<th>Partition A</th>\n<th>Partition B</th>\n<th>Expected Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>3-node cluster, 2+1 split</td>\n<td>2 nodes</td>\n<td>1 node</td>\n<td>Majority partition maintains leadership</td>\n</tr>\n<tr>\n<td>5-node cluster, 2+3 split</td>\n<td>2 nodes</td>\n<td>3 nodes</td>\n<td>Majority partition (3 nodes) leads</td>\n</tr>\n<tr>\n<td>2-node cluster partition</td>\n<td>1 node</td>\n<td>1 node</td>\n<td>Both step down, no leader until reunion</td>\n</tr>\n</tbody></table>\n<p><strong>Data Consistency Tests</strong> validate that concurrent operations and failures don&#39;t corrupt the job state or create impossible system states like jobs assigned to multiple workers simultaneously.</p>\n<table>\n<thead>\n<tr>\n<th>Consistency Scenario</th>\n<th>Operation Pattern</th>\n<th>Validation</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Concurrent Job Updates</td>\n<td>Multiple workers report on same job</td>\n<td>Last valid update wins, fencing prevents conflicts</td>\n</tr>\n<tr>\n<td>Worker Failure During Execution</td>\n<td>Worker dies mid-job execution</td>\n<td>Job marked for retry, not marked complete</td>\n</tr>\n<tr>\n<td>Coordinator Failure During Assignment</td>\n<td>Leader dies during job assignment</td>\n<td>Assignment either completes fully or rolls back</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Integration Testing Philosophy</strong>: Integration tests should focus on emergent behaviors that only appear when components interact under realistic conditions. Unlike unit tests that verify algorithmic correctness, integration tests validate system properties like consistency, availability, and partition tolerance that define distributed system correctness.</p>\n</blockquote>\n<h4 id=\"end-to-end-job-execution-flow\">End-to-End Job Execution Flow</h4>\n<p>End-to-end testing validates complete job lifecycle flows from initial cron schedule evaluation through final execution completion. These tests ensure all system components integrate correctly to deliver the promised scheduling and execution guarantees.</p>\n<p><strong>Complete Job Lifecycle Tests</strong> trace individual jobs through the entire execution pipeline, validating state transitions and ensuring no jobs are lost or duplicated during normal operation.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>End-to-End Flow Validation:\n1. Cron timer fires for scheduled job\n2. Job inserted into priority queue with correct priority\n3. Available worker claims job atomically\n4. Worker executes job payload successfully  \n5. Worker reports completion with valid fencing token\n6. Job marked complete and archived\n7. Next cron execution calculated and scheduled</code></pre></div>\n\n<p><strong>Retry and Failure Handling Tests</strong> verify the system correctly handles job execution failures and applies the configured retry policy including exponential backoff and maximum retry limits.</p>\n<table>\n<thead>\n<tr>\n<th>Job Failure Type</th>\n<th>Retry Configuration</th>\n<th>Expected Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Transient Failure</td>\n<td>Max retries: 3, exponential backoff</td>\n<td>Job retried with increasing delays</td>\n</tr>\n<tr>\n<td>Permanent Failure</td>\n<td>Max retries: 3, all attempts fail</td>\n<td>Job moved to dead letter queue</td>\n</tr>\n<tr>\n<td>Worker Failure</td>\n<td>Job in progress when worker dies</td>\n<td>Job reassigned to different worker</td>\n</tr>\n<tr>\n<td>Timeout Failure</td>\n<td>Job exceeds execution timeout</td>\n<td>Job killed and retried on different worker</td>\n</tr>\n</tbody></table>\n<p><strong>Scheduling Accuracy Tests</strong> validate that recurring jobs are scheduled and executed according to their cron expressions with acceptable timing precision despite system load and failures.</p>\n<table>\n<thead>\n<tr>\n<th>Cron Expression</th>\n<th>Expected Execution Pattern</th>\n<th>Tolerance</th>\n<th>Validation Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>0 */5 * * *</code></td>\n<td>Every 5 minutes</td>\n<td>±30 seconds</td>\n<td>Compare actual vs expected execution times</td>\n</tr>\n<tr>\n<td><code>0 0 * * MON</code></td>\n<td>Every Monday at midnight</td>\n<td>±2 minutes</td>\n<td>Verify weekly execution pattern</td>\n</tr>\n<tr>\n<td><code>0 0 1 * *</code></td>\n<td>First day of each month</td>\n<td>±5 minutes</td>\n<td>Confirm monthly boundary handling</td>\n</tr>\n</tbody></table>\n<p>⚠️ <strong>Pitfall: Integration Test Environment Consistency</strong>\nIntegration tests often fail intermittently due to timing dependencies and resource contention. Ensure test environments provide consistent resource allocation, use deterministic timing where possible, and implement proper test isolation to prevent tests from interfering with each other. Consider using containerized test environments to ensure reproducible conditions.</p>\n<h3 id=\"milestone-checkpoints\">Milestone Checkpoints</h3>\n<p>Milestone checkpoints provide structured validation points that ensure correct implementation at each development stage. These checkpoints serve as both progress indicators and regression prevention mechanisms, catching integration issues early before they compound into complex debugging scenarios.</p>\n<p>Think of milestone checkpoints like progressive flight training evaluations - a pilot must demonstrate mastery of basic instruments before advancing to navigation, then to weather handling, and finally to emergency procedures. Each checkpoint validates not just new functionality but also ensures previous capabilities remain intact under the expanded system complexity.</p>\n<h4 id=\"milestone-1-cron-expression-parser-validation\">Milestone 1: Cron Expression Parser Validation</h4>\n<p>The first milestone checkpoint validates the cron expression parsing and next execution time calculation logic that forms the foundation for all scheduling operations.</p>\n<p><strong>Functional Verification Tests</strong> ensure the parser correctly handles the full spectrum of cron expression syntax while providing accurate next execution time calculations.</p>\n<table>\n<thead>\n<tr>\n<th>Validation Category</th>\n<th>Test Commands</th>\n<th>Expected Behavior</th>\n<th>Success Criteria</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Basic Parsing</td>\n<td><code>go test ./internal/cron/...</code></td>\n<td>All parser unit tests pass</td>\n<td>100% test coverage on core parsing logic</td>\n</tr>\n<tr>\n<td>Expression Validation</td>\n<td>Parse sample expressions</td>\n<td>Valid expressions accepted, invalid rejected</td>\n<td>Clear error messages for malformed input</td>\n</tr>\n<tr>\n<td>Next Time Calculation</td>\n<td>Calculate execution times</td>\n<td>Accurate future timestamps returned</td>\n<td>Timing precision within 1-second tolerance</td>\n</tr>\n<tr>\n<td>Timezone Support</td>\n<td>Test across multiple timezones</td>\n<td>Correct UTC normalization</td>\n<td>DST transitions handled properly</td>\n</tr>\n</tbody></table>\n<p><strong>Parser Stress Testing</strong> validates performance and correctness under high-volume parsing operations that simulate production workloads.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Stress Test Validation:\n- Parse 10,000 varied cron expressions\n- Measure parsing performance (target: &lt;1ms per expression)\n- Verify memory usage remains bounded\n- Confirm no memory leaks during batch processing</code></pre></div>\n\n<p><strong>Edge Case Coverage</strong> ensures the parser handles calendar arithmetic edge cases that commonly cause scheduling failures in production systems.</p>\n<table>\n<thead>\n<tr>\n<th>Edge Case Category</th>\n<th>Specific Tests</th>\n<th>Validation Points</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Month Boundaries</td>\n<td>Feb 31, Apr 31 expressions</td>\n<td>Correctly skips to next valid date</td>\n</tr>\n<tr>\n<td>Leap Year Handling</td>\n<td>Feb 29 in non-leap years</td>\n<td>Proper year advancement</td>\n</tr>\n<tr>\n<td>DST Transitions</td>\n<td>2 AM during spring forward</td>\n<td>No duplicate or missed executions</td>\n</tr>\n<tr>\n<td>Year Rollover</td>\n<td>Dec 31 to Jan 1 transitions</td>\n<td>Correct year increment</td>\n</tr>\n</tbody></table>\n<h4 id=\"milestone-2-priority-queue-system-validation\">Milestone 2: Priority Queue System Validation</h4>\n<p>The second milestone checkpoint validates the priority queue implementation including delayed execution, deduplication, and atomic job operations.</p>\n<p><strong>Queue Operation Verification</strong> tests the core priority queue functionality under both single-threaded and concurrent access patterns.</p>\n<table>\n<thead>\n<tr>\n<th>Test Category</th>\n<th>Validation Command</th>\n<th>Success Criteria</th>\n<th>Performance Target</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Priority Ordering</td>\n<td><code>go test ./internal/queue/priority_test.go</code></td>\n<td>Jobs dequeued in strict priority order</td>\n<td>O(log n) insertion/removal</td>\n</tr>\n<tr>\n<td>Delayed Jobs</td>\n<td><code>go test ./internal/queue/delay_test.go</code></td>\n<td>Scheduled jobs remain invisible until promotion</td>\n<td>Sub-second promotion accuracy</td>\n</tr>\n<tr>\n<td>Deduplication</td>\n<td><code>go test ./internal/queue/dedup_test.go</code></td>\n<td>Duplicate submissions prevented</td>\n<td>Hash calculation &lt;100μs</td>\n</tr>\n<tr>\n<td>Concurrent Access</td>\n<td><code>go test -race ./internal/queue/...</code></td>\n<td>No race conditions detected</td>\n<td>Thread-safe under load</td>\n</tr>\n</tbody></table>\n<p><strong>Redis Integration Testing</strong> validates the persistent queue backend handles Redis connection failures and ensures data durability across service restarts.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Redis Integration Validation:\n1. Start Redis and queue service\n2. Submit 1000 jobs with mixed priorities\n3. Stop queue service (graceful shutdown)\n4. Restart queue service \n5. Verify all jobs recovered with correct priorities\n6. Test Redis failover scenarios</code></pre></div>\n\n<p><strong>Deduplication Accuracy Tests</strong> verify the duplicate detection logic correctly identifies duplicate submissions while avoiding false positives that would reject legitimate jobs.</p>\n<table>\n<thead>\n<tr>\n<th>Deduplication Scenario</th>\n<th>Input Jobs</th>\n<th>Expected Outcome</th>\n<th>Validation</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Identical Payloads</td>\n<td>Same job submitted twice</td>\n<td>Only one job queued</td>\n<td>Content hash match detected</td>\n</tr>\n<tr>\n<td>Same Idempotency Key</td>\n<td>Different payloads, same key</td>\n<td>Both jobs rejected after first</td>\n<td>Key-based deduplication</td>\n</tr>\n<tr>\n<td>Hash Collision Simulation</td>\n<td>Crafted payloads with same hash</td>\n<td>Jobs accepted, full comparison performed</td>\n<td>Rare collision handled</td>\n</tr>\n</tbody></table>\n<h4 id=\"milestone-3-worker-coordination-validation\">Milestone 3: Worker Coordination Validation</h4>\n<p>The third milestone checkpoint validates the complete distributed coordination system including leader election, worker registration, and job recovery mechanisms.</p>\n<p><strong>Coordination System Testing</strong> verifies the distributed consensus and worker management functionality operates correctly across multiple nodes.</p>\n<table>\n<thead>\n<tr>\n<th>Coordination Feature</th>\n<th>Test Approach</th>\n<th>Success Criteria</th>\n<th>Fault Tolerance</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Leader Election</td>\n<td>Multi-node cluster startup</td>\n<td>Single leader elected</td>\n<td>Recovery from leader failure</td>\n</tr>\n<tr>\n<td>Worker Registration</td>\n<td>Dynamic worker join/leave</td>\n<td>Workers tracked correctly</td>\n<td>Graceful shutdown handling</td>\n</tr>\n<tr>\n<td>Job Assignment</td>\n<td>Multi-worker job distribution</td>\n<td>Fair load balancing</td>\n<td>Failed worker job recovery</td>\n</tr>\n<tr>\n<td>Heartbeat Monitoring</td>\n<td>Worker health tracking</td>\n<td>Failure detection within SLA</td>\n<td>False positive prevention</td>\n</tr>\n</tbody></table>\n<p><strong>Multi-Node Integration Tests</strong> validate system behavior across realistic deployment scenarios with multiple coordinator and worker nodes.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Multi-Node Test Scenario:\n1. Deploy 3-node coordinator cluster\n2. Register 5 worker nodes with varying capacity\n3. Submit continuous job stream (100 jobs/minute)\n4. Introduce random worker failures\n5. Verify job completion rate &gt;99%\n6. Validate no duplicate job executions\n7. Confirm system stability over 1-hour test</code></pre></div>\n\n<p><strong>Failure Recovery Validation</strong> tests the system&#39;s ability to maintain operation and data consistency during various failure scenarios.</p>\n<table>\n<thead>\n<tr>\n<th>Failure Type</th>\n<th>Recovery Test</th>\n<th>Validation Metrics</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Worker Node Failure</td>\n<td>Kill worker during job execution</td>\n<td>Jobs reassigned within 60 seconds</td>\n</tr>\n<tr>\n<td>Coordinator Failure</td>\n<td>Kill leader node</td>\n<td>New leader elected within 30 seconds</td>\n</tr>\n<tr>\n<td>Network Partition</td>\n<td>Isolate subset of nodes</td>\n<td>Majority partition continues operation</td>\n</tr>\n<tr>\n<td>Database Failure</td>\n<td>Redis/etcd unavailability</td>\n<td>Graceful degradation, recovery on reconnect</td>\n</tr>\n</tbody></table>\n<p><strong>End-to-End System Validation</strong> confirms the complete system delivers the promised distributed job scheduling functionality with acceptable performance and reliability characteristics.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Complete System Checkpoint:\n✓ Cron jobs scheduled with &lt;5 second accuracy\n✓ Priority ordering maintained under load\n✓ Worker failures handled without job loss  \n✓ Leader election completes in &lt;30 seconds\n✓ System throughput &gt;1000 jobs/hour/worker\n✓ Memory usage bounded under continuous operation\n✓ No race conditions detected in stress testing</code></pre></div>\n\n<blockquote>\n<p><strong>Milestone Checkpoint Philosophy</strong>: Each checkpoint should validate not just new functionality but also ensure previous milestone capabilities remain intact. This regression prevention approach catches integration issues early and provides confidence for continued development on a solid foundation.</p>\n</blockquote>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The testing strategy implementation requires careful orchestration of test environments, mock services, and validation frameworks that can handle the complexity of distributed system testing while maintaining deterministic and reproducible results.</p>\n<p><strong>A. Testing Technology Recommendations:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Unit Testing</td>\n<td>Go&#39;s built-in testing package</td>\n<td>Testify with assertions and mocking</td>\n</tr>\n<tr>\n<td>Integration Testing</td>\n<td>Docker Compose test environments</td>\n<td>Kubernetes test namespaces</td>\n</tr>\n<tr>\n<td>Mock Services</td>\n<td>Hand-written mocks</td>\n<td>Gomock generated mocks</td>\n</tr>\n<tr>\n<td>Time Control</td>\n<td>Fixed time.Now() override</td>\n<td>Clockwork time manipulation</td>\n</tr>\n<tr>\n<td>Redis Testing</td>\n<td>Miniredis embedded server</td>\n<td>Real Redis with test database</td>\n</tr>\n<tr>\n<td>etcd Testing</td>\n<td>Embedded etcd test server</td>\n<td>Real etcd cluster in containers</td>\n</tr>\n</tbody></table>\n<p><strong>B. Testing File Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>project-root/\n  internal/\n    cron/\n      parser.go\n      parser_test.go           ← Unit tests for cron parsing\n      integration_test.go      ← Cron timing integration tests\n    queue/\n      priority.go\n      priority_test.go         ← Unit tests for queue operations\n      redis_test.go           ← Redis integration tests\n    coordinator/\n      coordinator.go\n      coordinator_test.go      ← Unit tests for coordination logic\n      election_test.go        ← Leader election integration tests\n  test/\n    integration/\n      multi_worker_test.go     ← Multi-node integration scenarios\n      failure_injection_test.go ← Failure recovery tests\n      e2e_test.go             ← Complete system validation\n    fixtures/\n      test_jobs.json          ← Sample job definitions\n      cron_expressions.txt    ← Test cron patterns\n    mocks/\n      mock_storage.go         ← Generated storage mocks\n      mock_transport.go       ← Generated transport mocks\n  scripts/\n    test_runner.sh            ← Automated test execution\n    setup_test_env.sh         ← Test environment setup</code></pre></div>\n\n<p><strong>C. Core Testing Infrastructure (Complete Implementation):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// test/infrastructure/test_harness.go</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> infrastructure</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">context</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">testing</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">github.com/stretchr/testify/require</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">github.com/alicebob/miniredis/v2</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">go.etcd.io/etcd/server/v3/embed</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// TestHarness provides complete testing infrastructure for distributed scheduler tests</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> TestHarness</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    t        </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">testing</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">T</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    redis    </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">miniredis</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Miniredis</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    etcd     </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">embed</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Etcd</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cleanup  []</span><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    timeCtrl </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">TimeController</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// NewTestHarness creates a complete testing environment with Redis, etcd, and time control</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewTestHarness</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">t</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">testing</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">T</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">TestHarness</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    redis, err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> miniredis.</span><span style=\"color:#B392F0\">Run</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    require.</span><span style=\"color:#B392F0\">NoError</span><span style=\"color:#E1E4E8\">(t, err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    etcdConfig </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> embed.</span><span style=\"color:#B392F0\">NewConfig</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    etcdConfig.Dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> t.</span><span style=\"color:#B392F0\">TempDir</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    etcdConfig.LogLevel </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"error\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    etcdConfig.Logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"zap\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    etcd, err </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> embed.</span><span style=\"color:#B392F0\">StartEtcd</span><span style=\"color:#E1E4E8\">(etcdConfig)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    require.</span><span style=\"color:#B392F0\">NoError</span><span style=\"color:#E1E4E8\">(t, err)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    harness </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">TestHarness</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        t:        t,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        redis:    redis,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        etcd:     etcd,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        timeCtrl: </span><span style=\"color:#B392F0\">NewTimeController</span><span style=\"color:#E1E4E8\">(),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        cleanup:  </span><span style=\"color:#B392F0\">make</span><span style=\"color:#E1E4E8\">([]</span><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\">(), </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    harness.cleanup </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> append</span><span style=\"color:#E1E4E8\">(harness.cleanup, </span><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        redis.</span><span style=\"color:#B392F0\">Close</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        etcd.</span><span style=\"color:#B392F0\">Close</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    })</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> harness</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// TimeController provides deterministic time control for testing</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> TimeController</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    currentTime </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    callbacks   []</span><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewTimeController</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">TimeController</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">TimeController</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        currentTime: time.</span><span style=\"color:#B392F0\">Date</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">2024</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">12</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, time.UTC),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        callbacks:   </span><span style=\"color:#B392F0\">make</span><span style=\"color:#E1E4E8\">([]</span><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\">(time.Time), </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">tc </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">TimeController</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Now</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> tc.currentTime</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">tc </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">TimeController</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Advance</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">duration</span><span style=\"color:#B392F0\"> time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    tc.currentTime </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> tc.currentTime.</span><span style=\"color:#B392F0\">Add</span><span style=\"color:#E1E4E8\">(duration)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> _, callback </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> range</span><span style=\"color:#E1E4E8\"> tc.callbacks {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        callback</span><span style=\"color:#E1E4E8\">(tc.currentTime)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Cleanup releases all test resources</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">h </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">TestHarness</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">Cleanup</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">:=</span><span style=\"color:#B392F0\"> len</span><span style=\"color:#E1E4E8\">(h.cleanup) </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">; i </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">; i</span><span style=\"color:#F97583\">--</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        h.</span><span style=\"color:#B392F0\">cleanup</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#B392F0\">i</span><span style=\"color:#E1E4E8\">]()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>D. Unit Test Skeleton Templates:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// internal/cron/parser_test.go - Cron Parser Unit Tests</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> cron</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">testing</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">github.com/stretchr/testify/assert</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">github.com/stretchr/testify/require</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> TestParseCronExpression</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">t</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">testing</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">T</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    tests </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> []</span><span style=\"color:#F97583\">struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        name        </span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        expression  </span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        expectValid </span><span style=\"color:#F97583\">bool</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        expectError </span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }{</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 1: Add test cases for valid cron expressions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 2: Add test cases for invalid field values  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 3: Add test cases for malformed syntax</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 4: Add test cases for timezone expressions</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> _, tt </span><span style=\"color:#F97583\">:=</span><span style=\"color:#F97583\"> range</span><span style=\"color:#E1E4E8\"> tests {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        t.</span><span style=\"color:#B392F0\">Run</span><span style=\"color:#E1E4E8\">(tt.name, </span><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">t</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">testing</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">T</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // TODO 5: Call ParseCronExpression with test input</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // TODO 6: Validate expected success/failure</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // TODO 7: Check error message format if applicable</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // TODO 8: Verify parsed field values for valid expressions</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        })</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> TestNextExecutionTime</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">t</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">testing</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">T</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Create test cron expressions with known patterns</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Set up controlled time scenarios  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Calculate expected next execution times manually</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Validate NextExecutionTime returns correct results</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Test edge cases like month boundaries and DST</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Verify timezone conversion accuracy</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// internal/queue/priority_test.go - Priority Queue Unit Tests  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> queue</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> TestJobHeapOrdering</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">t</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">testing</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">T</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    heap </span><span style=\"color:#F97583\">:=</span><span style=\"color:#B392F0\"> NewJobHeap</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Create jobs with different priority values</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Insert jobs in random order</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Pop all jobs and verify strict priority ordering</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Test tie-breaking for identical priorities</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Validate heap property maintained during operations</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> TestDelayedJobVisibility</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">t</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">testing</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">T</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    queue </span><span style=\"color:#F97583\">:=</span><span style=\"color:#B392F0\"> NewPriorityQueue</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">testRedisConfig</span><span style=\"color:#E1E4E8\">())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Submit jobs with future ScheduledAt times</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Attempt ClaimJob before scheduled time</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Verify jobs remain invisible </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Advance time to scheduled execution</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Verify jobs become claimable after promotion</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> TestDeduplication</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">t</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">testing</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">T</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    queue </span><span style=\"color:#F97583\">:=</span><span style=\"color:#B392F0\"> NewPriorityQueue</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">testRedisConfig</span><span style=\"color:#E1E4E8\">())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Create jobs with identical idempotency keys</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Submit duplicate jobs concurrently</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Verify only one job accepted</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Test content-based deduplication</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Validate hash collision handling</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>E. Integration Test Framework:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// test/integration/multi_worker_test.go</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> integration</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">context</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">testing</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">sync</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">github.com/stretchr/testify/require</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> TestMultiWorkerJobDistribution</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">t</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">testing</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">T</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    harness </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> infrastructure.</span><span style=\"color:#B392F0\">NewTestHarness</span><span style=\"color:#E1E4E8\">(t)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> harness.</span><span style=\"color:#B392F0\">Cleanup</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Start coordinator cluster with test harness</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Register multiple workers with different capacities</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Submit batch of jobs with mixed priorities</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Verify jobs distributed proportionally to capacity</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Check no jobs claimed by multiple workers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Validate all jobs eventually complete</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> TestWorkerFailureRecovery</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">t</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">testing</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">T</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    harness </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> infrastructure.</span><span style=\"color:#B392F0\">NewTestHarness</span><span style=\"color:#E1E4E8\">(t)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    defer</span><span style=\"color:#E1E4E8\"> harness.</span><span style=\"color:#B392F0\">Cleanup</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Start system with multiple workers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Assign jobs to workers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Simulate worker failure (kill process)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Verify failed worker jobs are reassigned</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Confirm no duplicate execution occurs</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Check system continues normal operation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>F. Milestone Checkpoint Validation:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">#!/bin/bash</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># scripts/milestone_checkpoint.sh</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Milestone 1: Cron Parser Validation</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#9ECBFF\"> \"=== Milestone 1: Cron Expression Parser ===\"</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> test</span><span style=\"color:#79B8FF\"> -v</span><span style=\"color:#9ECBFF\"> ./internal/cron/...</span><span style=\"color:#F97583\"> ||</span><span style=\"color:#79B8FF\"> exit</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> test</span><span style=\"color:#79B8FF\"> -race</span><span style=\"color:#9ECBFF\"> ./internal/cron/...</span><span style=\"color:#F97583\"> ||</span><span style=\"color:#79B8FF\"> exit</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Validate specific parser capabilities</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#9ECBFF\"> \"Testing cron expression edge cases...\"</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> run</span><span style=\"color:#9ECBFF\"> ./cmd/cron-validator/</span><span style=\"color:#F97583\"> &#x3C;</span><span style=\"color:#9ECBFF\"> test/fixtures/cron_expressions.txt</span><span style=\"color:#F97583\"> ||</span><span style=\"color:#79B8FF\"> exit</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Milestone 2: Priority Queue Validation  </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#9ECBFF\"> \"=== Milestone 2: Priority Queue System ===\"</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> test</span><span style=\"color:#79B8FF\"> -v</span><span style=\"color:#9ECBFF\"> ./internal/queue/...</span><span style=\"color:#F97583\"> ||</span><span style=\"color:#79B8FF\"> exit</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Start Redis for integration testing</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">docker</span><span style=\"color:#9ECBFF\"> run</span><span style=\"color:#79B8FF\"> -d</span><span style=\"color:#79B8FF\"> --name</span><span style=\"color:#9ECBFF\"> test-redis</span><span style=\"color:#79B8FF\"> -p</span><span style=\"color:#9ECBFF\"> 6379:6379</span><span style=\"color:#9ECBFF\"> redis:alpine</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">sleep</span><span style=\"color:#79B8FF\"> 2</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> test</span><span style=\"color:#79B8FF\"> -v</span><span style=\"color:#9ECBFF\"> ./test/integration/queue_test.go</span><span style=\"color:#F97583\"> ||</span><span style=\"color:#79B8FF\"> exit</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">docker</span><span style=\"color:#9ECBFF\"> stop</span><span style=\"color:#9ECBFF\"> test-redis</span><span style=\"color:#E1E4E8\"> &#x26;&#x26; </span><span style=\"color:#B392F0\">docker</span><span style=\"color:#9ECBFF\"> rm</span><span style=\"color:#9ECBFF\"> test-redis</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Milestone 3: Worker Coordination Validation</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#9ECBFF\"> \"=== Milestone 3: Worker Coordination ===\"</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> test</span><span style=\"color:#79B8FF\"> -v</span><span style=\"color:#9ECBFF\"> ./internal/coordinator/...</span><span style=\"color:#F97583\"> ||</span><span style=\"color:#79B8FF\"> exit</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> test</span><span style=\"color:#79B8FF\"> -v</span><span style=\"color:#9ECBFF\"> ./test/integration/coordination_test.go</span><span style=\"color:#F97583\"> ||</span><span style=\"color:#79B8FF\"> exit</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># End-to-End System Validation</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#9ECBFF\"> \"=== Complete System Validation ===\"</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">./scripts/setup_test_env.sh</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">go</span><span style=\"color:#9ECBFF\"> test</span><span style=\"color:#79B8FF\"> -v</span><span style=\"color:#79B8FF\"> -timeout=5m</span><span style=\"color:#9ECBFF\"> ./test/integration/e2e_test.go</span><span style=\"color:#F97583\"> ||</span><span style=\"color:#79B8FF\"> exit</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#9ECBFF\"> \"All milestone checkpoints passed successfully!\"</span></span></code></pre></div>\n\n<p><strong>G. Debugging Integration Test Failures:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>Diagnosis</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Tests pass individually, fail in suite</td>\n<td>Resource cleanup issues</td>\n<td>Check for leaked connections/processes</td>\n<td>Add proper cleanup in teardown</td>\n</tr>\n<tr>\n<td>Intermittent integration failures</td>\n<td>Race conditions or timing issues</td>\n<td>Add deterministic timing controls</td>\n<td>Use TimeController for predictable timing</td>\n</tr>\n<tr>\n<td>&quot;Connection refused&quot; errors</td>\n<td>Test infrastructure not ready</td>\n<td>Services starting too quickly</td>\n<td>Add readiness checks before tests</td>\n</tr>\n<tr>\n<td>Memory leaks in long tests</td>\n<td>Resources not released</td>\n<td>Profile memory usage</td>\n<td>Ensure all contexts cancelled, connections closed</td>\n</tr>\n<tr>\n<td>etcd election timeouts</td>\n<td>Cluster formation issues</td>\n<td>Check etcd logs for split-brain</td>\n<td>Configure proper cluster membership</td>\n</tr>\n</tbody></table>\n<p>This comprehensive testing strategy ensures reliable validation of the distributed job scheduler across all implementation phases, providing both development feedback and production confidence through systematic verification of system behavior under normal and failure conditions.</p>\n<h2 id=\"debugging-guide\">Debugging Guide</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section covers debugging techniques that apply across all three milestones - diagnosing cron parsing and scheduling issues (Milestone 1), troubleshooting queue operation failures and priority conflicts (Milestone 2), and resolving worker coordination and distributed consensus problems (Milestone 3).</p>\n</blockquote>\n<p>Debugging a distributed job scheduler presents unique challenges that combine the complexity of distributed systems with the time-sensitive nature of scheduled execution. Think of debugging a distributed scheduler like diagnosing problems in a city&#39;s emergency response system - you need to understand not just individual component failures, but how those failures cascade through the entire coordination network, potentially causing missed emergencies or duplicate responses across multiple stations.</p>\n<p>The debugging process requires systematic observation of three interconnected layers: the scheduling logic that determines when jobs should run, the coordination protocols that distribute work across workers, and the execution monitoring that tracks job completion. Unlike debugging a single-process application where you can step through code linearly, distributed scheduler debugging requires correlating events across multiple nodes, understanding timing relationships, and distinguishing between genuine failures and expected distributed systems behavior like temporary network partitions.</p>\n<p>This guide provides structured approaches to identify, diagnose, and resolve the most common categories of distributed scheduler problems. Each troubleshooting workflow follows a hypothesis-driven approach that systematically eliminates potential causes while gathering evidence about the actual failure mode.</p>\n<h3 id=\"common-symptoms\">Common Symptoms</h3>\n<p>Understanding the observable symptoms of distributed scheduler problems enables rapid problem classification and appropriate diagnostic approaches. Each symptom category corresponds to failures in specific system layers, allowing targeted investigation rather than broad system exploration.</p>\n<p><strong>Duplicate Job Execution Symptoms</strong></p>\n<p>The most critical symptom category involves jobs executing multiple times despite exactly-once execution guarantees. This manifests in several observable patterns that indicate different underlying failure modes.</p>\n<p>Multiple completion reports for the same job represent the classic duplicate execution symptom. The system logs show the same job ID completing successfully on different workers within a short time window, often with identical or conflicting results. This typically indicates failures in the fencing token validation mechanism or race conditions during job claiming.</p>\n<p>Idempotency key violations occur when jobs with identical <code>IdempotencyKey</code> values execute multiple times despite deduplication logic. The symptom appears as duplicate database records, double-charged transactions, or redundant external API calls that should have been prevented by the deduplication system. This suggests failures in the <code>DeduplicationChecker</code> or inconsistent deduplication state across coordinator nodes.</p>\n<p>Worker claim conflicts manifest as multiple workers believing they own the same job simultaneously. The logs show different worker IDs reporting progress or completion for identical job IDs, often accompanied by fencing token validation errors when workers attempt to report completion. This indicates failures in the atomic job claiming mechanism or coordinator split-brain scenarios.</p>\n<p>Retry amplification creates a cascade of duplicate executions when failed jobs retry across multiple workers simultaneously. The symptom appears as exponentially increasing execution attempts for jobs that should follow controlled retry policies, often overwhelming downstream systems with duplicate requests. This suggests coordination failures during worker crash scenarios or incorrect retry state management.</p>\n<table>\n<thead>\n<tr>\n<th>Duplicate Symptom</th>\n<th>Observable Evidence</th>\n<th>Likely Root Cause</th>\n<th>Investigation Priority</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Multiple completion reports</td>\n<td>Same job ID completing on different workers</td>\n<td>Fencing token validation failure</td>\n<td>High - affects data integrity</td>\n</tr>\n<tr>\n<td>Idempotency violations</td>\n<td>Same IdempotencyKey executes multiple times</td>\n<td>DeduplicationChecker failure</td>\n<td>Critical - bypasses client guarantees</td>\n</tr>\n<tr>\n<td>Worker claim conflicts</td>\n<td>Multiple workers reporting same job progress</td>\n<td>Atomic claiming race condition</td>\n<td>High - indicates coordination breakdown</td>\n</tr>\n<tr>\n<td>Retry amplification</td>\n<td>Exponential retry attempts across workers</td>\n<td>Failed worker job recovery logic</td>\n<td>Medium - self-limiting but wasteful</td>\n</tr>\n</tbody></table>\n<p><strong>Missed Schedule Symptoms</strong></p>\n<p>Missed schedules represent the opposite failure mode where jobs fail to execute when expected, violating timing guarantees and potentially causing business impact through delayed processing.</p>\n<p>Cron schedule drift occurs when recurring jobs gradually shift their execution times away from the expected cron schedule. The symptom manifests as jobs that should run every hour at :00 minutes instead executing at :03, then :07, then :12, creating an accumulating delay. This typically indicates problems in next execution time calculation or clock synchronization across coordinator nodes.</p>\n<p>Delayed job promotion failures cause jobs with future execution times to remain invisible past their scheduled execution time. The symptom appears as jobs stuck in delayed state while their <code>ScheduledAt</code> time has passed, often accompanied by gaps in execution logs during specific time periods. This suggests failures in the <code>PromoteDelayedJobs</code> background process.</p>\n<p>Priority queue starvation occurs when high-priority jobs prevent lower-priority jobs from executing, even when worker capacity exists. The symptom manifests as continuously growing queues of lower-priority jobs while only high-priority jobs execute, eventually leading to timeout failures for starved jobs. This indicates problems in priority queue balancing or worker assignment algorithms.</p>\n<p>Timezone calculation errors cause jobs to execute at incorrect absolute times, particularly during daylight saving time transitions. The symptom appears as jobs executing one hour early or late relative to local business hours, or failing to execute during the &quot;spring forward&quot; hour that doesn&#39;t exist. This suggests failures in UTC normalization or timezone conversion logic.</p>\n<p>Worker capacity exhaustion prevents job execution when all workers reach their capacity limits simultaneously. The symptom manifests as growing job queues despite healthy workers, often correlating with long-running job execution times or worker resource constraints. This indicates insufficient worker scaling or improper capacity management.</p>\n<table>\n<thead>\n<tr>\n<th>Missed Schedule Symptom</th>\n<th>Observable Evidence</th>\n<th>Likely Root Cause</th>\n<th>Investigation Priority</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Cron schedule drift</td>\n<td>Gradual execution time delays</td>\n<td>Next execution calculation errors</td>\n<td>Medium - affects long-term reliability</td>\n</tr>\n<tr>\n<td>Delayed job promotion failures</td>\n<td>Jobs stuck past ScheduledAt time</td>\n<td>PromoteDelayedJobs process failure</td>\n<td>High - breaks delayed execution</td>\n</tr>\n<tr>\n<td>Priority queue starvation</td>\n<td>Lower priority jobs never execute</td>\n<td>Priority balancing algorithm failure</td>\n<td>Medium - affects fairness guarantees</td>\n</tr>\n<tr>\n<td>Timezone calculation errors</td>\n<td>Jobs execute at wrong local times</td>\n<td>UTC conversion or DST handling bugs</td>\n<td>High - affects business SLA compliance</td>\n</tr>\n<tr>\n<td>Worker capacity exhaustion</td>\n<td>Growing queues despite healthy workers</td>\n<td>Capacity management or scaling issues</td>\n<td>Medium - affects throughput scaling</td>\n</tr>\n</tbody></table>\n<p><strong>Worker Coordination Failures</strong></p>\n<p>Worker coordination failures disrupt the distributed consensus mechanisms that enable fault-tolerant job distribution, often cascading into both duplicate execution and missed schedule problems.</p>\n<p>Leader election split-brain scenarios occur when multiple coordinator nodes simultaneously believe they hold leadership authority. The symptom manifests as conflicting job assignments, duplicate scheduling decisions, and workers receiving contradictory instructions from different coordinator nodes. The logs show multiple nodes reporting leadership status and issuing fencing tokens with overlapping ranges.</p>\n<p>Heartbeat timeout cascades happen when network issues cause multiple workers to appear failed simultaneously, triggering mass job reassignment that overwhelms the remaining workers. The symptom appears as sudden spikes in job reassignment activity followed by worker overload, often correlating with network connectivity issues or coordination service degradation.</p>\n<p>Worker registration failures prevent new workers from joining the cluster or cause existing workers to lose their registration intermittently. The symptom manifests as workers that appear healthy locally but don&#39;t receive job assignments, often accompanied by authentication or connectivity errors when attempting to register with the coordinator.</p>\n<p>Job recovery loops occur when failed worker detection triggers job reassignment, but the reassignment process itself fails, creating repeated attempts to recover the same jobs. The symptom appears as continuous job state transitions between <code>CLAIMED</code> and <code>PENDING</code> without successful execution, often accompanied by worker state thrashing.</p>\n<p>Fencing token validation errors prevent workers from completing jobs due to stale or invalid authorization tokens. The symptom manifests as successful job execution followed by completion report rejection, causing jobs to remain in <code>EXECUTING</code> state until timeout. This typically indicates coordination service connectivity issues or token generation failures.</p>\n<table>\n<thead>\n<tr>\n<th>Coordination Failure Symptom</th>\n<th>Observable Evidence</th>\n<th>Likely Root Cause</th>\n<th>Investigation Priority</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Leader election split-brain</td>\n<td>Multiple coordinators claiming leadership</td>\n<td>Consensus algorithm failure or network partition</td>\n<td>Critical - affects all system operations</td>\n</tr>\n<tr>\n<td>Heartbeat timeout cascades</td>\n<td>Mass worker failure detection</td>\n<td>Network issues or coordination service overload</td>\n<td>High - triggers unnecessary job reassignment</td>\n</tr>\n<tr>\n<td>Worker registration failures</td>\n<td>Healthy workers not receiving job assignments</td>\n<td>Authentication or connectivity problems</td>\n<td>Medium - affects cluster capacity</td>\n</tr>\n<tr>\n<td>Job recovery loops</td>\n<td>Jobs stuck cycling between CLAIMED and PENDING</td>\n<td>Job reassignment logic failures</td>\n<td>High - creates resource waste and blocks execution</td>\n</tr>\n<tr>\n<td>Fencing token validation errors</td>\n<td>Job completion reports rejected despite success</td>\n<td>Stale tokens or coordinator connectivity issues</td>\n<td>High - causes jobs to appear failed incorrectly</td>\n</tr>\n</tbody></table>\n<h3 id=\"diagnostic-tools\">Diagnostic Tools</h3>\n<p>Effective diagnosis of distributed scheduler problems requires coordinated observation across multiple system components, with particular emphasis on correlating events across time and node boundaries. The diagnostic strategy combines structured logging, quantitative metrics, and distributed tracing to build a comprehensive picture of system behavior during both normal operation and failure scenarios.</p>\n<p><strong>Logging Strategies</strong></p>\n<p>Structured logging provides the foundation for distributed scheduler diagnosis by creating searchable, correlatable records of system events across all components. The logging strategy must balance information richness with performance impact while ensuring consistent data formats across all system boundaries.</p>\n<p>Each log entry includes mandatory context fields that enable correlation across distributed components: <code>component</code> identifies the logging service (coordinator, worker, queue), <code>node_id</code> specifies the physical machine, <code>correlation_id</code> links related operations across services, <code>timestamp</code> provides nanosecond-precision timing, and <code>log_level</code> indicates severity. Additional fields like <code>job_id</code>, <code>worker_id</code>, and <code>fencing_token</code> provide domain-specific context for scheduler operations.</p>\n<p>The coordinator logging strategy focuses on decision points and state transitions that affect job distribution and worker coordination. Leadership election events log candidate announcements, vote outcomes, and leadership transitions with detailed reasoning. Job assignment decisions include worker selection criteria, capacity calculations, and assignment success or failure reasons. Worker health monitoring logs heartbeat reception, timeout detection, and failure recovery initiation with precise timing information.</p>\n<p>Worker logging emphasizes job execution lifecycle and coordination protocol participation. Job claim attempts log the claiming worker ID, job priority comparison results, and atomic claim success or failure with detailed error information. Job execution logging captures start times, progress checkpoints, completion status, and any execution errors with full stack traces. Heartbeat transmission logs include coordinator connectivity status and any heartbeat rejection reasons.</p>\n<p>Queue operation logging tracks job flow through the priority queue system with emphasis on state transitions and timing. Job submission logs include deduplication check results, priority assignment reasoning, and queue insertion confirmation. Job promotion from delayed to active status logs the promotion trigger time and any promotion failures. Priority ordering logs capture job comparison decisions during queue operations.</p>\n<table>\n<thead>\n<tr>\n<th>Log Level</th>\n<th>Coordinator Events</th>\n<th>Worker Events</th>\n<th>Queue Events</th>\n<th>Required Fields</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>ERROR</td>\n<td>Leadership loss, worker failure detection</td>\n<td>Job execution failures, heartbeat rejections</td>\n<td>Queue corruption, deduplication failures</td>\n<td>component, node_id, correlation_id, timestamp, error_details</td>\n</tr>\n<tr>\n<td>WARN</td>\n<td>Slow heartbeat responses, job reassignments</td>\n<td>Long-running jobs, capacity warnings</td>\n<td>Priority queue imbalance, delayed promotion lag</td>\n<td>component, node_id, correlation_id, timestamp, warning_reason</td>\n</tr>\n<tr>\n<td>INFO</td>\n<td>Leadership elections, job assignments</td>\n<td>Job claims, execution completions</td>\n<td>Job submissions, priority promotions</td>\n<td>component, node_id, correlation_id, timestamp, operation_result</td>\n</tr>\n<tr>\n<td>DEBUG</td>\n<td>Heartbeat processing, fencing token generation</td>\n<td>Job progress updates, worker registrations</td>\n<td>Deduplication checks, priority comparisons</td>\n<td>component, node_id, correlation_id, timestamp, detailed_state</td>\n</tr>\n</tbody></table>\n<p><strong>Metrics Collection</strong></p>\n<p>Quantitative metrics provide real-time insight into system health and performance characteristics, enabling both automated alerting and trend analysis for capacity planning. The metrics strategy emphasizes leading indicators that predict problems before they cause observable failures.</p>\n<p>Job execution metrics track the core business functionality of the scheduler system. Job submission rate measures incoming work load with breakdown by priority levels and job types. Job completion rate tracks successful execution with timing distributions to identify performance degradation. Job failure rate monitors error conditions with categorization by failure type (timeout, execution error, coordination failure) to identify systemic issues. Job queue depth measures pending work backlog with priority-level breakdown to identify starvation or overload conditions.</p>\n<p>Worker coordination metrics monitor the health of the distributed consensus mechanisms. Active worker count tracks cluster capacity with breakdown by worker capabilities and current load. Heartbeat latency measures coordination responsiveness with percentile distributions to identify coordination service degradation. Leader election frequency tracks consensus stability - frequent elections indicate network or leadership failures. Job assignment latency measures the time from job submission to worker claim, indicating coordination efficiency.</p>\n<p>Queue operation metrics provide insight into the priority queue performance and correctness. Deduplication hit rate measures how frequently duplicate jobs are submitted, indicating client behavior patterns. Delayed job promotion latency tracks the accuracy of scheduled execution timing. Priority queue operation latency measures the performance of queue insertions and claims under load.</p>\n<p>System-level metrics monitor the underlying infrastructure health. Coordination service response times track etcd or Redis performance that underpins consensus operations. Network partition detection counts coordination connectivity failures between nodes. Memory usage tracks queue size growth and potential memory leaks in long-running processes.</p>\n<table>\n<thead>\n<tr>\n<th>Metric Category</th>\n<th>Metric Name</th>\n<th>Aggregation</th>\n<th>Alert Thresholds</th>\n<th>Business Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Job Execution</td>\n<td>job_submission_rate</td>\n<td>Per second by priority</td>\n<td>&gt; 1000/sec (capacity warning)</td>\n<td>Indicates incoming load trends</td>\n</tr>\n<tr>\n<td>Job Execution</td>\n<td>job_completion_latency_p99</td>\n<td>99th percentile in milliseconds</td>\n<td>&gt; 30000ms (30 second warning)</td>\n<td>Affects SLA compliance</td>\n</tr>\n<tr>\n<td>Job Execution</td>\n<td>job_failure_rate</td>\n<td>Percentage over 5-minute window</td>\n<td>&gt; 5% (critical alert)</td>\n<td>Direct business impact</td>\n</tr>\n<tr>\n<td>Worker Coordination</td>\n<td>active_worker_count</td>\n<td>Current count</td>\n<td>&lt; 2 workers (critical alert)</td>\n<td>Affects fault tolerance</td>\n</tr>\n<tr>\n<td>Worker Coordination</td>\n<td>heartbeat_latency_p95</td>\n<td>95th percentile in milliseconds</td>\n<td>&gt; 5000ms (coordination degradation)</td>\n<td>Predicts coordination failures</td>\n</tr>\n<tr>\n<td>Worker Coordination</td>\n<td>leader_election_frequency</td>\n<td>Elections per hour</td>\n<td>&gt; 1/hour (stability warning)</td>\n<td>Indicates consensus instability</td>\n</tr>\n<tr>\n<td>Queue Operations</td>\n<td>deduplication_hit_rate</td>\n<td>Percentage over 1-minute window</td>\n<td>&gt; 50% (client behavior warning)</td>\n<td>Indicates client retry storms</td>\n</tr>\n<tr>\n<td>Queue Operations</td>\n<td>delayed_promotion_lag</td>\n<td>Seconds behind scheduled time</td>\n<td>&gt; 60s (timing accuracy warning)</td>\n<td>Affects schedule reliability</td>\n</tr>\n</tbody></table>\n<p><strong>Distributed Tracing Approaches</strong></p>\n<p>Distributed tracing reconstructs the complete execution flow of individual jobs across multiple system components, providing causal relationships between events that are difficult to establish through logs and metrics alone. The tracing strategy focuses on critical execution paths that cross service boundaries.</p>\n<p>Job execution traces begin with job submission and follow the complete lifecycle through queue insertion, delayed promotion, worker assignment, execution, and completion reporting. Each trace span represents a logical operation within a single component, while the overall trace shows the end-to-end execution flow with precise timing information and failure points.</p>\n<p>The job submission trace span captures the initial request processing including payload validation, deduplication checking, priority assignment, and queue insertion. The trace includes custom attributes for job priority, scheduled execution time, and deduplication results that enable filtering and analysis of specific job patterns.</p>\n<p>Queue operation spans track the job through priority queue management including delayed job promotion, priority comparison during claims, and atomic job assignment. The trace attributes include queue depth at operation time, priority comparison results, and worker selection criteria that influenced assignment decisions.</p>\n<p>Worker execution spans capture the actual job processing including claim acquisition, execution startup, progress reporting, and completion status. The span attributes include worker capacity information, execution environment details, and any error conditions that occurred during processing.</p>\n<p>Coordination protocol spans track the distributed consensus operations that enable worker coordination including heartbeat processing, leader election participation, and job recovery operations. These spans often cross multiple service boundaries as coordination decisions propagate through the cluster.</p>\n<p>Trace sampling strategies balance information completeness with system performance impact. All failed operations generate traces regardless of sampling rate to ensure failure diagnosis information is always available. Successful operations use adaptive sampling that increases trace collection during periods of high error rates or performance degradation.</p>\n<table>\n<thead>\n<tr>\n<th>Trace Type</th>\n<th>Span Hierarchy</th>\n<th>Key Attributes</th>\n<th>Sampling Rate</th>\n<th>Retention Period</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Job Execution</td>\n<td>submission → queue_insert → promotion → assignment → execution → completion</td>\n<td>job_id, priority, worker_id, execution_time</td>\n<td>1% normal, 100% on failures</td>\n<td>7 days</td>\n</tr>\n<tr>\n<td>Worker Coordination</td>\n<td>heartbeat → health_check → assignment_eligibility → job_claim</td>\n<td>worker_id, capacity, capabilities, claim_result</td>\n<td>5% normal, 100% on coordination failures</td>\n<td>3 days</td>\n</tr>\n<tr>\n<td>Queue Operations</td>\n<td>priority_comparison → deduplication_check → atomic_insert → delayed_promotion</td>\n<td>queue_depth, priority_order, dedup_result, promotion_timing</td>\n<td>10% normal, 100% on queue errors</td>\n<td>5 days</td>\n</tr>\n<tr>\n<td>Coordination Protocol</td>\n<td>leader_election → consensus_vote → leadership_transition → authority_validation</td>\n<td>node_id, vote_result, leadership_status, authority_scope</td>\n<td>100% always</td>\n<td>14 days</td>\n</tr>\n</tbody></table>\n<h3 id=\"troubleshooting-workflows\">Troubleshooting Workflows</h3>\n<p>Systematic troubleshooting workflows provide structured approaches to diagnose and resolve the most common categories of distributed scheduler failures. Each workflow follows a hypothesis-driven methodology that systematically eliminates potential causes while gathering evidence about the actual failure mode.</p>\n<p><strong>Network Partition Diagnosis</strong></p>\n<p>Network partitions represent one of the most challenging failure modes in distributed scheduler systems, creating scenarios where different parts of the cluster have inconsistent views of system state. The partition diagnosis workflow systematically identifies partition boundaries and determines appropriate recovery strategies.</p>\n<p>The initial partition detection phase examines coordination service connectivity patterns across all cluster nodes. Begin by checking etcd or Redis connectivity from each coordinator and worker node, looking for patterns where specific node groups can communicate internally but cannot reach other groups. Review network routing tables and firewall configurations to identify infrastructure changes that might have created connectivity barriers.</p>\n<p>Coordinator split-brain investigation focuses on leadership status across the cluster. Query the leadership election state from each coordinator node to identify whether multiple nodes believe they hold leadership authority. Check the fencing token generation logs to see if multiple coordinators are issuing overlapping token ranges, which indicates split-brain scenarios. Review recent leadership election logs for unusual patterns like rapid leadership transitions or vote timeouts.</p>\n<p>Worker isolation analysis determines which workers can communicate with which coordinators during the partition. Check worker heartbeat logs to identify patterns where workers successfully send heartbeats to some coordinators but receive timeout errors from others. Review job assignment patterns to see if specific workers are receiving assignments from multiple coordinator nodes simultaneously.</p>\n<p>Job state consistency verification examines whether the same jobs have different states on different sides of the partition. Query job state from multiple coordinator nodes and compare results, looking for jobs that appear as <code>EXECUTING</code> on one coordinator but <code>PENDING</code> on another. Check for duplicate job assignments where the same job ID is claimed by workers on different sides of the partition.</p>\n<p>Recovery strategy determination depends on the partition scope and duration. For brief network hiccups lasting less than heartbeat timeout intervals, the system should self-recover as connectivity resumes. For sustained partitions lasting longer than coordination timeouts, manual intervention may be required to resolve state inconsistencies and prevent duplicate job execution during partition recovery.</p>\n<table>\n<thead>\n<tr>\n<th>Partition Symptom</th>\n<th>Investigation Steps</th>\n<th>Evidence to Collect</th>\n<th>Recovery Action</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Multiple leaders detected</td>\n<td>Check leadership status on all coordinators</td>\n<td>Leadership election logs, fencing token ranges</td>\n<td>Stop all coordinators, restart with clean election</td>\n</tr>\n<tr>\n<td>Worker heartbeat split</td>\n<td>Verify worker connectivity to each coordinator</td>\n<td>Heartbeat success/failure patterns by coordinator</td>\n<td>Identify majority partition, isolate minority nodes</td>\n</tr>\n<tr>\n<td>Duplicate job assignments</td>\n<td>Compare job states across coordinators</td>\n<td>Job state differences, worker claim conflicts</td>\n<td>Cancel assignments from minority partition coordinators</td>\n</tr>\n<tr>\n<td>Coordination service split</td>\n<td>Test etcd/Redis connectivity from each node</td>\n<td>Connection success patterns, error messages</td>\n<td>Restore network connectivity, restart coordination service</td>\n</tr>\n</tbody></table>\n<p><strong>Timing Issue Analysis</strong></p>\n<p>Timing-related problems in distributed schedulers often involve subtle interactions between clock synchronization, timezone handling, and distributed coordination that create intermittent failures difficult to reproduce consistently.</p>\n<p>Clock skew detection examines time differences across cluster nodes that can cause coordination failures or incorrect scheduling decisions. Begin by comparing system clock values across all coordinator and worker nodes, looking for differences larger than a few seconds. Check NTP synchronization status and identify any nodes that have lost time synchronization or are using different time sources.</p>\n<p>Cron expression evaluation verification tests the next execution time calculation logic against known timezone and daylight saving time scenarios. Create test cases with specific cron expressions and verify that next execution times are calculated correctly across DST transitions, leap years, and month boundaries. Pay particular attention to expressions using day-of-week and day-of-month combinations that can create complex interaction patterns.</p>\n<p>Delayed job promotion timing analysis examines the accuracy of scheduled job execution by comparing actual execution times with intended schedule times. Review the <code>PromoteDelayedJobs</code> execution logs to identify patterns where promotion occurs significantly before or after the intended execution time. Check for systematic delays that might indicate performance problems in the promotion process.</p>\n<p>Coordination timeout investigation focuses on distributed operation timing that affects consensus and job assignment. Review heartbeat timeout patterns to identify whether timeouts occur due to network latency, coordinator overload, or genuine worker failures. Examine job claim timeouts that might indicate coordination service performance problems or excessive contention during high-load periods.</p>\n<p>Race condition identification requires careful analysis of timing-sensitive operations that might behave differently under varying load or network conditions. Focus on atomic job claiming operations where multiple workers might attempt to claim the same job simultaneously. Review fencing token validation timing to identify scenarios where token expiration occurs between job claim and completion reporting.</p>\n<table>\n<thead>\n<tr>\n<th>Timing Issue Category</th>\n<th>Diagnostic Approach</th>\n<th>Tools and Techniques</th>\n<th>Resolution Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Clock skew problems</td>\n<td>Compare system times across all nodes</td>\n<td>chrony/ntpd status, manual time comparison</td>\n<td>Implement NTP synchronization, add clock skew detection</td>\n</tr>\n<tr>\n<td>Cron calculation errors</td>\n<td>Test edge cases with known correct results</td>\n<td>Unit tests for DST transitions, month boundaries</td>\n<td>Fix timezone handling logic, add comprehensive test coverage</td>\n</tr>\n<tr>\n<td>Delayed promotion lag</td>\n<td>Compare intended vs actual execution times</td>\n<td>PromoteDelayedJobs timing logs, execution latency metrics</td>\n<td>Optimize promotion process, adjust promotion interval</td>\n</tr>\n<tr>\n<td>Coordination timeouts</td>\n<td>Analyze heartbeat and consensus timing</td>\n<td>Coordination service performance metrics, network latency</td>\n<td>Tune timeout values, improve coordination service performance</td>\n</tr>\n<tr>\n<td>Job claim race conditions</td>\n<td>Review atomic operation timing</td>\n<td>Concurrent claim attempt logs, success/failure patterns</td>\n<td>Implement stronger consistency guarantees, add retry logic</td>\n</tr>\n</tbody></table>\n<p><strong>Race Condition Investigation</strong></p>\n<p>Race conditions in distributed schedulers typically occur during concurrent operations on shared state, creating timing-dependent failures that may only manifest under specific load or network conditions.</p>\n<p>Job claiming race condition analysis focuses on scenarios where multiple workers attempt to claim the same job simultaneously. Begin by reviewing job claim attempt logs during high-concurrency periods, looking for patterns where multiple workers report successful claim operations for the same job ID. Examine the atomic operation implementation in the underlying storage system to verify that compare-and-swap operations are functioning correctly.</p>\n<p>Deduplication race condition investigation examines scenarios where identical jobs bypass deduplication logic due to timing windows in the duplicate detection process. Review job submission logs for jobs with identical <code>IdempotencyKey</code> values that both result in successful queue insertion. Check the deduplication hash table consistency and verify that hash computation produces identical results for equivalent job payloads.</p>\n<p>Worker registration race conditions occur when multiple workers attempt to register with the same ID simultaneously or when worker state updates conflict during rapid heartbeat processing. Examine worker registration logs for duplicate worker IDs or workers that appear to register successfully but don&#39;t receive job assignments. Review heartbeat processing for workers that report successful heartbeat transmission but show as unavailable in coordinator state.</p>\n<p>Coordination state race conditions involve conflicts during leader election or job assignment operations where distributed state updates occur in different orders across cluster nodes. Review leadership election logs for scenarios where vote counting produces inconsistent results or where multiple nodes claim victory simultaneously. Examine job assignment state for jobs that appear assigned to multiple workers or workers that report assignment conflicts.</p>\n<p>Recovery operation race conditions can occur when failed worker detection triggers job reassignment while the original worker is still processing the job successfully. Review job recovery logs for scenarios where job reassignment occurs followed by completion reports from the original worker. Check fencing token validation for jobs that complete successfully but have their completion reports rejected due to stale authorization.</p>\n<table>\n<thead>\n<tr>\n<th>Race Condition Type</th>\n<th>Detection Method</th>\n<th>Evidence Patterns</th>\n<th>Mitigation Approach</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Job claim conflicts</td>\n<td>Multiple workers claiming same job</td>\n<td>Duplicate successful claim logs for same job ID</td>\n<td>Implement stronger atomic operations, add claim verification</td>\n</tr>\n<tr>\n<td>Deduplication bypass</td>\n<td>Identical IdempotencyKey jobs both execute</td>\n<td>Same IdempotencyKey with multiple queue insertions</td>\n<td>Add deduplication transaction scope, implement retries</td>\n</tr>\n<tr>\n<td>Worker registration conflicts</td>\n<td>Duplicate worker IDs or state inconsistency</td>\n<td>Worker registration success with no job assignments</td>\n<td>Serialize worker registration, add registration verification</td>\n</tr>\n<tr>\n<td>Coordination state conflicts</td>\n<td>Inconsistent leadership or assignment state</td>\n<td>Multiple leaders or conflicting job assignments</td>\n<td>Implement coordination transaction boundaries</td>\n</tr>\n<tr>\n<td>Recovery operation conflicts</td>\n<td>Job reassignment during successful execution</td>\n<td>Job completion after reassignment triggers</td>\n<td>Strengthen fencing token validation, add recovery coordination</td>\n</tr>\n</tbody></table>\n<p>⚠️ <strong>Pitfall: Log Analysis Without Correlation</strong></p>\n<p>A common debugging mistake involves analyzing logs from individual components without correlating events across the distributed system boundaries. For example, investigating duplicate job execution by only examining worker logs misses the coordination failures that enabled the duplication. Always gather logs from all relevant components (coordinator, worker, queue) for the same time period and correlate events using <code>correlation_id</code> and <code>job_id</code> fields to understand the complete failure sequence.</p>\n<p>⚠️ <strong>Pitfall: Metric Alert Threshold Sensitivity</strong></p>\n<p>Setting metric alert thresholds too sensitively creates alert fatigue while setting them too loosely misses genuine problems. Distributed scheduler metrics often show natural variation due to job patterns and network conditions. Establish baseline behavior during normal operation before setting alert thresholds, and use percentage-based thresholds rather than absolute values to account for system scaling.</p>\n<p>⚠️ <strong>Pitfall: Race Condition Reproduction Attempts</strong></p>\n<p>Attempting to reproduce race conditions by manually triggering concurrent operations often fails because the timing conditions that created the original race may not be replicable in testing environments. Instead, focus on identifying the shared state and atomic operation boundaries where races can occur, then implement stronger consistency guarantees rather than trying to reproduce the exact race scenario.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>Implementing effective debugging capabilities requires building observability into the distributed scheduler from the ground up, rather than adding diagnostic tools as an afterthought. The debugging implementation focuses on structured data collection, efficient storage and retrieval, and automated analysis tools that accelerate problem diagnosis.</p>\n<p><strong>Technology Recommendations</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n<th>Trade-offs</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Structured Logging</td>\n<td>Go standard log/slog with JSON formatting</td>\n<td>ELK Stack (Elasticsearch, Logstash, Kibana)</td>\n<td>Simple: easy setup, limited search. Advanced: powerful search, complex infrastructure</td>\n</tr>\n<tr>\n<td>Metrics Collection</td>\n<td>Prometheus with Go prometheus client</td>\n<td>Datadog or New Relic with custom dashboards</td>\n<td>Simple: open source, self-hosted. Advanced: managed service, better UI</td>\n</tr>\n<tr>\n<td>Distributed Tracing</td>\n<td>Jaeger with OpenTelemetry Go SDK</td>\n<td>Zipkin with custom span correlation</td>\n<td>Simple: CNCF standard, good community. Advanced: better performance analysis</td>\n</tr>\n<tr>\n<td>Time Series Database</td>\n<td>Prometheus for metrics storage</td>\n<td>InfluxDB with Grafana for visualization</td>\n<td>Simple: integrated with collection. Advanced: better time series performance</td>\n</tr>\n<tr>\n<td>Log Aggregation</td>\n<td>File-based logging with logrotate</td>\n<td>Fluentd with Elasticsearch backend</td>\n<td>Simple: no external dependencies. Advanced: centralized searchable logs</td>\n</tr>\n</tbody></table>\n<p><strong>Recommended File Structure</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>internal/\n  debugging/\n    logger.go              ← Structured logging configuration\n    metrics.go             ← Metrics collection and registration  \n    tracing.go             ← Distributed tracing setup\n    correlation.go         ← Correlation ID management\n    diagnostics.go         ← Health check and diagnostic endpoints\n    debug_handler.go       ← Debug information HTTP endpoints\n  monitoring/\n    alerts.go              ← Metric alert definitions\n    dashboards.go          ← Dashboard configuration\n    healthcheck.go         ← System health assessment\ncmd/\n  debug-cli/\n    main.go                ← Command-line debugging utility\n    job_inspector.go       ← Job state inspection commands\n    worker_inspector.go    ← Worker state inspection commands\n    trace_analyzer.go      ← Trace analysis utilities\ntools/\n  log-analyzer/\n    main.go                ← Log analysis and correlation tool\n    pattern_detector.go    ← Common failure pattern detection\n  metrics-dashboard/\n    grafana-config.json    ← Pre-built dashboard definitions\n    alert-rules.yaml       ← Prometheus alert rule definitions</code></pre></div>\n\n<p><strong>Infrastructure Starter Code</strong></p>\n<p>Complete logging infrastructure with structured output and correlation support:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// internal/debugging/logger.go</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> debugging</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">context</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">log/slog</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">os</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> ContextKey</span><span style=\"color:#F97583\"> string</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">const</span><span style=\"color:#79B8FF\"> CorrelationIDKey</span><span style=\"color:#B392F0\"> ContextKey</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"correlation_id\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// CorrelatedLogger provides structured logging with automatic correlation ID injection</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> CorrelatedLogger</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    logger </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">slog</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Logger</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    component </span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    nodeID </span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// NewCorrelatedLogger creates a structured logger with component identification</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewCorrelatedLogger</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">component</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">nodeID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">CorrelatedLogger</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    handler </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> slog.</span><span style=\"color:#B392F0\">NewJSONHandler</span><span style=\"color:#E1E4E8\">(os.Stdout, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#B392F0\">slog</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">HandlerOptions</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Level: slog.LevelDebug,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        AddSource: </span><span style=\"color:#79B8FF\">true</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    })</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    logger </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> slog.</span><span style=\"color:#B392F0\">New</span><span style=\"color:#E1E4E8\">(handler).</span><span style=\"color:#B392F0\">With</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        slog.</span><span style=\"color:#B392F0\">String</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"component\"</span><span style=\"color:#E1E4E8\">, component),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        slog.</span><span style=\"color:#B392F0\">String</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"node_id\"</span><span style=\"color:#E1E4E8\">, nodeID),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        slog.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"timestamp\"</span><span style=\"color:#E1E4E8\">, time.</span><span style=\"color:#B392F0\">Now</span><span style=\"color:#E1E4E8\">()),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">CorrelatedLogger</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        logger: logger,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        component: component,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        nodeID: nodeID,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// WithContext extracts correlation ID from context and adds it to log entry</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">l </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">CorrelatedLogger</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">WithContext</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">slog</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Logger</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    correlationID, ok </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> ctx.</span><span style=\"color:#B392F0\">Value</span><span style=\"color:#E1E4E8\">(CorrelationIDKey).(</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> !</span><span style=\"color:#E1E4E8\">ok {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        correlationID </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"unknown\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> l.logger.</span><span style=\"color:#B392F0\">With</span><span style=\"color:#E1E4E8\">(slog.</span><span style=\"color:#B392F0\">String</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"correlation_id\"</span><span style=\"color:#E1E4E8\">, correlationID))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// JobOperation logs job-related operations with standardized fields</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">l </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">CorrelatedLogger</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">JobOperation</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">level</span><span style=\"color:#B392F0\"> slog</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Level</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">operation</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">jobID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">attrs</span><span style=\"color:#F97583\"> ...</span><span style=\"color:#B392F0\">slog</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Attr</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    logger </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> l.</span><span style=\"color:#B392F0\">WithContext</span><span style=\"color:#E1E4E8\">(ctx).</span><span style=\"color:#B392F0\">With</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        slog.</span><span style=\"color:#B392F0\">String</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"operation\"</span><span style=\"color:#E1E4E8\">, operation),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        slog.</span><span style=\"color:#B392F0\">String</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"job_id\"</span><span style=\"color:#E1E4E8\">, jobID),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    logger.</span><span style=\"color:#B392F0\">LogAttrs</span><span style=\"color:#E1E4E8\">(ctx, level, operation, attrs</span><span style=\"color:#F97583\">...</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// WorkerOperation logs worker-related operations with standardized fields  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">l </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">CorrelatedLogger</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">WorkerOperation</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">level</span><span style=\"color:#B392F0\"> slog</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Level</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">operation</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">workerID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">attrs</span><span style=\"color:#F97583\"> ...</span><span style=\"color:#B392F0\">slog</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Attr</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    logger </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> l.</span><span style=\"color:#B392F0\">WithContext</span><span style=\"color:#E1E4E8\">(ctx).</span><span style=\"color:#B392F0\">With</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        slog.</span><span style=\"color:#B392F0\">String</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"operation\"</span><span style=\"color:#E1E4E8\">, operation),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        slog.</span><span style=\"color:#B392F0\">String</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"worker_id\"</span><span style=\"color:#E1E4E8\">, workerID),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    logger.</span><span style=\"color:#B392F0\">LogAttrs</span><span style=\"color:#E1E4E8\">(ctx, level, operation, attrs</span><span style=\"color:#F97583\">...</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// CoordinationOperation logs coordination protocol events</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">l </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">CorrelatedLogger</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">CoordinationOperation</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ctx</span><span style=\"color:#B392F0\"> context</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Context</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">level</span><span style=\"color:#B392F0\"> slog</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Level</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">operation</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">attrs</span><span style=\"color:#F97583\"> ...</span><span style=\"color:#B392F0\">slog</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Attr</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    logger </span><span style=\"color:#F97583\">:=</span><span style=\"color:#E1E4E8\"> l.</span><span style=\"color:#B392F0\">WithContext</span><span style=\"color:#E1E4E8\">(ctx).</span><span style=\"color:#B392F0\">With</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        slog.</span><span style=\"color:#B392F0\">String</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"operation\"</span><span style=\"color:#E1E4E8\">, operation),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        slog.</span><span style=\"color:#B392F0\">String</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"protocol\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"coordination\"</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    logger.</span><span style=\"color:#B392F0\">LogAttrs</span><span style=\"color:#E1E4E8\">(ctx, level, operation, attrs</span><span style=\"color:#F97583\">...</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p>Complete metrics collection infrastructure with Prometheus integration:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// internal/debugging/metrics.go</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> debugging</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">github.com/prometheus/client_golang/prometheus</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">github.com/prometheus/client_golang/prometheus/promauto</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// SchedulerMetrics provides comprehensive metrics collection for distributed scheduler</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> SchedulerMetrics</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Job execution metrics</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    JobSubmissionRate </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">prometheus</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">CounterVec</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    JobCompletionLatency </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">prometheus</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">HistogramVec</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    JobFailureRate </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">prometheus</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">CounterVec</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    JobQueueDepth </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">prometheus</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">GaugeVec</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Worker coordination metrics  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ActiveWorkerCount </span><span style=\"color:#B392F0\">prometheus</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Gauge</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HeartbeatLatency </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">prometheus</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">HistogramVec</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LeaderElectionCount </span><span style=\"color:#B392F0\">prometheus</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Counter</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    JobAssignmentLatency </span><span style=\"color:#B392F0\">prometheus</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Histogram</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Queue operation metrics</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    DeduplicationHitRate </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">prometheus</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">CounterVec</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    DelayedPromotionLag </span><span style=\"color:#B392F0\">prometheus</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Histogram</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    QueueOperationLatency </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">prometheus</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">HistogramVec</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // System health metrics</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CoordinationServiceLatency </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">prometheus</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">HistogramVec</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    NetworkPartitionCount </span><span style=\"color:#B392F0\">prometheus</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Counter</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    MemoryUsage </span><span style=\"color:#B392F0\">prometheus</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Gauge</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// NewSchedulerMetrics creates and registers all scheduler metrics with Prometheus</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewSchedulerMetrics</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">component</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">SchedulerMetrics</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">SchedulerMetrics</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        JobSubmissionRate: promauto.</span><span style=\"color:#B392F0\">NewCounterVec</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            prometheus</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">CounterOpts</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Name: </span><span style=\"color:#9ECBFF\">\"scheduler_job_submissions_total\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Help: </span><span style=\"color:#9ECBFF\">\"Total number of job submissions by priority level\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            },</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            []</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">{</span><span style=\"color:#9ECBFF\">\"component\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"priority\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"job_type\"</span><span style=\"color:#E1E4E8\">},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        JobCompletionLatency: promauto.</span><span style=\"color:#B392F0\">NewHistogramVec</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            prometheus</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">HistogramOpts</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Name: </span><span style=\"color:#9ECBFF\">\"scheduler_job_completion_duration_seconds\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Help: </span><span style=\"color:#9ECBFF\">\"Job completion latency distribution\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Buckets: []</span><span style=\"color:#F97583\">float64</span><span style=\"color:#E1E4E8\">{</span><span style=\"color:#79B8FF\">0.1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0.5</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">5.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">10.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">30.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">60.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">300.0</span><span style=\"color:#E1E4E8\">},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            },</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            []</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">{</span><span style=\"color:#9ECBFF\">\"component\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"priority\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"success\"</span><span style=\"color:#E1E4E8\">},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        JobFailureRate: promauto.</span><span style=\"color:#B392F0\">NewCounterVec</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            prometheus</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">CounterOpts</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Name: </span><span style=\"color:#9ECBFF\">\"scheduler_job_failures_total\"</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Help: </span><span style=\"color:#9ECBFF\">\"Total job failures by failure type\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            },</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            []</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">{</span><span style=\"color:#9ECBFF\">\"component\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"failure_type\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"retriable\"</span><span style=\"color:#E1E4E8\">},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        JobQueueDepth: promauto.</span><span style=\"color:#B392F0\">NewGaugeVec</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            prometheus</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">GaugeOpts</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Name: </span><span style=\"color:#9ECBFF\">\"scheduler_queue_depth\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Help: </span><span style=\"color:#9ECBFF\">\"Current job queue depth by priority level\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            },</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            []</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">{</span><span style=\"color:#9ECBFF\">\"component\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"priority\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"state\"</span><span style=\"color:#E1E4E8\">},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ActiveWorkerCount: promauto.</span><span style=\"color:#B392F0\">NewGauge</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            prometheus</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">GaugeOpts</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Name: </span><span style=\"color:#9ECBFF\">\"scheduler_active_workers\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Help: </span><span style=\"color:#9ECBFF\">\"Number of currently active workers\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            },</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        HeartbeatLatency: promauto.</span><span style=\"color:#B392F0\">NewHistogramVec</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            prometheus</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">HistogramOpts</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Name: </span><span style=\"color:#9ECBFF\">\"scheduler_heartbeat_latency_seconds\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Help: </span><span style=\"color:#9ECBFF\">\"Worker heartbeat response time distribution\"</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Buckets: []</span><span style=\"color:#F97583\">float64</span><span style=\"color:#E1E4E8\">{</span><span style=\"color:#79B8FF\">0.001</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0.005</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0.01</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0.05</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0.1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0.5</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">5.0</span><span style=\"color:#E1E4E8\">},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            },</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            []</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">{</span><span style=\"color:#9ECBFF\">\"component\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"worker_id\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"success\"</span><span style=\"color:#E1E4E8\">},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        LeaderElectionCount: promauto.</span><span style=\"color:#B392F0\">NewCounter</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            prometheus</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">CounterOpts</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Name: </span><span style=\"color:#9ECBFF\">\"scheduler_leader_elections_total\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Help: </span><span style=\"color:#9ECBFF\">\"Total number of leader election events\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            },</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        JobAssignmentLatency: promauto.</span><span style=\"color:#B392F0\">NewHistogram</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            prometheus</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">HistogramOpts</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Name: </span><span style=\"color:#9ECBFF\">\"scheduler_job_assignment_duration_seconds\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Help: </span><span style=\"color:#9ECBFF\">\"Time from job submission to worker assignment\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Buckets: []</span><span style=\"color:#F97583\">float64</span><span style=\"color:#E1E4E8\">{</span><span style=\"color:#79B8FF\">0.01</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0.05</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0.1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0.5</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">5.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">10.0</span><span style=\"color:#E1E4E8\">},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            },</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        DeduplicationHitRate: promauto.</span><span style=\"color:#B392F0\">NewCounterVec</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            prometheus</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">CounterOpts</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Name: </span><span style=\"color:#9ECBFF\">\"scheduler_deduplication_checks_total\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Help: </span><span style=\"color:#9ECBFF\">\"Deduplication check results\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            },</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            []</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">{</span><span style=\"color:#9ECBFF\">\"component\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"result\"</span><span style=\"color:#E1E4E8\">},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        DelayedPromotionLag: promauto.</span><span style=\"color:#B392F0\">NewHistogram</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            prometheus</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">HistogramOpts</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Name: </span><span style=\"color:#9ECBFF\">\"scheduler_delayed_promotion_lag_seconds\"</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Help: </span><span style=\"color:#9ECBFF\">\"Delay between scheduled time and actual job promotion\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Buckets: []</span><span style=\"color:#F97583\">float64</span><span style=\"color:#E1E4E8\">{</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">30</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">60</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">300</span><span style=\"color:#E1E4E8\">},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            },</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        QueueOperationLatency: promauto.</span><span style=\"color:#B392F0\">NewHistogramVec</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            prometheus</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">HistogramOpts</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Name: </span><span style=\"color:#9ECBFF\">\"scheduler_queue_operation_duration_seconds\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Help: </span><span style=\"color:#9ECBFF\">\"Queue operation latency by operation type\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Buckets: []</span><span style=\"color:#F97583\">float64</span><span style=\"color:#E1E4E8\">{</span><span style=\"color:#79B8FF\">0.0001</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0.0005</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0.001</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0.005</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0.01</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0.05</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0.1</span><span style=\"color:#E1E4E8\">},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            },</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            []</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">{</span><span style=\"color:#9ECBFF\">\"component\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"operation\"</span><span style=\"color:#E1E4E8\">},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        CoordinationServiceLatency: promauto.</span><span style=\"color:#B392F0\">NewHistogramVec</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            prometheus</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">HistogramOpts</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Name: </span><span style=\"color:#9ECBFF\">\"scheduler_coordination_service_duration_seconds\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Help: </span><span style=\"color:#9ECBFF\">\"Coordination service response time distribution\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Buckets: []</span><span style=\"color:#F97583\">float64</span><span style=\"color:#E1E4E8\">{</span><span style=\"color:#79B8FF\">0.001</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0.005</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0.01</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0.05</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0.1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0.5</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1.0</span><span style=\"color:#E1E4E8\">},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            },</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            []</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">{</span><span style=\"color:#9ECBFF\">\"component\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"service\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"operation\"</span><span style=\"color:#E1E4E8\">},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        NetworkPartitionCount: promauto.</span><span style=\"color:#B392F0\">NewCounter</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            prometheus</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">CounterOpts</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Name: </span><span style=\"color:#9ECBFF\">\"scheduler_network_partitions_total\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Help: </span><span style=\"color:#9ECBFF\">\"Total number of detected network partition events\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            },</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        MemoryUsage: promauto.</span><span style=\"color:#B392F0\">NewGauge</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            prometheus</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">GaugeOpts</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Name: </span><span style=\"color:#9ECBFF\">\"scheduler_memory_usage_bytes\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                Help: </span><span style=\"color:#9ECBFF\">\"Current memory usage in bytes\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            },</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// RecordJobSubmission records a job submission event with priority and type labels</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">m </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">SchedulerMetrics</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">RecordJobSubmission</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">component</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">priority</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">jobType</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    m.JobSubmissionRate.</span><span style=\"color:#B392F0\">WithLabelValues</span><span style=\"color:#E1E4E8\">(component, priority, jobType).</span><span style=\"color:#B392F0\">Inc</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// RecordJobCompletion records job completion timing with success indicator</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">m </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">SchedulerMetrics</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">RecordJobCompletion</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">component</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">priority</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">duration</span><span style=\"color:#B392F0\"> time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">success</span><span style=\"color:#F97583\"> bool</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    successLabel </span><span style=\"color:#F97583\">:=</span><span style=\"color:#9ECBFF\"> \"false\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> success {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        successLabel </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"true\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    m.JobCompletionLatency.</span><span style=\"color:#B392F0\">WithLabelValues</span><span style=\"color:#E1E4E8\">(component, priority, successLabel).</span><span style=\"color:#B392F0\">Observe</span><span style=\"color:#E1E4E8\">(duration.</span><span style=\"color:#B392F0\">Seconds</span><span style=\"color:#E1E4E8\">())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// RecordJobFailure records job failure with categorization</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">m </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">SchedulerMetrics</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">RecordJobFailure</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">component</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">failureType</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">retriable</span><span style=\"color:#F97583\"> bool</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    retriableLabel </span><span style=\"color:#F97583\">:=</span><span style=\"color:#9ECBFF\"> \"false\"</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> retriable {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        retriableLabel </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"true\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    m.JobFailureRate.</span><span style=\"color:#B392F0\">WithLabelValues</span><span style=\"color:#E1E4E8\">(component, failureType, retriableLabel).</span><span style=\"color:#B392F0\">Inc</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// UpdateQueueDepth updates the current queue depth for a specific priority level</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">m </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">SchedulerMetrics</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">UpdateQueueDepth</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">component</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">priority</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">state</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">depth</span><span style=\"color:#F97583\"> float64</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    m.JobQueueDepth.</span><span style=\"color:#B392F0\">WithLabelValues</span><span style=\"color:#E1E4E8\">(component, priority, state).</span><span style=\"color:#B392F0\">Set</span><span style=\"color:#E1E4E8\">(depth)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// RecordHeartbeat records worker heartbeat timing and success</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">m </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">SchedulerMetrics</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">RecordHeartbeat</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">component</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">workerID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">latency</span><span style=\"color:#B392F0\"> time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">success</span><span style=\"color:#F97583\"> bool</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    successLabel </span><span style=\"color:#F97583\">:=</span><span style=\"color:#9ECBFF\"> \"false\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> success {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        successLabel </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"true\"</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    m.HeartbeatLatency.</span><span style=\"color:#B392F0\">WithLabelValues</span><span style=\"color:#E1E4E8\">(component, workerID, successLabel).</span><span style=\"color:#B392F0\">Observe</span><span style=\"color:#E1E4E8\">(latency.</span><span style=\"color:#B392F0\">Seconds</span><span style=\"color:#E1E4E8\">())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Core Debugging Utilities</strong></p>\n<p>Debug information collection and analysis utilities:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">go</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// internal/debugging/diagnostics.go</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">package</span><span style=\"color:#B392F0\"> debugging</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">context</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">encoding/json</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">fmt</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">net/http</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">runtime</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"</span><span style=\"color:#B392F0\">time</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// DiagnosticCollector gathers system diagnostic information for debugging</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> DiagnosticCollector</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    component </span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    nodeID    </span><span style=\"color:#F97583\">string</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    startTime </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// SystemDiagnostics contains comprehensive system state for debugging</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> SystemDiagnostics</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Component    </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">            `json:\"component\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    NodeID       </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">            `json:\"node_id\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Timestamp    </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">         `json:\"timestamp\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Uptime       </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#9ECBFF\">     `json:\"uptime\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    MemoryStats  </span><span style=\"color:#B392F0\">runtime</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">MemStats</span><span style=\"color:#9ECBFF\">  `json:\"memory_stats\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    GoRoutines   </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">               `json:\"goroutines\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    SystemInfo   </span><span style=\"color:#B392F0\">SystemInfo</span><span style=\"color:#9ECBFF\">        `json:\"system_info\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CustomState  </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{} </span><span style=\"color:#9ECBFF\">`json:\"custom_state\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// SystemInfo contains basic system identification information</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> SystemInfo</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    GoVersion   </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\"> `json:\"go_version\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    OS          </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\"> `json:\"os\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Arch        </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\"> `json:\"arch\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CPUs        </span><span style=\"color:#F97583\">int</span><span style=\"color:#9ECBFF\">    `json:\"cpus\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// NewDiagnosticCollector creates diagnostic collector for specified component</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewDiagnosticCollector</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">component</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">nodeID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">DiagnosticCollector</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">DiagnosticCollector</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        component: component,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        nodeID:    nodeID,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        startTime: time.</span><span style=\"color:#B392F0\">Now</span><span style=\"color:#E1E4E8\">(),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// CollectDiagnostics gathers comprehensive system diagnostic information</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">d </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">DiagnosticCollector</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">CollectDiagnostics</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">customState</span><span style=\"color:#F97583\"> map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{}) </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">SystemDiagnostics</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    var</span><span style=\"color:#E1E4E8\"> memStats </span><span style=\"color:#B392F0\">runtime</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">MemStats</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    runtime.</span><span style=\"color:#B392F0\">ReadMemStats</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">memStats)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">SystemDiagnostics</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Component:   d.component,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        NodeID:      d.nodeID,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Timestamp:   time.</span><span style=\"color:#B392F0\">Now</span><span style=\"color:#E1E4E8\">(),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Uptime:      time.</span><span style=\"color:#B392F0\">Since</span><span style=\"color:#E1E4E8\">(d.startTime),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        MemoryStats: memStats,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        GoRoutines:  runtime.</span><span style=\"color:#B392F0\">NumGoroutine</span><span style=\"color:#E1E4E8\">(),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        SystemInfo: </span><span style=\"color:#B392F0\">SystemInfo</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            GoVersion: runtime.</span><span style=\"color:#B392F0\">Version</span><span style=\"color:#E1E4E8\">(),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            OS:        runtime.GOOS,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            Arch:      runtime.GOARCH,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            CPUs:      runtime.</span><span style=\"color:#B392F0\">NumCPU</span><span style=\"color:#E1E4E8\">(),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        },</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        CustomState: customState,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// DebugHandler provides HTTP endpoint for diagnostic information retrieval</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> DebugHandler</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    collector </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">DiagnosticCollector</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    stateProvider </span><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// NewDebugHandler creates HTTP handler for debug endpoints</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewDebugHandler</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">collector</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">DiagnosticCollector</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">stateProvider</span><span style=\"color:#F97583\"> func</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{}) </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">DebugHandler</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">DebugHandler</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        collector: collector,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        stateProvider: stateProvider,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ServeHTTP handles diagnostic information requests</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">h </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">DebugHandler</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">ServeHTTP</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">w</span><span style=\"color:#B392F0\"> http</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">ResponseWriter</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">r</span><span style=\"color:#F97583\"> *</span><span style=\"color:#B392F0\">http</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Request</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Extract diagnostic request type from URL path (/debug/system, /debug/state, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Call appropriate diagnostic collection method based on request type</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Collect custom state from stateProvider function</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Marshal diagnostic information to JSON response</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Set appropriate HTTP headers (Content-Type: application/json)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Write JSON response with proper error handling</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use h.collector.CollectDiagnostics(h.stateProvider()) for full diagnostics</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// LogAnalyzer provides utilities for parsing and analyzing structured logs</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> LogAnalyzer</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    correlationIndex </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">][]</span><span style=\"color:#B392F0\">LogEntry</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    timeIndex        []</span><span style=\"color:#B392F0\">LogEntry</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// LogEntry represents a parsed structured log entry</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> LogEntry</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Timestamp     </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Time</span><span style=\"color:#9ECBFF\">              `json:\"timestamp\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Component     </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">                 `json:\"component\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    NodeID        </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">                 `json:\"node_id\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CorrelationID </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">                 `json:\"correlation_id\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Level         </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">                 `json:\"level\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Operation     </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">                 `json:\"operation,omitempty\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    JobID         </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">                 `json:\"job_id,omitempty\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    WorkerID      </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">                 `json:\"worker_id,omitempty\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Message       </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">                 `json:\"message\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Attributes    </span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">interface</span><span style=\"color:#E1E4E8\">{} </span><span style=\"color:#9ECBFF\">`json:\"attributes\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// NewLogAnalyzer creates log analysis utility with indexing capability</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#B392F0\"> NewLogAnalyzer</span><span style=\"color:#E1E4E8\">() </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">LogAnalyzer</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> &#x26;</span><span style=\"color:#B392F0\">LogAnalyzer</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        correlationIndex: </span><span style=\"color:#B392F0\">make</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">map</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#F97583\">string</span><span style=\"color:#E1E4E8\">][]</span><span style=\"color:#B392F0\">LogEntry</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        timeIndex:        </span><span style=\"color:#B392F0\">make</span><span style=\"color:#E1E4E8\">([]</span><span style=\"color:#B392F0\">LogEntry</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// ParseLogLine parses structured JSON log entry and adds to indexes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">a </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">LogAnalyzer</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">ParseLogLine</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">line</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">error</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Parse JSON log line into LogEntry struct</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Add entry to correlationIndex using correlation_id as key</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Insert entry into timeIndex maintaining chronological order</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Return parsing errors with context about malformed fields</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use json.Unmarshal() for parsing and sort.Search() for time index insertion</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// GetCorrelatedEntries retrieves all log entries for specific correlation ID</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">a </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">LogAnalyzer</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">GetCorrelatedEntries</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">correlationID</span><span style=\"color:#F97583\"> string</span><span style=\"color:#E1E4E8\">) []</span><span style=\"color:#B392F0\">LogEntry</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Look up correlation ID in correlationIndex</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Return slice of log entries in chronological order</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Return empty slice if correlation ID not found</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Sort entries by timestamp before returning</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> nil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// AnalyzeFailurePattern identifies common failure patterns in log sequences  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">func</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#FFAB70\">a </span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\">LogAnalyzer</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">AnalyzeFailurePattern</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">entries</span><span style=\"color:#E1E4E8\"> []</span><span style=\"color:#B392F0\">LogEntry</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#B392F0\">FailurePattern</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Scan entries for error-level log messages</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Identify timing patterns (rapid retries, timeout sequences)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Correlate component failure sequences (coordinator -> worker failures)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Classify failure type based on observed patterns</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Return structured failure analysis with root cause hypothesis</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#B392F0\"> FailurePattern</span><span style=\"color:#E1E4E8\">{}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// FailurePattern represents analysis results for a failure sequence</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">type</span><span style=\"color:#B392F0\"> FailurePattern</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    FailureType   </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">    `json:\"failure_type\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    RootCause     </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">    `json:\"root_cause\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ComponentPath []</span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">  `json:\"component_path\"`</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Duration      </span><span style=\"color:#B392F0\">time</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">Duration</span><span style=\"color:#9ECBFF\"> `json:\"duration\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Symptoms      []</span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">  `json:\"symptoms\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Recommendation </span><span style=\"color:#F97583\">string</span><span style=\"color:#9ECBFF\">   `json:\"recommendation\"`</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Milestone Checkpoints</strong></p>\n<p>After implementing the debugging infrastructure, verify the following behavior:</p>\n<ol>\n<li><p><strong>Structured Logging Verification</strong>: Start all scheduler components and submit test jobs. Check that logs contain all required fields (component, node_id, correlation_id, timestamp) and can be filtered by correlation ID. Verify that job operations include job_id fields and worker operations include worker_id fields.</p>\n</li>\n<li><p><strong>Metrics Collection Validation</strong>: Access the metrics endpoint (typically <code>/metrics</code>) and verify that all defined metrics appear with appropriate labels. Submit jobs and confirm that job submission and completion metrics increment correctly. Monitor queue depth metrics during job processing.</p>\n</li>\n<li><p><strong>Diagnostic Endpoint Testing</strong>: Access the debug endpoints (<code>/debug/system</code>) and verify that complete diagnostic information returns in JSON format. Check that memory statistics, goroutine counts, and custom state information appear correctly.</p>\n</li>\n<li><p><strong>Correlation Analysis Testing</strong>: Generate correlated log entries by submitting jobs and verify that the log analyzer can retrieve all entries for a specific correlation ID. Test failure pattern analysis with intentionally failed jobs.</p>\n</li>\n</ol>\n<p><strong>Debugging Tips</strong></p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>Diagnostic Command</th>\n<th>Fix Approach</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Metrics not updating</td>\n<td>Prometheus registration failure</td>\n<td>Check <code>/metrics</code> endpoint for metric presence</td>\n<td>Verify metric registration in component initialization</td>\n</tr>\n<tr>\n<td>Correlation IDs missing</td>\n<td>Context propagation failure</td>\n<td>Grep logs for &quot;correlation_id&quot;:&quot;unknown&quot;</td>\n<td>Add correlation ID to all context.Context values</td>\n</tr>\n<tr>\n<td>Log entries missing fields</td>\n<td>Logger configuration error</td>\n<td>Check log JSON structure with <code>jq</code> tool</td>\n<td>Verify structured logger initialization with required fields</td>\n</tr>\n<tr>\n<td>Debug endpoint returns errors</td>\n<td>State provider function panic</td>\n<td>Check component logs during debug request</td>\n<td>Add error handling in state provider function</td>\n</tr>\n<tr>\n<td>Trace spans not appearing</td>\n<td>Tracing backend connectivity</td>\n<td>Check Jaeger UI for trace presence</td>\n<td>Verify tracing configuration and network connectivity</td>\n</tr>\n</tbody></table>\n<h2 id=\"future-extensions\">Future Extensions</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section explores potential enhancements that build upon the completed implementation of all three milestones - extending the cron parser with workflow dependencies (Milestone 1), adding advanced queue features like resource awareness (Milestone 2), and scaling the worker coordination beyond single-cluster deployments (Milestone 3).</p>\n</blockquote>\n<p>The distributed job scheduler established through the three core milestones provides a solid foundation for reliable, fault-tolerant job execution. However, real-world production systems often require capabilities beyond basic scheduling, prioritization, and coordination. This section outlines significant enhancements that transform the scheduler from a general-purpose task executor into a comprehensive workflow orchestration platform capable of handling complex enterprise workloads across multiple data centers.</p>\n<p>Think of the current scheduler as a well-organized city bus system - it reliably transports passengers (jobs) from origin to destination using fixed routes (cron schedules) with good capacity management (priorities) and fault tolerance (worker coordination). The future extensions described here are like evolving from a bus system to a comprehensive transportation network that includes subways, trains, and planes - adding route dependencies, real-time capacity optimization, and inter-city connections.</p>\n<p>These extensions fall into three categories that build naturally upon the existing architecture. <strong>Advanced Scheduling</strong> capabilities transform the scheduler from executing independent jobs to orchestrating complex workflows with dependencies and resource constraints. <strong>Operational Features</strong> provide the visibility and control mechanisms necessary for production deployments at scale. <strong>Scalability Improvements</strong> enable the scheduler to operate across multiple data centers and handle workloads that exceed single-cluster capacity.</p>\n<blockquote>\n<p>The key architectural insight is that these extensions maintain backward compatibility with the existing three-milestone implementation while adding new layers of functionality. Existing jobs continue to work unchanged, but new capabilities become available through extended APIs and configuration options.</p>\n</blockquote>\n<p>Each extension category addresses different aspects of production readiness. Advanced scheduling tackles the complexity of real-world workflows where jobs have interdependencies and compete for limited resources. Operational features provide the observability and administrative capabilities that operations teams require for managing large-scale deployments. Scalability improvements address the fundamental limits of single-cluster architectures by enabling geographic distribution and horizontal scaling beyond individual data center capacity.</p>\n<h3 id=\"advanced-scheduling\">Advanced Scheduling</h3>\n<p>The current scheduler executes jobs independently based on cron expressions and priorities. Advanced scheduling extends this model to handle <strong>job dependencies</strong>, <strong>resource-aware scheduling</strong>, and <strong>workflow orchestration</strong> - transforming the system from a task executor into a comprehensive workflow engine.</p>\n<p>Think of job dependencies like a restaurant kitchen during dinner service. The salad station can&#39;t plate dishes until the grill finishes the protein, the dessert chef waits for dinner orders to complete, and dishwashing depends on completed courses returning to the kitchen. Similarly, data processing workflows often require strict ordering - the ETL job must complete before the reporting job runs, and the backup job should wait until all database operations finish.</p>\n<h4 id=\"job-dependencies-and-workflow-dags\">Job Dependencies and Workflow DAGs</h4>\n<p>Job dependencies introduce directed acyclic graph (DAG) scheduling where jobs specify prerequisite jobs that must complete successfully before execution begins. This extends the current <code>Job</code> structure to include dependency relationships and success criteria.</p>\n<p><strong>Extended Job Definition for Dependencies:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Dependencies</td>\n<td>[]JobDependency</td>\n<td>List of prerequisite jobs that must complete before this job can execute</td>\n</tr>\n<tr>\n<td>DependencyMode</td>\n<td>DependencyMode</td>\n<td>How to handle dependency completion (ALL_SUCCESS, ANY_SUCCESS, ALL_COMPLETE)</td>\n</tr>\n<tr>\n<td>DependencyTimeout</td>\n<td>time.Duration</td>\n<td>Maximum time to wait for dependencies before marking job as failed</td>\n</tr>\n<tr>\n<td>WorkflowID</td>\n<td>string</td>\n<td>Optional identifier grouping related jobs into a workflow unit</td>\n</tr>\n<tr>\n<td>WorkflowPosition</td>\n<td>int</td>\n<td>Job&#39;s position in workflow execution order (for visualization)</td>\n</tr>\n</tbody></table>\n<p><strong>JobDependency Structure:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>JobID</td>\n<td>string</td>\n<td>Identifier of the prerequisite job</td>\n</tr>\n<tr>\n<td>JobName</td>\n<td>string</td>\n<td>Human-readable name of the prerequisite job for workflow visualization</td>\n</tr>\n<tr>\n<td>RequiredState</td>\n<td>JobState</td>\n<td>Required completion state (COMPLETED for success, FAILED for failure trigger)</td>\n</tr>\n<tr>\n<td>DataPassing</td>\n<td>map[string]string</td>\n<td>Output data from prerequisite job to pass as input to dependent job</td>\n</tr>\n<tr>\n<td>TimeoutAction</td>\n<td>TimeoutAction</td>\n<td>Action when dependency doesn&#39;t complete within timeout (FAIL, SKIP, PROCEED)</td>\n</tr>\n</tbody></table>\n<p>The dependency resolution algorithm operates through a <strong>dependency graph evaluator</strong> that maintains workflow state and triggers job execution when prerequisites complete:</p>\n<ol>\n<li><strong>Dependency Registration</strong>: When jobs with dependencies are submitted, the scheduler builds an in-memory dependency graph linking prerequisite jobs to their dependents</li>\n<li><strong>Completion Monitoring</strong>: As jobs complete, the dependency evaluator checks all dependent jobs to see if their prerequisites are now satisfied</li>\n<li><strong>Eligibility Promotion</strong>: Jobs with satisfied dependencies are promoted from a &quot;waiting&quot; state to the normal priority queue for worker assignment</li>\n<li><strong>Failure Propagation</strong>: When a prerequisite job fails, dependent jobs can either fail immediately, skip execution, or proceed based on their configured <code>TimeoutAction</code></li>\n<li><strong>Cycle Detection</strong>: The scheduler validates that dependency relationships form a DAG and rejects job submissions that would create cycles</li>\n</ol>\n<blockquote>\n<p><strong>Decision: Dependency Storage Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Job dependencies need persistent storage to survive coordinator restarts and enable dependency resolution across time</li>\n<li><strong>Options Considered</strong>: In-memory only, database relations, graph database, Redis graph structures</li>\n<li><strong>Decision</strong>: Redis with graph-like operations using sets for incoming/outgoing edges per job</li>\n<li><strong>Rationale</strong>: Leverages existing Redis infrastructure, provides atomic operations for dependency updates, enables efficient graph traversal queries</li>\n<li><strong>Consequences</strong>: Dependency relationships persist across restarts, but complex graph queries are less efficient than dedicated graph databases</li>\n</ul>\n</blockquote>\n<h4 id=\"resource-aware-scheduling\">Resource-Aware Scheduling</h4>\n<p>The current scheduler assigns jobs to workers based solely on availability and capability matching. Resource-aware scheduling extends this to consider <strong>memory requirements</strong>, <strong>CPU constraints</strong>, <strong>storage needs</strong>, and <strong>exclusive resource access</strong> when making assignment decisions.</p>\n<p>Think of resource-aware scheduling like an airport gate assignment system. Small regional jets can use any gate, but wide-body aircraft require gates with jetbridges capable of handling their size. Similarly, some gates have ground power connections needed for electric aircraft, while others provide fuel access for conventional planes. The scheduler must match aircraft requirements with gate capabilities while maximizing utilization.</p>\n<p><strong>Extended Worker Resource Model:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>AvailableMemoryMB</td>\n<td>int64</td>\n<td>Current available memory in megabytes for job execution</td>\n</tr>\n<tr>\n<td>AvailableCPUCores</td>\n<td>float64</td>\n<td>Available CPU cores (fractional for partial core allocation)</td>\n</tr>\n<tr>\n<td>AvailableStorageGB</td>\n<td>int64</td>\n<td>Available temporary storage in gigabytes</td>\n</tr>\n<tr>\n<td>ExclusiveResources</td>\n<td>[]string</td>\n<td>List of exclusive resources this worker can provide (GPU types, license slots)</td>\n</tr>\n<tr>\n<td>ResourceLimits</td>\n<td>ResourceLimits</td>\n<td>Maximum resource levels this worker can provide</td>\n</tr>\n<tr>\n<td>CurrentAllocations</td>\n<td>map[string]ResourceAllocation</td>\n<td>Resources currently allocated to running jobs</td>\n</tr>\n</tbody></table>\n<p><strong>Job Resource Requirements:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>RequiredMemoryMB</td>\n<td>int64</td>\n<td>Minimum memory required for successful job execution</td>\n</tr>\n<tr>\n<td>RequiredCPUCores</td>\n<td>float64</td>\n<td>Minimum CPU cores needed (fractional allocation supported)</td>\n</tr>\n<tr>\n<td>RequiredStorageGB</td>\n<td>int64</td>\n<td>Temporary storage space needed during execution</td>\n</tr>\n<tr>\n<td>ExclusiveResource</td>\n<td>string</td>\n<td>Exclusive resource required (empty string if none needed)</td>\n</tr>\n<tr>\n<td>ResourceReservation</td>\n<td>time.Duration</td>\n<td>How long to hold resources before job starts (for delayed jobs)</td>\n</tr>\n<tr>\n<td>AffinityRules</td>\n<td>[]AffinityRule</td>\n<td>Preferences for worker selection based on resource characteristics</td>\n</tr>\n</tbody></table>\n<p>The resource-aware assignment algorithm extends the current job claiming process with resource validation and allocation tracking:</p>\n<ol>\n<li><strong>Resource Requirement Analysis</strong>: When a job becomes eligible for assignment, the scheduler extracts its resource requirements and determines compatible workers</li>\n<li><strong>Worker Capacity Filtering</strong>: The scheduler filters available workers to only those with sufficient resources to meet the job&#39;s requirements</li>\n<li><strong>Affinity Evaluation</strong>: Among capable workers, affinity rules are evaluated to prefer workers with characteristics like same datacenter, SSD storage, or specific CPU architectures</li>\n<li><strong>Resource Reservation</strong>: When a job is assigned to a worker, the scheduler reserves the required resources in its tracking system to prevent over-allocation</li>\n<li><strong>Dynamic Rebalancing</strong>: If high-priority jobs require resources currently allocated to lower-priority work, the scheduler can preempt lower-priority jobs</li>\n<li><strong>Resource Release</strong>: When jobs complete, their allocated resources are immediately returned to the worker&#39;s available pool</li>\n</ol>\n<h4 id=\"workflow-orchestration-engine\">Workflow Orchestration Engine</h4>\n<p>Building upon job dependencies and resource awareness, workflow orchestration provides high-level primitives for defining and executing complex multi-job workflows with <strong>conditional execution</strong>, <strong>parallel branches</strong>, <strong>loops</strong>, and <strong>error handling</strong>.</p>\n<p>Think of workflow orchestration like a sophisticated manufacturing assembly line. Raw materials enter the line, pass through multiple stations that can operate in parallel or sequence, with quality control checkpoints that can redirect work to rework stations or alternate paths. The entire process is coordinated by a central control system that monitors progress and handles disruptions.</p>\n<p><strong>Workflow Definition Structure:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>WorkflowID</td>\n<td>string</td>\n<td>Unique identifier for this workflow template</td>\n</tr>\n<tr>\n<td>Name</td>\n<td>string</td>\n<td>Human-readable workflow name for administrative interfaces</td>\n</tr>\n<tr>\n<td>Steps</td>\n<td>[]WorkflowStep</td>\n<td>Ordered list of steps defining the workflow execution path</td>\n</tr>\n<tr>\n<td>GlobalVariables</td>\n<td>map[string]string</td>\n<td>Variables available to all steps in the workflow</td>\n</tr>\n<tr>\n<td>ErrorHandling</td>\n<td>ErrorHandlingPolicy</td>\n<td>How to handle step failures (ABORT, CONTINUE, RETRY_STEP)</td>\n</tr>\n<tr>\n<td>MaxExecutionTime</td>\n<td>time.Duration</td>\n<td>Total timeout for entire workflow execution</td>\n</tr>\n<tr>\n<td>CronSchedule</td>\n<td>string</td>\n<td>Optional cron expression for recurring workflow execution</td>\n</tr>\n</tbody></table>\n<p><strong>WorkflowStep Definition:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>StepID</td>\n<td>string</td>\n<td>Unique identifier within the workflow</td>\n</tr>\n<tr>\n<td>StepType</td>\n<td>StepType</td>\n<td>Type of step (JOB, CONDITION, PARALLEL, LOOP, WAIT)</td>\n</tr>\n<tr>\n<td>JobTemplate</td>\n<td>*Job</td>\n<td>Job definition for JOB-type steps</td>\n</tr>\n<tr>\n<td>Condition</td>\n<td>string</td>\n<td>Boolean expression for CONDITION-type steps</td>\n</tr>\n<tr>\n<td>ParallelBranches</td>\n<td>[][]WorkflowStep</td>\n<td>Parallel execution branches for PARALLEL-type steps</td>\n</tr>\n<tr>\n<td>LoopCondition</td>\n<td>string</td>\n<td>Loop continuation condition for LOOP-type steps</td>\n</tr>\n<tr>\n<td>WaitDuration</td>\n<td>time.Duration</td>\n<td>Fixed wait duration for WAIT-type steps</td>\n</tr>\n<tr>\n<td>OnSuccess</td>\n<td>[]string</td>\n<td>Next step IDs to execute on successful completion</td>\n</tr>\n<tr>\n<td>OnFailure</td>\n<td>[]string</td>\n<td>Next step IDs to execute on failure</td>\n</tr>\n<tr>\n<td>RetryPolicy</td>\n<td>StepRetryPolicy</td>\n<td>Step-specific retry configuration</td>\n</tr>\n</tbody></table>\n<p>The workflow orchestration engine operates as a state machine that tracks workflow execution progress and coordinates step transitions:</p>\n<ol>\n<li><strong>Workflow Instantiation</strong>: When a workflow is triggered (by cron schedule or API call), the engine creates a workflow execution instance with unique execution ID</li>\n<li><strong>Step Resolution</strong>: The engine identifies the first step(s) to execute based on the workflow definition and begins execution</li>\n<li><strong>Job Generation</strong>: For JOB-type steps, the engine creates actual <code>Job</code> instances from templates, substituting workflow variables and context</li>\n<li><strong>Condition Evaluation</strong>: CONDITION-type steps evaluate boolean expressions against workflow variables and job outputs to determine execution paths</li>\n<li><strong>Parallel Coordination</strong>: PARALLEL-type steps spawn multiple execution branches that run concurrently, with the engine tracking completion of all branches</li>\n<li><strong>State Persistence</strong>: Workflow execution state is persisted to enable recovery from coordinator failures during long-running workflows</li>\n<li><strong>Completion Detection</strong>: The workflow completes when all steps finish successfully or when an unrecoverable error occurs based on the error handling policy</li>\n</ol>\n<blockquote>\n<p><strong>Decision: Workflow Expression Language</strong></p>\n<ul>\n<li><strong>Context</strong>: Conditional steps and loop conditions require expression evaluation within workflow context</li>\n<li><strong>Options Considered</strong>: JavaScript V8 engine, Go template syntax, custom domain-specific language, JSONPath expressions</li>\n<li><strong>Decision</strong>: Go template syntax with custom functions for job output access and variable manipulation</li>\n<li><strong>Rationale</strong>: Leverages Go&#39;s built-in template engine, provides familiar syntax for Go developers, enables safe expression evaluation without full scripting language security concerns</li>\n<li><strong>Consequences</strong>: Expressions are limited to Go template capabilities but execution is fast and secure, with no risk of arbitrary code execution</li>\n</ul>\n</blockquote>\n<p><strong>Common Pitfalls in Advanced Scheduling:</strong></p>\n<p>⚠️ <strong>Pitfall: Circular Dependency Creation</strong><br>Allowing users to create job dependencies without cycle detection leads to workflows that can never execute because jobs wait for each other in a cycle. This manifests as jobs permanently stuck in &quot;waiting for dependencies&quot; state. Implement topological sort validation during workflow submission and reject any workflow definition that contains cycles.</p>\n<p>⚠️ <strong>Pitfall: Resource Over-Commitment</strong><br>Reserving resources for delayed jobs without considering time-based availability leads to resource starvation where workers appear full but aren&#39;t actually executing work. Implement time-aware resource reservations that only hold resources close to job execution time, with automatic reservation release if jobs don&#39;t start within expected windows.</p>\n<p>⚠️ <strong>Pitfall: Workflow State Explosion</strong><br>Storing complete workflow execution state for every step and variable update creates excessive storage overhead and slow state operations. Implement incremental state updates that only persist state changes, with periodic state compaction to merge incremental updates into consolidated checkpoints.</p>\n<h3 id=\"operational-features\">Operational Features</h3>\n<p>Production distributed systems require comprehensive observability, administrative controls, and historical analysis capabilities. The operational features category adds <strong>metrics and monitoring</strong>, <strong>job execution history</strong>, <strong>administrative interfaces</strong>, and <strong>audit logging</strong> to transform the scheduler from a development tool into an enterprise-ready platform.</p>\n<p>Think of operational features like the instrumentation and controls in an airline&#39;s operations center. Dispatchers need real-time visibility into flight status, weather conditions, and aircraft maintenance schedules. They require historical data to analyze patterns and optimize routes. Emergency procedures and administrative controls enable rapid response to disruptions. Similarly, a production job scheduler needs comprehensive operational capabilities to ensure reliable service delivery.</p>\n<h4 id=\"comprehensive-metrics-and-monitoring\">Comprehensive Metrics and Monitoring</h4>\n<p>The current scheduler includes basic Prometheus metrics for job execution and worker coordination. Comprehensive monitoring extends this with <strong>detailed performance metrics</strong>, <strong>business-level indicators</strong>, <strong>alerting rules</strong>, and <strong>dashboard templates</strong> that provide complete visibility into scheduler health and performance.</p>\n<p><strong>Enhanced Metrics Collection:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Metric Category</th>\n<th>Metrics</th>\n<th>Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Job Lifecycle</td>\n<td>job_submission_rate, job_completion_latency, job_success_rate, job_retry_frequency</td>\n<td>Track job processing health and identify performance bottlenecks</td>\n</tr>\n<tr>\n<td>Queue Dynamics</td>\n<td>queue_depth_by_priority, queue_wait_time, job_aging_histogram, deduplication_rate</td>\n<td>Monitor queue behavior and capacity planning needs</td>\n</tr>\n<tr>\n<td>Worker Performance</td>\n<td>worker_utilization, worker_job_throughput, worker_failure_rate, worker_resource_efficiency</td>\n<td>Assess worker health and identify problematic nodes</td>\n</tr>\n<tr>\n<td>Coordination Health</td>\n<td>leader_election_frequency, heartbeat_latency, split_brain_events, consensus_latency</td>\n<td>Monitor distributed coordination stability and network issues</td>\n</tr>\n<tr>\n<td>Resource Utilization</td>\n<td>memory_allocation_efficiency, cpu_utilization_distribution, storage_usage_patterns, exclusive_resource_contention</td>\n<td>Track resource usage patterns for capacity planning</td>\n</tr>\n<tr>\n<td>Workflow Execution</td>\n<td>workflow_completion_rate, workflow_step_latency, workflow_branch_parallelism, workflow_failure_causes</td>\n<td>Monitor complex workflow execution and identify optimization opportunities</td>\n</tr>\n</tbody></table>\n<p><strong>Business-Level Indicators:</strong></p>\n<p>Beyond technical metrics, operational deployments require business-level indicators that translate system behavior into business impact measurements:</p>\n<table>\n<thead>\n<tr>\n<th>Business Indicator</th>\n<th>Calculation</th>\n<th>Business Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Schedule Adherence Rate</td>\n<td>(Jobs started within SLA window) / (Total scheduled jobs)</td>\n<td>Measures reliability of time-sensitive business processes</td>\n</tr>\n<tr>\n<td>Critical Job Success Rate</td>\n<td>(Critical priority jobs completed successfully) / (Total critical jobs)</td>\n<td>Tracks success of highest-impact business operations</td>\n</tr>\n<tr>\n<td>Resource ROI</td>\n<td>(Successful job compute hours) / (Total provisioned compute hours)</td>\n<td>Measures efficiency of infrastructure investment</td>\n</tr>\n<tr>\n<td>Workflow SLA Compliance</td>\n<td>(Workflows completed within SLA) / (Total workflows)</td>\n<td>Tracks end-to-end business process reliability</td>\n</tr>\n<tr>\n<td>Dependency Chain Efficiency</td>\n<td>Average workflow completion time / Sum of individual job times</td>\n<td>Measures overhead of workflow coordination vs direct execution</td>\n</tr>\n</tbody></table>\n<p><strong>Alerting Framework:</strong></p>\n<p>The monitoring system includes a comprehensive alerting framework with <strong>graduated severity levels</strong>, <strong>smart alert correlation</strong>, and <strong>automated runbook integration</strong>:</p>\n<ol>\n<li><strong>Threshold-Based Alerts</strong>: Traditional alerts based on metric thresholds (queue depth exceeds capacity, worker failure rate above normal)</li>\n<li><strong>Anomaly Detection</strong>: Machine learning-based alerts that identify unusual patterns in job execution, resource usage, or coordination behavior</li>\n<li><strong>Correlation Rules</strong>: Logic that groups related alerts to prevent alert storms during widespread issues (network partition affecting multiple workers)</li>\n<li><strong>Escalation Policies</strong>: Graduated response based on alert severity and duration (page on-call engineer for critical failures, create ticket for performance degradation)</li>\n<li><strong>Runbook Integration</strong>: Automatic attachment of relevant troubleshooting procedures and diagnostic commands to alert notifications</li>\n</ol>\n<h4 id=\"job-execution-history-and-analytics\">Job Execution History and Analytics</h4>\n<p>The current scheduler focuses on active job execution without preserving detailed historical information. Comprehensive job history provides <strong>execution analytics</strong>, <strong>performance trending</strong>, <strong>failure pattern analysis</strong>, and <strong>capacity planning data</strong> through long-term data retention and analysis capabilities.</p>\n<p><strong>Job Execution Record:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>ExecutionID</td>\n<td>string</td>\n<td>Unique identifier for this specific job execution attempt</td>\n</tr>\n<tr>\n<td>JobID</td>\n<td>string</td>\n<td>Identifier of the job definition that was executed</td>\n</tr>\n<tr>\n<td>WorkflowID</td>\n<td>string</td>\n<td>Optional workflow identifier if job was part of workflow execution</td>\n</tr>\n<tr>\n<td>SubmissionTime</td>\n<td>time.Time</td>\n<td>When the job was originally submitted to the scheduler</td>\n</tr>\n<tr>\n<td>ScheduledTime</td>\n<td>time.Time</td>\n<td>When the job was scheduled to begin execution based on cron expression</td>\n</tr>\n<tr>\n<td>ClaimTime</td>\n<td>time.Time</td>\n<td>When a worker successfully claimed the job for execution</td>\n</tr>\n<tr>\n<td>StartTime</td>\n<td>time.Time</td>\n<td>When job execution actually began on the worker</td>\n</tr>\n<tr>\n<td>CompletionTime</td>\n<td>time.Time</td>\n<td>When job execution finished (successfully or with failure)</td>\n</tr>\n<tr>\n<td>ExecutionDuration</td>\n<td>time.Duration</td>\n<td>Total time spent executing the job</td>\n</tr>\n<tr>\n<td>QueueWaitTime</td>\n<td>time.Duration</td>\n<td>Time spent waiting in queue before worker assignment</td>\n</tr>\n<tr>\n<td>ClaimToStartDelay</td>\n<td>time.Duration</td>\n<td>Delay between worker claim and actual execution start</td>\n</tr>\n<tr>\n<td>WorkerID</td>\n<td>string</td>\n<td>Identifier of the worker that executed the job</td>\n</tr>\n<tr>\n<td>ResourcesUsed</td>\n<td>ResourceUtilization</td>\n<td>Actual resource consumption during execution</td>\n</tr>\n<tr>\n<td>ExitCode</td>\n<td>int</td>\n<td>Job process exit code</td>\n</tr>\n<tr>\n<td>ExecutionLogs</td>\n<td>string</td>\n<td>Captured standard output and error from job execution</td>\n</tr>\n<tr>\n<td>RetryAttempts</td>\n<td>[]RetryRecord</td>\n<td>Details of any retry attempts before final completion</td>\n</tr>\n<tr>\n<td>Dependencies</td>\n<td>[]DependencyResolution</td>\n<td>How job dependencies were resolved for this execution</td>\n</tr>\n</tbody></table>\n<p><strong>Performance Analytics Engine:</strong></p>\n<p>The analytics engine processes historical execution records to provide insights for optimization and troubleshooting:</p>\n<ol>\n<li><strong>Trend Analysis</strong>: Identifies patterns in job execution times, failure rates, and resource usage over time to detect performance degradation or improvement</li>\n<li><strong>Capacity Planning</strong>: Analyzes historical queue depths, worker utilization, and execution patterns to recommend infrastructure scaling decisions</li>\n<li><strong>Failure Root Cause Analysis</strong>: Correlates job failures with system conditions (worker health, resource availability, network issues) to identify common failure causes</li>\n<li><strong>Schedule Optimization</strong>: Recommends schedule adjustments based on actual execution patterns to reduce resource contention and improve completion rates</li>\n<li><strong>Worker Performance Profiling</strong>: Identifies workers with consistently poor performance or resource efficiency to guide maintenance decisions</li>\n</ol>\n<p><strong>Data Retention and Archival:</strong></p>\n<p>Long-term job history requires careful data management to balance analytical value with storage costs:</p>\n<table>\n<thead>\n<tr>\n<th>Retention Period</th>\n<th>Data Granularity</th>\n<th>Storage Location</th>\n<th>Access Pattern</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Last 7 days</td>\n<td>Full execution records with logs</td>\n<td>Hot storage (SSD)</td>\n<td>Real-time dashboards, immediate troubleshooting</td>\n</tr>\n<tr>\n<td>8-90 days</td>\n<td>Execution records without logs</td>\n<td>Warm storage (HDD)</td>\n<td>Performance analysis, capacity planning</td>\n</tr>\n<tr>\n<td>91 days - 1 year</td>\n<td>Aggregated daily/hourly summaries</td>\n<td>Cold storage (object store)</td>\n<td>Long-term trending, compliance reporting</td>\n</tr>\n<tr>\n<td>1+ years</td>\n<td>Monthly aggregate summaries</td>\n<td>Archive storage</td>\n<td>Historical analysis, audit requirements</td>\n</tr>\n</tbody></table>\n<h4 id=\"administrative-interfaces\">Administrative Interfaces</h4>\n<p>Production schedulers require comprehensive administrative capabilities for <strong>job management</strong>, <strong>worker administration</strong>, <strong>system configuration</strong>, and <strong>emergency operations</strong>. The administrative interface provides both web-based dashboards and programmatic APIs for operational teams.</p>\n<p><strong>Web-Based Administrative Dashboard:</strong></p>\n<p>The dashboard provides comprehensive visibility and control through several specialized views:</p>\n<ol>\n<li><strong>System Overview Dashboard</strong>: Real-time system health, active job counts, worker status, and critical alerts in a single view</li>\n<li><strong>Job Management Interface</strong>: Search, filter, and manage jobs with capabilities to pause, resume, cancel, or manually trigger job execution</li>\n<li><strong>Worker Administration Panel</strong>: View worker health, resource utilization, and administrative actions like graceful shutdown or resource limit adjustments</li>\n<li><strong>Workflow Visualization</strong>: Graphical representation of workflow definitions and execution progress with interactive dependency graphs</li>\n<li><strong>Performance Analytics Dashboard</strong>: Historical performance trends, capacity utilization reports, and optimization recommendations</li>\n<li><strong>Configuration Management</strong>: Administrative interface for scheduler settings, worker policies, and system parameters</li>\n</ol>\n<p><strong>Administrative API Endpoints:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Endpoint Category</th>\n<th>Operations</th>\n<th>Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Job Administration</td>\n<td>List, search, pause, resume, cancel, retry, manual trigger</td>\n<td>Operational control over job execution</td>\n</tr>\n<tr>\n<td>Worker Management</td>\n<td>List workers, drain worker, remove worker, update capacity</td>\n<td>Worker lifecycle and capacity management</td>\n</tr>\n<tr>\n<td>System Configuration</td>\n<td>Get/set scheduler config, update cron schedules, modify priorities</td>\n<td>Runtime configuration adjustments</td>\n</tr>\n<tr>\n<td>Emergency Operations</td>\n<td>Emergency stop, bulk job cancellation, system maintenance mode</td>\n<td>Crisis response and maintenance procedures</td>\n</tr>\n<tr>\n<td>Audit and Reporting</td>\n<td>Execution reports, performance summaries, compliance exports</td>\n<td>Operational reporting and audit trails</td>\n</tr>\n</tbody></table>\n<p><strong>Role-Based Access Control:</strong></p>\n<p>Administrative interfaces require sophisticated access control to ensure appropriate separation of duties:</p>\n<table>\n<thead>\n<tr>\n<th>Role</th>\n<th>Permissions</th>\n<th>Typical Use Cases</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Viewer</td>\n<td>Read-only access to dashboards and job status</td>\n<td>Developers checking job status, managers reviewing performance</td>\n</tr>\n<tr>\n<td>Operator</td>\n<td>Job pause/resume/cancel, worker drain operations</td>\n<td>On-call engineers responding to alerts, scheduled maintenance</td>\n</tr>\n<tr>\n<td>Administrator</td>\n<td>Full system configuration, worker management, emergency operations</td>\n<td>System administrators, DevOps team leads</td>\n</tr>\n<tr>\n<td>Auditor</td>\n<td>Read-only access to all data including sensitive logs and configurations</td>\n<td>Compliance audits, security reviews</td>\n</tr>\n</tbody></table>\n<h4 id=\"comprehensive-audit-logging\">Comprehensive Audit Logging</h4>\n<p>Enterprise deployments require detailed audit trails for <strong>compliance requirements</strong>, <strong>security monitoring</strong>, and <strong>operational analysis</strong>. Comprehensive audit logging captures all administrative actions, system events, and security-relevant activities with tamper-evident storage.</p>\n<p><strong>Audit Event Categories:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Category</th>\n<th>Events Logged</th>\n<th>Security Relevance</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Administrative Actions</td>\n<td>Job creation/modification/deletion, worker management, configuration changes</td>\n<td>High - tracks all system modifications</td>\n</tr>\n<tr>\n<td>Authentication/Authorization</td>\n<td>User login/logout, permission checks, access denials</td>\n<td>Critical - security monitoring and compliance</td>\n</tr>\n<tr>\n<td>Job Execution</td>\n<td>Job starts, completions, failures, retry attempts</td>\n<td>Medium - operational analysis and debugging</td>\n</tr>\n<tr>\n<td>System Events</td>\n<td>Leader elections, worker registrations, coordinator failovers</td>\n<td>Medium - system health and coordination monitoring</td>\n</tr>\n<tr>\n<td>Data Access</td>\n<td>Job payload access, log retrieval, configuration queries</td>\n<td>Low - data access patterns and usage analysis</td>\n</tr>\n</tbody></table>\n<p><strong>Audit Record Structure:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>AuditID</td>\n<td>string</td>\n<td>Unique identifier for this audit event</td>\n</tr>\n<tr>\n<td>Timestamp</td>\n<td>time.Time</td>\n<td>Precise timestamp when event occurred</td>\n</tr>\n<tr>\n<td>EventType</td>\n<td>AuditEventType</td>\n<td>Category and specific type of audited event</td>\n</tr>\n<tr>\n<td>ActorID</td>\n<td>string</td>\n<td>Identity of user or system component that triggered the event</td>\n</tr>\n<tr>\n<td>ActorType</td>\n<td>ActorType</td>\n<td>Whether actor is human user, system service, or external API client</td>\n</tr>\n<tr>\n<td>TargetResource</td>\n<td>string</td>\n<td>Resource that was affected by the audited action</td>\n</tr>\n<tr>\n<td>Action</td>\n<td>string</td>\n<td>Specific action taken (CREATE, UPDATE, DELETE, ACCESS)</td>\n</tr>\n<tr>\n<td>Outcome</td>\n<td>AuditOutcome</td>\n<td>Whether the action succeeded, failed, or was denied</td>\n</tr>\n<tr>\n<td>SourceIP</td>\n<td>string</td>\n<td>Network address where the action originated</td>\n</tr>\n<tr>\n<td>UserAgent</td>\n<td>string</td>\n<td>Client identifier for API or web interface actions</td>\n</tr>\n<tr>\n<td>SessionID</td>\n<td>string</td>\n<td>Session identifier for correlated actions within same user session</td>\n</tr>\n<tr>\n<td>Changes</td>\n<td>map[string]AuditChange</td>\n<td>Before/after values for modification actions</td>\n</tr>\n<tr>\n<td>Context</td>\n<td>map[string]string</td>\n<td>Additional context relevant to the specific event</td>\n</tr>\n</tbody></table>\n<p><strong>Tamper-Evident Storage:</strong></p>\n<p>Audit logs require protection against modification to maintain their evidentiary value:</p>\n<ol>\n<li><strong>Cryptographic Hashing</strong>: Each audit record includes a hash of its content and the hash of the previous record, creating a blockchain-like chain</li>\n<li><strong>Append-Only Storage</strong>: Audit logs are stored in append-only files or database tables that prevent modification of existing records</li>\n<li><strong>External Backup</strong>: Regular encrypted backups of audit logs to external storage systems controlled by separate administrative domains</li>\n<li><strong>Integrity Verification</strong>: Automated processes verify the hash chain integrity and alert on any tampering attempts</li>\n<li><strong>Retention Enforcement</strong>: Automated retention policies prevent premature deletion while ensuring compliance with data retention regulations</li>\n</ol>\n<h3 id=\"scalability-improvements\">Scalability Improvements</h3>\n<p>The current three-milestone implementation operates effectively within a single cluster or data center. Production deployments often require capabilities that exceed single-cluster capacity or span multiple geographic regions. Scalability improvements enable <strong>horizontal sharding</strong>, <strong>multi-datacenter deployment</strong>, and <strong>performance optimizations</strong> that support enterprise-scale workloads.</p>\n<p>Think of scalability improvements like expanding from a single factory to a global manufacturing network. The single factory has excellent coordination and efficiency, but geographic expansion requires regional facilities, supply chain coordination, and quality standardization across locations. Similarly, scaling the job scheduler beyond single-cluster deployment requires careful design of data partitioning, cross-region coordination, and performance optimization.</p>\n<h4 id=\"horizontal-sharding-architecture\">Horizontal Sharding Architecture</h4>\n<p>Single-cluster deployments face fundamental limits in job throughput, worker capacity, and coordination overhead. Horizontal sharding distributes jobs across multiple independent scheduler clusters based on <strong>sharding keys</strong>, with a <strong>shard coordinator</strong> managing job distribution and cross-shard queries.</p>\n<p><strong>Sharding Strategy Design:</strong></p>\n<p>The sharding architecture divides the job namespace across multiple clusters using configurable sharding keys:</p>\n<table>\n<thead>\n<tr>\n<th>Sharding Key</th>\n<th>Distribution Strategy</th>\n<th>Use Cases</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Job Name Prefix</td>\n<td>Hash-based distribution by job name prefix</td>\n<td>Application-based isolation (billing-<em>, analytics-</em>, etc.)</td>\n</tr>\n<tr>\n<td>Cron Schedule</td>\n<td>Time-based distribution by execution frequency</td>\n<td>Separate high-frequency and batch workloads</td>\n</tr>\n<tr>\n<td>Priority Level</td>\n<td>Priority-based shard assignment</td>\n<td>Dedicated clusters for critical vs. routine work</td>\n</tr>\n<tr>\n<td>Resource Requirements</td>\n<td>Resource-based distribution by job resource needs</td>\n<td>Specialized clusters for CPU-intensive vs. memory-intensive jobs</td>\n</tr>\n<tr>\n<td>Tenant ID</td>\n<td>Multi-tenant isolation with dedicated shards</td>\n<td>Enterprise deployments with strict tenant isolation</td>\n</tr>\n</tbody></table>\n<p><strong>Shard Coordinator Architecture:</strong></p>\n<p>The shard coordinator operates as a lightweight routing layer that distributes jobs to appropriate shards without becoming a bottleneck:</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Responsibility</th>\n<th>Scalability Characteristics</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Routing Service</td>\n<td>Determines target shard for job submissions</td>\n<td>Stateless, horizontally scalable, caches shard mappings</td>\n</tr>\n<tr>\n<td>Shard Registry</td>\n<td>Maintains shard health and capacity information</td>\n<td>Replicated across multiple registry nodes, eventually consistent</td>\n</tr>\n<tr>\n<td>Cross-Shard Query Engine</td>\n<td>Aggregates queries across multiple shards</td>\n<td>Parallel query execution, result merging, timeout handling</td>\n</tr>\n<tr>\n<td>Rebalancing Coordinator</td>\n<td>Manages shard capacity and job migration</td>\n<td>Low-frequency operations, careful coordination to prevent disruption</td>\n</tr>\n</tbody></table>\n<p><strong>Job Distribution Algorithm:</strong></p>\n<p>The shard coordinator uses a consistent hashing algorithm to ensure stable job assignment even as shards are added or removed:</p>\n<ol>\n<li><strong>Shard Key Extraction</strong>: Extract the configured sharding key value from incoming job submissions</li>\n<li><strong>Hash Calculation</strong>: Compute a consistent hash of the shard key using a stable hash function (SHA-256)</li>\n<li><strong>Shard Selection</strong>: Map the hash value to a specific shard using consistent hashing ring or modulo arithmetic</li>\n<li><strong>Health Check</strong>: Verify the selected shard is healthy and accepting jobs; if not, select the next healthy shard in the ring</li>\n<li><strong>Job Submission</strong>: Forward the job to the selected shard&#39;s job submission API with original metadata preserved</li>\n<li><strong>Response Handling</strong>: Return the shard&#39;s response to the original client, including any shard-specific job identifiers</li>\n</ol>\n<blockquote>\n<p><strong>Decision: Cross-Shard Dependency Handling</strong></p>\n<ul>\n<li><strong>Context</strong>: Jobs with dependencies may be distributed across different shards, requiring coordination for dependency resolution</li>\n<li><strong>Options Considered</strong>: Prohibit cross-shard dependencies, centralized dependency tracker, distributed dependency resolution, job co-location</li>\n<li><strong>Decision</strong>: Implement job co-location where jobs with dependencies are assigned to the same shard as their prerequisites</li>\n<li><strong>Rationale</strong>: Maintains dependency resolution performance and simplifies coordination logic by avoiding cross-shard communication</li>\n<li><strong>Consequences</strong>: May create load imbalances if dependency chains are concentrated, but eliminates complex distributed dependency protocols</li>\n</ul>\n</blockquote>\n<h4 id=\"multi-datacenter-deployment\">Multi-Datacenter Deployment</h4>\n<p>Enterprise deployments often require job execution across multiple geographic regions for <strong>disaster recovery</strong>, <strong>latency optimization</strong>, and <strong>regulatory compliance</strong>. Multi-datacenter deployment extends the scheduler to operate across regions while maintaining consistency and handling network partitions gracefully.</p>\n<p><strong>Datacenter Topology Models:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Deployment Model</th>\n<th>Characteristics</th>\n<th>Coordination Requirements</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Active-Passive</td>\n<td>Single active datacenter, passive backup for disaster recovery</td>\n<td>Minimal coordination, fast failover, potential data loss during transition</td>\n</tr>\n<tr>\n<td>Active-Active Regional</td>\n<td>Each datacenter handles jobs for its geographic region</td>\n<td>Moderate coordination for cross-region workflows and shared schedules</td>\n</tr>\n<tr>\n<td>Global Active-Active</td>\n<td>Jobs distributed globally based on resource availability</td>\n<td>High coordination overhead, complex consensus, maximum availability</td>\n</tr>\n<tr>\n<td>Federated</td>\n<td>Independent schedulers with optional job sharing</td>\n<td>Minimal coordination, loose coupling, manual intervention for cross-datacenter workflows</td>\n</tr>\n</tbody></table>\n<p><strong>Network Partition Tolerance:</strong></p>\n<p>Multi-datacenter deployments must handle network partitions gracefully without losing job execution capability:</p>\n<ol>\n<li><strong>Partition Detection</strong>: Monitor inter-datacenter connectivity using multiple network paths and consensus protocols to identify partitions</li>\n<li><strong>Split-Brain Prevention</strong>: Use external consensus systems (like managed etcd clusters) or quorum-based decisions to prevent multiple datacenters claiming leadership</li>\n<li><strong>Graceful Degradation</strong>: Continue processing region-local jobs during partitions while deferring cross-region workflows until connectivity restores</li>\n<li><strong>State Reconciliation</strong>: Automatically reconcile job states and execution history when partitions heal, handling conflicts through timestamp ordering or manual review</li>\n<li><strong>Emergency Procedures</strong>: Provide administrative controls to manually override partition detection for emergency operations</li>\n</ol>\n<p><strong>Cross-Datacenter Job Scheduling:</strong></p>\n<p>Some jobs require execution in specific datacenters due to data locality, regulatory requirements, or resource availability:</p>\n<table>\n<thead>\n<tr>\n<th>Scheduling Strategy</th>\n<th>Implementation</th>\n<th>Trade-offs</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Datacenter Affinity</td>\n<td>Jobs specify preferred datacenter in metadata</td>\n<td>Simple implementation, may create load imbalances</td>\n</tr>\n<tr>\n<td>Data Locality Optimization</td>\n<td>Schedule jobs in datacenter closest to required data</td>\n<td>Optimal performance, requires data location tracking</td>\n</tr>\n<tr>\n<td>Regulatory Compliance</td>\n<td>Enforce jobs execute only in compliant regions</td>\n<td>Strict compliance, potential capacity constraints</td>\n</tr>\n<tr>\n<td>Load Balancing</td>\n<td>Dynamically assign jobs based on datacenter capacity</td>\n<td>Optimal resource utilization, complex coordination</td>\n</tr>\n</tbody></table>\n<h4 id=\"performance-optimizations\">Performance Optimizations</h4>\n<p>High-throughput deployments require performance optimizations that minimize coordination overhead, reduce latency, and maximize resource utilization efficiency. These optimizations focus on <strong>coordination protocol improvements</strong>, <strong>caching strategies</strong>, and <strong>batching optimizations</strong>.</p>\n<p><strong>Coordination Protocol Enhancements:</strong></p>\n<p>The current leader election and worker coordination protocols can be optimized for higher scale:</p>\n<ol>\n<li><strong>Hierarchical Leadership</strong>: Implement regional leaders that coordinate with a global leader, reducing coordination overhead for local operations</li>\n<li><strong>Lease-Based Coordination</strong>: Use longer lease periods with more sophisticated renewal protocols to reduce heartbeat frequency without sacrificing failure detection speed</li>\n<li><strong>Bulk Operations</strong>: Batch multiple coordination operations (job assignments, status updates) into single messages to reduce network overhead</li>\n<li><strong>Protocol Pipelining</strong>: Allow multiple outstanding coordination requests to improve throughput in high-latency network environments</li>\n<li><strong>Adaptive Timeouts</strong>: Dynamically adjust coordination timeouts based on network conditions and system load to optimize for both responsiveness and stability</li>\n</ol>\n<p><strong>Intelligent Caching Strategies:</strong></p>\n<p>Caching reduces load on core coordination services and improves response times for frequently accessed data:</p>\n<table>\n<thead>\n<tr>\n<th>Cache Type</th>\n<th>Cached Data</th>\n<th>Invalidation Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Job Metadata Cache</td>\n<td>Job definitions, cron expressions, priorities</td>\n<td>TTL-based with immediate invalidation on updates</td>\n</tr>\n<tr>\n<td>Worker Capability Cache</td>\n<td>Worker resources, capabilities, health status</td>\n<td>Heartbeat-driven updates with fallback TTL</td>\n</tr>\n<tr>\n<td>Cron Calculation Cache</td>\n<td>Next execution times for common cron expressions</td>\n<td>Long TTL with timezone-aware invalidation</td>\n</tr>\n<tr>\n<td>Dependency Graph Cache</td>\n<td>Job dependency relationships for active workflows</td>\n<td>Version-based invalidation when dependencies change</td>\n</tr>\n<tr>\n<td>Shard Routing Cache</td>\n<td>Shard assignment mappings for sharded deployments</td>\n<td>Consistent hash-based with health-driven updates</td>\n</tr>\n</tbody></table>\n<p><strong>Batching and Bulk Operations:</strong></p>\n<p>Single-operation APIs create coordination overhead that limits throughput. Batching operations improves efficiency:</p>\n<ol>\n<li><strong>Bulk Job Submission</strong>: Accept multiple jobs in single API calls with transactional semantics for all-or-nothing submission</li>\n<li><strong>Batch Worker Updates</strong>: Aggregate multiple worker status updates into periodic batch operations to reduce coordination frequency</li>\n<li><strong>Bulk Query Operations</strong>: Support queries that return multiple jobs or workers in single requests to reduce API round-trips</li>\n<li><strong>Streaming Updates</strong>: Provide streaming APIs for real-time job status updates instead of polling-based approaches</li>\n<li><strong>Lazy Evaluation</strong>: Defer expensive operations like dependency resolution until actually needed rather than computing eagerly</li>\n</ol>\n<p><strong>Common Pitfalls in Scalability Improvements:</strong></p>\n<p>⚠️ <strong>Pitfall: Inconsistent Sharding During Rebalancing</strong><br>Rebalancing shards while jobs are in flight can lead to job assignments to incorrect shards or lost jobs during migration. Implement careful coordination protocols that ensure all in-flight jobs complete on their original shards before migrating future jobs to rebalanced shards.</p>\n<p>⚠️ <strong>Pitfall: Cross-Datacenter Clock Skew</strong><br>Cron scheduling across datacenters with significant clock skew causes jobs to execute at unexpected times or miss schedules entirely. Implement NTP synchronization monitoring and validate that clock skew remains within acceptable bounds (typically under 1 second) across all scheduler nodes.</p>\n<p>⚠️ <strong>Pitfall: Cache Invalidation Storms</strong><br>Popular job patterns or mass configuration updates can trigger cache invalidation storms that overload coordination services during cache refill. Implement staggered cache invalidation with exponential backoff and circuit breakers around cache refresh operations.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The future extensions described above represent significant enhancements to the core scheduler implementation. While these features go beyond the scope of the three-milestone project, understanding their architectural patterns and implementation approaches provides valuable insight into production system evolution.</p>\n<p><strong>Technology Recommendations for Extensions:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Extension Category</th>\n<th>Recommended Technologies</th>\n<th>Rationale</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Job Dependencies</td>\n<td>Redis Graph, Neo4j, or PostgreSQL with recursive queries</td>\n<td>Graph relationships require efficient traversal and cycle detection</td>\n</tr>\n<tr>\n<td>Resource Scheduling</td>\n<td>Kubernetes-style resource quotas, cgroups integration</td>\n<td>Proven patterns for resource management and isolation</td>\n</tr>\n<tr>\n<td>Multi-Datacenter</td>\n<td>etcd clusters, Consul Connect, or custom Raft implementation</td>\n<td>Mature distributed consensus systems with partition tolerance</td>\n</tr>\n<tr>\n<td>Metrics/Monitoring</td>\n<td>Prometheus + Grafana, DataDog, or New Relic</td>\n<td>Established monitoring ecosystems with alerting and dashboards</td>\n</tr>\n<tr>\n<td>Workflow Orchestration</td>\n<td>Temporal, Apache Airflow patterns, or custom state machines</td>\n<td>Mature workflow engines provide proven orchestration patterns</td>\n</tr>\n</tbody></table>\n<p><strong>File Structure for Extensions:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>project-root/\n  cmd/\n    scheduler/              ← main scheduler service\n    shard-coordinator/      ← sharding coordinator service\n    admin-dashboard/        ← administrative web interface\n  internal/\n    scheduler/              ← core scheduler from milestones\n    extensions/\n      dependencies/         ← job dependency resolution\n        graph.go           ← dependency graph operations\n        resolver.go        ← dependency resolution engine\n      resources/           ← resource-aware scheduling\n        allocator.go       ← resource allocation tracking\n        scheduler.go       ← resource-aware job assignment\n      workflows/           ← workflow orchestration\n        engine.go          ← workflow execution engine\n        definition.go      ← workflow definition parsing\n      sharding/            ← horizontal sharding\n        coordinator.go     ← shard coordination logic\n        hasher.go          ← consistent hashing implementation\n      monitoring/          ← enhanced monitoring\n        collector.go       ← comprehensive metrics collection\n        analytics.go       ← historical data analysis\n      admin/               ← administrative interfaces\n        api.go             ← administrative REST API\n        dashboard.go       ← web dashboard handlers\n  web/                     ← dashboard static assets\n    dashboard/\n      index.html           ← main dashboard page\n      workflow-viz.js      ← workflow visualization\n  deployments/\n    k8s/                   ← Kubernetes deployment manifests\n    docker-compose/        ← Docker Compose for development</code></pre></div>\n\n<p><strong>Extension Implementation Priorities:</strong></p>\n<p>For teams considering implementing these extensions, the recommended priority order balances implementation complexity with operational value:</p>\n<ol>\n<li><strong>Enhanced Monitoring and Metrics</strong> - Essential for production deployment, builds on existing Prometheus integration</li>\n<li><strong>Job Execution History</strong> - Provides immediate operational value with moderate implementation complexity</li>\n<li><strong>Administrative Interfaces</strong> - Critical for operational teams, can start with simple REST APIs and evolve to full dashboards  </li>\n<li><strong>Resource-Aware Scheduling</strong> - High value for resource optimization, extends existing worker coordination patterns</li>\n<li><strong>Job Dependencies</strong> - Complex but enables significant workflow capabilities, requires careful dependency resolution design</li>\n<li><strong>Horizontal Sharding</strong> - Needed only for very high scale, complex distributed systems challenges</li>\n<li><strong>Multi-Datacenter Deployment</strong> - Specialized requirement for global deployments, highest complexity implementation</li>\n<li><strong>Workflow Orchestration</strong> - Builds on dependencies, provides highest-level abstraction for complex workflows</li>\n</ol>\n<p><strong>Integration Testing for Extensions:</strong></p>\n<p>Extensions require comprehensive integration testing beyond the unit testing approaches outlined in the main testing strategy:</p>\n<ol>\n<li><strong>Multi-Node Testing</strong>: Test extension behavior across multiple coordinator and worker nodes to verify distributed behavior</li>\n<li><strong>Failure Injection</strong>: Systematically test network partitions, node failures, and resource exhaustion scenarios  </li>\n<li><strong>Load Testing</strong>: Validate performance characteristics under production-level job submission and execution rates</li>\n<li><strong>Cross-Version Testing</strong>: Ensure extensions maintain backward compatibility with jobs and workflows created by older versions</li>\n<li><strong>End-to-End Workflows</strong>: Test complete business workflows that exercise multiple extension features in combination</li>\n</ol>\n<p><strong>Milestone Checkpoints for Extensions:</strong></p>\n<p>Each extension category represents a significant development milestone with specific verification criteria:</p>\n<ul>\n<li><strong>Advanced Scheduling Milestone</strong>: Successfully execute a workflow with job dependencies, resource constraints, and conditional steps</li>\n<li><strong>Operational Features Milestone</strong>: Deploy monitoring dashboards, execute administrative operations through web interface, demonstrate audit trail completeness  </li>\n<li><strong>Scalability Milestone</strong>: Demonstrate job execution across multiple shards or datacenters with consistent behavior and partition tolerance</li>\n</ul>\n<p>These extensions transform the distributed job scheduler from a reliable task execution system into a comprehensive enterprise workflow platform. While the three core milestones provide a solid foundation for most use cases, these extensions enable the scheduler to handle the complex requirements of large-scale production deployments across diverse organizational and technical environments.</p>\n<h2 id=\"glossary\">Glossary</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section provides essential terminology definitions that apply across all three milestones - cron scheduling terminology for Milestone 1, priority queue and deduplication concepts for Milestone 2, and distributed systems coordination terms for Milestone 3.</p>\n</blockquote>\n<p>This glossary defines the key terminology used throughout the distributed job scheduler design document. Understanding these terms is crucial for implementing the system correctly and communicating effectively about distributed scheduling concepts. The terms are organized by domain area, starting with fundamental distributed systems concepts, then moving to scheduling-specific terminology, and finally covering operational and debugging concepts.</p>\n<h3 id=\"distributed-systems-core-concepts\">Distributed Systems Core Concepts</h3>\n<p><strong>Exactly-once execution</strong> - A guarantee that each job runs precisely one time, never skipped and never duplicated. This is the strongest consistency guarantee in distributed scheduling but requires careful coordination mechanisms. In practice, most systems achieve at-least-once execution with idempotent job design rather than true exactly-once semantics due to the complexity of distributed consensus.</p>\n<p><strong>At-least-once execution</strong> - A weaker guarantee where jobs may run multiple times but are never lost or skipped. This is more practical to implement in distributed systems because it only requires durable job queuing and retry logic, not distributed coordination to prevent duplicates. Jobs must be designed to handle duplicate execution gracefully.</p>\n<p><strong>Leader election</strong> - The process of selecting a single coordinator node from multiple candidates in a distributed system. The leader is responsible for making decisions that require global coordination, such as job assignment and worker failure detection. Leader election prevents split-brain scenarios where multiple nodes attempt to coordinate simultaneously.</p>\n<p><strong>Split-brain</strong> - A failure condition where network partitions cause multiple coordinator nodes to believe they are the leader simultaneously. This can result in duplicate job execution, conflicting worker assignments, and data corruption. Prevention requires consensus protocols and fencing mechanisms to ensure only one active leader.</p>\n<p><strong>Fencing token</strong> - A unique, monotonically increasing identifier that prevents stale operations from interfering with current system state. When a worker claims a job, it receives a fencing token. Later operations must present this token to prove they are authorized and current. Outdated tokens are rejected, preventing race conditions during worker failures.</p>\n<p><strong>Network partition</strong> - A failure mode where network connectivity is lost between subsets of nodes, effectively splitting the cluster into isolated groups. Each partition may continue operating independently, potentially causing inconsistent state. Partition tolerance requires careful design of consensus algorithms and data consistency mechanisms.</p>\n<p><strong>Consensus algorithms</strong> - Distributed protocols that enable multiple nodes to agree on a single value or decision despite failures and network issues. Examples include Raft, Paxos, and Byzantine Fault Tolerance. Consensus is essential for leader election, cluster membership, and ensuring consistent job scheduling decisions across coordinators.</p>\n<p><strong>Distributed locking</strong> - Mechanisms that ensure only one node can access a shared resource at a time, even across network boundaries. In job scheduling, distributed locks prevent multiple workers from claiming the same job simultaneously. Implementation typically uses external coordination services like etcd or Redis with lease-based timeouts.</p>\n<h3 id=\"job-scheduling-and-cron-concepts\">Job Scheduling and Cron Concepts</h3>\n<p><strong>Cron expression</strong> - A time-based job scheduler pattern using five or six fields (minute, hour, day-of-month, month, day-of-week, optionally seconds) to specify when jobs should execute. Each field can contain specific values, ranges, lists, step values, or wildcards. For example, <code>0 */2 * * *</code> means &quot;every two hours at minute 0&quot;.</p>\n<p><strong>Field constraint</strong> - Individual time component filters within a cron expression that determine when execution is allowed. For minute field <code>10,20,30</code>, the constraint allows execution only when the current minute is exactly 10, 20, or 30. All field constraints must be satisfied simultaneously for execution to occur.</p>\n<p><strong>Next execution time</strong> - The future timestamp when a cron job should run next, calculated by finding the earliest time after the current moment that satisfies all field constraints. This requires calendar arithmetic to handle month boundaries, leap years, and timezone transitions correctly.</p>\n<p><strong>Pattern matching</strong> - The process of checking whether a current timestamp satisfies all field constraints in a cron expression. This involves expanding ranges and step values into explicit lists, then testing if each time component (minute, hour, etc.) appears in the corresponding constraint list.</p>\n<p><strong>Range expansion</strong> - Converting cron syntax shortcuts like <code>1-5</code> (range) or <code>*/15</code> (step values) into explicit lists of valid values. Range <code>1-5</code> becomes <code>[1, 2, 3, 4, 5]</code>, while <code>*/15</code> in the minute field becomes <code>[0, 15, 30, 45]</code>. This simplifies pattern matching logic.</p>\n<p><strong>Calendar arithmetic</strong> - Mathematical operations involving dates and time periods that must account for irregular calendar rules like varying month lengths, leap years, and daylight saving time transitions. Simple timestamp addition fails across month boundaries; proper date libraries handle these complexities.</p>\n<p><strong>Timezone normalization</strong> - Converting all timestamps to UTC (Coordinated Universal Time) for consistent storage and comparison, then converting back to local timezone for display or cron evaluation. This prevents scheduling errors when coordinators and workers operate in different timezones.</p>\n<p><strong>Daylight saving time (DST)</strong> - Seasonal time adjustments that create temporal anomalies twice yearly. During &quot;spring forward&quot;, 2:30 AM doesn&#39;t exist. During &quot;fall back&quot;, 1:30 AM occurs twice. Cron scheduling must handle these transitions by skipping or duplicating execution appropriately.</p>\n<p><strong>DST transition</strong> - The specific moments when clocks change between standard and daylight saving time. Jobs scheduled during transition periods may be skipped (spring forward) or run twice (fall back) unless the scheduler implements special handling for these edge cases.</p>\n<h3 id=\"priority-queue-and-job-management\">Priority Queue and Job Management</h3>\n<p><strong>Priority queue</strong> - A data structure that serves the highest-priority element first, regardless of insertion order. In job scheduling, higher-priority jobs are dequeued before lower-priority ones. Implementation typically uses a min-heap or max-heap depending on whether lower or higher numbers indicate priority.</p>\n<p><strong>Deduplication</strong> - Prevention of duplicate job submissions using idempotency keys or content hashes. When a job is submitted with the same deduplication identifier as an existing job, the system returns the existing job instead of creating a duplicate. This prevents accidental double-execution from client retry logic.</p>\n<p><strong>Idempotency key</strong> - A client-provided unique identifier that ensures multiple submissions of the same job create only one execution. The key should be deterministic based on job content and intent. For example, <code>&quot;user-123-daily-report-2024-01-15&quot;</code> ensures only one daily report per user per day.</p>\n<p><strong>Content hash</strong> - A deterministic hash (like SHA-256) computed from normalized job payload content. Used for deduplication when no explicit idempotency key is provided. The hash must be computed from a canonical representation to ensure identical jobs produce identical hashes regardless of field ordering.</p>\n<p><strong>Delayed execution</strong> - Jobs that exist in the system but remain invisible and ineligible for worker assignment until a specified future time. Implementation uses the visibility timeout pattern where jobs are stored with a &quot;not_before&quot; timestamp and promoted to the active queue when that time arrives.</p>\n<p><strong>Visibility timeout pattern</strong> - A queuing mechanism where messages exist but remain invisible to consumers until a timeout expires. For job scheduling, this enables delayed execution by setting visibility timeout to the scheduled execution time. Jobs become visible and claimable only when ready to run.</p>\n<p><strong>Atomic operations</strong> - Database or data structure operations that complete entirely or not at all, with no partial states visible to concurrent operations. Critical for job claiming to prevent race conditions where multiple workers attempt to claim the same job simultaneously.</p>\n<p><strong>Priority inversion</strong> - A condition where high-priority jobs are blocked by lower-priority work, either through resource contention or implementation bugs. In job queues, this can occur if priority ordering is not strictly maintained or if workers become blocked on low-priority long-running tasks.</p>\n<h3 id=\"worker-coordination-and-fault-tolerance\">Worker Coordination and Fault Tolerance</h3>\n<p><strong>Worker coordination</strong> - The process of managing job distribution across multiple worker nodes, including worker registration, capability matching, load balancing, and failure detection. Coordination ensures work is distributed efficiently while maintaining fault tolerance through redundancy.</p>\n<p><strong>Heartbeat</strong> - A periodic liveness signal sent from workers to coordinators indicating the worker is healthy and available for job assignment. Missed heartbeats trigger failure detection. Heartbeat messages typically include current job count, resource utilization, and capability information.</p>\n<p><strong>Graceful shutdown</strong> - A controlled worker termination process that completes currently executing jobs before stopping, rather than abruptly terminating and losing work. This prevents job loss during planned maintenance or scaling operations.</p>\n<p><strong>Capability matching</strong> - Ensuring workers can handle specific job types by comparing required job capabilities against worker-provided capabilities. For example, jobs requiring GPU processing are only assigned to workers advertising GPU capability. This prevents job failures from resource mismatches.</p>\n<p><strong>Fault tolerance</strong> - The system&#39;s ability to continue operating correctly despite node failures, network issues, or other faults. Achieved through redundancy, replication, failure detection, and recovery mechanisms. In job scheduling, fault tolerance ensures jobs complete even when individual workers fail.</p>\n<p><strong>Failure detection</strong> - Mechanisms for identifying when system components have stopped functioning correctly. Common approaches include heartbeat timeouts, health check failures, and monitoring error rates. Accurate failure detection is crucial for triggering recovery procedures promptly.</p>\n<p><strong>Job recovery</strong> - The process of reassigning jobs from failed workers to healthy workers. Recovery must handle jobs in various states: claimed but not started, currently executing, and completed but not reported. Proper recovery prevents job loss while avoiding duplicate execution.</p>\n<p><strong>Message amplification</strong> - A failure mode where message retries create exponentially increasing load, potentially overwhelming the system. Can occur when multiple components retry simultaneously or when retry delays are not properly randomized. Mitigation requires exponential backoff with jitter.</p>\n<p><strong>Thundering herd</strong> - A scenario where many workers simultaneously attempt to claim jobs or reconnect after a shared dependency (like the coordinator) recovers from failure. This can overwhelm the recovering component. Prevention uses randomized delays and gradual reconnection.</p>\n<h3 id=\"error-handling-and-reliability\">Error Handling and Reliability</h3>\n<p><strong>Exponential backoff</strong> - A retry strategy where the delay between attempts increases exponentially (e.g., 1s, 2s, 4s, 8s) to reduce load on failing systems and increase the chance of recovery. Often combined with jitter (random variation) to prevent synchronized retry storms across multiple clients.</p>\n<p><strong>Circuit breaker</strong> - A reliability pattern that prevents cascade failures by temporarily stopping calls to a failing service. The circuit breaker monitors error rates and &quot;opens&quot; (blocks requests) when failures exceed a threshold, allowing the downstream service time to recover.</p>\n<p><strong>Dead letter queue</strong> - A repository for operations that failed all retry attempts and require manual intervention. Dead letter entries include the original operation, failure history, and diagnostic context. This prevents permanent job loss while allowing operators to investigate and potentially resubmit failed work.</p>\n<p><strong>Retry amplification</strong> - A failure mode where multiple system layers retry the same operation simultaneously, creating exponential load increase. For example, if both the client and server retry a failed job submission, the total retry attempts become multiplicative rather than additive.</p>\n<p><strong>Jitter</strong> - Random variation added to retry delays to prevent synchronized behavior across multiple clients. Without jitter, all clients retry at exactly the same intervals, creating periodic load spikes. Random jitter spreads the load over time for better system stability.</p>\n<p><strong>Idempotency</strong> - A property where executing the same operation multiple times produces the same result as executing it once. Essential for reliable distributed systems because network failures can make it unclear whether operations succeeded, requiring safe retry mechanisms.</p>\n<p><strong>Graduated failure detection</strong> - An escalating response strategy where the system&#39;s reaction intensifies based on failure duration and severity. Short transient failures might trigger simple retries, while sustained failures escalate to circuit breaker activation and alerting.</p>\n<h3 id=\"testing-and-development\">Testing and Development</h3>\n<p><strong>Unit testing</strong> - Testing individual components (functions, classes, modules) in isolation using mocked dependencies. For the job scheduler, this includes testing cron parsing logic, priority queue operations, and worker state transitions independently of external systems.</p>\n<p><strong>Integration testing</strong> - Testing component interactions under realistic conditions with actual dependencies like Redis, etcd, or databases. This verifies that components work together correctly and can handle real network delays, connection failures, and concurrent access patterns.</p>\n<p><strong>End-to-end testing</strong> - Complete system validation that tests the entire job execution flow from submission through completion. This includes submitting jobs, verifying they execute on workers, handling failures, and confirming final state matches expectations.</p>\n<p><strong>Failure injection</strong> - Systematic introduction of failures into the system during testing to verify resilience mechanisms work correctly. Examples include network partitions, process crashes, disk failures, and resource exhaustion. Also called chaos engineering or fault injection.</p>\n<p><strong>Race conditions</strong> - Timing-dependent bugs in concurrent code where the outcome depends on the relative timing of operations across threads or processes. Common in distributed systems due to network delays. Prevention requires careful synchronization and atomic operations.</p>\n<p><strong>Deterministic testing</strong> - Creating predictable test behavior by controlling sources of randomness like timestamps, network delays, and thread scheduling. This makes tests repeatable and debuggable by eliminating timing-dependent failures.</p>\n<p><strong>Test harness</strong> - Infrastructure providing consistent test environments including mock services, controlled time, isolated databases, and cleanup mechanisms. The harness handles setup and teardown, allowing tests to focus on business logic verification.</p>\n<p><strong>Milestone checkpoints</strong> - Structured validation points at each development stage that verify expected functionality is working before proceeding. Checkpoints include automated tests, manual verification steps, and integration smoke tests.</p>\n<h3 id=\"observability-and-debugging\">Observability and Debugging</h3>\n<p><strong>Structured logging</strong> - Logging with consistent data formats (typically JSON) that enable programmatic analysis, filtering, and correlation. Each log entry includes standard fields like timestamp, component, correlation ID, and operation name, plus operation-specific details.</p>\n<p><strong>Correlation ID</strong> - A unique identifier that links related operations across distributed system boundaries. When a job is submitted, the same correlation ID appears in logs from the coordinator, worker, and queue components, enabling end-to-end request tracing.</p>\n<p><strong>Distributed tracing</strong> - A technique for tracking request flow across multiple service boundaries by propagating trace context and recording timing spans. Each operation adds a span with start time, duration, and metadata, creating a complete timeline of distributed request execution.</p>\n<p><strong>Metrics collection</strong> - Systematic gathering of quantitative system performance data like job completion rates, queue depths, worker utilization, and error rates. Metrics are typically time-series data stored in systems like Prometheus for alerting and dashboards.</p>\n<p><strong>Log aggregation</strong> - Centralized collection and indexing of log entries from multiple distributed components. Aggregation enables searching across all system logs simultaneously and correlating events that span multiple services.</p>\n<p><strong>Failure pattern analysis</strong> - Systematic identification of common failure sequences in distributed systems by analyzing log patterns, metrics anomalies, and error correlations. Helps identify root causes and prevent recurring issues through improved error handling.</p>\n<p><strong>Observability</strong> - The ability to understand system internal state through external outputs (logs, metrics, traces). High observability enables rapid troubleshooting and performance optimization by providing visibility into system behavior during both normal and failure conditions.</p>\n<p><strong>Alert threshold</strong> - Metric value boundaries that trigger automated notifications when crossed. Thresholds must balance sensitivity (catching real issues quickly) with specificity (avoiding false alarms). Common examples include error rate percentages and response time percentiles.</p>\n<h3 id=\"future-extensions-and-advanced-concepts\">Future Extensions and Advanced Concepts</h3>\n<p><strong>Job dependencies</strong> - Prerequisites that must be satisfied before a job can execute, such as completion of other jobs or availability of required data. Dependencies create directed acyclic graphs (DAGs) of job relationships and require topological sorting for execution order.</p>\n<p><strong>Resource-aware scheduling</strong> - Job assignment that considers memory, CPU, storage, and other resource requirements against worker capacity. This prevents resource exhaustion and improves overall system efficiency by matching job needs with worker capabilities.</p>\n<p><strong>Workflow orchestration</strong> - Coordinated execution of multi-job workflows with conditional logic, parallel branches, loops, and error handling. More complex than simple job dependencies, workflows require state machines and execution engines to manage complex business processes.</p>\n<p><strong>Horizontal sharding</strong> - Distributing jobs across multiple independent scheduler clusters based on characteristics like tenant ID, job type, or hash key. Sharding improves scalability by reducing coordination overhead and enabling independent scaling of different workload types.</p>\n<p><strong>Multi-datacenter deployment</strong> - Operating the scheduler across multiple geographic regions for disaster recovery and latency optimization. Requires careful handling of clock skew, network partitions, and data consistency across wide-area networks.</p>\n<p><strong>Audit logging</strong> - Detailed recording of administrative actions, configuration changes, and security events for compliance and security purposes. Audit logs are typically immutable and include who performed actions, when, what changed, and why.</p>\n<p>This comprehensive glossary provides the foundation for understanding distributed job scheduler concepts and implementing the system correctly. The terminology spans from fundamental distributed systems concepts through specific scheduling algorithms to operational concerns, supporting both learning and professional communication about the system.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The terminology in this glossary should be used consistently throughout code comments, documentation, and team communication. Here are practical guidelines for applying these terms in implementation:</p>\n<p><strong>Code Documentation Standards</strong></p>\n<p>When writing code comments and documentation, use these terms precisely and consistently. For example, always refer to &quot;exactly-once execution&quot; rather than mixing terms like &quot;exactly-once delivery&quot; or &quot;once-only processing&quot;. This consistency helps team members communicate clearly and reduces misunderstandings during code reviews and debugging sessions.</p>\n<p><strong>Variable and Function Naming</strong></p>\n<p>Incorporate terminology into identifier names to make code self-documenting. Use <code>idempotencyKey</code> rather than generic names like <code>dedupId</code>. Name functions like <code>detectWorkerFailure()</code> and <code>performLeaderElection()</code> to clearly indicate their purpose using standard distributed systems terminology.</p>\n<p><strong>Error Messages and Logging</strong></p>\n<p>Include proper terminology in error messages and log entries to aid debugging. Instead of &quot;job failed&quot;, use &quot;job exceeded maximum retry attempts and moved to dead letter queue&quot;. This provides operators with precise information about system state and required actions.</p>\n<p><strong>Team Communication Guidelines</strong></p>\n<table>\n<thead>\n<tr>\n<th>Term Category</th>\n<th>Usage Guideline</th>\n<th>Example</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Consistency Levels</td>\n<td>Always specify exactly-once vs at-least-once when discussing guarantees</td>\n<td>&quot;This implementation provides at-least-once execution with idempotent job design&quot;</td>\n</tr>\n<tr>\n<td>Failure Modes</td>\n<td>Use precise terms for different types of failures</td>\n<td>&quot;We&#39;re seeing split-brain behavior, not general leader election failure&quot;</td>\n</tr>\n<tr>\n<td>Timing Concepts</td>\n<td>Distinguish between different time-related operations</td>\n<td>&quot;The DST transition caused cron schedule skipping, not general timezone normalization issues&quot;</td>\n</tr>\n<tr>\n<td>System States</td>\n<td>Use exact state names from data model</td>\n<td>&quot;Worker is in UNAVAILABLE state, not just &#39;down&#39; or &#39;broken&#39;&quot;</td>\n</tr>\n</tbody></table>\n<p><strong>Documentation Cross-References</strong></p>\n<p>When writing design documents or architectural decision records, reference this glossary to ensure consistent terminology. Include brief definitions for complex terms when first introduced in new contexts, with references back to the full glossary definitions for complete understanding.</p>\n<p>This implementation guidance ensures the terminology serves its purpose of enabling clear, precise communication about the distributed job scheduler system throughout the development lifecycle.</p>\n","toc":[{"level":1,"text":"Distributed Job Scheduler: Design Document","id":"distributed-job-scheduler-design-document"},{"level":2,"text":"Overview","id":"overview"},{"level":2,"text":"Context and Problem Statement","id":"context-and-problem-statement"},{"level":3,"text":"Problem Overview","id":"problem-overview"},{"level":3,"text":"Existing Approaches","id":"existing-approaches"},{"level":3,"text":"Technical Challenges","id":"technical-challenges"},{"level":4,"text":"Consensus: Who Decides What Jobs Run When?","id":"consensus-who-decides-what-jobs-run-when"},{"level":4,"text":"Failure Detection: When Has a Worker Actually Failed?","id":"failure-detection-when-has-a-worker-actually-failed"},{"level":4,"text":"Exactly-Once Execution: The Distributed Scheduling Holy Grail","id":"exactly-once-execution-the-distributed-scheduling-holy-grail"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations for Distributed Coordination","id":"technology-recommendations-for-distributed-coordination"},{"level":4,"text":"Key Architectural Decisions to Make","id":"key-architectural-decisions-to-make"},{"level":2,"text":"Goals and Non-Goals","id":"goals-and-non-goals"},{"level":3,"text":"Functional Goals","id":"functional-goals"},{"level":3,"text":"Non-Functional Goals","id":"non-functional-goals"},{"level":3,"text":"Explicit Non-Goals","id":"explicit-non-goals"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"High-Level Architecture","id":"high-level-architecture"},{"level":3,"text":"System Components","id":"system-components"},{"level":4,"text":"Scheduler Service Components","id":"scheduler-service-components"},{"level":4,"text":"Job Queue Infrastructure","id":"job-queue-infrastructure"},{"level":4,"text":"Worker Pool Management","id":"worker-pool-management"},{"level":4,"text":"Coordination Layer Architecture","id":"coordination-layer-architecture"},{"level":3,"text":"Deployment Model","id":"deployment-model"},{"level":4,"text":"Physical Deployment Topology","id":"physical-deployment-topology"},{"level":4,"text":"Network Communication Patterns","id":"network-communication-patterns"},{"level":4,"text":"Scaling and Resource Planning","id":"scaling-and-resource-planning"},{"level":3,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Package Dependency Guidelines","id":"package-dependency-guidelines"},{"level":4,"text":"Development Workflow Organization","id":"development-workflow-organization"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeleton Code","id":"core-logic-skeleton-code"},{"level":4,"text":"File Structure Commands","id":"file-structure-commands"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":4,"text":"Language-Specific Go Hints","id":"language-specific-go-hints"},{"level":2,"text":"Data Model","id":"data-model"},{"level":3,"text":"Job Definition","id":"job-definition"},{"level":3,"text":"Worker Model","id":"worker-model"},{"level":3,"text":"Schedule Model","id":"schedule-model"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Cron Expression Parser","id":"cron-expression-parser"},{"level":3,"text":"Mental Model: Understanding cron as a calendar pattern matching system","id":"mental-model-understanding-cron-as-a-calendar-pattern-matching-system"},{"level":3,"text":"Parsing Algorithm: Field-by-field validation and range expansion for cron expressions","id":"parsing-algorithm-field-by-field-validation-and-range-expansion-for-cron-expressions"},{"level":3,"text":"Next Time Calculation: Algorithm for finding the next valid execution time from current timestamp","id":"next-time-calculation-algorithm-for-finding-the-next-valid-execution-time-from-current-timestamp"},{"level":3,"text":"Timezone Handling: UTC normalization and daylight saving time considerations","id":"timezone-handling-utc-normalization-and-daylight-saving-time-considerations"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Priority Job Queue","id":"priority-job-queue"},{"level":3,"text":"Mental Model: Priority Queue as a Hospital Triage System","id":"mental-model-priority-queue-as-a-hospital-triage-system"},{"level":3,"text":"Priority Mechanism: Numeric Priority Levels and Heap-Based Ordering","id":"priority-mechanism-numeric-priority-levels-and-heap-based-ordering"},{"level":3,"text":"Delayed Execution: Visibility Timeout Pattern for Scheduled Jobs","id":"delayed-execution-visibility-timeout-pattern-for-scheduled-jobs"},{"level":3,"text":"Deduplication Strategy: Idempotency Keys and Hash-Based Detection","id":"deduplication-strategy-idempotency-keys-and-hash-based-detection"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Worker Coordination","id":"worker-coordination"},{"level":3,"text":"Mental Model: Worker coordination as an orchestra with conductor and failure recovery","id":"mental-model-worker-coordination-as-an-orchestra-with-conductor-and-failure-recovery"},{"level":3,"text":"Leader Election: Raft-like consensus for scheduler leadership and split-brain prevention","id":"leader-election-raft-like-consensus-for-scheduler-leadership-and-split-brain-prevention"},{"level":4,"text":"Common Pitfalls","id":"common-pitfalls"},{"level":3,"text":"Worker Registration: Dynamic worker discovery, capacity reporting, and capability matching","id":"worker-registration-dynamic-worker-discovery-capacity-reporting-and-capability-matching"},{"level":3,"text":"Heartbeat Mechanism: Failure detection through periodic health checks and timeout handling","id":"heartbeat-mechanism-failure-detection-through-periodic-health-checks-and-timeout-handling"},{"level":3,"text":"Job Recovery: Detecting failed workers and reassigning their in-progress jobs","id":"job-recovery-detecting-failed-workers-and-reassigning-their-in-progress-jobs"},{"level":4,"text":"Common Pitfalls","id":"common-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Interactions and Data Flow","id":"interactions-and-data-flow"},{"level":3,"text":"Mental Model: Orchestra Performance","id":"mental-model-orchestra-performance"},{"level":3,"text":"Job Submission Flow","id":"job-submission-flow"},{"level":4,"text":"Submission Process Overview","id":"submission-process-overview"},{"level":4,"text":"Submission Message Formats","id":"submission-message-formats"},{"level":4,"text":"Deduplication Strategy Details","id":"deduplication-strategy-details"},{"level":4,"text":"Error Handling in Submission Flow","id":"error-handling-in-submission-flow"},{"level":4,"text":"Common Pitfalls in Job Submission","id":"common-pitfalls-in-job-submission"},{"level":3,"text":"Job Execution Flow","id":"job-execution-flow"},{"level":4,"text":"Execution Process Overview","id":"execution-process-overview"},{"level":4,"text":"Job State Machine During Execution","id":"job-state-machine-during-execution"},{"level":4,"text":"Worker Job Claiming Process","id":"worker-job-claiming-process"},{"level":4,"text":"Fencing Token Mechanism","id":"fencing-token-mechanism"},{"level":4,"text":"Execution Monitoring and Heartbeats","id":"execution-monitoring-and-heartbeats"},{"level":4,"text":"Retry Logic and Failure Handling","id":"retry-logic-and-failure-handling"},{"level":4,"text":"Common Pitfalls in Job Execution","id":"common-pitfalls-in-job-execution"},{"level":3,"text":"Coordination Messages","id":"coordination-messages"},{"level":4,"text":"Message Categories and Purposes","id":"message-categories-and-purposes"},{"level":4,"text":"Leader Election Messages","id":"leader-election-messages"},{"level":4,"text":"Worker Registration Messages","id":"worker-registration-messages"},{"level":4,"text":"Heartbeat Message Protocol","id":"heartbeat-message-protocol"},{"level":4,"text":"Job Assignment Messages","id":"job-assignment-messages"},{"level":4,"text":"Message Reliability and Ordering","id":"message-reliability-and-ordering"},{"level":4,"text":"Common Pitfalls in Coordination Messages","id":"common-pitfalls-in-coordination-messages"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Core Message Handling Infrastructure","id":"core-message-handling-infrastructure"},{"level":4,"text":"Job Assignment Message Implementation","id":"job-assignment-message-implementation"},{"level":4,"text":"Heartbeat Protocol Implementation","id":"heartbeat-protocol-implementation"},{"level":4,"text":"Message Flow Orchestration","id":"message-flow-orchestration"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":2,"text":"Error Handling and Edge Cases","id":"error-handling-and-edge-cases"},{"level":3,"text":"Mental Model: Emergency Response Coordination","id":"mental-model-emergency-response-coordination"},{"level":3,"text":"Failure Modes","id":"failure-modes"},{"level":4,"text":"Network Partition Failures","id":"network-partition-failures"},{"level":4,"text":"Worker Crash Failures","id":"worker-crash-failures"},{"level":4,"text":"Coordination Service Outages","id":"coordination-service-outages"},{"level":3,"text":"Retry Strategies","id":"retry-strategies"},{"level":4,"text":"Exponential Backoff Implementation","id":"exponential-backoff-implementation"},{"level":4,"text":"Maximum Attempts and Escalation","id":"maximum-attempts-and-escalation"},{"level":4,"text":"Dead Letter Queue Handling","id":"dead-letter-queue-handling"},{"level":3,"text":"Consistency Guarantees","id":"consistency-guarantees"},{"level":4,"text":"At-Least-Once vs Exactly-Once Execution","id":"at-least-once-vs-exactly-once-execution"},{"level":4,"text":"Idempotency Requirements","id":"idempotency-requirements"},{"level":4,"text":"Fencing Tokens and Split-Brain Prevention","id":"fencing-tokens-and-split-brain-prevention"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeleton Code","id":"core-logic-skeleton-code"},{"level":4,"text":"Language-Specific Hints","id":"language-specific-hints"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":4,"text":"Debugging Tips","id":"debugging-tips"},{"level":2,"text":"Testing Strategy","id":"testing-strategy"},{"level":3,"text":"Unit Testing","id":"unit-testing"},{"level":4,"text":"Cron Expression Parsing Tests","id":"cron-expression-parsing-tests"},{"level":4,"text":"Priority Queue Operation Tests","id":"priority-queue-operation-tests"},{"level":4,"text":"Coordination Logic Tests","id":"coordination-logic-tests"},{"level":3,"text":"Integration Testing","id":"integration-testing"},{"level":4,"text":"Multi-Worker Coordination Scenarios","id":"multi-worker-coordination-scenarios"},{"level":4,"text":"Failure Injection and Recovery","id":"failure-injection-and-recovery"},{"level":4,"text":"End-to-End Job Execution Flow","id":"end-to-end-job-execution-flow"},{"level":3,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":4,"text":"Milestone 1: Cron Expression Parser Validation","id":"milestone-1-cron-expression-parser-validation"},{"level":4,"text":"Milestone 2: Priority Queue System Validation","id":"milestone-2-priority-queue-system-validation"},{"level":4,"text":"Milestone 3: Worker Coordination Validation","id":"milestone-3-worker-coordination-validation"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Debugging Guide","id":"debugging-guide"},{"level":3,"text":"Common Symptoms","id":"common-symptoms"},{"level":3,"text":"Diagnostic Tools","id":"diagnostic-tools"},{"level":3,"text":"Troubleshooting Workflows","id":"troubleshooting-workflows"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Future Extensions","id":"future-extensions"},{"level":3,"text":"Advanced Scheduling","id":"advanced-scheduling"},{"level":4,"text":"Job Dependencies and Workflow DAGs","id":"job-dependencies-and-workflow-dags"},{"level":4,"text":"Resource-Aware Scheduling","id":"resource-aware-scheduling"},{"level":4,"text":"Workflow Orchestration Engine","id":"workflow-orchestration-engine"},{"level":3,"text":"Operational Features","id":"operational-features"},{"level":4,"text":"Comprehensive Metrics and Monitoring","id":"comprehensive-metrics-and-monitoring"},{"level":4,"text":"Job Execution History and Analytics","id":"job-execution-history-and-analytics"},{"level":4,"text":"Administrative Interfaces","id":"administrative-interfaces"},{"level":4,"text":"Comprehensive Audit Logging","id":"comprehensive-audit-logging"},{"level":3,"text":"Scalability Improvements","id":"scalability-improvements"},{"level":4,"text":"Horizontal Sharding Architecture","id":"horizontal-sharding-architecture"},{"level":4,"text":"Multi-Datacenter Deployment","id":"multi-datacenter-deployment"},{"level":4,"text":"Performance Optimizations","id":"performance-optimizations"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Glossary","id":"glossary"},{"level":3,"text":"Distributed Systems Core Concepts","id":"distributed-systems-core-concepts"},{"level":3,"text":"Job Scheduling and Cron Concepts","id":"job-scheduling-and-cron-concepts"},{"level":3,"text":"Priority Queue and Job Management","id":"priority-queue-and-job-management"},{"level":3,"text":"Worker Coordination and Fault Tolerance","id":"worker-coordination-and-fault-tolerance"},{"level":3,"text":"Error Handling and Reliability","id":"error-handling-and-reliability"},{"level":3,"text":"Testing and Development","id":"testing-and-development"},{"level":3,"text":"Observability and Debugging","id":"observability-and-debugging"},{"level":3,"text":"Future Extensions and Advanced Concepts","id":"future-extensions-and-advanced-concepts"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"}],"title":"Distributed Job Scheduler: Design Document","markdown":"# Distributed Job Scheduler: Design Document\n\n\n## Overview\n\nA distributed job scheduler that executes tasks across multiple workers using cron expressions for timing, with priorities, retries, and fault-tolerant coordination. The key architectural challenge is maintaining consistency and preventing duplicate execution while ensuring high availability and fair job distribution across a dynamic cluster of workers.\n\n\n> This guide is meant to help you understand the big picture before diving into each milestone. Refer back to it whenever you need context on how components connect.\n\n\n## Context and Problem Statement\n\n> **Milestone(s):** This section provides foundational understanding for all three milestones by establishing the need for distributed job scheduling and the technical challenges that inform our architectural decisions.\n\n### Problem Overview\n\nThink of distributed job scheduling as managing a city's public transportation system. Just as a city needs buses to run on time, reach every neighborhood, and continue operating even when some vehicles break down, modern applications need **scheduled tasks** to execute reliably across multiple machines, handle varying workloads, and maintain service availability despite individual server failures.\n\nIn a traditional single-server environment, job scheduling is straightforward—you run a cron daemon on one machine, and it executes tasks at predetermined times. This works perfectly for simple scenarios, like a personal blog that generates a daily summary or a small business that backs up its database nightly. However, as systems scale and reliability requirements increase, this centralized approach reveals critical limitations.\n\nConsider an e-commerce platform that needs to process millions of scheduled tasks daily: sending abandoned cart reminders, generating analytics reports, processing subscription renewals, cleaning up temporary files, and synchronizing inventory across multiple warehouses. A single-server scheduler becomes a **single point of failure**—if that machine crashes, all scheduled work stops. Even worse, the machine might become overwhelmed by the sheer volume of tasks, leading to delays, missed schedules, and cascading failures throughout the system.\n\nThe distributed job scheduler we're building addresses these challenges by spreading the work across multiple **worker nodes**, much like how a transit system uses multiple buses to serve a city. When one bus breaks down, others continue running their routes. When passenger demand increases in certain areas, the system can deploy additional buses to those routes. Similarly, our scheduler can distribute jobs across healthy workers, automatically reassign work from failed nodes, and scale capacity by adding more worker machines.\n\nThe core insight is that **reliable scheduling at scale requires coordination**. Just as buses need a central dispatch system to prevent multiple buses from serving the same route simultaneously while ensuring no routes go unserved, distributed workers need coordination mechanisms to prevent duplicate job execution while guaranteeing that every scheduled task eventually runs.\n\nHowever, this coordination introduces complexity that doesn't exist in single-server systems. We must solve fundamental distributed systems problems: How do multiple workers agree on who should execute a specific job? How do we detect when a worker has failed and reassign its work? How do we ensure that a job runs exactly once, even when network partitions occur or workers crash mid-execution? These challenges form the technical foundation for our entire design.\n\n### Existing Approaches\n\nThe landscape of job scheduling solutions reflects different trade-offs between simplicity, reliability, and scalability. Understanding these existing approaches helps us appreciate why we need a custom distributed scheduler and informs our architectural decisions.\n\n| Approach | Description | Strengths | Limitations |\n|----------|-------------|-----------|-------------|\n| **Centralized Schedulers** | Single coordinator manages all scheduling (cron, Jenkins, Airflow single-node) | Simple to reason about, strong consistency guarantees, easy debugging | Single point of failure, limited scalability, resource bottleneck |\n| **Message Queue Systems** | Jobs queued in brokers, workers poll for tasks (RabbitMQ, AWS SQS + Lambda) | High throughput, natural load distribution, proven reliability | Limited scheduling flexibility, complex delay mechanisms, external dependencies |\n| **Database-Driven Polling** | Jobs stored in DB tables, workers query for pending tasks | Simple implementation, leverages existing infrastructure, transaction support | Database becomes bottleneck, polling inefficiency, lock contention |\n| **Distributed Coordination** | Multiple schedulers coordinate via consensus (Kubernetes CronJobs, distributed Quartz) | High availability, horizontal scalability, fault tolerance | Complex implementation, consensus overhead, split-brain risks |\n\n**Centralized schedulers** like traditional cron or single-node Airflow offer the strongest consistency guarantees because there's only one decision-maker. When you schedule a job to run \"every day at 2 AM,\" you can be absolutely certain it won't run multiple times because only one scheduler exists. These systems are also easier to debug—you have one log file, one configuration, and one point of control. However, they fail catastrophically when the central coordinator goes down, and they cannot scale beyond the resources of a single machine.\n\n**Message queue approaches** excel at handling high-throughput job processing by naturally distributing work across multiple consumer workers. Systems like RabbitMQ with delayed message plugins or AWS SQS with visibility timeouts provide reliable job delivery guarantees. However, they struggle with complex scheduling requirements. Implementing a job that runs \"every weekday at 9 AM except holidays\" requires external scheduling logic to enqueue messages at the right times, and advanced features like job dependencies or conditional execution become cumbersome.\n\n**Database-driven polling** represents a common middle-ground approach where jobs are stored as database records with scheduling metadata, and workers periodically query for pending tasks. This leverages existing database infrastructure and provides ACID transaction support for job state transitions. However, the database becomes a bottleneck as worker counts increase, and frequent polling creates unnecessary load. Additionally, implementing fair job distribution and preventing race conditions requires careful lock management.\n\n**Distributed coordination approaches** like Kubernetes CronJobs or clustered Quartz schedulers provide both high availability and scalability by running multiple scheduler instances that coordinate through consensus protocols. These systems can survive individual node failures and distribute load across multiple coordinators. However, they introduce significant complexity in consensus algorithms, leader election, and split-brain prevention.\n\n> **Design Insight**: Each approach optimizes for different priorities. Centralized systems prioritize correctness and simplicity. Message queues prioritize throughput and reliability. Database polling prioritizes implementation simplicity. Distributed coordination prioritizes availability and scalability. Our design must explicitly choose which properties matter most for our use case.\n\nOur distributed job scheduler combines elements from multiple approaches. We use **distributed coordination** for high availability and scalability, but implement our own lightweight consensus mechanism tailored to scheduling workloads rather than adopting heavyweight protocols like Raft. We incorporate **message queue patterns** for reliable job delivery between coordinators and workers, but maintain scheduling logic within the scheduler rather than pushing complexity to external systems. We leverage **database storage** for job persistence and atomic state transitions, but minimize polling overhead through event-driven notifications.\n\n> **Decision: Hybrid Architecture with Custom Coordination**\n> - **Context**: Existing solutions either sacrifice availability for simplicity or introduce unnecessary complexity for general-purpose consensus\n> - **Options Considered**: \n>   1. Pure message queue with external scheduling (simple but limited scheduling flexibility)\n>   2. Database polling with advisory locks (simple but poor scaling characteristics)  \n>   3. Full Raft consensus for all scheduling decisions (robust but heavyweight for our use case)\n>   4. Custom coordination protocol optimized for scheduling workloads\n> - **Decision**: Hybrid architecture with custom coordination protocol\n> - **Rationale**: Scheduling workloads have specific characteristics (time-based triggers, priority ordering, delayed execution) that allow for simpler coordination than general-purpose consensus while still maintaining availability and consistency\n> - **Consequences**: We gain scheduling-optimized performance and can implement exactly-once execution guarantees, but must implement and maintain our own coordination logic\n\n### Technical Challenges\n\nBuilding a distributed job scheduler requires solving three fundamental distributed systems problems: **consensus**, **failure detection**, and **exactly-once execution**. These challenges are interconnected—solving one affects how we approach the others—and their solutions form the core of our architectural design.\n\n#### Consensus: Who Decides What Jobs Run When?\n\nThe consensus problem in distributed scheduling is like coordinating traffic at a busy intersection without traffic lights. Multiple scheduler nodes might simultaneously decide that a job scheduled for \"2:00 PM\" should execute now, leading to duplicate execution. Alternatively, in trying to avoid duplicates, all nodes might assume another node will handle the job, resulting in missed executions.\n\nTraditional consensus algorithms like Raft or PBFT provide strong consistency guarantees by ensuring all nodes agree on a single sequence of operations. However, these algorithms are designed for general-purpose state machine replication and carry significant overhead for our scheduling use case. Consider a job scheduled to run every hour—full consensus for each execution decision would require multiple round-trips between nodes, potentially taking longer than the job execution itself.\n\nOur scheduling workload has specific characteristics that allow for more efficient coordination:\n\n1. **Time-based triggers**: Most decisions are triggered by time passage rather than external events\n2. **Predictable scheduling**: Next execution times can be calculated in advance using cron expressions\n3. **Priority ordering**: Jobs have explicit priority levels that provide natural ordering\n4. **Delayed execution**: Jobs can wait in queues without immediate execution requirements\n\nThese characteristics enable a **leader-based coordination model** where one scheduler node acts as the primary coordinator for job scheduling decisions, while other nodes remain in standby mode ready to take over during failures. This approach reduces coordination overhead during normal operation while maintaining availability through leader election during failures.\n\n| Consensus Challenge | Traditional Approach | Our Scheduling-Optimized Approach |\n|---------------------|---------------------|-----------------------------------|\n| **Job Execution Decisions** | Full consensus on each job execution | Leader decides, followers standby with leader election |\n| **Clock Synchronization** | Complex vector clocks or logical timestamps | NTP synchronization with tolerance windows |\n| **Schedule Conflicts** | Distributed lock acquisition per job | Centralized scheduling with atomic job claiming |\n| **Split-Brain Prevention** | Quorum-based decisions requiring majority | Lease-based leadership with automatic expiration |\n\n#### Failure Detection: When Has a Worker Actually Failed?\n\nFailure detection in distributed systems is notoriously difficult because there's no reliable way to distinguish between a slow worker and a failed worker. Network partitions can make healthy workers appear dead, while zombie processes can continue sending heartbeats despite being unable to process jobs. This is known as the **failure detection impossibility** in asynchronous distributed systems.\n\nIn our job scheduler context, failure detection mistakes have serious consequences:\n\n- **False positives** (marking healthy workers as failed) lead to unnecessary job reassignment and potential duplicate execution\n- **False negatives** (not detecting actual failures) result in jobs being assigned to dead workers, causing missed executions and system-wide delays\n\nConsider a worker executing a long-running data analysis job that takes 45 minutes to complete. If our failure detection timeout is set to 30 minutes, we'll incorrectly mark the worker as failed and potentially start duplicate execution on another worker. Conversely, if we set the timeout to 90 minutes to accommodate long jobs, actual worker failures won't be detected quickly enough, leaving jobs stuck in limbo.\n\nOur approach uses a **multi-layered failure detection strategy** that combines multiple signals:\n\n1. **Heartbeat timeouts**: Workers send periodic \"I'm alive\" messages with configurable timeout thresholds\n2. **Job progress updates**: Workers report intermediate progress on long-running jobs to prove they're actively processing\n3. **Lease-based job ownership**: Jobs are assigned with time-bounded leases that automatically expire, enabling recovery without explicit failure detection\n4. **Graceful shutdown signaling**: Workers announce their intention to shut down, allowing clean job handoff\n\n| Failure Detection Layer | Purpose | Timeout | False Positive Risk | False Negative Risk |\n|-------------------------|---------|---------|-------------------|-------------------|\n| **Heartbeat Messages** | Basic liveness detection | 30 seconds | Network partitions | Process zombies |\n| **Job Progress Updates** | Active processing verification | 5 minutes | Long-running jobs | Infinite loops |\n| **Lease Expiration** | Automatic job recovery | Job-specific | Resource constraints | Slow processing |\n| **Graceful Shutdown** | Clean worker termination | 60 seconds | None | Sudden crashes |\n\n#### Exactly-Once Execution: The Distributed Scheduling Holy Grail\n\nExactly-once execution is the most challenging problem in distributed job scheduling. Unlike at-least-once delivery (where duplicates are acceptable) or at-most-once delivery (where job loss is acceptable), exactly-once requires that every scheduled job runs precisely once, despite worker failures, network partitions, and coordinator crashes.\n\nThe fundamental challenge is that network failures can occur at any point during job execution, making it impossible to distinguish between these scenarios:\n\n1. **Job never started**: The worker received the job assignment but crashed before beginning execution\n2. **Job started but didn't finish**: The worker began execution but crashed mid-way through processing\n3. **Job finished but acknowledgment was lost**: The worker completed the job successfully but the network failed before it could report completion\n4. **Job finished and reported**: The worker completed the job and successfully reported completion, but a delayed retry caused duplicate assignment\n\nEach scenario requires different recovery actions, but they're indistinguishable from the coordinator's perspective. Traditional approaches use **idempotency** (making duplicate executions safe) or **transactional semantics** (rolling back partial executions), but these place significant burden on job implementations.\n\nOur scheduler implements exactly-once execution through a combination of techniques:\n\n**Job Leasing with Fencing Tokens**: Each job assignment includes a unique, monotonically increasing fencing token. Workers must present valid tokens when reporting job results, preventing race conditions where slow workers report results after their jobs have been reassigned.\n\n**Execution State Tracking**: Jobs progress through explicit states (`PENDING` → `CLAIMED` → `EXECUTING` → `COMPLETED`), with each transition recorded atomically in persistent storage. This provides a clear audit trail and enables precise recovery logic.\n\n**Idempotency Key Deduplication**: Jobs include client-provided idempotency keys that prevent duplicate submissions. Even if the same cron schedule fires multiple times due to coordinator failures, duplicate jobs are silently ignored.\n\n**Timeout-Based Recovery**: Jobs that remain in intermediate states (`CLAIMED`, `EXECUTING`) beyond their lease timeouts are automatically made available for reassignment, ensuring forward progress even when workers fail silently.\n\n| Exactly-Once Challenge | Problem | Our Solution | Trade-offs |\n|-------------------------|---------|--------------|------------|\n| **Duplicate Submission** | Same cron schedule triggers multiple times | Idempotency key deduplication | Requires deterministic key generation |\n| **Worker Failure Mid-Execution** | Unknown whether job completed before crash | Atomic state transitions + timeouts | Jobs must be idempotent or resumable |\n| **Network Partition During Reporting** | Coordinator can't distinguish completion from failure | Fencing tokens prevent stale reports | Adds complexity to job result handling |\n| **Coordinator Failure During Assignment** | Job assignment state may be lost or duplicated | Persistent job state + recovery scanning | Requires durable storage for all state |\n\n⚠️ **Pitfall: Assuming Network Reliability**\n\nA common mistake is designing the scheduler assuming that network operations either succeed completely or fail immediately. In reality, network operations can experience arbitrary delays, partial failures, or reordering. For example, a job assignment message might be delayed for several minutes due to network congestion, arriving after the job has already been reassigned to another worker due to timeout. This can lead to duplicate execution unless the system uses fencing tokens or similar disambiguation mechanisms.\n\nThe solution is to design all inter-component communication as potentially unreliable and implement disambiguation mechanisms (like fencing tokens) that allow recipients to determine whether received messages are current or stale.\n\n> **Critical Design Principle**: Our distributed scheduler must degrade gracefully under various failure conditions. When consensus is impossible, we prefer conservative decisions (potentially missing a single job execution) over dangerous ones (definitely executing jobs multiple times). This bias toward safety over liveness reflects the reality that most scheduled jobs are periodic—missing one execution of an hourly job is recoverable, while duplicate executions often cause irreversible side effects.\n\nThese three technical challenges—consensus, failure detection, and exactly-once execution—drive every major architectural decision in our distributed job scheduler. The solutions we choose for each problem must work together cohesively, as optimizing for one often creates constraints for the others.\n\n### Implementation Guidance\n\nThis foundational section doesn't include implementation code, but understanding the technical challenges above informs the technology choices we'll make throughout the project.\n\n#### Technology Recommendations for Distributed Coordination\n\n| Component | Simple Option | Advanced Option | Trade-offs |\n|-----------|---------------|-----------------|------------|\n| **Consensus/Coordination** | Redis with Lua scripts for atomic operations | etcd with Raft consensus for leader election | Redis simpler but less fault-tolerant; etcd more complex but industry-proven |\n| **Job Persistence** | PostgreSQL with advisory locks | Redis Streams with consumer groups | PostgreSQL stronger consistency; Redis higher performance |\n| **Worker Communication** | HTTP REST with polling | gRPC with streaming for real-time updates | REST simpler debugging; gRPC better performance |\n| **Time Synchronization** | Basic system clock comparison | NTP daemon with drift monitoring | System clocks sufficient for most use cases; NTP required for tight timing |\n\n#### Key Architectural Decisions to Make\n\nAs we progress through the implementation milestones, we'll need to make several critical decisions that balance the trade-offs identified in this section:\n\n**Consistency vs. Availability**: When network partitions occur, do we prioritize ensuring no duplicate job execution (consistency) or ensuring jobs continue to be scheduled (availability)? Our design leans toward consistency for safety.\n\n**Coordination Complexity**: Do we implement full consensus for all decisions, or use simpler leader-based coordination with the risk of brief unavailability during failover? We choose leader-based coordination for performance.\n\n**Failure Detection Sensitivity**: Do we use aggressive timeouts that quickly detect failures but risk false positives, or conservative timeouts that reduce false positives but slow failure recovery? We use configurable timeouts that can be tuned per deployment.\n\n**Storage Dependencies**: Do we require external coordination services like etcd, or can we build coordination on top of simpler storage like Redis or PostgreSQL? We support multiple storage backends with different consistency guarantees.\n\nThese decisions will become concrete as we implement each milestone, starting with the cron expression parser that must handle timezone-aware scheduling across distributed nodes.\n\n\n## Goals and Non-Goals\n\n> **Milestone(s):** This section establishes the scope and requirements for all three milestones by defining what the distributed job scheduler must accomplish and explicitly excluding complex enterprise features.\n\nThink of defining project goals like planning a city's public transportation system. You need to be crystal clear about what routes you'll serve (functional goals), how many passengers you can handle and how fast they'll get there (non-functional goals), and what services you explicitly won't provide like door-to-door limousine service (non-goals). Without this clarity, you'll either build something that doesn't meet user needs or get overwhelmed trying to solve every possible problem at once.\n\nThe goals for our distributed job scheduler emerge from real-world requirements where organizations need to execute recurring tasks reliably across multiple machines. These goals directly map to our three milestones: parsing scheduling expressions, managing job priorities and queuing, and coordinating work across a cluster of machines. Equally important are the non-goals that keep this project feasible for implementation while still providing substantial learning value.\n\n### Functional Goals\n\nThe functional goals define what the distributed job scheduler must actually do for users. These capabilities form the core user-facing behavior that determines whether the system succeeds or fails in practice.\n\n**Cron Expression Scheduling** forms the foundation of time-based job execution. The scheduler must parse standard five-field cron expressions (`minute hour day-of-month month day-of-week`) and calculate the next execution time with perfect accuracy. This includes handling wildcards (`*`), ranges (`1-5`), step values (`*/15`), and specific lists (`1,3,5`). The system should also support common shorthand aliases like `@daily`, `@hourly`, and `@weekly` for user convenience.\n\n> **Decision: Standard Five-Field Cron Support**\n> - **Context**: Multiple cron formats exist, from traditional five fields to extended six-field versions with seconds\n> - **Options Considered**: Five-field only, six-field with seconds, full Quartz-style expressions\n> - **Decision**: Support standard five-field cron with common aliases\n> - **Rationale**: Five-field cron covers 95% of real-world scheduling needs while keeping parsing complexity manageable for a learning project\n> - **Consequences**: Users get familiar, well-documented syntax, but cannot schedule sub-minute tasks\n\n| Cron Feature | Supported | Example | Description |\n|--------------|-----------|---------|-------------|\n| Wildcards | Yes | `* * * * *` | Every minute |\n| Specific Values | Yes | `30 14 * * 1` | 2:30 PM every Monday |\n| Ranges | Yes | `0 9-17 * * 1-5` | Every hour during business days |\n| Step Values | Yes | `*/15 * * * *` | Every 15 minutes |\n| Lists | Yes | `0 8,12,18 * * *` | 8 AM, noon, and 6 PM daily |\n| Aliases | Yes | `@daily`, `@weekly` | Common scheduling shortcuts |\n\n**Priority-Based Job Queuing** ensures that critical jobs execute before less important ones. The system must accept jobs with numeric priority levels (higher numbers indicate higher priority) and guarantee that a higher-priority job never waits behind a lower-priority job when workers are available. This requires a priority queue implementation that can handle thousands of pending jobs efficiently.\n\nThe queuing system must also support **delayed execution** where jobs submitted now don't become eligible for execution until a future timestamp. This enables both one-time scheduled jobs and recurring jobs generated from cron expressions. Jobs should remain invisible to workers until their scheduled time arrives.\n\n**Deduplication** prevents the same job from being queued multiple times within a configurable time window. Each job submission includes an idempotency key, and the system silently ignores submissions with duplicate keys that haven't expired. This protects against client retry logic accidentally flooding the queue with identical work.\n\n| Queue Operation | Behavior | Guarantees |\n|----------------|----------|------------|\n| Enqueue | Accept job with priority and schedule time | Atomic insertion with deduplication check |\n| Dequeue | Return highest-priority ready job | Strict priority ordering among ready jobs |\n| Delayed Jobs | Hold jobs until scheduled time | Jobs become visible exactly at schedule time |\n| Deduplication | Reject jobs with duplicate idempotency keys | Configurable deduplication window (e.g., 1 hour) |\n\n**Multi-Worker Coordination** distributes job execution across a cluster of worker machines while preventing duplicate execution. The system must implement distributed locking so that exactly one worker can claim each job. Workers use the `claimJob()` operation to atomically reserve a job for execution, receiving a unique fencing token that prevents stale operations from affecting job state.\n\nThe coordination layer tracks worker health through periodic `heartbeat()` signals. When a worker fails to send heartbeats within the configured timeout, the system automatically reassigns that worker's in-progress jobs to healthy workers. This ensures jobs complete even when individual machines crash or become unresponsive.\n\n**Fault Tolerance** keeps the scheduler operating despite individual component failures. The system must detect worker failures through missed heartbeats and reassign their jobs to healthy workers. Job state persists in durable storage (Redis or similar) so that scheduler restarts don't lose pending work. The leader election mechanism ensures exactly one coordinator node manages job assignment even if multiple scheduler instances are running.\n\n> **Decision: At-Least-Once Job Execution**\n> - **Context**: Distributed systems can guarantee at-most-once or at-least-once execution, but not exactly-once without significant complexity\n> - **Options Considered**: At-most-once (jobs may be lost), at-least-once (jobs may run twice), exactly-once (complex)\n> - **Decision**: Provide at-least-once execution with idempotency key support\n> - **Rationale**: Most job types can be made idempotent, and losing jobs is worse than occasionally running them twice\n> - **Consequences**: Job implementations must handle duplicate execution gracefully, but no jobs are lost due to failures\n\n| Fault Tolerance Feature | Recovery Time | Detection Method |\n|------------------------|---------------|------------------|\n| Worker Failure | 30-60 seconds | Missed heartbeat timeout |\n| Coordinator Failure | 10-30 seconds | Leader election timeout |\n| Storage Failure | Manual intervention | Connection errors and timeouts |\n| Network Partition | Variable | Split-brain detection via consensus |\n\n### Non-Functional Goals\n\nThe non-functional goals establish performance, scalability, and reliability targets that make the scheduler suitable for production-like workloads while remaining implementable as a learning project.\n\n**Performance Targets** ensure the scheduler can handle realistic workloads without becoming a bottleneck. The system should support at least 1,000 jobs per minute throughput for job submissions and completions. Cron expression parsing should complete in under 1 millisecond per expression. Job queue operations (enqueue/dequeue) should complete in under 10 milliseconds at the 95th percentile when the queue contains up to 10,000 pending jobs.\n\n**Scalability Requirements** allow the system to grow with organizational needs. The scheduler must support at least 10 concurrent worker nodes without performance degradation. The job queue should handle up to 100,000 pending jobs while maintaining sub-second dequeue times. Adding new workers should be as simple as starting a new process with the coordinator's address.\n\n| Scalability Dimension | Target | Measurement Method |\n|--------------------|---------|-------------------|\n| Concurrent Workers | 10-50 nodes | Worker registration count |\n| Pending Jobs | 100,000 jobs | Queue depth metrics |\n| Job Throughput | 1,000 jobs/minute | Completed jobs per time window |\n| Cron Parsing | <1ms per expression | Microbenchmark timing |\n| Queue Operations | <10ms p95 latency | Operation timing histograms |\n\n**Reliability Standards** ensure the scheduler operates dependably in production environments. The system should achieve 99.9% uptime, meaning no more than 8.76 hours of downtime per year. No jobs should be lost due to single-point failures like individual worker crashes or temporary network partitions. The system should gracefully degrade by continuing to execute jobs even if some workers become unavailable.\n\n**Resource Efficiency** keeps the scheduler lightweight enough to run alongside other services. Memory usage should remain under 512 MB for a coordinator managing 10,000 jobs and 20 workers. CPU usage should stay under 25% on a modest server (2-4 cores) during normal operations. Network bandwidth should be minimal, with heartbeats and coordination messages consuming less than 1 MB/minute per worker.\n\n> The key insight for non-functional goals is that they must be measurable and achievable within the project constraints. Setting targets like \"unlimited scalability\" or \"microsecond latency\" would make the project impossible to complete, while setting no targets at all would result in a system that doesn't work well enough to demonstrate the concepts effectively.\n\n**Operational Simplicity** ensures the scheduler can be deployed and maintained without extensive infrastructure. The system should start with a single configuration file and require no external dependencies beyond Redis for job storage. Logs should provide enough information to diagnose common problems without requiring specialized monitoring tools. The entire system should be deployable on a developer's laptop for testing and development.\n\n### Explicit Non-Goals\n\nThe non-goals establish firm boundaries on what this scheduler will NOT include, preventing scope creep while acknowledging that these features exist in enterprise scheduling systems.\n\n**Job Dependencies and Workflows** are explicitly excluded because they add significant complexity to both the data model and execution engine. Features like \"run Job B only after Job A completes successfully\" or \"run these five jobs in parallel, then run the final job\" require dependency graph resolution, deadlock detection, and complex state management. While valuable in production systems, these features would triple the implementation effort without providing proportional learning value about the core distributed systems concepts.\n\n**Resource-Aware Scheduling** that considers CPU, memory, or disk constraints is not included. The scheduler treats all jobs as equivalent resource consumers and doesn't consider whether a worker has sufficient capacity for a specific job type. Real production schedulers often include features like \"only run this job on machines with 8+ GB RAM\" or \"don't run more than 2 CPU-intensive jobs per worker simultaneously.\" These features require resource modeling, capacity planning, and bin-packing algorithms that would shift focus away from distributed coordination.\n\n| Excluded Feature Category | Specific Examples | Why Excluded |\n|---------------------------|------------------|--------------|\n| Job Dependencies | Workflow orchestration, dependency graphs | Complex state management distracts from core distributed systems learning |\n| Resource Constraints | Memory limits, CPU quotas, disk space checks | Requires sophisticated resource modeling beyond project scope |\n| Advanced Security | Authentication, authorization, job isolation | Security implementation would dominate development time |\n| Multi-Datacenter | Cross-region replication, geo-distributed coordination | Network complexity exceeds single-datacenter learning goals |\n| Job Artifacts | Input/output file management, result storage | File handling distracts from scheduling and coordination logic |\n\n**Authentication and Authorization** are omitted to focus on the distributed systems challenges rather than security implementation. The scheduler assumes all job submissions are authorized and all workers are trusted. Production systems would include features like API keys, role-based access control, and job owner isolation, but implementing these would consume significant development time without advancing understanding of distributed coordination, consensus algorithms, or failure recovery.\n\n**Advanced Monitoring and Metrics** beyond basic logging are not included. While production schedulers provide detailed dashboards showing job success rates, worker utilization, queue depth over time, and performance histograms, building these interfaces would shift effort away from the core distributed systems implementation. The system will log enough information for debugging, but won't include web dashboards or metrics exporters.\n\n> **Decision: Focus on Core Distributed Systems Concepts**\n> - **Context**: Distributed job schedulers in production include dozens of enterprise features for security, monitoring, resource management, and workflow orchestration\n> - **Options Considered**: Include subset of enterprise features, build minimal viable scheduler, create full-featured system\n> - **Decision**: Implement only features essential for demonstrating distributed coordination, consensus, and fault tolerance\n> - **Rationale**: The learning value comes from solving distributed systems problems, not from building user interfaces or security layers\n> - **Consequences**: The resulting scheduler demonstrates core concepts clearly but would need additional features for production use\n\n**Multi-Datacenter Deployment** and geographic distribution are explicitly out of scope. The scheduler assumes all components (coordinators, workers, and storage) operate within a single datacenter with reliable, low-latency network connectivity. Cross-datacenter replication, split-brain resolution across WAN links, and geographic failover introduce network partition scenarios that are beyond the project's educational goals.\n\n**Job Result Storage and Artifact Management** are not included. The scheduler tracks whether jobs completed successfully or failed, but doesn't store job output, intermediate files, or result artifacts. Workers report completion status through `reportCompletion()`, but any job-specific data management is the responsibility of the job implementation itself, not the scheduler infrastructure.\n\n**Dynamic Job Modification** capabilities like updating cron expressions for running schedules, changing job priorities after submission, or canceling queued jobs are omitted. Once a job enters the system, it follows its original schedule and priority until completion. While useful for operational flexibility, these features require complex state transitions and conflict resolution that would complicate the core coordination logic.\n\nThe explicit non-goals serve as a contract with implementers: these boundaries won't expand during development. When facing implementation challenges, the solution should work within these constraints rather than adding excluded features as \"quick fixes.\" This discipline ensures the project remains focused on its educational objectives while building a system sophisticated enough to demonstrate real distributed systems principles.\n\n### Implementation Guidance\n\nThis section provides practical direction for implementing the functional and non-functional goals using Go as the primary development language.\n\n**Technology Recommendations Table:**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Job Queue Storage | Redis with sorted sets | Redis with custom Lua scripts |\n| Worker Coordination | etcd for leader election | Custom Raft implementation |\n| Cron Parsing | `github.com/robfig/cron/v3` | Custom parser with extended syntax |\n| Configuration | YAML files with `gopkg.in/yaml.v3` | etcd-based dynamic configuration |\n| Logging | Standard library `log/slog` | Structured logging with `logrus` |\n| HTTP API | `net/http` with `gorilla/mux` | gRPC with Protocol Buffers |\n| Metrics | Basic counters in memory | Prometheus metrics export |\n| Testing | Standard `testing` package | Testcontainers for integration tests |\n\n**Recommended Project Structure:**\n\n```\ndistributed-job-scheduler/\n├── cmd/\n│   ├── coordinator/\n│   │   └── main.go              ← coordinator service entry point\n│   └── worker/\n│       └── main.go              ← worker service entry point\n├── internal/\n│   ├── coordinator/\n│   │   ├── coordinator.go       ← leader election and job assignment\n│   │   ├── coordinator_test.go\n│   │   └── heartbeat.go         ← worker health tracking\n│   ├── cron/\n│   │   ├── parser.go           ← cron expression parsing (Milestone 1)\n│   │   ├── parser_test.go\n│   │   └── schedule.go         ← next execution time calculation\n│   ├── queue/\n│   │   ├── priority_queue.go   ← job priority queue (Milestone 2)\n│   │   ├── priority_queue_test.go\n│   │   ├── deduplication.go    ← idempotency key handling\n│   │   └── delayed_jobs.go     ← scheduled job visibility\n│   ├── worker/\n│   │   ├── worker.go           ← job execution and heartbeat (Milestone 3)\n│   │   ├── worker_test.go\n│   │   └── job_executor.go     ← job execution engine\n│   └── models/\n│       ├── job.go              ← Job, Worker data structures\n│       ├── cron.go             ← CronExpression struct\n│       └── constants.go        ← PENDING, EXECUTING, etc.\n├── pkg/\n│   ├── api/\n│   │   └── client.go           ← HTTP client for job submission\n│   └── storage/\n│       └── redis.go            ← Redis connection and operations\n├── configs/\n│   ├── coordinator.yaml        ← coordinator configuration\n│   └── worker.yaml             ← worker configuration\n├── scripts/\n│   ├── start-coordinator.sh    ← development startup scripts\n│   └── start-worker.sh\n├── docker/\n│   ├── docker-compose.yml      ← local development environment\n│   └── Dockerfile              ← service container image\n└── docs/\n    └── api.md                  ← HTTP API documentation\n```\n\n**Core Data Structures (Complete Definitions):**\n\n```go\npackage models\n\nimport (\n    \"time\"\n)\n\n// Job represents a scheduled task with priority and execution metadata\ntype Job struct {\n    ID              string            `json:\"id\" redis:\"id\"`\n    Name            string            `json:\"name\" redis:\"name\"`\n    CronExpression  string            `json:\"cron_expression\" redis:\"cron_expression\"`\n    Priority        int               `json:\"priority\" redis:\"priority\"`\n    Payload         map[string]string `json:\"payload\" redis:\"payload\"`\n    IdempotencyKey  string            `json:\"idempotency_key\" redis:\"idempotency_key\"`\n    State           JobState          `json:\"state\" redis:\"state\"`\n    WorkerID        string            `json:\"worker_id,omitempty\" redis:\"worker_id\"`\n    FencingToken    string            `json:\"fencing_token,omitempty\" redis:\"fencing_token\"`\n    ScheduledAt     time.Time         `json:\"scheduled_at\" redis:\"scheduled_at\"`\n    ClaimedAt       *time.Time        `json:\"claimed_at,omitempty\" redis:\"claimed_at\"`\n    CompletedAt     *time.Time        `json:\"completed_at,omitempty\" redis:\"completed_at\"`\n    RetryCount      int               `json:\"retry_count\" redis:\"retry_count\"`\n    MaxRetries      int               `json:\"max_retries\" redis:\"max_retries\"`\n    CreatedAt       time.Time         `json:\"created_at\" redis:\"created_at\"`\n    UpdatedAt       time.Time         `json:\"updated_at\" redis:\"updated_at\"`\n}\n\n// Worker represents a node that executes jobs with capacity tracking\ntype Worker struct {\n    ID              string            `json:\"id\" redis:\"id\"`\n    Address         string            `json:\"address\" redis:\"address\"`\n    Capacity        int               `json:\"capacity\" redis:\"capacity\"`\n    CurrentJobs     int               `json:\"current_jobs\" redis:\"current_jobs\"`\n    Capabilities    []string          `json:\"capabilities\" redis:\"capabilities\"`\n    LastHeartbeat   time.Time         `json:\"last_heartbeat\" redis:\"last_heartbeat\"`\n    State           WorkerState       `json:\"state\" redis:\"state\"`\n    StartedAt       time.Time         `json:\"started_at\" redis:\"started_at\"`\n    Metadata        map[string]string `json:\"metadata\" redis:\"metadata\"`\n}\n\n// CronExpression holds parsed cron schedule with next execution calculation\ntype CronExpression struct {\n    Original    string        `json:\"original\"`\n    Minutes     []int         `json:\"minutes\"`     // 0-59\n    Hours       []int         `json:\"hours\"`       // 0-23\n    DaysOfMonth []int         `json:\"days_month\"`  // 1-31\n    Months      []int         `json:\"months\"`      // 1-12\n    DaysOfWeek  []int         `json:\"days_week\"`   // 0-6 (Sunday=0)\n    Timezone    *time.Location `json:\"timezone\"`\n}\n\n// JobState constants for job lifecycle\ntype JobState string\n\nconst (\n    PENDING   JobState = \"PENDING\"   // job queued, waiting for worker\n    CLAIMED   JobState = \"CLAIMED\"   // job assigned to worker, not yet started\n    EXECUTING JobState = \"EXECUTING\" // job currently running on worker\n    COMPLETED JobState = \"COMPLETED\" // job finished successfully\n    FAILED    JobState = \"FAILED\"    // job failed after all retries\n)\n\n// WorkerState constants for worker lifecycle\ntype WorkerState string\n\nconst (\n    AVAILABLE   WorkerState = \"AVAILABLE\"   // worker ready to accept jobs\n    BUSY        WorkerState = \"BUSY\"        // worker at capacity\n    UNAVAILABLE WorkerState = \"UNAVAILABLE\" // worker failed or shutdown\n)\n```\n\n**Configuration Management (Complete Implementation):**\n\n```go\npackage config\n\nimport (\n    \"fmt\"\n    \"gopkg.in/yaml.v3\"\n    \"os\"\n    \"time\"\n)\n\ntype CoordinatorConfig struct {\n    Server struct {\n        Port         int           `yaml:\"port\"`\n        ReadTimeout  time.Duration `yaml:\"read_timeout\"`\n        WriteTimeout time.Duration `yaml:\"write_timeout\"`\n    } `yaml:\"server\"`\n    \n    Redis struct {\n        Address  string `yaml:\"address\"`\n        Password string `yaml:\"password\"`\n        Database int    `yaml:\"database\"`\n    } `yaml:\"redis\"`\n    \n    Coordinator struct {\n        HeartbeatTimeout time.Duration `yaml:\"heartbeat_timeout\"`\n        ElectionTimeout  time.Duration `yaml:\"election_timeout\"`\n        JobScanInterval  time.Duration `yaml:\"job_scan_interval\"`\n    } `yaml:\"coordinator\"`\n}\n\ntype WorkerConfig struct {\n    Worker struct {\n        ID           string        `yaml:\"id\"`\n        Capacity     int           `yaml:\"capacity\"`\n        Capabilities []string      `yaml:\"capabilities\"`\n        HeartbeatInterval time.Duration `yaml:\"heartbeat_interval\"`\n    } `yaml:\"worker\"`\n    \n    Coordinator struct {\n        Address string `yaml:\"address\"`\n    } `yaml:\"coordinator\"`\n    \n    Redis struct {\n        Address  string `yaml:\"address\"`\n        Password string `yaml:\"password\"`\n        Database int    `yaml:\"database\"`\n    } `yaml:\"redis\"`\n}\n\nfunc LoadCoordinatorConfig(path string) (*CoordinatorConfig, error) {\n    data, err := os.ReadFile(path)\n    if err != nil {\n        return nil, fmt.Errorf(\"reading config file: %w\", err)\n    }\n    \n    var config CoordinatorConfig\n    if err := yaml.Unmarshal(data, &config); err != nil {\n        return nil, fmt.Errorf(\"parsing config YAML: %w\", err)\n    }\n    \n    return &config, nil\n}\n\nfunc LoadWorkerConfig(path string) (*WorkerConfig, error) {\n    data, err := os.ReadFile(path)\n    if err != nil {\n        return nil, fmt.Errorf(\"reading config file: %w\", err)\n    }\n    \n    var config WorkerConfig\n    if err := yaml.Unmarshal(data, &config); err != nil {\n        return nil, fmt.Errorf(\"parsing config YAML: %w\", err)\n    }\n    \n    return &config, nil\n}\n```\n\n**HTTP API Infrastructure (Complete Implementation):**\n\n```go\npackage api\n\nimport (\n    \"encoding/json\"\n    \"net/http\"\n    \"time\"\n    \"github.com/gorilla/mux\"\n    \"distributed-job-scheduler/internal/models\"\n)\n\ntype JobSubmissionRequest struct {\n    Name           string            `json:\"name\"`\n    CronExpression string            `json:\"cron_expression\"`\n    Priority       int               `json:\"priority\"`\n    Payload        map[string]string `json:\"payload\"`\n    IdempotencyKey string            `json:\"idempotency_key\"`\n    MaxRetries     int               `json:\"max_retries\"`\n}\n\ntype JobSubmissionResponse struct {\n    JobID     string    `json:\"job_id\"`\n    Status    string    `json:\"status\"`\n    NextRun   time.Time `json:\"next_run,omitempty\"`\n    Message   string    `json:\"message,omitempty\"`\n}\n\ntype ErrorResponse struct {\n    Error   string `json:\"error\"`\n    Code    string `json:\"code,omitempty\"`\n    Details string `json:\"details,omitempty\"`\n}\n\n// JobSubmissionHandler handles HTTP requests for job submission\nfunc JobSubmissionHandler(jobQueue JobQueue) http.HandlerFunc {\n    return func(w http.ResponseWriter, r *http.Request) {\n        // TODO: Parse JSON request body into JobSubmissionRequest\n        // TODO: Validate cron expression using cron parser\n        // TODO: Generate unique job ID and fencing token\n        // TODO: Create Job struct with PENDING state\n        // TODO: Submit job to priority queue with deduplication check\n        // TODO: Calculate next execution time from cron expression\n        // TODO: Return JobSubmissionResponse with job details\n        // TODO: Handle errors with appropriate HTTP status codes\n    }\n}\n\n// WorkerHeartbeatHandler accepts heartbeat signals from workers\nfunc WorkerHeartbeatHandler(coordinator Coordinator) http.HandlerFunc {\n    return func(w http.ResponseWriter, r *http.Request) {\n        // TODO: Extract worker ID from URL path or headers\n        // TODO: Parse heartbeat payload with current job count and capabilities\n        // TODO: Update worker's last heartbeat timestamp in coordination store\n        // TODO: Return current job assignments or coordination commands\n        // TODO: Handle new worker registration if ID not found\n    }\n}\n\n// SetupRoutes configures HTTP routes for the coordinator API\nfunc SetupRoutes(jobQueue JobQueue, coordinator Coordinator) *mux.Router {\n    r := mux.NewRouter()\n    \n    // Job management endpoints\n    r.HandleFunc(\"/api/v1/jobs\", JobSubmissionHandler(jobQueue)).Methods(\"POST\")\n    r.HandleFunc(\"/api/v1/jobs\", ListJobsHandler(jobQueue)).Methods(\"GET\")\n    r.HandleFunc(\"/api/v1/jobs/{id}\", GetJobHandler(jobQueue)).Methods(\"GET\")\n    \n    // Worker coordination endpoints\n    r.HandleFunc(\"/api/v1/workers/heartbeat\", WorkerHeartbeatHandler(coordinator)).Methods(\"POST\")\n    r.HandleFunc(\"/api/v1/workers\", ListWorkersHandler(coordinator)).Methods(\"GET\")\n    \n    return r\n}\n\n// Helper function for JSON responses\nfunc WriteJSONResponse(w http.ResponseWriter, status int, data interface{}) {\n    w.Header().Set(\"Content-Type\", \"application/json\")\n    w.WriteHeader(status)\n    json.NewEncoder(w).Encode(data)\n}\n\n// Helper function for error responses\nfunc WriteErrorResponse(w http.ResponseWriter, status int, message string) {\n    response := ErrorResponse{\n        Error: message,\n        Code:  http.StatusText(status),\n    }\n    WriteJSONResponse(w, status, response)\n}\n```\n\n**Redis Storage Interface (Complete Implementation):**\n\n```go\npackage storage\n\nimport (\n    \"context\"\n    \"encoding/json\"\n    \"fmt\"\n    \"time\"\n    \"github.com/go-redis/redis/v8\"\n    \"distributed-job-scheduler/internal/models\"\n)\n\ntype RedisClient struct {\n    client *redis.Client\n    ctx    context.Context\n}\n\nfunc NewRedisClient(addr, password string, db int) *RedisClient {\n    rdb := redis.NewClient(&redis.Options{\n        Addr:     addr,\n        Password: password,\n        DB:       db,\n    })\n    \n    return &RedisClient{\n        client: rdb,\n        ctx:    context.Background(),\n    }\n}\n\n// Job storage operations\nfunc (r *RedisClient) StoreJob(job *models.Job) error {\n    jobData, err := json.Marshal(job)\n    if err != nil {\n        return fmt.Errorf(\"marshaling job: %w\", err)\n    }\n    \n    // Store job data\n    jobKey := fmt.Sprintf(\"job:%s\", job.ID)\n    if err := r.client.Set(r.ctx, jobKey, jobData, 0).Err(); err != nil {\n        return fmt.Errorf(\"storing job data: %w\", err)\n    }\n    \n    // Add to priority queue with score = (priority << 32) | scheduled_timestamp\n    score := float64(job.Priority<<32) + float64(job.ScheduledAt.Unix())\n    queueKey := \"job_queue\"\n    if err := r.client.ZAdd(r.ctx, queueKey, &redis.Z{\n        Score:  score,\n        Member: job.ID,\n    }).Err(); err != nil {\n        return fmt.Errorf(\"adding to priority queue: %w\", err)\n    }\n    \n    return nil\n}\n\nfunc (r *RedisClient) GetJob(jobID string) (*models.Job, error) {\n    jobKey := fmt.Sprintf(\"job:%s\", jobID)\n    data, err := r.client.Get(r.ctx, jobKey).Result()\n    if err != nil {\n        return nil, fmt.Errorf(\"getting job data: %w\", err)\n    }\n    \n    var job models.Job\n    if err := json.Unmarshal([]byte(data), &job); err != nil {\n        return nil, fmt.Errorf(\"unmarshaling job: %w\", err)\n    }\n    \n    return &job, nil\n}\n\n// Worker registration and heartbeat operations\nfunc (r *RedisClient) RegisterWorker(worker *models.Worker) error {\n    workerData, err := json.Marshal(worker)\n    if err != nil {\n        return fmt.Errorf(\"marshaling worker: %w\", err)\n    }\n    \n    workerKey := fmt.Sprintf(\"worker:%s\", worker.ID)\n    if err := r.client.Set(r.ctx, workerKey, workerData, 0).Err(); err != nil {\n        return fmt.Errorf(\"storing worker data: %w\", err)\n    }\n    \n    // Add to active workers set\n    activeWorkersKey := \"active_workers\"\n    if err := r.client.SAdd(r.ctx, activeWorkersKey, worker.ID).Err(); err != nil {\n        return fmt.Errorf(\"adding to active workers: %w\", err)\n    }\n    \n    return nil\n}\n\nfunc (r *RedisClient) UpdateWorkerHeartbeat(workerID string, timestamp time.Time) error {\n    workerKey := fmt.Sprintf(\"worker:%s\", workerID)\n    \n    // Update heartbeat timestamp using hash field\n    if err := r.client.HSet(r.ctx, workerKey, \"last_heartbeat\", timestamp.Unix()).Err(); err != nil {\n        return fmt.Errorf(\"updating heartbeat: %w\", err)\n    }\n    \n    return nil\n}\n\n// Atomic job claiming operation using Lua script\nconst claimJobScript = `\nlocal job_id = ARGV[1]\nlocal worker_id = ARGV[2]\nlocal fencing_token = ARGV[3]\nlocal current_time = ARGV[4]\n\nlocal job_key = \"job:\" .. job_id\nlocal job_data = redis.call(\"GET\", job_key)\n\nif not job_data then\n    return {err = \"Job not found\"}\nend\n\nlocal job = cjson.decode(job_data)\nif job.state ~= \"PENDING\" then\n    return {err = \"Job not in PENDING state\"}\nend\n\n-- Update job state to CLAIMED\njob.state = \"CLAIMED\"\njob.worker_id = worker_id\njob.fencing_token = fencing_token\njob.claimed_at = current_time\n\nlocal updated_data = cjson.encode(job)\nredis.call(\"SET\", job_key, updated_data)\n\n-- Remove from general queue, add to worker's queue\nredis.call(\"ZREM\", \"job_queue\", job_id)\nredis.call(\"LPUSH\", \"worker_jobs:\" .. worker_id, job_id)\n\nreturn {ok = \"Job claimed successfully\"}\n`\n\nfunc (r *RedisClient) ClaimJob(jobID, workerID, fencingToken string) error {\n    currentTime := time.Now().Unix()\n    \n    result := r.client.Eval(r.ctx, claimJobScript, []string{}, \n        jobID, workerID, fencingToken, currentTime)\n    \n    if result.Err() != nil {\n        return fmt.Errorf(\"claiming job: %w\", result.Err())\n    }\n    \n    return nil\n}\n```\n\n**Milestone Verification Checkpoints:**\n\nAfter implementing each milestone, verify correct behavior using these specific tests:\n\n**Milestone 1 Checkpoint - Cron Parser:**\n```bash\n# Run cron parser tests\ngo test ./internal/cron/... -v\n\n# Manual verification\ngo run cmd/test-cron/main.go \"0 9 * * 1-5\"\n# Expected output: Next execution at 2024-01-08 09:00:00 UTC (next weekday at 9 AM)\n\ngo run cmd/test-cron/main.go \"*/15 * * * *\"\n# Expected output: Next execution within 15 minutes of current time\n```\n\n**Milestone 2 Checkpoint - Priority Queue:**\n```bash\n# Run queue tests\ngo test ./internal/queue/... -v\n\n# Manual verification with Redis CLI\nredis-cli ZADD test_queue 100 job1 200 job2 150 job3\nredis-cli ZREVRANGE test_queue 0 -1 WITHSCORES\n# Expected: job2 (score 200), job3 (score 150), job1 (score 100)\n```\n\n**Milestone 3 Checkpoint - Worker Coordination:**\n```bash\n# Start coordinator\ngo run cmd/coordinator/main.go -config configs/coordinator.yaml\n\n# Start worker in another terminal\ngo run cmd/worker/main.go -config configs/worker.yaml\n\n# Submit test job via HTTP\ncurl -X POST http://localhost:8080/api/v1/jobs \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"name\":\"test\",\"cron_expression\":\"* * * * *\",\"priority\":100,\"payload\":{\"command\":\"echo hello\"}}'\n\n# Expected: Job appears in worker logs within 60 seconds\n```\n\n**Language-Specific Implementation Tips:**\n\n1. **Time Handling**: Use `time.Time` in UTC for all internal calculations, convert to local timezone only for display\n2. **Concurrency**: Use `sync.RWMutex` for protecting shared data structures like worker registry\n3. **Context Cancellation**: Pass `context.Context` through all long-running operations for graceful shutdown\n4. **Error Wrapping**: Use `fmt.Errorf(\"operation: %w\", err)` for error context without losing original error\n5. **JSON Tags**: Include both `json` and `redis` struct tags for serialization to different stores\n6. **Configuration**: Use `gopkg.in/yaml.v3` for human-readable config files\n7. **Testing**: Use `testcontainers-go` for integration tests that need real Redis instances\n8. **Logging**: Use structured logging with fields: `slog.Info(\"job claimed\", \"jobID\", job.ID, \"workerID\", worker.ID)`\n\n\n## High-Level Architecture\n\n> **Milestone(s):** This section provides the architectural foundation for all three milestones by establishing the core components and their interactions that enable cron expression parsing (Milestone 1), priority job queuing (Milestone 2), and worker coordination (Milestone 3).\n\nThe distributed job scheduler architecture can be understood through a mental model of a sophisticated **orchestra with multiple conductors and musicians**. Just as an orchestra needs sheet music (cron expressions), a conductor to coordinate timing (scheduler service), musicians with different capabilities (workers), and a system to distribute music sheets fairly (job queue), our distributed scheduler coordinates the execution of jobs across multiple machines while maintaining consistency and fault tolerance.\n\nThe architecture consists of four primary layers that work together to provide reliable, distributed job scheduling. The **coordination layer** acts as the nervous system, managing leader election and maintaining cluster state. The **scheduler service** serves as the brain, parsing cron expressions and making job assignment decisions. The **job queue** functions as the memory, storing pending jobs with priorities and timing information. Finally, the **worker pool** represents the muscles, executing the actual job payloads while reporting status back to the coordination layer.\n\n### System Components\n\nThe distributed job scheduler is composed of several core components, each with distinct responsibilities that collectively enable fault-tolerant job execution across a cluster of machines.\n\n![System Architecture Overview](./diagrams/system-architecture.svg)\n\n#### Scheduler Service Components\n\nThe **Scheduler Service** acts as the central orchestrator, responsible for transforming cron expressions into executable jobs and coordinating their distribution to workers. This service embodies the \"conductor\" role in our orchestra analogy, ensuring that each job plays at precisely the right time.\n\n| Component | Responsibility | Key Operations | Failure Impact |\n|-----------|---------------|----------------|-----------------|\n| Cron Engine | Parse cron expressions and calculate next execution times | `parseExpression()`, `calculateNext()`, `validateTimezone()` | Jobs stop being scheduled until recovery |\n| Job Scheduler | Create job instances from recurring schedules | `createJobFromSchedule()`, `applyPriority()`, `setIdempotencyKey()` | New job instances not created, existing jobs continue |\n| Assignment Manager | Distribute jobs to available workers based on capacity | `selectWorker()`, `assignJob()`, `trackAssignments()` | Jobs queue up but don't execute until recovery |\n| Heartbeat Monitor | Track worker health and detect failures | `processHeartbeat()`, `detectFailures()`, `triggerRecovery()` | Failed workers not detected, jobs may be stuck |\n\nThe Scheduler Service maintains several critical data structures to coordinate job execution:\n\n| Data Structure | Purpose | Key Fields | Update Frequency |\n|----------------|---------|------------|------------------|\n| Active Schedules Map | Track all registered cron schedules | `scheduleID`, `cronExpression`, `nextRun`, `lastRun` | Every job creation |\n| Worker Registry | Maintain current worker status and capacity | `workerID`, `capacity`, `currentLoad`, `capabilities` | Every heartbeat (30s) |\n| Job Assignments | Track which worker owns which job | `jobID`, `workerID`, `claimedAt`, `fencingToken` | Every job claim/completion |\n| Failed Workers Set | Workers pending cleanup and job recovery | `workerID`, `failedAt`, `assignedJobs` | On heartbeat timeout |\n\n> **Design Insight:** The Scheduler Service is designed to be stateless except for in-memory caches. All persistent state lives in the coordination layer (etcd) or job queue (Redis), allowing multiple scheduler instances to run simultaneously with leader election determining which instance actively makes scheduling decisions.\n\n#### Job Queue Infrastructure\n\nThe **Job Queue** serves as the system's durable memory, implementing a sophisticated priority queue with delayed execution capabilities. Think of it as a **hospital emergency room triage system** - jobs arrive with different priority levels, some must wait until a specific time (delayed execution), and the system ensures the most critical jobs are handled first while preventing duplicate treatment of the same patient.\n\n| Queue Component | Purpose | Implementation | Scalability Limit |\n|-----------------|---------|----------------|-------------------|\n| Priority Heap | Order jobs by priority and scheduled time | Redis sorted sets with score-based ordering | ~10M jobs per Redis instance |\n| Delayed Job Timer | Hold jobs until their execution time arrives | Redis key expiration notifications | Limited by Redis memory |\n| Deduplication Store | Prevent duplicate job submissions | Redis hash with idempotency keys | ~100M unique keys |\n| Dead Letter Queue | Store permanently failed jobs for analysis | Separate Redis list with TTL | Manual cleanup required |\n\nThe queue implements several sophisticated algorithms to ensure fair job distribution:\n\n1. **Priority Resolution**: When multiple jobs have the same priority level, the queue uses scheduled time as a secondary sort key, ensuring first-in-first-out behavior within priority bands.\n\n2. **Delayed Visibility**: Jobs with future scheduled times are stored in a separate \"delayed\" namespace and moved to the active queue through Redis key expiration events, providing precise timing control.\n\n3. **Atomic Job Claims**: Workers claim jobs using Redis Lua scripts that atomically check job availability, update job state to `CLAIMED`, and set a fencing token to prevent duplicate processing.\n\n4. **Deduplication Windows**: The system maintains idempotency keys for a configurable time window (default 24 hours), allowing clients to safely retry job submissions without creating duplicates.\n\n> **Architecture Decision: Redis vs Database for Job Queue**\n> - **Context**: Need to choose storage backend for job queue with priority ordering and atomic operations\n> - **Options Considered**: \n>   - PostgreSQL with indexed priority columns\n>   - Redis with sorted sets and Lua scripts  \n>   - In-memory Go data structures with clustering\n> - **Decision**: Redis with sorted sets\n> - **Rationale**: Redis sorted sets provide O(log N) priority ordering natively, Lua scripts enable atomic multi-operation commands, and pub/sub supports real-time job notifications. PostgreSQL would require complex locking for atomic job claims, while in-memory structures lose durability.\n> - **Consequences**: Introduces Redis as a dependency but provides superior performance for queue operations. Limits job metadata size due to Redis memory constraints.\n\n#### Worker Pool Management\n\nThe **Worker Pool** represents the distributed execution layer, where actual job processing occurs. Workers function like **specialized craftspeople in a guild** - each worker registers their capabilities, maintains their tools (execution environment), and communicates regularly with the guild master (coordinator) about their availability and current projects.\n\nWorkers operate through a well-defined lifecycle that ensures reliable job execution:\n\n| Worker State | Description | Valid Transitions | Trigger Conditions |\n|--------------|-------------|-------------------|-------------------|\n| `REGISTERING` | Initial state during startup | → `AVAILABLE`, → `UNAVAILABLE` | Successful/failed coordinator registration |\n| `AVAILABLE` | Ready to accept new jobs | → `BUSY`, → `UNAVAILABLE` | Job assignment or failure detection |\n| `BUSY` | At capacity, cannot accept more jobs | → `AVAILABLE`, → `UNAVAILABLE` | Job completion or failure |\n| `UNAVAILABLE` | Failed or shutting down | → `AVAILABLE` (recovery only) | Heartbeat timeout or explicit shutdown |\n\nEach worker maintains comprehensive metadata to support intelligent job assignment:\n\n| Worker Metadata | Type | Purpose | Update Trigger |\n|-----------------|------|---------|----------------|\n| `ID` | string | Unique worker identifier across cluster | At registration |\n| `Address` | string | Network endpoint for direct communication | At registration |\n| `Capacity` | int | Maximum concurrent jobs this worker can handle | At registration, capacity changes |\n| `CurrentJobs` | int | Number of jobs currently executing | Job claim/completion |\n| `Capabilities` | []string | Job types this worker can execute | At registration |\n| `LastHeartbeat` | time.Time | Most recent health check timestamp | Every heartbeat interval |\n| `Metadata` | map[string]string | Custom worker attributes for job matching | At registration, periodic updates |\n\nWorkers implement a robust heartbeat mechanism that serves multiple purposes beyond simple health checking:\n\n1. **Capacity Reporting**: Each heartbeat includes current job count and available capacity, enabling intelligent load balancing.\n\n2. **Capability Updates**: Workers can dynamically advertise new capabilities or remove support for job types during runtime.\n\n3. **Graceful Shutdown Signaling**: Workers use heartbeat metadata to indicate planned shutdown, allowing coordinators to stop assigning new jobs while existing jobs complete.\n\n4. **Performance Metrics**: Heartbeats carry job execution statistics that help coordinators optimize future job assignments.\n\n> **Common Pitfall: Heartbeat Frequency vs Job Duration**\n> \n> ⚠️ **Pitfall: Setting heartbeat timeout shorter than maximum job duration**\n> \n> If heartbeat timeout is 60 seconds but jobs can run for 10 minutes, the coordinator will incorrectly mark workers as failed while they're executing long jobs. This causes job reassignment and potential duplicate execution.\n> \n> **Solution**: Set heartbeat timeout to at least 2x the maximum expected job duration, or implement job-specific timeout extensions where workers can request longer heartbeat intervals for long-running jobs.\n\n#### Coordination Layer Architecture\n\nThe **Coordination Layer** provides the distributed systems infrastructure that enables multiple scheduler instances and workers to operate as a unified cluster. This layer implements consensus protocols and distributed locking mechanisms that prevent the chaos that would result from multiple coordinators making conflicting decisions simultaneously.\n\nThe coordination layer is built around **etcd** as the primary consensus store, chosen for its strong consistency guarantees and proven reliability in production distributed systems:\n\n| Coordination Service | Purpose | Data Stored | Consistency Requirements |\n|---------------------|---------|-------------|-------------------------|\n| Leader Election | Ensure single active scheduler | Current leader ID, lease expiration | Strong consistency, linearizable reads |\n| Worker Discovery | Maintain cluster member registry | Worker metadata, health status | Eventually consistent |\n| Configuration Management | Distribute cluster-wide settings | Cron schedules, retry policies | Strong consistency for updates |\n| Distributed Locking | Coordinate job recovery operations | Lock owner, expiration time | Strong consistency, exclusive access |\n\nThe leader election algorithm follows a lease-based approach that prevents split-brain scenarios:\n\n1. **Candidate Announcement**: Scheduler instances announce candidacy by attempting to create a leader key in etcd with a TTL lease.\n\n2. **Lease Renewal**: The current leader continuously renews its lease every 10 seconds (with 30-second TTL) to maintain leadership.\n\n3. **Leadership Transfer**: When a leader fails to renew its lease, the key expires and other candidates immediately compete for leadership.\n\n4. **Graceful Handoff**: During planned shutdown, leaders can explicitly transfer leadership by deleting their key and allowing immediate re-election.\n\n> **Architecture Decision: etcd vs Consul vs Zookeeper for Coordination**\n> - **Context**: Need distributed coordination service for leader election and configuration management\n> - **Options Considered**:\n>   - etcd with Raft consensus\n>   - Consul with Raft consensus  \n>   - Apache Zookeeper with ZAB protocol\n> - **Decision**: etcd\n> - **Rationale**: etcd provides simpler HTTP/gRPC APIs compared to Zookeeper's complex protocol, has excellent Go client libraries, and offers strong consistency guarantees. Consul focuses more on service discovery and less on general-purpose coordination. etcd is proven in Kubernetes and other large-scale systems.\n> - **Consequences**: Requires etcd cluster deployment and management, but provides reliable foundation for all coordination needs with excellent operational tooling.\n\n### Deployment Model\n\nThe distributed job scheduler is designed for deployment across multiple machines in a cluster configuration, with each component type running on dedicated or shared infrastructure based on operational requirements and scale.\n\n#### Physical Deployment Topology\n\nThe recommended deployment follows a **three-tier architecture** that separates coordination, scheduling, and execution concerns while maintaining high availability and fault tolerance:\n\n| Tier | Components | Minimum Nodes | Recommended Sizing | Network Requirements |\n|------|------------|---------------|-------------------|---------------------|\n| Coordination Tier | etcd cluster, Redis cluster | 3 etcd, 3 Redis | 2 CPU, 4GB RAM per node | Low latency, high bandwidth between nodes |\n| Control Tier | Scheduler services | 2 active/standby | 4 CPU, 8GB RAM per node | Low latency to coordination tier |\n| Worker Tier | Worker processes | Variable | Based on job requirements | Moderate latency acceptable |\n\n**Coordination Tier Deployment**: The coordination tier forms the backbone of cluster consensus and must be deployed with careful attention to fault tolerance. The etcd cluster should span multiple availability zones with odd numbers of nodes (3 or 5) to maintain quorum during failures. Redis deployment can follow either clustering or master/replica patterns depending on job throughput requirements.\n\n**Control Tier Deployment**: Scheduler services run in active/standby configuration with leader election determining which instance actively schedules jobs. Multiple scheduler instances can run simultaneously, but only the elected leader performs job creation and assignment. This design allows for instant failover when the current leader fails.\n\n**Worker Tier Deployment**: Workers can be deployed flexibly based on job execution requirements. CPU-intensive jobs might require dedicated worker nodes, while I/O-bound jobs could share nodes with other services. Workers automatically register with the coordination tier on startup and can be added or removed dynamically without affecting system operation.\n\n#### Network Communication Patterns\n\nThe scheduler implements multiple communication patterns optimized for different types of cluster coordination:\n\n| Communication Type | Protocol | Frequency | Failure Handling |\n|-------------------|----------|-----------|------------------|\n| Scheduler → etcd | gRPC | Continuous (leader election) | Exponential backoff, multiple endpoints |\n| Scheduler → Redis | Redis protocol | Per job operation | Connection pooling, failover |\n| Worker → Scheduler | HTTP/JSON | 30-second heartbeats | Retry with jitter, graceful degradation |\n| Scheduler → Worker | HTTP/JSON | Job assignments only | Timeout and reassignment |\n\nThe system is designed to gracefully handle network partitions and intermittent connectivity issues. Workers continue executing assigned jobs even during network partitions, reporting completion when connectivity resumes. Schedulers detect worker failures through heartbeat timeouts and reassign jobs to healthy workers.\n\n#### Scaling and Resource Planning\n\nResource planning should consider both steady-state operation and peak load scenarios:\n\n**Scheduler Service Scaling**: A single scheduler instance can typically handle 10,000+ active schedules and coordinate 100+ workers. The primary bottleneck is usually etcd throughput for leader election heartbeats and worker registration updates.\n\n**Job Queue Scaling**: Redis memory requirements scale linearly with queue depth. Estimate 1KB per queued job for metadata, with additional memory for deduplication tracking. A single Redis instance can typically handle 100,000+ queued jobs.\n\n**Worker Scaling**: Workers scale horizontally without limits. Each worker's capacity depends on job types - CPU-bound jobs might allow 1-2 concurrent executions per core, while I/O-bound jobs could handle 10-20 concurrent executions.\n\n> **Deployment Insight**: The scheduler is designed as a \"shared-nothing\" architecture where all persistent state lives in external stores (etcd, Redis). This enables sophisticated deployment patterns like blue/green deployments, rolling updates, and cross-datacenter replication without complex data migration procedures.\n\n### Recommended File Structure\n\nThe Go module organization follows domain-driven design principles, separating concerns by functional area while maintaining clear dependency boundaries between components. This structure supports the three-milestone development approach by organizing code into coherent packages that can be developed and tested independently.\n\n```\ndistributed-job-scheduler/\n├── cmd/                              # Application entry points\n│   ├── scheduler/                    # Scheduler service binary\n│   │   └── main.go                   # Service initialization and configuration\n│   ├── worker/                       # Worker service binary  \n│   │   └── main.go                   # Worker startup and registration\n│   └── cli/                          # Administrative command-line tools\n│       └── main.go                   # Job submission, cluster status\n├── internal/                         # Private application packages\n│   ├── coordinator/                  # Milestone 3: Worker coordination\n│   │   ├── coordinator.go            # Leader election and job assignment\n│   │   ├── heartbeat.go             # Worker health monitoring\n│   │   ├── recovery.go              # Failed job recovery logic\n│   │   └── coordinator_test.go      # Coordination integration tests\n│   ├── cron/                        # Milestone 1: Cron expression parsing\n│   │   ├── parser.go                # Cron syntax parsing and validation\n│   │   ├── calculator.go            # Next execution time calculation\n│   │   ├── timezone.go              # Timezone handling and DST logic\n│   │   └── parser_test.go           # Comprehensive parsing test suite\n│   ├── queue/                       # Milestone 2: Priority job queue\n│   │   ├── priority_queue.go        # Priority-based job ordering\n│   │   ├── delayed_queue.go         # Scheduled job timing management\n│   │   ├── deduplication.go         # Idempotency key handling\n│   │   ├── redis_backend.go         # Redis storage implementation\n│   │   └── queue_test.go            # Queue operation tests\n│   ├── worker/                      # Worker execution engine\n│   │   ├── worker.go                # Job execution and lifecycle management\n│   │   ├── executor.go              # Job payload processing interface\n│   │   ├── heartbeat_client.go      # Coordinator communication\n│   │   └── worker_test.go           # Worker behavior tests\n│   ├── models/                      # Shared data structures\n│   │   ├── job.go                   # Job struct and state management\n│   │   ├── worker.go                # Worker struct and capability tracking\n│   │   ├── schedule.go              # Schedule definitions and metadata\n│   │   └── cron_expression.go       # Parsed cron expression representation\n│   └── storage/                     # Storage layer abstractions\n│       ├── etcd/                    # etcd coordination client\n│       │   ├── client.go            # Connection management and operations\n│       │   ├── leader_election.go   # Leader election implementation\n│       │   └── watcher.go           # Configuration change notifications\n│       ├── redis/                   # Redis queue client\n│       │   ├── client.go            # Connection pooling and commands\n│       │   ├── lua_scripts.go       # Atomic operation scripts\n│       │   └── pubsub.go            # Job notification handling\n│       └── interfaces.go            # Storage interface definitions\n├── pkg/                             # Public API packages\n│   ├── api/                         # HTTP REST API definitions\n│   │   ├── handlers/                # Request handlers for job management\n│   │   ├── middleware/              # Authentication, logging, metrics\n│   │   └── types/                   # API request/response structures\n│   ├── client/                      # Go client library for job submission\n│   │   ├── scheduler_client.go      # High-level client interface\n│   │   └── retry.go                 # Client-side retry and backoff\n│   └── metrics/                     # Observability and monitoring\n│       ├── prometheus.go            # Prometheus metrics integration\n│       └── tracing.go               # Distributed tracing support\n├── configs/                         # Configuration files and templates\n│   ├── scheduler.yaml               # Scheduler service configuration\n│   ├── worker.yaml                  # Worker service configuration\n│   └── docker-compose.yml           # Local development environment\n├── deployments/                     # Deployment manifests and scripts\n│   ├── kubernetes/                  # Kubernetes YAML manifests\n│   ├── docker/                      # Dockerfile for containerization\n│   └── terraform/                   # Infrastructure as code\n├── docs/                           # Additional documentation\n├── scripts/                        # Development and deployment scripts\n└── tests/                          # Integration and end-to-end tests\n    ├── integration/                # Cross-component integration tests\n    ├── e2e/                       # Full system end-to-end tests\n    └── fixtures/                  # Test data and mock configurations\n```\n\n#### Package Dependency Guidelines\n\nThe module structure enforces clear dependency boundaries that support milestone-based development:\n\n| Package | Can Import | Cannot Import | Reasoning |\n|---------|------------|---------------|-----------|\n| `internal/cron` | `internal/models` only | Other internal packages | Pure parsing logic, no external dependencies |\n| `internal/queue` | `internal/models`, `internal/storage/redis` | `internal/coordinator`, `internal/worker` | Queue operations independent of coordination |\n| `internal/coordinator` | All internal packages | None | Top-level orchestration needs access to all components |\n| `internal/worker` | `internal/models`, `pkg/client` | `internal/coordinator` | Workers should not directly depend on coordination logic |\n\n#### Development Workflow Organization\n\nThe file structure supports a natural development progression aligned with the project milestones:\n\n**Milestone 1 Development Focus**: Developers start with `internal/cron` and `internal/models/cron_expression.go`, building and testing cron parsing logic in isolation. The clear separation allows comprehensive testing without external dependencies.\n\n**Milestone 2 Development Focus**: Queue implementation in `internal/queue` can proceed independently, with Redis backend abstracted through interfaces in `internal/storage`. Mock implementations support testing without Redis infrastructure.\n\n**Milestone 3 Development Focus**: Coordinator logic in `internal/coordinator` integrates all previous components, with worker coordination building on established queue and parsing functionality.\n\n> **File Structure Insight**: The separation of `internal/` and `pkg/` follows Go conventions where `internal/` packages cannot be imported by external projects, while `pkg/` provides stable public APIs. This structure supports future open-source distribution while protecting internal implementation details from external dependencies.\n\nThe `cmd/` directory structure allows building separate binaries for different deployment scenarios - monolithic deployments can run scheduler and worker in the same process, while distributed deployments can deploy them separately. The shared `internal/` packages support both patterns without code duplication.\n\n### Implementation Guidance\n\nThis section provides concrete technology choices and starter code to help junior developers translate the architectural design into working Go code.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option | Trade-offs |\n|-----------|---------------|-----------------|------------|\n| HTTP Framework | `net/http` with `gorilla/mux` | `gin-gonic/gin` with middleware | Standard library vs performance optimized |\n| Configuration | `gopkg.in/yaml.v3` | `spf13/viper` with env overrides | Simple YAML vs dynamic configuration |\n| Logging | `log/slog` (Go 1.21+) | `sirupsen/logrus` with hooks | Built-in structured logging vs ecosystem |\n| Metrics | `prometheus/client_golang` | `prometheus/client_golang` + Grafana | Industry standard, no simpler alternative |\n| etcd Client | `go.etcd.io/etcd/clientv3` | Same with custom retry wrapper | Official client, wrap for convenience |\n| Redis Client | `go-redis/redis/v9` | `go-redis/redis/v9` with cluster | Mature library, cluster support when needed |\n| Testing | `testing` + `testify/assert` | `testify/suite` + `testcontainers` | Simple assertions vs full test suites |\n\n#### Infrastructure Starter Code\n\n**etcd Client Wrapper** (Complete implementation for coordination layer):\n\n```go\n// internal/storage/etcd/client.go\npackage etcd\n\nimport (\n    \"context\"\n    \"time\"\n    \n    clientv3 \"go.etcd.io/etcd/client/v3\"\n    \"go.etcd.io/etcd/client/v3/concurrency\"\n)\n\n// Client wraps etcd operations with retry logic and connection management\ntype Client struct {\n    client   *clientv3.Client\n    session  *concurrency.Session\n    timeout  time.Duration\n}\n\n// NewClient creates a new etcd client with recommended settings\nfunc NewClient(endpoints []string) (*Client, error) {\n    client, err := clientv3.New(clientv3.Config{\n        Endpoints:   endpoints,\n        DialTimeout: 5 * time.Second,\n    })\n    if err != nil {\n        return nil, err\n    }\n    \n    session, err := concurrency.NewSession(client, concurrency.WithTTL(30))\n    if err != nil {\n        client.Close()\n        return nil, err\n    }\n    \n    return &Client{\n        client:  client,\n        session: session,\n        timeout: 10 * time.Second,\n    }, nil\n}\n\n// Campaign attempts to become leader for the given election key\nfunc (c *Client) Campaign(ctx context.Context, election string) error {\n    e := concurrency.NewElection(c.session, election)\n    return e.Campaign(ctx, c.session.Lease())\n}\n\n// IsLeader checks if this client currently holds leadership\nfunc (c *Client) IsLeader(ctx context.Context, election string) (bool, error) {\n    e := concurrency.NewElection(c.session, election)\n    resp, err := e.Leader(ctx)\n    if err != nil {\n        return false, err\n    }\n    return string(resp.Kvs[0].Value) == string(c.session.Lease()), nil\n}\n\n// Close releases all resources\nfunc (c *Client) Close() error {\n    c.session.Close()\n    return c.client.Close()\n}\n```\n\n**Redis Queue Backend** (Complete implementation for job queue):\n\n```go\n// internal/storage/redis/client.go\npackage redis\n\nimport (\n    \"context\"\n    \"encoding/json\"\n    \"time\"\n    \n    \"github.com/redis/go-redis/v9\"\n)\n\n// Client wraps Redis operations for job queue management\ntype Client struct {\n    rdb *redis.Client\n}\n\n// NewClient creates Redis client with connection pooling\nfunc NewClient(addr, password string, db int) *Client {\n    rdb := redis.NewClient(&redis.Options{\n        Addr:     addr,\n        Password: password,\n        DB:       db,\n        PoolSize: 10,\n    })\n    \n    return &Client{rdb: rdb}\n}\n\n// EnqueueJob adds job to priority queue with deduplication\nfunc (c *Client) EnqueueJob(ctx context.Context, job interface{}, priority float64, idempotencyKey string) error {\n    // Lua script for atomic enqueue with deduplication\n    script := redis.NewScript(`\n        local key = KEYS[1]\n        local dedup_key = KEYS[2] \n        local job_data = ARGV[1]\n        local priority = ARGV[2]\n        local idempotency = ARGV[3]\n        \n        if redis.call('EXISTS', dedup_key) == 1 then\n            return 0  -- Job already exists\n        end\n        \n        redis.call('ZADD', key, priority, job_data)\n        redis.call('SETEX', dedup_key, 86400, idempotency)  -- 24 hour dedup window\n        return 1\n    `)\n    \n    jobData, err := json.Marshal(job)\n    if err != nil {\n        return err\n    }\n    \n    _, err = script.Run(ctx, c.rdb, \n        []string{\"jobs:pending\", \"dedup:\" + idempotencyKey},\n        string(jobData), priority, idempotencyKey,\n    ).Result()\n    \n    return err\n}\n\n// DequeueJob atomically claims highest priority job\nfunc (c *Client) DequeueJob(ctx context.Context, workerID string) ([]byte, error) {\n    script := redis.NewScript(`\n        local pending_key = KEYS[1]\n        local claimed_key = KEYS[2]\n        local worker_id = ARGV[1]\n        \n        local job = redis.call('ZPOPMIN', pending_key)\n        if #job == 0 then\n            return nil  -- No jobs available\n        end\n        \n        local job_data = job[1]\n        redis.call('HSET', claimed_key, job_data, worker_id)\n        return job_data\n    `)\n    \n    result, err := script.Run(ctx, c.rdb,\n        []string{\"jobs:pending\", \"jobs:claimed\"},\n        workerID,\n    ).Result()\n    \n    if err != nil || result == nil {\n        return nil, err\n    }\n    \n    return []byte(result.(string)), nil\n}\n\n// Close releases Redis connection\nfunc (c *Client) Close() error {\n    return c.rdb.Close()\n}\n```\n\n#### Core Logic Skeleton Code\n\n**Scheduler Service Main Logic** (Skeleton for Milestone 3):\n\n```go\n// internal/coordinator/coordinator.go\npackage coordinator\n\nimport (\n    \"context\"\n    \"sync\"\n    \"time\"\n    \n    \"your-project/internal/models\"\n    \"your-project/internal/storage/etcd\" \n    \"your-project/internal/storage/redis\"\n)\n\n// Coordinator manages job scheduling and worker coordination\ntype Coordinator struct {\n    etcdClient  *etcd.Client\n    redisClient *redis.Client\n    workers     map[string]*models.Worker\n    isLeader    bool\n    mu          sync.RWMutex\n}\n\n// NewCoordinator creates a new coordinator instance\nfunc NewCoordinator(etcdClient *etcd.Client, redisClient *redis.Client) *Coordinator {\n    return &Coordinator{\n        etcdClient:  etcdClient,\n        redisClient: redisClient,\n        workers:     make(map[string]*models.Worker),\n    }\n}\n\n// Start begins coordinator operations with leader election\nfunc (c *Coordinator) Start(ctx context.Context) error {\n    // TODO 1: Start leader election campaign in background goroutine\n    // TODO 2: Start worker heartbeat monitoring loop\n    // TODO 3: Start job assignment loop (only when leader)\n    // TODO 4: Start job recovery scanner for failed workers\n    // Hint: Use ctx.Done() to gracefully shutdown all goroutines\n}\n\n// ProcessWorkerHeartbeat handles incoming worker health signals\nfunc (c *Coordinator) ProcessWorkerHeartbeat(workerID string, metadata models.Worker) error {\n    // TODO 1: Validate worker metadata (capacity, capabilities)\n    // TODO 2: Update worker's LastHeartbeat timestamp\n    // TODO 3: If worker was marked UNAVAILABLE, transition to AVAILABLE\n    // TODO 4: Update worker's current job count and capacity\n    // Hint: Use c.mu.Lock() for thread-safe worker map updates\n}\n\n// AssignJobToWorker selects optimal worker and assigns job\nfunc (c *Coordinator) AssignJobToWorker(job *models.Job) error {\n    // TODO 1: Get list of AVAILABLE workers with matching capabilities\n    // TODO 2: Select worker with lowest current load (currentJobs/capacity ratio)\n    // TODO 3: Atomically claim job in Redis with worker ID and fencing token\n    // TODO 4: Update worker's CurrentJobs count and state if at capacity\n    // Hint: Use atomic operations to prevent race conditions in job claims\n}\n\n// RecoverFailedWorkerJobs reassigns jobs from unresponsive workers\nfunc (c *Coordinator) RecoverFailedWorkerJobs(workerID string) error {\n    // TODO 1: Query Redis for all jobs claimed by this worker\n    // TODO 2: For each job, check if it's still executing (ping worker)\n    // TODO 3: Reset job state from CLAIMED back to PENDING\n    // TODO 4: Clear worker assignment and increment retry count\n    // TODO 5: Remove worker from active registry\n    // Hint: Use Lua scripts for atomic job state transitions\n}\n```\n\n**Worker Service Core Logic** (Skeleton for all milestones):\n\n```go\n// internal/worker/worker.go  \npackage worker\n\nimport (\n    \"context\"\n    \"time\"\n    \n    \"your-project/internal/models\"\n    \"your-project/pkg/client\"\n)\n\n// Worker represents a job execution node in the cluster\ntype Worker struct {\n    id           string\n    capacity     int\n    capabilities []string\n    currentJobs  int\n    client       *client.SchedulerClient\n    executors    map[string]JobExecutor\n}\n\n// JobExecutor defines interface for job type handlers\ntype JobExecutor interface {\n    Execute(ctx context.Context, payload map[string]string) error\n    GetTimeout() time.Duration\n}\n\n// Start begins worker operations with coordinator registration\nfunc (w *Worker) Start(ctx context.Context) error {\n    // TODO 1: Register worker with coordinator (POST /workers)\n    // TODO 2: Start heartbeat goroutine (every 30 seconds)\n    // TODO 3: Start job polling loop \n    // TODO 4: Handle graceful shutdown on ctx.Done()\n    // Hint: Use sync.WaitGroup to coordinate goroutine shutdown\n}\n\n// pollForJobs continuously requests jobs from coordinator\nfunc (w *Worker) pollForJobs(ctx context.Context) {\n    // TODO 1: Call coordinator's claimJob() API endpoint\n    // TODO 2: If job received, validate payload and find appropriate executor\n    // TODO 3: Execute job in separate goroutine with timeout context\n    // TODO 4: Report completion or failure back to coordinator\n    // TODO 5: Handle job retry logic for transient failures\n    // Hint: Respect worker capacity - don't claim more jobs than can handle\n}\n\n// executeJob runs job payload with timeout and error handling\nfunc (w *Worker) executeJob(ctx context.Context, job *models.Job) error {\n    // TODO 1: Find executor for job type from capabilities\n    // TODO 2: Create timeout context based on job or executor limits\n    // TODO 3: Call executor.Execute() with job payload\n    // TODO 4: Handle context cancellation and timeout errors\n    // TODO 5: Update job metrics (execution time, success/failure)\n    // Hint: Use defer to ensure completion reporting even if job panics\n}\n\n// sendHeartbeat reports worker status to coordinator\nfunc (w *Worker) sendHeartbeat() error {\n    // TODO 1: Collect current worker metrics (currentJobs, capacity)\n    // TODO 2: Send heartbeat to coordinator (POST /heartbeat)\n    // TODO 3: Handle coordinator response (job assignments, shutdown signals)\n    // TODO 4: Update worker state based on coordinator instructions\n    // Hint: Include worker capabilities in heartbeat for dynamic job routing\n}\n```\n\n#### File Structure Commands\n\nTo set up the recommended directory structure:\n\n```bash\n# Create main directory structure\nmkdir -p cmd/{scheduler,worker,cli}\nmkdir -p internal/{coordinator,cron,queue,worker,models,storage/{etcd,redis}}\nmkdir -p pkg/{api/{handlers,middleware,types},client,metrics}\nmkdir -p configs deployments/{kubernetes,docker,terraform}\nmkdir -p tests/{integration,e2e,fixtures}\n\n# Initialize Go module\ngo mod init distributed-job-scheduler\n\n# Add essential dependencies\ngo get go.etcd.io/etcd/client/v3@latest\ngo get github.com/redis/go-redis/v9@latest  \ngo get github.com/gorilla/mux@latest\ngo get github.com/stretchr/testify@latest\ngo get gopkg.in/yaml.v3@latest\n```\n\n#### Milestone Checkpoints\n\n**After Milestone 1 (Cron Parser)**:\n```bash\n# Test cron parsing functionality\ncd internal/cron && go test -v\n# Expected: All cron expression tests pass\n# Manual verification: Create simple main.go that parses \"@daily\" and prints next 5 execution times\n```\n\n**After Milestone 2 (Priority Queue)**:\n```bash  \n# Test queue operations\ncd internal/queue && go test -v\n# Expected: Priority ordering, deduplication, delayed execution tests pass\n# Manual verification: Start Redis, enqueue jobs with different priorities, verify dequeue order\n```\n\n**After Milestone 3 (Worker Coordination)**:\n```bash\n# Integration test with all components\ngo test ./tests/integration/... -v\n# Expected: Multi-worker coordination, leader election, job recovery tests pass\n# Manual verification: Start coordinator + 2 workers, kill one worker, verify job reassignment\n```\n\n#### Language-Specific Go Hints\n\n- **Graceful Shutdown**: Use `context.Context` with `signal.NotifyContext()` for clean service shutdown\n- **Atomic Operations**: Use `sync/atomic` package for counters, avoid mutex overhead for simple increments  \n- **Time Handling**: Always use `time.UTC()` for cron calculations, convert to local time only for display\n- **Error Wrapping**: Use `fmt.Errorf(\"operation failed: %w\", err)` to maintain error chains\n- **JSON Marshaling**: Implement custom `MarshalJSON()`/`UnmarshalJSON()` for complex types like `CronExpression`\n- **Testing**: Use `testify/require` for test setup, `testify/assert` for verification - `require` stops on failure, `assert` continues\n- **Redis Lua Scripts**: Store scripts as constants and use `redis.NewScript()` for atomic multi-key operations\n- **HTTP Clients**: Set reasonable timeouts (`http.Client{Timeout: 30 * time.Second}`) to prevent hanging requests\n\n\n## Data Model\n\n> **Milestone(s):** This section defines the core data structures that underpin all three milestones - Job entities for Milestone 1's cron scheduling, Worker entities for Milestone 3's coordination, and Schedule models that tie everything together.\n\nThe data model serves as the foundation for our distributed job scheduler, defining how jobs, workers, and schedules are represented, stored, and related to each other. Think of the data model as the blueprint for a city's infrastructure - it defines the roads (relationships), buildings (entities), and addressing system (identifiers) that allow all the traffic (data flow) to move efficiently and safely.\n\nA well-designed data model in a distributed system must balance several competing concerns: consistency across multiple nodes, performance under high load, and flexibility to support complex scheduling scenarios. Our model must also handle the temporal nature of scheduled jobs, where the same logical job may exist in multiple states across time, and the dynamic nature of worker nodes that can join, leave, or fail at any moment.\n\n![Data Model Relationships](./diagrams/data-model.svg)\n\nThe core entities in our system form a triangle of relationships: Jobs represent work to be done, Workers represent compute capacity to execute that work, and Schedules represent the timing patterns that govern when jobs should run. Each entity has its own lifecycle, state management needs, and consistency requirements that we must carefully design.\n\n### Job Definition\n\nThe `Job` entity represents a unit of work to be executed by the distributed scheduler. Think of a job as a train ticket - it contains all the information needed to identify the passenger (job payload), determine the route (scheduling information), track the journey (execution state), and ensure the ticket isn't used twice (idempotency).\n\nJobs in our system have a complex lifecycle that spans from creation through multiple execution attempts to final completion or failure. Unlike simple message queue systems where messages are consumed once, scheduled jobs may need to execute repeatedly on a cron schedule, require retry logic for transient failures, and maintain state across multiple worker nodes and coordinator failures.\n\n| Field Name | Type | Description |\n|------------|------|-------------|\n| ID | string | Unique identifier for the job, typically a UUID to ensure global uniqueness across the distributed system |\n| Name | string | Human-readable name for the job, used for monitoring and debugging purposes |\n| CronExpression | string | Cron expression defining when this job should execute (e.g., \"0 9 * * MON\" for 9 AM every Monday) |\n| Priority | int | Numeric priority where higher values indicate higher priority (0 = lowest, 100 = highest) |\n| Payload | map[string]string | Key-value pairs containing the actual work parameters that workers need to execute the job |\n| IdempotencyKey | string | Client-provided key to prevent duplicate job submissions; jobs with the same key are deduplicated |\n| State | JobState | Current execution state of the job (PENDING, CLAIMED, EXECUTING, COMPLETED, FAILED) |\n| WorkerID | string | Identifier of the worker currently assigned to execute this job; empty if not yet claimed |\n| FencingToken | string | Unique token that prevents stale worker reports from affecting completed jobs |\n| ScheduledAt | time.Time | When this job instance should execute; calculated from cron expression for recurring jobs |\n| ClaimedAt | *time.Time | Timestamp when a worker claimed this job; nil if not yet claimed |\n| CompletedAt | *time.Time | Timestamp when job execution finished (successfully or failed); nil if still in progress |\n| RetryCount | int | Number of times this job has been retried after failure |\n| MaxRetries | int | Maximum number of retry attempts before marking the job as permanently failed |\n| CreatedAt | time.Time | Timestamp when this job was first created in the system |\n| UpdatedAt | time.Time | Timestamp of the last modification to this job record |\n\nThe job state machine is central to ensuring exactly-once execution in our distributed environment. Each state transition represents a coordination point between the scheduler and workers, with careful attention to failure scenarios that could leave jobs in inconsistent states.\n\n| Current State | Event | Next State | Actions Taken |\n|---------------|-------|------------|---------------|\n| PENDING | Worker calls `claimJob()` | CLAIMED | Set WorkerID, ClaimedAt timestamp, generate FencingToken |\n| CLAIMED | Worker starts execution | EXECUTING | Update state, maintain heartbeat timeout |\n| EXECUTING | Worker calls `reportCompletion()` with success | COMPLETED | Set CompletedAt, clear WorkerID, schedule next instance if recurring |\n| EXECUTING | Worker calls `reportCompletion()` with failure | FAILED or PENDING | Increment RetryCount, reset for retry or mark failed if MaxRetries exceeded |\n| CLAIMED | Claim timeout expires | PENDING | Clear WorkerID and ClaimedAt to allow re-assignment |\n| EXECUTING | Worker heartbeat timeout | PENDING | Clear WorkerID, increment RetryCount, log recovery action |\n\n> **Decision: Fencing Token Strategy**\n> - **Context**: Workers can crash, recover, or experience network delays that cause them to report completion for jobs that have already been reassigned to other workers\n> - **Options Considered**: Monotonic sequence numbers, UUID-based tokens, timestamp-based tokens\n> - **Decision**: UUID-based fencing tokens generated when jobs are claimed\n> - **Rationale**: UUIDs provide uniqueness without requiring coordination between nodes, unlike sequence numbers that need centralized generation. They're also immune to clock skew issues that affect timestamp-based approaches\n> - **Consequences**: Enables safe job recovery and prevents duplicate execution reports, but adds storage overhead and complexity to worker reporting logic\n\n| Option | Pros | Cons | Chosen? |\n|--------|------|------|---------|\n| Sequence Numbers | Simple ordering, small storage | Requires coordinated counter, single point of failure | No |\n| UUID Tokens | No coordination needed, globally unique | Larger storage, no natural ordering | **Yes** |\n| Timestamps | Natural ordering, human readable | Clock skew issues, not guaranteed unique | No |\n\nThe idempotency key mechanism prevents clients from accidentally submitting the same job multiple times due to network retries or application bugs. When a job is submitted with an idempotency key that already exists, the scheduler returns the existing job instead of creating a duplicate. This is similar to how payment systems prevent double-charging when a customer clicks \"submit\" multiple times.\n\nThe payload structure as a string map provides flexibility for different job types while maintaining simplicity for serialization and storage. More complex payload types can be JSON-encoded into string values, allowing the scheduler to remain agnostic about job content while still supporting rich data structures.\n\n> The critical insight for job lifecycle management is that state transitions must be atomic and fenced. A job that transitions from EXECUTING to COMPLETED must never transition back to PENDING due to a delayed worker report, which is why fencing tokens are essential for correctness.\n\n⚠️ **Pitfall: Race Condition Between Claim and Timeout**\nWhen a worker claims a job but experiences a delay before starting execution, the coordinator might timeout the claim and reassign the job to another worker. Without proper fencing, both workers could execute the same job. The fencing token ensures that only the worker with the current token can successfully report completion, preventing this race condition.\n\n⚠️ **Pitfall: Infinite Retry Loops**\nJobs that fail due to permanent conditions (bad payload data, missing dependencies) will consume resources indefinitely if retry logic doesn't distinguish between transient and permanent failures. The MaxRetries field provides a circuit breaker, but job implementations should also return non-retryable error types for permanent failures.\n\n### Worker Model\n\nThe `Worker` entity represents a compute node capable of executing jobs in our distributed scheduler. Think of workers as delivery trucks in a logistics network - each truck has a capacity (how many packages it can carry), capabilities (refrigerated, oversized, hazardous materials), and a current location and status that the dispatch center needs to track for efficient job assignment.\n\nWorkers in our system are dynamic entities that can join and leave the cluster at any time. Unlike static partitioning schemes, our model supports elastic scaling where workers can be added during peak load periods and removed when demand decreases. This requires careful state management to ensure that work isn't lost when workers disappear unexpectedly.\n\n| Field Name | Type | Description |\n|------------|------|-------------|\n| ID | string | Unique identifier for the worker, typically combining hostname and process ID for easy debugging |\n| Address | string | Network address where the worker can be reached for job assignment and health checks (host:port format) |\n| Capacity | int | Maximum number of concurrent jobs this worker can execute, based on CPU cores and memory |\n| CurrentJobs | int | Number of jobs currently being executed by this worker |\n| Capabilities | []string | List of job types or features this worker supports (e.g., [\"gpu\", \"large-memory\", \"secure-enclave\"]) |\n| LastHeartbeat | time.Time | Timestamp of the most recent heartbeat signal from this worker |\n| State | WorkerState | Current operational state of the worker (AVAILABLE, BUSY, UNAVAILABLE) |\n| StartedAt | time.Time | When this worker first registered with the scheduler |\n| Metadata | map[string]string | Additional worker-specific information like version, region, instance type |\n\nThe worker capacity model allows for load balancing based on actual resource utilization rather than simple round-robin assignment. Workers with higher capacity can accept more jobs, while workers approaching their limits are avoided for new assignments. This prevents overloading individual nodes while maximizing cluster utilization.\n\n| Current State | Event | Next State | Actions Taken |\n|---------------|-------|------------|---------------|\n| AVAILABLE | Job assigned and CurrentJobs >= Capacity | BUSY | Stop offering jobs to this worker |\n| BUSY | Job completed and CurrentJobs < Capacity | AVAILABLE | Resume offering jobs to this worker |\n| AVAILABLE/BUSY | Heartbeat timeout exceeded | UNAVAILABLE | Reassign all jobs, remove from assignment pool |\n| UNAVAILABLE | Worker re-registers with `heartbeat()` | AVAILABLE | Reset LastHeartbeat, set CurrentJobs to 0 |\n\nWorker capabilities enable job affinity and constraint-based scheduling. Jobs can specify required capabilities (e.g., GPU access, specific software versions), and the scheduler ensures they're only assigned to compatible workers. This is essential for workloads that need specialized hardware or have security requirements.\n\n> **Decision: Heartbeat-Based Health Monitoring**\n> - **Context**: The scheduler needs to detect worker failures quickly to reassign jobs, but network partitions and temporary slowdowns shouldn't trigger false positives\n> - **Options Considered**: Pull-based health checks, push-based heartbeats, hybrid approach with both\n> - **Decision**: Push-based heartbeat mechanism where workers periodically call `heartbeat()`\n> - **Rationale**: Push-based heartbeats reduce coordinator overhead since workers contact the scheduler rather than the scheduler polling every worker. Workers can include status updates in heartbeat messages, providing richer information than simple ping responses\n> - **Consequences**: Enables fast failure detection and efficient resource utilization tracking, but requires careful timeout tuning to balance false positives against detection latency\n\n| Option | Pros | Cons | Chosen? |\n|--------|------|------|---------|\n| Pull-based Health Checks | Coordinator controls timing, works through firewalls | High coordinator overhead, delayed updates | No |\n| Push-based Heartbeats | Low coordinator overhead, real-time updates | Requires worker initiative, complex timeout handling | **Yes** |\n| Hybrid Approach | Best of both worlds | Complex implementation, potential conflicts | No |\n\nThe metadata field allows workers to provide context that helps with debugging and operational monitoring. For example, workers can report their software version, AWS instance type, or geographic region. This information doesn't affect scheduling logic but is invaluable for troubleshooting performance issues or ensuring compliance with data locality requirements.\n\nWorker address management handles the networking complexity of reaching workers for job assignment. In containerized environments, workers might have dynamic IP addresses or run behind load balancers. The address field accommodates these scenarios while providing a stable endpoint for coordinator communication.\n\n> The key insight for worker lifecycle management is that workers are ephemeral resources that can disappear without notice, so the scheduler must be designed with failure as the default case rather than an exception. All worker state must be recoverable, and job assignments must include timeout mechanisms.\n\n⚠️ **Pitfall: Heartbeat Timeout During Long Jobs**\nWorkers executing long-running jobs might miss heartbeat deadlines not because they've failed, but because they're busy processing. This can cause the coordinator to incorrectly mark them as unavailable and reassign their jobs. The heartbeat mechanism should be implemented as a separate goroutine that continues signaling even while jobs are executing.\n\n⚠️ **Pitfall: Worker State Inconsistency**\nIf a worker's CurrentJobs count becomes inconsistent with reality (due to bugs or missed completion reports), it might permanently remain in BUSY state even when idle. Periodic reconciliation between the worker's actual job count and the coordinator's records prevents this deadlock scenario.\n\n### Schedule Model\n\nThe `Schedule` model represents the temporal patterns that govern when jobs execute in our distributed scheduler. Think of schedules as the conductor's score in an orchestra - they define not just when each instrument (job) should play, but also how the timing coordinates with other schedules to create a harmonious system-wide performance.\n\nSchedules in our system bridge the gap between human-readable cron expressions and the precise timing calculations needed by the distributed coordinator. They handle the complexity of timezone conversions, daylight saving time transitions, and edge cases like February 29th or \"the 31st of every month\" in months that only have 30 days.\n\n| Field Name | Type | Description |\n|------------|------|-------------|\n| Original | string | The exact cron expression as provided by the user, preserved for debugging and display |\n| Minutes | []int | Parsed minute values (0-59); empty slice means \"every minute\", single value means specific minute |\n| Hours | []int | Parsed hour values (0-23); supports ranges like 9-17 for business hours |\n| DaysOfMonth | []int | Parsed day-of-month values (1-31); handles month boundaries and leap years |\n| Months | []int | Parsed month values (1-12); supports seasonal scheduling patterns |\n| DaysOfWeek | []int | Parsed day-of-week values (0-6, Sunday=0); handles weekly recurring patterns |\n| Timezone | *time.Location | Time zone for interpreting the cron expression; nil defaults to UTC |\n\nThe parsed field arrays enable efficient next-time calculation without repeatedly parsing the cron expression string. Each array contains the specific values when execution should occur, making the calculation algorithm a matter of finding the next valid combination across all dimensions.\n\nCron expression parsing handles several complex scenarios that naive implementations often miss. The interaction between day-of-month and day-of-week fields follows cron's \"OR\" semantics - a job scheduled for \"15 * * * MON\" runs both on the 15th of every month AND every Monday, not just Mondays that fall on the 15th.\n\n> **Decision: Pre-parsed Field Arrays vs. Runtime Parsing**\n> - **Context**: Next execution time calculation happens frequently as the scheduler evaluates which jobs are ready to run\n> - **Options Considered**: Parse cron expression on every calculation, parse once and store parsed format, hybrid caching approach\n> - **Decision**: Parse cron expressions once during job creation and store the parsed field arrays\n> - **Rationale**: Parsing is computationally expensive and involves string manipulation and regex matching. Pre-parsing moves this cost to job creation time, which happens much less frequently than schedule evaluation\n> - **Consequences**: Faster schedule evaluation and reduced CPU overhead during peak scheduling periods, but increases storage requirements and complicates cron expression updates\n\n| Option | Pros | Cons | Chosen? |\n|--------|------|------|---------|\n| Runtime Parsing | Low memory usage, handles dynamic changes | High CPU overhead, repeated work | No |\n| Pre-parsed Storage | Fast evaluation, one-time parsing cost | Higher storage, complex updates | **Yes** |\n| Hybrid Caching | Balance of speed and memory | Complex cache invalidation, potential consistency issues | No |\n\nTimezone handling is one of the most complex aspects of schedule management. A job scheduled for \"9 AM daily\" in New York should execute at different UTC times throughout the year due to daylight saving time transitions. The Timezone field enables accurate local time interpretation while the coordinator operates on UTC internally.\n\nThe next execution time calculation algorithm works by finding the earliest future time that satisfies all the cron field constraints simultaneously:\n\n1. **Start with the current time** rounded up to the next minute boundary (since cron expressions have minute-level granularity)\n2. **Iterate through years** starting from the current year, but limit the search to prevent infinite loops for impossible expressions\n3. **For each valid year, iterate through the months** specified in the Months array\n4. **For each valid month, calculate candidate days** that satisfy either the DaysOfMonth constraint OR the DaysOfWeek constraint (cron's OR semantics)\n5. **For each candidate day, iterate through the hours** specified in the Hours array\n6. **For each valid hour, iterate through the minutes** specified in the Minutes array\n7. **Return the first combination** that represents a time after the current time\n8. **Handle timezone conversion** if the schedule specifies a non-UTC timezone\n\nThe algorithm must handle several edge cases that can cause infinite loops or incorrect results:\n\n- **Impossible dates**: \"31 * * 2 *\" (February 31st) should never match any date\n- **Leap year handling**: \"29 * * 2 *\" should only match in leap years\n- **Daylight saving transitions**: 2:30 AM might not exist on spring-forward days\n- **Year boundaries**: Ensure the search eventually terminates for expressions that have no valid future dates\n\n> The critical insight for schedule calculation is that cron expressions define constraints rather than sequences. Unlike simple interval timers, cron schedules require constraint satisfaction across multiple temporal dimensions, making the calculation algorithm fundamentally a search problem.\n\nTimezone support requires careful coordination between the schedule representation and the execution coordinator. The CronExpression stores timezone information and handles local-to-UTC conversion, but the rest of the system operates purely in UTC to avoid consistency issues across distributed nodes that might be running in different timezones.\n\n⚠️ **Pitfall: Daylight Saving Time Transitions**\nDuring spring-forward transitions, times like 2:30 AM simply don't exist in local time zones that observe daylight saving time. A naive implementation might either throw an error or calculate an incorrect UTC time. The correct approach is to detect these non-existent times and advance to the next valid time slot.\n\n⚠️ **Pitfall: Day-of-Month vs Day-of-Week Confusion**\nMany developers expect cron's day-of-month and day-of-week fields to work with AND semantics (both must be satisfied), but the actual cron standard uses OR semantics (either can be satisfied). A job scheduled for \"0 9 15 * MON\" runs at 9 AM both on the 15th of every month AND every Monday, not just Mondays that fall on the 15th.\n\n⚠️ **Pitfall: Infinite Loop on Impossible Expressions**\nCron expressions like \"0 0 30 2 *\" (February 30th) will never have a valid execution time. The calculation algorithm must detect these impossible expressions and either reject them during parsing or terminate the search after a reasonable number of iterations to prevent infinite loops.\n\n### Implementation Guidance\n\nThe data model implementation serves as the foundation for all three milestones, providing the type definitions and persistence layer that enable cron parsing, job queuing, and worker coordination. Think of this as building the database schema and entity classes that everything else will depend on.\n\n**A. Technology Recommendations:**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Data Storage | JSON files with file locking | Redis with persistence enabled |\n| Serialization | `encoding/json` with struct tags | Protocol Buffers with code generation |\n| Time Handling | `time.Time` with UTC normalization | `time.Time` with timezone-aware helpers |\n| Validation | Manual field validation | Struct validation library (go-playground/validator) |\n\n**B. Recommended File Structure:**\n\n```\nproject-root/\n  internal/model/\n    job.go              ← Job struct and methods\n    worker.go           ← Worker struct and methods  \n    schedule.go         ← CronExpression parsing and calculation\n    storage.go          ← Data persistence interface\n    types.go            ← Enums and constants\n  internal/storage/\n    redis.go            ← Redis storage implementation\n    memory.go           ← In-memory storage for testing\n  cmd/scheduler/\n    main.go             ← Entry point\n```\n\n**C. Complete Infrastructure Starter Code:**\n\n```go\n// internal/model/types.go\npackage model\n\n// JobState represents the current execution state of a job\ntype JobState int\n\nconst (\n    PENDING JobState = iota\n    CLAIMED\n    EXECUTING  \n    COMPLETED\n    FAILED\n)\n\nfunc (s JobState) String() string {\n    switch s {\n    case PENDING:\n        return \"pending\"\n    case CLAIMED:\n        return \"claimed\"\n    case EXECUTING:\n        return \"executing\"\n    case COMPLETED:\n        return \"completed\"\n    case FAILED:\n        return \"failed\"\n    default:\n        return \"unknown\"\n    }\n}\n\n// WorkerState represents the current operational state of a worker\ntype WorkerState int\n\nconst (\n    AVAILABLE WorkerState = iota\n    BUSY\n    UNAVAILABLE\n)\n\nfunc (s WorkerState) String() string {\n    switch s {\n    case AVAILABLE:\n        return \"available\"\n    case BUSY:\n        return \"busy\"\n    case UNAVAILABLE:\n        return \"unavailable\"\n    default:\n        return \"unknown\"\n    }\n}\n\n// Storage interface for persisting scheduler entities\ntype Storage interface {\n    // Job operations\n    CreateJob(job *Job) error\n    GetJob(id string) (*Job, error)\n    UpdateJob(job *Job) error\n    ListJobs(state JobState) ([]*Job, error)\n    \n    // Worker operations  \n    RegisterWorker(worker *Worker) error\n    GetWorker(id string) (*Worker, error)\n    UpdateWorker(worker *Worker) error\n    ListWorkers(state WorkerState) ([]*Worker, error)\n    \n    // Cleanup operations\n    DeleteJob(id string) error\n    UnregisterWorker(id string) error\n}\n```\n\n```go\n// internal/storage/memory.go\npackage storage\n\nimport (\n    \"fmt\"\n    \"sync\"\n    \"github.com/yourorg/scheduler/internal/model\"\n)\n\n// MemoryStorage provides in-memory storage for testing\ntype MemoryStorage struct {\n    mu      sync.RWMutex\n    jobs    map[string]*model.Job\n    workers map[string]*model.Worker\n}\n\nfunc NewMemoryStorage() *MemoryStorage {\n    return &MemoryStorage{\n        jobs:    make(map[string]*model.Job),\n        workers: make(map[string]*model.Worker),\n    }\n}\n\nfunc (s *MemoryStorage) CreateJob(job *model.Job) error {\n    s.mu.Lock()\n    defer s.mu.Unlock()\n    \n    if _, exists := s.jobs[job.ID]; exists {\n        return fmt.Errorf(\"job %s already exists\", job.ID)\n    }\n    \n    // Deep copy to prevent external modifications\n    jobCopy := *job\n    s.jobs[job.ID] = &jobCopy\n    return nil\n}\n\nfunc (s *MemoryStorage) GetJob(id string) (*model.Job, error) {\n    s.mu.RLock()\n    defer s.mu.RUnlock()\n    \n    job, exists := s.jobs[id]\n    if !exists {\n        return nil, fmt.Errorf(\"job %s not found\", id)\n    }\n    \n    // Deep copy to prevent external modifications\n    jobCopy := *job\n    return &jobCopy, nil\n}\n\nfunc (s *MemoryStorage) UpdateJob(job *model.Job) error {\n    s.mu.Lock()\n    defer s.mu.Unlock()\n    \n    if _, exists := s.jobs[job.ID]; !exists {\n        return fmt.Errorf(\"job %s not found\", job.ID)\n    }\n    \n    // Deep copy to prevent external modifications\n    jobCopy := *job\n    s.jobs[job.ID] = &jobCopy\n    return nil\n}\n\nfunc (s *MemoryStorage) ListJobs(state model.JobState) ([]*model.Job, error) {\n    s.mu.RLock()\n    defer s.mu.RUnlock()\n    \n    var jobs []*model.Job\n    for _, job := range s.jobs {\n        if job.State == state {\n            jobCopy := *job\n            jobs = append(jobs, &jobCopy)\n        }\n    }\n    \n    return jobs, nil\n}\n\n// Implement remaining Storage interface methods for workers...\n// (Similar pattern to job methods)\n```\n\n**D. Core Logic Skeleton Code:**\n\n```go\n// internal/model/job.go\npackage model\n\nimport (\n    \"time\"\n    \"github.com/google/uuid\"\n)\n\n// Job represents a unit of work to be executed by the distributed scheduler\ntype Job struct {\n    ID              string            `json:\"id\"`\n    Name            string            `json:\"name\"`\n    CronExpression  string            `json:\"cron_expression\"`\n    Priority        int               `json:\"priority\"`\n    Payload         map[string]string `json:\"payload\"`\n    IdempotencyKey  string            `json:\"idempotency_key\"`\n    State           JobState          `json:\"state\"`\n    WorkerID        string            `json:\"worker_id,omitempty\"`\n    FencingToken    string            `json:\"fencing_token,omitempty\"`\n    ScheduledAt     time.Time         `json:\"scheduled_at\"`\n    ClaimedAt       *time.Time        `json:\"claimed_at,omitempty\"`\n    CompletedAt     *time.Time        `json:\"completed_at,omitempty\"`\n    RetryCount      int               `json:\"retry_count\"`\n    MaxRetries      int               `json:\"max_retries\"`\n    CreatedAt       time.Time         `json:\"created_at\"`\n    UpdatedAt       time.Time         `json:\"updated_at\"`\n}\n\n// NewJob creates a new job with default values and validation\nfunc NewJob(name, cronExpr string, priority int, payload map[string]string) (*Job, error) {\n    // TODO 1: Validate cron expression using CronExpression.Parse()\n    // TODO 2: Generate unique ID using uuid.New().String()\n    // TODO 3: Calculate initial ScheduledAt time from cron expression\n    // TODO 4: Set CreatedAt and UpdatedAt to current time\n    // TODO 5: Initialize State to PENDING, RetryCount to 0\n    // TODO 6: Set MaxRetries to default value (e.g., 3)\n    // Hint: Use time.Now().UTC() for consistent timezone handling\n}\n\n// ClaimForWorker atomically claims this job for the specified worker\nfunc (j *Job) ClaimForWorker(workerID string) error {\n    // TODO 1: Check if job is in PENDING state, return error if not\n    // TODO 2: Generate new fencing token using uuid.New().String()\n    // TODO 3: Set WorkerID, FencingToken, and ClaimedAt timestamp\n    // TODO 4: Transition State to CLAIMED\n    // TODO 5: Update the UpdatedAt timestamp\n    // Hint: Caller must persist the job after claiming\n}\n\n// MarkExecuting transitions job to executing state with validation\nfunc (j *Job) MarkExecuting(workerID, fencingToken string) error {\n    // TODO 1: Validate that WorkerID matches the claimer\n    // TODO 2: Validate that fencingToken matches current token  \n    // TODO 3: Check that current State is CLAIMED\n    // TODO 4: Transition State to EXECUTING\n    // TODO 5: Update the UpdatedAt timestamp\n}\n\n// ReportCompletion handles job completion or failure reporting\nfunc (j *Job) ReportCompletion(workerID, fencingToken string, success bool, errorMsg string) error {\n    // TODO 1: Validate workerID and fencingToken match current assignment\n    // TODO 2: Check that current State is EXECUTING\n    // TODO 3: Set CompletedAt timestamp\n    // TODO 4: If success, transition to COMPLETED state\n    // TODO 5: If failure and retries available, increment RetryCount and reset to PENDING\n    // TODO 6: If failure and no retries left, transition to FAILED state\n    // TODO 7: Clear WorkerID and FencingToken\n    // TODO 8: Update the UpdatedAt timestamp\n    // Hint: Store errorMsg in Metadata field for debugging\n}\n```\n\n```go\n// internal/model/worker.go  \npackage model\n\nimport (\n    \"time\"\n)\n\n// Worker represents a compute node capable of executing jobs\ntype Worker struct {\n    ID            string            `json:\"id\"`\n    Address       string            `json:\"address\"`\n    Capacity      int               `json:\"capacity\"`\n    CurrentJobs   int               `json:\"current_jobs\"`\n    Capabilities  []string          `json:\"capabilities\"`\n    LastHeartbeat time.Time         `json:\"last_heartbeat\"`\n    State         WorkerState       `json:\"state\"`\n    StartedAt     time.Time         `json:\"started_at\"`\n    Metadata      map[string]string `json:\"metadata\"`\n}\n\n// NewWorker creates a new worker with validation\nfunc NewWorker(id, address string, capacity int, capabilities []string) (*Worker, error) {\n    // TODO 1: Validate that ID is non-empty and unique format\n    // TODO 2: Validate that address is valid host:port format\n    // TODO 3: Validate that capacity is positive integer\n    // TODO 4: Set State to AVAILABLE and CurrentJobs to 0\n    // TODO 5: Set StartedAt and LastHeartbeat to current time\n    // TODO 6: Initialize Metadata map and copy capabilities slice\n    // Hint: Use net.ResolveTCPAddr() to validate address format\n}\n\n// UpdateHeartbeat records a heartbeat and updates worker state\nfunc (w *Worker) UpdateHeartbeat(currentJobs int) {\n    // TODO 1: Update LastHeartbeat to current time\n    // TODO 2: Update CurrentJobs to the reported value\n    // TODO 3: Update State based on capacity: AVAILABLE if under capacity, BUSY if at/over capacity\n    // TODO 4: Validate that currentJobs is non-negative and not greater than realistic limits\n    // Hint: Consider adding validation for currentJobs > Capacity (might indicate bug)\n}\n\n// IsHealthy checks if worker is responding within timeout\nfunc (w *Worker) IsHealthy(timeout time.Duration) bool {\n    // TODO 1: Calculate time since LastHeartbeat\n    // TODO 2: Return true if within timeout and State is not UNAVAILABLE\n    // TODO 3: Return false if timeout exceeded or worker marked unavailable\n}\n\n// CanAcceptJob checks if worker can accept a new job\nfunc (w *Worker) CanAcceptJob(requiredCapabilities []string) bool {\n    // TODO 1: Check if State is AVAILABLE (not BUSY or UNAVAILABLE)\n    // TODO 2: Check if CurrentJobs < Capacity\n    // TODO 3: Check if worker has all required capabilities\n    // TODO 4: Return true only if all conditions are met\n    // Hint: Use string comparison to check capability matching\n}\n```\n\n```go\n// internal/model/schedule.go\npackage model\n\nimport (\n    \"time\"\n    \"strings\"\n)\n\n// CronExpression represents a parsed cron expression with timezone support\ntype CronExpression struct {\n    Original     string         `json:\"original\"`\n    Minutes      []int          `json:\"minutes\"`\n    Hours        []int          `json:\"hours\"`  \n    DaysOfMonth  []int          `json:\"days_of_month\"`\n    Months       []int          `json:\"months\"`\n    DaysOfWeek   []int          `json:\"days_of_week\"`\n    Timezone     *time.Location `json:\"timezone,omitempty\"`\n}\n\n// ParseCronExpression parses a cron expression string into structured format\nfunc ParseCronExpression(expr string) (*CronExpression, error) {\n    // TODO 1: Split expression into fields (space-separated)\n    // TODO 2: Validate field count (5 or 6 fields supported)\n    // TODO 3: Parse each field using parseField() helper\n    // TODO 4: Handle special expressions like @daily, @hourly\n    // TODO 5: Set timezone to UTC if not specified\n    // TODO 6: Store original expression for debugging\n    // Hint: Use strings.Fields() to split on whitespace\n}\n\n// NextExecutionTime calculates when this cron expression should next run\nfunc (c *CronExpression) NextExecutionTime(from time.Time) (time.Time, error) {\n    // TODO 1: Convert from time to the cron expression's timezone\n    // TODO 2: Round up to next minute boundary (cron has minute precision)\n    // TODO 3: Iterate through years, months, days to find next valid time\n    // TODO 4: Check both day-of-month and day-of-week constraints (OR semantics)\n    // TODO 5: Handle edge cases like February 29, month boundaries\n    // TODO 6: Convert result back to UTC before returning\n    // TODO 7: Return error if no valid time found within reasonable range (2 years)\n    // Hint: Use time.Date() to construct candidate times and check validity\n}\n\n// parseField parses a single cron field (minutes, hours, etc.) into integer slice\nfunc parseField(field string, min, max int) ([]int, error) {\n    // TODO 1: Handle wildcard \"*\" - return all values in range\n    // TODO 2: Handle step values like \"*/15\" or \"2-10/3\"\n    // TODO 3: Handle ranges like \"9-17\" \n    // TODO 4: Handle lists like \"1,15,30\"\n    // TODO 5: Handle single values like \"5\"\n    // TODO 6: Validate all values are within min-max range\n    // TODO 7: Sort and deduplicate the result slice\n    // Hint: Use strconv.Atoi() for string to int conversion\n}\n```\n\n**E. Language-Specific Hints:**\n\n- **Time Handling**: Always use `time.Now().UTC()` for consistency across distributed nodes. Use `time.LoadLocation()` for timezone parsing in cron expressions.\n- **JSON Serialization**: Add `json` struct tags with `omitempty` for optional fields like `ClaimedAt *time.Time`.\n- **UUID Generation**: Use `github.com/google/uuid` package for generating job IDs and fencing tokens.\n- **Validation**: Consider using `github.com/go-playground/validator/v10` for struct validation with tags like `validate:\"required,min=1,max=100\"`.\n- **Concurrency**: Use `sync.RWMutex` for storage implementations to allow concurrent reads while protecting writes.\n\n**F. Milestone Checkpoint:**\n\nAfter implementing the data model:\n- Run `go test ./internal/model/...` - should pass basic struct creation and validation tests\n- Create a job with `NewJob()` and verify all fields are populated correctly\n- Parse a simple cron expression like `\"0 9 * * MON\"` and verify the parsed fields match expected values\n- Test worker heartbeat updates and verify state transitions between AVAILABLE and BUSY\n- Verify that job state transitions follow the documented state machine (can't go from COMPLETED back to EXECUTING)\n\nExpected output when testing cron parsing:\n```\nExpression: \"0 9 * * 1\"\nMinutes: [0]\nHours: [9] \nDaysOfMonth: [1,2,3,...,31]\nMonths: [1,2,3,...,12]\nDaysOfWeek: [1]\nNext execution: 2024-01-08 09:00:00 UTC (next Monday at 9 AM)\n```\n\nSigns that something is wrong:\n- Job IDs are not unique across multiple calls to `NewJob()`\n- Cron parsing returns incorrect field arrays (e.g., `*` doesn't expand to full range)\n- Worker state doesn't change when `CurrentJobs` exceeds `Capacity`\n- Time calculations are inconsistent across different system timezones\n\n\n## Cron Expression Parser\n\n> **Milestone(s):** Milestone 1 - Cron Expression Parser. This section implements the core scheduling logic that parses cron expressions and calculates next execution times with timezone support.\n\n### Mental Model: Understanding cron as a calendar pattern matching system\n\nThink of cron expressions as a sophisticated calendar filter that answers the question: \"When should this job run next?\" Imagine you're a personal assistant managing a complex schedule for an executive. Instead of writing down specific dates and times, you create rules like \"every Monday at 9 AM\" or \"the 15th of every month at noon.\" Cron expressions work exactly the same way - they define patterns that match against the calendar to determine when jobs should execute.\n\nThe power of cron lies in its ability to express complex recurring patterns with simple field-based notation. Each field acts like a filter that constrains when execution can occur. When all five (or six) filters align - meaning the current time matches all specified constraints - the job becomes eligible for execution. This pattern-matching approach makes cron expressions incredibly flexible while remaining human-readable.\n\nConsider the analogy of a combination lock. Just as a combination lock only opens when all tumblers align to the correct positions, a cron job only executes when the current time matches all field constraints simultaneously. The minute field must match, AND the hour field must match, AND the day constraints must be satisfied, and so on. This intersection-based logic is the fundamental principle underlying cron scheduling.\n\nHowever, unlike simple calendar entries, cron expressions must handle edge cases that don't occur in human scheduling. What happens when you schedule a job for the 31st of every month, but February only has 28 days? How do you handle timezone transitions during daylight saving time? These complexities make cron parsing more challenging than it initially appears, requiring careful consideration of calendar arithmetic and timezone handling.\n\nThe `CronExpression` structure captures this pattern-matching concept by breaking down the textual cron expression into structured field lists. Instead of repeatedly parsing the string \"0 9 * * 1\", the parser converts it once into a format where minutes=[0], hours=[9], and daysOfWeek=[1], making subsequent time calculations much more efficient.\n\n### Parsing Algorithm: Field-by-field validation and range expansion for cron expressions\n\nThe cron parsing algorithm transforms a textual cron expression into a structured representation that enables efficient time calculations. This process involves tokenization, field validation, and range expansion to handle the various syntactic features that cron expressions support.\n\n> **Decision: Five-field vs Six-field Cron Support**\n> - **Context**: Standard Unix cron uses five fields (minute, hour, day-of-month, month, day-of-week), but many modern schedulers support a six-field format that includes seconds.\n> - **Options Considered**: Support only five-field format for simplicity, support only six-field format for precision, support both formats with auto-detection.\n> - **Decision**: Support both formats with auto-detection based on field count.\n> - **Rationale**: This provides maximum compatibility with existing cron expressions while enabling sub-minute scheduling precision when needed. Auto-detection eliminates the need for users to specify the format explicitly.\n> - **Consequences**: Parsing logic becomes slightly more complex, but the scheduler can handle both traditional Unix cron expressions and modern high-precision scheduling requirements.\n\n| Format Type | Field Count | Fields | Use Case |\n|-------------|-------------|---------|----------|\n| Traditional | 5 | minute, hour, day-of-month, month, day-of-week | Standard Unix cron compatibility |\n| Extended | 6 | second, minute, hour, day-of-month, month, day-of-week | Sub-minute scheduling precision |\n\nThe parsing process follows a systematic approach that validates each field and expands shorthand notations into explicit value lists. The algorithm begins by tokenizing the input string on whitespace boundaries, then determines the format based on the number of fields detected. This auto-detection prevents users from having to specify the format explicitly while ensuring backward compatibility with existing cron expressions.\n\n**Field Parsing Algorithm:**\n\n1. **Tokenization**: Split the input string on whitespace to extract individual field values, handling multiple consecutive spaces and tab characters gracefully.\n\n2. **Format Detection**: Count the number of fields to determine whether this is a five-field or six-field expression, adjusting field positions accordingly.\n\n3. **Shorthand Expansion**: Check for special shorthand expressions like @yearly, @monthly, @daily, @hourly, and @reboot, converting them to their equivalent standard field representations.\n\n4. **Field-by-Field Processing**: For each field position, validate the syntax and expand ranges, lists, and step values into explicit integer lists.\n\n5. **Range Validation**: Ensure all expanded values fall within valid ranges for each field type (0-59 for minutes, 1-31 for day-of-month, etc.).\n\n6. **Semantic Validation**: Check for semantic errors like invalid day-of-month values for specific months or conflicting day-of-week specifications.\n\nEach field supports multiple syntactic forms that must be parsed and normalized into integer lists. The wildcard character (*) represents all valid values for that field. Ranges (1-5) specify inclusive spans of values. Lists (1,3,5) enumerate specific values explicitly. Step values (*/5 or 2-10/3) generate arithmetic progressions within specified ranges.\n\n| Syntax Type | Example | Expansion | Description |\n|-------------|---------|-----------|-------------|\n| Wildcard | * | All valid values | Matches every possible value for this field |\n| Specific Value | 15 | [15] | Matches exactly one value |\n| Range | 1-5 | [1,2,3,4,5] | Matches all values in inclusive range |\n| List | 1,3,5 | [1,3,5] | Matches explicitly enumerated values |\n| Step (wildcard) | */5 | [0,5,10,15,...] | Every 5th value starting from minimum |\n| Step (range) | 10-20/3 | [10,13,16,19] | Every 3rd value within range |\n\nThe range expansion logic handles edge cases carefully. When processing step values, the algorithm starts from the range minimum (or field minimum for wildcards) and increments by the step size until exceeding the range maximum. This ensures consistent behavior regardless of whether the step divides evenly into the range size.\n\nField validation enforces both syntactic and semantic constraints. Syntactic validation ensures proper format (no invalid characters, correct range syntax), while semantic validation checks domain-specific rules (no 31st day in February, valid timezone names). The validator maintains separate error lists for each category to provide detailed feedback about parsing failures.\n\n> The critical insight in cron parsing is that expansion happens once at parse time, not at every time calculation. Converting \"*/5\" to [0,5,10,15,20,25,30,35,40,45,50,55] during parsing makes subsequent time calculations much faster, since they only need to check membership in pre-computed lists.\n\n**Common Edge Cases in Parsing:**\n\nThe parser must handle several edge cases that frequently cause issues in cron implementations. Day-of-month and day-of-week interaction follows Unix cron semantics where both constraints are OR'ed together rather than AND'ed. This means \"0 9 15 * 1\" runs at 9 AM on the 15th of every month OR every Monday, not just on Mondays that fall on the 15th.\n\nTimezone specifications can appear as suffixes to cron expressions in extended formats. The parser must extract timezone information and validate it against the system's timezone database before storing it in the `CronExpression` structure. Invalid timezone names should cause parsing failures with clear error messages.\n\nRange boundaries require careful validation. Day-of-month ranges that include 31 are valid during parsing but may not match certain months during execution. The parser accepts these ranges but the time calculation algorithm must handle month-specific limitations appropriately.\n\n| Field | Valid Range | Special Cases | Common Errors |\n|-------|-------------|---------------|---------------|\n| Second | 0-59 | N/A | Using 60 for leap seconds |\n| Minute | 0-59 | N/A | Using 60 instead of 0 |\n| Hour | 0-23 | N/A | Using 24 instead of 0 |\n| Day-of-Month | 1-31 | Month-dependent validity | Using 0, assuming all months have 31 days |\n| Month | 1-12 | N/A | Using 0-11 instead of 1-12 |\n| Day-of-Week | 0-7 | Both 0 and 7 represent Sunday | Confusion about Sunday representation |\n\n### Next Time Calculation: Algorithm for finding the next valid execution time from current timestamp\n\nThe next execution time calculation is the most complex part of cron processing because it must handle calendar arithmetic, timezone transitions, and the interaction between day-of-month and day-of-week constraints. The algorithm starts from the current timestamp and incrementally advances through time units until finding a moment that satisfies all field constraints simultaneously.\n\nThink of this process like solving a multi-dimensional constraint satisfaction problem. Each cron field represents a constraint that the target timestamp must satisfy. The algorithm works by advancing time in the smallest possible increments - typically one minute for five-field expressions or one second for six-field expressions - and checking whether the current time satisfies all constraints.\n\n> **Decision: Incremental vs Mathematical Next Time Calculation**\n> - **Context**: There are two approaches to finding the next execution time - incrementally advancing time units until constraints are satisfied, or mathematically calculating the next valid time directly.\n> - **Options Considered**: Pure incremental approach (simple but potentially slow), pure mathematical approach (fast but complex), hybrid approach that uses math for simple cases and incremental for complex ones.\n> - **Decision**: Implement a hybrid approach that uses mathematical shortcuts for simple patterns but falls back to incremental advancement for complex constraints.\n> - **Rationale**: Simple patterns like \"every hour\" or \"daily at 3 AM\" can be calculated directly using modular arithmetic, providing excellent performance. Complex patterns involving multiple constraints or day-of-week/day-of-month interactions require incremental checking to handle edge cases correctly.\n> - **Consequences**: Provides optimal performance for common scheduling patterns while maintaining correctness for complex expressions. Code complexity is moderate since the mathematical shortcuts are optional optimizations.\n\n**Next Time Calculation Algorithm:**\n\n1. **Normalization**: Convert the current timestamp to the target timezone and truncate to the appropriate precision (minute or second boundary based on expression format).\n\n2. **Constraint Checking**: Evaluate whether the current time satisfies all field constraints, returning immediately if it matches exactly.\n\n3. **Increment Strategy**: Choose the appropriate time increment based on which constraints are failing - advance by seconds, minutes, hours, days, or months as appropriate.\n\n4. **Calendar Advancement**: Increment the time by the chosen amount, handling month boundaries, leap years, and other calendar complexities correctly.\n\n5. **Constraint Re-evaluation**: Check the new timestamp against all field constraints, repeating the process until a matching time is found.\n\n6. **Infinite Loop Protection**: Implement safeguards to prevent infinite loops when no valid execution time exists within a reasonable future window.\n\nThe algorithm optimizes performance by choosing the largest possible time increment at each step. If the current hour doesn't match the hour constraint, there's no point in checking individual minutes - the algorithm can jump directly to the next valid hour. This coarse-grained advancement significantly reduces the number of iterations required.\n\n| Failed Constraint | Increment Strategy | Next Check Point | Optimization Benefit |\n|-------------------|-------------------|------------------|---------------------|\n| Second | +1 second | Next second | Minimal (baseline increment) |\n| Minute | Advance to next valid minute | Start of target minute | 60x faster than second-by-second |\n| Hour | Advance to next valid hour | Start of target hour | 3600x faster than second-by-second |\n| Day-of-Month | Advance to next valid day | Start of target day | Up to 86400x faster |\n| Month | Advance to next valid month | Start of target month | Up to 2.6M x faster |\n\n**Day-of-Week and Day-of-Month Interaction:**\n\nThe most complex aspect of cron time calculation is handling the interaction between day-of-month and day-of-week constraints when both are specified (neither is a wildcard). Unix cron semantics dictate that this creates an OR condition - the job runs if EITHER constraint is satisfied, not only when BOTH are satisfied simultaneously.\n\nThis means the expression \"0 9 15 * 1\" (9 AM on the 15th or on Mondays) has two separate series of execution times that must be computed and merged. The algorithm handles this by calculating next execution times for each constraint independently, then selecting the earliest result.\n\nConsider a concrete example: if today is Wednesday, March 10th, and we're looking for the next execution of \"0 9 15 * 1\":\n- Next 15th: March 15th at 9 AM (5 days from now)\n- Next Monday: March 14th at 9 AM (4 days from now)  \n- Result: March 14th at 9 AM (earlier of the two)\n\n**Calendar Arithmetic and Edge Cases:**\n\nThe algorithm must handle numerous calendar edge cases that don't occur in typical application development. Month lengths vary (28, 29, 30, or 31 days), requiring leap year calculations for February. When advancing from January 31st to February, the algorithm must recognize that February 31st doesn't exist and adjust accordingly.\n\nTimezone transitions during daylight saving time create additional complexity. When clocks \"spring forward,\" certain times don't exist (2:30 AM might be skipped entirely). When clocks \"fall back,\" certain times occur twice. The algorithm must handle these transitions gracefully, typically by selecting the first occurrence of ambiguous times and skipping non-existent times.\n\n| Edge Case | Scenario | Algorithm Behavior | Example |\n|-----------|----------|-------------------|---------|\n| Missing day | Job scheduled for 31st, current month has 30 days | Advance to next month with sufficient days | April 31st → May 31st |\n| Leap year | February 29th in non-leap year | Skip to next valid occurrence | Feb 29th 2023 → Feb 29th 2024 |\n| DST spring forward | 2:30 AM doesn't exist | Skip to next valid time after transition | 2:30 AM → 3:30 AM |\n| DST fall back | 2:30 AM occurs twice | Use first occurrence only | 2:30 AM (standard time) |\n| Year boundary | December → January transition | Handle year increment correctly | Dec 31st → Jan 1st (next year) |\n\n**Performance Optimization Strategies:**\n\nFor frequently-used cron expressions, the scheduler can implement caching strategies that pre-compute next execution times. Simple patterns like \"every hour\" or \"daily at midnight\" benefit from mathematical shortcuts that avoid iterative time advancement entirely.\n\nThe algorithm maintains an upper bound on search iterations to prevent infinite loops when no valid execution time exists. This can occur with malformed expressions or edge cases involving leap years and month boundaries. After exceeding the iteration limit, the algorithm returns an error rather than consuming infinite CPU time.\n\nFor expressions with large gaps between executions (like \"every February 29th\"), the algorithm uses month-level advancement to avoid checking individual days unnecessarily. This optimization is particularly important for expressions that match infrequently, where naive day-by-day advancement would be prohibitively expensive.\n\n### Timezone Handling: UTC normalization and daylight saving time considerations\n\nTimezone handling in distributed job schedulers requires careful consideration of where timezone conversions occur and how daylight saving time transitions are managed. The fundamental principle is to store all timestamps in UTC internally while supporting timezone-aware scheduling for user convenience.\n\nThink of timezone handling like international conference call scheduling. Participants specify their local times (\"let's meet at 3 PM my time\"), but the calendar system converts everything to a common reference (UTC) for storage and comparison. When displaying times back to users, the system converts from UTC to their local timezone. This normalization approach prevents confusion and ensures consistent behavior across different scheduler nodes.\n\n> **Decision: Timezone Storage and Conversion Strategy**\n> - **Context**: Cron expressions can specify timezone information, but the scheduler must coordinate across multiple nodes that may be in different timezones.\n> - **Options Considered**: Store all times in local timezone (simple but brittle), store all times in UTC (consistent but requires conversion), store times with timezone information (flexible but complex).\n> - **Decision**: Store all absolute timestamps in UTC, but preserve timezone information in cron expressions for calculation purposes.\n> - **Rationale**: UTC storage ensures consistency across scheduler nodes regardless of their local timezone configuration. Preserving timezone information in cron expressions allows proper handling of daylight saving time transitions and user-friendly scheduling.\n> - **Consequences**: Requires timezone conversion at job scheduling time and display time, but provides robust behavior during timezone transitions and distributed deployment.\n\nThe `CronExpression` structure includes a `Timezone` field that specifies the timezone for interpreting the cron schedule. When this field is nil, the expression uses UTC. When specified, the timezone affects how the cron expression is evaluated against wall-clock time in that timezone, while the calculated execution times are still converted to UTC for storage.\n\n**UTC Normalization Process:**\n\n1. **Parse Timezone**: Extract timezone information from the cron expression or use system default if not specified.\n\n2. **Calculate in Local Time**: Perform next time calculation in the specified timezone to handle daylight saving transitions correctly.\n\n3. **Convert to UTC**: Transform the calculated local time to UTC for storage in job queues and execution tracking.\n\n4. **Validate Conversion**: Ensure the conversion is unambiguous (handles DST transition edge cases).\n\n5. **Store UTC Timestamp**: Persist the UTC timestamp while retaining timezone information for future calculations.\n\nThis normalization process ensures that jobs scheduled in different timezones execute at the correct absolute times, even when scheduler nodes are distributed across multiple geographic regions.\n\n**Daylight Saving Time Transition Handling:**\n\nDaylight saving time transitions create two types of temporal anomalies that cron schedulers must handle gracefully. During \"spring forward\" transitions, certain times don't exist (clocks jump from 1:59 AM directly to 3:00 AM). During \"fall back\" transitions, certain times occur twice (2:30 AM happens once in daylight time, then again in standard time).\n\nFor jobs scheduled during non-existent times, the algorithm applies a forward adjustment strategy. If a job is scheduled for 2:30 AM during a spring forward transition, it executes at the next valid time (typically 3:30 AM after the transition). This ensures jobs don't get permanently stuck waiting for a time that will never occur.\n\n| Transition Type | Problem | Algorithm Behavior | Example |\n|-----------------|---------|-------------------|---------|\n| Spring Forward | Scheduled time doesn't exist | Execute at next valid time | 2:30 AM → 3:30 AM |\n| Fall Back | Scheduled time occurs twice | Execute only during first occurrence | 2:30 AM (DST), skip 2:30 AM (Standard) |\n| Timezone Change | Historical timezone rules | Use timezone rules active at execution time | Job scheduled before rule change |\n\nFor jobs scheduled during ambiguous times (times that occur twice), the scheduler executes the job only during the first occurrence. This prevents duplicate execution while maintaining predictable behavior. The algorithm achieves this by checking whether the calculated local time, when converted back to UTC, produces the expected UTC timestamp.\n\n**Cross-Timezone Coordination:**\n\nIn distributed deployments where scheduler nodes run in different timezones, UTC normalization becomes critical for preventing duplicate job execution. Consider a scenario where one scheduler node runs in New York and another in Los Angeles. Without UTC normalization, both nodes might claim responsibility for executing a job scheduled for \"3 AM Eastern Time\" because their local time calculations would differ.\n\nThe solution is to perform all coordination and locking operations using UTC timestamps. When a scheduler node calculates that a job should execute at \"3 AM Eastern Time,\" it converts this to a UTC timestamp (8 AM UTC during standard time, 7 AM UTC during daylight time) and uses this UTC value for all distributed coordination operations.\n\n> The key insight for timezone handling is that scheduling calculations must happen in the target timezone to respect local rules like daylight saving time, but all coordination and storage must use UTC to ensure consistency across distributed nodes.\n\n**Common Timezone Pitfalls:**\n\n⚠️ **Pitfall: Storing Local Timestamps**  \nStoring execution times in local timezone format makes the scheduler vulnerable to system timezone changes and creates inconsistencies in distributed deployments. Always convert calculated execution times to UTC before storage.\n\n⚠️ **Pitfall: Ignoring DST Transitions**  \nCalculating next execution times without considering daylight saving transitions can result in jobs running at unexpected times or not running at all. Always perform time calculations in the target timezone before converting to UTC.\n\n⚠️ **Pitfall: Assuming Fixed UTC Offsets**  \nTimezone offsets change throughout the year due to daylight saving time. Never hard-code UTC offsets; always use proper timezone libraries that handle historical and future timezone rule changes.\n\n⚠️ **Pitfall: Invalid Timezone Names**  \nAccepting arbitrary timezone names without validation can cause runtime errors during time calculations. Validate timezone names against the system's timezone database during cron expression parsing.\n\nThe scheduler should maintain a configurable policy for handling timezone-related errors. Options include failing the job submission, defaulting to UTC, or using the system's local timezone. The choice depends on whether the scheduler prioritizes safety (fail fast) or availability (best-effort execution).\n\n| Error Condition | Conservative Behavior | Permissive Behavior | Recommended |\n|-----------------|----------------------|---------------------|-------------|\n| Invalid timezone name | Reject job submission | Default to UTC | Conservative |\n| Ambiguous DST time | Reject job submission | Use first occurrence | Permissive |\n| Non-existent DST time | Reject job submission | Adjust to next valid time | Permissive |\n| Timezone rule changes | Require job resubmission | Apply new rules automatically | Depends on use case |\n\n### Implementation Guidance\n\nThe cron expression parser implementation requires careful attention to timezone handling, calendar arithmetic, and performance optimization. Go's time package provides excellent support for timezone-aware calculations, making it the ideal choice for implementing robust cron functionality.\n\n**Technology Recommendations:**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Cron Parsing | Custom parser with string splitting | Third-party library like robfig/cron |\n| Time Calculations | Go's time package with manual arithmetic | Specialized calendar library |\n| Timezone Data | Go's built-in time/tzdata | External timezone database |\n| Performance | Naive incremental time advancement | Optimized mathematical shortcuts |\n\n**Recommended File Structure:**\n\n```\ninternal/cron/\n  parser.go              ← CronExpression parsing logic\n  parser_test.go         ← Comprehensive parsing tests\n  calculator.go          ← Next time calculation algorithms\n  calculator_test.go     ← Time calculation test cases\n  timezone.go            ← Timezone handling utilities\n  timezone_test.go       ← DST transition test cases\n  expression.go          ← CronExpression data structures\n  errors.go              ← Cron-specific error types\n```\n\n**Core Data Structures:**\n\n```go\n// CronExpression represents a parsed cron expression with timezone support.\n// Fields contain expanded integer lists for efficient time matching.\ntype CronExpression struct {\n    // Original contains the unparsed cron expression string for debugging\n    Original string\n    \n    // Time field constraints as expanded integer lists\n    Seconds      []int  // 0-59, nil for 5-field expressions\n    Minutes      []int  // 0-59\n    Hours        []int  // 0-23\n    DaysOfMonth  []int  // 1-31\n    Months       []int  // 1-12\n    DaysOfWeek   []int  // 0-7 (both 0 and 7 represent Sunday)\n    \n    // Timezone specifies the timezone for schedule evaluation\n    // nil means UTC\n    Timezone *time.Location\n}\n\n// ParseResult contains parsing outcome with detailed error information\ntype ParseResult struct {\n    Expression *CronExpression\n    Errors     []ParseError\n    Warnings   []string\n}\n\n// ParseError provides specific information about parsing failures\ntype ParseError struct {\n    Field    string  // Which field caused the error\n    Value    string  // The problematic value\n    Position int     // Character position in original string\n    Message  string  // Human-readable error description\n}\n```\n\n**Cron Expression Parser Implementation:**\n\n```go\n// ParseCronExpression parses a cron expression string into structured format.\n// Supports both 5-field (minute hour day month weekday) and 6-field \n// (second minute hour day month weekday) formats with automatic detection.\nfunc ParseCronExpression(expr string) (*CronExpression, error) {\n    // TODO 1: Trim whitespace and validate non-empty input\n    \n    // TODO 2: Check for shorthand expressions (@yearly, @monthly, @daily, etc.)\n    // and convert to standard field format\n    \n    // TODO 3: Split expression on whitespace to extract individual fields\n    \n    // TODO 4: Determine format (5-field vs 6-field) based on field count\n    \n    // TODO 5: Parse each field according to its position and constraints\n    // Use parseField() helper for each field type\n    \n    // TODO 6: Validate semantic constraints (day-of-month vs month compatibility)\n    \n    // TODO 7: Extract timezone information if present (typically as suffix)\n    \n    // TODO 8: Create and populate CronExpression struct with parsed values\n    \n    return nil, nil // Replace with actual implementation\n}\n\n// parseField parses a single cron field and returns the expanded integer list.\n// Handles wildcards (*), ranges (1-5), lists (1,3,5), and steps (*/2, 1-10/3).\nfunc parseField(field string, min, max int) ([]int, error) {\n    // TODO 1: Handle wildcard (*) - return all values in range\n    \n    // TODO 2: Split on commas to handle lists (1,3,5,7-10)\n    \n    // TODO 3: For each list item, check for step syntax (value/step)\n    \n    // TODO 4: Parse ranges (start-end) and individual values\n    \n    // TODO 5: Expand step values within ranges\n    \n    // TODO 6: Validate all values are within min/max bounds\n    \n    // TODO 7: Sort and deduplicate the final value list\n    \n    return nil, nil // Replace with actual implementation\n}\n```\n\n**Next Time Calculation Implementation:**\n\n```go\n// NextExecutionTime calculates the next time this cron expression should execute\n// after the given timestamp. Returns time in UTC regardless of expression timezone.\nfunc (c *CronExpression) NextExecutionTime(after time.Time) (time.Time, error) {\n    // TODO 1: Convert 'after' timestamp to expression timezone for calculation\n    \n    // TODO 2: Truncate to appropriate precision (second or minute boundary)\n    \n    // TODO 3: Check if current time already matches all constraints\n    \n    // TODO 4: Implement main calculation loop with increment strategy:\n    //   - Determine which constraint is failing\n    //   - Choose appropriate time increment (second, minute, hour, day, month)\n    //   - Advance time by chosen increment\n    //   - Re-check all constraints\n    \n    // TODO 5: Handle day-of-week and day-of-month interaction (OR logic)\n    \n    // TODO 6: Implement infinite loop protection (max iterations limit)\n    \n    // TODO 7: Convert final result back to UTC before returning\n    \n    return time.Time{}, nil // Replace with actual implementation\n}\n\n// matchesConstraints checks if the given timestamp satisfies all cron field constraints.\n// Time should be provided in the expression's timezone for accurate evaluation.\nfunc (c *CronExpression) matchesConstraints(t time.Time) bool {\n    // TODO 1: Extract time components (second, minute, hour, day, month, weekday)\n    \n    // TODO 2: Check each field constraint using contains() helper\n    \n    // TODO 3: Handle special day-of-week/day-of-month logic:\n    //   - If both are specified (not wildcards), use OR logic\n    //   - If only one is specified, use normal AND logic\n    \n    // TODO 4: Return true only if all applicable constraints are satisfied\n    \n    return false // Replace with actual implementation\n}\n\n// contains checks if a value exists in an integer slice (field constraint list)\nfunc contains(slice []int, value int) bool {\n    for _, v := range slice {\n        if v == value {\n            return true\n        }\n    }\n    return false\n}\n```\n\n**Timezone Handling Utilities:**\n\n```go\n// parseTimezone extracts timezone information from a cron expression.\n// Supports timezone suffixes like \"0 9 * * * America/New_York\"\nfunc parseTimezone(expr string) (*time.Location, string, error) {\n    // TODO 1: Check for timezone suffix patterns (common timezone name formats)\n    \n    // TODO 2: Validate timezone name against time.LoadLocation\n    \n    // TODO 3: Return parsed timezone and expression with timezone removed\n    \n    return time.UTC, expr, nil // Replace with actual implementation\n}\n\n// convertToTimezone safely converts a UTC timestamp to the specified timezone,\n// handling DST transitions and invalid times appropriately.\nfunc convertToTimezone(utc time.Time, tz *time.Location) time.Time {\n    if tz == nil {\n        return utc\n    }\n    return utc.In(tz)\n}\n\n// convertToUTC converts a timezone-aware timestamp to UTC, handling\n// ambiguous times during DST transitions consistently.\nfunc convertToUTC(local time.Time) time.Time {\n    return local.UTC()\n}\n```\n\n**Milestone Checkpoint:**\n\nAfter implementing the cron expression parser, you should be able to:\n\n1. **Parse Valid Expressions**: `ParseCronExpression(\"0 9 * * 1\")` returns a valid CronExpression with Minutes=[0], Hours=[9], DaysOfWeek=[1].\n\n2. **Handle Extended Syntax**: `ParseCronExpression(\"30 0 9 * * 1-5\")` correctly parses the 6-field format with seconds.\n\n3. **Calculate Next Times**: For expression \"0 9 * * *\" at timestamp 2024-01-15 10:00:00 UTC, NextExecutionTime returns 2024-01-16 09:00:00 UTC.\n\n4. **Manage Timezones**: Expression \"0 9 * * * America/New_York\" correctly adjusts for EST/EDT transitions.\n\n**Test Commands:**\n```bash\ngo test ./internal/cron/... -v\ngo test ./internal/cron/... -run TestDSTTransitions\ngo test ./internal/cron/... -run TestComplexExpressions\n```\n\n**Expected Behavior:**\n- All parsing tests pass, including edge cases like February 29th and invalid timezone names\n- Next time calculations handle month boundaries and leap years correctly  \n- DST transition tests verify proper handling of spring forward and fall back scenarios\n- Performance benchmarks show sub-millisecond parsing times for typical expressions\n\n**Common Implementation Issues:**\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|-------------|----------------|-----|\n| Jobs run twice during DST | Ambiguous time handling | Check logs during DST transition | Use first occurrence only |\n| Jobs missing on 31st | Month boundary logic error | Test with expressions like \"0 0 31 * *\" | Skip months without target day |\n| Parser panics on invalid input | Missing input validation | Test with malformed expressions | Add comprehensive input validation |\n| Wrong timezone conversions | Hard-coded UTC offsets | Test around DST transitions | Use time.Location for all conversions |\n\n![Cron Expression Parsing](./diagrams/cron-parsing-flow.svg)\n\n\n## Priority Job Queue\n\n> **Milestone(s):** Milestone 2 - Job Queue with Priorities. This section implements a distributed priority queue system that orders jobs by priority levels, supports delayed execution for scheduled jobs, and prevents duplicate submissions through idempotency keys.\n\n### Mental Model: Priority Queue as a Hospital Triage System\n\nThink of the priority job queue as a hospital emergency room triage system. When patients arrive, they don't get treated in first-come-first-served order. Instead, a triage nurse evaluates each patient and assigns a priority level based on urgency - heart attack patients go straight to the front, while someone with a minor cut waits longer. The triage system also handles scheduled appointments (delayed execution) and prevents the same patient from being registered multiple times if they're brought in by both an ambulance and a family member (deduplication).\n\nThe priority job queue works similarly. Jobs arrive with different priority levels, and the system ensures that high-priority jobs get executed before low-priority ones, even if they arrived later. Some jobs are \"scheduled appointments\" that shouldn't be processed until a specific time, like a daily backup that runs at 3 AM. The deduplication mechanism prevents the same job from being queued multiple times if a client retries a submission or if multiple systems try to schedule the same recurring task.\n\nThis mental model helps understand why we need more than a simple FIFO queue. Real-world job scheduling requires sophisticated ordering, timing controls, and duplicate prevention - just like a hospital needs more than a simple waiting line to handle the complexity of medical care prioritization.\n\n### Priority Mechanism: Numeric Priority Levels and Heap-Based Ordering\n\nThe priority mechanism forms the core ordering logic of our job queue. Jobs are assigned numeric priority values where lower numbers indicate higher priority - similar to airline boarding groups where Group 1 boards before Group 5. This convention aligns with common computer science practice where priority 0 represents the highest urgency.\n\n![Priority Queue Structure](./diagrams/job-priority-queue.svg)\n\nThe priority system uses five standard levels, though the implementation supports any integer value:\n\n| Priority Level | Numeric Value | Description | Example Use Cases |\n|----------------|---------------|-------------|-------------------|\n| Critical | 0 | System-critical operations that must execute immediately | Security patches, critical alerts, system recovery |\n| High | 100 | Important business operations with tight deadlines | Payment processing, customer notifications, data backups |\n| Normal | 500 | Standard business operations with moderate timing requirements | Report generation, data synchronization, maintenance tasks |\n| Low | 1000 | Background operations that can be delayed | Log cleanup, cache warming, analytics processing |\n| Bulk | 2000 | Large batch operations that should yield to other work | Data imports, bulk exports, archive operations |\n\n> **Decision: Numeric Priority with Lower-is-Higher Convention**\n> - **Context**: Need a priority system that supports both predefined levels and custom priorities for specialized use cases\n> - **Options Considered**: \n>   - Enum-based priorities (CRITICAL, HIGH, NORMAL, LOW)\n>   - Numeric priorities with higher-is-higher (1-10 scale)\n>   - Numeric priorities with lower-is-higher (0-N scale)\n> - **Decision**: Numeric priorities with lower-is-higher convention\n> - **Rationale**: Numeric values allow infinite granularity for custom priorities between standard levels. Lower-is-higher convention matches Unix process priorities and min-heap data structures, reducing cognitive overhead for systems programmers.\n> - **Consequences**: Enables priority 150 jobs to run between High (100) and Normal (500). Requires documentation to clarify that 0 is highest priority, not lowest.\n\nThe queue implementation uses a min-heap data structure to maintain priority ordering efficiently. When jobs are inserted, the heap automatically positions them based on their priority value, ensuring that `Pop()` operations always return the highest-priority job in O(log n) time.\n\n**Priority Comparison Algorithm:**\n\nThe system compares jobs using a multi-level comparison that considers both priority and timing:\n\n1. **Primary Comparison**: Compare numeric priority values (lower wins)\n2. **Secondary Comparison**: If priorities are equal, compare scheduled execution times (earlier wins)\n3. **Tertiary Comparison**: If both priority and timing are equal, compare creation timestamps (older wins)\n4. **Final Tiebreaker**: If all other fields are equal, compare job IDs lexicographically for deterministic ordering\n\nThis comparison ensures that within each priority level, jobs execute in temporal order, providing predictable behavior for jobs with identical priorities.\n\n**Priority Inheritance and Boosting:**\n\nThe system supports priority boosting for jobs that have been waiting beyond acceptable thresholds. This prevents priority inversion where high-priority work depends on completion of lower-priority tasks:\n\n| Boost Condition | Wait Time Threshold | Priority Adjustment | Rationale |\n|------------------|---------------------|-------------------|-----------|\n| Age-based boost | 30 minutes | Increase priority by 50 points | Prevents starvation of normal-priority jobs |\n| Dependency boost | Immediate | Inherit dependent job's priority | Ensures dependency chains don't create bottlenecks |\n| Resource boost | 15 minutes | Increase priority by 25 points | Prioritizes jobs holding scarce resources |\n\n### Delayed Execution: Visibility Timeout Pattern for Scheduled Jobs\n\nDelayed execution enables jobs to remain invisible in the queue until their designated execution time arrives. This mechanism supports both one-time scheduled jobs (\"run this backup at 3 AM tomorrow\") and recurring jobs managed by the cron expression parser (\"run this report every Monday at 9 AM\").\n\nThe implementation uses the **visibility timeout pattern** borrowed from message queue systems like Amazon SQS. Jobs exist in the queue data structure but remain invisible to workers until their `ScheduledAt` timestamp passes. This approach provides several advantages over alternative designs:\n\n> **Decision: Visibility Timeout Pattern vs Separate Timer Service**\n> - **Context**: Need to store jobs that shouldn't execute until a future time without requiring separate infrastructure\n> - **Options Considered**: \n>   - External timer service that inserts jobs at scheduled time\n>   - Separate \"delayed jobs\" storage with timer-based promotion\n>   - Visibility timeout within single queue structure\n> - **Decision**: Visibility timeout within single queue structure\n> - **Rationale**: Single queue eliminates coordination complexity between timer service and queue. Visibility timeout pattern is well-understood from message queues. Redis native support reduces implementation complexity.\n> - **Consequences**: Requires queue scanning to find eligible jobs, but Redis sorted sets make this efficient. Eliminates race conditions between timer service and queue operations.\n\n**Delayed Job States and Transitions:**\n\nJobs progress through distinct visibility states as they approach their execution time:\n\n| State | Description | Worker Visibility | Queue Location |\n|-------|-------------|------------------|----------------|\n| Scheduled | Job exists but execution time is future | Invisible | Delayed jobs sorted set |\n| Eligible | Execution time has passed | Visible | Priority queue heap |\n| Claimed | Worker has claimed job for processing | Invisible to other workers | Worker's active jobs set |\n| Executing | Worker is actively processing job | Invisible | Worker's executing jobs set |\n\n**Visibility Promotion Algorithm:**\n\nThe queue periodically scans for delayed jobs whose execution time has arrived and promotes them to visible status:\n\n1. **Scan Trigger**: Every 30 seconds, or when queue becomes empty, or on explicit promotion request\n2. **Time Range Query**: Query delayed jobs sorted set for entries with `ScheduledAt <= current_time`\n3. **Batch Promotion**: Move up to 100 eligible jobs from delayed set to priority queue in single transaction\n4. **Priority Insertion**: Insert each promoted job into priority queue heap based on its priority value\n5. **Atomic Cleanup**: Remove promoted jobs from delayed set using Redis pipeline for atomicity\n\nThe batch promotion strategy balances responsiveness with efficiency. Promoting too few jobs creates unnecessary scanning overhead, while promoting too many jobs at once can cause latency spikes.\n\n**Scheduling Precision and Drift:**\n\nThe visibility timeout pattern provides **eventual consistency** for job scheduling rather than real-time precision. Jobs become eligible within the scan interval (30 seconds by default) of their scheduled time:\n\n| Precision Requirement | Scan Interval | Use Case Suitability |\n|----------------------|---------------|---------------------|\n| ±30 seconds | 30 seconds (default) | Most business operations, reports, backups |\n| ±5 seconds | 5 seconds | Time-sensitive notifications, monitoring alerts |\n| ±1 second | 1 second | Real-time processing, financial transactions |\n\n> The system prioritizes operational simplicity over microsecond precision. For use cases requiring sub-second scheduling accuracy, consider dedicated real-time job scheduling systems rather than distributed queue-based approaches.\n\n### Deduplication Strategy: Idempotency Keys and Hash-Based Detection\n\nDeduplication prevents the same logical job from being queued multiple times, which commonly occurs when clients retry failed submissions, when multiple systems attempt to schedule the same recurring job, or when network issues cause duplicate messages. The system uses **idempotency keys** provided by job submitters combined with hash-based detection for automatic duplicate prevention.\n\n**Idempotency Key Design:**\n\nEach job submission includes an `IdempotencyKey` field that uniquely identifies the logical operation. When clients submit jobs with identical idempotency keys, only the first submission creates a queue entry - subsequent submissions return the original job information without creating duplicates.\n\n| Idempotency Scope | Key Format | Example | Deduplication Window |\n|------------------|------------|---------|---------------------|\n| Global unique | UUID v4 | `550e8400-e29b-41d4-a716-446655440000` | Permanent |\n| Operation-based | `operation:params:timestamp` | `backup:user-db:20240315` | 24 hours |\n| Client-scoped | `client-id:sequence` | `payment-service:12345` | 1 hour |\n| Content-based | SHA-256 of normalized payload | `sha256:a1b2c3...` | 1 hour |\n\nThe deduplication window determines how long the system remembers previous submissions. Permanent deduplication works for globally unique operations, while time-bounded deduplication suits operations that legitimately repeat after certain intervals.\n\n**Hash-Based Automatic Detection:**\n\nBeyond explicit idempotency keys, the system automatically detects duplicates by computing content hashes of job payloads. This catches duplicates even when clients don't provide idempotency keys or use different keys for identical operations.\n\nThe content hash includes normalized versions of key job fields:\n\n1. **Normalized Job Name**: Converted to lowercase, whitespace trimmed\n2. **Sorted Payload Keys**: Payload map keys sorted alphabetically for consistent hashing\n3. **Canonical Cron Expression**: Cron expressions parsed and reformatted in standard form\n4. **Priority Level**: Included to distinguish identical payloads with different priorities\n\n**Deduplication Storage and Cleanup:**\n\nThe system maintains deduplication state in Redis using multiple data structures for efficient lookups and automatic cleanup:\n\n| Storage Structure | Purpose | Key Pattern | Expiration |\n|------------------|---------|-------------|------------|\n| Idempotency map | Explicit key tracking | `dedup:key:{idempotency-key}` | Configurable (1-24 hours) |\n| Content hash set | Automatic duplicate detection | `dedup:hash:{content-hash}` | 1 hour default |\n| Job reference map | Links dedup entries to job IDs | `dedup:job:{job-id}` | Same as job TTL |\n\n> **Decision: Redis-Based Deduplication vs In-Memory Cache**\n> - **Context**: Need persistent deduplication that survives service restarts and works across multiple queue service instances\n> - **Options Considered**: \n>   - In-memory LRU cache with configurable size\n>   - Redis with TTL-based automatic cleanup\n>   - Database table with periodic cleanup job\n> - **Decision**: Redis with TTL-based automatic cleanup  \n> - **Rationale**: Redis TTL provides automatic cleanup without manual intervention. Shared state across service instances prevents duplicates even during deployments. Redis performance characteristics suit high-frequency deduplication checks.\n> - **Consequences**: Requires Redis infrastructure dependency. Network latency for every deduplication check. Memory usage grows with deduplication window size.\n\n**Deduplication Algorithm:**\n\nThe complete deduplication check follows this sequence:\n\n1. **Extract Idempotency Key**: Check if job submission includes explicit `IdempotencyKey`\n2. **Check Explicit Deduplication**: Query Redis for existing entry with same idempotency key\n3. **Early Return**: If idempotency key matches, return existing job ID without creating duplicate\n4. **Compute Content Hash**: Calculate normalized hash of job name, payload, cron expression, and priority\n5. **Check Content Deduplication**: Query Redis for existing entry with same content hash\n6. **Hash Match Handling**: If content hash matches, compare full job details to confirm true duplicate vs hash collision\n7. **Create New Entry**: If no duplicates found, create new job and store both idempotency key and content hash mappings\n8. **Atomic Transaction**: Use Redis MULTI/EXEC to ensure deduplication state and job creation happen atomically\n\n**Edge Cases and Collision Handling:**\n\nThe deduplication system handles several edge cases that can cause incorrect behavior:\n\n⚠️ **Pitfall: Hash Collisions Causing False Duplicates**\nHash collisions can cause the system to incorrectly identify distinct jobs as duplicates. While SHA-256 collisions are extremely rare, they can occur with crafted inputs or in high-volume systems processing billions of jobs.\n\n**Detection**: Jobs with different payloads are rejected as duplicates during submission.\n\n**Fix**: When content hashes match, perform full job comparison including all payload fields. Only treat as duplicate if complete job specifications match exactly. Log hash collisions for monitoring.\n\n⚠️ **Pitfall: Race Conditions During Concurrent Submission**\nMultiple clients submitting identical jobs simultaneously can create duplicates if deduplication checks happen before job creation completes.\n\n**Detection**: Multiple jobs exist with identical idempotency keys or content hashes.\n\n**Fix**: Use Redis transactions (MULTI/EXEC) to make deduplication check and job creation atomic. Implement exponential backoff retry for clients when deduplication conflicts occur.\n\n⚠️ **Pitfall: Stale Deduplication Entries After Job Deletion**\nWhen jobs are deleted or expire, their deduplication entries may remain, preventing legitimate resubmission of the same operation.\n\n**Detection**: Job submissions rejected for non-existent jobs referenced in deduplication entries.\n\n**Fix**: Link deduplication entries to job TTL using Redis key expiration. Clean up orphaned deduplication entries during periodic maintenance.\n\n### Implementation Guidance\n\nThis subsection provides the Go-specific implementation details for building the priority job queue with Redis backing store and atomic operations.\n\n**Technology Recommendations:**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Queue Storage | Redis with Go-Redis client | Redis Cluster with sentinel failover |\n| Priority Queue | Go container/heap interface | Custom heap with batch operations |\n| Serialization | JSON with encoding/json | MessagePack with vmihailenco/msgpack |\n| Time Handling | time.Time with UTC normalization | Dedicated time library like jinzhu/now |\n| Deduplication | SHA-256 with crypto/sha256 | xxHash for performance-critical paths |\n| Atomic Operations | Redis transactions (MULTI/EXEC) | Redis Lua scripts for complex operations |\n\n**Recommended File Structure:**\n\n```\ninternal/queue/\n  queue.go                    ← PriorityQueue interface and Redis implementation\n  queue_test.go              ← Unit tests for queue operations\n  job.go                     ← Job struct and methods (NewJob, validation)\n  job_test.go                ← Job creation and state transition tests\n  deduplication.go           ← Idempotency and hash-based duplicate detection\n  deduplication_test.go      ← Deduplication logic tests\n  heap.go                    ← Go heap.Interface implementation for priorities\n  redis_client.go            ← Redis connection management and health checks\n  redis_scripts.go           ← Lua scripts for atomic Redis operations\n  types.go                   ← JobState enum, configuration structs\ninternal/storage/\n  interface.go               ← Storage interface for queue persistence\n  redis_storage.go           ← Redis-specific storage implementation\ncmd/queue-service/\n  main.go                    ← Queue service entry point\n  config.go                  ← Configuration loading and validation\n```\n\n**Infrastructure Starter Code:**\n\n**Redis Client Setup (`internal/queue/redis_client.go`):**\n\n```go\npackage queue\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"time\"\n\n    \"github.com/go-redis/redis/v8\"\n)\n\n// RedisConfig holds Redis connection configuration\ntype RedisConfig struct {\n    Address         string        `json:\"address\"`\n    Password        string        `json:\"password\"`\n    Database        int           `json:\"database\"`\n    MaxRetries      int           `json:\"max_retries\"`\n    PoolSize        int           `json:\"pool_size\"`\n    ConnectTimeout  time.Duration `json:\"connect_timeout\"`\n    ReadTimeout     time.Duration `json:\"read_timeout\"`\n    WriteTimeout    time.Duration `json:\"write_timeout\"`\n}\n\n// NewRedisClient creates configured Redis client with health checking\nfunc NewRedisClient(config RedisConfig) (*redis.Client, error) {\n    client := redis.NewClient(&redis.Options{\n        Addr:         config.Address,\n        Password:     config.Password,\n        DB:           config.Database,\n        MaxRetries:   config.MaxRetries,\n        PoolSize:     config.PoolSize,\n        DialTimeout:  config.ConnectTimeout,\n        ReadTimeout:  config.ReadTimeout,\n        WriteTimeout: config.WriteTimeout,\n    })\n\n    // Test connection\n    ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n    defer cancel()\n    \n    if err := client.Ping(ctx).Err(); err != nil {\n        return nil, fmt.Errorf(\"failed to connect to Redis: %w\", err)\n    }\n\n    return client, nil\n}\n\n// HealthCheck verifies Redis connectivity\nfunc (c *RedisClient) HealthCheck(ctx context.Context) error {\n    return c.client.Ping(ctx).Err()\n}\n\n// Close gracefully shuts down Redis connection\nfunc (c *RedisClient) Close() error {\n    return c.client.Close()\n}\n```\n\n**Job State Management (`internal/queue/types.go`):**\n\n```go\npackage queue\n\nimport (\n    \"fmt\"\n    \"time\"\n)\n\n// JobState represents current execution state of a job\ntype JobState string\n\nconst (\n    PENDING   JobState = \"pending\"\n    CLAIMED   JobState = \"claimed\"\n    EXECUTING JobState = \"executing\"\n    COMPLETED JobState = \"completed\"\n    FAILED    JobState = \"failed\"\n)\n\n// String implements Stringer interface for JobState\nfunc (js JobState) String() string {\n    return string(js)\n}\n\n// IsValid checks if job state is one of defined values\nfunc (js JobState) IsValid() bool {\n    switch js {\n    case PENDING, CLAIMED, EXECUTING, COMPLETED, FAILED:\n        return true\n    default:\n        return false\n    }\n}\n\n// CanTransitionTo checks if state transition is valid\nfunc (js JobState) CanTransitionTo(next JobState) bool {\n    transitions := map[JobState][]JobState{\n        PENDING:   {CLAIMED, FAILED},\n        CLAIMED:   {EXECUTING, PENDING, FAILED},\n        EXECUTING: {COMPLETED, FAILED, PENDING},\n        COMPLETED: {},  // Terminal state\n        FAILED:    {},  // Terminal state\n    }\n    \n    allowed, exists := transitions[js]\n    if !exists {\n        return false\n    }\n    \n    for _, allowedNext := range allowed {\n        if allowedNext == next {\n            return true\n        }\n    }\n    return false\n}\n\n// QueueConfig holds priority queue configuration\ntype QueueConfig struct {\n    ScanInterval        time.Duration `json:\"scan_interval\"`\n    BatchPromotionSize  int           `json:\"batch_promotion_size\"`\n    DefaultJobTTL       time.Duration `json:\"default_job_ttl\"`\n    DeduplicationWindow time.Duration `json:\"deduplication_window\"`\n    MaxRetries          int           `json:\"max_retries\"`\n    PriorityBoostAge    time.Duration `json:\"priority_boost_age\"`\n    PriorityBoostAmount int           `json:\"priority_boost_amount\"`\n}\n\n// DefaultQueueConfig returns sensible defaults\nfunc DefaultQueueConfig() QueueConfig {\n    return QueueConfig{\n        ScanInterval:        30 * time.Second,\n        BatchPromotionSize:  100,\n        DefaultJobTTL:       24 * time.Hour,\n        DeduplicationWindow: 1 * time.Hour,\n        MaxRetries:          3,\n        PriorityBoostAge:    30 * time.Minute,\n        PriorityBoostAmount: 50,\n    }\n}\n```\n\n**Core Logic Skeleton Code:**\n\n**Priority Queue Interface (`internal/queue/queue.go`):**\n\n```go\npackage queue\n\nimport (\n    \"context\"\n    \"time\"\n)\n\n// PriorityQueue defines interface for priority-based job queue\ntype PriorityQueue interface {\n    // SubmitJob adds job to queue with deduplication check\n    SubmitJob(ctx context.Context, job *Job) (*Job, error)\n    \n    // ClaimJob atomically assigns highest priority job to worker\n    ClaimJob(ctx context.Context, workerID string) (*Job, error)\n    \n    // CompleteJob marks job as successfully completed\n    CompleteJob(ctx context.Context, jobID string, result map[string]string) error\n    \n    // FailJob marks job as failed and handles retry logic\n    FailJob(ctx context.Context, jobID string, reason string) error\n    \n    // PromoteDelayedJobs moves eligible delayed jobs to active queue\n    PromoteDelayedJobs(ctx context.Context) (int, error)\n    \n    // GetQueueStats returns current queue statistics\n    GetQueueStats(ctx context.Context) (QueueStats, error)\n}\n\n// SubmitJob adds new job to queue with comprehensive deduplication\nfunc (pq *RedisPriorityQueue) SubmitJob(ctx context.Context, job *Job) (*Job, error) {\n    // TODO 1: Validate job fields - check required fields, validate cron expression, verify priority range\n    // TODO 2: Check idempotency key deduplication - query Redis for existing job with same IdempotencyKey\n    // TODO 3: If idempotency match found, return existing job without creating duplicate\n    // TODO 4: Compute content hash for automatic deduplication - normalize payload, hash job content\n    // TODO 5: Check content hash deduplication - query Redis for jobs with same content hash\n    // TODO 6: If content hash matches, compare full job details to handle hash collisions\n    // TODO 7: Create new job with generated ID, timestamps, and initial PENDING state\n    // TODO 8: Store job in appropriate queue - delayed queue if ScheduledAt is future, priority queue if immediate\n    // TODO 9: Create deduplication entries atomically using Redis transaction\n    // TODO 10: Return created job with populated metadata\n    // Hint: Use Redis MULTI/EXEC for atomic job creation and deduplication storage\n}\n\n// ClaimJob atomically assigns highest priority available job to worker\nfunc (pq *RedisPriorityQueue) ClaimJob(ctx context.Context, workerID string) (*Job, error) {\n    // TODO 1: Promote any eligible delayed jobs to active queue\n    // TODO 2: Get highest priority job from priority queue (lowest numeric priority value)\n    // TODO 3: Check if job is already claimed or expired - validate job state and TTL\n    // TODO 4: Atomically claim job for worker using Redis transaction with job state transition\n    // TODO 5: Set job ClaimedAt timestamp and WorkerID, transition state to CLAIMED\n    // TODO 6: Generate unique fencing token to prevent stale worker operations\n    // TODO 7: Add job to worker's active jobs set for tracking\n    // TODO 8: Set visibility timeout for job claim to handle worker failures\n    // TODO 9: Return claimed job with worker metadata populated\n    // Hint: Use Redis Lua script for atomic priority queue pop and claim operations\n}\n```\n\n**Deduplication Implementation (`internal/queue/deduplication.go`):**\n\n```go\npackage queue\n\nimport (\n    \"context\"\n    \"crypto/sha256\"\n    \"encoding/hex\"\n    \"encoding/json\"\n    \"fmt\"\n    \"sort\"\n    \"strings\"\n    \"time\"\n)\n\n// DeduplicationChecker handles job duplicate detection\ntype DeduplicationChecker struct {\n    client *redis.Client\n    config QueueConfig\n}\n\n// CheckDuplicate performs comprehensive deduplication check\nfunc (dc *DeduplicationChecker) CheckDuplicate(ctx context.Context, job *Job) (*Job, bool, error) {\n    // TODO 1: Check explicit idempotency key if provided by client\n    // TODO 2: Query Redis for existing deduplication entry with same IdempotencyKey\n    // TODO 3: If idempotency match found, retrieve and return existing job details\n    // TODO 4: Compute normalized content hash of job payload and metadata\n    // TODO 5: Query Redis for existing jobs with same content hash\n    // TODO 6: For content hash matches, perform full job comparison to handle hash collisions\n    // TODO 7: Return existing job if true duplicate found, nil if unique job\n    // Hint: Use Redis pipelining for efficient multiple key lookups\n}\n\n// computeContentHash creates deterministic hash of job content\nfunc (dc *DeduplicationChecker) computeContentHash(job *Job) string {\n    // TODO 1: Create normalized representation of job for consistent hashing\n    // TODO 2: Sort payload map keys alphabetically for deterministic ordering\n    // TODO 3: Include job name (normalized), cron expression (canonical), priority level\n    // TODO 4: Serialize normalized job data to JSON with consistent field ordering\n    // TODO 5: Compute SHA-256 hash of serialized data and return hex encoding\n    // Hint: Use json.Marshal with sorted maps for consistent serialization\n}\n\n// StoreDeduplicationEntry creates deduplication tracking entries\nfunc (dc *DeduplicationChecker) StoreDeduplicationEntry(ctx context.Context, job *Job) error {\n    // TODO 1: Create idempotency key mapping if IdempotencyKey is provided\n    // TODO 2: Create content hash mapping for automatic duplicate detection\n    // TODO 3: Set appropriate TTL on deduplication entries based on configuration\n    // TODO 4: Use Redis transaction to create all deduplication entries atomically\n    // TODO 5: Handle Redis errors and retry transient failures\n    // Hint: Use Redis SETEX for TTL-based automatic cleanup of deduplication entries\n}\n```\n\n**Heap Implementation for Priority Ordering (`internal/queue/heap.go`):**\n\n```go\npackage queue\n\nimport (\n    \"container/heap\"\n    \"time\"\n)\n\n// JobHeap implements heap.Interface for priority-ordered jobs\ntype JobHeap []*Job\n\n// Len returns number of jobs in heap\nfunc (jh JobHeap) Len() int {\n    return len(jh)\n}\n\n// Less compares two jobs for priority ordering (lower priority number = higher priority)\nfunc (jh JobHeap) Less(i, j int) bool {\n    // TODO 1: Compare priority values - lower numeric priority means higher priority\n    // TODO 2: If priorities equal, compare scheduled execution times - earlier time wins\n    // TODO 3: If priority and time equal, compare creation timestamps - older jobs first\n    // TODO 4: Final tiebreaker using job IDs for deterministic ordering\n    // Hint: Return true if job i should be popped before job j\n}\n\n// Swap exchanges two jobs in heap\nfunc (jh JobHeap) Swap(i, j int) {\n    jh[i], jh[j] = jh[j], jh[i]\n}\n\n// Push adds job to heap (called by heap.Push)\nfunc (jh *JobHeap) Push(x interface{}) {\n    *jh = append(*jh, x.(*Job))\n}\n\n// Pop removes highest priority job from heap (called by heap.Pop)\nfunc (jh *JobHeap) Pop() interface{} {\n    old := *jh\n    n := len(old)\n    job := old[n-1]\n    *jh = old[0 : n-1]\n    return job\n}\n\n// NewJobHeap creates initialized job heap\nfunc NewJobHeap() *JobHeap {\n    jh := &JobHeap{}\n    heap.Init(jh)\n    return jh\n}\n```\n\n**Redis Lua Scripts for Atomic Operations (`internal/queue/redis_scripts.go`):**\n\n```go\npackage queue\n\n// Lua script for atomic job claim operation\nconst claimJobScript = `\nlocal priority_queue_key = KEYS[1]\nlocal worker_jobs_key = KEYS[2]\nlocal job_key = KEYS[3]\nlocal worker_id = ARGV[1]\nlocal claim_timeout = ARGV[2]\nlocal current_time = ARGV[3]\n\n-- Get highest priority job from priority queue\nlocal job_data = redis.call('ZPOPMIN', priority_queue_key, 1)\nif #job_data == 0 then\n    return nil  -- No jobs available\nend\n\nlocal job_id = job_data[1]\nlocal job_info = redis.call('HGETALL', job_key .. job_id)\n\n-- Check if job is still claimable\nlocal job_state = job_info['state'] or 'unknown'\nif job_state ~= 'pending' then\n    return {'error', 'job_not_claimable', job_state}\nend\n\n-- Atomically claim job for worker\nredis.call('HSET', job_key .. job_id, \n    'state', 'claimed',\n    'worker_id', worker_id,\n    'claimed_at', current_time)\n\n-- Add to worker's active jobs\nredis.call('SADD', worker_jobs_key, job_id)\nredis.call('EXPIRE', worker_jobs_key, claim_timeout)\n\nreturn {job_id, job_info}\n`\n\n// Additional Lua scripts for batch promotion, cleanup, etc.\nconst promoteDelayedJobsScript = `\n-- Script for promoting delayed jobs to active queue\n-- TODO: Implement batch delayed job promotion logic\n`\n```\n\n**Language-Specific Hints:**\n\n- Use `go-redis/redis/v8` for Redis client with context support and connection pooling\n- Implement `container/heap` interface for efficient priority queue operations in memory\n- Use `crypto/sha256` for content hashing with hex encoding for Redis key compatibility  \n- Handle Redis pipeline operations for efficient batch deduplication checks\n- Use `time.Time.UTC()` for consistent timestamp normalization across timezones\n- Implement exponential backoff with `time.Sleep()` for Redis retry logic\n- Use Redis transactions (`MULTI/EXEC`) for atomic job state transitions\n- Consider Redis Lua scripts for complex atomic operations that require multiple commands\n\n**Milestone Checkpoint:**\n\nAfter implementing the priority queue foundation:\n\n1. **Unit Test Verification**: Run `go test ./internal/queue/...` - all tests should pass\n2. **Priority Ordering Test**: Submit jobs with priorities 100, 500, 100, 200 - claim order should be 100, 100, 200, 500  \n3. **Deduplication Test**: Submit identical jobs with same idempotency key - only first submission should create queue entry\n4. **Delayed Execution Test**: Submit job with `ScheduledAt` 30 seconds in future - job should not be claimable until promotion scan runs\n5. **Redis Persistence Test**: Restart queue service - submitted jobs should still exist in Redis and be claimable\n\n**Expected Behavior Verification:**\n- Queue service starts without errors and connects to Redis successfully\n- Job submission via REST API returns job ID and confirmation\n- Duplicate job submissions return original job ID instead of creating new entries\n- Priority ordering is maintained across service restarts\n- Delayed jobs become claimable after their scheduled time passes\n\n**Debugging Signs:**\n- Jobs claimed out of priority order → Check heap Less() implementation and Redis ZPOPMIN usage\n- Duplicate jobs created despite idempotency keys → Verify atomic Redis transactions and key formats  \n- Delayed jobs never become eligible → Check promotion scan interval and Redis key expiration\n- Memory leaks in long-running tests → Ensure proper Redis connection cleanup and heap memory management\n\n\n## Worker Coordination\n\n> **Milestone(s):** Milestone 3 - Worker Coordination. This section implements distributed worker management that enables fault-tolerant job execution across multiple worker nodes through leader election, heartbeat monitoring, and automatic job recovery when workers fail.\n\nThe worker coordination layer transforms our job scheduler from a single-node system into a truly distributed platform capable of scaling across multiple machines while maintaining consistency and fault tolerance. This coordination system ensures that jobs are fairly distributed across available workers, prevents duplicate execution through distributed locking, and automatically recovers from worker failures without losing work.\n\n### Mental Model: Worker coordination as an orchestra with conductor and failure recovery\n\nThink of worker coordination like a symphony orchestra performing a complex musical piece. The **conductor** (coordinator node) stands at the front, directing the performance by assigning musical parts to different musicians (workers) based on their instruments and current availability. Each musician must periodically make eye contact with the conductor (heartbeat) to receive cues and confirm they're still playing their assigned part.\n\nWhen a violinist suddenly becomes ill and leaves mid-performance, the conductor notices immediately because they stopped responding to cues. The conductor then quickly reassigns that violinist's remaining musical phrases to other available violinists who have the same instrument and capacity. The audience (job submitters) never notices the disruption because the music continues seamlessly.\n\nThe critical insight is that coordination requires both **active leadership** (one conductor making assignment decisions) and **continuous monitoring** (heartbeats to detect failures). Without the conductor, musicians would play over each other chaotically. Without heartbeats, the conductor couldn't detect when musicians fail and need replacement.\n\nJust as an orchestra has backup conductors ready to step in if the primary conductor collapses, our distributed system uses **leader election** to ensure exactly one coordinator is making decisions at any time, with other coordinator candidates ready to take over instantly upon failure.\n\n![Worker State Machine](./diagrams/worker-state-machine.svg)\n\n### Leader Election: Raft-like consensus for scheduler leadership and split-brain prevention\n\n**Leader election** is the process by which multiple coordinator nodes agree on a single leader responsible for job assignment and worker management. This prevents the catastrophic **split-brain** scenario where multiple coordinators simultaneously make conflicting job assignments, leading to duplicate execution or worker thrashing.\n\n![Leader Election Process](./diagrams/leader-election-flow.svg)\n\n> **Decision: etcd-based Leader Election with Lease Mechanism**\n> - **Context**: Multiple coordinator nodes need to agree on a single leader for job assignment decisions, with fast failover when the leader crashes\n> - **Options Considered**: Database-based locking, Redis-based election, etcd lease-based election\n> - **Decision**: etcd lease-based leader election with automatic renewal\n> - **Rationale**: etcd provides strong consistency guarantees through Raft consensus, built-in lease expiration for fast failure detection, and watch mechanisms for immediate leadership change notifications\n> - **Consequences**: Requires etcd as additional infrastructure dependency, but provides robust consensus with sub-second failover times\n\n| Election Component | Purpose | Behavior |\n|------------------|---------|----------|\n| `Leadership Lease` | Time-bounded leadership claim | Coordinator holds renewable lease; leadership expires if not renewed |\n| `Election Key` | Distributed lock for leadership | Single etcd key that only one coordinator can hold at a time |\n| `Candidate Registration` | Discovery of potential leaders | All coordinator nodes register as candidates with their addresses |\n| `Lease Renewal` | Maintain active leadership | Leader continuously renews lease every heartbeat interval |\n| `Watch Mechanism` | Fast failure detection | Non-leader candidates watch election key for leadership changes |\n\nThe leader election algorithm follows these steps:\n\n1. **Candidate Registration**: Each coordinator node attempts to create an etcd lease with a TTL of 30 seconds and writes its node ID and address to the leadership election key with that lease\n2. **Leadership Determination**: The first node to successfully write to the election key becomes the leader; subsequent attempts fail due to key already existing\n3. **Leadership Announcement**: The new leader broadcasts its leadership to all workers and begins accepting job assignment responsibilities\n4. **Lease Renewal Loop**: The leader continuously renews its lease every 10 seconds (one-third of TTL) to maintain leadership\n5. **Failure Detection**: If the leader fails to renew within the TTL window, etcd automatically deletes the election key, triggering immediate re-election\n6. **Candidate Notification**: All candidate coordinators watch the election key; when it's deleted, they immediately attempt to claim leadership\n7. **Split-Brain Prevention**: etcd's strong consistency ensures only one node can hold the election key, making simultaneous leadership impossible\n\n> The critical insight is that **lease expiration** provides both failure detection and automatic cleanup. A crashed leader doesn't need to explicitly release leadership - the lease simply expires, triggering immediate failover.\n\n**Leadership Responsibilities:**\n\n| Responsibility | Leader Action | Non-Leader Action |\n|---------------|---------------|------------------|\n| Job Assignment | Assigns jobs from queue to available workers | Rejects assignment requests, returns leader address |\n| Worker Health Monitoring | Processes heartbeats, detects failed workers | Ignores heartbeat messages |\n| Job Recovery | Reassigns jobs from failed workers | Does not perform recovery operations |\n| Schedule Management | Evaluates cron expressions, creates scheduled jobs | Passive; waits for leadership |\n| Worker Registration | Accepts new worker registrations | Redirects to current leader |\n\n#### Common Pitfalls\n\n⚠️ **Pitfall: Lease TTL Too Short Causes Leadership Thrashing**\nSetting the lease TTL too aggressively (e.g., 5 seconds) can cause false failovers during temporary network hiccups or garbage collection pauses. The leader temporarily cannot renew its lease, loses leadership, then immediately reclaims it, causing workers to experience multiple leadership changes.\n\n**Solution**: Use a lease TTL of 30 seconds with renewal every 10 seconds, providing tolerance for temporary failures while maintaining sub-30-second failover times.\n\n⚠️ **Pitfall: Stale Leadership Claims After Network Partition**\nA coordinator that was partitioned from etcd but can still communicate with workers might continue acting as leader, unaware that its lease expired and another node claimed leadership.\n\n**Solution**: Implement **fencing tokens** - the leader includes a monotonically increasing token in all job assignments. Workers reject assignments with tokens lower than the highest they've seen, preventing stale leaders from making assignments.\n\n### Worker Registration: Dynamic worker discovery, capacity reporting, and capability matching\n\n**Worker registration** enables dynamic scaling by allowing new workers to join the cluster and existing workers to report their current capacity and capabilities. This creates a live inventory that the coordinator uses for intelligent job assignment decisions.\n\nThe `Worker` data model captures all information needed for coordination:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `ID` | `string` | Unique worker identifier (typically hostname + UUID) |\n| `Address` | `string` | Network address for direct communication (host:port) |\n| `Capacity` | `int` | Maximum number of concurrent jobs this worker can execute |\n| `CurrentJobs` | `int` | Number of jobs currently executing on this worker |\n| `Capabilities` | `[]string` | Tags indicating job types this worker can handle |\n| `LastHeartbeat` | `time.Time` | Timestamp of most recent heartbeat received |\n| `State` | `WorkerState` | Current operational state of the worker |\n| `StartedAt` | `time.Time` | When this worker initially registered |\n| `Metadata` | `map[string]string` | Additional worker-specific information |\n\n**Worker States:**\n\n| State | Meaning | Transition Triggers |\n|-------|---------|-------------------|\n| `AVAILABLE` | Ready to accept new job assignments | Heartbeat received, job completed |\n| `BUSY` | At capacity, cannot accept new jobs | `CurrentJobs >= Capacity` |\n| `UNAVAILABLE` | Failed or gracefully shutting down | Heartbeat timeout, explicit shutdown |\n\n**Registration Process:**\n\n1. **Initial Registration**: Worker sends registration request to coordinator with its capabilities and capacity\n2. **Capability Validation**: Coordinator validates that worker capabilities match known job types\n3. **Worker ID Assignment**: Coordinator assigns unique ID and records worker in coordination storage\n4. **Heartbeat Initiation**: Worker begins sending periodic heartbeats to maintain registration\n5. **Job Eligibility**: Worker becomes eligible for job assignments once registration is confirmed\n\n> **Decision: Pull-Based Job Assignment vs Push-Based Distribution**\n> - **Context**: Workers need to receive job assignments, but network failures can cause assignments to be lost\n> - **Options Considered**: Coordinator pushes jobs to workers, workers poll coordinator for jobs, hybrid push-pull with acknowledgment\n> - **Decision**: Workers poll coordinator for job assignments (pull-based)\n> - **Rationale**: Pull-based assignment is more fault-tolerant because workers control timing and can retry failed requests. Push-based requires complex acknowledgment and retry logic when workers are temporarily unreachable.\n> - **Consequences**: Slightly higher latency for job assignment, but much simpler failure handling and worker autonomy\n\n**Capability Matching:**\n\nJobs include a `RequiredCapabilities` field that must be matched against worker capabilities for assignment eligibility:\n\n| Matching Rule | Example | Behavior |\n|---------------|---------|----------|\n| Exact Match | Job requires `[\"python\", \"gpu\"]`, Worker has `[\"python\", \"gpu\", \"docker\"]` | ✅ Worker eligible |\n| Missing Capability | Job requires `[\"python\", \"gpu\"]`, Worker has `[\"python\", \"docker\"]` | ❌ Worker not eligible |\n| Subset Match | Job requires `[\"python\"]`, Worker has `[\"python\", \"gpu\", \"docker\"]` | ✅ Worker eligible |\n| No Requirements | Job requires `[]`, Worker has any capabilities | ✅ Worker eligible |\n\n![Job Execution Sequence](./diagrams/job-execution-sequence.svg)\n\n### Heartbeat Mechanism: Failure detection through periodic health checks and timeout handling\n\nThe **heartbeat mechanism** provides continuous liveness monitoring that enables rapid failure detection and automatic job recovery. Workers send periodic heartbeat messages to prove they're operational and can continue executing assigned jobs.\n\n**Heartbeat Message Structure:**\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `WorkerID` | `string` | Unique identifier of the sending worker |\n| `Timestamp` | `time.Time` | When this heartbeat was generated |\n| `CurrentJobs` | `int` | Number of jobs currently executing |\n| `LoadAverage` | `float64` | System load indicator (optional) |\n| `FreeMemory` | `int64` | Available memory in bytes (optional) |\n| `Status` | `string` | Worker status message or health indicator |\n\n**Heartbeat Timing Parameters:**\n\n| Parameter | Value | Rationale |\n|-----------|-------|-----------|\n| Heartbeat Interval | 15 seconds | Frequent enough for quick failure detection, infrequent enough to avoid network overhead |\n| Failure Threshold | 45 seconds | Three missed heartbeats before declaring worker failed |\n| Grace Period | 60 seconds | Additional time for job completion during graceful shutdown |\n\nThe coordinator processes heartbeats through this algorithm:\n\n1. **Heartbeat Reception**: Coordinator receives heartbeat message from worker\n2. **Worker Lookup**: Verify worker ID exists in registered worker table\n3. **Timestamp Update**: Update `LastHeartbeat` field with current time\n4. **State Transition**: If worker was `UNAVAILABLE` due to timeout, transition back to `AVAILABLE`\n5. **Load Tracking**: Update `CurrentJobs` count for capacity management\n6. **Response Generation**: Send acknowledgment with current coordinator fencing token\n\n**Failure Detection Process:**\n\n1. **Timeout Scanning**: Coordinator runs background task every 10 seconds scanning all registered workers\n2. **Staleness Check**: Calculate time since last heartbeat for each worker\n3. **Failure Declaration**: Workers with heartbeats older than 45 seconds are marked `UNAVAILABLE`\n4. **Job Recovery Trigger**: Failed workers trigger immediate job reassignment process\n5. **Cleanup Scheduling**: Failed workers are removed from registry after 24 hours of inactivity\n\n> The failure detection algorithm must balance **false positive rate** (healthy workers marked failed due to network delays) against **detection latency** (time to detect actual failures). Our 45-second threshold tolerates temporary network issues while enabling recovery within one minute.\n\n**Graceful Shutdown Protocol:**\n\nWhen workers need to shut down (deployment updates, maintenance), they follow this graceful shutdown sequence:\n\n1. **Shutdown Signal**: Worker receives SIGTERM or shutdown command\n2. **Stop Accepting Jobs**: Worker stops polling coordinator for new job assignments\n3. **Completion Wait**: Worker continues executing current jobs with configurable timeout\n4. **Status Broadcast**: Worker sends heartbeat with status \"SHUTTING_DOWN\"\n5. **Final Heartbeat**: After job completion, worker sends final heartbeat with status \"OFFLINE\"\n6. **Cleanup**: Coordinator removes worker from active registry\n\n| Worker Method | Parameters | Returns | Description |\n|---------------|------------|---------|-------------|\n| `heartbeat()` | `status string, metrics map[string]float64` | `ack HeartbeatAck, err error` | Sends liveness signal with current status |\n| `CanAcceptJob()` | `capabilities []string` | `bool` | Checks if worker can handle job with given requirements |\n| `UpdateHeartbeat()` | `timestamp time.Time, status string` | `error` | Records heartbeat and updates worker state |\n| `IsHealthy()` | `timeout time.Duration` | `bool` | Checks if worker heartbeat is within timeout window |\n\n### Job Recovery: Detecting failed workers and reassigning their in-progress jobs\n\n**Job recovery** ensures that work is never lost when workers fail unexpectedly. When a worker becomes unavailable, all jobs it was executing must be identified and reassigned to healthy workers to maintain system reliability.\n\nThe recovery process addresses several complex scenarios where workers fail at different stages of job execution:\n\n| Failure Scenario | Job State | Recovery Action |\n|-----------------|-----------|-----------------|\n| Worker fails immediately after claiming job | `CLAIMED` | Reset to `PENDING`, make available for reassignment |\n| Worker fails during job execution | `EXECUTING` | Reset to `PENDING`, increment retry count |\n| Worker fails after completion but before reporting | `EXECUTING` | Check for side effects, potentially duplicate execution |\n| Worker recovers before timeout | Any state | Cancel recovery, allow worker to continue |\n\n**Recovery Algorithm:**\n\n1. **Failure Detection**: Coordinator identifies worker as failed due to heartbeat timeout\n2. **Job Query**: Query storage for all jobs with `WorkerID` matching failed worker\n3. **State Analysis**: Examine each job's current state and execution progress\n4. **Fencing Check**: Verify job hasn't completed using external side effect detection\n5. **Job Reset**: Reset job state to `PENDING` and clear worker assignment\n6. **Retry Logic**: Increment `RetryCount` and check against `MaxRetries` limit\n7. **Reassignment**: Make jobs eligible for assignment to healthy workers\n8. **Monitoring**: Log recovery actions for operational visibility\n\n> **Decision: Optimistic Recovery vs Pessimistic Job Fencing**\n> - **Context**: Workers might complete jobs after being declared failed, leading to duplicate execution if jobs are immediately reassigned\n> - **Options Considered**: Immediate reassignment (optimistic), wait period before reassignment (pessimistic), external completion checking\n> - **Decision**: Optimistic recovery with retry limits and idempotency requirements\n> - **Rationale**: Most job failures occur before significant progress, and jobs should be designed for idempotent execution anyway. Waiting introduces unnecessary latency for legitimate failures.\n> - **Consequences**: Possible duplicate execution in edge cases, but much faster recovery for genuine failures\n\n**Fencing Token Mechanism:**\n\nTo prevent **stale worker reports** where a failed worker later reports job completion, the system uses fencing tokens:\n\n| Component | Token Usage | Behavior |\n|-----------|-------------|----------|\n| Job Assignment | Coordinator assigns incrementing token with job | Token written to job record in storage |\n| Worker Execution | Worker includes token in all status updates | Token proves worker has legitimate claim |\n| Completion Reporting | Worker provides token when reporting results | Coordinator rejects reports with wrong token |\n| Recovery Process | New assignment gets new token | Previous worker's reports become invalid |\n\n**Recovery State Machine:**\n\n| Current Job State | Recovery Action | Next State | Reason |\n|------------------|----------------|------------|---------|\n| `CLAIMED` | Reset assignment | `PENDING` | Worker failed before starting execution |\n| `EXECUTING` | Check retry count | `PENDING` or `FAILED` | Worker failed during execution |\n| `COMPLETING` | External verification | `COMPLETED` or `PENDING` | Worker may have finished before failure |\n\n![Failure Recovery Sequence](./diagrams/failure-recovery-sequence.svg)\n\n**Retry Logic During Recovery:**\n\nThe recovery process must decide whether failed jobs should be retried or marked as permanently failed:\n\n```\nif job.RetryCount >= job.MaxRetries:\n    job.State = FAILED\n    job.FailureReason = \"Max retries exceeded after worker failure\"\nelse:\n    job.State = PENDING\n    job.RetryCount += 1\n    job.WorkerID = \"\"\n    job.FencingToken = generateNewToken()\n```\n\n**Recovery Metrics and Monitoring:**\n\n| Metric | Purpose | Alert Threshold |\n|--------|---------|----------------|\n| Jobs Recovered Per Hour | Track system stability | > 100/hour indicates worker instability |\n| Recovery Latency | Time from failure to reassignment | > 2 minutes indicates coordinator issues |\n| Duplicate Executions | Count jobs run multiple times | > 1% indicates timing problems |\n| Recovery Success Rate | Percentage of recovered jobs that complete | < 90% indicates job design issues |\n\n#### Common Pitfalls\n\n⚠️ **Pitfall: Race Condition Between Recovery and Worker Return**\nA worker experiences temporary network partition, coordinator declares it failed and reassigns its jobs, then worker reconnects and tries to report completion of already-reassigned jobs.\n\n**Solution**: Use strict fencing token validation. When jobs are reassigned during recovery, they receive new fencing tokens. The original worker's completion reports include the old token and are rejected.\n\n⚠️ **Pitfall: Infinite Recovery Loop for Consistently Failing Jobs**\nJobs that fail due to invalid input or missing dependencies get repeatedly reassigned to different workers, all of which fail for the same reason, creating an endless recovery cycle.\n\n**Solution**: Implement exponential backoff for job reassignment after recovery. Jobs that fail multiple times across different workers should be delayed longer between retry attempts and eventually moved to a dead letter queue for manual inspection.\n\n### Implementation Guidance\n\nThe worker coordination system requires careful orchestration of multiple Go services with strong consistency guarantees and efficient failure detection. The following implementation provides a production-ready foundation for distributed job scheduling.\n\n**Technology Recommendations:**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Coordination Store | etcd v3 client | etcd with embedded proxy |\n| Leader Election | etcd lease-based | Raft implementation |\n| Inter-node Communication | HTTP REST + JSON | gRPC with Protocol Buffers |\n| Configuration Management | YAML files + env vars | etcd-based dynamic config |\n| Health Monitoring | HTTP health endpoints | Prometheus metrics + alerts |\n| Logging | structured JSON logs | Distributed tracing with Jaeger |\n\n**Recommended File Structure:**\n\n```\ninternal/coordinator/\n  coordinator.go           ← main coordinator logic and leader election\n  coordinator_test.go      ← coordinator unit tests\n  worker_manager.go        ← worker registration and heartbeat handling\n  worker_manager_test.go   ← worker management tests\n  job_recovery.go          ← failed worker job recovery logic\n  job_recovery_test.go     ← recovery logic tests\n  election.go              ← etcd-based leader election\n  election_test.go         ← leader election tests\n  fencing.go               ← token generation and validation\n  fencing_test.go          ← fencing mechanism tests\n\ninternal/worker/\n  worker.go                ← worker node implementation\n  worker_test.go           ← worker unit tests\n  heartbeat.go             ← heartbeat and health reporting\n  heartbeat_test.go        ← heartbeat mechanism tests\n  executor.go              ← job execution logic\n  executor_test.go         ← execution tests\n\ninternal/etcd/\n  client.go                ← etcd client wrapper with retries\n  client_test.go           ← etcd integration tests\n  lease.go                 ← lease management utilities\n  watch.go                 ← etcd watch helper functions\n\npkg/coordination/\n  types.go                 ← shared types for coordination messages\n  constants.go             ← timing constants and configuration\n```\n\n**Core Coordinator Infrastructure (COMPLETE):**\n\n```go\npackage coordinator\n\nimport (\n    \"context\"\n    \"encoding/json\"\n    \"fmt\"\n    \"log\"\n    \"sync\"\n    \"time\"\n\n    clientv3 \"go.etcd.io/etcd/client/v3\"\n    \"go.etcd.io/etcd/client/v3/concurrency\"\n)\n\n// ETCDConfig holds etcd connection configuration\ntype ETCDConfig struct {\n    Endpoints   []string      `yaml:\"endpoints\"`\n    DialTimeout time.Duration `yaml:\"dial_timeout\"`\n    Username    string        `yaml:\"username\"`\n    Password    string        `yaml:\"password\"`\n}\n\n// CoordinatorConfig holds coordinator configuration\ntype CoordinatorConfig struct {\n    NodeID              string        `yaml:\"node_id\"`\n    ElectionPrefix      string        `yaml:\"election_prefix\"`\n    LeaseTimeout        time.Duration `yaml:\"lease_timeout\"`\n    HeartbeatInterval   time.Duration `yaml:\"heartbeat_interval\"`\n    FailureThreshold    time.Duration `yaml:\"failure_threshold\"`\n    RecoveryInterval    time.Duration `yaml:\"recovery_interval\"`\n}\n\n// Coordinator manages distributed job scheduling coordination\ntype Coordinator struct {\n    config       CoordinatorConfig\n    etcdClient   *clientv3.Client\n    session      *concurrency.Session\n    election     *concurrency.Election\n    \n    // Leadership state\n    isLeader     bool\n    leaderMux    sync.RWMutex\n    fencingToken int64\n    \n    // Worker management\n    workers      map[string]*Worker\n    workerMux    sync.RWMutex\n    \n    // Background tasks\n    ctx          context.Context\n    cancel       context.CancelFunc\n    wg           sync.WaitGroup\n}\n\n// NewCoordinator creates a new coordinator instance with etcd backend\nfunc NewCoordinator(config CoordinatorConfig, etcdConfig ETCDConfig) (*Coordinator, error) {\n    etcdClient, err := clientv3.New(clientv3.Config{\n        Endpoints:   etcdConfig.Endpoints,\n        DialTimeout: etcdConfig.DialTimeout,\n        Username:    etcdConfig.Username,\n        Password:    etcdConfig.Password,\n    })\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to connect to etcd: %w\", err)\n    }\n\n    session, err := concurrency.NewSession(etcdClient, \n        concurrency.WithTTL(int(config.LeaseTimeout.Seconds())))\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to create etcd session: %w\", err)\n    }\n\n    ctx, cancel := context.WithCancel(context.Background())\n    \n    return &Coordinator{\n        config:     config,\n        etcdClient: etcdClient,\n        session:    session,\n        election:   concurrency.NewElection(session, config.ElectionPrefix),\n        workers:    make(map[string]*Worker),\n        ctx:        ctx,\n        cancel:     cancel,\n    }, nil\n}\n\n// Start begins coordinator operations including leader election\nfunc (c *Coordinator) Start() error {\n    log.Printf(\"Starting coordinator %s\", c.config.NodeID)\n    \n    // Start leader election\n    c.wg.Add(1)\n    go c.runLeaderElection()\n    \n    // Start worker monitoring\n    c.wg.Add(1)\n    go c.runWorkerMonitoring()\n    \n    // Start job recovery\n    c.wg.Add(1)\n    go c.runJobRecovery()\n    \n    return nil\n}\n\n// Stop gracefully shuts down coordinator\nfunc (c *Coordinator) Stop() error {\n    log.Printf(\"Stopping coordinator %s\", c.config.NodeID)\n    \n    c.cancel()\n    c.wg.Wait()\n    \n    if c.session != nil {\n        c.session.Close()\n    }\n    \n    if c.etcdClient != nil {\n        c.etcdClient.Close()\n    }\n    \n    return nil\n}\n\n// IsLeader returns current leadership status\nfunc (c *Coordinator) IsLeader() bool {\n    c.leaderMux.RLock()\n    defer c.leaderMux.RUnlock()\n    return c.isLeader\n}\n\n// GetFencingToken returns current fencing token for job assignments\nfunc (c *Coordinator) GetFencingToken() int64 {\n    c.leaderMux.RLock()\n    defer c.leaderMux.RUnlock()\n    return c.fencingToken\n}\n```\n\n**Worker Heartbeat Infrastructure (COMPLETE):**\n\n```go\npackage worker\n\nimport (\n    \"context\"\n    \"encoding/json\"\n    \"fmt\"\n    \"log\"\n    \"net/http\"\n    \"sync\"\n    \"time\"\n)\n\n// WorkerConfig holds worker configuration\ntype WorkerConfig struct {\n    ID                 string            `yaml:\"id\"`\n    Address            string            `yaml:\"address\"`\n    Capacity           int               `yaml:\"capacity\"`\n    Capabilities       []string          `yaml:\"capabilities\"`\n    CoordinatorAddress string            `yaml:\"coordinator_address\"`\n    HeartbeatInterval  time.Duration     `yaml:\"heartbeat_interval\"`\n    ShutdownTimeout    time.Duration     `yaml:\"shutdown_timeout\"`\n    Metadata           map[string]string `yaml:\"metadata\"`\n}\n\n// Worker represents a job execution node\ntype Worker struct {\n    config        WorkerConfig\n    httpClient    *http.Client\n    \n    // Job execution\n    currentJobs   map[string]*Job\n    jobMux        sync.RWMutex\n    \n    // Lifecycle management\n    ctx           context.Context\n    cancel        context.CancelFunc\n    wg            sync.WaitGroup\n    isShuttingDown bool\n    shutdownMux   sync.RWMutex\n}\n\n// NewWorker creates a new worker instance\nfunc NewWorker(config WorkerConfig) *Worker {\n    ctx, cancel := context.WithCancel(context.Background())\n    \n    return &Worker{\n        config: config,\n        httpClient: &http.Client{\n            Timeout: 30 * time.Second,\n        },\n        currentJobs: make(map[string]*Job),\n        ctx:         ctx,\n        cancel:      cancel,\n    }\n}\n\n// Start begins worker operations including registration and heartbeating\nfunc (w *Worker) Start() error {\n    log.Printf(\"Starting worker %s\", w.config.ID)\n    \n    // Register with coordinator\n    if err := w.registerWithCoordinator(); err != nil {\n        return fmt.Errorf(\"failed to register: %w\", err)\n    }\n    \n    // Start heartbeat loop\n    w.wg.Add(1)\n    go w.runHeartbeatLoop()\n    \n    // Start job polling loop\n    w.wg.Add(1)\n    go w.runJobPollingLoop()\n    \n    return nil\n}\n\n// Stop gracefully shuts down worker\nfunc (w *Worker) Stop() error {\n    log.Printf(\"Stopping worker %s\", w.config.ID)\n    \n    w.shutdownMux.Lock()\n    w.isShuttingDown = true\n    w.shutdownMux.Unlock()\n    \n    // Cancel context to stop background loops\n    w.cancel()\n    \n    // Wait for current jobs to complete with timeout\n    done := make(chan struct{})\n    go func() {\n        w.wg.Wait()\n        close(done)\n    }()\n    \n    select {\n    case <-done:\n        log.Printf(\"Worker %s stopped gracefully\", w.config.ID)\n    case <-time.After(w.config.ShutdownTimeout):\n        log.Printf(\"Worker %s shutdown timeout, forcing stop\", w.config.ID)\n    }\n    \n    return nil\n}\n\n// HeartbeatMessage represents worker heartbeat data\ntype HeartbeatMessage struct {\n    WorkerID     string            `json:\"worker_id\"`\n    Timestamp    time.Time         `json:\"timestamp\"`\n    CurrentJobs  int               `json:\"current_jobs\"`\n    Status       string            `json:\"status\"`\n    Metadata     map[string]string `json:\"metadata\"`\n}\n\n// registerWithCoordinator sends initial registration request\nfunc (w *Worker) registerWithCoordinator() error {\n    registrationData := map[string]interface{}{\n        \"worker_id\":    w.config.ID,\n        \"address\":      w.config.Address,\n        \"capacity\":     w.config.Capacity,\n        \"capabilities\": w.config.Capabilities,\n        \"metadata\":     w.config.Metadata,\n    }\n    \n    // Implementation continues with HTTP request to coordinator...\n    return nil\n}\n\n// GetCurrentJobCount returns number of jobs currently executing\nfunc (w *Worker) GetCurrentJobCount() int {\n    w.jobMux.RLock()\n    defer w.jobMux.RUnlock()\n    return len(w.currentJobs)\n}\n\n// CanAcceptJob checks if worker can handle job with given requirements\nfunc (w *Worker) CanAcceptJob(requiredCapabilities []string) bool {\n    w.shutdownMux.RLock()\n    defer w.shutdownMux.RUnlock()\n    \n    if w.isShuttingDown {\n        return false\n    }\n    \n    if w.GetCurrentJobCount() >= w.config.Capacity {\n        return false\n    }\n    \n    // Check capability matching\n    workerCaps := make(map[string]bool)\n    for _, cap := range w.config.Capabilities {\n        workerCaps[cap] = true\n    }\n    \n    for _, required := range requiredCapabilities {\n        if !workerCaps[required] {\n            return false\n        }\n    }\n    \n    return true\n}\n```\n\n**Core Logic Skeleton for Leader Election:**\n\n```go\n// runLeaderElection handles leader election and maintains leadership\nfunc (c *Coordinator) runLeaderElection() {\n    defer c.wg.Done()\n    \n    for {\n        select {\n        case <-c.ctx.Done():\n            return\n        default:\n            // TODO 1: Campaign for leadership using etcd election\n            // Use: c.election.Campaign(c.ctx, c.config.NodeID)\n            \n            // TODO 2: If campaign succeeds, set leadership state and generate new fencing token\n            // Set: c.isLeader = true, c.fencingToken = time.Now().UnixNano()\n            \n            // TODO 3: Start leadership maintenance loop\n            // Monitor election key and renew session lease\n            \n            // TODO 4: Handle leadership loss detection\n            // Watch for election key changes or session expiration\n            \n            // TODO 5: Clean up leadership state when stepping down\n            // Set: c.isLeader = false, clear cached state\n        }\n    }\n}\n\n// runWorkerMonitoring periodically checks worker health and removes failed workers\nfunc (c *Coordinator) runWorkerMonitoring() {\n    defer c.wg.Done()\n    \n    ticker := time.NewTicker(10 * time.Second)\n    defer ticker.Stop()\n    \n    for {\n        select {\n        case <-c.ctx.Done():\n            return\n        case <-ticker.C:\n            // TODO 1: Check if this node is the leader\n            // Skip monitoring if not leader to avoid conflicts\n            \n            // TODO 2: Iterate through all registered workers\n            // Get worker list from c.workers map with proper locking\n            \n            // TODO 3: Check each worker's last heartbeat timestamp\n            // Compare time.Since(worker.LastHeartbeat) against c.config.FailureThreshold\n            \n            // TODO 4: Mark workers as UNAVAILABLE if heartbeat is stale\n            // Update worker.State and log failure detection\n            \n            // TODO 5: Trigger job recovery for newly failed workers\n            // Call job recovery process for workers that just became unavailable\n        }\n    }\n}\n\n// ProcessWorkerHeartbeat handles incoming heartbeat from worker\nfunc (c *Coordinator) ProcessWorkerHeartbeat(heartbeat *HeartbeatMessage) error {\n    // TODO 1: Validate heartbeat message fields\n    // Check that WorkerID is non-empty and timestamp is recent\n    \n    // TODO 2: Acquire worker registry lock\n    // Use c.workerMux.Lock() for exclusive access\n    \n    // TODO 3: Look up worker in registry\n    // Find worker by heartbeat.WorkerID in c.workers map\n    \n    // TODO 4: Update worker heartbeat timestamp and status\n    // Set LastHeartbeat = time.Now(), update CurrentJobs count\n    \n    // TODO 5: Transition worker state if it was previously UNAVAILABLE\n    // If worker.State == UNAVAILABLE, set to AVAILABLE\n    \n    // TODO 6: Return heartbeat acknowledgment with current fencing token\n    // Include c.GetFencingToken() in response for worker validation\n    \n    return nil\n}\n```\n\n**Core Logic Skeleton for Job Recovery:**\n\n```go\n// runJobRecovery periodically checks for jobs from failed workers and reassigns them\nfunc (c *Coordinator) runJobRecovery() {\n    defer c.wg.Done()\n    \n    ticker := time.NewTicker(c.config.RecoveryInterval)\n    defer ticker.Stop()\n    \n    for {\n        select {\n        case <-c.ctx.Done():\n            return\n        case <-ticker.C:\n            // TODO 1: Check if this node is the leader\n            // Only leader should perform job recovery\n            \n            // TODO 2: Find all jobs assigned to UNAVAILABLE workers\n            // Query storage for jobs where WorkerID matches failed workers\n            \n            // TODO 3: Group jobs by their current state\n            // Handle CLAIMED, EXECUTING, and COMPLETING states differently\n            \n            // TODO 4: Reset job assignments and increment retry counts\n            // Clear WorkerID, generate new FencingToken, increment RetryCount\n            \n            // TODO 5: Check retry limits and mark permanently failed jobs\n            // If RetryCount >= MaxRetries, set State = FAILED\n            \n            // TODO 6: Make recovered jobs available for reassignment\n            // Set State = PENDING for jobs that can be retried\n        }\n    }\n}\n\n// RecoverJobsFromWorker handles job recovery when a specific worker fails\nfunc (c *Coordinator) RecoverJobsFromWorker(workerID string) error {\n    // TODO 1: Query storage for all jobs assigned to this worker\n    // Use storage query: WHERE WorkerID = workerID AND State IN (CLAIMED, EXECUTING)\n    \n    // TODO 2: For each job, determine recovery action based on current state\n    // CLAIMED jobs can be immediately reset, EXECUTING jobs need retry logic\n    \n    // TODO 3: Generate new fencing tokens for recovered jobs\n    // Use time.Now().UnixNano() + job sequence for uniqueness\n    \n    // TODO 4: Update job records with recovery information\n    // Clear WorkerID, set new FencingToken, increment RetryCount\n    \n    // TODO 5: Log recovery actions for operational monitoring\n    // Include workerID, jobID, old state, new state in log messages\n    \n    // TODO 6: Update job queue to make recovered jobs available\n    // Call priority queue methods to reinsert jobs for assignment\n    \n    return nil\n}\n\n// ValidateFencingToken checks if worker has authority to report on job\nfunc (c *Coordinator) ValidateFencingToken(jobID string, workerID string, token string) (bool, error) {\n    // TODO 1: Look up current job record in storage\n    // Get job by jobID and check current WorkerID and FencingToken\n    \n    // TODO 2: Verify worker ID matches job assignment\n    // Return false if job.WorkerID != workerID\n    \n    // TODO 3: Compare provided token with stored token\n    // Return false if job.FencingToken != token\n    \n    // TODO 4: Check if job is in a state that accepts worker reports\n    // Only CLAIMED and EXECUTING jobs should accept status updates\n    \n    // TODO 5: Return validation result\n    // true = worker has authority, false = stale or invalid token\n    \n    return false, nil\n}\n```\n\n**Language-Specific Implementation Hints:**\n\n- **etcd Client**: Use `go.etcd.io/etcd/client/v3` for robust etcd integration with automatic retries and connection pooling\n- **Context Cancellation**: Use `context.WithCancel()` for graceful shutdown coordination across all goroutines\n- **Atomic Operations**: Use `sync.RWMutex` for worker registry access and `sync.atomic` for fencing token generation\n- **Time Handling**: Always use `time.Now().UTC()` for consistent timestamps across distributed nodes\n- **Error Wrapping**: Use `fmt.Errorf(\"context: %w\", err)` for error chain preservation in distributed debugging\n- **Structured Logging**: Use `log/slog` or similar for JSON-structured logs with correlation IDs across services\n\n**Milestone Checkpoint:**\n\nAfter implementing worker coordination, verify the system with these tests:\n\n1. **Leader Election Test**: `go run cmd/coordinator/main.go` on three separate machines - exactly one should claim leadership, others should remain candidates\n2. **Worker Registration**: Start workers with different capabilities - they should appear in coordinator logs as registered and healthy\n3. **Failure Detection**: Kill a worker process - coordinator should detect failure within 60 seconds and log worker state change\n4. **Job Recovery**: Submit jobs, kill workers mid-execution - jobs should be reassigned to healthy workers within recovery interval\n5. **Graceful Shutdown**: Send SIGTERM to worker - it should complete current jobs before exiting, coordinator should clean up registration\n\nExpected behavior: Workers register successfully, heartbeats maintain registration, leader election produces exactly one leader, failed workers trigger job recovery within 2 minutes, graceful shutdown completes current work.\n\n\n## Interactions and Data Flow\n\n> **Milestone(s):** This section synthesizes all three milestones by defining the communication patterns and message flows that connect the cron parser (Milestone 1), priority queue (Milestone 2), and worker coordination (Milestone 3) into a cohesive distributed system.\n\n### Mental Model: Orchestra Performance\n\nThink of the distributed job scheduler's interactions like a symphony orchestra performance. The **coordinator** acts as the conductor, maintaining the tempo and ensuring all musicians (workers) play their parts harmoniously. **Job submission** is like sheet music being distributed to the orchestra - each piece has timing requirements (cron expressions), priority levels (solo vs. background), and specific instructions (job payload). The **execution flow** resembles the actual performance where musicians claim their parts, play them according to the conductor's timing, and signal completion. **Coordination messages** are the conductor's gestures and the musicians' acknowledgments that keep everyone synchronized, detect when someone misses their cue, and recover gracefully from mistakes.\n\nJust as an orchestra must handle musicians arriving late, instruments breaking, or the conductor temporarily stepping away, our distributed scheduler must gracefully manage worker failures, network partitions, and leadership changes while ensuring the \"performance\" (job execution) continues without missing critical notes.\n\n### Job Submission Flow\n\nThe job submission flow represents the journey from external job creation through validation, scheduling, and queue insertion. This flow must handle duplicate detection, priority assignment, and delayed scheduling while maintaining consistency across the distributed system.\n\n#### Submission Process Overview\n\nThe job submission process begins when an external client creates a job request and continues through multiple validation and enrichment stages before the job becomes eligible for worker assignment. The process involves three primary actors: the **client** (job submitter), the **scheduler service** (API gateway and validation), and the **priority queue** (storage and ordering).\n\n> **Decision: Synchronous vs Asynchronous Submission API**\n> - **Context**: Clients need feedback about job acceptance, but synchronous processing could create bottlenecks under high load\n> - **Options Considered**: Fully synchronous processing, fire-and-forget async, async with acknowledgment\n> - **Decision**: Synchronous validation and deduplication with asynchronous scheduling\n> - **Rationale**: Clients get immediate feedback about validation errors and duplicates, but scheduling decisions happen asynchronously to prevent blocking\n> - **Consequences**: Enables immediate error handling while maintaining high throughput; requires careful state management for partially processed jobs\n\nThe submission flow follows this sequence of operations:\n\n1. **Client Request Validation**: The scheduler service validates the incoming job request against schema requirements, checking that required fields are present and properly formatted.\n\n2. **Cron Expression Parsing**: The system parses and validates the cron expression using the parser from Milestone 1, calculating the initial `ScheduledAt` timestamp for the job's first execution.\n\n3. **Idempotency Check**: The deduplication system checks if a job with the same `IdempotencyKey` already exists, preventing duplicate submissions from causing redundant work.\n\n4. **Job Enrichment**: The system enriches the job with metadata including creation timestamps, generated unique IDs, and computed priority scores.\n\n5. **Queue Insertion**: The priority queue atomically inserts the job, positioning it correctly based on priority and scheduled execution time.\n\n6. **Response Generation**: The scheduler service returns confirmation to the client with the job ID and next execution time.\n\n#### Submission Message Formats\n\n| Message Type | Direction | Format | Description |\n|--------------|-----------|---------|-------------|\n| JobSubmissionRequest | Client → Scheduler | JSON over HTTP | Contains job definition, cron expression, and metadata |\n| JobSubmissionResponse | Scheduler → Client | JSON over HTTP | Returns job ID, validation status, and next execution time |\n| QueueInsertionMessage | Scheduler → Queue | Internal struct | Enriched job data for priority queue insertion |\n| DeduplicationQuery | Scheduler → Storage | Redis command | Idempotency key lookup for duplicate detection |\n\nThe `JobSubmissionRequest` message contains all information necessary to create and schedule a job:\n\n| Field | Type | Required | Description |\n|-------|------|----------|-------------|\n| Name | string | Yes | Human-readable job identifier |\n| CronExpression | string | Yes | Valid cron timing specification |\n| Payload | map[string]string | Yes | Job-specific execution parameters |\n| Priority | int | No | Priority level (default: 0) |\n| IdempotencyKey | string | No | Client-provided deduplication key |\n| MaxRetries | int | No | Maximum retry attempts (default: 3) |\n| Capabilities | []string | No | Required worker capabilities |\n\n#### Deduplication Strategy Details\n\nThe job submission flow implements sophisticated deduplication to prevent clients from accidentally creating duplicate work. The system uses a multi-layered approach combining idempotency keys and content hashing.\n\n> **Decision: Idempotency Key vs Content Hash for Deduplication**\n> - **Context**: Need to prevent duplicate jobs while supporting both intentional and accidental resubmission scenarios\n> - **Options Considered**: Client-provided keys only, automatic content hashing, hybrid approach\n> - **Decision**: Primary idempotency keys with fallback content hashing\n> - **Rationale**: Gives clients explicit control while providing automatic protection; content hashing catches unintentional duplicates\n> - **Consequences**: More complex deduplication logic but better user experience and data integrity\n\n| Deduplication Method | When Applied | Scope | Duration |\n|---------------------|--------------|-------|----------|\n| Idempotency Key | Client provides explicit key | Exact key match | Configurable TTL |\n| Content Hash | Automatic for all jobs | Identical payload + schedule | 24 hours default |\n| Name + Schedule | Fallback protection | Same name and cron pattern | Until job completes |\n\nWhen deduplication detects an existing job, the system's response depends on the existing job's state:\n\n| Existing Job State | Response Action | HTTP Status | Message to Client |\n|-------------------|----------------|-------------|-------------------|\n| PENDING or CLAIMED | Return existing job | 200 OK | Job already exists with ID |\n| EXECUTING | Return existing job | 200 OK | Job currently executing |\n| COMPLETED | Create new job | 201 Created | Previous job completed, created new |\n| FAILED | Create new job | 201 Created | Previous job failed, created retry |\n\n#### Error Handling in Submission Flow\n\nThe submission flow must gracefully handle various error conditions while providing clear feedback to clients about what went wrong and how to fix it.\n\n| Error Condition | Detection Point | Recovery Action | Client Response |\n|----------------|-----------------|-----------------|-----------------|\n| Invalid cron expression | Parsing stage | Reject with detailed error | 400 Bad Request with parse details |\n| Missing required fields | Validation stage | Reject with field list | 400 Bad Request with missing fields |\n| Storage unavailable | Queue insertion | Retry with backoff | 503 Service Unavailable |\n| Duplicate job detected | Deduplication check | Return existing job | 200 OK with existing job ID |\n| Priority out of range | Validation stage | Clamp to valid range | 200 OK with adjusted priority |\n\n#### Common Pitfalls in Job Submission\n\n⚠️ **Pitfall: Race Condition in Deduplication**\nDuring high-frequency submissions, two identical jobs might pass the deduplication check simultaneously if the check and insertion aren't atomic. This occurs because the deduplication query and queue insertion happen in separate operations, creating a window where duplicate jobs can both appear to be unique.\n\nThe fix involves using atomic compare-and-set operations or database transactions to ensure the deduplication check and job insertion happen atomically. In Redis, this means using a Lua script that performs both operations as a single atomic unit.\n\n⚠️ **Pitfall: Timezone Confusion in Scheduled Jobs**\nClients often submit cron expressions assuming local timezone interpretation, but the scheduler stores everything in UTC. This causes jobs to run at unexpected times, especially around daylight saving time transitions.\n\nThe solution requires explicit timezone handling in the submission API, either requiring clients to specify timezones explicitly or documenting that all times are treated as UTC. The cron parser should normalize all scheduled times to UTC immediately upon submission.\n\n### Job Execution Flow\n\nThe job execution flow orchestrates the complex dance between coordinators and workers to ensure jobs run exactly once at the correct time with proper failure handling. This flow represents the core operational behavior of the distributed scheduler.\n\n![System Architecture Overview](./diagrams/system-architecture.svg)\n\n![Job Execution Sequence](./diagrams/job-execution-sequence.svg)\n\n#### Execution Process Overview\n\nJob execution involves four distinct phases: **job readiness detection**, **worker assignment**, **execution monitoring**, and **completion handling**. Each phase has specific responsibilities and failure modes that must be handled gracefully to maintain system reliability.\n\nThe execution process operates continuously across multiple components:\n\n1. **Promotion Phase**: The scheduler periodically scans for delayed jobs that have become eligible for execution, moving them from the delayed queue to the active priority queue.\n\n2. **Assignment Phase**: Available workers poll the coordinator for work, and the coordinator atomically assigns the highest-priority job to the most suitable worker.\n\n3. **Execution Phase**: The assigned worker executes the job while sending periodic heartbeats to maintain its lease on the work.\n\n4. **Reporting Phase**: The worker reports execution results back to the coordinator, which updates job state and triggers retry logic if necessary.\n\n> **Decision: Pull vs Push Job Assignment Model**\n> - **Context**: Workers need job assignments, but the coordinator must maintain control over job distribution and prevent duplicate assignments\n> - **Options Considered**: Coordinator pushes jobs to workers, workers pull jobs from coordinator, hybrid approach with notifications\n> - **Decision**: Worker-initiated pull model with coordinator-managed assignment\n> - **Rationale**: Pull model gives workers control over their capacity while preventing coordinator from overwhelming failed workers; atomic assignment prevents duplicates\n> - **Consequences**: Requires worker polling but provides better load balancing and failure isolation; adds latency but improves reliability\n\n#### Job State Machine During Execution\n\nJobs transition through multiple states during the execution flow, with specific rules governing valid transitions and the actions triggered by each state change.\n\n| Current State | Triggering Event | Next State | Actions Taken | Responsible Component |\n|---------------|------------------|------------|---------------|----------------------|\n| PENDING | Promotion timer fires | PENDING | Move to active queue | Scheduler service |\n| PENDING | Worker claims job | CLAIMED | Set WorkerID, ClaimedAt | Priority queue |\n| CLAIMED | Worker starts execution | EXECUTING | Set FencingToken | Worker |\n| EXECUTING | Worker reports success | COMPLETED | Set CompletedAt, cleanup | Coordinator |\n| EXECUTING | Worker reports failure | FAILED | Increment RetryCount | Coordinator |\n| FAILED | Retry available | PENDING | Reset state, new schedule | Coordinator |\n| FAILED | Max retries exceeded | FAILED | Final cleanup | Coordinator |\n| CLAIMED/EXECUTING | Worker heartbeat timeout | PENDING | Clear assignment | Coordinator |\n\n#### Worker Job Claiming Process\n\nThe job claiming process represents the critical handoff from the priority queue to an available worker. This process must be atomic to prevent duplicate assignments while being efficient enough to support high-throughput job processing.\n\nThe claiming process follows these detailed steps:\n\n1. **Worker Availability Check**: The worker evaluates its current capacity, checking that `CurrentJobs < Capacity` and that it possesses any required capabilities for available jobs.\n\n2. **Claim Request Submission**: The worker sends a claim request to the coordinator containing its worker ID, current load information, and capability list.\n\n3. **Coordinator Job Selection**: The coordinator queries the priority queue for the highest-priority job that matches the worker's capabilities and hasn't exceeded its retry limits.\n\n4. **Atomic Assignment**: The coordinator uses a compare-and-swap operation to atomically assign the job to the worker, setting the `WorkerID` and generating a unique `FencingToken`.\n\n5. **Lease Establishment**: The system records the claim time and establishes a lease timeout, after which the job becomes eligible for reassignment if no progress is reported.\n\n6. **Response Transmission**: The coordinator returns the claimed job to the worker along with the fencing token that the worker must include in all subsequent operations on this job.\n\n#### Fencing Token Mechanism\n\nThe fencing token system prevents race conditions and ensures that only the legitimately assigned worker can report results for a job, even in the presence of network delays and worker failures.\n\n> **Decision: Fencing Token Implementation Strategy**\n> - **Context**: Workers might report results after their lease has expired and the job has been reassigned to another worker\n> - **Options Considered**: Monotonic sequence numbers, timestamp-based tokens, UUID-based tokens\n> - **Decision**: Monotonic sequence numbers with coordinator-managed generation\n> - **Rationale**: Sequence numbers provide clear ordering for conflict resolution; coordinator generation ensures uniqueness and prevents conflicts\n> - **Consequences**: Requires coordinator state for token generation but provides strongest consistency guarantees\n\n| Token Component | Purpose | Generation Strategy | Validation Method |\n|----------------|---------|-------------------|-------------------|\n| Job ID | Identifies specific job | Client or system generated | Database lookup |\n| Worker ID | Identifies assigned worker | Worker registration | Active worker registry |\n| Sequence Number | Prevents stale reports | Monotonic increment | Compare with stored value |\n| Assignment Time | Establishes lease validity | Coordinator timestamp | Compare with current time |\n\nThe fencing token validation process works as follows:\n\n1. **Token Extraction**: The coordinator extracts the fencing token from the worker's completion report\n2. **Job State Verification**: The system verifies that the job exists and is in a reportable state (`CLAIMED` or `EXECUTING`)\n3. **Worker Authority Check**: The system confirms that the reporting worker matches the assigned worker ID\n4. **Sequence Validation**: The system verifies that the sequence number matches the most recent assignment token\n5. **Lease Validity Check**: The system confirms that the assignment hasn't expired based on the heartbeat timeout\n\n#### Execution Monitoring and Heartbeats\n\nDuring job execution, the worker must maintain regular communication with the coordinator to prove it's making progress and hasn't failed. This monitoring system enables rapid detection of worker failures and prevents jobs from being lost.\n\n| Heartbeat Component | Purpose | Frequency | Timeout Action |\n|--------------------|---------|-----------|----------------|\n| Worker Liveness | Proves worker is responsive | Every 30 seconds | Mark worker UNAVAILABLE |\n| Job Progress | Shows execution is proceeding | Every 60 seconds | Reassign job to new worker |\n| Capacity Update | Reports current job load | With each heartbeat | Update job assignment eligibility |\n| Capability Status | Reports available features | On change or every 5 minutes | Update job matching criteria |\n\nThe heartbeat message format includes comprehensive worker state information:\n\n| Field | Type | Description | Required |\n|-------|------|-------------|----------|\n| WorkerID | string | Unique worker identifier | Yes |\n| Timestamp | time.Time | When heartbeat was generated | Yes |\n| CurrentJobs | int | Number of jobs currently executing | Yes |\n| ExecutingJobIDs | []string | List of job IDs in progress | Yes |\n| Status | string | Worker operational status | Yes |\n| Capabilities | []string | Currently available worker capabilities | No |\n| Metadata | map[string]string | Additional worker information | No |\n\n#### Retry Logic and Failure Handling\n\nWhen jobs fail or workers become unresponsive, the scheduler implements sophisticated retry logic that balances rapid recovery with system stability.\n\n> **Decision: Exponential Backoff vs Fixed Interval Retries**\n> - **Context**: Failed jobs need rescheduling, but immediate retries might overwhelm struggling resources\n> - **Options Considered**: Immediate retry, fixed delay, exponential backoff, jittered exponential backoff\n> - **Decision**: Jittered exponential backoff with maximum delay cap\n> - **Rationale**: Exponential backoff reduces load on struggling resources; jitter prevents thundering herd; cap prevents indefinite delays\n> - **Consequences**: More complex scheduling logic but better system stability and recovery characteristics\n\n| Retry Attempt | Delay Calculation | Jitter Range | Maximum Delay |\n|---------------|------------------|--------------|---------------|\n| 1 | 2^1 = 2 seconds | ±50% (1-3 seconds) | 2 minutes |\n| 2 | 2^2 = 4 seconds | ±50% (2-6 seconds) | 2 minutes |\n| 3 | 2^3 = 8 seconds | ±50% (4-12 seconds) | 2 minutes |\n| 4+ | 2^4 = 16 seconds | ±50% (8-24 seconds) | 2 minutes |\n\nThe retry system categorizes failures into different types with distinct handling strategies:\n\n| Failure Type | Cause | Retry Strategy | Special Handling |\n|-------------|-------|----------------|------------------|\n| Transient Network | Connection timeout | Immediate retry | None |\n| Resource Exhaustion | Out of memory/disk | Exponential backoff | Route to different worker |\n| Logic Error | Invalid job payload | No retry | Send to dead letter queue |\n| Worker Crash | Process termination | Exponential backoff | Reassign to healthy worker |\n| Coordinator Failure | Leadership change | Wait for leader election | Resume after new leader elected |\n\n#### Common Pitfalls in Job Execution\n\n⚠️ **Pitfall: Duplicate Execution During Worker Recovery**\nWhen a worker fails during job execution, the coordinator reassigns the job to a new worker. However, if the original worker recovers and completes the job, both workers might report completion, leading to duplicate processing or inconsistent state.\n\nThis occurs because network partitions can make a worker appear failed when it's actually still processing. The worker continues execution while the coordinator reassigns the job elsewhere. The fencing token mechanism prevents this by ensuring only the worker with the current token can successfully report results.\n\n⚠️ **Pitfall: Heartbeat Timeout During Long-Running Jobs**\nJobs that take longer than the heartbeat timeout will be reassigned to new workers even though the original worker is still making progress. This creates wasteful duplicate work and can cause resource contention.\n\nThe solution involves implementing job progress heartbeats separate from worker liveness heartbeats. Workers executing long jobs should send periodic progress updates that extend the job lease without requiring full job completion.\n\n⚠️ **Pitfall: Lost Jobs During Coordinator Failover**\nWhen the coordinator fails during job assignment, jobs might be claimed by workers but not properly recorded in the persistent store. These jobs exist only in coordinator memory and are lost during failover.\n\nPrevention requires ensuring all job state changes are persisted before sending responses to workers. The job assignment must be a transaction that atomically updates both the job state and the worker assignment records.\n\n### Coordination Messages\n\nThe coordination message system enables distributed operation by facilitating leader election, worker registration, failure detection, and job assignment across the scheduler cluster. These messages form the nervous system of the distributed scheduler.\n\n#### Message Categories and Purposes\n\nCoordination messages fall into four primary categories, each serving a specific aspect of distributed system management:\n\n| Category | Purpose | Frequency | Reliability Requirements |\n|----------|---------|-----------|-------------------------|\n| Leadership | Leader election and status | On leadership change | Strong consistency required |\n| Registration | Worker join/leave cluster | On worker lifecycle events | At-least-once delivery |\n| Heartbeat | Failure detection and health monitoring | Every 30-60 seconds | Best-effort with timeout detection |\n| Assignment | Job distribution and result reporting | Per job execution | Exactly-once with fencing |\n\n#### Leader Election Messages\n\nLeader election messages coordinate the selection and maintenance of a single coordinator node responsible for job assignment and worker management. The election process must handle network partitions and prevent split-brain scenarios.\n\n> **Decision: Raft vs ETCD vs Custom Leader Election**\n> - **Context**: Need robust leader election that handles network partitions and prevents split-brain scenarios\n> - **Options Considered**: Custom implementation, Raft consensus library, ETCD-based election\n> - **Decision**: ETCD-based leader election with lease mechanism\n> - **Rationale**: ETCD provides battle-tested consensus with lease-based leadership that automatically handles failures; reduces implementation complexity\n> - **Consequences**: External dependency on ETCD but significantly more reliable than custom implementation; automatic failover and split-brain prevention\n\n| Message Type | Direction | Trigger | Contents |\n|-------------|-----------|---------|----------|\n| CandidateAnnouncement | Node → ETCD | Leadership vacancy | Node ID, capabilities, priority |\n| LeadershipClaim | ETCD → Nodes | Election completion | Leader node ID, lease expiration |\n| LeadershipRenewal | Leader → ETCD | Lease refresh | Current leader ID, health status |\n| LeadershipTransfer | Leader → ETCD | Graceful shutdown | New leader suggestion |\n\nThe leader election process follows this sequence:\n\n1. **Vacancy Detection**: Nodes detect leadership vacancy through ETCD watch mechanisms or lease expiration notifications\n2. **Candidate Registration**: Eligible nodes register as candidates in ETCD with their capabilities and priority scores\n3. **Election Resolution**: ETCD's consensus mechanism selects the leader based on predefined criteria (lowest node ID wins in case of ties)\n4. **Leadership Establishment**: The elected leader establishes a lease and begins accepting job assignment responsibilities\n5. **Ongoing Maintenance**: The leader periodically renews its lease while other nodes monitor for leadership changes\n\n#### Worker Registration Messages\n\nWorker registration messages handle the dynamic addition and removal of worker nodes from the cluster, enabling elastic scaling and graceful shutdown procedures.\n\n| Field | Type | Description | Validation Rules |\n|-------|------|-------------|------------------|\n| WorkerID | string | Unique worker identifier | Must be DNS-safe, 3-63 characters |\n| Address | string | Network address for communication | Must be reachable from coordinator |\n| Capabilities | []string | List of supported job types | Each capability must match known types |\n| Capacity | int | Maximum concurrent jobs | Must be positive integer |\n| Metadata | map[string]string | Additional worker information | Optional key-value pairs |\n| StartedAt | time.Time | Worker startup timestamp | Must be recent (within 5 minutes) |\n\nThe worker registration process ensures new workers can join the cluster and contribute to job processing:\n\n1. **Initial Registration**: New workers send registration messages to the current leader with their capabilities and capacity\n2. **Validation and Acceptance**: The coordinator validates worker information and adds the worker to the active registry\n3. **Capability Matching**: The system updates job assignment algorithms to consider the new worker's capabilities\n4. **Health Monitoring**: The coordinator begins expecting regular heartbeats from the newly registered worker\n5. **Job Assignment Eligibility**: The worker becomes eligible to receive job assignments based on its capacity and capabilities\n\n#### Heartbeat Message Protocol\n\nThe heartbeat protocol provides the foundation for failure detection and system health monitoring across the distributed cluster.\n\n| Message Component | Size | Purpose | Update Frequency |\n|------------------|------|---------|------------------|\n| WorkerID | 16 bytes | Worker identification | Never changes |\n| SequenceNumber | 8 bytes | Message ordering | Increments with each heartbeat |\n| Timestamp | 8 bytes | Generation time | Current time for each message |\n| JobStatus | Variable | Current job information | Updates when jobs start/complete |\n| ResourceUsage | 32 bytes | CPU, memory, disk usage | Updated each heartbeat |\n\nThe heartbeat message format provides comprehensive worker state information:\n\n```\nHeartbeatMessage {\n    WorkerID: string\n    SequenceNumber: int64\n    Timestamp: time.Time\n    Status: WorkerState\n    CurrentJobs: int\n    ExecutingJobs: []JobProgress\n    ResourceUsage: ResourceMetrics\n    Capabilities: []string\n}\n\nJobProgress {\n    JobID: string\n    StartedAt: time.Time\n    Progress: float64  // 0.0 to 1.0\n    EstimatedCompletion: time.Time\n}\n\nResourceMetrics {\n    CPUPercent: float64\n    MemoryPercent: float64\n    DiskPercent: float64\n    NetworkBytesPerSecond: int64\n}\n```\n\n#### Job Assignment Messages\n\nJob assignment messages coordinate the handoff of work from the priority queue to available workers, including all necessary context for successful execution.\n\n> **Decision: Message Format for Job Assignment**\n> - **Context**: Job assignment must include complete execution context while minimizing network overhead\n> - **Options Considered**: Full job serialization, reference-based with lookup, hybrid approach\n> - **Decision**: Full job serialization with compressed payload\n> - **Rationale**: Eliminates coordination dependencies during execution; worker has all necessary information locally\n> - **Consequences**: Larger message size but better fault tolerance and simpler worker implementation\n\n| Assignment Component | Purpose | Size Estimate | Compression Strategy |\n|--------------------|---------|---------------|---------------------|\n| Job Metadata | Identification and scheduling | 200 bytes | None (small, structured) |\n| Execution Payload | Job-specific parameters | Variable | gzip compression |\n| Worker Instructions | Execution hints and requirements | 100 bytes | None |\n| Fencing Information | Authority and lease details | 64 bytes | None |\n\nThe complete job assignment message structure:\n\n| Field | Type | Required | Description |\n|-------|------|----------|-------------|\n| JobID | string | Yes | Unique job identifier |\n| FencingToken | string | Yes | Authority token for this assignment |\n| WorkerID | string | Yes | Target worker identifier |\n| JobDefinition | Job | Yes | Complete job specification |\n| ExecutionHints | map[string]string | No | Performance and resource hints |\n| LeaseExpiration | time.Time | Yes | When assignment expires without progress |\n| RetryContext | RetryInfo | No | Previous attempt information |\n\nThe job assignment process ensures reliable work distribution:\n\n1. **Assignment Preparation**: Coordinator selects highest-priority job and most suitable available worker\n2. **Token Generation**: System generates unique fencing token linking job, worker, and assignment time\n3. **Atomic Assignment**: Database transaction atomically assigns job and records assignment details\n4. **Message Transmission**: Complete job assignment message sent to target worker\n5. **Acknowledgment Handling**: Worker confirms receipt and begins execution preparation\n6. **Lease Monitoring**: Coordinator tracks assignment lease and prepares for timeout handling\n\n#### Message Reliability and Ordering\n\nThe coordination message system must handle network failures, message loss, and out-of-order delivery while maintaining system correctness.\n\n| Message Type | Delivery Guarantee | Ordering Requirement | Timeout Handling |\n|-------------|-------------------|---------------------|------------------|\n| Leadership | Exactly-once via ETCD | Total ordering required | ETCD manages timeouts |\n| Registration | At-least-once | No ordering requirement | Retry with exponential backoff |\n| Heartbeat | Best-effort | Sequence number ordering | Timeout triggers failure detection |\n| Assignment | Exactly-once | Per-job ordering only | Reassignment after timeout |\n\n#### Common Pitfalls in Coordination Messages\n\n⚠️ **Pitfall: Message Amplification During Network Partitions**\nDuring network partitions, nodes might repeatedly retry coordination messages, creating message storms when connectivity is restored. This can overwhelm the coordination service and delay recovery.\n\nThe solution involves implementing jittered exponential backoff for all coordination messages and rate limiting to prevent message storms. Additionally, nodes should use circuit breaker patterns to temporarily stop sending messages when the coordination service appears unavailable.\n\n⚠️ **Pitfall: Stale Leadership Information**\nWorkers might continue sending messages to a coordinator that has lost leadership, wasting resources and potentially missing important updates from the new leader.\n\nPrevention requires implementing leadership change notifications through ETCD watches, allowing workers to immediately redirect their coordination messages to the current leader. Workers should also include leadership generation numbers in messages to detect stale leadership.\n\n⚠️ **Pitfall: Heartbeat Message Buildup**\nIf the coordinator becomes temporarily unresponsive, heartbeat messages can accumulate in network buffers or message queues. When the coordinator recovers, processing this backlog can create false failure detections and unnecessary job reassignments.\n\nThe fix involves implementing heartbeat message deduplication based on sequence numbers and timestamps. The coordinator should process only the most recent heartbeat from each worker and discard older messages to get an accurate view of current worker state.\n\n### Implementation Guidance\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Message Transport | HTTP REST with JSON (net/http) | gRPC with Protocol Buffers |\n| Message Queuing | Direct HTTP calls with retries | Redis pub/sub or Apache Kafka |\n| Coordination Store | Redis with atomic operations | ETCD with watches and leases |\n| Serialization | JSON encoding/decoding | Protocol Buffers or MessagePack |\n| Load Balancing | Round-robin with health checks | Weighted least-connections |\n\n#### Recommended File Structure\n\n```\ninternal/coordination/\n  coordinator.go           ← main coordinator logic\n  coordinator_test.go      ← coordinator unit tests\n  messages.go             ← message type definitions\n  election.go             ← leader election implementation\n  heartbeat.go            ← heartbeat handling logic\n  assignment.go           ← job assignment coordination\n  \ninternal/transport/\n  http_client.go          ← HTTP client wrapper\n  http_server.go          ← HTTP server with routing\n  grpc_client.go          ← gRPC client (optional)\n  grpc_server.go          ← gRPC server (optional)\n  \ninternal/messaging/\n  publisher.go            ← message publishing interface\n  subscriber.go           ← message subscription interface\n  redis_transport.go      ← Redis-based message transport\n  \ncmd/coordinator/\n  main.go                ← coordinator service entry point\n  \ncmd/worker/\n  main.go                ← worker service entry point\n```\n\n#### Core Message Handling Infrastructure\n\n```go\n// Message transport abstraction for testing and flexibility\ntype MessageTransport interface {\n    SendMessage(ctx context.Context, target string, message Message) error\n    ReceiveMessages(ctx context.Context, handler MessageHandler) error\n    Subscribe(ctx context.Context, topic string, handler MessageHandler) error\n    Close() error\n}\n\n// Base message interface implemented by all coordination messages\ntype Message interface {\n    Type() MessageType\n    Target() string\n    Payload() []byte\n    Validate() error\n}\n\n// HTTP-based message transport implementation\ntype HTTPTransport struct {\n    client    *http.Client\n    server    *http.Server\n    handlers  map[MessageType]MessageHandler\n    logger    *log.Logger\n}\n\nfunc NewHTTPTransport(port int) *HTTPTransport {\n    return &HTTPTransport{\n        client: &http.Client{\n            Timeout: 10 * time.Second,\n            Transport: &http.Transport{\n                MaxIdleConns:       100,\n                IdleConnTimeout:    90 * time.Second,\n                DisableCompression: false,\n            },\n        },\n        handlers: make(map[MessageType]MessageHandler),\n        logger:   log.New(os.Stdout, \"[TRANSPORT] \", log.LstdFlags),\n    }\n}\n\nfunc (t *HTTPTransport) SendMessage(ctx context.Context, target string, message Message) error {\n    payload := bytes.NewBuffer(message.Payload())\n    \n    req, err := http.NewRequestWithContext(ctx, \"POST\", target, payload)\n    if err != nil {\n        return fmt.Errorf(\"failed to create request: %w\", err)\n    }\n    \n    req.Header.Set(\"Content-Type\", \"application/json\")\n    req.Header.Set(\"Message-Type\", string(message.Type()))\n    \n    resp, err := t.client.Do(req)\n    if err != nil {\n        return fmt.Errorf(\"failed to send message: %w\", err)\n    }\n    defer resp.Body.Close()\n    \n    if resp.StatusCode >= 400 {\n        body, _ := io.ReadAll(resp.Body)\n        return fmt.Errorf(\"message rejected: status=%d, body=%s\", resp.StatusCode, string(body))\n    }\n    \n    return nil\n}\n\n// Message handler function type\ntype MessageHandler func(ctx context.Context, message Message) error\n\n// Message routing and validation\nfunc (t *HTTPTransport) handleHTTPMessage(w http.ResponseWriter, r *http.Request) {\n    msgType := MessageType(r.Header.Get(\"Message-Type\"))\n    handler, exists := t.handlers[msgType]\n    if !exists {\n        http.Error(w, \"Unknown message type\", http.StatusBadRequest)\n        return\n    }\n    \n    body, err := io.ReadAll(r.Body)\n    if err != nil {\n        http.Error(w, \"Failed to read body\", http.StatusBadRequest)\n        return\n    }\n    \n    message, err := DeserializeMessage(msgType, body)\n    if err != nil {\n        http.Error(w, fmt.Sprintf(\"Failed to deserialize: %v\", err), http.StatusBadRequest)\n        return\n    }\n    \n    if err := message.Validate(); err != nil {\n        http.Error(w, fmt.Sprintf(\"Invalid message: %v\", err), http.StatusBadRequest)\n        return\n    }\n    \n    ctx, cancel := context.WithTimeout(r.Context(), 30*time.Second)\n    defer cancel()\n    \n    if err := handler(ctx, message); err != nil {\n        t.logger.Printf(\"Handler error: %v\", err)\n        http.Error(w, \"Processing failed\", http.StatusInternalServerError)\n        return\n    }\n    \n    w.WriteHeader(http.StatusOK)\n}\n```\n\n#### Job Assignment Message Implementation\n\n```go\n// Complete job assignment message structure\ntype JobAssignmentMessage struct {\n    MessageID      string                 `json:\"message_id\"`\n    JobID          string                 `json:\"job_id\"`\n    WorkerID       string                 `json:\"worker_id\"`\n    FencingToken   string                 `json:\"fencing_token\"`\n    Job            *Job                   `json:\"job\"`\n    ExecutionHints map[string]string      `json:\"execution_hints,omitempty\"`\n    LeaseExpiration time.Time             `json:\"lease_expiration\"`\n    RetryContext   *RetryInfo             `json:\"retry_context,omitempty\"`\n    Timestamp      time.Time              `json:\"timestamp\"`\n}\n\nfunc (m *JobAssignmentMessage) Type() MessageType {\n    return MessageTypeJobAssignment\n}\n\nfunc (m *JobAssignmentMessage) Target() string {\n    return m.WorkerID  // Message is targeted at specific worker\n}\n\nfunc (m *JobAssignmentMessage) Payload() []byte {\n    data, _ := json.Marshal(m)  // Handle error in production\n    return data\n}\n\nfunc (m *JobAssignmentMessage) Validate() error {\n    if m.JobID == \"\" {\n        return errors.New(\"job_id is required\")\n    }\n    if m.WorkerID == \"\" {\n        return errors.New(\"worker_id is required\")\n    }\n    if m.FencingToken == \"\" {\n        return errors.New(\"fencing_token is required\")\n    }\n    if m.Job == nil {\n        return errors.New(\"job definition is required\")\n    }\n    if m.LeaseExpiration.Before(time.Now()) {\n        return errors.New(\"lease_expiration must be in the future\")\n    }\n    return nil\n}\n\n// Job assignment coordination logic\ntype JobAssigner struct {\n    transport    MessageTransport\n    queue        PriorityQueue\n    workers      WorkerRegistry\n    tokenGen     FencingTokenGenerator\n    logger       *log.Logger\n}\n\nfunc (a *JobAssigner) AssignJobToWorker(ctx context.Context, workerID string) error {\n    // TODO 1: Query priority queue for highest-priority job matching worker capabilities\n    // TODO 2: Generate unique fencing token for this assignment\n    // TODO 3: Atomically claim job and update state to CLAIMED\n    // TODO 4: Create job assignment message with complete job context\n    // TODO 5: Send assignment message to target worker\n    // TODO 6: Record assignment in persistent storage for failure recovery\n    // TODO 7: Start lease expiration timer for automatic reassignment\n    // Hint: Use database transactions to ensure atomic job claiming\n    // Hint: Include retry context if this job has failed before\n    \n    return nil\n}\n```\n\n#### Heartbeat Protocol Implementation\n\n```go\n// Comprehensive heartbeat message structure\ntype HeartbeatMessage struct {\n    WorkerID        string             `json:\"worker_id\"`\n    SequenceNumber  int64              `json:\"sequence_number\"`\n    Timestamp       time.Time          `json:\"timestamp\"`\n    Status          WorkerState        `json:\"status\"`\n    CurrentJobs     int                `json:\"current_jobs\"`\n    ExecutingJobs   []JobProgress      `json:\"executing_jobs\"`\n    ResourceUsage   ResourceMetrics    `json:\"resource_usage\"`\n    Capabilities    []string           `json:\"capabilities\"`\n    Metadata        map[string]string  `json:\"metadata,omitempty\"`\n}\n\ntype JobProgress struct {\n    JobID               string     `json:\"job_id\"`\n    StartedAt           time.Time  `json:\"started_at\"`\n    Progress            float64    `json:\"progress\"`          // 0.0 to 1.0\n    EstimatedCompletion time.Time  `json:\"estimated_completion\"`\n    Status              string     `json:\"status\"`\n}\n\ntype ResourceMetrics struct {\n    CPUPercent            float64 `json:\"cpu_percent\"`\n    MemoryPercent         float64 `json:\"memory_percent\"`\n    DiskPercent           float64 `json:\"disk_percent\"`\n    NetworkBytesPerSecond int64   `json:\"network_bytes_per_second\"`\n}\n\nfunc (m *HeartbeatMessage) Type() MessageType {\n    return MessageTypeHeartbeat\n}\n\nfunc (m *HeartbeatMessage) Target() string {\n    return \"coordinator\"  // Always sent to current coordinator\n}\n\nfunc (m *HeartbeatMessage) Payload() []byte {\n    data, _ := json.Marshal(m)\n    return data\n}\n\nfunc (m *HeartbeatMessage) Validate() error {\n    if m.WorkerID == \"\" {\n        return errors.New(\"worker_id is required\")\n    }\n    if m.SequenceNumber <= 0 {\n        return errors.New(\"sequence_number must be positive\")\n    }\n    if time.Since(m.Timestamp) > time.Minute {\n        return errors.New(\"timestamp is too old\")\n    }\n    if m.CurrentJobs < 0 {\n        return errors.New(\"current_jobs cannot be negative\")\n    }\n    return nil\n}\n\n// Heartbeat handling on coordinator side\ntype HeartbeatProcessor struct {\n    workers     WorkerRegistry\n    jobRecovery JobRecoveryService\n    logger      *log.Logger\n    mutex       sync.RWMutex\n}\n\nfunc (p *HeartbeatProcessor) ProcessHeartbeat(ctx context.Context, message Message) error {\n    heartbeat, ok := message.(*HeartbeatMessage)\n    if !ok {\n        return errors.New(\"invalid message type for heartbeat processor\")\n    }\n    \n    // TODO 1: Validate heartbeat message format and freshness\n    // TODO 2: Look up worker in registry and check sequence number ordering\n    // TODO 3: Update worker state with current capacity and job information\n    // TODO 4: Reset worker failure detection timer\n    // TODO 5: Update job progress information for executing jobs\n    // TODO 6: Check for any jobs that need progress updates\n    // TODO 7: Respond with any pending assignments or commands for worker\n    // Hint: Use atomic operations when updating worker state\n    // Hint: Log sequence number gaps as potential message loss\n    \n    return nil\n}\n```\n\n#### Message Flow Orchestration\n\n```go\n// End-to-end job execution flow coordinator\ntype ExecutionFlowCoordinator struct {\n    transport   MessageTransport\n    queue       PriorityQueue\n    workers     WorkerRegistry\n    storage     Storage\n    config      CoordinatorConfig\n    logger      *log.Logger\n}\n\nfunc (c *ExecutionFlowCoordinator) StartJobExecutionFlow(ctx context.Context) {\n    // TODO 1: Start goroutine for job promotion (delayed -> active queue)\n    // TODO 2: Start goroutine for worker heartbeat monitoring\n    // TODO 3: Start goroutine for job assignment processing\n    // TODO 4: Start goroutine for completion report handling\n    // TODO 5: Set up signal handling for graceful shutdown\n    // Hint: Use context cancellation to coordinate shutdown\n    // Hint: Implement proper error handling and restart logic for each goroutine\n}\n\nfunc (c *ExecutionFlowCoordinator) handleJobCompletion(ctx context.Context, message Message) error {\n    completion, ok := message.(*JobCompletionMessage)\n    if !ok {\n        return errors.New(\"invalid message type\")\n    }\n    \n    // TODO 1: Validate fencing token to ensure worker authority\n    // TODO 2: Update job state based on completion result (success/failure)\n    // TODO 3: Handle retry logic if job failed and retries remain\n    // TODO 4: Clean up worker assignment and update capacity\n    // TODO 5: Trigger next scheduled execution for recurring jobs\n    // TODO 6: Send completion notification to job submission client\n    // Hint: Use database transactions for state updates\n    // Hint: Implement dead letter queue for jobs that exhaust retries\n    \n    return nil\n}\n```\n\n#### Milestone Checkpoints\n\n**Checkpoint 1: Basic Message Transport**\n- Run: `go test ./internal/transport/... -v`\n- Expected: All message serialization and HTTP transport tests pass\n- Manual verification: Start coordinator and worker, send test heartbeat message\n- Success indicator: Worker successfully registers and sends first heartbeat\n\n**Checkpoint 2: Job Assignment Flow**\n- Run: `go test ./internal/coordination/... -v -run TestJobAssignment`\n- Expected: Job assignment messages are properly formatted and delivered\n- Manual verification: Submit test job, verify worker receives assignment message\n- Success indicator: Job transitions from PENDING to CLAIMED state\n\n**Checkpoint 3: End-to-End Execution**\n- Run: `go run cmd/coordinator/main.go & go run cmd/worker/main.go`\n- Expected: Complete job submission through execution and completion reporting\n- Manual verification: Submit job via API, monitor logs for execution flow\n- Success indicator: Job completes successfully and reports back to coordinator\n\n\n## Error Handling and Edge Cases\n\n> **Milestone(s):** This section covers error handling patterns that apply across all three milestones - cron parsing failures (Milestone 1), queue operation failures (Milestone 2), and worker coordination failures (Milestone 3). The distributed nature of the system requires sophisticated failure detection and recovery mechanisms to maintain consistency and availability.\n\nThe distributed job scheduler operates in an environment where failures are inevitable rather than exceptional. Like a city's emergency response system that must function despite individual component failures, our scheduler requires comprehensive error handling that prevents cascading failures and ensures graceful degradation. This section explores the failure modes inherent in distributed systems and establishes recovery strategies that maintain operational consistency while maximizing availability.\n\n### Mental Model: Emergency Response Coordination\n\nThink of error handling in a distributed job scheduler as coordinating emergency services across a city. Just as fire departments, police, and hospitals must maintain service during equipment failures, network outages, and staff shortages, our scheduler must continue operating when workers crash, networks partition, or coordination services become unavailable. The key insight is that **failure is not binary** - systems fail partially, intermittently, and in complex combinations that require nuanced responses rather than simple retry logic.\n\nEmergency services use several principles that apply directly to our distributed scheduler: **redundancy** (multiple fire stations), **failure detection** (911 dispatch monitoring), **resource reallocation** (sending backup units when primary responds are unavailable), and **graceful degradation** (reduced service levels rather than complete shutdown). Our error handling strategy implements these same patterns through worker redundancy, heartbeat monitoring, job reassignment, and priority-based service reduction.\n\n### Failure Modes\n\nDistributed systems exhibit failure patterns that rarely occur in single-node applications. Understanding these failure modes enables us to design detection and recovery mechanisms that maintain system integrity despite component failures.\n\n> **Decision: Failure Classification Taxonomy**\n> - **Context**: Distributed job scheduler experiences various failure types requiring different detection and recovery strategies\n> - **Options Considered**: Binary fail/success model, Component-level categorization, Impact-based classification\n> - **Decision**: Multi-dimensional failure taxonomy based on scope, duration, and detectability\n> - **Rationale**: Enables targeted recovery strategies and prevents over-engineering simple failure cases\n> - **Consequences**: More complex error handling logic but much better system resilience and recovery times\n\n#### Network Partition Failures\n\nNetwork partitions represent the most challenging failure mode because they create **split-brain scenarios** where different parts of the system have inconsistent views of reality. Unlike clean failures where components stop responding entirely, partitions create zones of connectivity where nodes within a zone can communicate but cannot reach nodes in other zones.\n\n| Partition Scenario | Symptoms | Impact | Detection Method |\n|-------------------|----------|--------|------------------|\n| Coordinator-Worker Partition | Workers cannot send heartbeats; coordinator sees mass worker failure | Job assignment stops; workers continue executing claimed jobs | Heartbeat timeout; workers cannot reach coordination service |\n| Inter-Worker Partition | Workers isolated from each other but connected to coordinator | Load balancing becomes ineffective; some workers overloaded | Job claim patterns show uneven distribution |\n| Coordination Service Partition | Cannot access etcd/Redis cluster | All coordination stops; system freezes | Connection timeouts to backing services |\n| Client-Scheduler Partition | Job submission requests fail | New jobs cannot be submitted | HTTP/gRPC connection failures |\n\nThe **Byzantine nature** of network partitions means that different components may observe different failure patterns simultaneously. A coordinator might lose connectivity to half its workers while maintaining connectivity to the coordination service, creating a scenario where the coordinator attempts to reassign jobs from healthy workers it cannot communicate with.\n\n**Partition detection** relies on timeout-based mechanisms combined with **fencing tokens** to prevent stale operations. When a coordinator loses communication with a worker, it cannot immediately determine whether the worker failed or a network partition occurred. The coordinator must wait for a timeout period before declaring the worker failed and reassigning its jobs. However, if the worker is healthy but partitioned, it may complete its current job and attempt to report completion after the coordinator has already reassigned the job to another worker.\n\n#### Worker Crash Failures\n\nWorker failures manifest in several distinct patterns, each requiring different detection and recovery strategies. Unlike network partitions where the worker may still be processing jobs, crash failures represent complete worker unavailability.\n\n| Failure Type | Characteristics | Detection Latency | Recovery Strategy |\n|--------------|-----------------|-------------------|-------------------|\n| Hard Crash | Process terminates immediately | Next heartbeat interval | Immediate job reassignment |\n| Graceful Shutdown | Worker completes current jobs before stopping | Worker sends shutdown signal | Allow completion, then reassign remaining |\n| Resource Exhaustion | Worker becomes unresponsive due to memory/CPU limits | Heartbeat timeout or health check failure | Restart worker, reassign jobs |\n| Dependency Failure | External service unavailable (database, API) | Job execution failures | Retry with backoff, possibly reassign |\n\n**Crash detection** combines multiple signals to distinguish between different failure types. The primary mechanism is **heartbeat timeout**, where workers must send periodic liveness signals to the coordinator. However, heartbeat timeout alone cannot distinguish between a crashed worker and a temporarily overloaded worker that cannot send heartbeats promptly.\n\nThe coordinator implements **graduated failure detection** that escalates response based on failure duration:\n\n1. **Initial timeout (30 seconds)**: Mark worker as potentially unavailable, stop assigning new jobs\n2. **Extended timeout (2 minutes)**: Attempt direct health check to worker endpoint\n3. **Failure confirmation (5 minutes)**: Declare worker failed, begin job reassignment process\n4. **Cleanup timeout (10 minutes)**: Remove worker from active pool, clean up metadata\n\nThis graduated approach prevents **flapping**, where temporary network hiccups cause repeated job reassignments that waste resources and potentially violate exactly-once execution guarantees.\n\n#### Coordination Service Outages\n\nThe coordination service (etcd or Redis cluster) represents a **single point of failure** for cluster-wide operations despite being internally distributed. While etcd and Redis provide their own fault tolerance, they can still become unavailable from the scheduler's perspective due to network issues, resource exhaustion, or configuration problems.\n\n| Service | Outage Impact | Mitigation Strategy | Recovery Process |\n|---------|---------------|-------------------|------------------|\n| etcd Leader Election | Cannot elect new coordinator; current coordinator continues | Local coordinator state caching | Retry election with exponential backoff |\n| etcd Job Metadata | Cannot update job states | Write-ahead logging to local storage | Replay logs when connectivity restored |\n| Redis Priority Queue | Cannot enqueue/dequeue jobs | Local job buffer with overflow to disk | Drain buffer to Redis when available |\n| Redis Deduplication | Cannot prevent duplicate submissions | Accept duplicates temporarily | Post-recovery deduplication scan |\n\n**Coordination service failures** require the scheduler to operate in **degraded mode** rather than stopping entirely. The system maintains local state and implements **write-ahead logging** to ensure that state changes during the outage can be replayed when connectivity is restored.\n\nThe most critical challenge is **preventing split-brain scenarios** during coordination service outages. If the current coordinator leader loses connectivity to etcd but workers can still reach etcd, a new coordinator may be elected while the original coordinator continues operating. This scenario requires **fencing tokens** that increment with each leader election, ensuring that operations from stale coordinators are rejected.\n\n⚠️ **Pitfall: Coordination Service Timeout Configuration**\nSetting coordination service timeouts too aggressively causes false positives where temporary network delays trigger unnecessary failover procedures. However, setting timeouts too conservatively delays failure detection and prolongs service degradation. The timeout values must account for network latency variance, service processing time, and the cost of false positives versus false negatives. A common mistake is using the same timeout values for different operation types - leader election can tolerate longer timeouts than job state updates.\n\n### Retry Strategies\n\nRetry logic in distributed systems requires sophisticated strategies that account for failure types, system load, and consistency requirements. Unlike simple HTTP retries, our job scheduler must implement **differentiated retry strategies** that prevent retry storms while ensuring forward progress.\n\n> **Decision: Retry Strategy Framework**\n> - **Context**: Different failure types require different retry approaches to balance reliability with system stability\n> - **Options Considered**: Universal exponential backoff, Per-operation retry logic, Adaptive retry with feedback\n> - **Decision**: Hierarchical retry framework with operation-specific strategies and system-wide backpressure\n> - **Rationale**: Provides fine-grained control while preventing retry amplification and cascading failures\n> - **Consequences**: More complex implementation but much better system stability under load\n\n#### Exponential Backoff Implementation\n\n**Exponential backoff** forms the foundation of our retry strategy but requires careful tuning to prevent **retry amplification** where multiple components retrying simultaneously create artificial load spikes that prevent recovery.\n\n| Retry Scenario | Initial Delay | Backoff Factor | Max Delay | Max Attempts | Jitter |\n|----------------|---------------|----------------|-----------|--------------|--------|\n| Heartbeat Transmission | 1 second | 2.0 | 30 seconds | 5 | ±20% |\n| Job State Update | 100ms | 1.5 | 10 seconds | 8 | ±25% |\n| Worker Registration | 5 seconds | 2.0 | 5 minutes | 3 | ±30% |\n| Coordination Service Connection | 2 seconds | 1.8 | 2 minutes | 10 | ±15% |\n\nThe **jitter component** prevents **thundering herd** scenarios where multiple workers retry simultaneously after a shared dependency recovers. Each retry delay includes random variation: `actual_delay = base_delay * (1 + jitter * random(-1, 1))`.\n\n**Backoff calculation** follows the formula: `delay = min(initial_delay * (backoff_factor ^ attempt), max_delay)`. However, our implementation includes **circuit breaker** logic that suspends retries when failure rates exceed thresholds, preventing resources from being consumed by operations that are unlikely to succeed.\n\nThe retry framework implements **differentiated strategies** based on operation criticality:\n\n1. **Critical operations** (job completion reports): Aggressive retries with local persistence and manual intervention escalation\n2. **Important operations** (heartbeats): Moderate retries with graceful degradation when max attempts exceeded\n3. **Best-effort operations** (metrics reporting): Limited retries with silent failure after max attempts\n4. **Background operations** (cleanup tasks): Infrequent retries with extended backoff periods\n\n#### Maximum Attempts and Escalation\n\n**Maximum retry attempts** prevent infinite retry loops while ensuring that temporary failures do not cause permanent data loss. However, different operation types require different escalation strategies when max attempts are exceeded.\n\n| Operation Type | Max Attempts | Escalation Strategy | Manual Intervention Required |\n|----------------|--------------|-------------------|----------------------------|\n| Job Completion Report | 15 | Write to dead letter queue | Yes - job state reconciliation |\n| Worker Heartbeat | 5 | Mark worker as failed | No - automatic recovery |\n| Job Assignment | 8 | Return job to queue | No - automatic retry |\n| Leader Election | 3 | Enter follower mode | Possibly - configuration check |\n\n**Escalation procedures** ensure that operations that cannot succeed through retries alone are handled appropriately rather than being lost. The dead letter queue serves as a **last resort repository** for operations that require manual intervention or extended retry periods.\n\nThe system implements **retry budgets** that limit the total number of retries across all operations within a time window. This prevents scenarios where retry storms consume all available resources and prevent successful operations from completing. Each operation type has an allocated retry budget, and when the budget is exhausted, operations fail fast rather than queuing for later retry.\n\n**Exponential backoff state** is maintained per operation type and target to ensure that repeated failures to the same destination use progressively longer delays. However, successful operations reset the backoff state, allowing rapid recovery when services become available.\n\n#### Dead Letter Queue Handling\n\nThe **dead letter queue** serves as a repository for operations that cannot be completed through normal retry mechanisms. Unlike simple failure logging, the dead letter queue enables **recovery workflows** that can resolve issues and replay failed operations.\n\nDead letter queue entries include comprehensive context for later resolution:\n\n| Field | Purpose | Example Value |\n|-------|---------|---------------|\n| Original Operation | The operation that failed | JobCompletionReport |\n| Failure Reason | Why retries were exhausted | \"Coordinator unreachable after 15 attempts\" |\n| Original Timestamp | When operation was first attempted | 2024-01-15T10:30:00Z |\n| Context Data | Information needed for replay | Job ID, Worker ID, Execution Result |\n| Retry History | Previous attempt timestamps and errors | [attempt1: timeout, attempt2: connection refused] |\n| Manual Review Flag | Whether human intervention is required | true |\n\n**Dead letter processing** includes both automated and manual resolution paths:\n\n1. **Automated recovery**: Periodic replay of dead letter entries when target services become available\n2. **Batch reconciliation**: Comparing dead letter entries against current system state to identify resolved operations\n3. **Manual intervention workflows**: Administrative interfaces for resolving operations that require human judgment\n4. **Data consistency checks**: Validation that replaying dead letter operations will not violate system invariants\n\nThe dead letter queue implements **aging policies** that automatically archive entries older than configurable thresholds. However, critical operations like job completion reports are never automatically discarded, ensuring that job execution results are not lost even during extended outages.\n\n⚠️ **Pitfall: Retry Strategy Coordination**\nImplementing retry logic independently in each component can create **retry amplification** where failures cascade through the system as each component retries failed operations. For example, if the coordination service becomes temporarily unavailable, all workers may simultaneously retry heartbeats, creating a load spike when the service recovers that prevents successful recovery. Retry strategies must be coordinated across components with shared circuit breakers and backpressure mechanisms.\n\n### Consistency Guarantees\n\nDistributed job scheduling must balance **consistency** with **availability** under the constraints of the CAP theorem. Our scheduler provides configurable consistency guarantees that can be tuned based on application requirements and operational priorities.\n\n> **Decision: Consistency Model Selection**\n> - **Context**: Job execution requires balancing exactly-once guarantees with system availability during failures\n> - **Options Considered**: Exactly-once execution, At-least-once execution, At-most-once execution\n> - **Decision**: Configurable consistency with at-least-once as default and exactly-once as optional mode\n> - **Rationale**: Most applications can handle duplicate job execution better than missing job execution\n> - **Consequences**: Simpler failure handling but requires idempotent job design\n\n#### At-Least-Once vs Exactly-Once Execution\n\n**At-least-once execution** guarantees that every submitted job will be executed at least once, but jobs may be executed multiple times due to failures and retries. **Exactly-once execution** guarantees that every job is executed exactly one time, but achieving this guarantee requires more complex coordination that can impact availability.\n\n| Consistency Model | Guarantee | Implementation Complexity | Failure Recovery Time | Use Cases |\n|-------------------|-----------|---------------------------|----------------------|-----------|\n| At-least-once | Jobs never lost, may duplicate | Low | Fast (seconds) | Idempotent operations, data processing |\n| Exactly-once | Jobs executed precisely once | High | Slow (minutes) | Financial transactions, state mutations |\n| At-most-once | Jobs never duplicate, may be lost | Medium | Medium (30 seconds) | Best-effort notifications, logging |\n\n**At-least-once implementation** uses **optimistic execution** where workers claim jobs and begin execution immediately, reporting completion when finished. If a worker fails during execution, the job is reassigned to another worker after a timeout period. This approach prioritizes availability and fast recovery at the cost of potential duplicate execution.\n\n**Exactly-once implementation** requires **two-phase commit** protocols where workers must confirm job completion before the job is marked as completed system-wide. This involves:\n\n1. **Execution phase**: Worker claims job and executes it locally\n2. **Preparation phase**: Worker reports execution completion but job remains in \"completing\" state\n3. **Commit phase**: Coordinator confirms no other worker has claimed the job and marks it as completed\n4. **Cleanup phase**: All replicas acknowledge the completion and remove local job state\n\nThe exactly-once protocol introduces **blocking periods** where job completion is delayed while the coordinator verifies that no other worker has also executed the job. During network partitions or coordinator failures, jobs may remain in the \"completing\" state until consistency can be verified.\n\n#### Idempotency Requirements\n\n**Idempotency** enables at-least-once execution patterns by ensuring that executing a job multiple times produces the same result as executing it once. However, achieving idempotency requires careful job design and system support for **idempotency tracking**.\n\nJob idempotency is implemented through several mechanisms:\n\n| Mechanism | Scope | Implementation | Example |\n|-----------|-------|----------------|---------|\n| Idempotency Key | Per Job | Client-provided unique identifier | UUID generated at job submission |\n| Content Hash | Per Execution | Hash of normalized job payload | SHA-256 of sorted job parameters |\n| External System State | Per Side Effect | Query before mutation | Check if database record already exists |\n| Operation Sequencing | Per Workflow | Monotonic sequence numbers | Process events in timestamp order |\n\n**Idempotency key enforcement** prevents duplicate job submissions when clients retry job creation requests. The scheduler maintains a deduplication cache that maps idempotency keys to job identifiers, ensuring that submitting the same job multiple times results in a single job execution.\n\n**Content-based deduplication** prevents duplicate jobs even when different idempotency keys are used. This addresses scenarios where multiple systems submit identical jobs independently, such as multiple monitoring systems detecting the same failure condition.\n\nThe scheduler provides **idempotency validation helpers** that jobs can use to check whether their side effects have already been applied:\n\n1. **State query interfaces**: Check external system state before applying mutations\n2. **Operation logging**: Record intended operations before applying them\n3. **Result caching**: Store operation results to avoid recomputation\n4. **Conditional execution**: Use compare-and-swap operations for state mutations\n\n⚠️ **Pitfall: False Idempotency Assumptions**\nMany operations that appear idempotent actually have hidden side effects that violate idempotency. For example, sending an email notification may be considered idempotent because sending the same email twice is acceptable, but if the email system generates unique tracking identifiers or charges per message, duplicate execution creates unintended consequences. Jobs must be carefully designed to handle duplicate execution at the system level, not just at the application logic level.\n\n#### Fencing Tokens and Split-Brain Prevention\n\n**Fencing tokens** provide a mechanism to prevent **split-brain scenarios** where multiple coordinators or workers believe they have authority over the same resources. Fencing tokens are monotonically increasing identifiers that accompany all operations, allowing the system to reject stale operations from previous epochs.\n\n| Token Type | Scope | Generation | Validation |\n|------------|--------|------------|------------|\n| Coordinator Token | Cluster-wide | Incremented at each leader election | Coordination service validates before writes |\n| Worker Token | Per Worker | Generated at worker registration | Coordinator validates before job assignment |\n| Job Token | Per Job | Generated at job assignment | Worker validates before state updates |\n| Operation Token | Per Operation | Generated at operation start | Target validates before applying changes |\n\n**Coordinator fencing** prevents scenarios where a partitioned coordinator continues operating after a new coordinator has been elected. Each coordinator operation includes the current coordinator token, and the coordination service rejects operations with stale tokens. This ensures that only the current leader can modify cluster state.\n\n**Worker fencing** prevents workers from reporting results for jobs that have been reassigned to other workers. When a coordinator reassigns a job due to worker failure, it generates a new job token. The original worker's completion report includes the old token and is rejected, preventing duplicate completion reporting.\n\n**Fencing token implementation** requires atomic operations in the coordination service:\n\n1. **Token generation**: Atomic increment operation that returns new token value\n2. **Token validation**: Compare-and-swap operation that succeeds only if token is current\n3. **Token refresh**: Periodic token update to maintain operation authority\n4. **Token revocation**: Explicit invalidation of tokens during failure scenarios\n\nThe fencing protocol ensures **monotonic consistency** where the system never moves backward in time or accepts operations from previous epochs. However, fencing introduces **operational overhead** as every distributed operation must include token validation.\n\nFencing tokens are **persisted durably** in the coordination service to survive coordinator restarts and network partitions. During recovery scenarios, the new coordinator queries the coordination service to obtain the current token value and increments it to establish new epoch authority.\n\n> **Critical Design Insight**: Fencing tokens represent a fundamental trade-off between consistency and performance. Every operation becomes more expensive due to token validation, but this cost is essential for preventing data corruption during failure scenarios. Systems that skip fencing to improve performance inevitably encounter split-brain scenarios that require complex manual recovery procedures.\n\n### Implementation Guidance\n\nThe error handling and retry mechanisms require careful integration with Go's context cancellation and timeout systems to provide responsive failure detection without resource leaks.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Retry Framework | Manual exponential backoff with time.Sleep | github.com/cenkalti/backoff library |\n| Circuit Breaker | Counter-based with mutex | github.com/sony/gobreaker |\n| Timeout Management | context.WithTimeout per operation | Hierarchical timeout trees |\n| Error Classification | Custom error types with Is/As | github.com/pkg/errors wrapping |\n| Metrics Collection | Prometheus counters/histograms | OpenTelemetry with distributed tracing |\n\n#### Recommended File Structure\n\n```\ninternal/\n  errors/\n    retry.go              ← exponential backoff implementation\n    circuit_breaker.go    ← circuit breaker pattern\n    dead_letter.go        ← dead letter queue management\n    errors.go             ← custom error types\n  fencing/\n    tokens.go             ← fencing token generation/validation\n    coordinator.go        ← coordinator fencing logic\n    worker.go            ← worker fencing implementation\n  coordination/\n    failure_detector.go   ← heartbeat and failure detection\n    recovery.go          ← job recovery and reassignment\n    split_brain.go       ← split-brain prevention\n```\n\n#### Infrastructure Starter Code\n\n```go\n// Package errors provides retry and error handling infrastructure\npackage errors\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"math\"\n    \"math/rand\"\n    \"time\"\n)\n\n// RetryConfig defines retry behavior for different operation types\ntype RetryConfig struct {\n    InitialDelay   time.Duration\n    BackoffFactor  float64\n    MaxDelay       time.Duration\n    MaxAttempts    int\n    JitterPercent  float64\n}\n\n// DefaultRetryConfigs provides sensible retry configurations\nvar DefaultRetryConfigs = map[string]RetryConfig{\n    \"heartbeat\": {\n        InitialDelay:  time.Second,\n        BackoffFactor: 2.0,\n        MaxDelay:      30 * time.Second,\n        MaxAttempts:   5,\n        JitterPercent: 0.2,\n    },\n    \"job_state\": {\n        InitialDelay:  100 * time.Millisecond,\n        BackoffFactor: 1.5,\n        MaxDelay:      10 * time.Second,\n        MaxAttempts:   8,\n        JitterPercent: 0.25,\n    },\n}\n\n// RetryableError indicates an operation can be retried\ntype RetryableError struct {\n    Err       error\n    Temporary bool\n    Backoff   time.Duration\n}\n\nfunc (e *RetryableError) Error() string {\n    return fmt.Sprintf(\"retryable error (backoff=%v): %v\", e.Backoff, e.Err)\n}\n\n// IsRetryable returns true if error should be retried\nfunc IsRetryable(err error) bool {\n    var retryableErr *RetryableError\n    return errors.As(err, &retryableErr)\n}\n\n// CircuitBreaker prevents cascade failures during sustained error conditions\ntype CircuitBreaker struct {\n    mu          sync.Mutex\n    state       CircuitState\n    failures    int\n    lastFailure time.Time\n    config      CircuitConfig\n}\n\ntype CircuitState int\n\nconst (\n    CircuitClosed CircuitState = iota\n    CircuitOpen\n    CircuitHalfOpen\n)\n\ntype CircuitConfig struct {\n    FailureThreshold int\n    RecoveryTimeout  time.Duration\n    TestRequests     int\n}\n\n// Execute runs operation with circuit breaker protection\nfunc (cb *CircuitBreaker) Execute(ctx context.Context, operation func() error) error {\n    // TODO 1: Check circuit state and return fast failure if open\n    // TODO 2: Execute operation and record success/failure\n    // TODO 3: Update circuit state based on recent failure patterns\n    // TODO 4: Return appropriate error with circuit state information\n    return nil\n}\n\n// DeadLetterQueue stores operations that failed all retry attempts\ntype DeadLetterQueue struct {\n    storage    Storage\n    maxAge     time.Duration\n    maxEntries int\n}\n\ntype DeadLetterEntry struct {\n    ID              string\n    OriginalOp      string\n    FailureReason   string\n    Context         map[string]string\n    RetryHistory    []RetryAttempt\n    CreatedAt       time.Time\n    RequiresManual  bool\n}\n\ntype RetryAttempt struct {\n    Timestamp time.Time\n    Error     string\n    Duration  time.Duration\n}\n\n// Add stores failed operation for later resolution\nfunc (dlq *DeadLetterQueue) Add(ctx context.Context, entry *DeadLetterEntry) error {\n    // TODO 1: Validate entry has required fields\n    // TODO 2: Store entry in persistent storage\n    // TODO 3: Check if cleanup is needed for old entries\n    // TODO 4: Emit metrics for dead letter queue depth\n    return nil\n}\n```\n\n#### Core Logic Skeleton Code\n\n```go\n// RetryWithBackoff executes operation with exponential backoff retry logic\nfunc RetryWithBackoff(ctx context.Context, config RetryConfig, operation func() error) error {\n    // TODO 1: Initialize attempt counter and current delay\n    // TODO 2: Loop until max attempts reached or context cancelled\n    // TODO 3: Execute operation and check if error is retryable\n    // TODO 4: Calculate next delay with jitter and backoff factor\n    // TODO 5: Sleep for calculated delay or return on context cancellation\n    // TODO 6: Return last error if all attempts exhausted\n    return nil\n}\n\n// ValidateFencingToken checks if operation token is current and valid\nfunc (f *FencingManager) ValidateFencingToken(ctx context.Context, tokenType string, token int64) error {\n    // TODO 1: Query coordination service for current token value\n    // TODO 2: Compare provided token with current token\n    // TODO 3: Return specific error if token is stale\n    // TODO 4: Update token validation metrics\n    return nil\n}\n\n// DetectWorkerFailure monitors heartbeats and detects failed workers\nfunc (fd *FailureDetector) DetectWorkerFailure(ctx context.Context, workerID string) error {\n    // TODO 1: Check time since last heartbeat for worker\n    // TODO 2: Compare against graduated timeout thresholds\n    // TODO 3: Attempt direct health check if initial timeout exceeded\n    // TODO 4: Mark worker as failed if all checks fail\n    // TODO 5: Trigger job recovery process for failed worker\n    return nil\n}\n\n// RecoverJobsFromFailedWorker reassigns jobs when worker becomes unavailable\nfunc (r *JobRecovery) RecoverJobsFromFailedWorker(ctx context.Context, workerID string, reason string) error {\n    // TODO 1: Query all jobs currently assigned to failed worker\n    // TODO 2: Determine which jobs were executing vs pending\n    // TODO 3: Reset job states to allow reassignment\n    // TODO 4: Add jobs back to priority queue with appropriate priority\n    // TODO 5: Log recovery actions and update metrics\n    return nil\n}\n```\n\n#### Language-Specific Hints\n\n- Use `context.WithTimeout()` for operation-level timeouts and `context.WithCancel()` for graceful shutdown\n- Implement custom error types with `errors.Is()` and `errors.As()` support for error classification\n- Use `sync.Mutex` for circuit breaker state but consider `sync.RWMutex` for high-read scenarios\n- Leverage `time.NewTimer()` for retry delays to avoid blocking goroutines during backoff periods\n- Use `atomic` package for counters and flags that are accessed from multiple goroutines\n- Implement graceful shutdown with `sync.WaitGroup` to ensure in-flight operations complete\n\n#### Milestone Checkpoints\n\n**After implementing retry framework:**\n- Run `go test ./internal/errors/...` - all retry tests should pass\n- Test circuit breaker behavior: rapid failures should open circuit, recovery should close it\n- Verify jitter prevents thundering herd: multiple concurrent retries should have different delays\n\n**After implementing fencing tokens:**\n- Start coordinator, verify token increments with each leadership change\n- Simulate split-brain: old coordinator operations should be rejected with stale token errors\n- Test job assignment fencing: worker cannot complete job after reassignment\n\n**After implementing failure detection:**\n- Stop worker heartbeats, verify coordinator detects failure within expected timeout\n- Test graduated failure detection: temporary slowness should not trigger immediate failure\n- Verify job recovery: jobs from failed worker should be reassigned to healthy workers\n\n#### Debugging Tips\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|-----------------|-----|\n| Jobs executed multiple times | Worker failure during execution, job reassigned | Check job execution logs for same job ID from multiple workers | Implement idempotency keys, verify fencing tokens |\n| Retry storms overloading services | All components retrying simultaneously | Check retry metrics for spikes after service recovery | Add jitter to retry delays, implement circuit breakers |\n| Split-brain job assignments | Network partition with multiple active coordinators | Check coordination service logs for multiple leaders | Verify fencing token implementation, check leader election |\n| Dead letter queue growing rapidly | Systemic failure with all retry attempts failing | Analyze failure patterns in dead letter entries | Fix underlying service issues, tune retry parameters |\n| Workers marked failed but still healthy | Heartbeat timeouts too aggressive | Compare heartbeat intervals with timeout thresholds | Increase timeout values, check network latency patterns |\n\nThe error handling implementation should focus on **fail-fast for unrecoverable errors** and **intelligent retry for transient failures**. The key is distinguishing between these categories correctly and implementing backpressure mechanisms that prevent retry storms from overwhelming recovering services.\n\n\n## Testing Strategy\n\n> **Milestone(s):** This section covers testing approaches that verify the correct implementation across all three milestones - unit tests for isolated component validation (cron parsing, queue operations, coordination logic), integration tests for multi-component scenarios, and milestone-specific verification checkpoints that ensure proper functionality at each development stage.\n\nBuilding a comprehensive testing strategy for a distributed job scheduler is like designing quality assurance for a city's emergency response system. Just as emergency services must be tested at multiple levels - individual responder training, department coordination drills, and full-scale disaster simulations - our distributed scheduler requires unit tests for component isolation, integration tests for system-wide behavior, and milestone checkpoints for development validation. The complexity arises from testing distributed systems where timing, concurrency, and failure modes create non-deterministic behavior that traditional testing approaches struggle to handle.\n\nThe testing strategy operates at three distinct levels, each addressing different aspects of system correctness. Unit testing focuses on algorithmic correctness and component isolation, ensuring individual pieces work correctly in controlled environments. Integration testing validates system-wide behavior under realistic conditions including network partitions, worker failures, and concurrent job execution. Milestone checkpoints provide development feedback loops that verify expected functionality at each implementation stage, preventing architectural drift and catching integration issues early.\n\n### Unit Testing\n\nThink of unit testing for a distributed scheduler like testing individual instruments in an orchestra before the full performance. Each component must demonstrate perfect execution in isolation before we can trust it to perform correctly when coordinated with other components under the unpredictable conditions of distributed operation.\n\nUnit testing in our distributed job scheduler focuses on three primary domains: **cron expression parsing and scheduling logic**, **priority queue operations and deduplication mechanisms**, and **coordination algorithms including leader election and heartbeat processing**. Each domain presents unique challenges that require specialized testing approaches to ensure correctness under all edge cases.\n\n#### Cron Expression Parsing Tests\n\nThe cron expression parser represents pure algorithmic logic that transforms textual time patterns into structured execution schedules. Unit testing this component requires comprehensive coverage of cron syntax variations, timezone handling edge cases, and calendar arithmetic correctness across different temporal boundaries.\n\n**Cron Field Parsing Tests** validate the `parseField()` method's ability to correctly interpret individual cron field syntax including wildcards, ranges, step values, and shorthand aliases. These tests use table-driven approaches to verify parsing accuracy across the full spectrum of valid and invalid inputs.\n\n| Test Category | Input Examples | Expected Behavior | Edge Cases |\n|---------------|----------------|-------------------|-------------|\n| Wildcard Parsing | `*`, `*/5`, `*/15` | Expands to full range with step intervals | Step values that don't divide evenly |\n| Range Parsing | `1-5`, `10-20`, `MON-FRI` | Expands to inclusive integer sequences | Cross-boundary ranges like `23-1` |\n| List Parsing | `1,3,5`, `MON,WED,FRI` | Expands to explicit value lists | Duplicate values and unsorted lists |\n| Step Parsing | `*/2`, `1-10/3`, `MON-FRI/2` | Applies step intervals to base ranges | Step larger than range span |\n| Alias Parsing | `@daily`, `@hourly`, `@weekly` | Converts to standard five-field format | Invalid aliases and malformed syntax |\n\n**Next Execution Time Tests** verify the `NextExecutionTime()` method's calendar arithmetic across temporal boundaries including month transitions, leap years, and daylight saving time adjustments. These tests require comprehensive coverage of edge cases that occur at calendar boundaries.\n\n| Boundary Type | Test Scenarios | Validation Points | Common Failures |\n|---------------|----------------|-------------------|-----------------|\n| Month Boundaries | Jobs scheduled for day 31 in February | Correctly skips to next valid month | Infinite loops on impossible dates |\n| Leap Year Handling | February 29 scheduling in non-leap years | Proper year advancement logic | Incorrect leap year detection |\n| DST Transitions | Jobs scheduled during spring-forward/fall-back | Maintains consistent UTC scheduling | Duplicate or skipped executions |\n| Year Boundaries | December to January transitions | Correct year increment behavior | Off-by-one errors in year calculation |\n| Week Boundaries | Day-of-week constraints across month ends | Proper week calculation logic | Incorrect week number arithmetic |\n\n**Timezone Conversion Tests** validate the timezone normalization logic that ensures consistent UTC storage while supporting local timezone interpretation. These tests verify correct conversion behavior across timezone boundaries and DST transitions.\n\n```\nTest Matrix: Timezone Conversion Validation\n- Standard Time Zones: EST, PST, GMT, UTC+5\n- DST Transitions: Spring forward, Fall back scenarios  \n- Edge Cases: Invalid timezones, missing location data\n- Boundary Conditions: Midnight crossings, leap seconds\n```\n\n#### Priority Queue Operation Tests\n\nPriority queue testing validates the core job ordering and atomic operation logic that ensures correct job distribution under concurrent access patterns. The priority queue must maintain strict ordering guarantees while supporting delayed execution and deduplication features.\n\n**Priority Ordering Tests** verify the `JobHeap` implementation maintains correct priority ordering under all insertion and removal operations. These tests validate both the heap property maintenance and the tie-breaking logic for jobs with identical priorities.\n\n| Test Scenario | Setup | Operation | Expected Result |\n|---------------|-------|-----------|-----------------|\n| Basic Priority Order | Jobs with priorities 1, 5, 3, 2 | Pop all jobs | Retrieved in order: 1, 2, 3, 5 |\n| Identical Priority | Multiple jobs with priority 3 | Pop with FIFO tie-breaking | Oldest job retrieved first |\n| Mixed Priorities | Interleaved high/low priority jobs | Random insertions and removals | Always returns highest priority |\n| Empty Queue | No jobs present | Pop operation | Returns nil with appropriate error |\n| Single Job | Queue with one job | Pop followed by another pop | First succeeds, second returns empty |\n\n**Delayed Execution Tests** validate the visibility timeout pattern implementation that holds jobs until their scheduled execution time. These tests verify that delayed jobs remain invisible to `ClaimJob()` operations until promotion time arrives.\n\n| Timing Scenario | Job Schedule | Current Time | Visibility Status |\n|-----------------|--------------|--------------|-------------------|\n| Future Scheduled | 2024-01-01 12:00 | 2024-01-01 11:30 | Hidden from claim operations |\n| Exact Time | 2024-01-01 12:00 | 2024-01-01 12:00 | Becomes visible immediately |\n| Past Due | 2024-01-01 12:00 | 2024-01-01 12:30 | Visible and claimable |\n| Promotion Batch | 100 delayed jobs | Time advancement | Batch promotion efficiency |\n\n**Deduplication Logic Tests** verify the `CheckDuplicate()` method correctly identifies duplicate job submissions using both idempotency keys and content hashing. These tests ensure no duplicate jobs enter the execution pipeline while avoiding false positive deduplication.\n\n| Deduplication Type | Primary Key | Secondary Check | Test Validation |\n|--------------------|-------------|-----------------|-----------------|\n| Idempotency Key | Client-provided unique key | Exact key match | Same key prevents duplicate submission |\n| Content Hash | Hash of normalized payload | Deterministic hash comparison | Identical content detected regardless of key |\n| Key Collision | Different jobs, same key | Payload comparison | Content differs, both jobs accepted |\n| Hash Collision | Different payloads, same hash | Full payload comparison | Rare hash collision handled correctly |\n\n⚠️ **Pitfall: Non-Deterministic Hash Calculation**\nA common testing mistake is creating content hashes that vary based on map iteration order or pointer values. The `computeContentHash()` function must produce identical hashes for semantically identical job payloads, requiring field normalization and sorted serialization. Test this by creating the same job payload multiple times and verifying hash consistency.\n\n#### Coordination Logic Tests\n\nCoordination logic testing validates the distributed consensus and failure detection algorithms that enable fault-tolerant job execution across multiple worker nodes. These tests focus on algorithmic correctness rather than network behavior, using mock coordination backends to ensure deterministic test execution.\n\n**Leader Election Tests** verify the consensus algorithm implementation that ensures exactly one coordinator node assumes leadership at any given time. These tests use controlled scenarios to validate election correctness under various failure and recovery patterns.\n\n| Election Scenario | Node Configuration | Expected Outcome | Validation Points |\n|-------------------|-------------------|------------------|-------------------|\n| Clean Election | 3 healthy nodes, no previous leader | Single winner elected | All nodes agree on leader |\n| Leadership Change | Current leader fails, 2 remaining nodes | New leader elected promptly | No split-brain condition |\n| Network Partition | 3 nodes split into 2+1 partitions | Majority partition maintains leadership | Minority partition steps down |\n| Simultaneous Startup | All nodes start concurrently | Deterministic leader selection | Election completes in bounded time |\n\n**Heartbeat Processing Tests** validate the failure detection logic that monitors worker health and triggers job recovery when workers become unresponsive. These tests verify correct timeout handling and state transitions.\n\n| Heartbeat Pattern | Worker Behavior | Expected Response | Recovery Actions |\n|-------------------|------------------|-------------------|------------------|\n| Regular Heartbeats | Heartbeat every 10 seconds | Worker marked healthy | No recovery needed |\n| Missed Heartbeat | Skip one heartbeat cycle | Worker marked suspect | Grace period activated |\n| Extended Silence | No heartbeat for 60 seconds | Worker marked failed | Job recovery initiated |\n| Recovery Heartbeat | Heartbeat after failure | Worker re-registered | Previous jobs reassigned |\n\n**Fencing Token Tests** verify the token-based mechanism that prevents stale worker reports from corrupting job state. These tests validate that only the current job assignee can report completion or failure status.\n\n| Token Scenario | Job Assignment Token | Report Token | Result |\n|-----------------|---------------------|--------------|--------|\n| Valid Token | Token 12345 | Token 12345 | Report accepted |\n| Stale Token | Token 12345 | Token 12344 | Report rejected |\n| No Token | Token assigned | No token provided | Report rejected |\n| Token Mismatch | Token for Job A | Token for Job B | Report rejected |\n\n> **Critical Testing Insight**: Unit tests for coordination logic must focus on algorithmic correctness rather than distributed system behavior. Use dependency injection and mock backends to create deterministic test scenarios that validate the decision-making logic without the complexity of actual network communication or timing dependencies.\n\n### Integration Testing\n\nIntegration testing for distributed systems is like conducting full-scale emergency response drills where all departments must coordinate under realistic stress conditions. Unlike unit tests that isolate individual components, integration tests validate system-wide behavior including timing dependencies, network communication, and failure recovery patterns that only emerge when components interact in realistic deployment scenarios.\n\nIntegration testing operates across three primary dimensions: **multi-worker job distribution scenarios**, **failure injection and recovery validation**, and **end-to-end job execution flows**. Each dimension addresses different aspects of distributed system correctness, ensuring the scheduler maintains consistency and availability despite the inherent challenges of distributed operation.\n\n#### Multi-Worker Coordination Scenarios\n\nMulti-worker scenarios validate the job distribution and coordination algorithms under realistic deployment conditions where multiple worker nodes compete for jobs while maintaining system consistency. These scenarios test the interaction between job queuing, worker registration, and coordination messaging.\n\n**Load Distribution Tests** verify that jobs are distributed fairly across available workers based on their capacity and current load. These tests validate both the initial assignment algorithm and the rebalancing behavior when worker availability changes.\n\n| Test Scenario | Worker Configuration | Job Load | Expected Distribution |\n|---------------|---------------------|----------|----------------------|\n| Equal Capacity | 3 workers, capacity 10 each | 15 jobs submitted | 5 jobs per worker |\n| Mixed Capacity | Workers with capacity 5, 10, 15 | 30 jobs submitted | Proportional to capacity |\n| Dynamic Scaling | Start 2 workers, add 2 more | Continuous job stream | Load rebalances to new workers |\n| Worker Removal | 4 workers, remove 2 gracefully | Jobs in progress | Completing jobs finish, new jobs redistribute |\n\n**Concurrent Job Claiming Tests** validate the atomic job assignment mechanism prevents duplicate execution when multiple workers simultaneously attempt to claim available jobs. These tests stress-test the `ClaimJob()` operation under high concurrency.\n\n```\nConcurrency Test Pattern:\n1. Submit 100 jobs to priority queue\n2. Start 10 workers simultaneously  \n3. Each worker attempts to claim jobs concurrently\n4. Verify exactly 100 jobs are claimed (no duplicates)\n5. Verify no jobs are claimed by multiple workers\n6. Validate fencing token uniqueness across claims\n```\n\n**Capability Matching Tests** verify that jobs requiring specific worker capabilities are assigned only to workers that advertise those capabilities. These tests validate the constraint satisfaction logic in the job assignment algorithm.\n\n| Job Requirements | Available Workers | Assignment Expectation | Validation |\n|------------------|-------------------|------------------------|------------|\n| `[\"python\", \"gpu\"]` | Worker A: `[\"python\"]`, Worker B: `[\"python\", \"gpu\"]` | Assigned to Worker B | Capability constraints satisfied |\n| `[\"database\"]` | No workers with database capability | Job remains unassigned | Waits for capable worker |\n| `[]` (no requirements) | Any available worker | Assigned to any worker | No capability restrictions |\n\n#### Failure Injection and Recovery\n\nFailure injection testing validates the system's resilience to various failure modes that occur in production distributed environments. These tests systematically introduce failures and verify that the system detects, isolates, and recovers from failures while maintaining data consistency.\n\n**Worker Failure Scenarios** test the system's ability to detect unresponsive workers and reassign their jobs to healthy workers without data loss or duplicate execution.\n\n| Failure Type | Injection Method | Expected Detection | Recovery Validation |\n|--------------|------------------|-------------------|-------------------|\n| Sudden Worker Death | Kill worker process | Missed heartbeat detection | Jobs reassigned within timeout |\n| Network Partition | Block worker network access | Heartbeat timeout | Jobs recovered, worker isolated |\n| Slow Worker | Introduce artificial delays | Performance degradation detection | Load rebalanced to faster workers |\n| Resource Exhaustion | Consume worker memory/CPU | Resource monitoring alerts | Worker marked unavailable |\n\n**Coordinator Failure Tests** validate the leader election and failover mechanisms that ensure continuous system operation despite coordinator node failures.\n\n```\nCoordinator Failover Test Sequence:\n1. Start 3-node coordinator cluster with elected leader\n2. Submit jobs and verify normal operation\n3. Kill current leader node abruptly\n4. Verify new leader election completes within SLA\n5. Confirm job scheduling continues without interruption\n6. Validate no jobs are lost or duplicated during transition\n```\n\n**Split-Brain Prevention Tests** verify the coordination system prevents multiple nodes from simultaneously believing they are the leader, which could result in conflicting job assignments and data corruption.\n\n| Network Partition | Partition A | Partition B | Expected Behavior |\n|-------------------|-------------|-------------|-------------------|\n| 3-node cluster, 2+1 split | 2 nodes | 1 node | Majority partition maintains leadership |\n| 5-node cluster, 2+3 split | 2 nodes | 3 nodes | Majority partition (3 nodes) leads |\n| 2-node cluster partition | 1 node | 1 node | Both step down, no leader until reunion |\n\n**Data Consistency Tests** validate that concurrent operations and failures don't corrupt the job state or create impossible system states like jobs assigned to multiple workers simultaneously.\n\n| Consistency Scenario | Operation Pattern | Validation |\n|----------------------|-------------------|------------|\n| Concurrent Job Updates | Multiple workers report on same job | Last valid update wins, fencing prevents conflicts |\n| Worker Failure During Execution | Worker dies mid-job execution | Job marked for retry, not marked complete |\n| Coordinator Failure During Assignment | Leader dies during job assignment | Assignment either completes fully or rolls back |\n\n> **Integration Testing Philosophy**: Integration tests should focus on emergent behaviors that only appear when components interact under realistic conditions. Unlike unit tests that verify algorithmic correctness, integration tests validate system properties like consistency, availability, and partition tolerance that define distributed system correctness.\n\n#### End-to-End Job Execution Flow\n\nEnd-to-end testing validates complete job lifecycle flows from initial cron schedule evaluation through final execution completion. These tests ensure all system components integrate correctly to deliver the promised scheduling and execution guarantees.\n\n**Complete Job Lifecycle Tests** trace individual jobs through the entire execution pipeline, validating state transitions and ensuring no jobs are lost or duplicated during normal operation.\n\n```\nEnd-to-End Flow Validation:\n1. Cron timer fires for scheduled job\n2. Job inserted into priority queue with correct priority\n3. Available worker claims job atomically\n4. Worker executes job payload successfully  \n5. Worker reports completion with valid fencing token\n6. Job marked complete and archived\n7. Next cron execution calculated and scheduled\n```\n\n**Retry and Failure Handling Tests** verify the system correctly handles job execution failures and applies the configured retry policy including exponential backoff and maximum retry limits.\n\n| Job Failure Type | Retry Configuration | Expected Behavior |\n|-------------------|-------------------|-------------------|\n| Transient Failure | Max retries: 3, exponential backoff | Job retried with increasing delays |\n| Permanent Failure | Max retries: 3, all attempts fail | Job moved to dead letter queue |\n| Worker Failure | Job in progress when worker dies | Job reassigned to different worker |\n| Timeout Failure | Job exceeds execution timeout | Job killed and retried on different worker |\n\n**Scheduling Accuracy Tests** validate that recurring jobs are scheduled and executed according to their cron expressions with acceptable timing precision despite system load and failures.\n\n| Cron Expression | Expected Execution Pattern | Tolerance | Validation Method |\n|-----------------|---------------------------|-----------|-------------------|\n| `0 */5 * * *` | Every 5 minutes | ±30 seconds | Compare actual vs expected execution times |\n| `0 0 * * MON` | Every Monday at midnight | ±2 minutes | Verify weekly execution pattern |\n| `0 0 1 * *` | First day of each month | ±5 minutes | Confirm monthly boundary handling |\n\n⚠️ **Pitfall: Integration Test Environment Consistency**\nIntegration tests often fail intermittently due to timing dependencies and resource contention. Ensure test environments provide consistent resource allocation, use deterministic timing where possible, and implement proper test isolation to prevent tests from interfering with each other. Consider using containerized test environments to ensure reproducible conditions.\n\n### Milestone Checkpoints\n\nMilestone checkpoints provide structured validation points that ensure correct implementation at each development stage. These checkpoints serve as both progress indicators and regression prevention mechanisms, catching integration issues early before they compound into complex debugging scenarios.\n\nThink of milestone checkpoints like progressive flight training evaluations - a pilot must demonstrate mastery of basic instruments before advancing to navigation, then to weather handling, and finally to emergency procedures. Each checkpoint validates not just new functionality but also ensures previous capabilities remain intact under the expanded system complexity.\n\n#### Milestone 1: Cron Expression Parser Validation\n\nThe first milestone checkpoint validates the cron expression parsing and next execution time calculation logic that forms the foundation for all scheduling operations.\n\n**Functional Verification Tests** ensure the parser correctly handles the full spectrum of cron expression syntax while providing accurate next execution time calculations.\n\n| Validation Category | Test Commands | Expected Behavior | Success Criteria |\n|---------------------|---------------|-------------------|-------------------|\n| Basic Parsing | `go test ./internal/cron/...` | All parser unit tests pass | 100% test coverage on core parsing logic |\n| Expression Validation | Parse sample expressions | Valid expressions accepted, invalid rejected | Clear error messages for malformed input |\n| Next Time Calculation | Calculate execution times | Accurate future timestamps returned | Timing precision within 1-second tolerance |\n| Timezone Support | Test across multiple timezones | Correct UTC normalization | DST transitions handled properly |\n\n**Parser Stress Testing** validates performance and correctness under high-volume parsing operations that simulate production workloads.\n\n```\nStress Test Validation:\n- Parse 10,000 varied cron expressions\n- Measure parsing performance (target: <1ms per expression)\n- Verify memory usage remains bounded\n- Confirm no memory leaks during batch processing\n```\n\n**Edge Case Coverage** ensures the parser handles calendar arithmetic edge cases that commonly cause scheduling failures in production systems.\n\n| Edge Case Category | Specific Tests | Validation Points |\n|--------------------|----------------|-------------------|\n| Month Boundaries | Feb 31, Apr 31 expressions | Correctly skips to next valid date |\n| Leap Year Handling | Feb 29 in non-leap years | Proper year advancement |\n| DST Transitions | 2 AM during spring forward | No duplicate or missed executions |\n| Year Rollover | Dec 31 to Jan 1 transitions | Correct year increment |\n\n#### Milestone 2: Priority Queue System Validation\n\nThe second milestone checkpoint validates the priority queue implementation including delayed execution, deduplication, and atomic job operations.\n\n**Queue Operation Verification** tests the core priority queue functionality under both single-threaded and concurrent access patterns.\n\n| Test Category | Validation Command | Success Criteria | Performance Target |\n|---------------|-------------------|------------------|-------------------|\n| Priority Ordering | `go test ./internal/queue/priority_test.go` | Jobs dequeued in strict priority order | O(log n) insertion/removal |\n| Delayed Jobs | `go test ./internal/queue/delay_test.go` | Scheduled jobs remain invisible until promotion | Sub-second promotion accuracy |\n| Deduplication | `go test ./internal/queue/dedup_test.go` | Duplicate submissions prevented | Hash calculation <100μs |\n| Concurrent Access | `go test -race ./internal/queue/...` | No race conditions detected | Thread-safe under load |\n\n**Redis Integration Testing** validates the persistent queue backend handles Redis connection failures and ensures data durability across service restarts.\n\n```\nRedis Integration Validation:\n1. Start Redis and queue service\n2. Submit 1000 jobs with mixed priorities\n3. Stop queue service (graceful shutdown)\n4. Restart queue service \n5. Verify all jobs recovered with correct priorities\n6. Test Redis failover scenarios\n```\n\n**Deduplication Accuracy Tests** verify the duplicate detection logic correctly identifies duplicate submissions while avoiding false positives that would reject legitimate jobs.\n\n| Deduplication Scenario | Input Jobs | Expected Outcome | Validation |\n|------------------------|------------|------------------|------------|\n| Identical Payloads | Same job submitted twice | Only one job queued | Content hash match detected |\n| Same Idempotency Key | Different payloads, same key | Both jobs rejected after first | Key-based deduplication |\n| Hash Collision Simulation | Crafted payloads with same hash | Jobs accepted, full comparison performed | Rare collision handled |\n\n#### Milestone 3: Worker Coordination Validation\n\nThe third milestone checkpoint validates the complete distributed coordination system including leader election, worker registration, and job recovery mechanisms.\n\n**Coordination System Testing** verifies the distributed consensus and worker management functionality operates correctly across multiple nodes.\n\n| Coordination Feature | Test Approach | Success Criteria | Fault Tolerance |\n|---------------------|---------------|------------------|-----------------|\n| Leader Election | Multi-node cluster startup | Single leader elected | Recovery from leader failure |\n| Worker Registration | Dynamic worker join/leave | Workers tracked correctly | Graceful shutdown handling |\n| Job Assignment | Multi-worker job distribution | Fair load balancing | Failed worker job recovery |\n| Heartbeat Monitoring | Worker health tracking | Failure detection within SLA | False positive prevention |\n\n**Multi-Node Integration Tests** validate system behavior across realistic deployment scenarios with multiple coordinator and worker nodes.\n\n```\nMulti-Node Test Scenario:\n1. Deploy 3-node coordinator cluster\n2. Register 5 worker nodes with varying capacity\n3. Submit continuous job stream (100 jobs/minute)\n4. Introduce random worker failures\n5. Verify job completion rate >99%\n6. Validate no duplicate job executions\n7. Confirm system stability over 1-hour test\n```\n\n**Failure Recovery Validation** tests the system's ability to maintain operation and data consistency during various failure scenarios.\n\n| Failure Type | Recovery Test | Validation Metrics |\n|--------------|---------------|--------------------|\n| Worker Node Failure | Kill worker during job execution | Jobs reassigned within 60 seconds |\n| Coordinator Failure | Kill leader node | New leader elected within 30 seconds |\n| Network Partition | Isolate subset of nodes | Majority partition continues operation |\n| Database Failure | Redis/etcd unavailability | Graceful degradation, recovery on reconnect |\n\n**End-to-End System Validation** confirms the complete system delivers the promised distributed job scheduling functionality with acceptable performance and reliability characteristics.\n\n```\nComplete System Checkpoint:\n✓ Cron jobs scheduled with <5 second accuracy\n✓ Priority ordering maintained under load\n✓ Worker failures handled without job loss  \n✓ Leader election completes in <30 seconds\n✓ System throughput >1000 jobs/hour/worker\n✓ Memory usage bounded under continuous operation\n✓ No race conditions detected in stress testing\n```\n\n> **Milestone Checkpoint Philosophy**: Each checkpoint should validate not just new functionality but also ensure previous milestone capabilities remain intact. This regression prevention approach catches integration issues early and provides confidence for continued development on a solid foundation.\n\n### Implementation Guidance\n\nThe testing strategy implementation requires careful orchestration of test environments, mock services, and validation frameworks that can handle the complexity of distributed system testing while maintaining deterministic and reproducible results.\n\n**A. Testing Technology Recommendations:**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Unit Testing | Go's built-in testing package | Testify with assertions and mocking |\n| Integration Testing | Docker Compose test environments | Kubernetes test namespaces |\n| Mock Services | Hand-written mocks | Gomock generated mocks |\n| Time Control | Fixed time.Now() override | Clockwork time manipulation |\n| Redis Testing | Miniredis embedded server | Real Redis with test database |\n| etcd Testing | Embedded etcd test server | Real etcd cluster in containers |\n\n**B. Testing File Structure:**\n```\nproject-root/\n  internal/\n    cron/\n      parser.go\n      parser_test.go           ← Unit tests for cron parsing\n      integration_test.go      ← Cron timing integration tests\n    queue/\n      priority.go\n      priority_test.go         ← Unit tests for queue operations\n      redis_test.go           ← Redis integration tests\n    coordinator/\n      coordinator.go\n      coordinator_test.go      ← Unit tests for coordination logic\n      election_test.go        ← Leader election integration tests\n  test/\n    integration/\n      multi_worker_test.go     ← Multi-node integration scenarios\n      failure_injection_test.go ← Failure recovery tests\n      e2e_test.go             ← Complete system validation\n    fixtures/\n      test_jobs.json          ← Sample job definitions\n      cron_expressions.txt    ← Test cron patterns\n    mocks/\n      mock_storage.go         ← Generated storage mocks\n      mock_transport.go       ← Generated transport mocks\n  scripts/\n    test_runner.sh            ← Automated test execution\n    setup_test_env.sh         ← Test environment setup\n```\n\n**C. Core Testing Infrastructure (Complete Implementation):**\n\n```go\n// test/infrastructure/test_harness.go\npackage infrastructure\n\nimport (\n    \"context\"\n    \"testing\"\n    \"time\"\n    \"github.com/stretchr/testify/require\"\n    \"github.com/alicebob/miniredis/v2\"\n    \"go.etcd.io/etcd/server/v3/embed\"\n)\n\n// TestHarness provides complete testing infrastructure for distributed scheduler tests\ntype TestHarness struct {\n    t        *testing.T\n    redis    *miniredis.Miniredis\n    etcd     *embed.Etcd\n    cleanup  []func()\n    timeCtrl *TimeController\n}\n\n// NewTestHarness creates a complete testing environment with Redis, etcd, and time control\nfunc NewTestHarness(t *testing.T) *TestHarness {\n    redis, err := miniredis.Run()\n    require.NoError(t, err)\n    \n    etcdConfig := embed.NewConfig()\n    etcdConfig.Dir = t.TempDir()\n    etcdConfig.LogLevel = \"error\"\n    etcdConfig.Logger = \"zap\"\n    \n    etcd, err := embed.StartEtcd(etcdConfig)\n    require.NoError(t, err)\n    \n    harness := &TestHarness{\n        t:        t,\n        redis:    redis,\n        etcd:     etcd,\n        timeCtrl: NewTimeController(),\n        cleanup:  make([]func(), 0),\n    }\n    \n    harness.cleanup = append(harness.cleanup, func() {\n        redis.Close()\n        etcd.Close()\n    })\n    \n    return harness\n}\n\n// TimeController provides deterministic time control for testing\ntype TimeController struct {\n    currentTime time.Time\n    callbacks   []func(time.Time)\n}\n\nfunc NewTimeController() *TimeController {\n    return &TimeController{\n        currentTime: time.Date(2024, 1, 1, 12, 0, 0, 0, time.UTC),\n        callbacks:   make([]func(time.Time), 0),\n    }\n}\n\nfunc (tc *TimeController) Now() time.Time {\n    return tc.currentTime\n}\n\nfunc (tc *TimeController) Advance(duration time.Duration) {\n    tc.currentTime = tc.currentTime.Add(duration)\n    for _, callback := range tc.callbacks {\n        callback(tc.currentTime)\n    }\n}\n\n// Cleanup releases all test resources\nfunc (h *TestHarness) Cleanup() {\n    for i := len(h.cleanup) - 1; i >= 0; i-- {\n        h.cleanup[i]()\n    }\n}\n```\n\n**D. Unit Test Skeleton Templates:**\n\n```go\n// internal/cron/parser_test.go - Cron Parser Unit Tests\npackage cron\n\nimport (\n    \"testing\"\n    \"time\"\n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/require\"\n)\n\nfunc TestParseCronExpression(t *testing.T) {\n    tests := []struct {\n        name        string\n        expression  string\n        expectValid bool\n        expectError string\n    }{\n        // TODO 1: Add test cases for valid cron expressions\n        // TODO 2: Add test cases for invalid field values  \n        // TODO 3: Add test cases for malformed syntax\n        // TODO 4: Add test cases for timezone expressions\n    }\n    \n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            // TODO 5: Call ParseCronExpression with test input\n            // TODO 6: Validate expected success/failure\n            // TODO 7: Check error message format if applicable\n            // TODO 8: Verify parsed field values for valid expressions\n        })\n    }\n}\n\nfunc TestNextExecutionTime(t *testing.T) {\n    // TODO 1: Create test cron expressions with known patterns\n    // TODO 2: Set up controlled time scenarios  \n    // TODO 3: Calculate expected next execution times manually\n    // TODO 4: Validate NextExecutionTime returns correct results\n    // TODO 5: Test edge cases like month boundaries and DST\n    // TODO 6: Verify timezone conversion accuracy\n}\n```\n\n```go\n// internal/queue/priority_test.go - Priority Queue Unit Tests  \npackage queue\n\nfunc TestJobHeapOrdering(t *testing.T) {\n    heap := NewJobHeap()\n    \n    // TODO 1: Create jobs with different priority values\n    // TODO 2: Insert jobs in random order\n    // TODO 3: Pop all jobs and verify strict priority ordering\n    // TODO 4: Test tie-breaking for identical priorities\n    // TODO 5: Validate heap property maintained during operations\n}\n\nfunc TestDelayedJobVisibility(t *testing.T) {\n    queue := NewPriorityQueue(testRedisConfig())\n    \n    // TODO 1: Submit jobs with future ScheduledAt times\n    // TODO 2: Attempt ClaimJob before scheduled time\n    // TODO 3: Verify jobs remain invisible \n    // TODO 4: Advance time to scheduled execution\n    // TODO 5: Verify jobs become claimable after promotion\n}\n\nfunc TestDeduplication(t *testing.T) {\n    queue := NewPriorityQueue(testRedisConfig())\n    \n    // TODO 1: Create jobs with identical idempotency keys\n    // TODO 2: Submit duplicate jobs concurrently\n    // TODO 3: Verify only one job accepted\n    // TODO 4: Test content-based deduplication\n    // TODO 5: Validate hash collision handling\n}\n```\n\n**E. Integration Test Framework:**\n\n```go\n// test/integration/multi_worker_test.go\npackage integration\n\nimport (\n    \"context\"\n    \"testing\"\n    \"time\"\n    \"sync\"\n    \"github.com/stretchr/testify/require\"\n)\n\nfunc TestMultiWorkerJobDistribution(t *testing.T) {\n    harness := infrastructure.NewTestHarness(t)\n    defer harness.Cleanup()\n    \n    // TODO 1: Start coordinator cluster with test harness\n    // TODO 2: Register multiple workers with different capacities\n    // TODO 3: Submit batch of jobs with mixed priorities\n    // TODO 4: Verify jobs distributed proportionally to capacity\n    // TODO 5: Check no jobs claimed by multiple workers\n    // TODO 6: Validate all jobs eventually complete\n}\n\nfunc TestWorkerFailureRecovery(t *testing.T) {\n    harness := infrastructure.NewTestHarness(t)\n    defer harness.Cleanup()\n    \n    // TODO 1: Start system with multiple workers\n    // TODO 2: Assign jobs to workers\n    // TODO 3: Simulate worker failure (kill process)\n    // TODO 4: Verify failed worker jobs are reassigned\n    // TODO 5: Confirm no duplicate execution occurs\n    // TODO 6: Check system continues normal operation\n}\n```\n\n**F. Milestone Checkpoint Validation:**\n\n```bash\n#!/bin/bash\n# scripts/milestone_checkpoint.sh\n\n# Milestone 1: Cron Parser Validation\necho \"=== Milestone 1: Cron Expression Parser ===\"\ngo test -v ./internal/cron/... || exit 1\ngo test -race ./internal/cron/... || exit 1\n\n# Validate specific parser capabilities\necho \"Testing cron expression edge cases...\"\ngo run ./cmd/cron-validator/ < test/fixtures/cron_expressions.txt || exit 1\n\n# Milestone 2: Priority Queue Validation  \necho \"=== Milestone 2: Priority Queue System ===\"\ngo test -v ./internal/queue/... || exit 1\n\n# Start Redis for integration testing\ndocker run -d --name test-redis -p 6379:6379 redis:alpine\nsleep 2\n\ngo test -v ./test/integration/queue_test.go || exit 1\ndocker stop test-redis && docker rm test-redis\n\n# Milestone 3: Worker Coordination Validation\necho \"=== Milestone 3: Worker Coordination ===\"\ngo test -v ./internal/coordinator/... || exit 1\ngo test -v ./test/integration/coordination_test.go || exit 1\n\n# End-to-End System Validation\necho \"=== Complete System Validation ===\"\n./scripts/setup_test_env.sh\ngo test -v -timeout=5m ./test/integration/e2e_test.go || exit 1\n\necho \"All milestone checkpoints passed successfully!\"\n```\n\n**G. Debugging Integration Test Failures:**\n\n| Symptom | Likely Cause | Diagnosis | Fix |\n|---------|--------------|-----------|-----|\n| Tests pass individually, fail in suite | Resource cleanup issues | Check for leaked connections/processes | Add proper cleanup in teardown |\n| Intermittent integration failures | Race conditions or timing issues | Add deterministic timing controls | Use TimeController for predictable timing |\n| \"Connection refused\" errors | Test infrastructure not ready | Services starting too quickly | Add readiness checks before tests |\n| Memory leaks in long tests | Resources not released | Profile memory usage | Ensure all contexts cancelled, connections closed |\n| etcd election timeouts | Cluster formation issues | Check etcd logs for split-brain | Configure proper cluster membership |\n\nThis comprehensive testing strategy ensures reliable validation of the distributed job scheduler across all implementation phases, providing both development feedback and production confidence through systematic verification of system behavior under normal and failure conditions.\n\n\n## Debugging Guide\n\n> **Milestone(s):** This section covers debugging techniques that apply across all three milestones - diagnosing cron parsing and scheduling issues (Milestone 1), troubleshooting queue operation failures and priority conflicts (Milestone 2), and resolving worker coordination and distributed consensus problems (Milestone 3).\n\nDebugging a distributed job scheduler presents unique challenges that combine the complexity of distributed systems with the time-sensitive nature of scheduled execution. Think of debugging a distributed scheduler like diagnosing problems in a city's emergency response system - you need to understand not just individual component failures, but how those failures cascade through the entire coordination network, potentially causing missed emergencies or duplicate responses across multiple stations.\n\nThe debugging process requires systematic observation of three interconnected layers: the scheduling logic that determines when jobs should run, the coordination protocols that distribute work across workers, and the execution monitoring that tracks job completion. Unlike debugging a single-process application where you can step through code linearly, distributed scheduler debugging requires correlating events across multiple nodes, understanding timing relationships, and distinguishing between genuine failures and expected distributed systems behavior like temporary network partitions.\n\nThis guide provides structured approaches to identify, diagnose, and resolve the most common categories of distributed scheduler problems. Each troubleshooting workflow follows a hypothesis-driven approach that systematically eliminates potential causes while gathering evidence about the actual failure mode.\n\n### Common Symptoms\n\nUnderstanding the observable symptoms of distributed scheduler problems enables rapid problem classification and appropriate diagnostic approaches. Each symptom category corresponds to failures in specific system layers, allowing targeted investigation rather than broad system exploration.\n\n**Duplicate Job Execution Symptoms**\n\nThe most critical symptom category involves jobs executing multiple times despite exactly-once execution guarantees. This manifests in several observable patterns that indicate different underlying failure modes.\n\nMultiple completion reports for the same job represent the classic duplicate execution symptom. The system logs show the same job ID completing successfully on different workers within a short time window, often with identical or conflicting results. This typically indicates failures in the fencing token validation mechanism or race conditions during job claiming.\n\nIdempotency key violations occur when jobs with identical `IdempotencyKey` values execute multiple times despite deduplication logic. The symptom appears as duplicate database records, double-charged transactions, or redundant external API calls that should have been prevented by the deduplication system. This suggests failures in the `DeduplicationChecker` or inconsistent deduplication state across coordinator nodes.\n\nWorker claim conflicts manifest as multiple workers believing they own the same job simultaneously. The logs show different worker IDs reporting progress or completion for identical job IDs, often accompanied by fencing token validation errors when workers attempt to report completion. This indicates failures in the atomic job claiming mechanism or coordinator split-brain scenarios.\n\nRetry amplification creates a cascade of duplicate executions when failed jobs retry across multiple workers simultaneously. The symptom appears as exponentially increasing execution attempts for jobs that should follow controlled retry policies, often overwhelming downstream systems with duplicate requests. This suggests coordination failures during worker crash scenarios or incorrect retry state management.\n\n| Duplicate Symptom | Observable Evidence | Likely Root Cause | Investigation Priority |\n|------------------|-------------------|------------------|---------------------|\n| Multiple completion reports | Same job ID completing on different workers | Fencing token validation failure | High - affects data integrity |\n| Idempotency violations | Same IdempotencyKey executes multiple times | DeduplicationChecker failure | Critical - bypasses client guarantees |\n| Worker claim conflicts | Multiple workers reporting same job progress | Atomic claiming race condition | High - indicates coordination breakdown |\n| Retry amplification | Exponential retry attempts across workers | Failed worker job recovery logic | Medium - self-limiting but wasteful |\n\n**Missed Schedule Symptoms**\n\nMissed schedules represent the opposite failure mode where jobs fail to execute when expected, violating timing guarantees and potentially causing business impact through delayed processing.\n\nCron schedule drift occurs when recurring jobs gradually shift their execution times away from the expected cron schedule. The symptom manifests as jobs that should run every hour at :00 minutes instead executing at :03, then :07, then :12, creating an accumulating delay. This typically indicates problems in next execution time calculation or clock synchronization across coordinator nodes.\n\nDelayed job promotion failures cause jobs with future execution times to remain invisible past their scheduled execution time. The symptom appears as jobs stuck in delayed state while their `ScheduledAt` time has passed, often accompanied by gaps in execution logs during specific time periods. This suggests failures in the `PromoteDelayedJobs` background process.\n\nPriority queue starvation occurs when high-priority jobs prevent lower-priority jobs from executing, even when worker capacity exists. The symptom manifests as continuously growing queues of lower-priority jobs while only high-priority jobs execute, eventually leading to timeout failures for starved jobs. This indicates problems in priority queue balancing or worker assignment algorithms.\n\nTimezone calculation errors cause jobs to execute at incorrect absolute times, particularly during daylight saving time transitions. The symptom appears as jobs executing one hour early or late relative to local business hours, or failing to execute during the \"spring forward\" hour that doesn't exist. This suggests failures in UTC normalization or timezone conversion logic.\n\nWorker capacity exhaustion prevents job execution when all workers reach their capacity limits simultaneously. The symptom manifests as growing job queues despite healthy workers, often correlating with long-running job execution times or worker resource constraints. This indicates insufficient worker scaling or improper capacity management.\n\n| Missed Schedule Symptom | Observable Evidence | Likely Root Cause | Investigation Priority |\n|------------------------|-------------------|------------------|---------------------|\n| Cron schedule drift | Gradual execution time delays | Next execution calculation errors | Medium - affects long-term reliability |\n| Delayed job promotion failures | Jobs stuck past ScheduledAt time | PromoteDelayedJobs process failure | High - breaks delayed execution |\n| Priority queue starvation | Lower priority jobs never execute | Priority balancing algorithm failure | Medium - affects fairness guarantees |\n| Timezone calculation errors | Jobs execute at wrong local times | UTC conversion or DST handling bugs | High - affects business SLA compliance |\n| Worker capacity exhaustion | Growing queues despite healthy workers | Capacity management or scaling issues | Medium - affects throughput scaling |\n\n**Worker Coordination Failures**\n\nWorker coordination failures disrupt the distributed consensus mechanisms that enable fault-tolerant job distribution, often cascading into both duplicate execution and missed schedule problems.\n\nLeader election split-brain scenarios occur when multiple coordinator nodes simultaneously believe they hold leadership authority. The symptom manifests as conflicting job assignments, duplicate scheduling decisions, and workers receiving contradictory instructions from different coordinator nodes. The logs show multiple nodes reporting leadership status and issuing fencing tokens with overlapping ranges.\n\nHeartbeat timeout cascades happen when network issues cause multiple workers to appear failed simultaneously, triggering mass job reassignment that overwhelms the remaining workers. The symptom appears as sudden spikes in job reassignment activity followed by worker overload, often correlating with network connectivity issues or coordination service degradation.\n\nWorker registration failures prevent new workers from joining the cluster or cause existing workers to lose their registration intermittently. The symptom manifests as workers that appear healthy locally but don't receive job assignments, often accompanied by authentication or connectivity errors when attempting to register with the coordinator.\n\nJob recovery loops occur when failed worker detection triggers job reassignment, but the reassignment process itself fails, creating repeated attempts to recover the same jobs. The symptom appears as continuous job state transitions between `CLAIMED` and `PENDING` without successful execution, often accompanied by worker state thrashing.\n\nFencing token validation errors prevent workers from completing jobs due to stale or invalid authorization tokens. The symptom manifests as successful job execution followed by completion report rejection, causing jobs to remain in `EXECUTING` state until timeout. This typically indicates coordination service connectivity issues or token generation failures.\n\n| Coordination Failure Symptom | Observable Evidence | Likely Root Cause | Investigation Priority |\n|----------------------------|-------------------|------------------|---------------------|\n| Leader election split-brain | Multiple coordinators claiming leadership | Consensus algorithm failure or network partition | Critical - affects all system operations |\n| Heartbeat timeout cascades | Mass worker failure detection | Network issues or coordination service overload | High - triggers unnecessary job reassignment |\n| Worker registration failures | Healthy workers not receiving job assignments | Authentication or connectivity problems | Medium - affects cluster capacity |\n| Job recovery loops | Jobs stuck cycling between CLAIMED and PENDING | Job reassignment logic failures | High - creates resource waste and blocks execution |\n| Fencing token validation errors | Job completion reports rejected despite success | Stale tokens or coordinator connectivity issues | High - causes jobs to appear failed incorrectly |\n\n### Diagnostic Tools\n\nEffective diagnosis of distributed scheduler problems requires coordinated observation across multiple system components, with particular emphasis on correlating events across time and node boundaries. The diagnostic strategy combines structured logging, quantitative metrics, and distributed tracing to build a comprehensive picture of system behavior during both normal operation and failure scenarios.\n\n**Logging Strategies**\n\nStructured logging provides the foundation for distributed scheduler diagnosis by creating searchable, correlatable records of system events across all components. The logging strategy must balance information richness with performance impact while ensuring consistent data formats across all system boundaries.\n\nEach log entry includes mandatory context fields that enable correlation across distributed components: `component` identifies the logging service (coordinator, worker, queue), `node_id` specifies the physical machine, `correlation_id` links related operations across services, `timestamp` provides nanosecond-precision timing, and `log_level` indicates severity. Additional fields like `job_id`, `worker_id`, and `fencing_token` provide domain-specific context for scheduler operations.\n\nThe coordinator logging strategy focuses on decision points and state transitions that affect job distribution and worker coordination. Leadership election events log candidate announcements, vote outcomes, and leadership transitions with detailed reasoning. Job assignment decisions include worker selection criteria, capacity calculations, and assignment success or failure reasons. Worker health monitoring logs heartbeat reception, timeout detection, and failure recovery initiation with precise timing information.\n\nWorker logging emphasizes job execution lifecycle and coordination protocol participation. Job claim attempts log the claiming worker ID, job priority comparison results, and atomic claim success or failure with detailed error information. Job execution logging captures start times, progress checkpoints, completion status, and any execution errors with full stack traces. Heartbeat transmission logs include coordinator connectivity status and any heartbeat rejection reasons.\n\nQueue operation logging tracks job flow through the priority queue system with emphasis on state transitions and timing. Job submission logs include deduplication check results, priority assignment reasoning, and queue insertion confirmation. Job promotion from delayed to active status logs the promotion trigger time and any promotion failures. Priority ordering logs capture job comparison decisions during queue operations.\n\n| Log Level | Coordinator Events | Worker Events | Queue Events | Required Fields |\n|-----------|-------------------|---------------|--------------|-----------------|\n| ERROR | Leadership loss, worker failure detection | Job execution failures, heartbeat rejections | Queue corruption, deduplication failures | component, node_id, correlation_id, timestamp, error_details |\n| WARN | Slow heartbeat responses, job reassignments | Long-running jobs, capacity warnings | Priority queue imbalance, delayed promotion lag | component, node_id, correlation_id, timestamp, warning_reason |\n| INFO | Leadership elections, job assignments | Job claims, execution completions | Job submissions, priority promotions | component, node_id, correlation_id, timestamp, operation_result |\n| DEBUG | Heartbeat processing, fencing token generation | Job progress updates, worker registrations | Deduplication checks, priority comparisons | component, node_id, correlation_id, timestamp, detailed_state |\n\n**Metrics Collection**\n\nQuantitative metrics provide real-time insight into system health and performance characteristics, enabling both automated alerting and trend analysis for capacity planning. The metrics strategy emphasizes leading indicators that predict problems before they cause observable failures.\n\nJob execution metrics track the core business functionality of the scheduler system. Job submission rate measures incoming work load with breakdown by priority levels and job types. Job completion rate tracks successful execution with timing distributions to identify performance degradation. Job failure rate monitors error conditions with categorization by failure type (timeout, execution error, coordination failure) to identify systemic issues. Job queue depth measures pending work backlog with priority-level breakdown to identify starvation or overload conditions.\n\nWorker coordination metrics monitor the health of the distributed consensus mechanisms. Active worker count tracks cluster capacity with breakdown by worker capabilities and current load. Heartbeat latency measures coordination responsiveness with percentile distributions to identify coordination service degradation. Leader election frequency tracks consensus stability - frequent elections indicate network or leadership failures. Job assignment latency measures the time from job submission to worker claim, indicating coordination efficiency.\n\nQueue operation metrics provide insight into the priority queue performance and correctness. Deduplication hit rate measures how frequently duplicate jobs are submitted, indicating client behavior patterns. Delayed job promotion latency tracks the accuracy of scheduled execution timing. Priority queue operation latency measures the performance of queue insertions and claims under load.\n\nSystem-level metrics monitor the underlying infrastructure health. Coordination service response times track etcd or Redis performance that underpins consensus operations. Network partition detection counts coordination connectivity failures between nodes. Memory usage tracks queue size growth and potential memory leaks in long-running processes.\n\n| Metric Category | Metric Name | Aggregation | Alert Thresholds | Business Impact |\n|-----------------|-------------|-------------|------------------|-----------------|\n| Job Execution | job_submission_rate | Per second by priority | > 1000/sec (capacity warning) | Indicates incoming load trends |\n| Job Execution | job_completion_latency_p99 | 99th percentile in milliseconds | > 30000ms (30 second warning) | Affects SLA compliance |\n| Job Execution | job_failure_rate | Percentage over 5-minute window | > 5% (critical alert) | Direct business impact |\n| Worker Coordination | active_worker_count | Current count | < 2 workers (critical alert) | Affects fault tolerance |\n| Worker Coordination | heartbeat_latency_p95 | 95th percentile in milliseconds | > 5000ms (coordination degradation) | Predicts coordination failures |\n| Worker Coordination | leader_election_frequency | Elections per hour | > 1/hour (stability warning) | Indicates consensus instability |\n| Queue Operations | deduplication_hit_rate | Percentage over 1-minute window | > 50% (client behavior warning) | Indicates client retry storms |\n| Queue Operations | delayed_promotion_lag | Seconds behind scheduled time | > 60s (timing accuracy warning) | Affects schedule reliability |\n\n**Distributed Tracing Approaches**\n\nDistributed tracing reconstructs the complete execution flow of individual jobs across multiple system components, providing causal relationships between events that are difficult to establish through logs and metrics alone. The tracing strategy focuses on critical execution paths that cross service boundaries.\n\nJob execution traces begin with job submission and follow the complete lifecycle through queue insertion, delayed promotion, worker assignment, execution, and completion reporting. Each trace span represents a logical operation within a single component, while the overall trace shows the end-to-end execution flow with precise timing information and failure points.\n\nThe job submission trace span captures the initial request processing including payload validation, deduplication checking, priority assignment, and queue insertion. The trace includes custom attributes for job priority, scheduled execution time, and deduplication results that enable filtering and analysis of specific job patterns.\n\nQueue operation spans track the job through priority queue management including delayed job promotion, priority comparison during claims, and atomic job assignment. The trace attributes include queue depth at operation time, priority comparison results, and worker selection criteria that influenced assignment decisions.\n\nWorker execution spans capture the actual job processing including claim acquisition, execution startup, progress reporting, and completion status. The span attributes include worker capacity information, execution environment details, and any error conditions that occurred during processing.\n\nCoordination protocol spans track the distributed consensus operations that enable worker coordination including heartbeat processing, leader election participation, and job recovery operations. These spans often cross multiple service boundaries as coordination decisions propagate through the cluster.\n\nTrace sampling strategies balance information completeness with system performance impact. All failed operations generate traces regardless of sampling rate to ensure failure diagnosis information is always available. Successful operations use adaptive sampling that increases trace collection during periods of high error rates or performance degradation.\n\n| Trace Type | Span Hierarchy | Key Attributes | Sampling Rate | Retention Period |\n|------------|-----------------|----------------|---------------|------------------|\n| Job Execution | submission → queue_insert → promotion → assignment → execution → completion | job_id, priority, worker_id, execution_time | 1% normal, 100% on failures | 7 days |\n| Worker Coordination | heartbeat → health_check → assignment_eligibility → job_claim | worker_id, capacity, capabilities, claim_result | 5% normal, 100% on coordination failures | 3 days |\n| Queue Operations | priority_comparison → deduplication_check → atomic_insert → delayed_promotion | queue_depth, priority_order, dedup_result, promotion_timing | 10% normal, 100% on queue errors | 5 days |\n| Coordination Protocol | leader_election → consensus_vote → leadership_transition → authority_validation | node_id, vote_result, leadership_status, authority_scope | 100% always | 14 days |\n\n### Troubleshooting Workflows\n\nSystematic troubleshooting workflows provide structured approaches to diagnose and resolve the most common categories of distributed scheduler failures. Each workflow follows a hypothesis-driven methodology that systematically eliminates potential causes while gathering evidence about the actual failure mode.\n\n**Network Partition Diagnosis**\n\nNetwork partitions represent one of the most challenging failure modes in distributed scheduler systems, creating scenarios where different parts of the cluster have inconsistent views of system state. The partition diagnosis workflow systematically identifies partition boundaries and determines appropriate recovery strategies.\n\nThe initial partition detection phase examines coordination service connectivity patterns across all cluster nodes. Begin by checking etcd or Redis connectivity from each coordinator and worker node, looking for patterns where specific node groups can communicate internally but cannot reach other groups. Review network routing tables and firewall configurations to identify infrastructure changes that might have created connectivity barriers.\n\nCoordinator split-brain investigation focuses on leadership status across the cluster. Query the leadership election state from each coordinator node to identify whether multiple nodes believe they hold leadership authority. Check the fencing token generation logs to see if multiple coordinators are issuing overlapping token ranges, which indicates split-brain scenarios. Review recent leadership election logs for unusual patterns like rapid leadership transitions or vote timeouts.\n\nWorker isolation analysis determines which workers can communicate with which coordinators during the partition. Check worker heartbeat logs to identify patterns where workers successfully send heartbeats to some coordinators but receive timeout errors from others. Review job assignment patterns to see if specific workers are receiving assignments from multiple coordinator nodes simultaneously.\n\nJob state consistency verification examines whether the same jobs have different states on different sides of the partition. Query job state from multiple coordinator nodes and compare results, looking for jobs that appear as `EXECUTING` on one coordinator but `PENDING` on another. Check for duplicate job assignments where the same job ID is claimed by workers on different sides of the partition.\n\nRecovery strategy determination depends on the partition scope and duration. For brief network hiccups lasting less than heartbeat timeout intervals, the system should self-recover as connectivity resumes. For sustained partitions lasting longer than coordination timeouts, manual intervention may be required to resolve state inconsistencies and prevent duplicate job execution during partition recovery.\n\n| Partition Symptom | Investigation Steps | Evidence to Collect | Recovery Action |\n|------------------|-------------------|-------------------|-----------------|\n| Multiple leaders detected | Check leadership status on all coordinators | Leadership election logs, fencing token ranges | Stop all coordinators, restart with clean election |\n| Worker heartbeat split | Verify worker connectivity to each coordinator | Heartbeat success/failure patterns by coordinator | Identify majority partition, isolate minority nodes |\n| Duplicate job assignments | Compare job states across coordinators | Job state differences, worker claim conflicts | Cancel assignments from minority partition coordinators |\n| Coordination service split | Test etcd/Redis connectivity from each node | Connection success patterns, error messages | Restore network connectivity, restart coordination service |\n\n**Timing Issue Analysis**\n\nTiming-related problems in distributed schedulers often involve subtle interactions between clock synchronization, timezone handling, and distributed coordination that create intermittent failures difficult to reproduce consistently.\n\nClock skew detection examines time differences across cluster nodes that can cause coordination failures or incorrect scheduling decisions. Begin by comparing system clock values across all coordinator and worker nodes, looking for differences larger than a few seconds. Check NTP synchronization status and identify any nodes that have lost time synchronization or are using different time sources.\n\nCron expression evaluation verification tests the next execution time calculation logic against known timezone and daylight saving time scenarios. Create test cases with specific cron expressions and verify that next execution times are calculated correctly across DST transitions, leap years, and month boundaries. Pay particular attention to expressions using day-of-week and day-of-month combinations that can create complex interaction patterns.\n\nDelayed job promotion timing analysis examines the accuracy of scheduled job execution by comparing actual execution times with intended schedule times. Review the `PromoteDelayedJobs` execution logs to identify patterns where promotion occurs significantly before or after the intended execution time. Check for systematic delays that might indicate performance problems in the promotion process.\n\nCoordination timeout investigation focuses on distributed operation timing that affects consensus and job assignment. Review heartbeat timeout patterns to identify whether timeouts occur due to network latency, coordinator overload, or genuine worker failures. Examine job claim timeouts that might indicate coordination service performance problems or excessive contention during high-load periods.\n\nRace condition identification requires careful analysis of timing-sensitive operations that might behave differently under varying load or network conditions. Focus on atomic job claiming operations where multiple workers might attempt to claim the same job simultaneously. Review fencing token validation timing to identify scenarios where token expiration occurs between job claim and completion reporting.\n\n| Timing Issue Category | Diagnostic Approach | Tools and Techniques | Resolution Strategy |\n|----------------------|-------------------|-------------------|-------------------|\n| Clock skew problems | Compare system times across all nodes | chrony/ntpd status, manual time comparison | Implement NTP synchronization, add clock skew detection |\n| Cron calculation errors | Test edge cases with known correct results | Unit tests for DST transitions, month boundaries | Fix timezone handling logic, add comprehensive test coverage |\n| Delayed promotion lag | Compare intended vs actual execution times | PromoteDelayedJobs timing logs, execution latency metrics | Optimize promotion process, adjust promotion interval |\n| Coordination timeouts | Analyze heartbeat and consensus timing | Coordination service performance metrics, network latency | Tune timeout values, improve coordination service performance |\n| Job claim race conditions | Review atomic operation timing | Concurrent claim attempt logs, success/failure patterns | Implement stronger consistency guarantees, add retry logic |\n\n**Race Condition Investigation**\n\nRace conditions in distributed schedulers typically occur during concurrent operations on shared state, creating timing-dependent failures that may only manifest under specific load or network conditions.\n\nJob claiming race condition analysis focuses on scenarios where multiple workers attempt to claim the same job simultaneously. Begin by reviewing job claim attempt logs during high-concurrency periods, looking for patterns where multiple workers report successful claim operations for the same job ID. Examine the atomic operation implementation in the underlying storage system to verify that compare-and-swap operations are functioning correctly.\n\nDeduplication race condition investigation examines scenarios where identical jobs bypass deduplication logic due to timing windows in the duplicate detection process. Review job submission logs for jobs with identical `IdempotencyKey` values that both result in successful queue insertion. Check the deduplication hash table consistency and verify that hash computation produces identical results for equivalent job payloads.\n\nWorker registration race conditions occur when multiple workers attempt to register with the same ID simultaneously or when worker state updates conflict during rapid heartbeat processing. Examine worker registration logs for duplicate worker IDs or workers that appear to register successfully but don't receive job assignments. Review heartbeat processing for workers that report successful heartbeat transmission but show as unavailable in coordinator state.\n\nCoordination state race conditions involve conflicts during leader election or job assignment operations where distributed state updates occur in different orders across cluster nodes. Review leadership election logs for scenarios where vote counting produces inconsistent results or where multiple nodes claim victory simultaneously. Examine job assignment state for jobs that appear assigned to multiple workers or workers that report assignment conflicts.\n\nRecovery operation race conditions can occur when failed worker detection triggers job reassignment while the original worker is still processing the job successfully. Review job recovery logs for scenarios where job reassignment occurs followed by completion reports from the original worker. Check fencing token validation for jobs that complete successfully but have their completion reports rejected due to stale authorization.\n\n| Race Condition Type | Detection Method | Evidence Patterns | Mitigation Approach |\n|-------------------|-----------------|------------------|-------------------|\n| Job claim conflicts | Multiple workers claiming same job | Duplicate successful claim logs for same job ID | Implement stronger atomic operations, add claim verification |\n| Deduplication bypass | Identical IdempotencyKey jobs both execute | Same IdempotencyKey with multiple queue insertions | Add deduplication transaction scope, implement retries |\n| Worker registration conflicts | Duplicate worker IDs or state inconsistency | Worker registration success with no job assignments | Serialize worker registration, add registration verification |\n| Coordination state conflicts | Inconsistent leadership or assignment state | Multiple leaders or conflicting job assignments | Implement coordination transaction boundaries |\n| Recovery operation conflicts | Job reassignment during successful execution | Job completion after reassignment triggers | Strengthen fencing token validation, add recovery coordination |\n\n⚠️ **Pitfall: Log Analysis Without Correlation**\n\nA common debugging mistake involves analyzing logs from individual components without correlating events across the distributed system boundaries. For example, investigating duplicate job execution by only examining worker logs misses the coordination failures that enabled the duplication. Always gather logs from all relevant components (coordinator, worker, queue) for the same time period and correlate events using `correlation_id` and `job_id` fields to understand the complete failure sequence.\n\n⚠️ **Pitfall: Metric Alert Threshold Sensitivity**\n\nSetting metric alert thresholds too sensitively creates alert fatigue while setting them too loosely misses genuine problems. Distributed scheduler metrics often show natural variation due to job patterns and network conditions. Establish baseline behavior during normal operation before setting alert thresholds, and use percentage-based thresholds rather than absolute values to account for system scaling.\n\n⚠️ **Pitfall: Race Condition Reproduction Attempts**\n\nAttempting to reproduce race conditions by manually triggering concurrent operations often fails because the timing conditions that created the original race may not be replicable in testing environments. Instead, focus on identifying the shared state and atomic operation boundaries where races can occur, then implement stronger consistency guarantees rather than trying to reproduce the exact race scenario.\n\n### Implementation Guidance\n\nImplementing effective debugging capabilities requires building observability into the distributed scheduler from the ground up, rather than adding diagnostic tools as an afterthought. The debugging implementation focuses on structured data collection, efficient storage and retrieval, and automated analysis tools that accelerate problem diagnosis.\n\n**Technology Recommendations**\n\n| Component | Simple Option | Advanced Option | Trade-offs |\n|-----------|---------------|-----------------|------------|\n| Structured Logging | Go standard log/slog with JSON formatting | ELK Stack (Elasticsearch, Logstash, Kibana) | Simple: easy setup, limited search. Advanced: powerful search, complex infrastructure |\n| Metrics Collection | Prometheus with Go prometheus client | Datadog or New Relic with custom dashboards | Simple: open source, self-hosted. Advanced: managed service, better UI |\n| Distributed Tracing | Jaeger with OpenTelemetry Go SDK | Zipkin with custom span correlation | Simple: CNCF standard, good community. Advanced: better performance analysis |\n| Time Series Database | Prometheus for metrics storage | InfluxDB with Grafana for visualization | Simple: integrated with collection. Advanced: better time series performance |\n| Log Aggregation | File-based logging with logrotate | Fluentd with Elasticsearch backend | Simple: no external dependencies. Advanced: centralized searchable logs |\n\n**Recommended File Structure**\n\n```\ninternal/\n  debugging/\n    logger.go              ← Structured logging configuration\n    metrics.go             ← Metrics collection and registration  \n    tracing.go             ← Distributed tracing setup\n    correlation.go         ← Correlation ID management\n    diagnostics.go         ← Health check and diagnostic endpoints\n    debug_handler.go       ← Debug information HTTP endpoints\n  monitoring/\n    alerts.go              ← Metric alert definitions\n    dashboards.go          ← Dashboard configuration\n    healthcheck.go         ← System health assessment\ncmd/\n  debug-cli/\n    main.go                ← Command-line debugging utility\n    job_inspector.go       ← Job state inspection commands\n    worker_inspector.go    ← Worker state inspection commands\n    trace_analyzer.go      ← Trace analysis utilities\ntools/\n  log-analyzer/\n    main.go                ← Log analysis and correlation tool\n    pattern_detector.go    ← Common failure pattern detection\n  metrics-dashboard/\n    grafana-config.json    ← Pre-built dashboard definitions\n    alert-rules.yaml       ← Prometheus alert rule definitions\n```\n\n**Infrastructure Starter Code**\n\nComplete logging infrastructure with structured output and correlation support:\n\n```go\n// internal/debugging/logger.go\npackage debugging\n\nimport (\n    \"context\"\n    \"log/slog\"\n    \"os\"\n    \"time\"\n)\n\ntype ContextKey string\n\nconst CorrelationIDKey ContextKey = \"correlation_id\"\n\n// CorrelatedLogger provides structured logging with automatic correlation ID injection\ntype CorrelatedLogger struct {\n    logger *slog.Logger\n    component string\n    nodeID string\n}\n\n// NewCorrelatedLogger creates a structured logger with component identification\nfunc NewCorrelatedLogger(component, nodeID string) *CorrelatedLogger {\n    handler := slog.NewJSONHandler(os.Stdout, &slog.HandlerOptions{\n        Level: slog.LevelDebug,\n        AddSource: true,\n    })\n    \n    logger := slog.New(handler).With(\n        slog.String(\"component\", component),\n        slog.String(\"node_id\", nodeID),\n        slog.Time(\"timestamp\", time.Now()),\n    )\n    \n    return &CorrelatedLogger{\n        logger: logger,\n        component: component,\n        nodeID: nodeID,\n    }\n}\n\n// WithContext extracts correlation ID from context and adds it to log entry\nfunc (l *CorrelatedLogger) WithContext(ctx context.Context) *slog.Logger {\n    correlationID, ok := ctx.Value(CorrelationIDKey).(string)\n    if !ok {\n        correlationID = \"unknown\"\n    }\n    \n    return l.logger.With(slog.String(\"correlation_id\", correlationID))\n}\n\n// JobOperation logs job-related operations with standardized fields\nfunc (l *CorrelatedLogger) JobOperation(ctx context.Context, level slog.Level, operation string, jobID string, attrs ...slog.Attr) {\n    logger := l.WithContext(ctx).With(\n        slog.String(\"operation\", operation),\n        slog.String(\"job_id\", jobID),\n    )\n    \n    logger.LogAttrs(ctx, level, operation, attrs...)\n}\n\n// WorkerOperation logs worker-related operations with standardized fields  \nfunc (l *CorrelatedLogger) WorkerOperation(ctx context.Context, level slog.Level, operation string, workerID string, attrs ...slog.Attr) {\n    logger := l.WithContext(ctx).With(\n        slog.String(\"operation\", operation),\n        slog.String(\"worker_id\", workerID),\n    )\n    \n    logger.LogAttrs(ctx, level, operation, attrs...)\n}\n\n// CoordinationOperation logs coordination protocol events\nfunc (l *CorrelatedLogger) CoordinationOperation(ctx context.Context, level slog.Level, operation string, attrs ...slog.Attr) {\n    logger := l.WithContext(ctx).With(\n        slog.String(\"operation\", operation),\n        slog.String(\"protocol\", \"coordination\"),\n    )\n    \n    logger.LogAttrs(ctx, level, operation, attrs...)\n}\n```\n\nComplete metrics collection infrastructure with Prometheus integration:\n\n```go\n// internal/debugging/metrics.go\npackage debugging\n\nimport (\n    \"github.com/prometheus/client_golang/prometheus\"\n    \"github.com/prometheus/client_golang/prometheus/promauto\"\n    \"time\"\n)\n\n// SchedulerMetrics provides comprehensive metrics collection for distributed scheduler\ntype SchedulerMetrics struct {\n    // Job execution metrics\n    JobSubmissionRate *prometheus.CounterVec\n    JobCompletionLatency *prometheus.HistogramVec\n    JobFailureRate *prometheus.CounterVec\n    JobQueueDepth *prometheus.GaugeVec\n    \n    // Worker coordination metrics  \n    ActiveWorkerCount prometheus.Gauge\n    HeartbeatLatency *prometheus.HistogramVec\n    LeaderElectionCount prometheus.Counter\n    JobAssignmentLatency prometheus.Histogram\n    \n    // Queue operation metrics\n    DeduplicationHitRate *prometheus.CounterVec\n    DelayedPromotionLag prometheus.Histogram\n    QueueOperationLatency *prometheus.HistogramVec\n    \n    // System health metrics\n    CoordinationServiceLatency *prometheus.HistogramVec\n    NetworkPartitionCount prometheus.Counter\n    MemoryUsage prometheus.Gauge\n}\n\n// NewSchedulerMetrics creates and registers all scheduler metrics with Prometheus\nfunc NewSchedulerMetrics(component string) *SchedulerMetrics {\n    return &SchedulerMetrics{\n        JobSubmissionRate: promauto.NewCounterVec(\n            prometheus.CounterOpts{\n                Name: \"scheduler_job_submissions_total\",\n                Help: \"Total number of job submissions by priority level\",\n            },\n            []string{\"component\", \"priority\", \"job_type\"},\n        ),\n        \n        JobCompletionLatency: promauto.NewHistogramVec(\n            prometheus.HistogramOpts{\n                Name: \"scheduler_job_completion_duration_seconds\",\n                Help: \"Job completion latency distribution\",\n                Buckets: []float64{0.1, 0.5, 1.0, 5.0, 10.0, 30.0, 60.0, 300.0},\n            },\n            []string{\"component\", \"priority\", \"success\"},\n        ),\n        \n        JobFailureRate: promauto.NewCounterVec(\n            prometheus.CounterOpts{\n                Name: \"scheduler_job_failures_total\", \n                Help: \"Total job failures by failure type\",\n            },\n            []string{\"component\", \"failure_type\", \"retriable\"},\n        ),\n        \n        JobQueueDepth: promauto.NewGaugeVec(\n            prometheus.GaugeOpts{\n                Name: \"scheduler_queue_depth\",\n                Help: \"Current job queue depth by priority level\",\n            },\n            []string{\"component\", \"priority\", \"state\"},\n        ),\n        \n        ActiveWorkerCount: promauto.NewGauge(\n            prometheus.GaugeOpts{\n                Name: \"scheduler_active_workers\",\n                Help: \"Number of currently active workers\",\n            },\n        ),\n        \n        HeartbeatLatency: promauto.NewHistogramVec(\n            prometheus.HistogramOpts{\n                Name: \"scheduler_heartbeat_latency_seconds\",\n                Help: \"Worker heartbeat response time distribution\", \n                Buckets: []float64{0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0},\n            },\n            []string{\"component\", \"worker_id\", \"success\"},\n        ),\n        \n        LeaderElectionCount: promauto.NewCounter(\n            prometheus.CounterOpts{\n                Name: \"scheduler_leader_elections_total\",\n                Help: \"Total number of leader election events\",\n            },\n        ),\n        \n        JobAssignmentLatency: promauto.NewHistogram(\n            prometheus.HistogramOpts{\n                Name: \"scheduler_job_assignment_duration_seconds\",\n                Help: \"Time from job submission to worker assignment\",\n                Buckets: []float64{0.01, 0.05, 0.1, 0.5, 1.0, 5.0, 10.0},\n            },\n        ),\n        \n        DeduplicationHitRate: promauto.NewCounterVec(\n            prometheus.CounterOpts{\n                Name: \"scheduler_deduplication_checks_total\",\n                Help: \"Deduplication check results\",\n            },\n            []string{\"component\", \"result\"},\n        ),\n        \n        DelayedPromotionLag: promauto.NewHistogram(\n            prometheus.HistogramOpts{\n                Name: \"scheduler_delayed_promotion_lag_seconds\", \n                Help: \"Delay between scheduled time and actual job promotion\",\n                Buckets: []float64{0, 1, 5, 10, 30, 60, 300},\n            },\n        ),\n        \n        QueueOperationLatency: promauto.NewHistogramVec(\n            prometheus.HistogramOpts{\n                Name: \"scheduler_queue_operation_duration_seconds\",\n                Help: \"Queue operation latency by operation type\",\n                Buckets: []float64{0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1},\n            },\n            []string{\"component\", \"operation\"},\n        ),\n        \n        CoordinationServiceLatency: promauto.NewHistogramVec(\n            prometheus.HistogramOpts{\n                Name: \"scheduler_coordination_service_duration_seconds\",\n                Help: \"Coordination service response time distribution\",\n                Buckets: []float64{0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0},\n            },\n            []string{\"component\", \"service\", \"operation\"},\n        ),\n        \n        NetworkPartitionCount: promauto.NewCounter(\n            prometheus.CounterOpts{\n                Name: \"scheduler_network_partitions_total\",\n                Help: \"Total number of detected network partition events\",\n            },\n        ),\n        \n        MemoryUsage: promauto.NewGauge(\n            prometheus.GaugeOpts{\n                Name: \"scheduler_memory_usage_bytes\",\n                Help: \"Current memory usage in bytes\",\n            },\n        ),\n    }\n}\n\n// RecordJobSubmission records a job submission event with priority and type labels\nfunc (m *SchedulerMetrics) RecordJobSubmission(component, priority, jobType string) {\n    m.JobSubmissionRate.WithLabelValues(component, priority, jobType).Inc()\n}\n\n// RecordJobCompletion records job completion timing with success indicator\nfunc (m *SchedulerMetrics) RecordJobCompletion(component, priority string, duration time.Duration, success bool) {\n    successLabel := \"false\"\n    if success {\n        successLabel = \"true\"\n    }\n    m.JobCompletionLatency.WithLabelValues(component, priority, successLabel).Observe(duration.Seconds())\n}\n\n// RecordJobFailure records job failure with categorization\nfunc (m *SchedulerMetrics) RecordJobFailure(component, failureType string, retriable bool) {\n    retriableLabel := \"false\"  \n    if retriable {\n        retriableLabel = \"true\"\n    }\n    m.JobFailureRate.WithLabelValues(component, failureType, retriableLabel).Inc()\n}\n\n// UpdateQueueDepth updates the current queue depth for a specific priority level\nfunc (m *SchedulerMetrics) UpdateQueueDepth(component, priority, state string, depth float64) {\n    m.JobQueueDepth.WithLabelValues(component, priority, state).Set(depth)\n}\n\n// RecordHeartbeat records worker heartbeat timing and success\nfunc (m *SchedulerMetrics) RecordHeartbeat(component, workerID string, latency time.Duration, success bool) {\n    successLabel := \"false\"\n    if success {\n        successLabel = \"true\"  \n    }\n    m.HeartbeatLatency.WithLabelValues(component, workerID, successLabel).Observe(latency.Seconds())\n}\n```\n\n**Core Debugging Utilities**\n\nDebug information collection and analysis utilities:\n\n```go\n// internal/debugging/diagnostics.go\npackage debugging\n\nimport (\n    \"context\"\n    \"encoding/json\"\n    \"fmt\"\n    \"net/http\"\n    \"runtime\"\n    \"time\"\n)\n\n// DiagnosticCollector gathers system diagnostic information for debugging\ntype DiagnosticCollector struct {\n    component string\n    nodeID    string\n    startTime time.Time\n}\n\n// SystemDiagnostics contains comprehensive system state for debugging\ntype SystemDiagnostics struct {\n    Component    string            `json:\"component\"`\n    NodeID       string            `json:\"node_id\"`\n    Timestamp    time.Time         `json:\"timestamp\"`\n    Uptime       time.Duration     `json:\"uptime\"`\n    MemoryStats  runtime.MemStats  `json:\"memory_stats\"`\n    GoRoutines   int               `json:\"goroutines\"`\n    SystemInfo   SystemInfo        `json:\"system_info\"`\n    CustomState  map[string]interface{} `json:\"custom_state\"`\n}\n\n// SystemInfo contains basic system identification information\ntype SystemInfo struct {\n    GoVersion   string `json:\"go_version\"`\n    OS          string `json:\"os\"`\n    Arch        string `json:\"arch\"`\n    CPUs        int    `json:\"cpus\"`\n}\n\n// NewDiagnosticCollector creates diagnostic collector for specified component\nfunc NewDiagnosticCollector(component, nodeID string) *DiagnosticCollector {\n    return &DiagnosticCollector{\n        component: component,\n        nodeID:    nodeID,\n        startTime: time.Now(),\n    }\n}\n\n// CollectDiagnostics gathers comprehensive system diagnostic information\nfunc (d *DiagnosticCollector) CollectDiagnostics(customState map[string]interface{}) *SystemDiagnostics {\n    var memStats runtime.MemStats\n    runtime.ReadMemStats(&memStats)\n    \n    return &SystemDiagnostics{\n        Component:   d.component,\n        NodeID:      d.nodeID,\n        Timestamp:   time.Now(),\n        Uptime:      time.Since(d.startTime),\n        MemoryStats: memStats,\n        GoRoutines:  runtime.NumGoroutine(),\n        SystemInfo: SystemInfo{\n            GoVersion: runtime.Version(),\n            OS:        runtime.GOOS,\n            Arch:      runtime.GOARCH,\n            CPUs:      runtime.NumCPU(),\n        },\n        CustomState: customState,\n    }\n}\n\n// DebugHandler provides HTTP endpoint for diagnostic information retrieval\ntype DebugHandler struct {\n    collector *DiagnosticCollector\n    stateProvider func() map[string]interface{}\n}\n\n// NewDebugHandler creates HTTP handler for debug endpoints\nfunc NewDebugHandler(collector *DiagnosticCollector, stateProvider func() map[string]interface{}) *DebugHandler {\n    return &DebugHandler{\n        collector: collector,\n        stateProvider: stateProvider,\n    }\n}\n\n// ServeHTTP handles diagnostic information requests\nfunc (h *DebugHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) {\n    // TODO 1: Extract diagnostic request type from URL path (/debug/system, /debug/state, etc.)\n    // TODO 2: Call appropriate diagnostic collection method based on request type\n    // TODO 3: Collect custom state from stateProvider function\n    // TODO 4: Marshal diagnostic information to JSON response\n    // TODO 5: Set appropriate HTTP headers (Content-Type: application/json)\n    // TODO 6: Write JSON response with proper error handling\n    // Hint: Use h.collector.CollectDiagnostics(h.stateProvider()) for full diagnostics\n}\n\n// LogAnalyzer provides utilities for parsing and analyzing structured logs\ntype LogAnalyzer struct {\n    correlationIndex map[string][]LogEntry\n    timeIndex        []LogEntry\n}\n\n// LogEntry represents a parsed structured log entry\ntype LogEntry struct {\n    Timestamp     time.Time              `json:\"timestamp\"`\n    Component     string                 `json:\"component\"`\n    NodeID        string                 `json:\"node_id\"`\n    CorrelationID string                 `json:\"correlation_id\"`\n    Level         string                 `json:\"level\"`\n    Operation     string                 `json:\"operation,omitempty\"`\n    JobID         string                 `json:\"job_id,omitempty\"`\n    WorkerID      string                 `json:\"worker_id,omitempty\"`\n    Message       string                 `json:\"message\"`\n    Attributes    map[string]interface{} `json:\"attributes\"`\n}\n\n// NewLogAnalyzer creates log analysis utility with indexing capability\nfunc NewLogAnalyzer() *LogAnalyzer {\n    return &LogAnalyzer{\n        correlationIndex: make(map[string][]LogEntry),\n        timeIndex:        make([]LogEntry, 0),\n    }\n}\n\n// ParseLogLine parses structured JSON log entry and adds to indexes\nfunc (a *LogAnalyzer) ParseLogLine(line string) error {\n    // TODO 1: Parse JSON log line into LogEntry struct\n    // TODO 2: Add entry to correlationIndex using correlation_id as key\n    // TODO 3: Insert entry into timeIndex maintaining chronological order\n    // TODO 4: Return parsing errors with context about malformed fields\n    // Hint: Use json.Unmarshal() for parsing and sort.Search() for time index insertion\n    return nil\n}\n\n// GetCorrelatedEntries retrieves all log entries for specific correlation ID\nfunc (a *LogAnalyzer) GetCorrelatedEntries(correlationID string) []LogEntry {\n    // TODO 1: Look up correlation ID in correlationIndex\n    // TODO 2: Return slice of log entries in chronological order\n    // TODO 3: Return empty slice if correlation ID not found\n    // Hint: Sort entries by timestamp before returning\n    return nil\n}\n\n// AnalyzeFailurePattern identifies common failure patterns in log sequences  \nfunc (a *LogAnalyzer) AnalyzeFailurePattern(entries []LogEntry) FailurePattern {\n    // TODO 1: Scan entries for error-level log messages\n    // TODO 2: Identify timing patterns (rapid retries, timeout sequences)\n    // TODO 3: Correlate component failure sequences (coordinator -> worker failures)\n    // TODO 4: Classify failure type based on observed patterns\n    // TODO 5: Return structured failure analysis with root cause hypothesis\n    return FailurePattern{}\n}\n\n// FailurePattern represents analysis results for a failure sequence\ntype FailurePattern struct {\n    FailureType   string    `json:\"failure_type\"`\n    RootCause     string    `json:\"root_cause\"`\n    ComponentPath []string  `json:\"component_path\"` \n    Duration      time.Duration `json:\"duration\"`\n    Symptoms      []string  `json:\"symptoms\"`\n    Recommendation string   `json:\"recommendation\"`\n}\n```\n\n**Milestone Checkpoints**\n\nAfter implementing the debugging infrastructure, verify the following behavior:\n\n1. **Structured Logging Verification**: Start all scheduler components and submit test jobs. Check that logs contain all required fields (component, node_id, correlation_id, timestamp) and can be filtered by correlation ID. Verify that job operations include job_id fields and worker operations include worker_id fields.\n\n2. **Metrics Collection Validation**: Access the metrics endpoint (typically `/metrics`) and verify that all defined metrics appear with appropriate labels. Submit jobs and confirm that job submission and completion metrics increment correctly. Monitor queue depth metrics during job processing.\n\n3. **Diagnostic Endpoint Testing**: Access the debug endpoints (`/debug/system`) and verify that complete diagnostic information returns in JSON format. Check that memory statistics, goroutine counts, and custom state information appear correctly.\n\n4. **Correlation Analysis Testing**: Generate correlated log entries by submitting jobs and verify that the log analyzer can retrieve all entries for a specific correlation ID. Test failure pattern analysis with intentionally failed jobs.\n\n**Debugging Tips**\n\n| Symptom | Likely Cause | Diagnostic Command | Fix Approach |\n|---------|--------------|-------------------|--------------|\n| Metrics not updating | Prometheus registration failure | Check `/metrics` endpoint for metric presence | Verify metric registration in component initialization |\n| Correlation IDs missing | Context propagation failure | Grep logs for \"correlation_id\":\"unknown\" | Add correlation ID to all context.Context values |\n| Log entries missing fields | Logger configuration error | Check log JSON structure with `jq` tool | Verify structured logger initialization with required fields |\n| Debug endpoint returns errors | State provider function panic | Check component logs during debug request | Add error handling in state provider function |\n| Trace spans not appearing | Tracing backend connectivity | Check Jaeger UI for trace presence | Verify tracing configuration and network connectivity |\n\n\n## Future Extensions\n\n> **Milestone(s):** This section explores potential enhancements that build upon the completed implementation of all three milestones - extending the cron parser with workflow dependencies (Milestone 1), adding advanced queue features like resource awareness (Milestone 2), and scaling the worker coordination beyond single-cluster deployments (Milestone 3).\n\nThe distributed job scheduler established through the three core milestones provides a solid foundation for reliable, fault-tolerant job execution. However, real-world production systems often require capabilities beyond basic scheduling, prioritization, and coordination. This section outlines significant enhancements that transform the scheduler from a general-purpose task executor into a comprehensive workflow orchestration platform capable of handling complex enterprise workloads across multiple data centers.\n\nThink of the current scheduler as a well-organized city bus system - it reliably transports passengers (jobs) from origin to destination using fixed routes (cron schedules) with good capacity management (priorities) and fault tolerance (worker coordination). The future extensions described here are like evolving from a bus system to a comprehensive transportation network that includes subways, trains, and planes - adding route dependencies, real-time capacity optimization, and inter-city connections.\n\nThese extensions fall into three categories that build naturally upon the existing architecture. **Advanced Scheduling** capabilities transform the scheduler from executing independent jobs to orchestrating complex workflows with dependencies and resource constraints. **Operational Features** provide the visibility and control mechanisms necessary for production deployments at scale. **Scalability Improvements** enable the scheduler to operate across multiple data centers and handle workloads that exceed single-cluster capacity.\n\n> The key architectural insight is that these extensions maintain backward compatibility with the existing three-milestone implementation while adding new layers of functionality. Existing jobs continue to work unchanged, but new capabilities become available through extended APIs and configuration options.\n\nEach extension category addresses different aspects of production readiness. Advanced scheduling tackles the complexity of real-world workflows where jobs have interdependencies and compete for limited resources. Operational features provide the observability and administrative capabilities that operations teams require for managing large-scale deployments. Scalability improvements address the fundamental limits of single-cluster architectures by enabling geographic distribution and horizontal scaling beyond individual data center capacity.\n\n### Advanced Scheduling\n\nThe current scheduler executes jobs independently based on cron expressions and priorities. Advanced scheduling extends this model to handle **job dependencies**, **resource-aware scheduling**, and **workflow orchestration** - transforming the system from a task executor into a comprehensive workflow engine.\n\nThink of job dependencies like a restaurant kitchen during dinner service. The salad station can't plate dishes until the grill finishes the protein, the dessert chef waits for dinner orders to complete, and dishwashing depends on completed courses returning to the kitchen. Similarly, data processing workflows often require strict ordering - the ETL job must complete before the reporting job runs, and the backup job should wait until all database operations finish.\n\n#### Job Dependencies and Workflow DAGs\n\nJob dependencies introduce directed acyclic graph (DAG) scheduling where jobs specify prerequisite jobs that must complete successfully before execution begins. This extends the current `Job` structure to include dependency relationships and success criteria.\n\n**Extended Job Definition for Dependencies:**\n\n| Field | Type | Description |\n|-------|------|-------------|\n| Dependencies | []JobDependency | List of prerequisite jobs that must complete before this job can execute |\n| DependencyMode | DependencyMode | How to handle dependency completion (ALL_SUCCESS, ANY_SUCCESS, ALL_COMPLETE) |\n| DependencyTimeout | time.Duration | Maximum time to wait for dependencies before marking job as failed |\n| WorkflowID | string | Optional identifier grouping related jobs into a workflow unit |\n| WorkflowPosition | int | Job's position in workflow execution order (for visualization) |\n\n**JobDependency Structure:**\n\n| Field | Type | Description |\n|-------|------|-------------|\n| JobID | string | Identifier of the prerequisite job |\n| JobName | string | Human-readable name of the prerequisite job for workflow visualization |\n| RequiredState | JobState | Required completion state (COMPLETED for success, FAILED for failure trigger) |\n| DataPassing | map[string]string | Output data from prerequisite job to pass as input to dependent job |\n| TimeoutAction | TimeoutAction | Action when dependency doesn't complete within timeout (FAIL, SKIP, PROCEED) |\n\nThe dependency resolution algorithm operates through a **dependency graph evaluator** that maintains workflow state and triggers job execution when prerequisites complete:\n\n1. **Dependency Registration**: When jobs with dependencies are submitted, the scheduler builds an in-memory dependency graph linking prerequisite jobs to their dependents\n2. **Completion Monitoring**: As jobs complete, the dependency evaluator checks all dependent jobs to see if their prerequisites are now satisfied\n3. **Eligibility Promotion**: Jobs with satisfied dependencies are promoted from a \"waiting\" state to the normal priority queue for worker assignment\n4. **Failure Propagation**: When a prerequisite job fails, dependent jobs can either fail immediately, skip execution, or proceed based on their configured `TimeoutAction`\n5. **Cycle Detection**: The scheduler validates that dependency relationships form a DAG and rejects job submissions that would create cycles\n\n> **Decision: Dependency Storage Strategy**\n> - **Context**: Job dependencies need persistent storage to survive coordinator restarts and enable dependency resolution across time\n> - **Options Considered**: In-memory only, database relations, graph database, Redis graph structures\n> - **Decision**: Redis with graph-like operations using sets for incoming/outgoing edges per job\n> - **Rationale**: Leverages existing Redis infrastructure, provides atomic operations for dependency updates, enables efficient graph traversal queries\n> - **Consequences**: Dependency relationships persist across restarts, but complex graph queries are less efficient than dedicated graph databases\n\n#### Resource-Aware Scheduling\n\nThe current scheduler assigns jobs to workers based solely on availability and capability matching. Resource-aware scheduling extends this to consider **memory requirements**, **CPU constraints**, **storage needs**, and **exclusive resource access** when making assignment decisions.\n\nThink of resource-aware scheduling like an airport gate assignment system. Small regional jets can use any gate, but wide-body aircraft require gates with jetbridges capable of handling their size. Similarly, some gates have ground power connections needed for electric aircraft, while others provide fuel access for conventional planes. The scheduler must match aircraft requirements with gate capabilities while maximizing utilization.\n\n**Extended Worker Resource Model:**\n\n| Field | Type | Description |\n|-------|------|-------------|\n| AvailableMemoryMB | int64 | Current available memory in megabytes for job execution |\n| AvailableCPUCores | float64 | Available CPU cores (fractional for partial core allocation) |\n| AvailableStorageGB | int64 | Available temporary storage in gigabytes |\n| ExclusiveResources | []string | List of exclusive resources this worker can provide (GPU types, license slots) |\n| ResourceLimits | ResourceLimits | Maximum resource levels this worker can provide |\n| CurrentAllocations | map[string]ResourceAllocation | Resources currently allocated to running jobs |\n\n**Job Resource Requirements:**\n\n| Field | Type | Description |\n|-------|------|-------------|\n| RequiredMemoryMB | int64 | Minimum memory required for successful job execution |\n| RequiredCPUCores | float64 | Minimum CPU cores needed (fractional allocation supported) |\n| RequiredStorageGB | int64 | Temporary storage space needed during execution |\n| ExclusiveResource | string | Exclusive resource required (empty string if none needed) |\n| ResourceReservation | time.Duration | How long to hold resources before job starts (for delayed jobs) |\n| AffinityRules | []AffinityRule | Preferences for worker selection based on resource characteristics |\n\nThe resource-aware assignment algorithm extends the current job claiming process with resource validation and allocation tracking:\n\n1. **Resource Requirement Analysis**: When a job becomes eligible for assignment, the scheduler extracts its resource requirements and determines compatible workers\n2. **Worker Capacity Filtering**: The scheduler filters available workers to only those with sufficient resources to meet the job's requirements\n3. **Affinity Evaluation**: Among capable workers, affinity rules are evaluated to prefer workers with characteristics like same datacenter, SSD storage, or specific CPU architectures\n4. **Resource Reservation**: When a job is assigned to a worker, the scheduler reserves the required resources in its tracking system to prevent over-allocation\n5. **Dynamic Rebalancing**: If high-priority jobs require resources currently allocated to lower-priority work, the scheduler can preempt lower-priority jobs\n6. **Resource Release**: When jobs complete, their allocated resources are immediately returned to the worker's available pool\n\n#### Workflow Orchestration Engine\n\nBuilding upon job dependencies and resource awareness, workflow orchestration provides high-level primitives for defining and executing complex multi-job workflows with **conditional execution**, **parallel branches**, **loops**, and **error handling**.\n\nThink of workflow orchestration like a sophisticated manufacturing assembly line. Raw materials enter the line, pass through multiple stations that can operate in parallel or sequence, with quality control checkpoints that can redirect work to rework stations or alternate paths. The entire process is coordinated by a central control system that monitors progress and handles disruptions.\n\n**Workflow Definition Structure:**\n\n| Field | Type | Description |\n|-------|------|-------------|\n| WorkflowID | string | Unique identifier for this workflow template |\n| Name | string | Human-readable workflow name for administrative interfaces |\n| Steps | []WorkflowStep | Ordered list of steps defining the workflow execution path |\n| GlobalVariables | map[string]string | Variables available to all steps in the workflow |\n| ErrorHandling | ErrorHandlingPolicy | How to handle step failures (ABORT, CONTINUE, RETRY_STEP) |\n| MaxExecutionTime | time.Duration | Total timeout for entire workflow execution |\n| CronSchedule | string | Optional cron expression for recurring workflow execution |\n\n**WorkflowStep Definition:**\n\n| Field | Type | Description |\n|-------|------|-------------|\n| StepID | string | Unique identifier within the workflow |\n| StepType | StepType | Type of step (JOB, CONDITION, PARALLEL, LOOP, WAIT) |\n| JobTemplate | *Job | Job definition for JOB-type steps |\n| Condition | string | Boolean expression for CONDITION-type steps |\n| ParallelBranches | [][]WorkflowStep | Parallel execution branches for PARALLEL-type steps |\n| LoopCondition | string | Loop continuation condition for LOOP-type steps |\n| WaitDuration | time.Duration | Fixed wait duration for WAIT-type steps |\n| OnSuccess | []string | Next step IDs to execute on successful completion |\n| OnFailure | []string | Next step IDs to execute on failure |\n| RetryPolicy | StepRetryPolicy | Step-specific retry configuration |\n\nThe workflow orchestration engine operates as a state machine that tracks workflow execution progress and coordinates step transitions:\n\n1. **Workflow Instantiation**: When a workflow is triggered (by cron schedule or API call), the engine creates a workflow execution instance with unique execution ID\n2. **Step Resolution**: The engine identifies the first step(s) to execute based on the workflow definition and begins execution\n3. **Job Generation**: For JOB-type steps, the engine creates actual `Job` instances from templates, substituting workflow variables and context\n4. **Condition Evaluation**: CONDITION-type steps evaluate boolean expressions against workflow variables and job outputs to determine execution paths\n5. **Parallel Coordination**: PARALLEL-type steps spawn multiple execution branches that run concurrently, with the engine tracking completion of all branches\n6. **State Persistence**: Workflow execution state is persisted to enable recovery from coordinator failures during long-running workflows\n7. **Completion Detection**: The workflow completes when all steps finish successfully or when an unrecoverable error occurs based on the error handling policy\n\n> **Decision: Workflow Expression Language**\n> - **Context**: Conditional steps and loop conditions require expression evaluation within workflow context\n> - **Options Considered**: JavaScript V8 engine, Go template syntax, custom domain-specific language, JSONPath expressions\n> - **Decision**: Go template syntax with custom functions for job output access and variable manipulation\n> - **Rationale**: Leverages Go's built-in template engine, provides familiar syntax for Go developers, enables safe expression evaluation without full scripting language security concerns\n> - **Consequences**: Expressions are limited to Go template capabilities but execution is fast and secure, with no risk of arbitrary code execution\n\n**Common Pitfalls in Advanced Scheduling:**\n\n⚠️ **Pitfall: Circular Dependency Creation**  \nAllowing users to create job dependencies without cycle detection leads to workflows that can never execute because jobs wait for each other in a cycle. This manifests as jobs permanently stuck in \"waiting for dependencies\" state. Implement topological sort validation during workflow submission and reject any workflow definition that contains cycles.\n\n⚠️ **Pitfall: Resource Over-Commitment**  \nReserving resources for delayed jobs without considering time-based availability leads to resource starvation where workers appear full but aren't actually executing work. Implement time-aware resource reservations that only hold resources close to job execution time, with automatic reservation release if jobs don't start within expected windows.\n\n⚠️ **Pitfall: Workflow State Explosion**  \nStoring complete workflow execution state for every step and variable update creates excessive storage overhead and slow state operations. Implement incremental state updates that only persist state changes, with periodic state compaction to merge incremental updates into consolidated checkpoints.\n\n### Operational Features\n\nProduction distributed systems require comprehensive observability, administrative controls, and historical analysis capabilities. The operational features category adds **metrics and monitoring**, **job execution history**, **administrative interfaces**, and **audit logging** to transform the scheduler from a development tool into an enterprise-ready platform.\n\nThink of operational features like the instrumentation and controls in an airline's operations center. Dispatchers need real-time visibility into flight status, weather conditions, and aircraft maintenance schedules. They require historical data to analyze patterns and optimize routes. Emergency procedures and administrative controls enable rapid response to disruptions. Similarly, a production job scheduler needs comprehensive operational capabilities to ensure reliable service delivery.\n\n#### Comprehensive Metrics and Monitoring\n\nThe current scheduler includes basic Prometheus metrics for job execution and worker coordination. Comprehensive monitoring extends this with **detailed performance metrics**, **business-level indicators**, **alerting rules**, and **dashboard templates** that provide complete visibility into scheduler health and performance.\n\n**Enhanced Metrics Collection:**\n\n| Metric Category | Metrics | Purpose |\n|-----------------|---------|---------|\n| Job Lifecycle | job_submission_rate, job_completion_latency, job_success_rate, job_retry_frequency | Track job processing health and identify performance bottlenecks |\n| Queue Dynamics | queue_depth_by_priority, queue_wait_time, job_aging_histogram, deduplication_rate | Monitor queue behavior and capacity planning needs |\n| Worker Performance | worker_utilization, worker_job_throughput, worker_failure_rate, worker_resource_efficiency | Assess worker health and identify problematic nodes |\n| Coordination Health | leader_election_frequency, heartbeat_latency, split_brain_events, consensus_latency | Monitor distributed coordination stability and network issues |\n| Resource Utilization | memory_allocation_efficiency, cpu_utilization_distribution, storage_usage_patterns, exclusive_resource_contention | Track resource usage patterns for capacity planning |\n| Workflow Execution | workflow_completion_rate, workflow_step_latency, workflow_branch_parallelism, workflow_failure_causes | Monitor complex workflow execution and identify optimization opportunities |\n\n**Business-Level Indicators:**\n\nBeyond technical metrics, operational deployments require business-level indicators that translate system behavior into business impact measurements:\n\n| Business Indicator | Calculation | Business Impact |\n|--------------------|-------------|-----------------|\n| Schedule Adherence Rate | (Jobs started within SLA window) / (Total scheduled jobs) | Measures reliability of time-sensitive business processes |\n| Critical Job Success Rate | (Critical priority jobs completed successfully) / (Total critical jobs) | Tracks success of highest-impact business operations |\n| Resource ROI | (Successful job compute hours) / (Total provisioned compute hours) | Measures efficiency of infrastructure investment |\n| Workflow SLA Compliance | (Workflows completed within SLA) / (Total workflows) | Tracks end-to-end business process reliability |\n| Dependency Chain Efficiency | Average workflow completion time / Sum of individual job times | Measures overhead of workflow coordination vs direct execution |\n\n**Alerting Framework:**\n\nThe monitoring system includes a comprehensive alerting framework with **graduated severity levels**, **smart alert correlation**, and **automated runbook integration**:\n\n1. **Threshold-Based Alerts**: Traditional alerts based on metric thresholds (queue depth exceeds capacity, worker failure rate above normal)\n2. **Anomaly Detection**: Machine learning-based alerts that identify unusual patterns in job execution, resource usage, or coordination behavior\n3. **Correlation Rules**: Logic that groups related alerts to prevent alert storms during widespread issues (network partition affecting multiple workers)\n4. **Escalation Policies**: Graduated response based on alert severity and duration (page on-call engineer for critical failures, create ticket for performance degradation)\n5. **Runbook Integration**: Automatic attachment of relevant troubleshooting procedures and diagnostic commands to alert notifications\n\n#### Job Execution History and Analytics\n\nThe current scheduler focuses on active job execution without preserving detailed historical information. Comprehensive job history provides **execution analytics**, **performance trending**, **failure pattern analysis**, and **capacity planning data** through long-term data retention and analysis capabilities.\n\n**Job Execution Record:**\n\n| Field | Type | Description |\n|-------|------|-------------|\n| ExecutionID | string | Unique identifier for this specific job execution attempt |\n| JobID | string | Identifier of the job definition that was executed |\n| WorkflowID | string | Optional workflow identifier if job was part of workflow execution |\n| SubmissionTime | time.Time | When the job was originally submitted to the scheduler |\n| ScheduledTime | time.Time | When the job was scheduled to begin execution based on cron expression |\n| ClaimTime | time.Time | When a worker successfully claimed the job for execution |\n| StartTime | time.Time | When job execution actually began on the worker |\n| CompletionTime | time.Time | When job execution finished (successfully or with failure) |\n| ExecutionDuration | time.Duration | Total time spent executing the job |\n| QueueWaitTime | time.Duration | Time spent waiting in queue before worker assignment |\n| ClaimToStartDelay | time.Duration | Delay between worker claim and actual execution start |\n| WorkerID | string | Identifier of the worker that executed the job |\n| ResourcesUsed | ResourceUtilization | Actual resource consumption during execution |\n| ExitCode | int | Job process exit code |\n| ExecutionLogs | string | Captured standard output and error from job execution |\n| RetryAttempts | []RetryRecord | Details of any retry attempts before final completion |\n| Dependencies | []DependencyResolution | How job dependencies were resolved for this execution |\n\n**Performance Analytics Engine:**\n\nThe analytics engine processes historical execution records to provide insights for optimization and troubleshooting:\n\n1. **Trend Analysis**: Identifies patterns in job execution times, failure rates, and resource usage over time to detect performance degradation or improvement\n2. **Capacity Planning**: Analyzes historical queue depths, worker utilization, and execution patterns to recommend infrastructure scaling decisions\n3. **Failure Root Cause Analysis**: Correlates job failures with system conditions (worker health, resource availability, network issues) to identify common failure causes\n4. **Schedule Optimization**: Recommends schedule adjustments based on actual execution patterns to reduce resource contention and improve completion rates\n5. **Worker Performance Profiling**: Identifies workers with consistently poor performance or resource efficiency to guide maintenance decisions\n\n**Data Retention and Archival:**\n\nLong-term job history requires careful data management to balance analytical value with storage costs:\n\n| Retention Period | Data Granularity | Storage Location | Access Pattern |\n|------------------|------------------|------------------|----------------|\n| Last 7 days | Full execution records with logs | Hot storage (SSD) | Real-time dashboards, immediate troubleshooting |\n| 8-90 days | Execution records without logs | Warm storage (HDD) | Performance analysis, capacity planning |\n| 91 days - 1 year | Aggregated daily/hourly summaries | Cold storage (object store) | Long-term trending, compliance reporting |\n| 1+ years | Monthly aggregate summaries | Archive storage | Historical analysis, audit requirements |\n\n#### Administrative Interfaces\n\nProduction schedulers require comprehensive administrative capabilities for **job management**, **worker administration**, **system configuration**, and **emergency operations**. The administrative interface provides both web-based dashboards and programmatic APIs for operational teams.\n\n**Web-Based Administrative Dashboard:**\n\nThe dashboard provides comprehensive visibility and control through several specialized views:\n\n1. **System Overview Dashboard**: Real-time system health, active job counts, worker status, and critical alerts in a single view\n2. **Job Management Interface**: Search, filter, and manage jobs with capabilities to pause, resume, cancel, or manually trigger job execution\n3. **Worker Administration Panel**: View worker health, resource utilization, and administrative actions like graceful shutdown or resource limit adjustments\n4. **Workflow Visualization**: Graphical representation of workflow definitions and execution progress with interactive dependency graphs\n5. **Performance Analytics Dashboard**: Historical performance trends, capacity utilization reports, and optimization recommendations\n6. **Configuration Management**: Administrative interface for scheduler settings, worker policies, and system parameters\n\n**Administrative API Endpoints:**\n\n| Endpoint Category | Operations | Purpose |\n|-------------------|------------|---------|\n| Job Administration | List, search, pause, resume, cancel, retry, manual trigger | Operational control over job execution |\n| Worker Management | List workers, drain worker, remove worker, update capacity | Worker lifecycle and capacity management |\n| System Configuration | Get/set scheduler config, update cron schedules, modify priorities | Runtime configuration adjustments |\n| Emergency Operations | Emergency stop, bulk job cancellation, system maintenance mode | Crisis response and maintenance procedures |\n| Audit and Reporting | Execution reports, performance summaries, compliance exports | Operational reporting and audit trails |\n\n**Role-Based Access Control:**\n\nAdministrative interfaces require sophisticated access control to ensure appropriate separation of duties:\n\n| Role | Permissions | Typical Use Cases |\n|------|-------------|-------------------|\n| Viewer | Read-only access to dashboards and job status | Developers checking job status, managers reviewing performance |\n| Operator | Job pause/resume/cancel, worker drain operations | On-call engineers responding to alerts, scheduled maintenance |\n| Administrator | Full system configuration, worker management, emergency operations | System administrators, DevOps team leads |\n| Auditor | Read-only access to all data including sensitive logs and configurations | Compliance audits, security reviews |\n\n#### Comprehensive Audit Logging\n\nEnterprise deployments require detailed audit trails for **compliance requirements**, **security monitoring**, and **operational analysis**. Comprehensive audit logging captures all administrative actions, system events, and security-relevant activities with tamper-evident storage.\n\n**Audit Event Categories:**\n\n| Category | Events Logged | Security Relevance |\n|----------|---------------|-------------------|\n| Administrative Actions | Job creation/modification/deletion, worker management, configuration changes | High - tracks all system modifications |\n| Authentication/Authorization | User login/logout, permission checks, access denials | Critical - security monitoring and compliance |\n| Job Execution | Job starts, completions, failures, retry attempts | Medium - operational analysis and debugging |\n| System Events | Leader elections, worker registrations, coordinator failovers | Medium - system health and coordination monitoring |\n| Data Access | Job payload access, log retrieval, configuration queries | Low - data access patterns and usage analysis |\n\n**Audit Record Structure:**\n\n| Field | Type | Description |\n|-------|------|-------------|\n| AuditID | string | Unique identifier for this audit event |\n| Timestamp | time.Time | Precise timestamp when event occurred |\n| EventType | AuditEventType | Category and specific type of audited event |\n| ActorID | string | Identity of user or system component that triggered the event |\n| ActorType | ActorType | Whether actor is human user, system service, or external API client |\n| TargetResource | string | Resource that was affected by the audited action |\n| Action | string | Specific action taken (CREATE, UPDATE, DELETE, ACCESS) |\n| Outcome | AuditOutcome | Whether the action succeeded, failed, or was denied |\n| SourceIP | string | Network address where the action originated |\n| UserAgent | string | Client identifier for API or web interface actions |\n| SessionID | string | Session identifier for correlated actions within same user session |\n| Changes | map[string]AuditChange | Before/after values for modification actions |\n| Context | map[string]string | Additional context relevant to the specific event |\n\n**Tamper-Evident Storage:**\n\nAudit logs require protection against modification to maintain their evidentiary value:\n\n1. **Cryptographic Hashing**: Each audit record includes a hash of its content and the hash of the previous record, creating a blockchain-like chain\n2. **Append-Only Storage**: Audit logs are stored in append-only files or database tables that prevent modification of existing records\n3. **External Backup**: Regular encrypted backups of audit logs to external storage systems controlled by separate administrative domains\n4. **Integrity Verification**: Automated processes verify the hash chain integrity and alert on any tampering attempts\n5. **Retention Enforcement**: Automated retention policies prevent premature deletion while ensuring compliance with data retention regulations\n\n### Scalability Improvements\n\nThe current three-milestone implementation operates effectively within a single cluster or data center. Production deployments often require capabilities that exceed single-cluster capacity or span multiple geographic regions. Scalability improvements enable **horizontal sharding**, **multi-datacenter deployment**, and **performance optimizations** that support enterprise-scale workloads.\n\nThink of scalability improvements like expanding from a single factory to a global manufacturing network. The single factory has excellent coordination and efficiency, but geographic expansion requires regional facilities, supply chain coordination, and quality standardization across locations. Similarly, scaling the job scheduler beyond single-cluster deployment requires careful design of data partitioning, cross-region coordination, and performance optimization.\n\n#### Horizontal Sharding Architecture\n\nSingle-cluster deployments face fundamental limits in job throughput, worker capacity, and coordination overhead. Horizontal sharding distributes jobs across multiple independent scheduler clusters based on **sharding keys**, with a **shard coordinator** managing job distribution and cross-shard queries.\n\n**Sharding Strategy Design:**\n\nThe sharding architecture divides the job namespace across multiple clusters using configurable sharding keys:\n\n| Sharding Key | Distribution Strategy | Use Cases |\n|--------------|----------------------|-----------|\n| Job Name Prefix | Hash-based distribution by job name prefix | Application-based isolation (billing-*, analytics-*, etc.) |\n| Cron Schedule | Time-based distribution by execution frequency | Separate high-frequency and batch workloads |\n| Priority Level | Priority-based shard assignment | Dedicated clusters for critical vs. routine work |\n| Resource Requirements | Resource-based distribution by job resource needs | Specialized clusters for CPU-intensive vs. memory-intensive jobs |\n| Tenant ID | Multi-tenant isolation with dedicated shards | Enterprise deployments with strict tenant isolation |\n\n**Shard Coordinator Architecture:**\n\nThe shard coordinator operates as a lightweight routing layer that distributes jobs to appropriate shards without becoming a bottleneck:\n\n| Component | Responsibility | Scalability Characteristics |\n|-----------|---------------|---------------------------|\n| Routing Service | Determines target shard for job submissions | Stateless, horizontally scalable, caches shard mappings |\n| Shard Registry | Maintains shard health and capacity information | Replicated across multiple registry nodes, eventually consistent |\n| Cross-Shard Query Engine | Aggregates queries across multiple shards | Parallel query execution, result merging, timeout handling |\n| Rebalancing Coordinator | Manages shard capacity and job migration | Low-frequency operations, careful coordination to prevent disruption |\n\n**Job Distribution Algorithm:**\n\nThe shard coordinator uses a consistent hashing algorithm to ensure stable job assignment even as shards are added or removed:\n\n1. **Shard Key Extraction**: Extract the configured sharding key value from incoming job submissions\n2. **Hash Calculation**: Compute a consistent hash of the shard key using a stable hash function (SHA-256)\n3. **Shard Selection**: Map the hash value to a specific shard using consistent hashing ring or modulo arithmetic\n4. **Health Check**: Verify the selected shard is healthy and accepting jobs; if not, select the next healthy shard in the ring\n5. **Job Submission**: Forward the job to the selected shard's job submission API with original metadata preserved\n6. **Response Handling**: Return the shard's response to the original client, including any shard-specific job identifiers\n\n> **Decision: Cross-Shard Dependency Handling**\n> - **Context**: Jobs with dependencies may be distributed across different shards, requiring coordination for dependency resolution\n> - **Options Considered**: Prohibit cross-shard dependencies, centralized dependency tracker, distributed dependency resolution, job co-location\n> - **Decision**: Implement job co-location where jobs with dependencies are assigned to the same shard as their prerequisites\n> - **Rationale**: Maintains dependency resolution performance and simplifies coordination logic by avoiding cross-shard communication\n> - **Consequences**: May create load imbalances if dependency chains are concentrated, but eliminates complex distributed dependency protocols\n\n#### Multi-Datacenter Deployment\n\nEnterprise deployments often require job execution across multiple geographic regions for **disaster recovery**, **latency optimization**, and **regulatory compliance**. Multi-datacenter deployment extends the scheduler to operate across regions while maintaining consistency and handling network partitions gracefully.\n\n**Datacenter Topology Models:**\n\n| Deployment Model | Characteristics | Coordination Requirements |\n|------------------|-----------------|--------------------------|\n| Active-Passive | Single active datacenter, passive backup for disaster recovery | Minimal coordination, fast failover, potential data loss during transition |\n| Active-Active Regional | Each datacenter handles jobs for its geographic region | Moderate coordination for cross-region workflows and shared schedules |\n| Global Active-Active | Jobs distributed globally based on resource availability | High coordination overhead, complex consensus, maximum availability |\n| Federated | Independent schedulers with optional job sharing | Minimal coordination, loose coupling, manual intervention for cross-datacenter workflows |\n\n**Network Partition Tolerance:**\n\nMulti-datacenter deployments must handle network partitions gracefully without losing job execution capability:\n\n1. **Partition Detection**: Monitor inter-datacenter connectivity using multiple network paths and consensus protocols to identify partitions\n2. **Split-Brain Prevention**: Use external consensus systems (like managed etcd clusters) or quorum-based decisions to prevent multiple datacenters claiming leadership\n3. **Graceful Degradation**: Continue processing region-local jobs during partitions while deferring cross-region workflows until connectivity restores\n4. **State Reconciliation**: Automatically reconcile job states and execution history when partitions heal, handling conflicts through timestamp ordering or manual review\n5. **Emergency Procedures**: Provide administrative controls to manually override partition detection for emergency operations\n\n**Cross-Datacenter Job Scheduling:**\n\nSome jobs require execution in specific datacenters due to data locality, regulatory requirements, or resource availability:\n\n| Scheduling Strategy | Implementation | Trade-offs |\n|---------------------|----------------|------------|\n| Datacenter Affinity | Jobs specify preferred datacenter in metadata | Simple implementation, may create load imbalances |\n| Data Locality Optimization | Schedule jobs in datacenter closest to required data | Optimal performance, requires data location tracking |\n| Regulatory Compliance | Enforce jobs execute only in compliant regions | Strict compliance, potential capacity constraints |\n| Load Balancing | Dynamically assign jobs based on datacenter capacity | Optimal resource utilization, complex coordination |\n\n#### Performance Optimizations\n\nHigh-throughput deployments require performance optimizations that minimize coordination overhead, reduce latency, and maximize resource utilization efficiency. These optimizations focus on **coordination protocol improvements**, **caching strategies**, and **batching optimizations**.\n\n**Coordination Protocol Enhancements:**\n\nThe current leader election and worker coordination protocols can be optimized for higher scale:\n\n1. **Hierarchical Leadership**: Implement regional leaders that coordinate with a global leader, reducing coordination overhead for local operations\n2. **Lease-Based Coordination**: Use longer lease periods with more sophisticated renewal protocols to reduce heartbeat frequency without sacrificing failure detection speed\n3. **Bulk Operations**: Batch multiple coordination operations (job assignments, status updates) into single messages to reduce network overhead\n4. **Protocol Pipelining**: Allow multiple outstanding coordination requests to improve throughput in high-latency network environments\n5. **Adaptive Timeouts**: Dynamically adjust coordination timeouts based on network conditions and system load to optimize for both responsiveness and stability\n\n**Intelligent Caching Strategies:**\n\nCaching reduces load on core coordination services and improves response times for frequently accessed data:\n\n| Cache Type | Cached Data | Invalidation Strategy |\n|------------|-------------|----------------------|\n| Job Metadata Cache | Job definitions, cron expressions, priorities | TTL-based with immediate invalidation on updates |\n| Worker Capability Cache | Worker resources, capabilities, health status | Heartbeat-driven updates with fallback TTL |\n| Cron Calculation Cache | Next execution times for common cron expressions | Long TTL with timezone-aware invalidation |\n| Dependency Graph Cache | Job dependency relationships for active workflows | Version-based invalidation when dependencies change |\n| Shard Routing Cache | Shard assignment mappings for sharded deployments | Consistent hash-based with health-driven updates |\n\n**Batching and Bulk Operations:**\n\nSingle-operation APIs create coordination overhead that limits throughput. Batching operations improves efficiency:\n\n1. **Bulk Job Submission**: Accept multiple jobs in single API calls with transactional semantics for all-or-nothing submission\n2. **Batch Worker Updates**: Aggregate multiple worker status updates into periodic batch operations to reduce coordination frequency\n3. **Bulk Query Operations**: Support queries that return multiple jobs or workers in single requests to reduce API round-trips\n4. **Streaming Updates**: Provide streaming APIs for real-time job status updates instead of polling-based approaches\n5. **Lazy Evaluation**: Defer expensive operations like dependency resolution until actually needed rather than computing eagerly\n\n**Common Pitfalls in Scalability Improvements:**\n\n⚠️ **Pitfall: Inconsistent Sharding During Rebalancing**  \nRebalancing shards while jobs are in flight can lead to job assignments to incorrect shards or lost jobs during migration. Implement careful coordination protocols that ensure all in-flight jobs complete on their original shards before migrating future jobs to rebalanced shards.\n\n⚠️ **Pitfall: Cross-Datacenter Clock Skew**  \nCron scheduling across datacenters with significant clock skew causes jobs to execute at unexpected times or miss schedules entirely. Implement NTP synchronization monitoring and validate that clock skew remains within acceptable bounds (typically under 1 second) across all scheduler nodes.\n\n⚠️ **Pitfall: Cache Invalidation Storms**  \nPopular job patterns or mass configuration updates can trigger cache invalidation storms that overload coordination services during cache refill. Implement staggered cache invalidation with exponential backoff and circuit breakers around cache refresh operations.\n\n### Implementation Guidance\n\nThe future extensions described above represent significant enhancements to the core scheduler implementation. While these features go beyond the scope of the three-milestone project, understanding their architectural patterns and implementation approaches provides valuable insight into production system evolution.\n\n**Technology Recommendations for Extensions:**\n\n| Extension Category | Recommended Technologies | Rationale |\n|-------------------|-------------------------|-----------|\n| Job Dependencies | Redis Graph, Neo4j, or PostgreSQL with recursive queries | Graph relationships require efficient traversal and cycle detection |\n| Resource Scheduling | Kubernetes-style resource quotas, cgroups integration | Proven patterns for resource management and isolation |\n| Multi-Datacenter | etcd clusters, Consul Connect, or custom Raft implementation | Mature distributed consensus systems with partition tolerance |\n| Metrics/Monitoring | Prometheus + Grafana, DataDog, or New Relic | Established monitoring ecosystems with alerting and dashboards |\n| Workflow Orchestration | Temporal, Apache Airflow patterns, or custom state machines | Mature workflow engines provide proven orchestration patterns |\n\n**File Structure for Extensions:**\n\n```\nproject-root/\n  cmd/\n    scheduler/              ← main scheduler service\n    shard-coordinator/      ← sharding coordinator service\n    admin-dashboard/        ← administrative web interface\n  internal/\n    scheduler/              ← core scheduler from milestones\n    extensions/\n      dependencies/         ← job dependency resolution\n        graph.go           ← dependency graph operations\n        resolver.go        ← dependency resolution engine\n      resources/           ← resource-aware scheduling\n        allocator.go       ← resource allocation tracking\n        scheduler.go       ← resource-aware job assignment\n      workflows/           ← workflow orchestration\n        engine.go          ← workflow execution engine\n        definition.go      ← workflow definition parsing\n      sharding/            ← horizontal sharding\n        coordinator.go     ← shard coordination logic\n        hasher.go          ← consistent hashing implementation\n      monitoring/          ← enhanced monitoring\n        collector.go       ← comprehensive metrics collection\n        analytics.go       ← historical data analysis\n      admin/               ← administrative interfaces\n        api.go             ← administrative REST API\n        dashboard.go       ← web dashboard handlers\n  web/                     ← dashboard static assets\n    dashboard/\n      index.html           ← main dashboard page\n      workflow-viz.js      ← workflow visualization\n  deployments/\n    k8s/                   ← Kubernetes deployment manifests\n    docker-compose/        ← Docker Compose for development\n```\n\n**Extension Implementation Priorities:**\n\nFor teams considering implementing these extensions, the recommended priority order balances implementation complexity with operational value:\n\n1. **Enhanced Monitoring and Metrics** - Essential for production deployment, builds on existing Prometheus integration\n2. **Job Execution History** - Provides immediate operational value with moderate implementation complexity\n3. **Administrative Interfaces** - Critical for operational teams, can start with simple REST APIs and evolve to full dashboards  \n4. **Resource-Aware Scheduling** - High value for resource optimization, extends existing worker coordination patterns\n5. **Job Dependencies** - Complex but enables significant workflow capabilities, requires careful dependency resolution design\n6. **Horizontal Sharding** - Needed only for very high scale, complex distributed systems challenges\n7. **Multi-Datacenter Deployment** - Specialized requirement for global deployments, highest complexity implementation\n8. **Workflow Orchestration** - Builds on dependencies, provides highest-level abstraction for complex workflows\n\n**Integration Testing for Extensions:**\n\nExtensions require comprehensive integration testing beyond the unit testing approaches outlined in the main testing strategy:\n\n1. **Multi-Node Testing**: Test extension behavior across multiple coordinator and worker nodes to verify distributed behavior\n2. **Failure Injection**: Systematically test network partitions, node failures, and resource exhaustion scenarios  \n3. **Load Testing**: Validate performance characteristics under production-level job submission and execution rates\n4. **Cross-Version Testing**: Ensure extensions maintain backward compatibility with jobs and workflows created by older versions\n5. **End-to-End Workflows**: Test complete business workflows that exercise multiple extension features in combination\n\n**Milestone Checkpoints for Extensions:**\n\nEach extension category represents a significant development milestone with specific verification criteria:\n\n- **Advanced Scheduling Milestone**: Successfully execute a workflow with job dependencies, resource constraints, and conditional steps\n- **Operational Features Milestone**: Deploy monitoring dashboards, execute administrative operations through web interface, demonstrate audit trail completeness  \n- **Scalability Milestone**: Demonstrate job execution across multiple shards or datacenters with consistent behavior and partition tolerance\n\nThese extensions transform the distributed job scheduler from a reliable task execution system into a comprehensive enterprise workflow platform. While the three core milestones provide a solid foundation for most use cases, these extensions enable the scheduler to handle the complex requirements of large-scale production deployments across diverse organizational and technical environments.\n\n\n## Glossary\n\n> **Milestone(s):** This section provides essential terminology definitions that apply across all three milestones - cron scheduling terminology for Milestone 1, priority queue and deduplication concepts for Milestone 2, and distributed systems coordination terms for Milestone 3.\n\nThis glossary defines the key terminology used throughout the distributed job scheduler design document. Understanding these terms is crucial for implementing the system correctly and communicating effectively about distributed scheduling concepts. The terms are organized by domain area, starting with fundamental distributed systems concepts, then moving to scheduling-specific terminology, and finally covering operational and debugging concepts.\n\n### Distributed Systems Core Concepts\n\n**Exactly-once execution** - A guarantee that each job runs precisely one time, never skipped and never duplicated. This is the strongest consistency guarantee in distributed scheduling but requires careful coordination mechanisms. In practice, most systems achieve at-least-once execution with idempotent job design rather than true exactly-once semantics due to the complexity of distributed consensus.\n\n**At-least-once execution** - A weaker guarantee where jobs may run multiple times but are never lost or skipped. This is more practical to implement in distributed systems because it only requires durable job queuing and retry logic, not distributed coordination to prevent duplicates. Jobs must be designed to handle duplicate execution gracefully.\n\n**Leader election** - The process of selecting a single coordinator node from multiple candidates in a distributed system. The leader is responsible for making decisions that require global coordination, such as job assignment and worker failure detection. Leader election prevents split-brain scenarios where multiple nodes attempt to coordinate simultaneously.\n\n**Split-brain** - A failure condition where network partitions cause multiple coordinator nodes to believe they are the leader simultaneously. This can result in duplicate job execution, conflicting worker assignments, and data corruption. Prevention requires consensus protocols and fencing mechanisms to ensure only one active leader.\n\n**Fencing token** - A unique, monotonically increasing identifier that prevents stale operations from interfering with current system state. When a worker claims a job, it receives a fencing token. Later operations must present this token to prove they are authorized and current. Outdated tokens are rejected, preventing race conditions during worker failures.\n\n**Network partition** - A failure mode where network connectivity is lost between subsets of nodes, effectively splitting the cluster into isolated groups. Each partition may continue operating independently, potentially causing inconsistent state. Partition tolerance requires careful design of consensus algorithms and data consistency mechanisms.\n\n**Consensus algorithms** - Distributed protocols that enable multiple nodes to agree on a single value or decision despite failures and network issues. Examples include Raft, Paxos, and Byzantine Fault Tolerance. Consensus is essential for leader election, cluster membership, and ensuring consistent job scheduling decisions across coordinators.\n\n**Distributed locking** - Mechanisms that ensure only one node can access a shared resource at a time, even across network boundaries. In job scheduling, distributed locks prevent multiple workers from claiming the same job simultaneously. Implementation typically uses external coordination services like etcd or Redis with lease-based timeouts.\n\n### Job Scheduling and Cron Concepts\n\n**Cron expression** - A time-based job scheduler pattern using five or six fields (minute, hour, day-of-month, month, day-of-week, optionally seconds) to specify when jobs should execute. Each field can contain specific values, ranges, lists, step values, or wildcards. For example, `0 */2 * * *` means \"every two hours at minute 0\".\n\n**Field constraint** - Individual time component filters within a cron expression that determine when execution is allowed. For minute field `10,20,30`, the constraint allows execution only when the current minute is exactly 10, 20, or 30. All field constraints must be satisfied simultaneously for execution to occur.\n\n**Next execution time** - The future timestamp when a cron job should run next, calculated by finding the earliest time after the current moment that satisfies all field constraints. This requires calendar arithmetic to handle month boundaries, leap years, and timezone transitions correctly.\n\n**Pattern matching** - The process of checking whether a current timestamp satisfies all field constraints in a cron expression. This involves expanding ranges and step values into explicit lists, then testing if each time component (minute, hour, etc.) appears in the corresponding constraint list.\n\n**Range expansion** - Converting cron syntax shortcuts like `1-5` (range) or `*/15` (step values) into explicit lists of valid values. Range `1-5` becomes `[1, 2, 3, 4, 5]`, while `*/15` in the minute field becomes `[0, 15, 30, 45]`. This simplifies pattern matching logic.\n\n**Calendar arithmetic** - Mathematical operations involving dates and time periods that must account for irregular calendar rules like varying month lengths, leap years, and daylight saving time transitions. Simple timestamp addition fails across month boundaries; proper date libraries handle these complexities.\n\n**Timezone normalization** - Converting all timestamps to UTC (Coordinated Universal Time) for consistent storage and comparison, then converting back to local timezone for display or cron evaluation. This prevents scheduling errors when coordinators and workers operate in different timezones.\n\n**Daylight saving time (DST)** - Seasonal time adjustments that create temporal anomalies twice yearly. During \"spring forward\", 2:30 AM doesn't exist. During \"fall back\", 1:30 AM occurs twice. Cron scheduling must handle these transitions by skipping or duplicating execution appropriately.\n\n**DST transition** - The specific moments when clocks change between standard and daylight saving time. Jobs scheduled during transition periods may be skipped (spring forward) or run twice (fall back) unless the scheduler implements special handling for these edge cases.\n\n### Priority Queue and Job Management\n\n**Priority queue** - A data structure that serves the highest-priority element first, regardless of insertion order. In job scheduling, higher-priority jobs are dequeued before lower-priority ones. Implementation typically uses a min-heap or max-heap depending on whether lower or higher numbers indicate priority.\n\n**Deduplication** - Prevention of duplicate job submissions using idempotency keys or content hashes. When a job is submitted with the same deduplication identifier as an existing job, the system returns the existing job instead of creating a duplicate. This prevents accidental double-execution from client retry logic.\n\n**Idempotency key** - A client-provided unique identifier that ensures multiple submissions of the same job create only one execution. The key should be deterministic based on job content and intent. For example, `\"user-123-daily-report-2024-01-15\"` ensures only one daily report per user per day.\n\n**Content hash** - A deterministic hash (like SHA-256) computed from normalized job payload content. Used for deduplication when no explicit idempotency key is provided. The hash must be computed from a canonical representation to ensure identical jobs produce identical hashes regardless of field ordering.\n\n**Delayed execution** - Jobs that exist in the system but remain invisible and ineligible for worker assignment until a specified future time. Implementation uses the visibility timeout pattern where jobs are stored with a \"not_before\" timestamp and promoted to the active queue when that time arrives.\n\n**Visibility timeout pattern** - A queuing mechanism where messages exist but remain invisible to consumers until a timeout expires. For job scheduling, this enables delayed execution by setting visibility timeout to the scheduled execution time. Jobs become visible and claimable only when ready to run.\n\n**Atomic operations** - Database or data structure operations that complete entirely or not at all, with no partial states visible to concurrent operations. Critical for job claiming to prevent race conditions where multiple workers attempt to claim the same job simultaneously.\n\n**Priority inversion** - A condition where high-priority jobs are blocked by lower-priority work, either through resource contention or implementation bugs. In job queues, this can occur if priority ordering is not strictly maintained or if workers become blocked on low-priority long-running tasks.\n\n### Worker Coordination and Fault Tolerance\n\n**Worker coordination** - The process of managing job distribution across multiple worker nodes, including worker registration, capability matching, load balancing, and failure detection. Coordination ensures work is distributed efficiently while maintaining fault tolerance through redundancy.\n\n**Heartbeat** - A periodic liveness signal sent from workers to coordinators indicating the worker is healthy and available for job assignment. Missed heartbeats trigger failure detection. Heartbeat messages typically include current job count, resource utilization, and capability information.\n\n**Graceful shutdown** - A controlled worker termination process that completes currently executing jobs before stopping, rather than abruptly terminating and losing work. This prevents job loss during planned maintenance or scaling operations.\n\n**Capability matching** - Ensuring workers can handle specific job types by comparing required job capabilities against worker-provided capabilities. For example, jobs requiring GPU processing are only assigned to workers advertising GPU capability. This prevents job failures from resource mismatches.\n\n**Fault tolerance** - The system's ability to continue operating correctly despite node failures, network issues, or other faults. Achieved through redundancy, replication, failure detection, and recovery mechanisms. In job scheduling, fault tolerance ensures jobs complete even when individual workers fail.\n\n**Failure detection** - Mechanisms for identifying when system components have stopped functioning correctly. Common approaches include heartbeat timeouts, health check failures, and monitoring error rates. Accurate failure detection is crucial for triggering recovery procedures promptly.\n\n**Job recovery** - The process of reassigning jobs from failed workers to healthy workers. Recovery must handle jobs in various states: claimed but not started, currently executing, and completed but not reported. Proper recovery prevents job loss while avoiding duplicate execution.\n\n**Message amplification** - A failure mode where message retries create exponentially increasing load, potentially overwhelming the system. Can occur when multiple components retry simultaneously or when retry delays are not properly randomized. Mitigation requires exponential backoff with jitter.\n\n**Thundering herd** - A scenario where many workers simultaneously attempt to claim jobs or reconnect after a shared dependency (like the coordinator) recovers from failure. This can overwhelm the recovering component. Prevention uses randomized delays and gradual reconnection.\n\n### Error Handling and Reliability\n\n**Exponential backoff** - A retry strategy where the delay between attempts increases exponentially (e.g., 1s, 2s, 4s, 8s) to reduce load on failing systems and increase the chance of recovery. Often combined with jitter (random variation) to prevent synchronized retry storms across multiple clients.\n\n**Circuit breaker** - A reliability pattern that prevents cascade failures by temporarily stopping calls to a failing service. The circuit breaker monitors error rates and \"opens\" (blocks requests) when failures exceed a threshold, allowing the downstream service time to recover.\n\n**Dead letter queue** - A repository for operations that failed all retry attempts and require manual intervention. Dead letter entries include the original operation, failure history, and diagnostic context. This prevents permanent job loss while allowing operators to investigate and potentially resubmit failed work.\n\n**Retry amplification** - A failure mode where multiple system layers retry the same operation simultaneously, creating exponential load increase. For example, if both the client and server retry a failed job submission, the total retry attempts become multiplicative rather than additive.\n\n**Jitter** - Random variation added to retry delays to prevent synchronized behavior across multiple clients. Without jitter, all clients retry at exactly the same intervals, creating periodic load spikes. Random jitter spreads the load over time for better system stability.\n\n**Idempotency** - A property where executing the same operation multiple times produces the same result as executing it once. Essential for reliable distributed systems because network failures can make it unclear whether operations succeeded, requiring safe retry mechanisms.\n\n**Graduated failure detection** - An escalating response strategy where the system's reaction intensifies based on failure duration and severity. Short transient failures might trigger simple retries, while sustained failures escalate to circuit breaker activation and alerting.\n\n### Testing and Development\n\n**Unit testing** - Testing individual components (functions, classes, modules) in isolation using mocked dependencies. For the job scheduler, this includes testing cron parsing logic, priority queue operations, and worker state transitions independently of external systems.\n\n**Integration testing** - Testing component interactions under realistic conditions with actual dependencies like Redis, etcd, or databases. This verifies that components work together correctly and can handle real network delays, connection failures, and concurrent access patterns.\n\n**End-to-end testing** - Complete system validation that tests the entire job execution flow from submission through completion. This includes submitting jobs, verifying they execute on workers, handling failures, and confirming final state matches expectations.\n\n**Failure injection** - Systematic introduction of failures into the system during testing to verify resilience mechanisms work correctly. Examples include network partitions, process crashes, disk failures, and resource exhaustion. Also called chaos engineering or fault injection.\n\n**Race conditions** - Timing-dependent bugs in concurrent code where the outcome depends on the relative timing of operations across threads or processes. Common in distributed systems due to network delays. Prevention requires careful synchronization and atomic operations.\n\n**Deterministic testing** - Creating predictable test behavior by controlling sources of randomness like timestamps, network delays, and thread scheduling. This makes tests repeatable and debuggable by eliminating timing-dependent failures.\n\n**Test harness** - Infrastructure providing consistent test environments including mock services, controlled time, isolated databases, and cleanup mechanisms. The harness handles setup and teardown, allowing tests to focus on business logic verification.\n\n**Milestone checkpoints** - Structured validation points at each development stage that verify expected functionality is working before proceeding. Checkpoints include automated tests, manual verification steps, and integration smoke tests.\n\n### Observability and Debugging\n\n**Structured logging** - Logging with consistent data formats (typically JSON) that enable programmatic analysis, filtering, and correlation. Each log entry includes standard fields like timestamp, component, correlation ID, and operation name, plus operation-specific details.\n\n**Correlation ID** - A unique identifier that links related operations across distributed system boundaries. When a job is submitted, the same correlation ID appears in logs from the coordinator, worker, and queue components, enabling end-to-end request tracing.\n\n**Distributed tracing** - A technique for tracking request flow across multiple service boundaries by propagating trace context and recording timing spans. Each operation adds a span with start time, duration, and metadata, creating a complete timeline of distributed request execution.\n\n**Metrics collection** - Systematic gathering of quantitative system performance data like job completion rates, queue depths, worker utilization, and error rates. Metrics are typically time-series data stored in systems like Prometheus for alerting and dashboards.\n\n**Log aggregation** - Centralized collection and indexing of log entries from multiple distributed components. Aggregation enables searching across all system logs simultaneously and correlating events that span multiple services.\n\n**Failure pattern analysis** - Systematic identification of common failure sequences in distributed systems by analyzing log patterns, metrics anomalies, and error correlations. Helps identify root causes and prevent recurring issues through improved error handling.\n\n**Observability** - The ability to understand system internal state through external outputs (logs, metrics, traces). High observability enables rapid troubleshooting and performance optimization by providing visibility into system behavior during both normal and failure conditions.\n\n**Alert threshold** - Metric value boundaries that trigger automated notifications when crossed. Thresholds must balance sensitivity (catching real issues quickly) with specificity (avoiding false alarms). Common examples include error rate percentages and response time percentiles.\n\n### Future Extensions and Advanced Concepts\n\n**Job dependencies** - Prerequisites that must be satisfied before a job can execute, such as completion of other jobs or availability of required data. Dependencies create directed acyclic graphs (DAGs) of job relationships and require topological sorting for execution order.\n\n**Resource-aware scheduling** - Job assignment that considers memory, CPU, storage, and other resource requirements against worker capacity. This prevents resource exhaustion and improves overall system efficiency by matching job needs with worker capabilities.\n\n**Workflow orchestration** - Coordinated execution of multi-job workflows with conditional logic, parallel branches, loops, and error handling. More complex than simple job dependencies, workflows require state machines and execution engines to manage complex business processes.\n\n**Horizontal sharding** - Distributing jobs across multiple independent scheduler clusters based on characteristics like tenant ID, job type, or hash key. Sharding improves scalability by reducing coordination overhead and enabling independent scaling of different workload types.\n\n**Multi-datacenter deployment** - Operating the scheduler across multiple geographic regions for disaster recovery and latency optimization. Requires careful handling of clock skew, network partitions, and data consistency across wide-area networks.\n\n**Audit logging** - Detailed recording of administrative actions, configuration changes, and security events for compliance and security purposes. Audit logs are typically immutable and include who performed actions, when, what changed, and why.\n\nThis comprehensive glossary provides the foundation for understanding distributed job scheduler concepts and implementing the system correctly. The terminology spans from fundamental distributed systems concepts through specific scheduling algorithms to operational concerns, supporting both learning and professional communication about the system.\n\n### Implementation Guidance\n\nThe terminology in this glossary should be used consistently throughout code comments, documentation, and team communication. Here are practical guidelines for applying these terms in implementation:\n\n**Code Documentation Standards**\n\nWhen writing code comments and documentation, use these terms precisely and consistently. For example, always refer to \"exactly-once execution\" rather than mixing terms like \"exactly-once delivery\" or \"once-only processing\". This consistency helps team members communicate clearly and reduces misunderstandings during code reviews and debugging sessions.\n\n**Variable and Function Naming**\n\nIncorporate terminology into identifier names to make code self-documenting. Use `idempotencyKey` rather than generic names like `dedupId`. Name functions like `detectWorkerFailure()` and `performLeaderElection()` to clearly indicate their purpose using standard distributed systems terminology.\n\n**Error Messages and Logging**\n\nInclude proper terminology in error messages and log entries to aid debugging. Instead of \"job failed\", use \"job exceeded maximum retry attempts and moved to dead letter queue\". This provides operators with precise information about system state and required actions.\n\n**Team Communication Guidelines**\n\n| Term Category | Usage Guideline | Example |\n|---------------|-----------------|---------|\n| Consistency Levels | Always specify exactly-once vs at-least-once when discussing guarantees | \"This implementation provides at-least-once execution with idempotent job design\" |\n| Failure Modes | Use precise terms for different types of failures | \"We're seeing split-brain behavior, not general leader election failure\" |\n| Timing Concepts | Distinguish between different time-related operations | \"The DST transition caused cron schedule skipping, not general timezone normalization issues\" |\n| System States | Use exact state names from data model | \"Worker is in UNAVAILABLE state, not just 'down' or 'broken'\" |\n\n**Documentation Cross-References**\n\nWhen writing design documents or architectural decision records, reference this glossary to ensure consistent terminology. Include brief definitions for complex terms when first introduced in new contexts, with references back to the full glossary definitions for complete understanding.\n\nThis implementation guidance ensures the terminology serves its purpose of enabling clear, precise communication about the distributed job scheduler system throughout the development lifecycle.\n"}