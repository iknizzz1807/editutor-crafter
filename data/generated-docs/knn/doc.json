{"html":"<h1 id=\"k-nearest-neighbors-classifier-design-document\">K-Nearest Neighbors Classifier: Design Document</h1>\n<h2 id=\"overview\">Overview</h2>\n<p>A K-Nearest Neighbors classification system that predicts class labels by finding the K most similar training examples using distance metrics and majority voting. The key architectural challenge is efficiently computing distances in high-dimensional spaces while supporting multiple distance metrics and providing accurate predictions through optimized neighbor selection.</p>\n<blockquote>\n<p>This guide is meant to help you understand the big picture before diving into each milestone. Refer back to it whenever you need context on how components connect.</p>\n</blockquote>\n<h2 id=\"context-and-problem-statement\">Context and Problem Statement</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Foundational understanding for all milestones - establishes the core classification problem that drives distance calculation (Milestone 1), neighbor finding and voting (Milestone 2), and evaluation strategies (Milestone 3).</p>\n</blockquote>\n<h3 id=\"mental-model-the-neighborhood-recommendation-system\">Mental Model: The Neighborhood Recommendation System</h3>\n<p>Think of K-Nearest Neighbors (KNN) classification like asking your neighbors for restaurant recommendations in a new city. When you want to find a good Italian restaurant, you don&#39;t ask everyone in the city - you ask the people who are most similar to you. Maybe you ask neighbors with similar tastes, similar age, or similar dining budgets. You assume that people who are like you in measurable ways will have preferences similar to yours.</p>\n<p>In this neighborhood recommendation system, each neighbor gets one vote for their favorite restaurant. If you ask 5 neighbors and 3 recommend &quot;Mario&#39;s Pizzeria&quot; while 2 recommend different places, you go with the majority vote - Mario&#39;s Pizzeria. The key insight is that <strong>similarity breeds similarity</strong> - if someone is similar to you in the ways you can measure (age, income, food preferences), they&#39;re likely to be similar in the ways you can&#39;t easily measure (what makes a restaurant great).</p>\n<p>KNN classification works exactly the same way, but instead of neighbors recommending restaurants, training examples &quot;recommend&quot; class labels for new data points. The algorithm finds the K training examples that are most similar to your new data point (measured by distance in feature space), then takes a majority vote of their class labels. Just like asking neighbors, the assumption is that similar data points will have similar class labels.</p>\n<p>This neighborhood analogy reveals why KNN is called a <strong>lazy learning algorithm</strong> - it doesn&#39;t try to understand the underlying rules that separate classes (like &quot;all good Italian restaurants have fresh pasta&quot;). Instead, it simply remembers all the training examples and makes decisions by consulting the most relevant neighbors when needed, just like you might keep a mental rolodex of neighbors to ask for different types of advice.</p>\n<h3 id=\"problem-definition\">Problem Definition</h3>\n<p><strong>Classification</strong> is the supervised learning task of predicting discrete class labels for new data points based on patterns learned from labeled training examples. Formally, given a training dataset D = {(x₁, y₁), (x₂, y₂), ..., (xₙ, yₙ)} where each xᵢ is a feature vector and yᵢ is its corresponding class label, the goal is to learn a function f: X → Y that can accurately predict the class label y for any new feature vector x.</p>\n<p>The <strong>K-Nearest Neighbors approach</strong> to classification is based on the fundamental assumption that <strong>similar inputs should produce similar outputs</strong>. This assumption, known as the smoothness assumption in machine learning, suggests that the decision boundary between classes is locally smooth - data points that are close together in feature space are likely to belong to the same class.</p>\n<p>KNN operationalizes this assumption through a simple three-step process:</p>\n<ol>\n<li><p><strong>Distance Calculation</strong>: Measure the similarity between the query point and every training example using a distance metric (Euclidean, Manhattan, cosine, etc.). The choice of distance metric defines what &quot;similarity&quot; means for your specific problem.</p>\n</li>\n<li><p><strong>Neighbor Selection</strong>: Identify the K training examples with the smallest distances to the query point. These are the &quot;nearest neighbors&quot; that will vote on the classification decision.</p>\n</li>\n<li><p><strong>Majority Voting</strong>: Assign the class label that appears most frequently among the K nearest neighbors. Optionally, weight each neighbor&#39;s vote by the inverse of its distance to give closer neighbors more influence.</p>\n</li>\n</ol>\n<blockquote>\n<p><strong>Key Insight</strong>: KNN makes no assumptions about the underlying data distribution or the shape of decision boundaries. Unlike parametric models that assume data follows a specific mathematical form, KNN adapts to whatever patterns exist in the training data, making it particularly effective for complex, non-linear decision boundaries.</p>\n</blockquote>\n<p>The effectiveness of KNN depends on several critical factors that will drive our implementation decisions:</p>\n<p><strong>Distance Metric Selection</strong>: The choice of distance metric fundamentally determines which training examples are considered &quot;neighbors.&quot; Euclidean distance works well for continuous features with similar scales, Manhattan distance is robust to outliers, and cosine similarity is effective for high-dimensional sparse data like text features.</p>\n<p><strong>Neighborhood Size (K)</strong>: The value of K controls the bias-variance tradeoff. Small K values (like K=1) create complex decision boundaries that closely follow the training data but may overfit to noise. Large K values create smoother decision boundaries that generalize better but may underfit complex patterns. The optimal K must be determined empirically through cross-validation.</p>\n<p><strong>Feature Scaling</strong>: Since distance calculations treat all features equally, features with larger scales will dominate the distance computation. A person&#39;s income (measured in tens of thousands) will overwhelm their age (measured in tens) unless features are properly scaled.</p>\n<p><strong>Curse of Dimensionality</strong>: In high-dimensional spaces, the concept of &quot;nearest&quot; becomes less meaningful as all points become roughly equidistant. This requires careful feature selection and potentially dimensionality reduction techniques.</p>\n<h3 id=\"comparison-with-other-classification-methods\">Comparison with Other Classification Methods</h3>\n<p>Understanding how KNN differs from other classification approaches illuminates its unique strengths and appropriate use cases. The fundamental distinction lies in how different algorithms learn patterns from training data and make predictions.</p>\n<table>\n<thead>\n<tr>\n<th>Classification Approach</th>\n<th>Learning Strategy</th>\n<th>Decision Boundary</th>\n<th>Computational Cost</th>\n<th>Interpretability</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>KNN</td>\n<td>Instance-based (lazy)</td>\n<td>Adaptive, non-parametric</td>\n<td>High prediction cost</td>\n<td>Local interpretability</td>\n</tr>\n<tr>\n<td>Logistic Regression</td>\n<td>Parametric optimization</td>\n<td>Linear hyperplane</td>\n<td>Low prediction cost</td>\n<td>Global interpretability</td>\n</tr>\n<tr>\n<td>Decision Trees</td>\n<td>Recursive splitting</td>\n<td>Axis-aligned rectangles</td>\n<td>Medium prediction cost</td>\n<td>High interpretability</td>\n</tr>\n<tr>\n<td>Neural Networks</td>\n<td>Gradient-based learning</td>\n<td>Complex non-linear</td>\n<td>Low prediction cost</td>\n<td>Low interpretability</td>\n</tr>\n<tr>\n<td>SVM</td>\n<td>Margin maximization</td>\n<td>Linear or kernel-based</td>\n<td>Medium prediction cost</td>\n<td>Medium interpretability</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Instance-Based vs Parametric Learning</strong></p>\n<ul>\n<li><strong>Context</strong>: We need to choose between learning explicit parameters that generalize patterns (parametric) versus storing training examples and making local decisions (instance-based)</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>Parametric approach (learn global decision boundary parameters)</li>\n<li>Instance-based approach (store examples, make local decisions)</li>\n<li>Hybrid approach (learn local parameters for regions)</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Instance-based learning (KNN approach)</li>\n<li><strong>Rationale</strong>: Instance-based learning requires no assumptions about data distribution, adapts automatically to complex decision boundaries, and provides intuitive explanations for individual predictions by showing which training examples influenced the decision</li>\n<li><strong>Consequences</strong>: Higher memory requirements (must store all training data), slower predictions (must compute distances), but greater flexibility and interpretability for complex datasets</li>\n</ul>\n</blockquote>\n<p><strong>KNN vs Logistic Regression</strong>: Logistic regression learns a global linear decision boundary by optimizing parameters that define a hyperplane separating classes. This creates fast predictions (just evaluate the linear function) but assumes classes are linearly separable. KNN makes no linearity assumptions and can handle arbitrarily complex decision boundaries by adapting locally to the data distribution. However, KNN requires computing distances to all training points for each prediction, making it much slower than logistic regression&#39;s simple arithmetic.</p>\n<p><strong>KNN vs Decision Trees</strong>: Decision trees recursively split the feature space along axis-aligned boundaries to create rectangular decision regions. Each prediction follows a path from root to leaf, making the decision process highly interpretable. KNN creates more flexible decision boundaries that aren&#39;t restricted to axis-aligned splits, but the &quot;decision process&quot; is less transparent - you know which neighbors voted, but not why those specific features made them neighbors. Trees can overfit with deep splits, while KNN overfits with small K values.</p>\n<p><strong>KNN vs Neural Networks</strong>: Neural networks learn complex non-linear transformations through multiple layers of weighted combinations and activation functions. Once trained, predictions are very fast (forward pass through the network), but the learned representation is opaque. KNN provides local interpretability - you can examine the K neighbors that influenced any prediction - but lacks the global patterns that neural networks discover. Neural networks excel when you have massive datasets and care primarily about accuracy, while KNN excels when you need to explain individual predictions or work with smaller datasets.</p>\n<blockquote>\n<p><strong>The No Free Lunch Theorem</strong>: No classification algorithm is universally superior across all possible problems. KNN&#39;s strength lies in problems where local similarity is a reliable predictor of class membership, where decision boundaries are complex and non-linear, and where interpretability of individual predictions is important.</p>\n</blockquote>\n<p><strong>When KNN Excels</strong>:</p>\n<ul>\n<li><strong>Recommendation Systems</strong>: Finding users with similar preferences to recommend products</li>\n<li><strong>Medical Diagnosis</strong>: Finding patients with similar symptoms and test results</li>\n<li><strong>Image Classification</strong>: Finding visually similar images in feature space</li>\n<li><strong>Anomaly Detection</strong>: Identifying data points that are far from all training examples</li>\n<li><strong>Multi-modal Distributions</strong>: Classes that form multiple clusters rather than single regions</li>\n</ul>\n<p><strong>When KNN Struggles</strong>:</p>\n<ul>\n<li><strong>High-Dimensional Data</strong>: Curse of dimensionality makes distance metrics less meaningful</li>\n<li><strong>Large-Scale Applications</strong>: Computational cost of distance calculations becomes prohibitive</li>\n<li><strong>Noisy Data</strong>: Without feature selection, irrelevant features pollute distance calculations</li>\n<li><strong>Imbalanced Classes</strong>: Majority class neighbors can overwhelm minority class signals</li>\n<li><strong>Real-Time Applications</strong>: Prediction latency may be unacceptable for time-critical systems</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>Problem Characteristic</th>\n<th>KNN Suitability</th>\n<th>Reasoning</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Complex decision boundaries</td>\n<td>Excellent</td>\n<td>Adapts locally without parametric assumptions</td>\n</tr>\n<tr>\n<td>Need for interpretability</td>\n<td>Good</td>\n<td>Can examine which neighbors influenced decisions</td>\n</tr>\n<tr>\n<td>Large training datasets</td>\n<td>Poor</td>\n<td>Computational cost grows linearly with data size</td>\n</tr>\n<tr>\n<td>High-dimensional features</td>\n<td>Poor</td>\n<td>Distance becomes less meaningful in high dimensions</td>\n</tr>\n<tr>\n<td>Real-time predictions</td>\n<td>Poor</td>\n<td>Must compute distances to all training points</td>\n</tr>\n<tr>\n<td>Irregular class distributions</td>\n<td>Excellent</td>\n<td>No assumptions about class shape or distribution</td>\n</tr>\n</tbody></table>\n<p>Understanding these trade-offs guides our implementation priorities. We&#39;ll focus on efficient distance calculations, flexible distance metrics, and clear interfaces for examining neighbors, while acknowledging that performance optimization and dimensionality handling are areas for future enhancement rather than core requirements for this foundational implementation.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The implementation approach balances educational clarity with practical functionality. Since KNN is often a student&#39;s first encounter with instance-based learning, the code should clearly illustrate the core concepts while remaining efficient enough for real experimentation.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Distance Computation</td>\n<td>Pure NumPy with explicit loops</td>\n<td>Vectorized NumPy operations</td>\n</tr>\n<tr>\n<td>Data Storage</td>\n<td>Python lists and dictionaries</td>\n<td>NumPy structured arrays</td>\n</tr>\n<tr>\n<td>Neighbor Search</td>\n<td>Linear scan through all points</td>\n<td>KD-tree or LSH for acceleration</td>\n</tr>\n<tr>\n<td>Evaluation</td>\n<td>Manual train/test splits</td>\n<td>Scikit-learn&#39;s evaluation utilities</td>\n</tr>\n<tr>\n<td>Visualization</td>\n<td>Matplotlib scatter plots</td>\n<td>Interactive plots with Plotly</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-module-structure\">Recommended Module Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>knn_classifier/\n├── __init__.py                    # Package initialization\n├── core/\n│   ├── __init__.py\n│   ├── distance_metrics.py       # Distance calculation functions\n│   ├── neighbor_finder.py        # K-nearest neighbor search\n│   ├── classifier.py             # Main KNN classifier class\n│   └── data_types.py             # Core data structures and types\n├── evaluation/\n│   ├── __init__.py\n│   ├── cross_validation.py       # K-fold CV implementation\n│   ├── metrics.py                # Accuracy, precision, recall calculations\n│   └── optimization.py           # Hyperparameter tuning utilities\n├── utils/\n│   ├── __init__.py\n│   ├── data_loader.py            # Dataset loading and preprocessing\n│   ├── plotting.py               # Visualization utilities\n│   └── preprocessing.py          # Feature scaling and normalization\n└── examples/\n    ├── iris_classification.py    # Complete example with Iris dataset\n    ├── synthetic_data.py         # Generated 2D data for visualization\n    └── comparison_study.py       # Compare KNN with other algorithms</code></pre></div>\n\n<p>This structure separates concerns clearly: core algorithms in <code>core/</code>, evaluation logic in <code>evaluation/</code>, utilities in <code>utils/</code>, and complete examples in <code>examples/</code>. Each module has a single responsibility, making the codebase easier to understand and test.</p>\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p><strong>Data Types Foundation</strong> (<code>core/data_types.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Core data types for KNN classifier implementation.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Provides type hints and data structures used throughout the system.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Tuple, Dict, Optional, Union, Protocol</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Type aliases for clarity</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">FeatureVector </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.ndarray  </span><span style=\"color:#6A737D\"># 1D array representing features of a single sample</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">FeatureMatrix </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.ndarray  </span><span style=\"color:#6A737D\"># 2D array where each row is a FeatureVector</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">ClassLabel </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Union[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]  </span><span style=\"color:#6A737D\"># Class labels can be integers or strings</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">DistanceArray </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.ndarray  </span><span style=\"color:#6A737D\"># 1D array of distances</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">NeighborIndices </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.ndarray  </span><span style=\"color:#6A737D\"># 1D array of indices into training data</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DistanceMetric</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Supported distance metrics for neighbor calculation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    EUCLIDEAN</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"euclidean\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    MANHATTAN</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"manhattan\"</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    COSINE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"cosine\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TrainingData</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Container for training dataset with features and labels.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, features: FeatureMatrix, labels: List[ClassLabel]):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.features </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.array(features)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.labels </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> labels</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.n_samples, </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.n_features </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.features.shape</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.unique_classes </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> list</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">set</span><span style=\"color:#E1E4E8\">(labels))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_sample</span><span style=\"color:#E1E4E8\">(self, index: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Tuple[FeatureVector, ClassLabel]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get a single training sample by index.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.features[index], </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.labels[index]</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> PredictionResult</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Result of a single prediction with confidence information.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, predicted_class: ClassLabel, neighbor_indices: NeighborIndices, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 neighbor_distances: DistanceArray, confidence: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.predicted_class </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> predicted_class</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.neighbor_indices </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> neighbor_indices</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.neighbor_distances </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> neighbor_distances  </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.confidence </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> confidence  </span><span style=\"color:#6A737D\"># Proportion of neighbors voting for this class</span></span></code></pre></div>\n\n<p><strong>Data Loading Utilities</strong> (<code>utils/data_loader.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Utilities for loading and preprocessing datasets for KNN classification.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Handles common datasets and provides data splitting functionality.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sklearn.datasets </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> load_iris, make_classification</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sklearn.model_selection </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> train_test_split</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sklearn.preprocessing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> StandardScaler</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> load_iris_dataset</span><span style=\"color:#E1E4E8\">() -> Tuple[np.ndarray, np.ndarray]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Load the classic Iris dataset for flower classification.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    iris </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> load_iris()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> iris.data, iris.target</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> create_synthetic_dataset</span><span style=\"color:#E1E4E8\">(n_samples: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 200</span><span style=\"color:#E1E4E8\">, n_features: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                           n_classes: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 3</span><span style=\"color:#E1E4E8\">, random_state: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 42</span><span style=\"color:#E1E4E8\">) -> Tuple[np.ndarray, np.ndarray]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Create synthetic classification dataset for testing and visualization.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    X, y </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> make_classification(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        n_samples</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">n_samples,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        n_features</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">n_features,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        n_redundant</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        n_informative</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">n_features,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        n_classes</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">n_classes,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        n_clusters_per_class</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        random_state</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">random_state</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    )</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> X, y</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> split_and_scale_data</span><span style=\"color:#E1E4E8\">(X: np.ndarray, y: np.ndarray, test_size: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0.2</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        scale_features: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span><span style=\"color:#E1E4E8\">, random_state: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 42</span><span style=\"color:#E1E4E8\">) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Split data into train/test sets and optionally apply feature scaling.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    X_train, X_test, y_train, y_test </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> train_test_split(X, y, </span><span style=\"color:#FFAB70\">test_size</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">test_size, </span><span style=\"color:#FFAB70\">random_state</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">random_state)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> scale_features:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        scaler </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> StandardScaler()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        X_train </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> scaler.fit_transform(X_train)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        X_test </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> scaler.transform(X_test)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> X_train, X_test, y_train, y_test</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeleton-code\">Core Logic Skeleton Code</h4>\n<p><strong>Main KNN Classifier Interface</strong> (<code>core/classifier.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Main KNN Classifier implementation combining distance calculation,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">neighbor finding, and voting into a complete classification system.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .data_types </span><span style=\"color:#F97583\">import</span><span style=\"color:#F97583\"> *</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .distance_metrics </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> DistanceCalculator</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .neighbor_finder </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> NeighborFinder</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> KNNClassifier</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    K-Nearest Neighbors classifier with configurable distance metrics and voting strategies.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    The classifier follows the standard fit/predict interface:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    1. fit() stores the training data</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    2. predict() finds neighbors and performs voting for each query point</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 3</span><span style=\"color:#E1E4E8\">, distance_metric: DistanceMetric </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> DistanceMetric.</span><span style=\"color:#79B8FF\">EUCLIDEAN</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 weighted_voting: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> False</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Store hyperparameters (k, distance_metric, weighted_voting)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Initialize DistanceCalculator with chosen metric  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Initialize NeighborFinder with k parameter</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Initialize training_data to None (set during fit)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> fit</span><span style=\"color:#E1E4E8\">(self, X: FeatureMatrix, y: List[ClassLabel]) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Store training data for use during prediction.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        KNN is lazy learning - no actual training computation happens here.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate that X and y have compatible shapes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Create TrainingData object from X and y</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Store the TrainingData in self.training_data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: This method should be very simple - just data storage</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> predict</span><span style=\"color:#E1E4E8\">(self, X: FeatureMatrix) -> List[ClassLabel]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Predict class labels for query points using K-nearest neighbors voting.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate that classifier has been fitted (training_data is not None)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: For each query point in X:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2a: Find K nearest neighbors using neighbor_finder</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2b: Get class labels for those neighbors</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2c: Perform voting (majority or weighted) to get prediction</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return list of predictions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Consider using _predict_single() helper method for each query point</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> predict_with_confidence</span><span style=\"color:#E1E4E8\">(self, X: FeatureMatrix) -> List[PredictionResult]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Predict class labels with detailed information about neighbors and confidence.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Similar to predict(), but return PredictionResult objects</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Include neighbor indices, distances, and confidence scores</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Confidence = proportion of neighbors voting for predicted class</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _predict_single</span><span style=\"color:#E1E4E8\">(self, query_point: FeatureVector) -> PredictionResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Helper method to predict a single query point.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Find K nearest neighbors to query_point</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Get their class labels from training_data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Perform voting to determine prediction</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Calculate confidence score</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return PredictionResult with all information</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"language-specific-hints\">Language-Specific Hints</h4>\n<p><strong>NumPy Optimization Tips</strong>:</p>\n<ul>\n<li>Use <code>np.linalg.norm()</code> for Euclidean distance calculation instead of manual sqrt(sum(squares))</li>\n<li>Leverage broadcasting for vectorized distance computation: <code>X[:, np.newaxis, :] - training_data[np.newaxis, :, :]</code></li>\n<li>Use <code>np.argpartition()</code> for finding K smallest distances without full sorting</li>\n<li>Apply <code>np.bincount()</code> for fast majority voting when labels are integers</li>\n</ul>\n<p><strong>Memory Management</strong>:</p>\n<ul>\n<li>For large datasets, compute distances in batches to avoid memory overflow</li>\n<li>Consider using <code>np.float32</code> instead of <code>np.float64</code> if precision allows, for 2x memory savings</li>\n<li>Use views instead of copies when possible: <code>X[indices]</code> not <code>np.copy(X[indices])</code></li>\n</ul>\n<p><strong>Performance Monitoring</strong>:</p>\n<ul>\n<li>Use <code>time.perf_counter()</code> to measure distance calculation vs voting time separately</li>\n<li>Profile with <code>cProfile</code> to identify bottlenecks: <code>python -m cProfile -o profile.stats your_script.py</code></li>\n<li>Monitor memory usage with <code>tracemalloc</code> for large dataset experiments</li>\n</ul>\n<h4 id=\"milestone-checkpoint\">Milestone Checkpoint</h4>\n<p>After implementing the foundational understanding from this section:</p>\n<p><strong>Conceptual Verification</strong>:</p>\n<ol>\n<li><strong>Analogy Test</strong>: Explain KNN to someone using the neighborhood recommendation analogy without using technical terms</li>\n<li><strong>Trade-off Understanding</strong>: List 3 scenarios where KNN would outperform logistic regression and 3 where it wouldn&#39;t</li>\n<li><strong>Parameter Intuition</strong>: Predict what happens to decision boundaries as K increases from 1 to 50</li>\n</ol>\n<p><strong>Code Structure Verification</strong>:</p>\n<ol>\n<li><strong>Module Organization</strong>: Verify that the recommended directory structure is created and each module has clear responsibilities</li>\n<li><strong>Type System</strong>: Ensure that <code>data_types.py</code> loads without errors and provides clear type hints</li>\n<li><strong>Data Loading</strong>: Test that synthetic and Iris datasets can be loaded and split properly</li>\n</ol>\n<p><strong>Expected Output</strong> from data loading test:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Run this verification script</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> knn_classifier.utils.data_loader </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> load_iris_dataset, split_and_scale_data</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">X, y </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> load_iris_dataset()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">X_train, X_test, y_train, y_test </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> split_and_scale_data(X, y)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Training set: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">X_train.shape[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> samples, </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">X_train.shape[</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> features\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Test set: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">X_test.shape[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> samples\"</span><span style=\"color:#E1E4E8\">) </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Classes: </span><span style=\"color:#79B8FF\">{set</span><span style=\"color:#E1E4E8\">(y_train)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Feature scaling applied: mean ≈ 0, std ≈ 1\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Sample training point: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">X_train[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p><strong>Signs of Problems</strong>:</p>\n<ul>\n<li><strong>Import Errors</strong>: Missing <code>__init__.py</code> files or incorrect module structure</li>\n<li><strong>Type Errors</strong>: Data types not properly defined or incompatible with NumPy arrays</li>\n<li><strong>Scale Issues</strong>: Features not properly normalized (means far from 0, std far from 1)</li>\n</ul>\n<p>This foundational section establishes the conceptual framework and code structure that will support all subsequent implementation milestones. The neighborhood analogy provides intuitive understanding, the comparison with other methods shows when KNN is appropriate, and the starter code creates a solid foundation for the actual algorithm implementation.</p>\n<h2 id=\"goals-and-non-goals\">Goals and Non-Goals</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Foundational scope definition that guides all three milestones - establishes boundaries for distance calculation (Milestone 1), neighbor finding and classification (Milestone 2), and evaluation improvements (Milestone 3)</p>\n</blockquote>\n<h3 id=\"mental-model-the-recipe-book-approach\">Mental Model: The Recipe Book Approach</h3>\n<p>Think of this design document as creating a recipe book for a neighborhood recommendation system. Just as a cookbook needs to clearly state what dishes it will teach you to make, what kitchen equipment it assumes you have, and what advanced techniques it won&#39;t cover, our KNN system needs explicit boundaries. A good recipe book doesn&#39;t try to teach everything about cooking - it focuses on a specific set of dishes and does them well. Similarly, our KNN implementation will excel at core classification tasks while deliberately excluding advanced features that would complicate the learning experience.</p>\n<p>This goal-setting process is like a chef deciding whether their cookbook will cover basic weeknight dinners or advanced molecular gastronomy. The choice isn&#39;t about which is better, but about what serves the intended audience. For a beginner learning KNN, we want to build a solid foundation with clear, understandable components before considering optimizations that might obscure the underlying principles.</p>\n<h3 id=\"functional-goals-core-classification-capabilities-and-performance-requirements\">Functional Goals: Core Classification Capabilities and Performance Requirements</h3>\n<p>The functional goals define the specific classification capabilities our KNN system must deliver. These represent the concrete behaviors users can expect when interacting with our implementation.</p>\n<p><strong>Primary Classification Functionality</strong></p>\n<p>Our KNN system will provide complete <strong>lazy learning</strong> capabilities, meaning it stores training examples without preprocessing and defers all computation until prediction time. The system will support both single-point predictions and batch predictions over multiple query points. Users will be able to train the classifier by providing feature vectors and corresponding class labels, then make predictions on new, unseen data points.</p>\n<p>The system will implement multiple <strong>distance metrics</strong> to measure similarity between data points. Each metric captures a different notion of similarity - Euclidean distance measures straight-line distance in feature space, Manhattan distance measures city-block distance along feature dimensions, and cosine similarity measures angular similarity regardless of magnitude. This variety allows users to choose the most appropriate similarity measure for their data characteristics.</p>\n<table>\n<thead>\n<tr>\n<th>Distance Metric</th>\n<th>Mathematical Definition</th>\n<th>Use Case</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Euclidean</td>\n<td>sqrt(sum((x_i - y_i)²))</td>\n<td>Continuous features with similar scales</td>\n</tr>\n<tr>\n<td>Manhattan</td>\n<td>sum(abs(x_i - y_i))</td>\n<td>Features with different scales or outliers</td>\n</tr>\n<tr>\n<td>Cosine</td>\n<td>dot(x,y) / (norm(x) * norm(y))</td>\n<td>High-dimensional sparse data</td>\n</tr>\n</tbody></table>\n<p><strong>Neighbor Selection and Voting</strong></p>\n<p>The system will provide flexible <strong>K parameter configuration</strong>, allowing users to specify how many nearest neighbors to consider for each prediction. This parameter fundamentally controls the <strong>bias-variance tradeoff</strong> - smaller K values create more flexible decision boundaries (high variance, low bias) while larger K values create smoother decision boundaries (low variance, high bias).</p>\n<p>Our implementation will support both simple <strong>majority voting</strong> and <strong>weighted voting</strong> strategies. In majority voting, each of the K nearest neighbors contributes one vote for their class label, and the class receiving the most votes becomes the prediction. In weighted voting, closer neighbors receive more influence in the final decision, typically using inverse distance weighting where neighbors at distance d contribute votes proportional to 1/d.</p>\n<table>\n<thead>\n<tr>\n<th>Voting Strategy</th>\n<th>Vote Weight</th>\n<th>Advantage</th>\n<th>Disadvantage</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Majority</td>\n<td>Equal (1.0 per neighbor)</td>\n<td>Simple, interpretable</td>\n<td>Ignores distance information</td>\n</tr>\n<tr>\n<td>Inverse Distance</td>\n<td>1 / distance</td>\n<td>Emphasizes closer neighbors</td>\n<td>Sensitive to very close points</td>\n</tr>\n<tr>\n<td>Inverse Square</td>\n<td>1 / distance²</td>\n<td>Strong distance emphasis</td>\n<td>Unstable with duplicate points</td>\n</tr>\n</tbody></table>\n<p><strong>Performance and Efficiency Requirements</strong></p>\n<p>The system will implement <strong>vectorized operations</strong> using NumPy to avoid Python-level loops during distance calculations. This requirement ensures that distance computation scales efficiently with both the number of training examples and the dimensionality of the feature space. All distance calculations will operate on entire matrices simultaneously rather than iterating through individual data points.</p>\n<p>For datasets with reasonable size (up to 10,000 training examples with up to 100 features), the system will complete training in under 1 second and individual predictions in under 0.1 seconds on standard hardware. These performance targets ensure the implementation remains practical for educational use and small to medium-sized classification problems.</p>\n<p><strong>Data Type Flexibility</strong></p>\n<p>Our KNN classifier will handle both <strong>numeric class labels</strong> (integers) and <strong>string class labels</strong> (categorical names), making it suitable for a wide variety of classification tasks. The system will automatically detect the class label type and handle voting appropriately for both cases.</p>\n<p>The implementation will accept feature data as NumPy arrays, providing compatibility with the broader Python scientific computing ecosystem. Training features will be stored as a <code>FeatureMatrix</code> (2D array where each row represents one training example) while predictions can be made on individual <code>FeatureVector</code> instances (1D arrays) or batches of query points.</p>\n<h3 id=\"non-functional-goals-quality-attributes\">Non-Functional Goals: Quality Attributes</h3>\n<p>Non-functional goals define the quality attributes that make our KNN system maintainable, extensible, and suitable for educational use. These requirements shape how we structure the code and design component interfaces.</p>\n<p><strong>Code Clarity and Educational Value</strong></p>\n<p>The implementation will prioritize <strong>code readability</strong> over micro-optimizations, ensuring that learners can easily understand each component&#39;s purpose and implementation. Every major algorithm will include detailed comments explaining the mathematical concepts and design decisions. Variable names will be descriptive and follow consistent naming conventions throughout the codebase.</p>\n<p>All core algorithms will be implemented as <strong>separate, focused functions</strong> rather than monolithic methods. This modular design allows learners to understand and test individual components in isolation before seeing how they integrate into the complete system. For example, distance calculation, neighbor finding, and voting will each be implemented as distinct modules with well-defined interfaces.</p>\n<blockquote>\n<p><strong>Design Principle</strong>: Each function should do one thing well and have a name that clearly describes its purpose. A function called <code>calculate_euclidean_distance</code> should only compute distance, not also find neighbors or make predictions.</p>\n</blockquote>\n<p><strong>Extensibility and Modularity</strong></p>\n<p>The system architecture will support <strong>easy addition of new distance metrics</strong> through a common interface. Adding a new distance function should require implementing a single method signature without modifying existing code. This extensibility allows learners to experiment with custom distance measures for their specific domains.</p>\n<p>Component interfaces will be designed to support future enhancements like <strong>approximate nearest neighbor algorithms</strong> or <strong>different voting strategies</strong> without requiring major architectural changes. The core <code>KNNClassifier</code> class will delegate to specialized components for distance calculation, neighbor finding, and voting, making it easy to swap implementations.</p>\n<p><strong>Error Handling and Robustness</strong></p>\n<p>The system will implement <strong>comprehensive input validation</strong> with clear, helpful error messages. When users provide invalid parameters (like K larger than the dataset size) or incompatible data shapes (mismatched feature dimensions), the system will detect these issues early and provide specific guidance on how to fix them.</p>\n<p>All mathematical operations will include <strong>numerical stability checks</strong> to handle edge cases like identical data points (zero distance) or empty datasets. The implementation will avoid common pitfalls like taking square roots of negative numbers or dividing by zero in distance calculations.</p>\n<p><strong>Testing and Verification Support</strong></p>\n<p>The codebase will include <strong>comprehensive test coverage</strong> with unit tests for each component and integration tests for end-to-end workflows. Test cases will cover both typical usage patterns and edge cases, providing learners with examples of how to verify their implementations.</p>\n<p>The system will provide <strong>built-in evaluation metrics</strong> including accuracy, precision, recall, and F1-score, along with confusion matrix generation. These tools allow learners to objectively assess their classifier&#39;s performance and understand its strengths and weaknesses on different types of data.</p>\n<h3 id=\"explicit-non-goals-features-excluded-from-this-implementation\">Explicit Non-Goals: Features Excluded from This Implementation</h3>\n<p>Clearly defining what we will NOT implement is crucial for maintaining scope and setting appropriate expectations. These non-goals represent features that, while valuable in production systems, would complicate the learning experience or exceed the project&#39;s educational objectives.</p>\n<p><strong>Advanced Optimization Algorithms</strong></p>\n<p>We will NOT implement <strong>KD-trees, ball trees, or other spatial indexing structures</strong> for accelerating neighbor search. While these algorithms can reduce neighbor finding from O(n) to O(log n) complexity, they introduce significant implementation complexity and can obscure the fundamental KNN concepts. Our implementation will use straightforward linear search, which is easier to understand and debug.</p>\n<p>We will NOT include <strong>approximate nearest neighbor algorithms</strong> like Locality-Sensitive Hashing (LSH) or hierarchical navigable small world graphs. These techniques trade accuracy for speed but require understanding of advanced data structures and probabilistic algorithms that exceed our beginner-level scope.</p>\n<p><strong>Production-Scale Performance Features</strong></p>\n<p>The system will NOT include <strong>distributed or parallel processing</strong> capabilities. All computation will occur on a single machine using single-threaded execution (except for NumPy&#39;s internal vectorization). While distributed KNN is important for large-scale applications, it introduces complexity around data partitioning, communication, and fault tolerance that distracts from core algorithm understanding.</p>\n<p>We will NOT implement <strong>online learning</strong> or <strong>incremental updates</strong> to the training set. Our classifier will follow the traditional batch learning paradigm where training data is fixed after the initial <code>fit</code> operation. Online learning requires additional data structures and algorithms to maintain neighbor relationships as new examples arrive.</p>\n<p><strong>Advanced Distance Metrics and Similarity Measures</strong></p>\n<p>The implementation will NOT include <strong>learned distance metrics</strong> or <strong>adaptive similarity measures</strong> that change based on the training data. While techniques like metric learning can improve KNN performance by learning optimal feature weightings, they require understanding of optimization algorithms and gradient-based learning that exceeds our scope.</p>\n<p>We will NOT support <strong>categorical features</strong> with specialized distance measures like Hamming distance for binary features or Gower&#39;s distance for mixed data types. Our focus remains on continuous numerical features where Euclidean, Manhattan, and cosine distance provide clear, interpretable similarity measures.</p>\n<p><strong>Complex Voting and Prediction Schemes</strong></p>\n<p>The system will NOT implement <strong>probabilistic predictions</strong> or <strong>prediction uncertainty quantification</strong> beyond basic confidence scores based on neighbor agreement. Advanced uncertainty estimation requires statistical modeling techniques that complicate the implementation without adding educational value for beginners.</p>\n<p>We will NOT support <strong>multi-output classification</strong> (predicting multiple labels simultaneously) or <strong>structured prediction</strong> tasks. Our scope focuses on single-label, multi-class classification problems where each example belongs to exactly one class from a predefined set.</p>\n<p><strong>Integration and Deployment Features</strong></p>\n<p>The implementation will NOT include <strong>model serialization</strong> or <strong>persistence</strong> capabilities beyond basic Python pickle support. Production ML systems require sophisticated model versioning and deployment pipelines, but these infrastructure concerns are outside our algorithm-focused scope.</p>\n<p>We will NOT provide <strong>REST APIs, web interfaces, or other service-oriented features</strong>. The system will remain a Python library with programmatic interfaces, allowing learners to focus on the algorithm implementation rather than software engineering concerns around API design and web development.</p>\n<blockquote>\n<p><strong>Architecture Decision: Educational Focus Over Production Readiness</strong></p>\n<ul>\n<li><strong>Context</strong>: Must choose between comprehensive production features and clear educational value</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>Full-featured production system with optimizations, persistence, APIs</li>\n<li>Educational implementation focused on core algorithms</li>\n<li>Hybrid approach with basic optimizations</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Focus purely on educational value with clear, readable implementations</li>\n<li><strong>Rationale</strong>: Beginners learn better with simple, understandable code than with complex optimized systems they cannot comprehend or debug</li>\n<li><strong>Consequences</strong>: Enables deep understanding of fundamental concepts but requires additional work to make production-ready</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Feature Category</th>\n<th>Included</th>\n<th>Excluded</th>\n<th>Rationale</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Distance Metrics</td>\n<td>Euclidean, Manhattan, Cosine</td>\n<td>Learned metrics, specialized categorical distances</td>\n<td>Core metrics sufficient for understanding principles</td>\n</tr>\n<tr>\n<td>Search Algorithms</td>\n<td>Linear search</td>\n<td>KD-trees, approximate search</td>\n<td>Complexity would obscure fundamental concepts</td>\n</tr>\n<tr>\n<td>Voting Strategies</td>\n<td>Majority, inverse distance weighting</td>\n<td>Probabilistic voting, uncertainty quantification</td>\n<td>Simple strategies demonstrate core principles</td>\n</tr>\n<tr>\n<td>Performance</td>\n<td>Vectorized NumPy operations</td>\n<td>Parallel processing, distributed computing</td>\n<td>Educational focus over production optimization</td>\n</tr>\n<tr>\n<td>Data Types</td>\n<td>Numerical features, class labels</td>\n<td>Categorical features, structured outputs</td>\n<td>Simplifies implementation while covering main use cases</td>\n</tr>\n</tbody></table>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>This implementation guidance provides concrete technical recommendations for building a KNN system that achieves the functional and non-functional goals while respecting the explicit boundaries defined above.</p>\n<p><strong>A. Technology Recommendations</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Numerical Computing</td>\n<td>NumPy arrays + pure Python</td>\n<td>NumPy + SciPy + Numba JIT compilation</td>\n</tr>\n<tr>\n<td>Distance Calculation</td>\n<td>NumPy vectorized operations</td>\n<td>SciKit-Learn distance metrics</td>\n</tr>\n<tr>\n<td>Data Loading</td>\n<td>CSV files + pandas</td>\n<td>MLOps pipelines with versioning</td>\n</tr>\n<tr>\n<td>Visualization</td>\n<td>Matplotlib scatter plots</td>\n<td>Interactive Plotly dashboards</td>\n</tr>\n<tr>\n<td>Testing</td>\n<td>Built-in unittest module</td>\n<td>Pytest with fixtures and parameterization</td>\n</tr>\n</tbody></table>\n<p><strong>B. Recommended File/Module Structure</strong></p>\n<p>The following structure organizes code into logical, testable modules that align with our component-based architecture:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>knn-classifier/\n├── src/\n│   ├── __init__.py\n│   ├── data_types.py          ← Core type definitions (FeatureVector, TrainingData, etc.)\n│   ├── distance_metrics.py    ← Distance calculation implementations\n│   ├── neighbor_finder.py     ← K-nearest neighbor search algorithms\n│   ├── classifier.py          ← Main KNNClassifier class and voting logic\n│   ├── evaluation.py          ← Cross-validation and performance metrics\n│   └── utils.py               ← Data loading and preprocessing utilities\n├── tests/\n│   ├── test_distance_metrics.py\n│   ├── test_neighbor_finder.py\n│   ├── test_classifier.py\n│   ├── test_evaluation.py\n│   └── test_integration.py\n├── examples/\n│   ├── iris_classification.py ← Complete example using iris dataset\n│   └── synthetic_data.py      ← Example with generated 2D data for visualization\n└── README.md</code></pre></div>\n\n<p><strong>C. Infrastructure Starter Code</strong></p>\n<p><strong>Core Data Types (Complete Implementation)</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># src/data_types.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Union, Optional, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Type aliases for clarity</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">FeatureVector </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.ndarray  </span><span style=\"color:#6A737D\"># 1D array representing features of a single sample</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">FeatureMatrix </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.ndarray  </span><span style=\"color:#6A737D\"># 2D array where each row is a FeatureVector</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">ClassLabel </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Union[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]  </span><span style=\"color:#6A737D\"># Union type for int or string class labels</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">DistanceArray </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.ndarray  </span><span style=\"color:#6A737D\"># 1D array of distance values</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">NeighborIndices </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.ndarray  </span><span style=\"color:#6A737D\"># 1D array of indices into training data</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DistanceMetric</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Enumeration of supported distance metrics.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    EUCLIDEAN</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"euclidean\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    MANHATTAN</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"manhattan\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    COSINE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"cosine\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TrainingData</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Container for training dataset with metadata.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, features: FeatureMatrix, labels: List[ClassLabel]):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.features </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> features</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.labels </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> labels</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.n_samples </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> features.shape[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.n_features </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> features.shape[</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.unique_classes </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> list</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">set</span><span style=\"color:#E1E4E8\">(labels))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Validation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(labels) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.n_samples:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Feature count </span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.n_samples</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> doesn't match label count </span><span style=\"color:#79B8FF\">{len</span><span style=\"color:#E1E4E8\">(labels)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_sample</span><span style=\"color:#E1E4E8\">(self, index: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Tuple[FeatureVector, ClassLabel]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Retrieve single training example.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> &#x3C;=</span><span style=\"color:#E1E4E8\"> index </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.n_samples:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> IndexError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Sample index </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">index</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> out of range [0, </span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.n_samples</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">)\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.features[index], </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.labels[index]</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> PredictionResult</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Container for prediction with neighbor information and confidence.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, predicted_class: ClassLabel, neighbor_indices: NeighborIndices, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 neighbor_distances: DistanceArray, confidence: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.predicted_class </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> predicted_class</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.neighbor_indices </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> neighbor_indices</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.neighbor_distances </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> neighbor_distances</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.confidence </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> confidence</span></span></code></pre></div>\n\n<p><strong>Data Loading Utilities (Complete Implementation)</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># src/utils.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sklearn.datasets </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> load_iris</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sklearn.model_selection </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> train_test_split</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sklearn.preprocessing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> StandardScaler</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Tuple</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> load_iris_dataset</span><span style=\"color:#E1E4E8\">() -> Tuple[np.ndarray, np.ndarray]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Load classic Iris classification dataset.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    iris </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> load_iris()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> iris.data, iris.target</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> split_and_scale_data</span><span style=\"color:#E1E4E8\">(X: np.ndarray, y: np.ndarray, test_size: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0.2</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        scale_features: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span><span style=\"color:#E1E4E8\">, random_state: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 42</span><span style=\"color:#E1E4E8\">) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Split data into train/test sets and optionally apply feature scaling.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    X_train, X_test, y_train, y_test </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> train_test_split(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        X, y, </span><span style=\"color:#FFAB70\">test_size</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">test_size, </span><span style=\"color:#FFAB70\">random_state</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">random_state, </span><span style=\"color:#FFAB70\">stratify</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">y</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> scale_features:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        scaler </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> StandardScaler()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        X_train </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> scaler.fit_transform(X_train)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        X_test </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> scaler.transform(X_test)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> X_train, X_test, y_train, y_test</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> generate_synthetic_2d_data</span><span style=\"color:#E1E4E8\">(n_samples: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 300</span><span style=\"color:#E1E4E8\">, n_classes: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 3</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                              random_state: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 42</span><span style=\"color:#E1E4E8\">) -> Tuple[np.ndarray, np.ndarray]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Generate 2D synthetic data for visualization and testing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    np.random.seed(random_state)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Create cluster centers</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    centers </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.random.uniform(</span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">, (n_classes, </span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    X </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    y </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    samples_per_class </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> n_samples </span><span style=\"color:#F97583\">//</span><span style=\"color:#E1E4E8\"> n_classes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> class_idx, center </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> enumerate</span><span style=\"color:#E1E4E8\">(centers):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Generate points around each center</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        class_X </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.random.multivariate_normal(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            center, [[</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">], [</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">]], samples_per_class</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        class_y </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [class_idx] </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> samples_per_class</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        X.append(class_X)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        y.extend(class_y)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    X </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.vstack(X)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    y </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.array(y)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Shuffle the data</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    indices </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.random.permutation(</span><span style=\"color:#79B8FF\">len</span><span style=\"color:#E1E4E8\">(X))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> X[indices], y[indices]</span></span></code></pre></div>\n\n<p><strong>D. Core Logic Skeleton Code</strong></p>\n<p><strong>KNN Classifier Main Class (Skeleton for Implementation)</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># src/classifier.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .data_types </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    FeatureMatrix, FeatureVector, ClassLabel, TrainingData, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PredictionResult, DistanceMetric, NeighborIndices, DistanceArray</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> KNNClassifier</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"K-Nearest Neighbors classifier with configurable distance metrics and voting strategies.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 5</span><span style=\"color:#E1E4E8\">, distance_metric: DistanceMetric </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> DistanceMetric.</span><span style=\"color:#79B8FF\">EUCLIDEAN</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 weighted_voting: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> False</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.k </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> k</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.distance_metric </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> distance_metric</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.weighted_voting </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> weighted_voting</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.training_data: Optional[TrainingData] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> fit</span><span style=\"color:#E1E4E8\">(self, X: FeatureMatrix, y: List[ClassLabel]) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Store training data for lazy learning.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate input dimensions and types</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Create TrainingData instance and store in self.training_data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Validate that k is not larger than number of training samples</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: This is lazy learning - no actual computation happens during fit</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> predict</span><span style=\"color:#E1E4E8\">(self, X: FeatureMatrix) -> List[ClassLabel]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Predict class labels for query points.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate that fit has been called (self.training_data is not None)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Handle both single vector and matrix input cases</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: For each query point, call predict_single to get the prediction</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return list of predicted class labels</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use predict_with_confidence internally and extract just the predicted_class</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> predict_with_confidence</span><span style=\"color:#E1E4E8\">(self, X: FeatureMatrix) -> List[PredictionResult]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Predict with neighbor and confidence information.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate inputs and ensure model is fitted</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Convert single vector input to matrix if needed</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: For each query point, find K nearest neighbors</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Apply voting strategy (majority or weighted) to determine prediction</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Calculate confidence based on neighbor agreement</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return PredictionResult objects with all information</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _predict_single</span><span style=\"color:#E1E4E8\">(self, query_point: FeatureVector) -> PredictionResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Predict class for a single query point.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Calculate distances from query point to all training points</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Find indices of K nearest neighbors</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Get class labels of K nearest neighbors</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Apply voting strategy (majority or weighted)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Calculate confidence score</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return PredictionResult with all information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use the distance_metrics module for distance calculations</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>Distance Metrics Module (Skeleton for Implementation)</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># src/distance_metrics.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .data_types </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> FeatureVector, FeatureMatrix, DistanceArray, DistanceMetric</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> calculate_distance</span><span style=\"color:#E1E4E8\">(point1: FeatureVector, point2: FeatureVector, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                      metric: DistanceMetric) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Calculate distance between two points using specified metric.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate that both points have same dimensionality</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Dispatch to appropriate distance function based on metric</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return computed distance value</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: Use a dictionary to map DistanceMetric enum values to functions</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> calculate_distances_vectorized</span><span style=\"color:#E1E4E8\">(query_point: FeatureVector, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                 training_data: FeatureMatrix,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                 metric: DistanceMetric) -> DistanceArray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Calculate distances from query point to all training points efficiently.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate input dimensions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Use vectorized NumPy operations for efficiency</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Handle different distance metrics with appropriate formulas</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return array of distances with same length as training_data rows</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: Avoid Python loops - use NumPy broadcasting for vectorization</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> euclidean_distance</span><span style=\"color:#E1E4E8\">(point1: FeatureVector, point2: FeatureVector) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Compute Euclidean (L2) distance between two points.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Calculate squared differences for each dimension</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Sum the squared differences</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Take square root of the sum</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Handle edge case where points are identical (distance = 0)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: np.sqrt(np.sum((point1 - point2) ** 2))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> manhattan_distance</span><span style=\"color:#E1E4E8\">(point1: FeatureVector, point2: FeatureVector) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Compute Manhattan (L1) distance between two points.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Calculate absolute differences for each dimension</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Sum the absolute differences</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return the sum</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: np.sum(np.abs(point1 - point2))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> cosine_similarity</span><span style=\"color:#E1E4E8\">(point1: FeatureVector, point2: FeatureVector) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Compute cosine similarity between two points (returns distance = 1 - similarity).\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Calculate dot product of the two vectors</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Calculate L2 norms (magnitudes) of both vectors</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Compute cosine similarity = dot_product / (norm1 * norm2)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Convert to distance by returning 1 - similarity</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Handle edge case where one or both vectors have zero norm</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: Use np.dot() and np.linalg.norm()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span></code></pre></div>\n\n<p><strong>E. Language-Specific Hints</strong></p>\n<p><strong>NumPy Optimization Tips:</strong></p>\n<ul>\n<li>Use <code>np.linalg.norm()</code> for efficient vector magnitude calculations</li>\n<li>Leverage NumPy broadcasting to avoid explicit loops when computing distances to multiple points</li>\n<li>Use <code>np.argsort()</code> to find indices of K smallest distances without fully sorting the array</li>\n<li>Apply <code>np.bincount()</code> for efficient majority vote counting when labels are integers</li>\n</ul>\n<p><strong>Error Handling Patterns:</strong></p>\n<ul>\n<li>Always validate array shapes before mathematical operations: <code>assert X.shape[1] == self.training_data.n_features</code></li>\n<li>Check for empty datasets: <code>if self.training_data.n_samples == 0: raise ValueError(&quot;No training data&quot;)</code></li>\n<li>Validate K parameter: <code>if k &gt; self.training_data.n_samples: raise ValueError(f&quot;k={k} larger than dataset size&quot;)</code></li>\n</ul>\n<p><strong>Memory Efficiency:</strong></p>\n<ul>\n<li>For large datasets, consider computing distances in batches rather than storing full distance matrix</li>\n<li>Use <code>dtype=np.float32</code> instead of default <code>np.float64</code> if precision allows for memory savings</li>\n</ul>\n<p><strong>F. Milestone Checkpoints</strong></p>\n<p><strong>After Milestone 1 (Distance Calculation):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test distance calculations</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/test_distance_metrics.py</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Manual verification</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from src.distance_metrics import euclidean_distance, manhattan_distance</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">import numpy as np</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">p1 = np.array([0, 0])</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">p2 = np.array([3, 4])</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">print(f'Euclidean: {euclidean_distance(p1, p2)}')  # Should be 5.0</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">print(f'Manhattan: {manhattan_distance(p1, p2)}')  # Should be 7.0</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span></code></pre></div>\n\n<p><strong>Expected output:</strong> Distance functions return correct mathematical values for simple test cases.</p>\n<p><strong>After Milestone 2 (KNN Classification):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test full classification pipeline</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> examples/iris_classification.py</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected: Accuracy around 95-100% on iris dataset with proper train/test split</span></span></code></pre></div>\n\n<p><strong>After Milestone 3 (Evaluation and Optimization):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test cross-validation and hyperparameter tuning</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from src.evaluation import cross_validate, find_optimal_k</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\"># Should complete without errors and show k-fold results</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span></code></pre></div>\n\n<p><strong>G. Common Implementation Pitfalls</strong></p>\n<table>\n<thead>\n<tr>\n<th>Pitfall</th>\n<th>Symptom</th>\n<th>Cause</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>All predictions same class</td>\n<td>Low accuracy, confusion matrix shows single class</td>\n<td>K too large, using majority of dataset</td>\n<td>Validate K &lt; n_samples/2, try smaller K values</td>\n</tr>\n<tr>\n<td>Slow distance calculation</td>\n<td>Long prediction times</td>\n<td>Using Python loops instead of vectorization</td>\n<td>Replace loops with NumPy broadcasting operations</td>\n</tr>\n<tr>\n<td>NaN in distance calculations</td>\n<td>Runtime errors or infinite distances</td>\n<td>Division by zero in cosine distance</td>\n<td>Add epsilon to denominators, check for zero-norm vectors</td>\n</tr>\n<tr>\n<td>Memory errors on large datasets</td>\n<td>Out of memory crashes</td>\n<td>Computing full distance matrix</td>\n<td>Implement batch processing for distance calculations</td>\n</tr>\n<tr>\n<td>Inconsistent predictions</td>\n<td>Same input gives different outputs</td>\n<td>Non-deterministic tie breaking</td>\n<td>Implement consistent tie-breaking strategy (e.g., smallest index wins)</td>\n</tr>\n</tbody></table>\n<h2 id=\"high-level-architecture\">High-Level Architecture</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Foundational architecture for all milestones - establishes the component structure for distance calculation (Milestone 1), neighbor finding and classification (Milestone 2), and evaluation systems (Milestone 3)</p>\n</blockquote>\n<h3 id=\"mental-model-the-recommendation-system-architecture\">Mental Model: The Recommendation System Architecture</h3>\n<p>Think of the KNN classifier like a sophisticated recommendation system at a bookstore. When a customer asks for book recommendations, the system follows a clear pipeline: first, it measures how similar the customer is to previous customers using various criteria (distance calculation component); then, it finds the most similar customers (neighbor finding component); finally, it looks at what those similar customers liked and makes a recommendation based on their preferences (classification component). An additional evaluation system tracks how well these recommendations work over time and tunes the system for better performance.</p>\n<p>This bookstore analogy maps directly to our KNN architecture: <strong>distance calculation</strong> measures similarity between data points, <strong>neighbor finding</strong> locates the most relevant training examples, <strong>classification</strong> aggregates their labels into predictions, and <strong>evaluation</strong> measures and optimizes system performance. Each component has a distinct responsibility but works together through a carefully orchestrated data flow.</p>\n<p><img src=\"/api/project/knn/architecture-doc/asset?path=diagrams%2Fsystem-components.svg\" alt=\"System Component Architecture\"></p>\n<p>The key architectural insight is that KNN follows the <strong>lazy learning</strong> paradigm - unlike algorithms that build complex models during training, KNN simply stores training data and defers all computation until prediction time. This creates a unique architecture where the &quot;training&quot; component is trivial (just data storage) while the prediction pipeline does all the heavy lifting through distance calculations, neighbor searches, and voting mechanisms.</p>\n<h3 id=\"component-overview\">Component Overview</h3>\n<p>The KNN classifier system consists of four primary components that work together to implement <strong>instance-based learning</strong>. Each component has a focused responsibility and well-defined interfaces that enable clean separation of concerns while supporting the overall classification pipeline.</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Primary Responsibility</th>\n<th>Key Data Inputs</th>\n<th>Key Data Outputs</th>\n<th>Performance Characteristics</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Distance Calculator</strong></td>\n<td>Compute similarity metrics between feature vectors</td>\n<td><code>FeatureVector</code> pairs, <code>DistanceMetric</code> enum</td>\n<td><code>DistanceArray</code>, distance matrices</td>\n<td>O(d) per pair where d = dimensions</td>\n</tr>\n<tr>\n<td><strong>Neighbor Finder</strong></td>\n<td>Locate K most similar training examples</td>\n<td>Query <code>FeatureVector</code>, <code>TrainingData</code>, K parameter</td>\n<td><code>NeighborIndices</code>, <code>DistanceArray</code></td>\n<td>O(n) linear search, O(log n) with spatial indexing</td>\n</tr>\n<tr>\n<td><strong>Classifier</strong></td>\n<td>Make predictions through voting mechanisms</td>\n<td><code>NeighborIndices</code>, neighbor labels, voting strategy</td>\n<td><code>ClassLabel</code>, <code>PredictionResult</code> with confidence</td>\n<td>O(K) for voting, O(C) where C = number of classes</td>\n</tr>\n<tr>\n<td><strong>Evaluator</strong></td>\n<td>Assess model performance and optimize hyperparameters</td>\n<td>Predictions, ground truth labels, cross-validation folds</td>\n<td>Accuracy metrics, confusion matrices, optimal K</td>\n<td>O(F×N) where F = folds, N = samples</td>\n</tr>\n</tbody></table>\n<h4 id=\"distance-calculator-component\">Distance Calculator Component</h4>\n<p>The Distance Calculator serves as the foundation of the entire KNN system by implementing various similarity metrics that quantify how &quot;close&quot; two data points are in feature space. This component embodies the <strong>smoothness assumption</strong> that underlies KNN - the principle that similar inputs should produce similar outputs.</p>\n<p>The component supports multiple distance metrics through a unified interface, allowing the system to adapt to different types of data and problem domains. <strong>Euclidean distance</strong> works well for continuous numerical features, <strong>Manhattan distance</strong> is robust to outliers and effective for high-dimensional sparse data, while <strong>cosine similarity</strong> excels with text and normalized feature vectors where magnitude is less important than direction.</p>\n<p>The architectural challenge here is achieving computational efficiency through <strong>vectorized operations</strong>. Rather than computing distances one pair at a time using Python loops, the component leverages NumPy&#39;s broadcasting capabilities to compute entire distance matrices in single operations. This transforms an O(n²d) nested loop computation into an O(nd) vectorized operation followed by O(n²) element-wise operations that run at C speed.</p>\n<h4 id=\"neighbor-finder-component\">Neighbor Finder Component</h4>\n<p>The Neighbor Finder component takes distance calculations and efficiently locates the K most similar training examples for each query point. This component implements the core search algorithms that determine both the accuracy and performance characteristics of the entire KNN system.</p>\n<p>At its simplest, the component performs linear search through all training examples, computing distances and maintaining a sorted list of the K closest neighbors. However, this O(n) per-query complexity becomes prohibitive for large datasets, motivating more sophisticated spatial indexing approaches like KD-trees that can reduce search complexity to O(log n) in favorable conditions.</p>\n<p>The component must handle several edge cases that frequently trip up implementations: what happens when K is larger than the dataset size, how to break ties when multiple neighbors have identical distances, and how to efficiently maintain the K-nearest list during search without expensive sorting operations. These design decisions significantly impact both correctness and performance.</p>\n<h4 id=\"classifier-component\">Classifier Component</h4>\n<p>The Classifier component implements the democratic decision-making process that transforms a set of neighbor labels into a final prediction. This component embodies the core assumption of KNN that local neighborhoods provide reliable information about class boundaries in feature space.</p>\n<p>The component supports two primary voting strategies. <strong>Majority voting</strong> gives each of the K neighbors an equal voice in the classification decision, essentially implementing a local democracy where the most frequent class wins. <strong>Weighted voting</strong> provides a more nuanced approach where closer neighbors have proportionally more influence on the final decision, implemented through inverse distance weighting or similar schemes.</p>\n<p>Beyond simple classification, this component also computes confidence metrics that indicate how certain the prediction is. A unanimous vote among neighbors indicates high confidence, while a close split suggests the query point lies near a class boundary. This confidence information proves invaluable for understanding model behavior and identifying uncertain predictions that might require human review.</p>\n<h4 id=\"evaluator-component\">Evaluator Component</h4>\n<p>The Evaluator component provides the scientific rigor necessary to assess model performance and optimize hyperparameters. This component implements cross-validation procedures that provide unbiased estimates of generalization performance and systematic hyperparameter optimization that finds the best K value for a given dataset.</p>\n<p>The component&#39;s <strong>K-fold cross-validation</strong> implementation carefully partitions data into training and validation folds while ensuring that each sample appears in exactly one validation fold. This provides robust performance estimates that account for dataset variance and help detect overfitting or underfitting behaviors that might not be apparent from simple train-test splits.</p>\n<p>Hyperparameter optimization within this component addresses the fundamental <strong>bias-variance tradeoff</strong> in KNN models. Small K values create high-variance, low-bias models that can capture fine-grained class boundaries but may overfit to noise. Large K values create low-variance, high-bias models that provide smooth decision boundaries but may underfit complex patterns. The evaluator systematically tests different K values to find the sweet spot for each specific dataset.</p>\n<h3 id=\"recommended-module-structure\">Recommended Module Structure</h3>\n<p>A well-organized module structure helps manage the complexity of the KNN system while providing clear interfaces between components. The structure follows standard Python packaging conventions while grouping related functionality and separating concerns.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>knn_classifier/\n├── __init__.py                     # Package initialization and public API exports\n├── core/\n│   ├── __init__.py\n│   ├── data_types.py              # Core data structures: FeatureVector, TrainingData, etc.\n│   └── enums.py                   # Enumerations: DistanceMetric, VotingStrategy\n├── distance/\n│   ├── __init__.py\n│   ├── base.py                    # Abstract base class for distance metrics\n│   ├── euclidean.py              # Euclidean distance implementation\n│   ├── manhattan.py              # Manhattan distance implementation\n│   └── cosine.py                 # Cosine similarity implementation\n├── neighbors/\n│   ├── __init__.py\n│   ├── base.py                   # Abstract base class for neighbor finders\n│   ├── linear_search.py          # Brute-force linear search implementation\n│   └── spatial_index.py          # KD-tree and advanced indexing (future extension)\n├── classification/\n│   ├── __init__.py\n│   ├── base.py                   # Abstract classifier interface\n│   ├── knn_classifier.py         # Main KNNClassifier implementation\n│   └── voting.py                 # Voting strategy implementations\n├── evaluation/\n│   ├── __init__.py\n│   ├── metrics.py                # Accuracy, precision, recall, F1-score calculations\n│   ├── cross_validation.py       # K-fold cross-validation implementation\n│   └── optimization.py           # Hyperparameter optimization routines\n├── utils/\n│   ├── __init__.py\n│   ├── data_loader.py            # Dataset loading utilities (iris, synthetic data)\n│   └── preprocessing.py          # Feature scaling and preprocessing utilities\n└── examples/\n    ├── basic_classification.py   # Simple KNN usage example\n    ├── cross_validation_demo.py  # Cross-validation and optimization example\n    └── distance_comparison.py    # Comparison of different distance metrics</code></pre></div>\n\n<p>This modular structure provides several key benefits for learners and maintainers. Each module has a single, well-defined responsibility, making it easier to understand, test, and modify individual components. The abstract base classes in each module establish clear contracts that enable easy extension with new distance metrics, search algorithms, or voting strategies.</p>\n<p>The separation between core data types and algorithmic components allows the data structures to evolve independently of the algorithms that use them. This proves particularly valuable when optimizing performance or adding new features that require additional fields in the data structures.</p>\n<blockquote>\n<p><strong>Design Insight</strong>: The module structure mirrors the conceptual architecture, making the codebase intuitive to navigate. Each major component from our architecture diagram corresponds directly to a Python package, and the flow of data between components is reflected in the import dependencies between modules.</p>\n</blockquote>\n<h3 id=\"data-flow-architecture\">Data Flow Architecture</h3>\n<p>The data flow through the KNN system follows a clear pipeline from training data ingestion through final prediction output. Understanding this flow is crucial for implementing each component correctly and optimizing overall system performance.</p>\n<h4 id=\"training-phase-data-flow\">Training Phase Data Flow</h4>\n<p>The training phase in KNN is deceptively simple due to the <strong>lazy learning</strong> nature of the algorithm. Unlike parametric models that extract patterns and parameters during training, KNN simply stores the training data for later use during prediction.</p>\n<table>\n<thead>\n<tr>\n<th>Step</th>\n<th>Component</th>\n<th>Input Data</th>\n<th>Processing</th>\n<th>Output Data</th>\n<th>Storage Location</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>Data Loader</td>\n<td>Raw dataset files</td>\n<td>Parse and validate data format</td>\n<td><code>FeatureMatrix</code>, label array</td>\n<td>Memory</td>\n</tr>\n<tr>\n<td>2</td>\n<td>Preprocessor</td>\n<td><code>FeatureMatrix</code>, labels</td>\n<td>Feature scaling, validation</td>\n<td>Scaled <code>FeatureMatrix</code>, <code>ClassLabel</code> list</td>\n<td>Memory</td>\n</tr>\n<tr>\n<td>3</td>\n<td>KNN Classifier</td>\n<td>Scaled features, labels</td>\n<td>Create <code>TrainingData</code> container</td>\n<td><code>TrainingData</code> object</td>\n<td><code>KNNClassifier.training_data</code></td>\n</tr>\n<tr>\n<td>4</td>\n<td>Distance Calculator</td>\n<td><code>TrainingData</code></td>\n<td>Pre-compute distance matrix (optional)</td>\n<td><code>DistanceMatrix</code></td>\n<td>Cache or disk</td>\n</tr>\n</tbody></table>\n<p>The key insight is that the &quot;training&quot; phase primarily involves data validation and storage rather than complex model fitting. The <code>fit</code> method validates that features and labels have compatible shapes, checks for missing values, stores the training data in an efficient format, and optionally pre-computes distance matrices for performance optimization.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> fit</span><span style=\"color:#E1E4E8\">(X: FeatureMatrix, y: List[ClassLabel]) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Store training data for lazy learning approach.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    This method performs minimal computation since KNN defers</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    all learning until prediction time.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Validation and storage steps - implementation in guidance section</span></span></code></pre></div>\n\n<h4 id=\"prediction-phase-data-flow\">Prediction Phase Data Flow</h4>\n<p>The prediction phase contains the computational heart of the KNN algorithm, where all the distance calculations, neighbor finding, and classification voting occur. This phase demonstrates the true complexity hidden behind KNN&#39;s conceptual simplicity.</p>\n<table>\n<thead>\n<tr>\n<th>Step</th>\n<th>Component</th>\n<th>Input Data</th>\n<th>Processing</th>\n<th>Output Data</th>\n<th>Complexity</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>Query Processing</td>\n<td>Query <code>FeatureMatrix</code></td>\n<td>Validate dimensions, apply same scaling</td>\n<td>Preprocessed queries</td>\n<td>O(Q×D)</td>\n</tr>\n<tr>\n<td>2</td>\n<td>Distance Calculator</td>\n<td>Query point, <code>TrainingData</code></td>\n<td>Compute distances to all training points</td>\n<td><code>DistanceArray</code></td>\n<td>O(Q×N×D)</td>\n</tr>\n<tr>\n<td>3</td>\n<td>Neighbor Finder</td>\n<td><code>DistanceArray</code>, K parameter</td>\n<td>Find K smallest distances and indices</td>\n<td><code>NeighborIndices</code>, neighbor distances</td>\n<td>O(Q×N log K)</td>\n</tr>\n<tr>\n<td>4</td>\n<td>Classifier</td>\n<td><code>NeighborIndices</code>, neighbor labels</td>\n<td>Apply voting strategy</td>\n<td><code>PredictionResult</code></td>\n<td>O(Q×K)</td>\n</tr>\n<tr>\n<td>5</td>\n<td>Output Formatter</td>\n<td><code>PredictionResult</code></td>\n<td>Extract final predictions</td>\n<td><code>List[ClassLabel]</code></td>\n<td>O(Q)</td>\n</tr>\n</tbody></table>\n<p>Where Q = number of query points, N = number of training points, D = number of dimensions, K = number of neighbors.</p>\n<p>The prediction data flow reveals why KNN can be computationally expensive at prediction time. For each query point, the system must compute distances to every training point, sort these distances to find the K nearest neighbors, and then aggregate their labels. This O(Q×N×D) complexity motivates the need for spatial indexing structures in production systems with large training sets.</p>\n<h4 id=\"cross-validation-data-flow\">Cross-Validation Data Flow</h4>\n<p>The evaluation phase implements a more complex data flow that involves systematic partitioning of data and repeated training/validation cycles to provide robust performance estimates.</p>\n<table>\n<thead>\n<tr>\n<th>Phase</th>\n<th>Component</th>\n<th>Input</th>\n<th>Processing</th>\n<th>Output</th>\n<th>Iterations</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Setup</td>\n<td>Cross Validator</td>\n<td>Full dataset, K-folds parameter</td>\n<td>Partition data into K equal folds</td>\n<td>List of (train, validation) splits</td>\n<td>1×K splits</td>\n</tr>\n<tr>\n<td>Training Loop</td>\n<td>KNN Classifier</td>\n<td>Training fold data</td>\n<td>Fit model on training fold</td>\n<td>Trained classifier instance</td>\n<td>K iterations</td>\n</tr>\n<tr>\n<td>Validation Loop</td>\n<td>Prediction Pipeline</td>\n<td>Validation fold, trained model</td>\n<td>Run full prediction pipeline</td>\n<td>Predictions for validation fold</td>\n<td>K iterations</td>\n</tr>\n<tr>\n<td>Metric Calculation</td>\n<td>Evaluator</td>\n<td>Predictions, ground truth labels</td>\n<td>Compute accuracy, precision, recall, F1</td>\n<td>Performance metrics per fold</td>\n<td>K iterations</td>\n</tr>\n<tr>\n<td>Aggregation</td>\n<td>Evaluator</td>\n<td>Metrics from all folds</td>\n<td>Average metrics across folds</td>\n<td>Final performance estimates</td>\n<td>1 aggregation</td>\n</tr>\n</tbody></table>\n<p>This cross-validation flow ensures that every data point appears in exactly one validation fold while being used for training in all other folds. The systematic partitioning provides unbiased performance estimates that generalize better than simple train-test splits.</p>\n<h4 id=\"hyperparameter-optimization-data-flow\">Hyperparameter Optimization Data Flow</h4>\n<p>The most complex data flow occurs during hyperparameter optimization, where cross-validation is repeated for multiple K values to find the optimal configuration.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>For each K in [1, 3, 5, 7, 9, 11, 15, 21, 31]:\n    └── Run complete K-fold cross-validation pipeline\n        ├── Split data into K folds  \n        ├── For each fold:\n        │   ├── Train KNN with current K parameter\n        │   ├── Validate on held-out fold\n        │   └── Record performance metrics\n        └── Average metrics across all folds\nSelect K with highest average validation accuracy</code></pre></div>\n\n<p>This nested loop structure means that hyperparameter optimization has O(H×F×N) complexity where H = number of hyperparameter values tested, F = number of cross-validation folds, and N = cost of training and evaluating each model. Understanding this complexity helps explain why hyperparameter optimization can be time-consuming and motivates careful selection of the hyperparameter search space.</p>\n<blockquote>\n<p><strong>Performance Insight</strong>: The data flow analysis reveals that distance calculation is the primary computational bottleneck in KNN systems. Optimizing this component through vectorized operations, efficient distance metrics, or spatial indexing provides the highest impact on overall system performance.</p>\n</blockquote>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>This section provides concrete implementation guidance to bridge the gap between the architectural design and working code.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n<th>Rationale</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Numerical Computing</td>\n<td>NumPy arrays + basic operations</td>\n<td>NumPy + SciPy sparse matrices</td>\n<td>NumPy sufficient for dense data, SciPy for high-dimensional sparse features</td>\n</tr>\n<tr>\n<td>Distance Computation</td>\n<td>Pure NumPy broadcasting</td>\n<td>scikit-learn distance metrics</td>\n<td>NumPy teaches fundamentals, sklearn optimized for production</td>\n</tr>\n<tr>\n<td>Data Storage</td>\n<td>Python lists/dicts</td>\n<td>pandas DataFrame + HDF5</td>\n<td>Simple structures for learning, pandas for larger datasets</td>\n</tr>\n<tr>\n<td>Spatial Indexing</td>\n<td>Linear search</td>\n<td>scikit-learn BallTree/KDTree</td>\n<td>Linear search for understanding, spatial indexing for performance</td>\n</tr>\n<tr>\n<td>Testing Framework</td>\n<td>pytest</td>\n<td>pytest + hypothesis</td>\n<td>pytest for standard tests, hypothesis for property-based testing</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<p>The following directory structure organizes the KNN implementation into logical modules that mirror the component architecture:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#E1E4E8\">knn_classifier</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">├── </span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">.py                     </span><span style=\"color:#6A737D\"># Public API exports</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">├── core</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   ├── </span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">.py</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   └── data_types.py              </span><span style=\"color:#6A737D\"># FeatureVector, TrainingData, PredictionResult</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">├── distance</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   ├── </span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">.py</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   └── metrics.py                 </span><span style=\"color:#6A737D\"># Distance calculation implementations  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">├── neighbors</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   ├── </span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">.py</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   └── finder.py                  </span><span style=\"color:#6A737D\"># Neighbor search implementations</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">├── classification</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   ├── </span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">.py</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   └── classifier.py              </span><span style=\"color:#6A737D\"># KNNClassifier and voting logic</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">├── evaluation</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   ├── </span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">.py</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   └── validator.py               </span><span style=\"color:#6A737D\"># Cross-validation and metrics</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">└── utils</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ├── </span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">.py</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    └── datasets.py                </span><span style=\"color:#6A737D\"># Data loading utilities</span></span></code></pre></div>\n\n<h4 id=\"core-data-types-complete-implementation\">Core Data Types (Complete Implementation)</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># core/data_types.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Union, List, Tuple, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Type aliases for clarity</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">FeatureVector </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.ndarray  </span><span style=\"color:#6A737D\"># 1D array representing single sample features</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">FeatureMatrix </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.ndarray  </span><span style=\"color:#6A737D\"># 2D array where each row is a FeatureVector</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">ClassLabel </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Union[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]  </span><span style=\"color:#6A737D\"># Flexible label types</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">DistanceArray </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.ndarray  </span><span style=\"color:#6A737D\"># 1D array of distance values</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">NeighborIndices </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.ndarray  </span><span style=\"color:#6A737D\"># 1D array of indices into training data</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DistanceMetric</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Supported distance metrics for KNN classification.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    EUCLIDEAN</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"euclidean\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    MANHATTAN</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"manhattan\"</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    COSINE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"cosine\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TrainingData</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Container for training dataset with metadata.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, features: FeatureMatrix, labels: List[ClassLabel]):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.features </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> features</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.labels </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.array(labels)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.n_samples, </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.n_features </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> features.shape</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.unique_classes </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.unique(labels)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_sample</span><span style=\"color:#E1E4E8\">(self, index: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Tuple[FeatureVector, ClassLabel]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Retrieve a single training example by index.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.features[index], </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.labels[index]</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> PredictionResult</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Comprehensive prediction result with confidence information.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, predicted_class: ClassLabel, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 neighbor_indices: NeighborIndices,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 neighbor_distances: DistanceArray,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 confidence: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.predicted_class </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> predicted_class</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.neighbor_indices </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> neighbor_indices</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.neighbor_distances </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> neighbor_distances</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.confidence </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> confidence</span></span></code></pre></div>\n\n<h4 id=\"knnclassifier-skeleton-core-learning-component\">KNNClassifier Skeleton (Core Learning Component)</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># classification/classifier.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..core.data_types </span><span style=\"color:#F97583\">import</span><span style=\"color:#F97583\"> *</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> KNNClassifier</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"K-Nearest Neighbors classifier implementation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 3</span><span style=\"color:#E1E4E8\">, distance_metric: DistanceMetric </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> DistanceMetric.</span><span style=\"color:#79B8FF\">EUCLIDEAN</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 weighted_voting: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> False</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.k </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> k</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.distance_metric </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> distance_metric</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.weighted_voting </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> weighted_voting</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.training_data: Optional[TrainingData] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> fit</span><span style=\"color:#E1E4E8\">(self, X: FeatureMatrix, y: List[ClassLabel]) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Store training data for lazy learning approach.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate that X and y have compatible shapes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check for missing values or invalid data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Create TrainingData object and store in self.training_data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Validate that k &#x3C;= number of training samples</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: This is lazy learning - no complex model fitting required!</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> predict</span><span style=\"color:#E1E4E8\">(self, X: FeatureMatrix) -> List[ClassLabel]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Predict class labels for query points.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate that model has been fitted (training_data exists)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check that query features have same dimensionality as training</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: For each query point, call predict_with_confidence</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Extract just the predicted_class from each PredictionResult</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return list of predicted class labels</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> predict_with_confidence</span><span style=\"color:#E1E4E8\">(self, X: FeatureMatrix) -> List[PredictionResult]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Predict with detailed neighbor and confidence information.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        results </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> query_point </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> X:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Compute distances from query_point to all training points</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Find indices of K nearest neighbors</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Get the class labels of these K neighbors</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Apply voting strategy (majority or weighted)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Compute confidence score</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Create PredictionResult object</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Add result to results list</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> results</span></span></code></pre></div>\n\n<h4 id=\"distance-calculation-infrastructure-complete-implementation\">Distance Calculation Infrastructure (Complete Implementation)</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># distance/metrics.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..core.data_types </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> FeatureVector, DistanceArray, DistanceMetric</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> euclidean_distance</span><span style=\"color:#E1E4E8\">(point1: FeatureVector, point2: FeatureVector) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Compute Euclidean (L2) distance between two points.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    diff </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> point1 </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> point2</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> np.sqrt(np.sum(diff </span><span style=\"color:#F97583\">**</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> manhattan_distance</span><span style=\"color:#E1E4E8\">(point1: FeatureVector, point2: FeatureVector) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Compute Manhattan (L1) distance between two points.\"\"\"</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    diff </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.abs(point1 </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> point2)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> np.sum(diff)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> cosine_similarity</span><span style=\"color:#E1E4E8\">(point1: FeatureVector, point2: FeatureVector) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Compute cosine similarity (returns 1 - similarity for distance).\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    dot_product </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.dot(point1, point2)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    norm1 </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.linalg.norm(point1)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    norm2 </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.linalg.norm(point2)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> norm1 </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> or</span><span style=\"color:#E1E4E8\"> norm2 </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> 1.0</span><span style=\"color:#6A737D\">  # Maximum distance for zero vectors</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    similarity </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> dot_product </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> (norm1 </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> norm2)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> 1.0</span><span style=\"color:#F97583\"> -</span><span style=\"color:#E1E4E8\"> similarity  </span><span style=\"color:#6A737D\"># Convert similarity to distance</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> compute_distances</span><span style=\"color:#E1E4E8\">(query_point: FeatureVector, training_data: </span><span style=\"color:#9ECBFF\">'TrainingData'</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                     metric: DistanceMetric) -> DistanceArray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Compute distances from query point to all training points using vectorized operations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> metric </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> DistanceMetric.</span><span style=\"color:#79B8FF\">EUCLIDEAN</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Vectorized Euclidean distance computation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        diff </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> training_data.features </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> query_point</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        distances </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.sqrt(np.sum(diff </span><span style=\"color:#F97583\">**</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">axis</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    elif</span><span style=\"color:#E1E4E8\"> metric </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> DistanceMetric.</span><span style=\"color:#79B8FF\">MANHATTAN</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Vectorized Manhattan distance computation  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        diff </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.abs(training_data.features </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> query_point)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        distances </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.sum(diff, </span><span style=\"color:#FFAB70\">axis</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    elif</span><span style=\"color:#E1E4E8\"> metric </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> DistanceMetric.</span><span style=\"color:#79B8FF\">COSINE</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Vectorized cosine distance computation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        dot_products </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.dot(training_data.features, query_point)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        query_norm </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.linalg.norm(query_point)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        training_norms </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.linalg.norm(training_data.features, </span><span style=\"color:#FFAB70\">axis</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Handle zero vectors</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        valid_mask </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (training_norms </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\"> (query_norm </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        similarities </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.zeros(</span><span style=\"color:#79B8FF\">len</span><span style=\"color:#E1E4E8\">(training_data.features))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        similarities[valid_mask] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (dot_products[valid_mask] </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                  (training_norms[valid_mask] </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> query_norm))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        distances </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 1.0</span><span style=\"color:#F97583\"> -</span><span style=\"color:#E1E4E8\"> similarities</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Unsupported distance metric: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">metric</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> distances</span></span></code></pre></div>\n\n<h4 id=\"dataset-utilities-complete-implementation\">Dataset Utilities (Complete Implementation)</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># utils/datasets.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sklearn.datasets </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> load_iris</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sklearn.model_selection </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> train_test_split</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sklearn.preprocessing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> StandardScaler</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Tuple</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> load_iris_dataset</span><span style=\"color:#E1E4E8\">() -> Tuple[np.ndarray, np.ndarray]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Load the classic Iris classification dataset.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    iris </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> load_iris()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> iris.data, iris.target</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> split_and_scale_data</span><span style=\"color:#E1E4E8\">(X: np.ndarray, y: np.ndarray, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        test_size: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0.2</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        scale_features: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        random_state: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 42</span><span style=\"color:#E1E4E8\">) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Split data into train/test sets and optionally apply feature scaling.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    X_train, X_test, y_train, y_test </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> train_test_split(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        X, y, </span><span style=\"color:#FFAB70\">test_size</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">test_size, </span><span style=\"color:#FFAB70\">random_state</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">random_state, </span><span style=\"color:#FFAB70\">stratify</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">y</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> scale_features:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        scaler </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> StandardScaler()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        X_train </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> scaler.fit_transform(X_train)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        X_test </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> scaler.transform(X_test)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> X_train, X_test, y_train, y_test</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p><strong>After Milestone 1 (Distance Calculation):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test basic distance calculation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> knn_classifier.distance.metrics </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> euclidean_distance, manhattan_distance</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">point1 </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.array([</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">3</span><span style=\"color:#E1E4E8\">])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">point2 </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.array([</span><span style=\"color:#79B8FF\">4</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">6</span><span style=\"color:#E1E4E8\">])</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">euclidean </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> euclidean_distance(point1, point2)  </span><span style=\"color:#6A737D\"># Should be ~5.196</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">manhattan </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> manhattan_distance(point1, point2)  </span><span style=\"color:#6A737D\"># Should be 9</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Euclidean: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">euclidean</span><span style=\"color:#F97583\">:.3f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">, Manhattan: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">manhattan</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected output: Euclidean: 5.196, Manhattan: 9</span></span></code></pre></div>\n\n<p><strong>After Milestone 2 (Basic Classification):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test full classification pipeline</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> knn_classifier.utils.datasets </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> load_iris_dataset, split_and_scale_data</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> knn_classifier.classification.classifier </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> KNNClassifier</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">X, y </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> load_iris_dataset()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">X_train, X_test, y_train, y_test </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> split_and_scale_data(X, y)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">knn </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> KNNClassifier(</span><span style=\"color:#FFAB70\">k</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">3</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">knn.fit(X_train, y_train)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">predictions </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> knn.predict(X_test)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">accuracy </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.mean(predictions </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> y_test)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Accuracy: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">accuracy</span><span style=\"color:#F97583\">:.3f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected: Accuracy should be > 0.90 for Iris dataset</span></span></code></pre></div>\n\n<h4 id=\"language-specific-implementation-hints\">Language-Specific Implementation Hints</h4>\n<p><strong>NumPy Performance Tips:</strong></p>\n<ul>\n<li>Use <code>np.sum(axis=1)</code> instead of Python loops for row-wise operations</li>\n<li>Leverage broadcasting: <code>training_data.features - query_point</code> automatically handles shape differences</li>\n<li>Use <code>np.argsort()</code> to get sorted indices without full sorting: <code>np.argsort(distances)[:k]</code></li>\n<li>Pre-allocate arrays when possible: <code>results = np.zeros(len(queries))</code></li>\n</ul>\n<p><strong>Memory Management:</strong></p>\n<ul>\n<li>For large datasets, compute distances in batches to avoid memory issues</li>\n<li>Use <code>dtype=np.float32</code> instead of <code>np.float64</code> if precision allows (50% memory reduction)</li>\n<li>Consider using <code>np.memmap</code> for datasets larger than available RAM</li>\n</ul>\n<p><strong>Common Python Gotchas:</strong></p>\n<ul>\n<li>Always use <code>np.array()</code> to convert lists to NumPy arrays before mathematical operations</li>\n<li>Check array shapes with <code>.shape</code> when debugging unexpected broadcasting errors</li>\n<li>Use <code>np.allclose()</code> for floating-point comparisons instead of <code>==</code></li>\n</ul>\n<h2 id=\"data-model\">Data Model</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Core data representation for all milestones - defines feature vectors and training data for distance calculation (Milestone 1), neighbor indices and distance arrays for KNN classification (Milestone 2), and prediction results with confidence scores for evaluation and optimization (Milestone 3)</p>\n</blockquote>\n<h3 id=\"mental-model-the-filing-cabinet-system\">Mental Model: The Filing Cabinet System</h3>\n<p>Think of the KNN data model as a sophisticated filing cabinet system in a library&#39;s recommendation service. Each book (training sample) has a <strong>feature card</strong> (<code>FeatureVector</code>) listing its characteristics - genre ratings, page count, complexity score, etc. The entire collection of feature cards forms the <strong>master catalog</strong> (<code>FeatureMatrix</code>), while each book also has a <strong>category label</strong> (<code>ClassLabel</code>) like &quot;mystery&quot;, &quot;romance&quot;, or &quot;science fiction&quot;.</p>\n<p>When someone asks for a recommendation, the librarian doesn&#39;t reorganize the entire collection or build complex models. Instead, they maintain a <strong>distance ledger</strong> (<code>DistanceArray</code>) showing how similar the requested book is to every book in the collection. They then create a <strong>recommendation list</strong> (<code>NeighborIndices</code>) of the closest matches and deliver a <strong>final recommendation</strong> (<code>PredictionResult</code>) that includes not just the suggested category, but also which specific books influenced the decision and how confident they are in the recommendation.</p>\n<p>This lazy learning approach means the filing cabinet stores everything exactly as received, deferring all computation until someone actually needs a recommendation. The data structures must efficiently support this deferred computation while maintaining the relationships between features, distances, neighbors, and predictions.</p>\n<h3 id=\"core-data-types\">Core Data Types</h3>\n<p>The foundation of our KNN classifier rests on five core data types that represent the essential mathematical concepts of instance-based learning. These types must efficiently support vectorized operations while maintaining type safety and clear semantic meaning.</p>\n<p><img src=\"/api/project/knn/architecture-doc/asset?path=diagrams%2Fdata-model.svg\" alt=\"Data Model Relationships\"></p>\n<p>A <code>FeatureVector</code> represents a single sample&#39;s characteristics as a one-dimensional NumPy array of floating-point values. Each position in the vector corresponds to a specific feature dimension - for example, in the classic Iris dataset, positions 0-3 might represent sepal length, sepal width, petal length, and petal width respectively. The vector must maintain consistent dimensionality across all samples to ensure meaningful distance calculations.</p>\n<p>The <code>FeatureMatrix</code> extends this concept to represent an entire dataset as a two-dimensional NumPy array where each row is a <code>FeatureVector</code>. This row-major organization aligns with NumPy&#39;s memory layout and enables efficient vectorized operations across samples. The matrix shape (n_samples, n_features) provides immediate access to dataset dimensions without separate tracking variables.</p>\n<p>A <code>ClassLabel</code> uses Python&#39;s Union typing to support both integer and string class identifiers, accommodating datasets with numeric labels (0, 1, 2) and categorical labels (&quot;setosa&quot;, &quot;versicolor&quot;, &quot;virginica&quot;). This flexibility allows the same classifier to work with diverse datasets without preprocessing label formats.</p>\n<p>Distance calculations produce a <code>DistanceArray</code> - a one-dimensional NumPy array containing floating-point distance values between a query point and all training samples. The array maintains the same ordering as the training data, enabling direct indexing from distances back to the corresponding training samples.</p>\n<p>The <code>NeighborIndices</code> array stores integer indices that reference specific rows in the training data. After computing distances and finding the K nearest neighbors, this array contains the row indices of the selected neighbors in order of increasing distance. These indices serve as the bridge between distance calculations and the actual training samples needed for classification voting.</p>\n<table>\n<thead>\n<tr>\n<th>Type</th>\n<th>Base Type</th>\n<th>Shape/Format</th>\n<th>Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>FeatureVector</code></td>\n<td>np.ndarray(dtype=float64)</td>\n<td>(n_features,)</td>\n<td>Single sample&#39;s feature values</td>\n</tr>\n<tr>\n<td><code>FeatureMatrix</code></td>\n<td>np.ndarray(dtype=float64)</td>\n<td>(n_samples, n_features)</td>\n<td>Complete dataset feature matrix</td>\n</tr>\n<tr>\n<td><code>ClassLabel</code></td>\n<td>Union[int, str]</td>\n<td>Scalar value</td>\n<td>Class identifier for training/prediction</td>\n</tr>\n<tr>\n<td><code>DistanceArray</code></td>\n<td>np.ndarray(dtype=float64)</td>\n<td>(n_distances,)</td>\n<td>Distance values from query to training samples</td>\n</tr>\n<tr>\n<td><code>NeighborIndices</code></td>\n<td>np.ndarray(dtype=int32)</td>\n<td>(k,)</td>\n<td>Indices of K nearest training samples</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Design Insight</strong>: The choice of float64 for all numeric arrays prevents precision loss during distance calculations, especially important for euclidean distance where we sum squared differences that could quickly overflow float32 precision. Integer indices use int32 to support datasets up to 2 billion samples while maintaining memory efficiency.</p>\n</blockquote>\n<h3 id=\"internal-data-structures\">Internal Data Structures</h3>\n<p>The KNN classifier requires three sophisticated internal data structures that manage the complete lifecycle from training data storage through prediction result delivery. These structures encapsulate not just raw data but also derived metadata that accelerates common operations.</p>\n<p>The <code>TrainingData</code> container serves as the central repository for all information about the training dataset. Beyond storing the feature matrix and corresponding labels, it maintains derived metadata including the number of samples, number of features, and the set of unique classes present in the training data. This metadata enables immediate validation of query dimensions and provides the class universe for voting operations.</p>\n<p>The training data container must support efficient random access to individual samples through the <code>get_sample</code> method while maintaining memory efficiency for large datasets. It also tracks data consistency - ensuring that the number of feature vectors exactly matches the number of labels and that all feature vectors have identical dimensionality.</p>\n<p>A <code>PredictionResult</code> represents the complete output of the KNN classification process for a single query point. Unlike simple classification algorithms that return only a class label, KNN predictions include rich context about how the decision was made. The predicted class comes from the voting process, while the neighbor indices and distances provide full transparency into which training samples influenced the decision and how strongly.</p>\n<p>The confidence score quantifies the algorithm&#39;s certainty in the prediction, typically calculated as the proportion of neighbors that voted for the winning class. For weighted voting, confidence incorporates the distance-based weights to provide a more nuanced measure of prediction reliability.</p>\n<p>The <code>KNNClassifier</code> itself serves as the primary data structure coordinating all other components. It encapsulates the hyperparameters (K value, distance metric, voting strategy) alongside the training data, providing a complete specification of the classifier&#39;s behavior. The lazy learning nature means the classifier stores training data without modification, deferring all computation until prediction time.</p>\n<table>\n<thead>\n<tr>\n<th>Structure</th>\n<th>Fields</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>TrainingData</code></td>\n<td>features</td>\n<td>FeatureMatrix</td>\n<td>Complete training feature matrix</td>\n</tr>\n<tr>\n<td></td>\n<td>labels</td>\n<td>List[ClassLabel]</td>\n<td>Corresponding class labels</td>\n</tr>\n<tr>\n<td></td>\n<td>n_samples</td>\n<td>int</td>\n<td>Number of training samples</td>\n</tr>\n<tr>\n<td></td>\n<td>n_features</td>\n<td>int</td>\n<td>Number of feature dimensions</td>\n</tr>\n<tr>\n<td></td>\n<td>unique_classes</td>\n<td>Set[ClassLabel]</td>\n<td>Set of all possible class values</td>\n</tr>\n<tr>\n<td><code>PredictionResult</code></td>\n<td>predicted_class</td>\n<td>ClassLabel</td>\n<td>Final classification decision</td>\n</tr>\n<tr>\n<td></td>\n<td>neighbor_indices</td>\n<td>NeighborIndices</td>\n<td>Indices of K nearest training samples</td>\n</tr>\n<tr>\n<td></td>\n<td>neighbor_distances</td>\n<td>DistanceArray</td>\n<td>Distances to each of the K neighbors</td>\n</tr>\n<tr>\n<td></td>\n<td>confidence</td>\n<td>float</td>\n<td>Prediction confidence score (0.0 to 1.0)</td>\n</tr>\n<tr>\n<td><code>KNNClassifier</code></td>\n<td>k</td>\n<td>int</td>\n<td>Number of neighbors for classification</td>\n</tr>\n<tr>\n<td></td>\n<td>distance_metric</td>\n<td>DistanceMetric</td>\n<td>Distance function (EUCLIDEAN/MANHATTAN/COSINE)</td>\n</tr>\n<tr>\n<td></td>\n<td>weighted_voting</td>\n<td>bool</td>\n<td>Whether to use distance-weighted voting</td>\n</tr>\n<tr>\n<td></td>\n<td>training_data</td>\n<td>Optional[TrainingData]</td>\n<td>Stored training dataset (None before fitting)</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Architecture Decision: Separate Training Data Container</strong></p>\n<ul>\n<li><strong>Context</strong>: We could store training features and labels directly in the classifier or create a separate container</li>\n<li><strong>Options Considered</strong>: Direct storage, separate TrainingData class, external data manager</li>\n<li><strong>Decision</strong>: Separate TrainingData container class</li>\n<li><strong>Rationale</strong>: Encapsulates data validation, provides clean interface for sample access, enables future optimizations like data preprocessing or indexing without changing classifier interface</li>\n<li><strong>Consequences</strong>: Adds one additional class but significantly improves code organization and enables better testing of data management logic separately from classification logic</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Design Option</th>\n<th>Pros</th>\n<th>Cons</th>\n<th>Chosen?</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Direct storage in classifier</td>\n<td>Simple, fewer classes</td>\n<td>Mixing concerns, harder to test</td>\n<td>No</td>\n</tr>\n<tr>\n<td>Separate TrainingData container</td>\n<td>Clean separation, testable, extensible</td>\n<td>Additional complexity</td>\n<td><strong>Yes</strong></td>\n</tr>\n<tr>\n<td>External data manager</td>\n<td>Maximum flexibility</td>\n<td>Over-engineering for basic KNN</td>\n<td>No</td>\n</tr>\n</tbody></table>\n<h3 id=\"type-relationships-and-data-flow\">Type Relationships and Data Flow</h3>\n<p>The KNN data model creates a sophisticated pipeline where each type transforms into the next through well-defined operations, supporting the fundamental lazy learning paradigm. Understanding these relationships is crucial for implementing correct and efficient KNN classification.</p>\n<p>The transformation pipeline begins with raw training data entering as separate <code>FeatureMatrix</code> and label arrays through the <code>fit</code> method. The classifier immediately packages these into a <code>TrainingData</code> container, performing validation to ensure dimensional consistency and extracting metadata like unique classes and sample counts. This containerization provides a clean interface for all subsequent operations while encapsulating data integrity checks.</p>\n<p>During prediction, query points arrive as a <code>FeatureMatrix</code> where each row represents a sample to classify. The distance calculation component transforms each query <code>FeatureVector</code> and the entire training <code>FeatureMatrix</code> into a <code>DistanceArray</code> containing distances from the query to every training sample. This transformation is the computational heart of KNN, requiring efficient vectorized operations to avoid performance bottlenecks.</p>\n<p>The neighbor finding component then transforms the <code>DistanceArray</code> into <code>NeighborIndices</code> by identifying the K smallest distances and extracting their corresponding array positions. This transformation requires careful handling of ties and edge cases where K exceeds the number of available training samples. The resulting indices serve as references back into the training data for the voting phase.</p>\n<p>Classification voting transforms the <code>NeighborIndices</code> into a <code>PredictionResult</code> by retrieving the corresponding class labels from the training data and applying either majority voting or weighted voting algorithms. This transformation produces not just the predicted class but also rich metadata about the decision process, including confidence scores and the complete neighbor information.</p>\n<p>The type relationships embody important mathematical properties of the KNN algorithm. Distance calculations preserve the smoothness assumption - similar feature vectors produce similar distance values. The neighbor finding process maintains locality - the K nearest neighbors form a local neighborhood around the query point. The voting process implements the democratic principle - the local neighborhood determines the classification through collective decision-making.</p>\n<table>\n<thead>\n<tr>\n<th>Transformation</th>\n<th>Input Types</th>\n<th>Output Type</th>\n<th>Operation</th>\n<th>Key Properties</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Training</td>\n<td>FeatureMatrix, List[ClassLabel]</td>\n<td>TrainingData</td>\n<td>Data validation and packaging</td>\n<td>Lazy storage, no preprocessing</td>\n</tr>\n<tr>\n<td>Distance Calculation</td>\n<td>FeatureVector, TrainingData</td>\n<td>DistanceArray</td>\n<td>Vectorized distance computation</td>\n<td>Preserves similarity relationships</td>\n</tr>\n<tr>\n<td>Neighbor Finding</td>\n<td>DistanceArray</td>\n<td>NeighborIndices</td>\n<td>K-smallest selection with indexing</td>\n<td>Maintains locality properties</td>\n</tr>\n<tr>\n<td>Classification</td>\n<td>NeighborIndices, TrainingData</td>\n<td>PredictionResult</td>\n<td>Voting with confidence calculation</td>\n<td>Democratic decision making</td>\n</tr>\n<tr>\n<td>Batch Prediction</td>\n<td>FeatureMatrix</td>\n<td>List[PredictionResult]</td>\n<td>Repeated single predictions</td>\n<td>Parallel processing opportunity</td>\n</tr>\n</tbody></table>\n<p>The data flow architecture supports both single predictions and batch processing efficiently. Single predictions flow linearly through each transformation stage, while batch predictions can leverage vectorized operations and parallel processing where the distance calculations for multiple query points can proceed independently.</p>\n<p>Memory management considerations influence the type relationships significantly. The <code>TrainingData</code> persists throughout the classifier&#39;s lifetime, while <code>DistanceArray</code> and intermediate calculations exist only during prediction operations. This pattern minimizes memory overhead while supporting efficient computation.</p>\n<blockquote>\n<p><strong>Design Insight</strong>: The type transformation pipeline mirrors the mathematical structure of KNN classification - from high-dimensional feature spaces through distance metrics to discrete classification decisions. Each transformation preserves essential properties while reducing complexity for the next stage.</p>\n</blockquote>\n<h3 id=\"data-validation-and-consistency\">Data Validation and Consistency</h3>\n<p>The data model must enforce strict consistency rules to prevent subtle bugs that could compromise classification accuracy. These validation rules operate at multiple levels - from individual type construction through complete pipeline validation.</p>\n<p><code>FeatureVector</code> validation ensures that all values are finite floating-point numbers, rejecting NaN or infinite values that would corrupt distance calculations. The vector must also maintain consistent dimensionality with the training data&#39;s feature space. Dimension mismatches between query and training features represent fundamental incompatibility that must be caught immediately.</p>\n<p><code>FeatureMatrix</code> validation extends vector-level checks to ensure that all rows have identical dimensionality and that the matrix contains at least one sample. Empty feature matrices would cause division-by-zero errors in distance calculations and make classification impossible. The validation also verifies that the number of features matches the classifier&#39;s expectations from training.</p>\n<p><code>ClassLabel</code> validation ensures that predicted labels belong to the set of classes seen during training. While KNN can theoretically encounter completely novel classes through its neighbors, the training data defines the universe of possible predictions. Labels outside this universe indicate either data corruption or fundamental dataset inconsistencies.</p>\n<p>Distance calculations require additional validation to prevent numerical instabilities. <code>DistanceArray</code> validation ensures that all distances are non-negative finite values. Negative distances violate mathematical properties of distance metrics, while infinite distances indicate computational overflow or invalid input data.</p>\n<p>The <code>TrainingData</code> container enforces the most critical consistency requirements - that the number of feature vectors exactly equals the number of labels, that all feature vectors have identical dimensionality, and that at least one sample exists for each claimed unique class. These invariants must be established at construction time and maintained throughout the object&#39;s lifetime.</p>\n<table>\n<thead>\n<tr>\n<th>Validation Rule</th>\n<th>Checked At</th>\n<th>Failure Consequence</th>\n<th>Recovery Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Feature vectors finite</td>\n<td>Input processing</td>\n<td>Invalid distance calculations</td>\n<td>Reject input with clear error</td>\n</tr>\n<tr>\n<td>Consistent dimensionality</td>\n<td>Prediction time</td>\n<td>Runtime dimension mismatch</td>\n<td>Validate against training data</td>\n</tr>\n<tr>\n<td>Non-empty datasets</td>\n<td>Training time</td>\n<td>Division by zero, no neighbors</td>\n<td>Require minimum sample count</td>\n</tr>\n<tr>\n<td>Label consistency</td>\n<td>Result validation</td>\n<td>Invalid predictions</td>\n<td>Restrict to training label universe</td>\n</tr>\n<tr>\n<td>Non-negative distances</td>\n<td>Distance calculation</td>\n<td>Corrupted neighbor selection</td>\n<td>Numerical stability checks</td>\n</tr>\n</tbody></table>\n<h3 id=\"common-data-model-pitfalls\">Common Data Model Pitfalls</h3>\n<p>Understanding the most frequent mistakes in KNN data model implementation helps prevent subtle bugs that can be extremely difficult to diagnose. These pitfalls often manifest as degraded accuracy rather than obvious crashes, making them particularly insidious.</p>\n<p>⚠️ <strong>Pitfall: Mixed Feature Scaling</strong>\nMany datasets contain features with vastly different scales - for example, age in years (0-100) and income in dollars (0-100,000). Without proper scaling, distance calculations become dominated by the high-magnitude features, effectively ignoring low-magnitude but potentially important features. The euclidean distance between points (25, 50000) and (30, 55000) is approximately 5000, entirely dominated by the income difference despite the age difference being proportionally significant. Always normalize features to similar scales before training, typically using standardization (zero mean, unit variance) or min-max scaling to [0,1] range.</p>\n<p>⚠️ <strong>Pitfall: Integer Feature Precision</strong>\nStoring feature data as integers instead of floating-point values creates precision loss during distance calculations that can alter neighbor rankings. Integer arithmetic cannot represent the fractional results of normalization or the intermediate calculations in distance metrics. Even if input features are integers, convert them to float64 arrays immediately to ensure numerical accuracy throughout the pipeline.</p>\n<p>⚠️ <strong>Pitfall: Inconsistent Missing Value Handling</strong>\nKNN algorithms cannot directly handle missing feature values since distance calculations require complete vectors. Inconsistent handling of missing values - sometimes dropping samples, sometimes imputing with zeros, sometimes using mean values - creates subtle dataset inconsistencies that degrade classification performance. Establish a consistent missing value strategy during data preprocessing and apply it uniformly to both training and query data.</p>\n<p>⚠️ <strong>Pitfall: Memory Layout Inefficiency</strong>\nNumPy arrays can have different memory layouts (C-contiguous vs Fortran-contiguous) that dramatically affect performance of vectorized operations. Feature matrices stored in Fortran layout force NumPy to perform expensive memory copying during row-wise distance calculations. Always ensure feature matrices use C-contiguous layout with <code>np.ascontiguousarray()</code> to enable efficient vectorized distance computations.</p>\n<p>⚠️ <strong>Pitfall: Label Type Inconsistency</strong>\nMixing different label types within the same dataset - some samples with integer labels, others with string labels - creates type confusion during prediction result construction. Python&#39;s dynamic typing allows this inconsistency to propagate deep into the classification pipeline before causing errors. Establish consistent label typing during training data construction and validate that all labels conform to the expected type.</p>\n<p>⚠️ <strong>Pitfall: Neighbor Index Out-of-Bounds</strong>\nWhen K exceeds the number of training samples, neighbor finding algorithms can generate invalid indices or return insufficient neighbors for voting. This edge case particularly affects small datasets or datasets with severe class imbalance where one class has fewer than K samples. Always validate that K is less than or equal to the total number of training samples and handle edge cases gracefully by reducing K or weighted voting by available neighbors.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The data model implementation requires careful attention to NumPy array management, type safety, and memory efficiency. These recommendations provide a solid foundation for building reliable KNN classifiers.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Array Operations</td>\n<td>NumPy with basic indexing</td>\n<td>NumPy with advanced indexing + scipy.spatial</td>\n</tr>\n<tr>\n<td>Type Checking</td>\n<td>Python type hints + runtime checks</td>\n<td>mypy static analysis + pydantic validation</td>\n</tr>\n<tr>\n<td>Memory Management</td>\n<td>Standard NumPy arrays</td>\n<td>Memory-mapped arrays for large datasets</td>\n</tr>\n<tr>\n<td>Serialization</td>\n<td>pickle for simple persistence</td>\n<td>joblib for efficient numerical array storage</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<p>Organize the data model components into logical modules that separate concerns and enable clear testing:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>knn_classifier/\n  core/\n    data_types.py           ← Core type definitions and containers\n    validation.py           ← Data validation functions and error classes\n  datasets/\n    loaders.py             ← Dataset loading utilities (Iris, etc.)\n    preprocessing.py        ← Feature scaling and preprocessing\n  tests/\n    test_data_types.py     ← Unit tests for core data structures\n    test_validation.py     ← Validation logic tests\n    test_datasets.py       ← Dataset loading tests</code></pre></div>\n\n<h4 id=\"core-data-types-implementation\">Core Data Types Implementation</h4>\n<p>Here&#39;s the complete implementation of the core data types that forms the foundation of your KNN classifier:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Core data types for KNN classification.</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">This module defines the fundamental data structures used throughout the KNN</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">classifier implementation, providing type safety and efficient operations.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Union, List, Optional, Tuple, Set</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Type aliases for clarity and consistency</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">FeatureVector </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.ndarray  </span><span style=\"color:#6A737D\"># Shape: (n_features,)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">FeatureMatrix </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.ndarray  </span><span style=\"color:#6A737D\"># Shape: (n_samples, n_features)  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">ClassLabel </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Union[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">DistanceArray </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.ndarray  </span><span style=\"color:#6A737D\"># Shape: (n_distances,)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">NeighborIndices </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.ndarray  </span><span style=\"color:#6A737D\"># Shape: (k,)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DistanceMetric</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Supported distance metrics for KNN classification.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    EUCLIDEAN</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"euclidean\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    MANHATTAN</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"manhattan\"</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    COSINE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"cosine\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TrainingData</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Container for training dataset with derived metadata.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    features: FeatureMatrix</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    labels: List[ClassLabel]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    n_samples: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    n_features: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    unique_classes: Set[ClassLabel]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __post_init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate data consistency after construction.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.labels) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.n_samples:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Label count </span><span style=\"color:#79B8FF\">{len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.labels)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> != sample count </span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.n_samples</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.features.shape </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.n_samples, </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.n_features):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Feature shape </span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.features.shape</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> inconsistent with metadata\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Ensure features are float64 and C-contiguous for efficiency</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.features </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.ascontiguousarray(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.features, </span><span style=\"color:#FFAB70\">dtype</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">np.float64)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Validate that all features are finite</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> np.all(np.isfinite(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.features)):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Training features contain NaN or infinite values\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_sample</span><span style=\"color:#E1E4E8\">(self, index: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Tuple[FeatureVector, ClassLabel]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Retrieve a single training sample by index.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> &#x3C;=</span><span style=\"color:#E1E4E8\"> index </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.n_samples:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> IndexError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Sample index </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">index</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> out of range [0, </span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.n_samples</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">)\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.features[index], </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.labels[index]</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> PredictionResult</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Complete prediction result with neighbor information and confidence.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    predicted_class: ClassLabel</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    neighbor_indices: NeighborIndices</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    neighbor_distances: DistanceArray</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    confidence: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __post_init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate prediction result consistency.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.neighbor_indices) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.neighbor_distances):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Neighbor indices and distances must have same length\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> 0.0</span><span style=\"color:#F97583\"> &#x3C;=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.confidence </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 1.0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Confidence </span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.confidence</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> must be in range [0.0, 1.0]\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> np.all(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.neighbor_distances </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Neighbor distances must be non-negative\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> KNNClassifier</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Main KNN classifier with configurable parameters and training data.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 3</span><span style=\"color:#E1E4E8\">, distance_metric: DistanceMetric </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> DistanceMetric.</span><span style=\"color:#79B8FF\">EUCLIDEAN</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 weighted_voting: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> False</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Initialize KNN classifier with hyperparameters.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> k </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"K must be positive, got </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">k</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.k </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> k</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.distance_metric </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> distance_metric  </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.weighted_voting </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> weighted_voting</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.training_data: Optional[TrainingData] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> fit</span><span style=\"color:#E1E4E8\">(self, X: FeatureMatrix, y: List[ClassLabel]) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Store training data for lazy learning.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate input dimensions and types</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Create TrainingData container with metadata extraction  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Store training data for prediction time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> predict</span><span style=\"color:#E1E4E8\">(self, X: FeatureMatrix) -> List[ClassLabel]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Predict class labels for query points.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate that classifier has been fitted</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate query data dimensions match training data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: For each query point, compute distances to all training samples</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Find K nearest neighbors for each query</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Apply voting strategy to determine predicted class</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return list of predicted labels</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> predict_with_confidence</span><span style=\"color:#E1E4E8\">(self, X: FeatureMatrix) -> List[PredictionResult]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Predict with full neighbor and confidence information.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Perform same steps as predict() but return complete PredictionResult</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate confidence scores based on voting margins</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Include neighbor indices and distances in results</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> create_training_data</span><span style=\"color:#E1E4E8\">(X: FeatureMatrix, y: List[ClassLabel]) -> TrainingData:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Factory function to create validated TrainingData container.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    X </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.asarray(X, </span><span style=\"color:#FFAB70\">dtype</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">np.float64)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> X.ndim </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Feature matrix must be 2D, got shape </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">X.shape</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    n_samples, n_features </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> X.shape</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    unique_classes </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> set</span><span style=\"color:#E1E4E8\">(y)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> TrainingData(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        features</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">X,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        labels</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">y,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        n_samples</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">n_samples, </span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        n_features</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">n_features,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        unique_classes</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">unique_classes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    )</span></span></code></pre></div>\n\n<h4 id=\"dataset-loading-utilities\">Dataset Loading Utilities</h4>\n<p>Complete utilities for loading and preprocessing standard datasets:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Dataset loading and preprocessing utilities for KNN classification.</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Provides standardized interfaces for loading common datasets with proper</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">feature scaling and train/test splitting.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sklearn </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datasets</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sklearn.model_selection </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> train_test_split</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sklearn.preprocessing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> StandardScaler, MinMaxScaler</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Tuple, Optional</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> load_iris_dataset</span><span style=\"color:#E1E4E8\">() -> Tuple[np.ndarray, np.ndarray]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Load the classic Iris classification dataset.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    iris </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> datasets.load_iris()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> iris.data.astype(np.float64), iris.target</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> load_wine_dataset</span><span style=\"color:#E1E4E8\">() -> Tuple[np.ndarray, np.ndarray]:  </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Load the Wine classification dataset.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    wine </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> datasets.load_wine()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> wine.data.astype(np.float64), wine.target</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> split_and_scale_data</span><span style=\"color:#E1E4E8\">(X: np.ndarray, y: np.ndarray, test_size: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0.2</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        scale_features: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span><span style=\"color:#E1E4E8\">, random_state: Optional[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Split dataset and optionally apply feature scaling.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    X_train, X_test, y_train, y_test </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> train_test_split(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        X, y, </span><span style=\"color:#FFAB70\">test_size</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">test_size, </span><span style=\"color:#FFAB70\">random_state</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">random_state, </span><span style=\"color:#FFAB70\">stratify</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">y</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> scale_features:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        scaler </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> StandardScaler()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        X_train </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> scaler.fit_transform(X_train)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        X_test </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> scaler.transform(X_test)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> X_train, X_test, y_train, y_test</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> validate_feature_consistency</span><span style=\"color:#E1E4E8\">(X_train: np.ndarray, X_test: np.ndarray) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Validate that training and test data have consistent feature dimensions.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> X_train.shape[</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> X_test.shape[</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Feature dimension mismatch: train=</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">X_train.shape[</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">, test=</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">X_test.shape[</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> np.all(np.isfinite(X_train)) </span><span style=\"color:#F97583\">or</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> np.all(np.isfinite(X_test)):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Feature data contains NaN or infinite values\"</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p><strong>Checkpoint 1: Basic Data Type Creation</strong>\nAfter implementing the core data types, verify correct construction and validation:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test basic type creation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">X </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.array([[</span><span style=\"color:#79B8FF\">1.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">2.0</span><span style=\"color:#E1E4E8\">], [</span><span style=\"color:#79B8FF\">3.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">4.0</span><span style=\"color:#E1E4E8\">], [</span><span style=\"color:#79B8FF\">5.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">6.0</span><span style=\"color:#E1E4E8\">]])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">y </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span><span style=\"color:#9ECBFF\">'A'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'B'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'A'</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">training_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> create_training_data(X, y)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Created training data: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">training_data.n_samples</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> samples, </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">training_data.n_features</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> features\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Unique classes: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">training_data.unique_classes</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test sample retrieval</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">features, label </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> training_data.get_sample(</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Sample 0: features=</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">features</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">, label=</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">label</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p>Expected output: No exceptions, correct metadata extraction, proper sample retrieval.</p>\n<p><strong>Checkpoint 2: Dataset Loading and Preprocessing</strong>\nVerify that standard datasets load correctly with proper scaling:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test Iris dataset loading</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">X, y </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> load_iris_dataset() </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">X_train, X_test, y_train, y_test </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> split_and_scale_data(X, y, </span><span style=\"color:#FFAB70\">random_state</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">42</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Iris dataset: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">X.shape[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> samples, </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">X.shape[</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> features\"</span><span style=\"color:#E1E4E8\">) </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Training set: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">X_train.shape[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> samples\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Test set: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">X_test.shape[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> samples\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Feature means after scaling: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">np.mean(X_train, </span><span style=\"color:#FFAB70\">axis</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Feature stds after scaling: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">np.std(X_train, </span><span style=\"color:#FFAB70\">axis</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p>Expected output: 150 Iris samples with 4 features, approximately 80/20 train/test split, feature means near 0.0 and standard deviations near 1.0 after scaling.</p>\n<h4 id=\"debugging-tips\">Debugging Tips</h4>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Distance calculations return NaN</td>\n<td>Non-finite input features</td>\n<td>Check <code>np.isfinite(X).all()</code></td>\n<td>Add input validation, handle missing values</td>\n</tr>\n<tr>\n<td>Memory usage grows during prediction</td>\n<td>Arrays not being garbage collected</td>\n<td>Profile memory usage, check for circular references</td>\n<td>Explicitly delete intermediate arrays</td>\n</tr>\n<tr>\n<td>Slow distance calculations</td>\n<td>Non-contiguous array layout</td>\n<td>Check <code>X.flags[&#39;C_CONTIGUOUS&#39;]</code></td>\n<td>Use <code>np.ascontiguousarray(X)</code></td>\n</tr>\n<tr>\n<td>Type errors during prediction</td>\n<td>Inconsistent label types</td>\n<td>Check <code>type(y[0])</code> for all labels</td>\n<td>Convert labels to consistent type</td>\n</tr>\n<tr>\n<td>Index out of bounds errors</td>\n<td>K larger than training set size</td>\n<td>Compare <code>k</code> with <code>len(training_data)</code></td>\n<td>Validate K during classifier construction</td>\n</tr>\n</tbody></table>\n<h2 id=\"distance-metrics-component\">Distance Metrics Component</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Milestone 1: Distance Calculation - implements all distance metrics with vectorized operations for efficient computation between feature vectors</p>\n</blockquote>\n<p>The distance metrics component forms the computational foundation of the KNN classifier, responsible for measuring similarity between data points in feature space. This component directly implements the core deliverables of Milestone 1, providing Euclidean distance, Manhattan distance, cosine similarity, and distance matrix building capabilities. The architectural challenge lies in creating efficient vectorized implementations that can handle high-dimensional data while maintaining numerical stability and providing a clean interface for different similarity measures.</p>\n<h3 id=\"mental-model-measuring-similarity\">Mental Model: Measuring Similarity</h3>\n<p>Understanding distance metrics requires thinking about how we naturally measure similarity in everyday life. Imagine you&#39;re trying to find people similar to yourself based on attributes like height, age, income, and education level. Different distance metrics represent different philosophies for measuring this similarity.</p>\n<p>The <strong>Euclidean distance</strong> is like measuring the straight-line distance between two people if you plotted them as points in a multi-dimensional space. If person A is at coordinates (height=70, age=30, income=50000) and person B is at (height=72, age=32, income=52000), Euclidean distance draws an imaginary straight line between these two points and measures its length. This treats all dimensions equally and gives you the most intuitive &quot;as the crow flies&quot; distance.</p>\n<p>The <strong>Manhattan distance</strong> takes a different approach, like measuring the distance you&#39;d actually walk in a city with a grid street system. Instead of cutting diagonally through buildings, you have to walk along the streets - first going 2 units in the height direction, then 2 units in the age direction, then 2000 units in the income direction, and summing up all these individual distances. This metric is more robust to outliers because it doesn&#39;t square the differences.</p>\n<p>The <strong>cosine similarity</strong> focuses purely on the shape or direction of the data vectors, ignoring their magnitude. Think of it as asking &quot;do these two people have similar proportions across all attributes?&quot; rather than &quot;are their absolute values close?&quot;. Two people might have very different absolute incomes and ages, but if their relative patterns are similar (both high in education relative to their age group, both moderate in income relative to their education level), cosine similarity will consider them highly similar.</p>\n<p>This mental model helps us understand when to use each metric. Euclidean works well when all dimensions have similar scales and meaning. Manhattan is better when you want to reduce the influence of outliers or when the features represent counts. Cosine similarity shines when you care about patterns and proportions rather than absolute magnitudes, which is common in text analysis and recommendation systems.</p>\n<h3 id=\"distance-calculator-interface\">Distance Calculator Interface</h3>\n<p>The distance calculator provides a unified interface for computing similarity between feature vectors, abstracting away the mathematical details while ensuring consistent behavior across different metrics. The interface design follows the principle of separating metric selection from computation execution, allowing the same calculation logic to work with any distance function.</p>\n<table>\n<thead>\n<tr>\n<th>Method Name</th>\n<th>Parameters</th>\n<th>Returns</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>calculate_distance</code></td>\n<td><code>point1: FeatureVector, point2: FeatureVector, metric: DistanceMetric</code></td>\n<td><code>float64</code></td>\n<td>Computes distance between two feature vectors using specified metric</td>\n</tr>\n<tr>\n<td><code>calculate_distances_to_point</code></td>\n<td><code>query_point: FeatureVector, training_matrix: FeatureMatrix, metric: DistanceMetric</code></td>\n<td><code>DistanceArray</code></td>\n<td>Vectorized computation of distances from query point to all training samples</td>\n</tr>\n<tr>\n<td><code>calculate_pairwise_distances</code></td>\n<td><code>matrix1: FeatureMatrix, matrix2: FeatureMatrix, metric: DistanceMetric</code></td>\n<td><code>DistanceMatrix</code></td>\n<td>Builds full distance matrix between two sets of points</td>\n</tr>\n<tr>\n<td><code>validate_inputs</code></td>\n<td><code>point1: FeatureVector, point2: FeatureVector</code></td>\n<td><code>None</code></td>\n<td>Ensures input vectors have compatible dimensions and valid values</td>\n</tr>\n<tr>\n<td><code>get_available_metrics</code></td>\n<td><code>None</code></td>\n<td><code>List[DistanceMetric]</code></td>\n<td>Returns list of supported distance metrics</td>\n</tr>\n</tbody></table>\n<p>The interface design prioritizes both individual point calculations and batch operations. The <code>calculate_distance</code> method handles single point-to-point calculations, essential for debugging and small-scale operations. The <code>calculate_distances_to_point</code> method provides the core functionality needed for KNN neighbor finding, computing distances from one query point to all training samples in a single vectorized operation. The <code>calculate_pairwise_distances</code> method supports advanced use cases like building complete distance matrices for analysis or optimization algorithms.</p>\n<p>Input validation occurs at the interface level to ensure consistent error handling across all distance metrics. The validation checks for dimension compatibility between vectors, the presence of NaN or infinite values, and appropriate data types. This centralized validation prevents the need to duplicate error checking logic in each individual distance metric implementation.</p>\n<p>The interface supports metric parameterization through the <code>DistanceMetric</code> enum, enabling runtime selection of similarity measures. This design allows the same classifier instance to experiment with different distance functions without requiring code changes, supporting hyperparameter optimization workflows where distance metric selection becomes part of the model tuning process.</p>\n<h3 id=\"distance-algorithms\">Distance Algorithms</h3>\n<p>The three core distance algorithms each implement a different mathematical approach to measuring similarity, optimized for efficient computation using vectorized operations. Each algorithm follows a consistent pattern of input validation, vectorized computation, and result formatting, but differs in the underlying mathematical operations.</p>\n<h4 id=\"euclidean-distance-algorithm\">Euclidean Distance Algorithm</h4>\n<p>The Euclidean distance algorithm computes the L2 norm between two feature vectors, representing the straight-line distance in multi-dimensional space. The mathematical foundation is the Pythagorean theorem extended to n dimensions: the square root of the sum of squared differences across all features.</p>\n<ol>\n<li><p><strong>Input validation</strong>: Verify both input vectors have identical dimensions and contain only finite numeric values. Check that neither vector is empty and both have matching data types.</p>\n</li>\n<li><p><strong>Difference computation</strong>: Calculate the element-wise difference between the two feature vectors using vectorized subtraction. This creates a new vector where each element represents the difference in that particular feature dimension.</p>\n</li>\n<li><p><strong>Squared differences</strong>: Apply element-wise squaring to the difference vector, transforming each difference into its squared value. This squaring operation eliminates negative values and gives greater weight to larger differences.</p>\n</li>\n<li><p><strong>Sum of squares</strong>: Compute the sum of all squared differences using vectorized summation. This produces a single scalar value representing the total squared distance across all dimensions.</p>\n</li>\n<li><p><strong>Square root extraction</strong>: Apply the square root function to the sum of squares, yielding the final Euclidean distance. Include numerical stability checks to handle potential floating-point precision issues near zero.</p>\n</li>\n<li><p><strong>Result validation</strong>: Ensure the computed distance is non-negative and finite. Handle edge cases where the input vectors are identical (distance should be exactly zero).</p>\n</li>\n</ol>\n<p>The vectorized implementation leverages NumPy&#39;s broadcasting capabilities to perform element-wise operations on entire arrays simultaneously, avoiding Python-level loops that would significantly degrade performance on high-dimensional data.</p>\n<h4 id=\"manhattan-distance-algorithm\">Manhattan Distance Algorithm</h4>\n<p>The Manhattan distance algorithm computes the L1 norm between feature vectors, measuring similarity as the sum of absolute differences across all dimensions. This approach is more robust to outliers than Euclidean distance because it doesn&#39;t square the individual differences.</p>\n<ol>\n<li><p><strong>Input validation</strong>: Perform identical validation steps as Euclidean distance, ensuring dimension compatibility and finite numeric values.</p>\n</li>\n<li><p><strong>Difference computation</strong>: Calculate element-wise differences between the two feature vectors using vectorized subtraction, identical to the Euclidean approach.</p>\n</li>\n<li><p><strong>Absolute differences</strong>: Apply element-wise absolute value function to the difference vector, ensuring all differences are non-negative. This step replaces the squaring operation used in Euclidean distance.</p>\n</li>\n<li><p><strong>Sum of absolute differences</strong>: Compute the sum of all absolute differences using vectorized summation, producing the final Manhattan distance as a single scalar value.</p>\n</li>\n<li><p><strong>Result validation</strong>: Verify the computed distance is non-negative and finite, with special handling for identical input vectors.</p>\n</li>\n</ol>\n<p>The Manhattan distance algorithm is computationally simpler than Euclidean distance because it avoids both squaring and square root operations, making it potentially faster for high-dimensional data while providing different similarity semantics.</p>\n<h4 id=\"cosine-similarity-algorithm\">Cosine Similarity Algorithm</h4>\n<p>The cosine similarity algorithm measures the angular relationship between two feature vectors, focusing on their directional similarity rather than magnitude differences. The computation involves dot products and vector norms, with the final result representing the cosine of the angle between the vectors.</p>\n<ol>\n<li><p><strong>Input validation</strong>: Validate dimensions and numeric properties, with additional checks for zero vectors that would make cosine similarity undefined.</p>\n</li>\n<li><p><strong>Dot product computation</strong>: Calculate the dot product between the two feature vectors using vectorized multiplication followed by summation. The dot product represents the projection of one vector onto the other.</p>\n</li>\n<li><p><strong>Norm calculations</strong>: Compute the L2 norm (Euclidean norm) of each input vector separately. This involves squaring all elements, summing them, and taking the square root for each vector.</p>\n</li>\n<li><p><strong>Zero vector handling</strong>: Check if either vector has zero norm, which would make cosine similarity undefined. Handle this edge case by returning a predefined similarity value or raising an appropriate error.</p>\n</li>\n<li><p><strong>Cosine computation</strong>: Divide the dot product by the product of the two norms, yielding the cosine similarity value between -1 and 1.</p>\n</li>\n<li><p><strong>Distance conversion</strong>: Convert cosine similarity to cosine distance by subtracting from 1.0, ensuring the result follows distance semantics where smaller values indicate greater similarity.</p>\n</li>\n</ol>\n<p>The cosine similarity algorithm requires careful handling of numerical edge cases, particularly zero vectors and very small norms that could lead to division by zero or numerical instability.</p>\n<h3 id=\"architecture-decisions-for-distance-calculation\">Architecture Decisions for Distance Calculation</h3>\n<p>The design of the distance calculation component involves several critical architectural decisions that impact performance, extensibility, and correctness. Each decision represents a trade-off between competing requirements and reflects the specific needs of the KNN classification system.</p>\n<blockquote>\n<p><strong>Decision: Vectorized Operations Over Loop-Based Implementations</strong></p>\n<ul>\n<li><strong>Context</strong>: Distance calculations are the computational bottleneck in KNN, often requiring thousands or millions of distance computations between query points and training samples. Python loops are notoriously slow compared to compiled code.</li>\n<li><strong>Options Considered</strong>: Pure Python loops with manual iteration, NumPy vectorized operations, hybrid approach with selective vectorization</li>\n<li><strong>Decision</strong>: Implement all distance calculations using NumPy vectorized operations exclusively</li>\n<li><strong>Rationale</strong>: Vectorized operations execute in compiled C code within NumPy, providing 10-100x speedup over Python loops. The performance gain is essential for practical KNN applications on realistic datasets. Memory usage is higher but acceptable for most applications.</li>\n<li><strong>Consequences</strong>: Requires NumPy dependency, uses more memory for intermediate arrays, but provides dramatic performance improvements and cleaner, more readable code</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Pros</th>\n<th>Cons</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Python Loops</td>\n<td>No memory overhead, easy to debug</td>\n<td>10-100x slower, harder to read</td>\n</tr>\n<tr>\n<td>NumPy Vectorized</td>\n<td>Very fast, clean code, leverages optimized libraries</td>\n<td>Higher memory usage, NumPy dependency</td>\n</tr>\n<tr>\n<td>Hybrid Approach</td>\n<td>Balanced performance/memory</td>\n<td>Complex implementation, inconsistent performance</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Single Metric Interface Over Separate Metric Classes</strong></p>\n<ul>\n<li><strong>Context</strong>: The system needs to support multiple distance metrics while providing a consistent interface for the classifier component. Different metrics have different computational patterns and edge cases.</li>\n<li><strong>Options Considered</strong>: Separate class for each metric with shared interface, single function with metric parameter, strategy pattern with metric objects</li>\n<li><strong>Decision</strong>: Single interface with metric parameter and internal dispatch to specialized implementations</li>\n<li><strong>Rationale</strong>: Reduces code duplication, provides consistent error handling and input validation, simplifies client code that needs to switch between metrics. Performance overhead of dispatch is negligible compared to computation time.</li>\n<li><strong>Consequences</strong>: Slightly more complex internal implementation, but much simpler client interface and better maintainability</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Pros</th>\n<th>Cons</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Separate Classes</td>\n<td>Clear separation, extensible</td>\n<td>Code duplication, complex client interface</td>\n</tr>\n<tr>\n<td>Single Function</td>\n<td>Simple implementation</td>\n<td>Becomes unwieldy with many metrics</td>\n</tr>\n<tr>\n<td>Strategy Pattern</td>\n<td>Clean design, extensible</td>\n<td>Over-engineering for this use case</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Eager Input Validation Over Lazy Error Handling</strong></p>\n<ul>\n<li><strong>Context</strong>: Distance calculations can fail due to dimension mismatches, NaN values, infinite values, or inappropriate data types. These errors are often difficult to debug when they occur deep in vectorized operations.</li>\n<li><strong>Options Considered</strong>: No validation (fail fast), lazy validation during computation, eager validation at interface boundary</li>\n<li><strong>Decision</strong>: Implement comprehensive input validation at the interface level before any computation</li>\n<li><strong>Rationale</strong>: Provides clear, actionable error messages at the point of call rather than cryptic NumPy errors. The performance cost of validation is minimal compared to distance computation. Improves debugging experience significantly.</li>\n<li><strong>Consequences</strong>: Slight performance overhead, more code complexity, but much better error messages and debugging experience</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Pros</th>\n<th>Cons</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>No Validation</td>\n<td>Fastest execution</td>\n<td>Cryptic errors, hard to debug</td>\n</tr>\n<tr>\n<td>Lazy Validation</td>\n<td>Minimal overhead</td>\n<td>Errors occur far from root cause</td>\n</tr>\n<tr>\n<td>Eager Validation</td>\n<td>Clear errors, easy debugging</td>\n<td>Small performance cost</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Distance Matrix Caching Over On-Demand Computation</strong></p>\n<ul>\n<li><strong>Context</strong>: KNN classification often involves repeated distance calculations between the same sets of points, especially during hyperparameter tuning and cross-validation. Computing distances on-demand wastes computation time.</li>\n<li><strong>Options Considered</strong>: Always compute on-demand, cache distance matrices in memory, hybrid caching with memory limits</li>\n<li><strong>Decision</strong>: Provide optional distance matrix caching with explicit cache management</li>\n<li><strong>Rationale</strong>: Dramatic performance improvements for repeated queries against the same training set. Memory usage is predictable and can be managed by the client. Optional nature allows memory-constrained applications to opt out.</li>\n<li><strong>Consequences</strong>: Higher memory usage when enabled, more complex cache management logic, but significant performance gains for common use cases</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Pros</th>\n<th>Cons</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>On-Demand Only</td>\n<td>Low memory usage</td>\n<td>Repeated computation waste</td>\n</tr>\n<tr>\n<td>Always Cache</td>\n<td>Best performance</td>\n<td>High memory usage, may not fit</td>\n</tr>\n<tr>\n<td>Optional Caching</td>\n<td>Flexible, configurable</td>\n<td>More complex implementation</td>\n</tr>\n</tbody></table>\n<p><img src=\"/api/project/knn/architecture-doc/asset?path=diagrams%2Fdistance-calculation.svg\" alt=\"Distance Calculation Process\"></p>\n<h3 id=\"common-distance-calculation-pitfalls\">Common Distance Calculation Pitfalls</h3>\n<p>Distance calculation implementations frequently encounter several categories of errors that can lead to incorrect results, poor performance, or runtime failures. Understanding these pitfalls helps developers avoid common mistakes and implement robust distance metrics.</p>\n<p>⚠️ <strong>Pitfall: Dimension Mismatch Between Vectors</strong></p>\n<p>One of the most frequent errors occurs when attempting to calculate distances between feature vectors of different dimensions. This typically happens when training data and query data are preprocessed differently, or when datasets are concatenated incorrectly.</p>\n<p><strong>Why it&#39;s wrong</strong>: Vectorized operations require compatible array shapes. NumPy will either fail with a broadcasting error or silently produce incorrect results by broadcasting smaller arrays. Distance calculations become meaningless when comparing vectors representing different feature spaces.</p>\n<p><strong>How to fix</strong>: Implement comprehensive dimension checking in the <code>validate_inputs</code> method. Verify that <code>point1.shape[0] == point2.shape[0]</code> for individual point calculations, and ensure all vectors in batch operations have identical feature dimensions. Provide clear error messages that include the actual dimensions found.</p>\n<p>⚠️ <strong>Pitfall: Ignoring Feature Scale Differences</strong></p>\n<p>Distance metrics are sensitive to the scale and range of different features. If one feature ranges from 0-1 while another ranges from 0-100000, the large-scale feature will dominate distance calculations regardless of its actual importance.</p>\n<p><strong>Why it&#39;s wrong</strong>: Features with larger numeric ranges contribute disproportionately to distance calculations, effectively making smaller-scale features irrelevant. This leads to poor classification performance where the model only considers high-magnitude features.</p>\n<p><strong>How to fix</strong>: While feature scaling is technically outside the distance calculator&#39;s responsibility, provide clear documentation about scale sensitivity. Consider adding optional built-in normalization capabilities or warning messages when feature ranges differ by orders of magnitude.</p>\n<p>⚠️ <strong>Pitfall: Numerical Instability with Small Values</strong></p>\n<p>Floating-point arithmetic can produce unexpected results when dealing with very small numbers, particularly in square root operations for Euclidean distance and division operations for cosine similarity.</p>\n<p><strong>Why it&#39;s wrong</strong>: Operations like <code>sqrt(very_small_number)</code> or <code>dot_product / (tiny_norm * other_norm)</code> can produce numerical artifacts, infinity values, or lose precision due to floating-point representation limits.</p>\n<p><strong>How to fix</strong>: Add epsilon tolerance for near-zero comparisons. For square root operations, check if the input is below a small threshold (e.g., 1e-15) and handle as exact zero. For cosine similarity, detect near-zero norms and handle as undefined similarity rather than attempting division.</p>\n<p>⚠️ <strong>Pitfall: Memory Explosion with Large Distance Matrices</strong></p>\n<p>When building full pairwise distance matrices for large datasets, memory usage scales quadratically with the number of points. A dataset with 10,000 points requires 100 million distance values, consuming gigabytes of RAM.</p>\n<p><strong>Why it&#39;s wrong</strong>: Large distance matrices can exceed available memory, causing the program to crash or swap to disk with severe performance degradation. Even when they fit in memory, they may crowd out other important data structures.</p>\n<p><strong>How to fix</strong>: Implement memory usage estimation before computing large distance matrices. Provide chunked computation options that process distance matrices in blocks. Consider lazy evaluation approaches where distances are computed on-demand rather than precomputed.</p>\n<p>⚠️ <strong>Pitfall: Incorrect Cosine Distance Conversion</strong></p>\n<p>Cosine similarity produces values between -1 and +1, but distance metrics should follow the convention where smaller values indicate greater similarity. The conversion from similarity to distance is often implemented incorrectly.</p>\n<p><strong>Why it&#39;s wrong</strong>: Simply negating cosine similarity or using <code>1 - cosine_similarity</code> can produce negative distances or incorrect ordering. Some implementations forget that cosine similarity can be negative for vectors pointing in opposite directions.</p>\n<p><strong>How to fix</strong>: Use the correct conversion formula: <code>cosine_distance = 1.0 - cosine_similarity</code>. This ensures distances range from 0 (identical direction) to 2 (opposite direction). Handle the edge case where cosine similarity is exactly -1 to avoid floating-point precision issues.</p>\n<p>⚠️ <strong>Pitfall: Inefficient Loop-Based Implementations</strong></p>\n<p>Python loops for distance calculations create severe performance bottlenecks, but developers often implement them when vectorized solutions seem complex or when handling edge cases.</p>\n<p><strong>Why it&#39;s wrong</strong>: Python loops execute at interpreted speed rather than compiled speed, creating 10-100x performance penalties. This makes KNN impractical for any reasonably-sized dataset.</p>\n<p><strong>How to fix</strong>: Always use NumPy vectorized operations. For complex edge cases, handle them outside the main computation loop rather than adding conditional logic inside loops. Profile code to identify any remaining loop bottlenecks and replace them with vectorized equivalents.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The distance metrics component requires careful attention to numerical stability and performance optimization. The implementation balances ease of use with computational efficiency, providing both simple single-distance calculations and optimized batch operations.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Numerical Computing</td>\n<td>NumPy arrays with basic operations</td>\n<td>NumPy + SciPy with optimized sparse matrix support</td>\n</tr>\n<tr>\n<td>Validation</td>\n<td>Manual type and shape checking</td>\n<td>Pandas-style data validation with detailed error reporting</td>\n</tr>\n<tr>\n<td>Performance Monitoring</td>\n<td>Basic timing with time.time()</td>\n<td>Line profiler + memory profiler for detailed optimization</td>\n</tr>\n<tr>\n<td>Testing</td>\n<td>Assert statements with manual test cases</td>\n<td>Hypothesis property-based testing with random data generation</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<p>The distance metrics component organizes into a focused module structure that separates core algorithms from utilities and testing:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#E1E4E8\">knn_classifier</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">  distance</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    __init__</span><span style=\"color:#E1E4E8\">.py              ← public interface exports</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    metrics.py               ← core distance algorithm implementations  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    calculator.py            ← distance calculator </span><span style=\"color:#F97583\">class</span><span style=\"color:#F97583\"> with</span><span style=\"color:#E1E4E8\"> interface</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    validation.py            ← </span><span style=\"color:#79B8FF\">input</span><span style=\"color:#E1E4E8\"> validation </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> error handling</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    test_distance.py         ← comprehensive distance metric tests</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">  data</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    types.py                 ← shared </span><span style=\"color:#79B8FF\">type</span><span style=\"color:#E1E4E8\"> definitions</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">  utils</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    performance.py           ← timing </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> profiling utilities</span></span></code></pre></div>\n\n<p>This structure keeps the core distance algorithms in <code>metrics.py</code>, the public interface in <code>calculator.py</code>, and supporting functionality in separate modules. The <code>__init__.py</code> file exports the main <code>DistanceCalculator</code> class and <code>DistanceMetric</code> enum for easy importing by client code.</p>\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p><strong>Complete Type Definitions</strong> (<code>data/types.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Union, List, Set, Optional, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Core data types for KNN system</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">FeatureVector </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.ndarray  </span><span style=\"color:#6A737D\"># 1D array of float64 features</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">FeatureMatrix </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.ndarray  </span><span style=\"color:#6A737D\"># 2D array shape (n_samples, n_features)  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">ClassLabel </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Union[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]  </span><span style=\"color:#6A737D\"># flexible class identifiers</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">DistanceArray </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.ndarray  </span><span style=\"color:#6A737D\"># 1D array of float64 distances</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">NeighborIndices </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.ndarray  </span><span style=\"color:#6A737D\"># 1D array of int32 indices</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DistanceMetric</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Supported distance metrics for KNN classification.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    EUCLIDEAN</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"euclidean\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    MANHATTAN</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"manhattan\"</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    COSINE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"cosine\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Training data container</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TrainingData</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Container for training dataset with metadata.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    features: FeatureMatrix</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    labels: List[ClassLabel]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    n_samples: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    n_features: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    unique_classes: Set[ClassLabel]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_sample</span><span style=\"color:#E1E4E8\">(self, index: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Tuple[FeatureVector, ClassLabel]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Retrieve single training example by index.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> &#x3C;=</span><span style=\"color:#E1E4E8\"> index </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.n_samples:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> IndexError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Sample index </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">index</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> out of range [0, </span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.n_samples</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">)\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.features[index], </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.labels[index]</span></span></code></pre></div>\n\n<p><strong>Complete Input Validation Module</strong> (<code>distance/validation.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Union</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..data.types </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> FeatureVector, FeatureMatrix, DistanceMetric</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ValidationError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">ValueError</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Raised when input validation fails.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> validate_feature_vector</span><span style=\"color:#E1E4E8\">(vector: FeatureVector, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"vector\"</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Validate single feature vector for distance calculation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(vector, np.ndarray):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#E1E4E8\"> ValidationError(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> must be numpy array, got </span><span style=\"color:#79B8FF\">{type</span><span style=\"color:#E1E4E8\">(vector)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> vector.ndim </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#E1E4E8\"> ValidationError(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> must be 1-dimensional, got shape </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">vector.shape</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> vector.size </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#E1E4E8\"> ValidationError(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> cannot be empty\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> np.issubdtype(vector.dtype, np.number):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#E1E4E8\"> ValidationError(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> must contain numeric data, got dtype </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">vector.dtype</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> np.all(np.isfinite(vector)):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#E1E4E8\"> ValidationError(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> contains non-finite values (NaN or inf)\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> validate_compatible_vectors</span><span style=\"color:#E1E4E8\">(v1: FeatureVector, v2: FeatureVector) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Validate two vectors are compatible for distance calculation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    validate_feature_vector(v1, </span><span style=\"color:#9ECBFF\">\"first vector\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    validate_feature_vector(v2, </span><span style=\"color:#9ECBFF\">\"second vector\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> v1.shape[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> v2.shape[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#E1E4E8\"> ValidationError(</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            f</span><span style=\"color:#9ECBFF\">\"Vector dimension mismatch: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">v1.shape[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> vs </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">v2.shape[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> validate_distance_metric</span><span style=\"color:#E1E4E8\">(metric: DistanceMetric) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Validate distance metric is supported.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(metric, DistanceMetric):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#E1E4E8\"> ValidationError(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"metric must be DistanceMetric enum, got </span><span style=\"color:#79B8FF\">{type</span><span style=\"color:#E1E4E8\">(metric)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> validate_feature_matrix</span><span style=\"color:#E1E4E8\">(matrix: FeatureMatrix, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"matrix\"</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Validate feature matrix for batch distance calculations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(matrix, np.ndarray):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#E1E4E8\"> ValidationError(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> must be numpy array, got </span><span style=\"color:#79B8FF\">{type</span><span style=\"color:#E1E4E8\">(matrix)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> matrix.ndim </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#E1E4E8\"> ValidationError(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> must be 2-dimensional, got shape </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">matrix.shape</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> matrix.size </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#E1E4E8\"> ValidationError(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> cannot be empty\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> np.issubdtype(matrix.dtype, np.number):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#E1E4E8\"> ValidationError(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> must contain numeric data, got dtype </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">matrix.dtype</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> np.all(np.isfinite(matrix)):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#E1E4E8\"> ValidationError(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> contains non-finite values (NaN or inf)\"</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeleton-code\">Core Logic Skeleton Code</h4>\n<p><strong>Distance Metrics Implementation</strong> (<code>distance/metrics.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..data.types </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> FeatureVector, FeatureMatrix, DistanceArray</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> euclidean_distance</span><span style=\"color:#E1E4E8\">(point1: FeatureVector, point2: FeatureVector) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Calculate Euclidean (L2) distance between two feature vectors.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    The Euclidean distance is the straight-line distance in n-dimensional space,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    computed as the square root of the sum of squared differences.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        point1: First feature vector</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        point2: Second feature vector (must have same dimensions)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Euclidean distance as float (always non-negative)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Calculate element-wise differences using vectorized subtraction</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Square each difference using element-wise multiplication or np.square()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Sum all squared differences using np.sum()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Take square root of sum using np.sqrt()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return the final distance value</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: The entire calculation can be done in one line: np.sqrt(np.sum((point1 - point2) ** 2))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> manhattan_distance</span><span style=\"color:#E1E4E8\">(point1: FeatureVector, point2: FeatureVector) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Calculate Manhattan (L1) distance between two feature vectors.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    The Manhattan distance is the sum of absolute differences across all dimensions,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    like walking along city blocks rather than cutting diagonally.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        point1: First feature vector</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        point2: Second feature vector (must have same dimensions)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Manhattan distance as float (always non-negative)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Calculate element-wise differences using vectorized subtraction</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Take absolute value of each difference using np.abs()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Sum all absolute differences using np.sum()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return the final distance value</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: Can be computed as np.sum(np.abs(point1 - point2))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> cosine_distance</span><span style=\"color:#E1E4E8\">(point1: FeatureVector, point2: FeatureVector) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Calculate cosine distance between two feature vectors.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Cosine distance focuses on vector direction rather than magnitude,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    computed as 1 - cosine_similarity where cosine_similarity = dot_product / (norm1 * norm2).</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        point1: First feature vector</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        point2: Second feature vector (must have same dimensions)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Cosine distance as float (0 = identical direction, 2 = opposite direction)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Calculate dot product using np.dot(point1, point2)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Calculate L2 norm of point1 using np.linalg.norm()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Calculate L2 norm of point2 using np.linalg.norm()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Check for zero norms - if either norm is 0, handle edge case</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Calculate cosine similarity as dot_product / (norm1 * norm2)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Convert similarity to distance using: distance = 1.0 - similarity</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Return the final distance value</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: Add small epsilon (1e-10) to norms to avoid division by zero</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> vectorized_distances_to_point</span><span style=\"color:#E1E4E8\">(query_point: FeatureVector, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                training_matrix: FeatureMatrix,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                metric_func) -> DistanceArray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Calculate distances from query point to all training samples using vectorization.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    This is the performance-critical function that enables efficient KNN neighbor finding</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    by computing thousands of distances in a single vectorized operation.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        query_point: Single query vector to find neighbors for</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        training_matrix: Matrix where each row is a training sample</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        metric_func: Distance function (euclidean_distance, manhattan_distance, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Array of distances from query_point to each training sample</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Get number of training samples from matrix shape</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Initialize distance array with zeros using np.zeros()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Use broadcasting to compute all distances at once - avoid Python loops!</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: For Euclidean: use np.sqrt(np.sum((query_point - training_matrix)**2, axis=1))</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: For Manhattan: use np.sum(np.abs(query_point - training_matrix), axis=1)  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: For Cosine: implement vectorized dot products and norms</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Return the distance array</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: The axis=1 parameter sums across features (columns) for each sample (row)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span></code></pre></div>\n\n<p><strong>Distance Calculator Interface</strong> (<code>distance/calculator.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .metrics </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> euclidean_distance, manhattan_distance, cosine_distance, vectorized_distances_to_point</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .validation </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> validate_compatible_vectors, validate_distance_metric, validate_feature_matrix</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..data.types </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> FeatureVector, FeatureMatrix, DistanceArray, DistanceMetric</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DistanceCalculator</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Main interface for computing distances between feature vectors.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Provides both single-pair distance calculation and efficient batch operations</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    for computing distances between query points and training datasets.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Initialize distance calculator with metric function mapping.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._metric_functions </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            DistanceMetric.</span><span style=\"color:#79B8FF\">EUCLIDEAN</span><span style=\"color:#E1E4E8\">: euclidean_distance,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            DistanceMetric.</span><span style=\"color:#79B8FF\">MANHATTAN</span><span style=\"color:#E1E4E8\">: manhattan_distance, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            DistanceMetric.</span><span style=\"color:#79B8FF\">COSINE</span><span style=\"color:#E1E4E8\">: cosine_distance</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> calculate_distance</span><span style=\"color:#E1E4E8\">(self, point1: FeatureVector, point2: FeatureVector, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                         metric: DistanceMetric) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Calculate distance between two individual feature vectors.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        This is the basic building block for all distance calculations,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        providing input validation and metric dispatch.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate input vectors are compatible using validation module</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Validate distance metric is supported</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Get the appropriate metric function from self._metric_functions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Call the metric function with the two points</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return the computed distance</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use validate_compatible_vectors() and validate_distance_metric()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> calculate_distances_to_point</span><span style=\"color:#E1E4E8\">(self, query_point: FeatureVector,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                   training_matrix: FeatureMatrix,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                   metric: DistanceMetric) -> DistanceArray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Calculate distances from query point to all training samples.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        This is the core method used by KNN for neighbor finding,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        optimized with vectorized operations for performance.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate query_point as feature vector</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Validate training_matrix as feature matrix</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Validate metric is supported</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Check dimension compatibility between query_point and training_matrix columns</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Use vectorized_distances_to_point() for efficient computation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return the distance array</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: training_matrix.shape[1] should equal query_point.shape[0]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_available_metrics</span><span style=\"color:#E1E4E8\">(self) -> List[DistanceMetric]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Return list of supported distance metrics.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> list</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._metric_functions.keys())</span></span></code></pre></div>\n\n<h4 id=\"language-specific-hints\">Language-Specific Hints</h4>\n<p><strong>NumPy Performance Optimization:</strong></p>\n<ul>\n<li>Use <code>np.sqrt()</code> instead of <code>** 0.5</code> for square roots - it&#39;s optimized and more readable</li>\n<li>Prefer <code>np.sum(arr, axis=1)</code> over <code>np.sum(arr, 1)</code> for clarity about which dimension you&#39;re summing</li>\n<li>Use <code>np.linalg.norm()</code> for vector norms - it handles edge cases and numerical stability better than manual implementation</li>\n<li>Set <code>dtype=np.float64</code> explicitly when creating arrays to ensure consistent precision</li>\n</ul>\n<p><strong>Memory Management:</strong></p>\n<ul>\n<li>Use <code>del large_array</code> after processing to free memory immediately rather than waiting for garbage collection</li>\n<li>For very large distance matrices, consider <code>np.float32</code> instead of <code>np.float64</code> to halve memory usage if precision allows</li>\n<li>Use <code>np.empty()</code> instead of <code>np.zeros()</code> when you&#39;ll overwrite all values anyway</li>\n</ul>\n<p><strong>Error Handling:</strong></p>\n<ul>\n<li>Catch <code>np.linalg.LinAlgError</code> specifically for norm calculations with degenerate inputs</li>\n<li>Use <code>np.seterr(divide=&#39;raise&#39;)</code> during development to catch division by zero early</li>\n<li>Check for <code>np.isfinite()</code> on results when debugging numerical issues</li>\n</ul>\n<p><strong>Testing and Debugging:</strong></p>\n<ul>\n<li>Use <code>np.allclose(a, b, rtol=1e-10)</code> for floating-point comparisons instead of exact equality</li>\n<li>Set <code>np.random.seed(42)</code> in tests for reproducible random data</li>\n<li>Use <code>np.testing.assert_array_almost_equal()</code> for comparing arrays in unit tests</li>\n</ul>\n<h4 id=\"milestone-checkpoint\">Milestone Checkpoint</h4>\n<p>After implementing the distance metrics component, verify correct functionality with these checkpoints:</p>\n<p><strong>Unit Test Execution:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#79B8FF\">cd</span><span style=\"color:#9ECBFF\"> knn_classifier/</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> distance/test_distance.py</span><span style=\"color:#79B8FF\"> -v</span></span></code></pre></div>\n\n<p><strong>Expected Test Output:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>test_euclidean_distance_basic ... PASSED\ntest_euclidean_distance_identical_points ... PASSED  \ntest_manhattan_distance_basic ... PASSED\ntest_cosine_distance_basic ... PASSED\ntest_vectorized_performance ... PASSED\ntest_input_validation_errors ... PASSED</code></pre></div>\n\n<p><strong>Manual Verification:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> distance.calculator </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> DistanceCalculator</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> data.types </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> DistanceMetric</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">calc </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> DistanceCalculator()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test basic distance calculation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">point1 </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.array([</span><span style=\"color:#79B8FF\">1.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">2.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">3.0</span><span style=\"color:#E1E4E8\">])  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">point2 </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.array([</span><span style=\"color:#79B8FF\">4.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">5.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">6.0</span><span style=\"color:#E1E4E8\">])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">dist </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> calc.calculate_distance(point1, point2, DistanceMetric.</span><span style=\"color:#79B8FF\">EUCLIDEAN</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Euclidean distance: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">dist</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Should be ~5.196</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test batch calculation  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">query </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.array([</span><span style=\"color:#79B8FF\">0.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0.0</span><span style=\"color:#E1E4E8\">])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">training </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.array([[</span><span style=\"color:#79B8FF\">1.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0.0</span><span style=\"color:#E1E4E8\">], [</span><span style=\"color:#79B8FF\">0.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1.0</span><span style=\"color:#E1E4E8\">], [</span><span style=\"color:#79B8FF\">1.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1.0</span><span style=\"color:#E1E4E8\">]])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">distances </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> calc.calculate_distances_to_point(query, training, DistanceMetric.</span><span style=\"color:#79B8FF\">EUCLIDEAN</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Batch distances: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">distances</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Should be [1.0, 1.0, 1.414]</span></span></code></pre></div>\n\n<p><strong>Performance Verification:</strong>\nTime the vectorized implementation against a naive loop implementation to ensure the performance benefits are realized. The vectorized version should be 10-50x faster for datasets with 1000+ samples.</p>\n<p><strong>Common Issues to Check:</strong></p>\n<ul>\n<li>If distances are negative, check the cosine distance conversion formula</li>\n<li>If you get dimension errors, verify query point and training matrix have compatible shapes</li>\n<li>If performance is slow, ensure you&#39;re not using Python loops in the distance calculations</li>\n<li>If you get NaN results, check for zero vectors in cosine similarity calculations</li>\n</ul>\n<h2 id=\"neighbor-finding-component\">Neighbor Finding Component</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Milestone 2: K-Nearest Neighbors Classification - implements the neighbor finding logic that identifies the K closest training samples to enable majority voting classification</p>\n</blockquote>\n<p>The neighbor finding component represents the heart of the KNN algorithm&#39;s computational challenge. After distance calculation provides the raw similarity measurements between a query point and all training samples, the neighbor finder must efficiently identify and retrieve the K most similar training examples. This component bridges the gap between mathematical distance computation and practical classification by transforming a continuous similarity space into a discrete set of voting neighbors.</p>\n<h3 id=\"mental-model-the-search-process\">Mental Model: The Search Process</h3>\n<p>Think of neighbor finding as organizing a <strong>recommendation committee</strong> from a large pool of advisors. Imagine you&#39;re new to a city and need restaurant recommendations. You have a database of thousands of residents, each with their own food preferences and demographic information. You&#39;ve already calculated how similar each resident is to you based on age, income, taste preferences, and lifestyle factors - this is analogous to the distance calculation phase.</p>\n<p>Now you need to form your <strong>recommendation committee</strong> of exactly K people. You can&#39;t just pick randomly - you want the people most similar to yourself because their recommendations will be most relevant. The neighbor finding process is like scanning through your similarity scores and saying &quot;I&#39;ll take the 5 most similar people&quot; or &quot;I&#39;ll take the 10 closest matches.&quot; You&#39;re essentially curating a focused advisory panel from a much larger population.</p>\n<p>The efficiency challenge mirrors real-world committee formation: if you have 10,000 potential advisors, you don&#39;t want to sort all 10,000 by similarity just to pick the top 5. You want smart strategies to quickly identify your target committee members without unnecessary computational overhead. This is why neighbor finding algorithms focus on efficient selection rather than complete ranking.</p>\n<p>The neighbor finder also handles the practical complexities that arise in committee formation. What if two advisors have identical similarity scores - who gets selected? What if you ask for 10 committee members but only 8 people live in the city? What if someone asks for a committee of size 0 or negative size? These edge cases require careful handling to ensure the recommendation system remains robust and predictable.</p>\n<h3 id=\"neighbor-finder-interface\">Neighbor Finder Interface</h3>\n<p>The neighbor finding interface provides methods for efficiently locating the K nearest training samples to any query point. The interface abstracts the underlying search strategy while ensuring consistent behavior across different algorithmic approaches. The design emphasizes flexibility in search parameters while maintaining type safety and performance predictability.</p>\n<p>The core interface revolves around the fundamental neighbor search operation, which takes a query point and returns both the indices of the nearest neighbors and their corresponding distances. This dual return provides downstream components with both the identity of the neighbors (for accessing their class labels) and their proximity information (for weighted voting schemes).</p>\n<table>\n<thead>\n<tr>\n<th>Method Name</th>\n<th>Parameters</th>\n<th>Returns</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>find_k_neighbors</code></td>\n<td><code>query_point: FeatureVector, k: int, distance_metric: DistanceMetric</code></td>\n<td><code>Tuple[NeighborIndices, DistanceArray]</code></td>\n<td>Find K nearest neighbors to query point using specified distance metric</td>\n</tr>\n<tr>\n<td><code>find_neighbors_within_radius</code></td>\n<td><code>query_point: FeatureVector, radius: float, distance_metric: DistanceMetric</code></td>\n<td><code>Tuple[NeighborIndices, DistanceArray]</code></td>\n<td>Find all neighbors within specified distance radius</td>\n</tr>\n<tr>\n<td><code>find_neighbors_batch</code></td>\n<td><code>query_points: FeatureMatrix, k: int, distance_metric: DistanceMetric</code></td>\n<td><code>List[Tuple[NeighborIndices, DistanceArray]]</code></td>\n<td>Find K neighbors for multiple query points efficiently</td>\n</tr>\n<tr>\n<td><code>validate_k_parameter</code></td>\n<td><code>k: int, dataset_size: int</code></td>\n<td><code>None</code></td>\n<td>Validate K value against dataset constraints and raise appropriate errors</td>\n</tr>\n<tr>\n<td><code>handle_distance_ties</code></td>\n<td><code>distances: DistanceArray, indices: NeighborIndices, k: int</code></td>\n<td><code>Tuple[NeighborIndices, DistanceArray]</code></td>\n<td>Resolve ties when multiple neighbors have identical distances</td>\n</tr>\n<tr>\n<td><code>get_neighbor_metadata</code></td>\n<td><code>neighbor_indices: NeighborIndices</code></td>\n<td><code>List[Dict[str, Any]]</code></td>\n<td>Retrieve additional information about selected neighbors</td>\n</tr>\n</tbody></table>\n<p>The interface supports both single-query and batch-query operations to accommodate different usage patterns. Single-query operations optimize for individual predictions, while batch operations leverage vectorized computations and memory locality for processing multiple queries simultaneously. The batch interface proves particularly valuable during model evaluation phases where hundreds or thousands of predictions occur in sequence.</p>\n<p>The radius-based neighbor finding provides an alternative selection criterion that complements the K-based approach. Instead of selecting a fixed number of neighbors, radius-based selection identifies all training samples within a specified distance threshold. This approach handles scenarios where the local density of training samples varies significantly across the feature space, ensuring that predictions in sparse regions don&#39;t artificially include very dissimilar neighbors.</p>\n<p>Parameter validation ensures that the neighbor finding process fails fast with clear error messages rather than producing subtly incorrect results. The K parameter validation checks for common issues like negative K values, K values larger than the training dataset, and edge cases where K equals zero. Distance tie handling addresses the mathematical reality that multiple training samples may have identical distances to a query point, requiring deterministic tie-breaking rules.</p>\n<p>The neighbor metadata retrieval supports advanced use cases where downstream components need additional context about the selected neighbors beyond their indices and distances. This might include information about neighbor selection confidence, local density estimates, or debugging information about the search process.</p>\n<h3 id=\"neighbor-search-algorithms\">Neighbor Search Algorithms</h3>\n<p>The neighbor search algorithms implement the core computational strategies for identifying the K closest training samples to a query point. The algorithmic choices represent fundamental trade-offs between computational complexity, memory usage, and implementation simplicity. For educational purposes, the focus remains on algorithms that provide clear learning value while maintaining practical utility.</p>\n<h4 id=\"linear-search-algorithm\">Linear Search Algorithm</h4>\n<p>Linear search represents the most straightforward neighbor finding approach, examining every training sample to identify the K nearest neighbors. Despite its O(n) computational complexity per query, linear search provides several educational and practical advantages that make it the preferred starting algorithm for KNN implementation.</p>\n<p>The linear search process follows these detailed steps:</p>\n<ol>\n<li><p><strong>Distance Computation</strong>: Calculate the distance from the query point to every training sample using the specified distance metric. This leverages the vectorized distance calculation functions from the Distance Metrics Component, computing all distances in a single NumPy operation rather than using Python loops.</p>\n</li>\n<li><p><strong>Distance Array Creation</strong>: Store all computed distances in a <code>DistanceArray</code> alongside the corresponding training sample indices. The array indices implicitly correspond to training sample positions, creating a direct mapping between distance values and sample identities.</p>\n</li>\n<li><p><strong>Partial Sorting</strong>: Use NumPy&#39;s <code>argpartition</code> function to identify the K smallest distances without fully sorting the entire distance array. This optimization reduces the complexity from O(n log n) full sorting to O(n + k log k) partial sorting, providing significant performance benefits when K is much smaller than the dataset size.</p>\n</li>\n<li><p><strong>Index Extraction</strong>: Extract the indices of the K nearest neighbors from the partitioned array. These indices serve as references back into the original training data for label retrieval and metadata access.</p>\n</li>\n<li><p><strong>Distance Extraction</strong>: Retrieve the actual distance values corresponding to the selected neighbors. These distances support weighted voting schemes and confidence estimation in downstream components.</p>\n</li>\n<li><p><strong>Tie Resolution</strong>: Handle cases where multiple training samples have identical distances to the query point. The tie resolution strategy uses deterministic index-based ordering to ensure reproducible results across multiple runs with the same data.</p>\n</li>\n<li><p><strong>Result Validation</strong>: Verify that exactly K neighbors were selected and that all distance values are non-negative finite numbers. This validation catches numerical errors and edge cases before they propagate to classification components.</p>\n</li>\n</ol>\n<p>The linear search algorithm excels in scenarios with small to medium-sized datasets (thousands of samples) where the computational overhead remains manageable. Its implementation simplicity makes it ideal for learning environments where understanding the core logic takes precedence over optimal performance. The algorithm also handles edge cases gracefully, including datasets smaller than K and queries with unusual distance distributions.</p>\n<blockquote>\n<p><strong>Key Insight</strong>: Linear search&#39;s O(n) complexity becomes acceptable when combined with vectorized distance calculations. The NumPy-based implementation processes thousands of distance calculations in milliseconds, making sophisticated tree-based algorithms unnecessary for many practical KNN applications.</p>\n</blockquote>\n<h4 id=\"optimized-search-strategies\">Optimized Search Strategies</h4>\n<p>While linear search provides educational value and practical utility for moderate dataset sizes, larger datasets benefit from optimized search strategies that reduce the computational complexity of neighbor finding. These strategies represent important algorithmic concepts that extend beyond KNN into broader computational geometry and information retrieval domains.</p>\n<p><strong>Partial Distance Calculation</strong>: For high-dimensional feature vectors, distance calculations can become expensive even with vectorization. Partial distance calculation implements early termination strategies that abandon distance computation when intermediate results already exceed the current K-th nearest distance. This optimization proves particularly effective with Manhattan distance calculations where dimensions can be processed incrementally.</p>\n<p><strong>Memory-Conscious Batch Processing</strong>: When processing multiple queries simultaneously, naive batch implementations can exhaust system memory by creating large distance matrices. Memory-conscious batch processing divides query batches into manageable chunks, processing each chunk completely before moving to the next. This approach maintains the performance benefits of vectorization while respecting memory constraints.</p>\n<p><strong>Distance Matrix Caching</strong>: In scenarios where the same query points are processed repeatedly (such as during cross-validation), caching previously computed distance matrices can eliminate redundant calculations. The caching strategy must balance memory usage against computation time, potentially using LRU eviction policies for large datasets.</p>\n<p><strong>Approximate Nearest Neighbors</strong>: For extremely large datasets where exact neighbor finding becomes prohibitively expensive, approximate algorithms can provide acceptable accuracy with dramatically improved performance. Random projection and locality-sensitive hashing represent two such approaches that maintain the core KNN learning concepts while introducing important approximation trade-offs.</p>\n<p>The selection of optimization strategies depends on dataset characteristics, query patterns, and performance requirements. Educational implementations typically start with linear search before introducing optimizations incrementally, allowing learners to measure performance improvements and understand algorithmic trade-offs through direct experimentation.</p>\n<h3 id=\"architecture-decisions-for-neighbor-finding\">Architecture Decisions for Neighbor Finding</h3>\n<p>The neighbor finding component involves several critical architectural decisions that impact performance, maintainability, and extensibility. Each decision represents trade-offs between competing priorities, requiring careful evaluation of the educational and practical implications.</p>\n<blockquote>\n<p><strong>Decision: Search Algorithm Selection</strong></p>\n<ul>\n<li><strong>Context</strong>: Multiple algorithms exist for finding nearest neighbors, ranging from simple linear search to sophisticated tree-based and hashing approaches. The choice impacts both implementation complexity and runtime performance, while educational value varies significantly across algorithms.</li>\n<li><strong>Options Considered</strong>: <ul>\n<li>Linear search with vectorized operations</li>\n<li>KD-tree spatial indexing</li>\n<li>Locality-sensitive hashing (LSH)</li>\n</ul>\n</li>\n<li><strong>Decision</strong>: Implement linear search as the primary algorithm with clear extension points for advanced algorithms</li>\n<li><strong>Rationale</strong>: Linear search provides maximum educational value by exposing the core neighbor finding logic without algorithmic complexity. Vectorized NumPy operations make linear search practical for datasets up to tens of thousands of samples, covering most educational scenarios. The simple implementation allows learners to focus on KNN concepts rather than spatial indexing details.</li>\n<li><strong>Consequences</strong>: Runtime complexity remains O(n) per query, limiting scalability to very large datasets. However, implementation simplicity enables rapid prototyping and debugging. Extension points allow advanced learners to explore tree-based algorithms without redesigning the core architecture.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Algorithm Option</th>\n<th>Pros</th>\n<th>Cons</th>\n<th>Educational Value</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Linear Search</td>\n<td>Simple implementation, handles all distance metrics, vectorized performance</td>\n<td>O(n) complexity per query</td>\n<td>High - exposes core logic clearly</td>\n</tr>\n<tr>\n<td>KD-Tree</td>\n<td>O(log n) average complexity, excellent for low dimensions</td>\n<td>Complex implementation, poor high-dimensional performance</td>\n<td>Medium - introduces spatial indexing concepts</td>\n</tr>\n<tr>\n<td>LSH</td>\n<td>Handles high dimensions, approximate results acceptable</td>\n<td>Complex implementation, approximate results only</td>\n<td>Low - obscures core KNN concepts</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Memory Usage Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Neighbor finding can consume significant memory through distance array storage, especially when processing batch queries or caching results. Memory usage patterns impact both performance and scalability, requiring careful resource management.</li>\n<li><strong>Options Considered</strong>:<ul>\n<li>Store all distances in memory simultaneously</li>\n<li>Stream processing with minimal memory footprint</li>\n<li>Hybrid approach with configurable memory limits</li>\n</ul>\n</li>\n<li><strong>Decision</strong>: Implement streaming processing with optional result caching based on dataset size</li>\n<li><strong>Rationale</strong>: Streaming processing ensures predictable memory usage regardless of dataset size, preventing out-of-memory errors during batch operations. Optional caching provides performance benefits for repeated queries while maintaining memory safety. The hybrid approach teaches memory-performance trade-offs explicitly.</li>\n<li><strong>Consequences</strong>: Slightly increased implementation complexity but significantly improved scalability. Memory usage becomes predictable and configurable, enabling deployment in resource-constrained environments.</li>\n</ul>\n</blockquote>\n<blockquote>\n<p><strong>Decision: Tie-Breaking Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Multiple training samples frequently have identical distances to query points, especially in discrete or low-precision feature spaces. Tie-breaking strategies must be deterministic to ensure reproducible results while remaining computationally efficient.</li>\n<li><strong>Options Considered</strong>:<ul>\n<li>Random selection among tied neighbors</li>\n<li>Index-based deterministic ordering</li>\n<li>Secondary distance metric for tie resolution</li>\n</ul>\n</li>\n<li><strong>Decision</strong>: Use index-based deterministic ordering with configurable random seed option</li>\n<li><strong>Rationale</strong>: Index-based ordering ensures reproducible results across multiple runs, essential for debugging and testing. The deterministic approach prevents subtle bugs caused by random tie-breaking. Optional random seeding supports scenarios where tie-breaking bias must be eliminated.</li>\n<li><strong>Consequences</strong>: Results become fully reproducible, simplifying debugging and testing. Tie-breaking bias toward earlier training samples may occur but can be controlled through data shuffling.</li>\n</ul>\n</blockquote>\n<blockquote>\n<p><strong>Decision: Batch Processing Architecture</strong></p>\n<ul>\n<li><strong>Context</strong>: Real-world KNN applications often process multiple queries simultaneously, either during model evaluation or in production prediction scenarios. Batch processing can leverage vectorization for significant performance improvements but introduces memory management complexity.</li>\n<li><strong>Options Considered</strong>:<ul>\n<li>Process queries individually with simple implementation</li>\n<li>Full batch processing with vectorized distance calculations</li>\n<li>Chunked batch processing with memory limits</li>\n</ul>\n</li>\n<li><strong>Decision</strong>: Implement chunked batch processing with automatic memory management</li>\n<li><strong>Rationale</strong>: Chunked processing balances vectorization benefits against memory constraints, ensuring scalability across different hardware configurations. Automatic memory management reduces implementation burden while maintaining performance benefits. The approach teaches both vectorization concepts and resource management.</li>\n<li><strong>Consequences</strong>: Implementation complexity increases moderately, but performance and scalability improve significantly. Memory usage remains controlled while leveraging vectorization benefits.</li>\n</ul>\n</blockquote>\n<h3 id=\"common-neighbor-finding-pitfalls\">Common Neighbor Finding Pitfalls</h3>\n<p>Neighbor finding implementation contains several subtle pitfalls that frequently trip up learners and even experienced developers. These pitfalls often produce plausible but incorrect results, making them particularly dangerous for learning environments where correctness verification may be limited.</p>\n<p>⚠️ <strong>Pitfall: K Value Larger Than Dataset</strong></p>\n<p>One of the most common errors occurs when the requested K parameter exceeds the total number of training samples in the dataset. This situation frequently arises during experimentation with small datasets or when using the same K value across different dataset sizes without validation.</p>\n<p>The naive implementation might attempt to select K neighbors from a dataset of size N where K &gt; N, leading to index out-of-bounds errors or attempting to pad results with invalid data. Even implementations that avoid crashes may return fewer than K neighbors without clearly communicating this deviation to calling code, causing downstream classification components to behave unexpectedly.</p>\n<p><strong>Detection</strong>: Validate K against dataset size before beginning neighbor search operations. Check that K &gt; 0 and K &lt;= training_data.n_samples, raising clear exceptions for invalid values.</p>\n<p><strong>Solution</strong>: Implement parameter validation that provides helpful error messages, suggesting appropriate K ranges based on dataset size. Consider offering automatic K adjustment with explicit warnings when K exceeds dataset size.</p>\n<p>⚠️ <strong>Pitfall: Distance Tie Mishandling</strong></p>\n<p>Distance ties occur more frequently than intuitive expectations suggest, especially in datasets with discrete features, normalized data, or low-dimensional spaces. When multiple training samples have identical distances to a query point, naive implementations may exhibit non-deterministic behavior, returning different neighbor sets across multiple runs with identical input data.</p>\n<p>The problem manifests when using unstable sorting algorithms or when tie-breaking logic depends on memory addresses or other runtime-dependent factors. This non-determinism makes debugging extremely difficult and violates the reproducibility expectations of scientific computing applications.</p>\n<p><strong>Detection</strong>: Run the same neighbor finding operation multiple times with identical inputs and verify that results remain consistent. Pay particular attention to boundary cases where the K-th and (K+1)-th distances are identical.</p>\n<p><strong>Solution</strong>: Implement deterministic tie-breaking using stable sorting with index-based secondary ordering. When distances are equal, prefer neighbors with smaller training data indices to ensure consistent results.</p>\n<p>⚠️ <strong>Pitfall: Memory Exhaustion in Batch Processing</strong></p>\n<p>Batch processing optimizations can inadvertently create memory usage patterns that exhaust available system memory, particularly when processing large query batches against large training datasets. The problem occurs when implementations create full distance matrices for batch operations without considering memory constraints.</p>\n<p>For example, processing 1,000 queries against 10,000 training samples creates a 10-million element distance matrix, potentially consuming gigabytes of memory. Systems may appear to hang or crash with out-of-memory errors, providing little indication of the underlying cause.</p>\n<p><strong>Detection</strong>: Monitor memory usage during batch operations and implement memory usage estimation before beginning large batch processes. Profile memory consumption patterns with representative dataset sizes.</p>\n<p><strong>Solution</strong>: Implement chunked batch processing that divides large query batches into memory-safe chunks. Process each chunk completely before proceeding to the next, maintaining vectorization benefits while controlling memory usage.</p>\n<p>⚠️ <strong>Pitfall: Incorrect Distance Array Indexing</strong></p>\n<p>Subtle indexing errors can corrupt the correspondence between distance values and training sample indices, leading to neighbors being selected based on correct distances but associated with wrong training samples. This error often produces plausible prediction accuracy while systematically misidentifying the actual neighbors used for classification.</p>\n<p>The problem typically arises during array manipulation operations like sorting, partitioning, or filtering, where distance values and indices become decoupled through incorrect index tracking or off-by-one errors.</p>\n<p><strong>Detection</strong>: Verify neighbor selection results manually on small, well-understood datasets where correct neighbors can be determined by visual inspection. Implement assertions that verify distance-index correspondence after array operations.</p>\n<p><strong>Solution</strong>: Maintain explicit index tracking throughout all array operations. Use NumPy operations that return both values and indices simultaneously (like <code>argsort</code> and <code>argpartition</code>) rather than manipulating values and indices separately.</p>\n<p>⚠️ <strong>Pitfall: Performance Degradation from Python Loops</strong></p>\n<p>Despite implementing vectorized distance calculations, neighbor finding performance can still suffer dramatically from hidden Python loops in neighbor selection logic. These loops often appear in edge case handling, tie-breaking, or result post-processing code where the performance impact may not be immediately obvious during development with small datasets.</p>\n<p>The performance degradation becomes apparent only when scaling to larger datasets, where O(n) Python loops can consume more time than the vectorized distance calculations they supplement.</p>\n<p><strong>Detection</strong>: Profile neighbor finding performance with varying dataset sizes, looking for performance characteristics that suggest hidden loop iterations. Time individual components of the neighbor finding pipeline to identify bottlenecks.</p>\n<p><strong>Solution</strong>: Replace Python loops with vectorized NumPy operations wherever possible. Use NumPy&#39;s advanced indexing, boolean masking, and array manipulation functions to eliminate explicit iteration.</p>\n<p><img src=\"/api/project/knn/architecture-doc/asset?path=diagrams%2Fprediction-flow.svg\" alt=\"Prediction Sequence Flow\"></p>\n<p><img src=\"/api/project/knn/architecture-doc/asset?path=diagrams%2Fneighbor-search.svg\" alt=\"Neighbor Search Algorithm\"></p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The neighbor finding component requires careful attention to both algorithmic correctness and performance optimization. The implementation builds on the vectorized distance calculations from the Distance Metrics Component while introducing new challenges around efficient neighbor selection and edge case handling.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Array Operations</td>\n<td>NumPy with basic indexing</td>\n<td>NumPy with advanced indexing and broadcasting</td>\n</tr>\n<tr>\n<td>Sorting/Selection</td>\n<td><code>numpy.argsort()</code> for full sorting</td>\n<td><code>numpy.argpartition()</code> for partial selection</td>\n</tr>\n<tr>\n<td>Memory Management</td>\n<td>Process all queries in memory</td>\n<td>Chunked processing with memory monitoring</td>\n</tr>\n<tr>\n<td>Tie Breaking</td>\n<td>Index-based deterministic ordering</td>\n<td>Configurable tie-breaking strategies</td>\n</tr>\n<tr>\n<td>Batch Processing</td>\n<td>Sequential query processing</td>\n<td>Vectorized batch operations with chunking</td>\n</tr>\n<tr>\n<td>Performance Monitoring</td>\n<td>Manual timing with <code>time.time()</code></td>\n<td><code>cProfile</code> with detailed performance analysis</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>knn_classifier/\n  core/\n    neighbor_finder.py          ← main neighbor finding implementation\n    neighbor_finder_test.py     ← comprehensive unit tests\n  distance/\n    distance_calculator.py      ← imported from Distance Metrics Component\n  data/\n    data_structures.py          ← FeatureVector, NeighborIndices, etc.\n  utils/\n    validation.py              ← parameter validation utilities\n    performance.py             ← performance monitoring helpers\n  examples/\n    neighbor_finding_demo.py    ← demonstration of neighbor finding capabilities</code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p><strong>Parameter Validation Utilities</strong> (<code>utils/validation.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Union, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..data.data_structures </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> FeatureVector, FeatureMatrix</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> validate_k_parameter</span><span style=\"color:#E1E4E8\">(k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, dataset_size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Validate K parameter against dataset constraints.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        k: Number of neighbors to find</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        dataset_size: Total number of training samples</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Raises:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        ValueError: If K is invalid for the given dataset size</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(k, </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"K must be an integer, got </span><span style=\"color:#79B8FF\">{type</span><span style=\"color:#E1E4E8\">(k)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> k </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"K must be positive, got </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">k</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> k </span><span style=\"color:#F97583\">></span><span style=\"color:#E1E4E8\"> dataset_size:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            f</span><span style=\"color:#9ECBFF\">\"K (</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">k</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">) cannot exceed dataset size (</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">dataset_size</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">). \"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            f</span><span style=\"color:#9ECBFF\">\"Consider using K &#x3C;= </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">dataset_size</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> validate_query_point</span><span style=\"color:#E1E4E8\">(query_point: FeatureVector, expected_features: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Validate query point dimensions and data types.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        query_point: Query feature vector</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        expected_features: Expected number of features</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Raises:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        ValueError: If query point is invalid</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(query_point, np.ndarray):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Query point must be a NumPy array\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> query_point.ndim </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Query point must be 1-dimensional, got shape </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">query_point.shape</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(query_point) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> expected_features:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            f</span><span style=\"color:#9ECBFF\">\"Query point has </span><span style=\"color:#79B8FF\">{len</span><span style=\"color:#E1E4E8\">(query_point)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> features, \"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            f</span><span style=\"color:#9ECBFF\">\"expected </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">expected_features</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> np.all(np.isfinite(query_point)):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Query point contains invalid values (NaN or infinity)\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> validate_distance_array</span><span style=\"color:#E1E4E8\">(distances: np.ndarray, expected_length: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Validate computed distance array for correctness.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        distances: Array of computed distances</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        expected_length: Expected array length</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Raises:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        ValueError: If distance array is invalid</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(distances) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> expected_length:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            f</span><span style=\"color:#9ECBFF\">\"Distance array has length </span><span style=\"color:#79B8FF\">{len</span><span style=\"color:#E1E4E8\">(distances)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">, \"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            f</span><span style=\"color:#9ECBFF\">\"expected </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">expected_length</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> np.all(distances </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Distances must be non-negative\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> np.all(np.isfinite(distances)):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Distance array contains invalid values\"</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p><strong>Performance Monitoring Utilities</strong> (<code>utils/performance.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Any</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> contextlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> contextmanager</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> PerformanceMonitor</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Monitor and report neighbor finding performance metrics.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.timing_data: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, List[</span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.memory_usage: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, List[</span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @contextmanager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> time_operation</span><span style=\"color:#E1E4E8\">(self, operation_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Context manager for timing operations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        start_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            yield</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        finally</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            elapsed </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> operation_name </span><span style=\"color:#F97583\">not</span><span style=\"color:#F97583\"> in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.timing_data:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">.timing_data[operation_name] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.timing_data[operation_name].append(elapsed)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> estimate_memory_usage</span><span style=\"color:#E1E4E8\">(self, n_samples: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, n_queries: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                             n_features: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Estimate memory requirements for neighbor finding operations.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            n_samples: Number of training samples</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            n_queries: Number of query points</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            n_features: Number of features per sample</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Dictionary with memory estimates in MB</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Distance matrix: n_queries × n_samples × 8 bytes (float64)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        distance_memory </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (n_queries </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> n_samples </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 8</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">1024</span><span style=\"color:#F97583\"> *</span><span style=\"color:#79B8FF\"> 1024</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Feature matrices: additional memory for data storage</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        feature_memory </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (n_samples </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> n_features </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 8</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">1024</span><span style=\"color:#F97583\"> *</span><span style=\"color:#79B8FF\"> 1024</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        query_memory </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (n_queries </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> n_features </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 8</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">1024</span><span style=\"color:#F97583\"> *</span><span style=\"color:#79B8FF\"> 1024</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Index arrays and intermediate results</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        index_memory </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (n_queries </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> n_samples </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 4</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">1024</span><span style=\"color:#F97583\"> *</span><span style=\"color:#79B8FF\"> 1024</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># int32</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'distance_matrix_mb'</span><span style=\"color:#E1E4E8\">: distance_memory,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'feature_data_mb'</span><span style=\"color:#E1E4E8\">: feature_memory </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> query_memory,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'index_arrays_mb'</span><span style=\"color:#E1E4E8\">: index_memory,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'total_estimated_mb'</span><span style=\"color:#E1E4E8\">: distance_memory </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> feature_memory </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> query_memory </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> index_memory</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_timing_summary</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get summary statistics for all timed operations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        summary </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> operation, times </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.timing_data.items():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            times_array </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.array(times)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            summary[operation] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'mean_seconds'</span><span style=\"color:#E1E4E8\">: np.mean(times_array),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'std_seconds'</span><span style=\"color:#E1E4E8\">: np.std(times_array),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'min_seconds'</span><span style=\"color:#E1E4E8\">: np.min(times_array),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'max_seconds'</span><span style=\"color:#E1E4E8\">: np.max(times_array),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'total_calls'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">len</span><span style=\"color:#E1E4E8\">(times_array)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> summary</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeleton-code\">Core Logic Skeleton Code</h4>\n<p><strong>Main Neighbor Finder Implementation</strong> (<code>core/neighbor_finder.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Tuple, List, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..data.data_structures </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    FeatureVector, FeatureMatrix, DistanceArray, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    NeighborIndices, DistanceMetric, TrainingData</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..distance.distance_calculator </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> calculate_distances_to_point</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..utils.validation </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> validate_k_parameter, validate_query_point</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..utils.performance </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> PerformanceMonitor</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> NeighborFinder</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Efficiently find K nearest neighbors using linear search with optimizations.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    This implementation prioritizes educational clarity while maintaining</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    practical performance through vectorized operations and memory management.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, training_data: TrainingData, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 performance_monitor: Optional[PerformanceMonitor] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.training_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> training_data</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.performance_monitor </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> performance_monitor </span><span style=\"color:#F97583\">or</span><span style=\"color:#E1E4E8\"> PerformanceMonitor()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> find_k_neighbors</span><span style=\"color:#E1E4E8\">(self, query_point: FeatureVector, k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        distance_metric: DistanceMetric) -> Tuple[NeighborIndices, DistanceArray]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Find K nearest neighbors to query point using linear search.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            query_point: Feature vector for which to find neighbors</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            k: Number of nearest neighbors to find</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            distance_metric: Distance metric to use for similarity calculation</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Tuple of (neighbor_indices, neighbor_distances) sorted by ascending distance</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Raises:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            ValueError: If parameters are invalid or query point is incompatible</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate input parameters using validation utilities</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Check K value, query point dimensions, and data types</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Calculate distances from query point to all training samples</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use calculate_distances_to_point with vectorized operations</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Store result in DistanceArray for downstream processing</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Use numpy.argpartition to find indices of K smallest distances</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: argpartition(distances, k-1) partitions around K-th element</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # This is more efficient than full sorting when K &#x3C;&#x3C; dataset_size</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Extract the K neighbor indices from partitioned array</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Take the first K elements from the partitioned indices</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # These correspond to the K smallest distances</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Sort the K selected neighbors by their actual distances</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use argsort on the distance subset for proper ordering</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # This ensures neighbors are returned in ascending distance order</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Handle distance ties using deterministic tie-breaking</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: When distances are equal, prefer smaller indices for reproducibility</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Use stable sorting to maintain consistent results</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Extract final neighbor distances corresponding to selected indices</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Index into the original distance array using the final neighbor indices</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Return both indices and distances as the required tuple</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Validate results before returning</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Check that exactly K neighbors were found and distances are valid</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Ensure all distances are non-negative and finite</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span><span style=\"color:#6A737D\">  # Replace with implementation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> find_neighbors_batch</span><span style=\"color:#E1E4E8\">(self, query_points: FeatureMatrix, k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                           distance_metric: DistanceMetric) -> List[Tuple[NeighborIndices, DistanceArray]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Find K nearest neighbors for multiple query points efficiently.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            query_points: Matrix of query feature vectors (n_queries × n_features)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            k: Number of nearest neighbors to find for each query</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            distance_metric: Distance metric to use for all queries</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            List of (neighbor_indices, neighbor_distances) tuples, one per query</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate batch parameters and estimate memory requirements</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Check that all query points have correct dimensions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Use performance_monitor to estimate memory usage</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Determine optimal chunk size based on available memory</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Balance vectorization benefits against memory constraints</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Consider both number of queries and training data size</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Process queries in chunks to manage memory usage</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Divide query_points into manageable chunks</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Process each chunk completely before moving to next</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: For each chunk, vectorize distance calculations across all queries</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Compute distance matrix for chunk_queries × training_samples</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Use broadcasting and vectorized operations for efficiency</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Apply neighbor selection to each row of distance matrix</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use find_k_neighbors logic or vectorized equivalent</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Maintain correspondence between queries and their neighbors</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Aggregate results from all chunks into final result list</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Concatenate chunk results while preserving query order</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Ensure result list length matches number of input queries</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span><span style=\"color:#6A737D\">  # Replace with implementation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> handle_distance_ties</span><span style=\"color:#E1E4E8\">(self, distances: DistanceArray, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                           indices: NeighborIndices, k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Tuple[NeighborIndices, DistanceArray]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Handle cases where multiple neighbors have identical distances.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            distances: Array of distances (may contain ties)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            indices: Corresponding neighbor indices</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            k: Number of neighbors to select</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Tuple of (selected_indices, selected_distances) with ties resolved</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Identify if ties exist around the K-th position</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Check if distances[k-1] equals any distances[k:] values</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Also check for ties within the first K positions</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: If no ties affect the K-th position, return first K neighbors</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Simple case where tie-breaking is not needed</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Return indices[:k] and distances[:k]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: For ties involving the K-th position, use index-based tie-breaking</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Among tied distances, prefer neighbors with smaller training indices</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # This ensures deterministic, reproducible results</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Sort tied neighbors by their original training data indices</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Create secondary sort key using training sample positions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Apply stable sorting to preserve distance-based primary ordering</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Select exactly K neighbors after tie resolution</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Take the first K elements after deterministic tie-breaking</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Ensure result length always equals K (when possible)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span><span style=\"color:#6A737D\">  # Replace with implementation</span></span></code></pre></div>\n\n<h4 id=\"language-specific-hints\">Language-Specific Hints</h4>\n<p><strong>NumPy Performance Optimization</strong>:</p>\n<ul>\n<li>Use <code>numpy.argpartition(arr, k-1)</code> instead of <code>numpy.argsort()</code> when you only need the K smallest elements - this reduces complexity from O(n log n) to O(n + k log k)</li>\n<li>Leverage <code>numpy.take()</code> for efficient index-based array access instead of multiple indexing operations</li>\n<li>Use <code>numpy.broadcast_arrays()</code> to handle dimension mismatches gracefully in batch operations</li>\n<li>Consider <code>numpy.memmap()</code> for very large training datasets that don&#39;t fit in memory</li>\n</ul>\n<p><strong>Memory Management</strong>:</p>\n<ul>\n<li>Monitor memory usage with <code>psutil</code> or similar tools during batch processing to detect memory leaks</li>\n<li>Use <code>del</code> statements to explicitly free large intermediate arrays</li>\n<li>Consider using <code>numpy.float32</code> instead of <code>float64</code> for distance calculations when precision allows, reducing memory usage by half</li>\n<li>Implement chunked processing with configurable chunk sizes based on available system memory</li>\n</ul>\n<p><strong>Debugging Techniques</strong>:</p>\n<ul>\n<li>Use small, manually-verifiable datasets (like 2D points) to validate neighbor finding logic</li>\n<li>Implement visualization helpers that plot query points, training data, and selected neighbors in 2D space</li>\n<li>Add detailed logging that reports intermediate values like distance array statistics and partitioning results</li>\n<li>Create unit tests with known correct answers for edge cases like ties and boundary conditions</li>\n</ul>\n<h4 id=\"milestone-checkpoint\">Milestone Checkpoint</h4>\n<p>After implementing the neighbor finding component, verify functionality using these checkpoints:</p>\n<p><strong>Correctness Verification</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> core/neighbor_finder_test.py</span><span style=\"color:#79B8FF\"> -v</span></span></code></pre></div>\n<p>Expected output should show all tests passing, particularly:</p>\n<ul>\n<li><code>test_find_k_neighbors_basic</code> - basic K neighbor selection</li>\n<li><code>test_distance_tie_handling</code> - deterministic tie resolution  </li>\n<li><code>test_batch_processing</code> - consistent batch vs individual results</li>\n<li><code>test_edge_cases</code> - K=1, K=dataset_size, empty datasets</li>\n</ul>\n<p><strong>Performance Verification</strong>:\nCreate a simple performance test with the Iris dataset:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> examples.neighbor_finding_demo </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> performance_demo</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">performance_demo(</span><span style=\"color:#FFAB70\">k_values</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">3</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">], </span><span style=\"color:#FFAB70\">n_queries</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">100</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n<p>Expected behavior: linear increase in runtime with K, batch processing significantly faster than individual queries for multiple queries.</p>\n<p><strong>Visual Verification</strong> (for 2D datasets):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> examples.neighbor_finding_demo </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> visualize_neighbors</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">visualize_neighbors(</span><span style=\"color:#FFAB70\">query_point</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">2.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">3.0</span><span style=\"color:#E1E4E8\">], </span><span style=\"color:#FFAB70\">k</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">dataset</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">'synthetic_2d'</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n<p>Expected output: scatter plot showing query point, training data, and K nearest neighbors highlighted with connecting lines.</p>\n<p><strong>Common Issues and Diagnostics</strong>:</p>\n<ul>\n<li><strong>Symptom</strong>: Non-deterministic results across runs → <strong>Check</strong>: Tie-breaking implementation uses stable sorting with index-based secondary key</li>\n<li><strong>Symptom</strong>: Memory errors during batch processing → <strong>Check</strong>: Chunk size calculation and memory estimation logic</li>\n<li><strong>Symptom</strong>: Performance much slower than expected → <strong>Check</strong>: Ensure vectorized operations used throughout, no hidden Python loops</li>\n<li><strong>Symptom</strong>: Incorrect neighbors selected → <strong>Check</strong>: Index correspondence between distances and training samples maintained after sorting operations</li>\n</ul>\n<h2 id=\"classification-component\">Classification Component</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Milestone 2: K-Nearest Neighbors Classification - implements majority voting and weighted voting to convert neighbor information into final class predictions</p>\n</blockquote>\n<h3 id=\"mental-model-democratic-decision-making\">Mental Model: Democratic Decision Making</h3>\n<p>Understanding how neighbors vote to determine the final classification is best conceptualized through the lens of democratic decision-making processes. Imagine you&#39;re in a new city and need to choose a restaurant for dinner. You ask the 5 people closest to you (your &quot;neighbors&quot; in this scenario) for their recommendations. Each person suggests their favorite type of cuisine based on their preferences, which are similar to yours since they&#39;re in the same area and situation.</p>\n<p>In the simplest voting scenario, you would choose the cuisine type that the majority of your 5 neighbors recommended - this is <strong>majority voting</strong>. If 3 people suggest Italian, 1 suggests Mexican, and 1 suggests Thai, you&#39;d choose Italian because it has the most votes. However, you might also consider that the person standing right next to you (closest neighbor) has preferences more similar to yours than someone farther away. In this case, you&#39;d give more weight to the recommendations of people closer to you - this is <strong>weighted voting</strong>.</p>\n<p>This democratic process captures the essence of the KNN classification decision-making mechanism. Each training sample in the neighborhood gets to &quot;vote&quot; for its class label, and we aggregate these votes using different strategies to make the final prediction. The key insight is that we&#39;re leveraging the collective wisdom of similar examples rather than relying on a single decision boundary or rule.</p>\n<p>The classification component serves as the decision-making body that takes the neighborhood information discovered by the neighbor finding component and transforms it into a concrete prediction. Unlike parametric models that learn explicit decision boundaries during training, KNN defers all computation to prediction time and makes decisions through this democratic voting process among the most relevant examples.</p>\n<h3 id=\"classifier-interface\">Classifier Interface</h3>\n<p>The classifier interface provides the core methods for training the model, making predictions, and configuring the voting behavior. The interface follows the lazy learning paradigm where no computation occurs during training - the system simply stores the training data for use during prediction.</p>\n<table>\n<thead>\n<tr>\n<th>Method Name</th>\n<th>Parameters</th>\n<th>Returns</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>fit</code></td>\n<td><code>X: FeatureMatrix, y: List[ClassLabel]</code></td>\n<td><code>None</code></td>\n<td>Store training data for lazy learning without performing any computation</td>\n</tr>\n<tr>\n<td><code>predict</code></td>\n<td><code>X: FeatureMatrix</code></td>\n<td><code>List[ClassLabel]</code></td>\n<td>Predict class labels for query points using configured voting strategy</td>\n</tr>\n<tr>\n<td><code>predict_with_confidence</code></td>\n<td><code>X: FeatureMatrix</code></td>\n<td><code>List[PredictionResult]</code></td>\n<td>Predict with neighbor information and confidence scores for detailed analysis</td>\n</tr>\n<tr>\n<td><code>get_sample</code></td>\n<td><code>index: int</code></td>\n<td><code>Tuple[FeatureVector, ClassLabel]</code></td>\n<td>Retrieve single training example by index for neighbor analysis</td>\n</tr>\n<tr>\n<td><code>set_voting_strategy</code></td>\n<td><code>weighted: bool</code></td>\n<td><code>None</code></td>\n<td>Configure whether to use majority voting or distance-weighted voting</td>\n</tr>\n<tr>\n<td><code>set_k_parameter</code></td>\n<td><code>k: int</code></td>\n<td><code>None</code></td>\n<td>Update the number of neighbors to consider for voting</td>\n</tr>\n</tbody></table>\n<p>The <code>KNNClassifier</code> maintains its configuration state through several key attributes that control the voting behavior and neighbor selection process:</p>\n<table>\n<thead>\n<tr>\n<th>Attribute</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>k</code></td>\n<td><code>int</code></td>\n<td>Number of neighbors to consider for voting decisions</td>\n</tr>\n<tr>\n<td><code>distance_metric</code></td>\n<td><code>DistanceMetric</code></td>\n<td>Metric used for measuring similarity between feature vectors</td>\n</tr>\n<tr>\n<td><code>weighted_voting</code></td>\n<td><code>bool</code></td>\n<td>Whether to use distance-weighted voting or simple majority voting</td>\n</tr>\n<tr>\n<td><code>training_data</code></td>\n<td><code>Optional[TrainingData]</code></td>\n<td>Stored training examples used for neighbor-based predictions</td>\n</tr>\n</tbody></table>\n<p>The training data structure encapsulates all information needed for the lazy learning process:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>features</code></td>\n<td><code>FeatureMatrix</code></td>\n<td>Feature vectors for all training samples in matrix form</td>\n</tr>\n<tr>\n<td><code>labels</code></td>\n<td><code>List[ClassLabel]</code></td>\n<td>Corresponding class labels for each training sample</td>\n</tr>\n<tr>\n<td><code>n_samples</code></td>\n<td><code>int</code></td>\n<td>Total number of training examples available</td>\n</tr>\n<tr>\n<td><code>n_features</code></td>\n<td><code>int</code></td>\n<td>Dimensionality of feature vectors</td>\n</tr>\n<tr>\n<td><code>unique_classes</code></td>\n<td><code>Set[ClassLabel]</code></td>\n<td>Set of all possible class labels in training data</td>\n</tr>\n</tbody></table>\n<p>The <code>PredictionResult</code> structure provides detailed information about each prediction, enabling analysis of the decision-making process:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>predicted_class</code></td>\n<td><code>ClassLabel</code></td>\n<td>Final class prediction from voting process</td>\n</tr>\n<tr>\n<td><code>neighbor_indices</code></td>\n<td><code>NeighborIndices</code></td>\n<td>Indices of K nearest neighbors used for voting</td>\n</tr>\n<tr>\n<td><code>neighbor_distances</code></td>\n<td><code>DistanceArray</code></td>\n<td>Distances to each neighbor used for weighted voting</td>\n</tr>\n<tr>\n<td><code>confidence</code></td>\n<td><code>float</code></td>\n<td>Confidence score between 0 and 1 based on voting agreement</td>\n</tr>\n</tbody></table>\n<h3 id=\"voting-algorithms\">Voting Algorithms</h3>\n<p>The classification component implements two primary voting strategies that aggregate neighbor opinions into final predictions. The choice between these strategies significantly impacts the behavior of the classifier, particularly in regions where class boundaries are ambiguous or when neighbors are at varying distances from the query point.</p>\n<h4 id=\"simple-majority-voting\">Simple Majority Voting</h4>\n<p>Simple majority voting treats all K neighbors as equal participants in the decision process, regardless of their distance to the query point. The algorithm follows a straightforward democratic process:</p>\n<ol>\n<li>Collect the class labels of all K nearest neighbors</li>\n<li>Count the frequency of each unique class label among the neighbors</li>\n<li>Select the class label that appears most frequently as the prediction</li>\n<li>Handle ties by selecting the class with the smallest lexicographic order or the class of the nearest neighbor</li>\n</ol>\n<p>The majority voting process can be formalized as finding the mode of the neighbor class distribution. For a query point with neighbors having labels <code>[label1, label2, ..., labelK]</code>, the prediction is:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>prediction = argmax(count(class)) for class in unique_neighbor_classes</code></pre></div>\n\n<p>This approach works well when neighbors are roughly equidistant from the query point or when distance information doesn&#39;t provide meaningful discriminative power. The simplicity of majority voting makes it robust and interpretable, but it discards potentially valuable distance information that could improve prediction accuracy.</p>\n<h4 id=\"distance-weighted-voting\">Distance-Weighted Voting</h4>\n<p>Distance-weighted voting incorporates the principle that closer neighbors should have more influence on the final decision than distant neighbors. This approach addresses situations where one or two very close neighbors might be outvoted by several distant neighbors in simple majority voting.</p>\n<p>The weighted voting algorithm assigns voting weights inversely proportional to distance:</p>\n<ol>\n<li>Calculate voting weight for each neighbor as <code>weight = 1 / (distance + epsilon)</code></li>\n<li>For each unique class, sum the weights of neighbors belonging to that class</li>\n<li>Select the class with the highest total weight as the prediction</li>\n<li>Handle zero distances by setting epsilon to a small positive value (e.g., 1e-10)</li>\n</ol>\n<p>The mathematical formulation for weighted voting is:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>class_weight(c) = sum(1 / (distance_i + epsilon)) for all neighbors i where label_i = c\nprediction = argmax(class_weight(c)) for c in unique_neighbor_classes</code></pre></div>\n\n<p>This weighting scheme ensures that a neighbor at distance 0.1 has 10 times more influence than a neighbor at distance 1.0, reflecting the assumption that very similar examples should dominate the prediction. The epsilon term prevents division by zero when a query point exactly matches a training point.</p>\n<h4 id=\"confidence-scoring\">Confidence Scoring</h4>\n<p>Both voting strategies can generate confidence scores that indicate the certainty of the prediction. Confidence scoring provides valuable information about prediction reliability and helps identify cases where the classifier is uncertain.</p>\n<p>For majority voting, confidence is calculated as the proportion of neighbors voting for the winning class:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>confidence = count(winning_class) / k</code></pre></div>\n\n<p>For weighted voting, confidence represents the proportion of total weight assigned to the winning class:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>confidence = weight(winning_class) / sum(weight(all_classes))</code></pre></div>\n\n<p>High confidence scores (close to 1.0) indicate strong agreement among neighbors, while low scores (close to 1/number_of_classes) suggest high uncertainty with neighbors split among multiple classes.</p>\n<h3 id=\"architecture-decisions-for-classification\">Architecture Decisions for Classification</h3>\n<blockquote>\n<p><strong>Decision: Voting Strategy Selection</strong></p>\n<ul>\n<li><strong>Context</strong>: The classifier must aggregate neighbor votes into final predictions, with options ranging from simple counting to sophisticated weighting schemes</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>Simple majority voting only</li>\n<li>Distance-weighted voting only  </li>\n<li>Configurable voting strategy with both options</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Implement configurable voting strategy supporting both majority and weighted voting</li>\n<li><strong>Rationale</strong>: Different datasets and scenarios benefit from different voting strategies - sparse data often benefits from weighted voting while dense, evenly distributed data works well with majority voting. Configurability allows experimentation and optimization.</li>\n<li><strong>Consequences</strong>: Increased implementation complexity but greater flexibility for optimization and experimentation. Enables comparative analysis of voting strategies on different datasets.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Pros</th>\n<th>Cons</th>\n<th>Chosen?</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Majority voting only</td>\n<td>Simple implementation, fast execution, interpretable results</td>\n<td>Ignores distance information, poor performance with varying neighbor distances</td>\n<td>No</td>\n</tr>\n<tr>\n<td>Weighted voting only</td>\n<td>Uses all available information, better handling of distance variations</td>\n<td>More complex, potential numerical instability with small distances</td>\n<td>No</td>\n</tr>\n<tr>\n<td>Configurable strategy</td>\n<td>Flexibility for different scenarios, enables comparison and optimization</td>\n<td>Increased code complexity, more parameters to tune</td>\n<td>Yes</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Tie-Breaking Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: When multiple classes receive equal votes (majority voting) or equal weights (weighted voting), the classifier must deterministically choose one class</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Random selection among tied classes</li>\n<li>Lexicographic ordering of class labels</li>\n<li>Selection based on nearest neighbor&#39;s class</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Use nearest neighbor&#39;s class for tie-breaking, with lexicographic fallback</li>\n<li><strong>Rationale</strong>: The nearest neighbor represents the most similar example and should have the strongest influence. Lexicographic ordering provides deterministic fallback when multiple tied classes have the same nearest neighbor distance.</li>\n<li><strong>Consequences</strong>: Deterministic and interpretable tie-breaking that prioritizes similarity. May introduce slight bias toward classes that appear early in lexicographic order in rare edge cases.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Pros</th>\n<th>Cons</th>\n<th>Chosen?</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Random selection</td>\n<td>Unbiased, simple to implement</td>\n<td>Non-deterministic results, poor user experience</td>\n<td>No</td>\n</tr>\n<tr>\n<td>Lexicographic ordering</td>\n<td>Deterministic, simple implementation</td>\n<td>May bias toward certain class labels, ignores distance information</td>\n<td>Partial</td>\n</tr>\n<tr>\n<td>Nearest neighbor class</td>\n<td>Uses similarity information, intuitive behavior</td>\n<td>Requires additional bookkeeping, complex with multiple equidistant neighbors</td>\n<td>Yes</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Confidence Score Calculation</strong></p>\n<ul>\n<li><strong>Context</strong>: Users need to understand prediction certainty for decision-making, especially in high-stakes applications</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>No confidence scores</li>\n<li>Vote proportion confidence</li>\n<li>Statistical significance testing</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Implement vote proportion confidence with separate calculations for majority and weighted voting</li>\n<li><strong>Rationale</strong>: Vote proportion is intuitive, computationally efficient, and provides meaningful uncertainty quantification. Statistical testing adds complexity without clear benefits for most use cases.</li>\n<li><strong>Consequences</strong>: Enables uncertainty-aware decision making and threshold-based prediction filtering. Simple calculation maintains performance while providing valuable information.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Pros</th>\n<th>Cons</th>\n<th>Chosen?</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>No confidence scores</td>\n<td>Simplest implementation, fastest execution</td>\n<td>No uncertainty quantification, limited decision support</td>\n<td>No</td>\n</tr>\n<tr>\n<td>Vote proportion</td>\n<td>Intuitive interpretation, efficient calculation, meaningful uncertainty measure</td>\n<td>Less sophisticated than statistical approaches</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>Statistical significance</td>\n<td>Rigorous uncertainty quantification, theoretical grounding</td>\n<td>Complex implementation, computational overhead, difficult interpretation</td>\n<td>No</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Handling Zero Distances</strong></p>\n<ul>\n<li><strong>Context</strong>: When query points exactly match training points (distance = 0), weighted voting faces division by zero</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Add small epsilon to all distances</li>\n<li>Special case handling for zero distances</li>\n<li>Use inverse square distances</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Add small epsilon (1e-10) to all distances uniformly</li>\n<li><strong>Rationale</strong>: Uniform epsilon addition is simple, numerically stable, and preserves relative distance relationships. The epsilon value is small enough to maintain strong preference for exact matches while preventing numerical issues.</li>\n<li><strong>Consequences</strong>: Prevents division by zero while maintaining intuitive behavior where exact matches dominate voting. Slightly modifies distance relationships but impact is negligible for practical purposes.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Pros</th>\n<th>Cons</th>\n<th>Chosen?</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Uniform epsilon addition</td>\n<td>Simple implementation, numerically stable, preserves relationships</td>\n<td>Slightly modifies distance relationships</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>Special case handling</td>\n<td>Mathematically pure, no distance modification</td>\n<td>Complex branching logic, potential edge cases</td>\n<td>No</td>\n</tr>\n<tr>\n<td>Inverse square distances</td>\n<td>Reduces sensitivity to distance variations</td>\n<td>Changes fundamental distance interpretation, may over-smooth</td>\n<td>No</td>\n</tr>\n</tbody></table>\n<h3 id=\"common-classification-pitfalls\">Common Classification Pitfalls</h3>\n<h4 id=\"-pitfall-voting-ties-with-even-k-values\">⚠️ <strong>Pitfall: Voting Ties with Even K Values</strong></h4>\n<p>When using an even number of neighbors (e.g., K=4) with binary classification, tie votes are common and can lead to inconsistent predictions. A query point with 2 neighbors from each class has no clear majority, forcing reliance on tie-breaking rules that may not reflect true class probabilities.</p>\n<p><strong>Why this occurs</strong>: Even K values create natural conditions for tied votes, especially in binary classification where 50-50 splits are mathematically likely. The tie-breaking mechanism becomes the primary decision factor rather than neighbor consensus.</p>\n<p><strong>How to avoid</strong>: Use odd K values (3, 5, 7, 9) to reduce tie probability, especially for binary classification problems. When even K values are necessary, ensure robust tie-breaking strategies and consider using weighted voting which is less susceptible to exact ties.</p>\n<p><strong>Detection</strong>: Monitor prediction confidence scores - frequent low confidence scores around 0.5 indicate excessive tie situations.</p>\n<h4 id=\"-pitfall-class-imbalance-bias-in-voting\">⚠️ <strong>Pitfall: Class Imbalance Bias in Voting</strong></h4>\n<p>In datasets with severe class imbalance (e.g., 90% class A, 10% class B), the KNN classifier tends to predict the majority class even when query points are close to minority class examples. This occurs because random sampling of neighbors is more likely to include majority class examples.</p>\n<p><strong>Why this occurs</strong>: The smoothness assumption of KNN breaks down in imbalanced datasets where minority class instances are sparse. Local neighborhoods tend to be dominated by majority class examples even near true minority class regions.</p>\n<p><strong>How to avoid</strong>: Use weighted voting to emphasize closer neighbors, consider stratified sampling for neighbor selection, or apply distance-based thresholding to ensure meaningful class representation in neighborhoods. Alternatively, use cost-sensitive voting where minority class votes receive higher weights.</p>\n<p><strong>Detection</strong>: Calculate per-class recall metrics - low recall for minority classes indicates imbalance bias.</p>\n<h4 id=\"-pitfall-inappropriate-k-parameter-selection\">⚠️ <strong>Pitfall: Inappropriate K Parameter Selection</strong></h4>\n<p>Choosing K too small (K=1) leads to high variance and sensitivity to outliers, where single noisy examples can dominate predictions. Choosing K too large approaches global class distribution, losing the benefits of local similarity and potentially causing underfitting.</p>\n<p><strong>Why this occurs</strong>: K parameter directly controls the bias-variance tradeoff. Small K gives low bias but high variance (overfitting to local noise), while large K gives low variance but high bias (underfitting to global patterns).</p>\n<p><strong>How to avoid</strong>: Use cross-validation to systematically evaluate different K values on your specific dataset. Start with K = sqrt(n_samples) as a rule-of-thumb, then test odd values in the range [1, sqrt(n_samples) * 2]. Monitor both training and validation accuracy to detect overfitting.</p>\n<p><strong>Detection</strong>: Plot learning curves showing training and validation accuracy versus K - optimal K minimizes validation error while maintaining reasonable training performance.</p>\n<h4 id=\"-pitfall-distance-metric-mismatch-with-voting-strategy\">⚠️ <strong>Pitfall: Distance Metric Mismatch with Voting Strategy</strong></h4>\n<p>Using distance metrics that don&#39;t align with the classification task characteristics leads to poor neighbor selection and voting outcomes. For example, using Euclidean distance on high-dimensional sparse data (curse of dimensionality) or cosine distance on data where magnitude matters.</p>\n<p><strong>Why this occurs</strong>: Different distance metrics capture different notions of similarity. Euclidean distance measures geometric proximity, Manhattan distance measures coordinate-wise differences, and cosine distance measures angular similarity. Mismatched metrics produce irrelevant neighbors.</p>\n<p><strong>How to avoid</strong>: Understand your data characteristics and choose appropriate distance metrics. Use Euclidean for continuous features with meaningful magnitude, Manhattan for categorical or ordinal features, and cosine for high-dimensional sparse features. Validate metric choice through cross-validation experiments.</p>\n<p><strong>Detection</strong>: Compare classification accuracy across different distance metrics - significant performance differences indicate metric sensitivity.</p>\n<h4 id=\"-pitfall-numerical-instability-in-weighted-voting\">⚠️ <strong>Pitfall: Numerical Instability in Weighted Voting</strong></h4>\n<p>When neighbors have very small distances (near zero), the inverse distance weighting can produce extremely large weights that dominate the voting process. This creates numerical instability and reduces the influence of other relevant neighbors to negligible levels.</p>\n<p><strong>Why this occurs</strong>: The 1/distance weighting scheme amplifies small distance differences into large weight differences. A neighbor at distance 0.001 receives 1000 times more weight than a neighbor at distance 1.0, creating extreme imbalances.</p>\n<p><strong>How to avoid</strong>: Add a small epsilon value to all distances before inversion, use alternative weighting schemes like Gaussian weights (exp(-distance²)), or implement weight normalization to prevent extreme values.</p>\n<p><strong>Detection</strong>: Monitor weight distributions during voting - weights varying by more than 3-4 orders of magnitude indicate potential instability.</p>\n<h4 id=\"-pitfall-ignoring-feature-scale-differences\">⚠️ <strong>Pitfall: Ignoring Feature Scale Differences</strong></h4>\n<p>When features have vastly different scales (e.g., age in years vs. income in dollars), distance calculations become dominated by high-magnitude features, leading to poor neighbor selection and biased voting outcomes.</p>\n<p><strong>Why this occurs</strong>: Distance metrics sum contributions from all features, so features with larger scales contribute disproportionately to distance calculations. A $1000 income difference might overshadow a 10-year age difference even when age is more predictive.</p>\n<p><strong>How to avoid</strong>: Apply feature scaling (standardization or normalization) before distance calculation. Standardization (mean=0, std=1) works well for normally distributed features, while min-max normalization (range [0,1]) suits features with known bounds.</p>\n<p><strong>Detection</strong>: Examine feature contributions to distance calculations - if one feature consistently dominates distances, scaling is likely needed.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Voting Logic</td>\n<td>Dictionary counting with max()</td>\n<td>NumPy vectorized operations with bincount</td>\n</tr>\n<tr>\n<td>Confidence Scoring</td>\n<td>Basic proportion calculation</td>\n<td>Statistical confidence intervals</td>\n</tr>\n<tr>\n<td>Tie Breaking</td>\n<td>Simple lexicographic ordering</td>\n<td>Sophisticated multi-criteria decision</td>\n</tr>\n<tr>\n<td>Weight Calculation</td>\n<td>Direct inverse distance</td>\n<td>Gaussian or exponential decay functions</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>src/knn_classifier/\n  classification/\n    __init__.py              ← expose main KNNClassifier class\n    classifier.py            ← core KNNClassifier implementation\n    voting_strategies.py     ← majority and weighted voting algorithms\n    confidence_calculator.py ← confidence scoring logic\n    tie_breaker.py          ← tie resolution strategies\n  tests/\n    test_classifier.py       ← classifier interface tests\n    test_voting.py          ← voting algorithm tests\n    test_confidence.py      ← confidence calculation tests</code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Complete voting strategy implementations for KNN classification.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Copy this file and use these functions in your KNNClassifier.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Dict, Set, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> collections </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Counter</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> VotingStrategy</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    MAJORITY</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"majority\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    WEIGHTED</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"weighted\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> majority_vote</span><span style=\"color:#E1E4E8\">(neighbor_labels: List, k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Complete implementation of majority voting for KNN classification.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns the most frequent class and confidence score.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Count frequency of each class</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    vote_counts </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Counter(neighbor_labels[:k])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Find class with maximum votes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    winning_class </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> vote_counts.most_common(</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">)[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">][</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    winning_votes </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> vote_counts[winning_class]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Calculate confidence as proportion of votes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    confidence </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> winning_votes </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> k</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> winning_class, confidence</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> weighted_vote</span><span style=\"color:#E1E4E8\">(neighbor_labels: List, neighbor_distances: np.ndarray, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                  k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, epsilon: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1e-10</span><span style=\"color:#E1E4E8\">) -> Tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Complete implementation of weighted voting for KNN classification.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Weights votes by inverse distance to give closer neighbors more influence.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Calculate weights as inverse distances with epsilon for stability</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    weights </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 1.0</span><span style=\"color:#F97583\"> /</span><span style=\"color:#E1E4E8\"> (neighbor_distances[:k] </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> epsilon)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Accumulate weights for each class</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    class_weights </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> label, weight </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> zip</span><span style=\"color:#E1E4E8\">(neighbor_labels[:k], weights):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        class_weights[label] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> class_weights.get(label, </span><span style=\"color:#79B8FF\">0.0</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> weight</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Find class with maximum total weight</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    winning_class </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> max</span><span style=\"color:#E1E4E8\">(class_weights, </span><span style=\"color:#FFAB70\">key</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">class_weights.get)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    winning_weight </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> class_weights[winning_class]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Calculate confidence as proportion of total weight</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    total_weight </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> sum</span><span style=\"color:#E1E4E8\">(class_weights.values())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    confidence </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> winning_weight </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> total_weight</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> winning_class, confidence</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> resolve_ties</span><span style=\"color:#E1E4E8\">(tied_classes: List, neighbor_labels: List, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                neighbor_distances: np.ndarray) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Complete tie-breaking implementation using nearest neighbor's class.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Falls back to lexicographic ordering if nearest neighbor ties exist.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Find the class of the nearest neighbor</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    nearest_class </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> neighbor_labels[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # If nearest neighbor's class is among tied classes, choose it</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> nearest_class </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> tied_classes:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> nearest_class</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Otherwise, fall back to lexicographic ordering</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> min</span><span style=\"color:#E1E4E8\">(tied_classes)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ConfidenceCalculator</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Complete confidence scoring implementation for both voting strategies.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">staticmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> majority_confidence</span><span style=\"color:#E1E4E8\">(class_counts: Dict, total_votes: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate confidence for majority voting as vote proportion.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        max_votes </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> max</span><span style=\"color:#E1E4E8\">(class_counts.values())</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> max_votes </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> total_votes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">staticmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> weighted_confidence</span><span style=\"color:#E1E4E8\">(class_weights: Dict) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate confidence for weighted voting as weight proportion.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        total_weight </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> sum</span><span style=\"color:#E1E4E8\">(class_weights.values())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        max_weight </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> max</span><span style=\"color:#E1E4E8\">(class_weights.values())</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> max_weight </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> total_weight</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">staticmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> uncertainty_threshold</span><span style=\"color:#E1E4E8\">(confidence: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">, threshold: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0.5</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Determine if prediction meets minimum confidence threshold.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> confidence </span><span style=\"color:#F97583\">>=</span><span style=\"color:#E1E4E8\"> threshold</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeleton-code\">Core Logic Skeleton Code</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> KNNClassifier</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    K-Nearest Neighbors classifier with configurable voting strategies.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Implements lazy learning with majority and weighted voting options.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 3</span><span style=\"color:#E1E4E8\">, distance_metric: DistanceMetric </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> DistanceMetric.</span><span style=\"color:#79B8FF\">EUCLIDEAN</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 weighted_voting: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> False</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Initialize classifier parameters (k, distance_metric, weighted_voting)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Initialize training_data as None (lazy learning - no training computation)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Validate k parameter is positive integer</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> fit</span><span style=\"color:#E1E4E8\">(self, X: FeatureMatrix, y: List[ClassLabel]) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Store training data for lazy learning without performing computation.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        KNN defers all computation to prediction time.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate input dimensions - X and y must have same number of samples</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Create TrainingData object with features=X, labels=y</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Calculate and store n_samples, n_features from X.shape</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Extract unique_classes from y using set() conversion</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Store TrainingData object in self.training_data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: No computation occurs here - this is lazy learning</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> predict</span><span style=\"color:#E1E4E8\">(self, X: FeatureMatrix) -> List[ClassLabel]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Predict class labels for query points using configured voting strategy.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check that model is fitted (self.training_data is not None)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: For each query point in X, call self._predict_single_point</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Extract predicted_class from each PredictionResult</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return list of predicted class labels</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use list comprehension for efficiency</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> predict_with_confidence</span><span style=\"color:#E1E4E8\">(self, X: FeatureMatrix) -> List[PredictionResult]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Predict with detailed neighbor and confidence information.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check that model is fitted (self.training_data is not None)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: For each query point in X, call self._predict_single_point</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return list of complete PredictionResult objects</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _predict_single_point</span><span style=\"color:#E1E4E8\">(self, query_point: FeatureVector) -> PredictionResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Core prediction logic for single query point.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Coordinates neighbor finding and voting to produce final prediction.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Find K nearest neighbors using self._find_neighbors</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Extract neighbor labels using neighbor indices</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Apply voting strategy (majority or weighted) using self._vote</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Calculate confidence score using self._calculate_confidence</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Create and return PredictionResult object</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: This method orchestrates the entire prediction pipeline</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _find_neighbors</span><span style=\"color:#E1E4E8\">(self, query_point: FeatureVector) -> Tuple[NeighborIndices, DistanceArray]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Find K nearest neighbors to query point using configured distance metric.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Calculate distances from query_point to all training samples</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Use np.argsort to get indices sorted by distance</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Select first K indices and corresponding distances</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Validate that K &#x3C;= number of training samples</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return neighbor indices and distances as tuple</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use calculate_distances_to_point from distance metrics component</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _vote</span><span style=\"color:#E1E4E8\">(self, neighbor_labels: List[ClassLabel], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">             neighbor_distances: DistanceArray) -> Tuple[ClassLabel, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Apply voting strategy to determine predicted class and confidence.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.weighted_voting:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Call weighted_vote with labels and distances</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Handle potential ties using resolve_ties function</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return winning class and confidence score</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Call majority_vote with neighbor labels</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Handle potential ties using resolve_ties function  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return winning class and confidence score</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> set_k_parameter</span><span style=\"color:#E1E4E8\">(self, k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Update the number of neighbors for voting.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate k is positive integer</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: If model is fitted, validate k &#x3C;= n_samples</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Update self.k parameter</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> set_voting_strategy</span><span style=\"color:#E1E4E8\">(self, weighted: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Configure voting strategy between majority and weighted voting.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Update self.weighted_voting parameter</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Log strategy change for debugging</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"language-specific-hints\">Language-Specific Hints</h4>\n<p><strong>NumPy Operations for Efficient Voting:</strong></p>\n<ul>\n<li>Use <code>np.bincount()</code> for fast frequency counting in majority voting</li>\n<li>Use <code>np.argsort()</code> for efficient neighbor sorting by distance  </li>\n<li>Use <code>collections.Counter</code> for readable class frequency counting</li>\n<li>Use <code>np.argmax()</code> to find winning class efficiently</li>\n</ul>\n<p><strong>Handling Edge Cases:</strong></p>\n<ul>\n<li>Check for empty neighbor lists before voting (K &gt; dataset size)</li>\n<li>Handle single-class datasets by returning that class with confidence 1.0</li>\n<li>Use <code>np.isfinite()</code> to detect invalid distances from numerical errors</li>\n<li>Implement graceful degradation when K exceeds available neighbors</li>\n</ul>\n<p><strong>Performance Optimization:</strong></p>\n<ul>\n<li>Pre-compute distance matrices for small datasets (&lt; 1000 samples)</li>\n<li>Use vectorized operations instead of Python loops for distance calculations</li>\n<li>Cache neighbor computations for repeated queries to same points</li>\n<li>Consider using <code>numba.jit</code> decorator for hot path functions</li>\n</ul>\n<h4 id=\"milestone-checkpoint\">Milestone Checkpoint</h4>\n<p>After implementing the classification component, verify correct behavior:</p>\n<p><strong>Test Commands:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/test_classifier.py</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/test_voting.py</span><span style=\"color:#79B8FF\"> -v</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> test_classification_integration.py</span></span></code></pre></div>\n\n<p><strong>Expected Behavior:</strong></p>\n<ul>\n<li>Majority voting produces deterministic results for the same inputs</li>\n<li>Weighted voting gives higher influence to closer neighbors</li>\n<li>Confidence scores range between 0 and 1 with intuitive interpretation</li>\n<li>Tie-breaking produces consistent results across runs</li>\n<li>Edge cases (K=1, single class data) handle gracefully</li>\n</ul>\n<p><strong>Manual Verification:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Create simple test case</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">X_train </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.array([[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">], [</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">], [</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">], [</span><span style=\"color:#79B8FF\">3</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">3</span><span style=\"color:#E1E4E8\">]])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">y_train </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span><span style=\"color:#9ECBFF\">'A'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'A'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'B'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'B'</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">classifier </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> KNNClassifier(</span><span style=\"color:#FFAB70\">k</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">3</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">weighted_voting</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">classifier.fit(X_train, y_train)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test prediction</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">query </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.array([[</span><span style=\"color:#79B8FF\">1.5</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1.5</span><span style=\"color:#E1E4E8\">]])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">result </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> classifier.predict_with_confidence(query)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Prediction: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">result[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">].predicted_class</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Confidence: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">result[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">].confidence</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Neighbors: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">result[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">].neighbor_indices</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p><strong>Expected Output:</strong></p>\n<ul>\n<li>Prediction should reflect majority class among 3 nearest neighbors</li>\n<li>Confidence should be 0.67 or 1.0 depending on class distribution</li>\n<li>Neighbor indices should be [1, 2, 0] or similar based on distances</li>\n</ul>\n<h2 id=\"evaluation-and-optimization-component\">Evaluation and Optimization Component</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Milestone 3: Improvements &amp; Evaluation - implements cross-validation, hyperparameter tuning, and performance metrics to find optimal K values and assess model quality</p>\n</blockquote>\n<p>The evaluation and optimization component transforms our KNN classifier from a basic prototype into a scientifically rigorous machine learning system. This component addresses the fundamental question that haunts every machine learning practitioner: &quot;How do we know our model is actually good?&quot; More specifically for KNN, it tackles the critical challenge of selecting the optimal value of K - the hyperparameter that determines how many neighbors influence each prediction.</p>\n<p>This component implements the scientific method for machine learning: systematic experimentation through cross-validation, objective measurement through comprehensive metrics, and evidence-based optimization through grid search. Without proper evaluation, our KNN classifier would be like a compass without calibration - it might point somewhere, but we wouldn&#39;t know if that direction leads us toward accurate predictions or away from them.</p>\n<h3 id=\"mental-model-scientific-testing\">Mental Model: Scientific Testing</h3>\n<p>Understanding rigorous evaluation requires thinking like a scientist conducting experiments. Imagine you&#39;re a medical researcher testing a new treatment. You can&#39;t simply give the treatment to patients and declare success based on gut feeling - you need controlled experiments, statistical significance, and peer review.</p>\n<p><strong>The Laboratory Analogy</strong>: Think of cross-validation as running multiple controlled experiments in separate laboratories. Each laboratory (fold) gets a different subset of patients (training data) to develop the treatment protocol, then tests it on a completely separate group of patients (validation data) who were never seen during protocol development. Only by repeating this experiment across multiple independent laboratories can we trust that our treatment works beyond the specific patients we happened to encounter.</p>\n<p><strong>The Hypothesis Testing Mindset</strong>: In our KNN context, each K value represents a different hypothesis about how many neighbors should influence decisions. K=1 hypothesizes that only the single closest neighbor matters - like asking only your best friend for advice. K=50 hypothesizes that we need a large community consensus - like surveying the entire neighborhood before making a decision. Cross-validation provides the experimental framework to test these competing hypotheses objectively.</p>\n<p><strong>The Measurement Precision Principle</strong>: Just as scientists use multiple measurement instruments to reduce error, we compute multiple evaluation metrics (accuracy, precision, recall, F1-score) to capture different aspects of model performance. A model might achieve high accuracy by correctly predicting the majority class while completely failing on minority classes - something that precision and recall would reveal but accuracy alone might hide.</p>\n<p><strong>The Reproducibility Standard</strong>: Scientific results must be reproducible by independent researchers. Similarly, our evaluation framework must produce consistent results across multiple runs through careful random seed management and standardized data splitting procedures. This ensures that our &quot;discovery&quot; of the optimal K value isn&#39;t just a lucky accident of data shuffling.</p>\n<h3 id=\"evaluation-interface\">Evaluation Interface</h3>\n<p>The evaluation interface provides the methods and contracts that enable systematic assessment of KNN performance across different configurations and datasets. This interface abstracts the complexity of statistical validation while exposing the essential controls that researchers and practitioners need for rigorous model evaluation.</p>\n<p>The core responsibility of this interface is to separate the concerns of model training from model assessment. During evaluation, the interface ensures that no information from validation data leaks into the training process - a principle as fundamental to machine learning as sterilization is to medical research.</p>\n<table>\n<thead>\n<tr>\n<th>Method Name</th>\n<th>Parameters</th>\n<th>Returns</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>k_fold_cross_validate</code></td>\n<td><code>X: FeatureMatrix, y: List[ClassLabel], k_folds: int, k_neighbors: int, distance_metric: DistanceMetric, random_seed: int</code></td>\n<td><code>CrossValidationResult</code></td>\n<td>Performs K-fold cross-validation and returns aggregated performance metrics across all folds</td>\n</tr>\n<tr>\n<td><code>grid_search_k</code></td>\n<td><code>X: FeatureMatrix, y: List[ClassLabel], k_values: List[int], cv_folds: int, distance_metric: DistanceMetric, random_seed: int</code></td>\n<td><code>GridSearchResult</code></td>\n<td>Tests multiple K values through cross-validation to find optimal hyperparameter</td>\n</tr>\n<tr>\n<td><code>calculate_confusion_matrix</code></td>\n<td><code>y_true: List[ClassLabel], y_pred: List[ClassLabel], class_labels: List[ClassLabel]</code></td>\n<td><code>ConfusionMatrix</code></td>\n<td>Computes confusion matrix showing true vs predicted classifications for each class</td>\n</tr>\n<tr>\n<td><code>calculate_classification_metrics</code></td>\n<td><code>y_true: List[ClassLabel], y_pred: List[ClassLabel], average: str</code></td>\n<td><code>ClassificationMetrics</code></td>\n<td>Calculates precision, recall, F1-score, and accuracy with support for micro/macro/weighted averaging</td>\n</tr>\n<tr>\n<td><code>split_stratified_folds</code></td>\n<td><code>X: FeatureMatrix, y: List[ClassLabel], n_folds: int, random_seed: int</code></td>\n<td><code>List[FoldIndices]</code></td>\n<td>Creates stratified train/validation splits that preserve class distribution across folds</td>\n</tr>\n<tr>\n<td><code>validate_evaluation_parameters</code></td>\n<td><code>X: FeatureMatrix, y: List[ClassLabel], k_values: List[int], cv_folds: int</code></td>\n<td><code>None</code></td>\n<td>Validates that evaluation parameters are consistent with dataset size and constraints</td>\n</tr>\n</tbody></table>\n<p>The interface design follows the principle of <strong>separation of statistical concerns</strong>. Each method handles one specific aspect of evaluation: data splitting, metric calculation, hyperparameter search, or result aggregation. This modular approach allows users to compose complex evaluation pipelines while maintaining clear boundaries between different statistical operations.</p>\n<p><strong>Key Design Principles</strong>:</p>\n<p><strong>Deterministic Reproducibility</strong>: All methods accept random seed parameters to ensure that evaluation results can be exactly reproduced across different runs and environments. This determinism is crucial for scientific validity and debugging evaluation pipelines.</p>\n<p><strong>Stratified Sampling</strong>: The interface enforces stratified sampling for cross-validation splits, ensuring that each fold maintains the same class distribution as the original dataset. This prevents evaluation artifacts where some folds accidentally exclude entire classes.</p>\n<p><strong>Comprehensive Metric Coverage</strong>: Rather than returning only accuracy, the interface computes the full spectrum of classification metrics. This comprehensive approach reveals model weaknesses that single metrics might hide.</p>\n<p><strong>Parameter Validation</strong>: The interface includes explicit validation methods that check for common configuration errors before expensive evaluation begins. This fail-fast approach saves computational time and prevents misleading results from invalid configurations.</p>\n<h3 id=\"evaluation-algorithms\">Evaluation Algorithms</h3>\n<p>The evaluation algorithms implement the statistical procedures that transform raw predictions into meaningful performance assessments. These algorithms must handle the delicate balance between computational efficiency and statistical rigor while avoiding the subtle pitfalls that can invalidate machine learning experiments.</p>\n<h4 id=\"k-fold-cross-validation-algorithm\">K-Fold Cross-Validation Algorithm</h4>\n<p>K-fold cross-validation serves as the foundation for all rigorous evaluation in our system. This algorithm addresses the fundamental challenge of limited data: how do we get reliable performance estimates when we can&#39;t afford to hold out a large validation set?</p>\n<p><img src=\"/api/project/knn/architecture-doc/asset?path=diagrams%2Fcross-validation.svg\" alt=\"Cross-Validation State Machine\"></p>\n<p>The cross-validation algorithm operates through a carefully orchestrated sequence of data partitioning, model training, and performance measurement:</p>\n<ol>\n<li><p><strong>Stratified Data Partitioning</strong>: The algorithm begins by dividing the dataset into K approximately equal folds while preserving the original class distribution in each fold. This stratification prevents evaluation bias where some folds accidentally under-represent or completely exclude certain classes.</p>\n</li>\n<li><p><strong>Fold Iteration Setup</strong>: For each of the K iterations, the algorithm designates one fold as the validation set and combines the remaining K-1 folds into the training set. This ensures that every data point is used for validation exactly once across all iterations.</p>\n</li>\n<li><p><strong>Isolated Model Training</strong>: Within each iteration, the algorithm creates a fresh <code>KNNClassifier</code> instance and trains it exclusively on the training fold data. This isolation prevents information leakage between iterations and ensures that each performance measurement is independent.</p>\n</li>\n<li><p><strong>Validation Prediction</strong>: The trained model makes predictions on the validation fold data - data that was completely hidden during training. The algorithm collects these predictions along with the true labels for metric calculation.</p>\n</li>\n<li><p><strong>Per-Fold Metric Calculation</strong>: The algorithm computes the full suite of classification metrics (accuracy, precision, recall, F1-score) for each fold&#39;s predictions. These per-fold metrics reveal the consistency of model performance across different data subsets.</p>\n</li>\n<li><p><strong>Statistical Aggregation</strong>: After all K iterations complete, the algorithm aggregates the per-fold metrics using both mean and standard deviation calculations. The mean provides the expected performance estimate while the standard deviation indicates performance stability.</p>\n</li>\n<li><p><strong>Confidence Interval Computation</strong>: The algorithm calculates confidence intervals around the mean performance estimates using the standard error of the mean. These intervals provide statistical bounds on the true performance values.</p>\n</li>\n</ol>\n<h4 id=\"grid-search-optimization-algorithm\">Grid Search Optimization Algorithm</h4>\n<p>The grid search algorithm systematically explores the hyperparameter space to identify the K value that maximizes cross-validated performance. This exhaustive search approach guarantees finding the optimal K within the specified search range.</p>\n<p><img src=\"/api/project/knn/architecture-doc/asset?path=diagrams%2Fhyperparameter-optimization.svg\" alt=\"Hyperparameter Optimization Flow\"></p>\n<p>The grid search process follows a nested optimization structure:</p>\n<ol>\n<li><p><strong>Parameter Space Definition</strong>: The algorithm accepts a list of K values to evaluate, typically ranging from 1 to some maximum value determined by dataset size and computational constraints.</p>\n</li>\n<li><p><strong>Outer Loop: K Value Iteration</strong>: For each candidate K value, the algorithm initiates a complete cross-validation experiment. This outer loop ensures that every K value receives identical evaluation treatment.</p>\n</li>\n<li><p><strong>Inner Loop: Cross-Validation Execution</strong>: Within each K value iteration, the algorithm runs the full K-fold cross-validation procedure described above. This inner loop produces the performance estimate for the current K value.</p>\n</li>\n<li><p><strong>Performance Tracking</strong>: The algorithm maintains a performance history that records the mean and standard deviation of each metric for every K value tested. This history enables comprehensive analysis of the hyperparameter sensitivity.</p>\n</li>\n<li><p><strong>Optimal K Selection</strong>: After evaluating all candidate K values, the algorithm selects the K that maximizes the primary optimization metric (typically cross-validated accuracy). In case of ties, the algorithm applies a tie-breaking rule favoring smaller K values to reduce model complexity.</p>\n</li>\n<li><p><strong>Statistical Significance Testing</strong>: The algorithm performs statistical significance tests to determine whether the performance differences between different K values are statistically meaningful or simply due to random variation.</p>\n</li>\n<li><p><strong>Final Model Training</strong>: Once the optimal K is identified, the algorithm trains a final model using the optimal K and the entire dataset to produce the production-ready classifier.</p>\n</li>\n</ol>\n<h4 id=\"confusion-matrix-algorithm\">Confusion Matrix Algorithm</h4>\n<p>The confusion matrix algorithm provides detailed insight into model behavior by tabulating the relationship between predicted and actual class labels. This tabulation reveals patterns of misclassification that aggregate metrics might obscure.</p>\n<p>The confusion matrix construction follows these steps:</p>\n<ol>\n<li><p><strong>Class Label Enumeration</strong>: The algorithm identifies all unique class labels present in either the true labels or predicted labels, ensuring that the matrix accommodates all possible classification outcomes.</p>\n</li>\n<li><p><strong>Matrix Initialization</strong>: The algorithm creates a square matrix with dimensions equal to the number of unique classes, initializing all entries to zero. The matrix rows represent true classes while columns represent predicted classes.</p>\n</li>\n<li><p><strong>Prediction Tabulation</strong>: For each prediction-truth pair, the algorithm increments the appropriate matrix cell. The cell at position (i, j) counts the number of times class i was predicted as class j.</p>\n</li>\n<li><p><strong>Normalization Options</strong>: The algorithm supports multiple normalization schemes: raw counts, row-wise normalization (showing the distribution of predictions for each true class), and overall normalization (showing proportions of the total predictions).</p>\n</li>\n<li><p><strong>Diagonal Analysis</strong>: The algorithm identifies the diagonal elements (correct predictions) and off-diagonal elements (misclassifications) to compute class-specific accuracy rates and confusion patterns.</p>\n</li>\n<li><p><strong>Metric Derivation</strong>: From the confusion matrix, the algorithm derives per-class precision, recall, and F1-score values by analyzing the row and column sums relative to the diagonal elements.</p>\n</li>\n</ol>\n<h3 id=\"architecture-decisions-for-evaluation\">Architecture Decisions for Evaluation</h3>\n<p>The evaluation component requires several critical architectural decisions that balance statistical rigor with computational efficiency. These decisions shape how our system approaches the fundamental trade-offs in machine learning evaluation.</p>\n<blockquote>\n<p><strong>Decision: Cross-Validation Strategy Selection</strong></p>\n<ul>\n<li><strong>Context</strong>: Multiple validation strategies exist (holdout, K-fold, leave-one-out, bootstrap), each with different statistical properties and computational costs. KNN evaluation needs reliable performance estimates while managing computational expense.</li>\n<li><strong>Options Considered</strong>: <ul>\n<li>Holdout validation (single train/test split)</li>\n<li>K-fold cross-validation (multiple train/test splits)</li>\n<li>Leave-one-out cross-validation (N train/test splits where N is dataset size)</li>\n</ul>\n</li>\n<li><strong>Decision</strong>: Implement K-fold cross-validation as the primary strategy with configurable fold count</li>\n<li><strong>Rationale</strong>: K-fold provides the optimal balance between statistical reliability and computational feasibility. Holdout validation wastes data and provides unstable estimates. Leave-one-out is computationally prohibitive for large datasets and can have high variance. K-fold with K=5 or K=10 provides robust estimates while remaining computationally tractable.</li>\n<li><strong>Consequences</strong>: Enables reliable performance estimation for datasets of varying sizes. Introduces complexity in data splitting and aggregation logic. Requires careful handling of stratification to maintain class balance across folds.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Pros</th>\n<th>Cons</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Holdout Validation</td>\n<td>Simple implementation, fast execution</td>\n<td>Wastes training data, unstable estimates, sensitive to data split</td>\n</tr>\n<tr>\n<td>K-Fold Cross-Validation</td>\n<td>Reliable estimates, efficient data use, tunable accuracy/speed tradeoff</td>\n<td>Moderate complexity, requires stratification logic</td>\n</tr>\n<tr>\n<td>Leave-One-Out</td>\n<td>Maximum data utilization, deterministic results</td>\n<td>Computationally expensive, high variance estimates</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Hyperparameter Search Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: KNN&#39;s primary hyperparameter K requires optimization, but the search space and optimization strategy affect both performance quality and computational cost. Different search strategies offer different trade-offs between thoroughness and efficiency.</li>\n<li><strong>Options Considered</strong>:<ul>\n<li>Exhaustive grid search over all K values</li>\n<li>Random search with early stopping</li>\n<li>Bayesian optimization with Gaussian processes</li>\n</ul>\n</li>\n<li><strong>Decision</strong>: Implement exhaustive grid search with user-defined K ranges</li>\n<li><strong>Rationale</strong>: KNN&#39;s hyperparameter space is one-dimensional and discrete, making exhaustive search computationally feasible. Grid search guarantees finding the global optimum within the search range. Random search and Bayesian optimization add complexity without significant benefits for such a simple parameter space.</li>\n<li><strong>Consequences</strong>: Guarantees optimal K discovery within search bounds. Simple implementation and debugging. Can be computationally expensive for large K ranges, but this is manageable with reasonable range selection.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Pros</th>\n<th>Cons</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Grid Search</td>\n<td>Guaranteed global optimum, simple implementation, deterministic results</td>\n<td>Can be computationally expensive for large ranges</td>\n</tr>\n<tr>\n<td>Random Search</td>\n<td>Efficient for high-dimensional spaces, can find good solutions quickly</td>\n<td>No optimality guarantee, less thorough than grid search</td>\n</tr>\n<tr>\n<td>Bayesian Optimization</td>\n<td>Intelligent search guidance, efficient in expensive evaluation scenarios</td>\n<td>Complex implementation, overkill for 1D parameter space</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Evaluation Metric Selection</strong></p>\n<ul>\n<li><strong>Context</strong>: Classification performance can be measured through various metrics (accuracy, precision, recall, F1-score, AUC), each emphasizing different aspects of model behavior. The choice affects how we define &quot;optimal&quot; performance and influences hyperparameter selection.</li>\n<li><strong>Options Considered</strong>:<ul>\n<li>Accuracy only (simple but potentially misleading)</li>\n<li>F1-score only (balanced precision/recall)</li>\n<li>Comprehensive metric suite (accuracy, precision, recall, F1)</li>\n</ul>\n</li>\n<li><strong>Decision</strong>: Implement comprehensive metric calculation with accuracy as the primary optimization target</li>\n<li><strong>Rationale</strong>: Different metrics reveal different model characteristics. Accuracy alone can be misleading with imbalanced datasets. Precision and recall provide insight into class-specific performance. F1-score balances precision and recall. Computing all metrics provides complete performance picture while using accuracy for optimization maintains simplicity.</li>\n<li><strong>Consequences</strong>: Provides complete performance assessment for thorough model evaluation. Enables detection of class-specific performance issues. Adds computational overhead and complexity in metric calculation and reporting.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Pros</th>\n<th>Cons</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Accuracy Only</td>\n<td>Simple implementation, widely understood, single optimization target</td>\n<td>Misleading with imbalanced data, hides class-specific issues</td>\n</tr>\n<tr>\n<td>F1-Score Only</td>\n<td>Balances precision/recall, robust to class imbalance</td>\n<td>Less intuitive than accuracy, single metric may miss nuances</td>\n</tr>\n<tr>\n<td>Comprehensive Suite</td>\n<td>Complete performance picture, reveals all model characteristics</td>\n<td>Complex reporting, potential confusion about optimization target</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Random Seed Management</strong></p>\n<ul>\n<li><strong>Context</strong>: Machine learning evaluation must be reproducible for scientific validity and debugging. Random processes in data splitting and tie-breaking can produce different results across runs. The system needs deterministic behavior while maintaining statistical validity.</li>\n<li><strong>Options Considered</strong>:<ul>\n<li>No seed management (non-reproducible results)</li>\n<li>Global random seed (simple but inflexible)</li>\n<li>Per-operation seed management (complex but flexible)</li>\n</ul>\n</li>\n<li><strong>Decision</strong>: Implement per-operation seed management with hierarchical seed derivation</li>\n<li><strong>Rationale</strong>: Reproducibility is essential for scientific machine learning. Global seeds are fragile and break when evaluation order changes. Per-operation seeds provide fine-grained control and robust reproducibility. Hierarchical derivation (master seed generates operation-specific seeds) balances simplicity with flexibility.</li>\n<li><strong>Consequences</strong>: Enables exact reproduction of evaluation results across different environments and runs. Adds complexity in seed management and propagation. Requires careful design to avoid seed correlation issues.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Pros</th>\n<th>Cons</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>No Seed Management</td>\n<td>Simple implementation, no additional complexity</td>\n<td>Non-reproducible results, impossible debugging</td>\n</tr>\n<tr>\n<td>Global Random Seed</td>\n<td>Easy to implement, single point of control</td>\n<td>Fragile to code changes, limited flexibility</td>\n</tr>\n<tr>\n<td>Per-Operation Seeds</td>\n<td>Robust reproducibility, fine-grained control</td>\n<td>Complex implementation, requires careful design</td>\n</tr>\n</tbody></table>\n<h3 id=\"common-evaluation-pitfalls\">Common Evaluation Pitfalls</h3>\n<p>Evaluation and optimization introduce subtle pitfalls that can invalidate experimental results or lead to overconfident performance estimates. These pitfalls often stem from the statistical complexities of cross-validation and the counterintuitive behaviors that emerge when optimizing over multiple hyperparameters.</p>\n<p>⚠️ <strong>Pitfall: Data Leakage Through Preprocessing</strong></p>\n<p>One of the most insidious evaluation errors occurs when data preprocessing steps (like feature scaling or normalization) are applied to the entire dataset before cross-validation splits. This seemingly innocent optimization creates subtle data leakage that inflates performance estimates.</p>\n<p><strong>Why it&#39;s wrong</strong>: When you scale features using statistics from the entire dataset, information from the validation set leaks into the training process. For example, if you compute the mean and standard deviation for feature normalization using all data, then split into folds, each training set already &quot;knows&quot; something about its corresponding validation set through these global statistics.</p>\n<p><strong>Concrete example</strong>: Consider a dataset where validation samples have systematically higher feature values than training samples. Global normalization would shift all values toward a global mean that includes validation data, making training samples artificially more similar to validation samples than they would be in real deployment.</p>\n<p><strong>How to avoid</strong>: Apply preprocessing separately within each cross-validation fold. Compute scaling parameters using only the training portion of each fold, then apply those parameters to both training and validation portions. This ensures that validation data remains truly unseen during the preprocessing phase.</p>\n<p>⚠️ <strong>Pitfall: Optimistic K Selection Through Multiple Testing</strong></p>\n<p>When testing many different K values through grid search, the multiple comparisons problem can lead to overly optimistic performance estimates. This occurs because random variation can make suboptimal K values appear superior by chance, especially when testing many values.</p>\n<p><strong>Why it&#39;s wrong</strong>: Each statistical test (comparing K values) has a probability of producing a false positive. When testing many K values, the probability that at least one produces an optimistically biased result increases dramatically. This is similar to flipping a coin many times - eventually you&#39;ll get a long streak of heads purely by chance.</p>\n<p><strong>Concrete example</strong>: Testing K values from 1 to 50 performs 50 different statistical experiments. Even if the true optimal K is 10, random variation might make K=23 appear superior in your particular dataset split. This &quot;discovered&quot; optimal K won&#39;t generalize to new data.</p>\n<p><strong>How to avoid</strong>: Apply statistical corrections for multiple testing, such as Bonferroni correction. Alternatively, use nested cross-validation where hyperparameter selection occurs within an inner cross-validation loop, and performance estimation occurs in an outer loop. Report confidence intervals rather than point estimates to acknowledge uncertainty.</p>\n<p>⚠️ <strong>Pitfall: Inappropriate K Values Relative to Dataset Size</strong></p>\n<p>Selecting K values that are too large relative to the dataset size can lead to meaningless cross-validation results and unstable performance estimates. This problem becomes particularly acute with small datasets or high numbers of cross-validation folds.</p>\n<p><strong>Why it&#39;s wrong</strong>: If K (number of neighbors) approaches the size of the training set in each cross-validation fold, the model behavior becomes dominated by the overall class distribution rather than local similarity patterns. Additionally, if the number of cross-validation folds is too high relative to dataset size, each fold contains too few samples for reliable training.</p>\n<p><strong>Concrete example</strong>: With a dataset of 100 samples using 10-fold cross-validation, each training fold contains only 90 samples. Testing K=80 means that 89% of the training data influences each prediction, essentially reducing KNN to a global vote rather than a local similarity-based decision.</p>\n<p><strong>How to avoid</strong>: Limit K to reasonable fractions of the training set size (typically K &lt; sqrt(n_training_samples)). Validate that cross-validation folds contain sufficient samples for meaningful training. Consider using fewer folds or stratified sampling for small datasets.</p>\n<p>⚠️ <strong>Pitfall: Ignoring Class Imbalance in Evaluation Metrics</strong></p>\n<p>Relying solely on accuracy for model evaluation can mask poor performance on minority classes, particularly problematic in imbalanced datasets where high accuracy can be achieved by simply predicting the majority class.</p>\n<p><strong>Why it&#39;s wrong</strong>: Accuracy treats all misclassifications equally, regardless of class frequency. In a dataset with 95% majority class samples, a model that never predicts the minority class still achieves 95% accuracy. This high accuracy masks the complete failure to learn minority class patterns.</p>\n<p><strong>Concrete example</strong>: In a medical diagnosis dataset with 1000 healthy patients and 50 disease cases, a model that always predicts &quot;healthy&quot; achieves 95% accuracy but provides zero clinical value since it fails to identify any actual disease cases.</p>\n<p><strong>How to avoid</strong>: Always compute and analyze precision, recall, and F1-score for each class individually. Use macro-averaged metrics that give equal weight to each class regardless of frequency. Consider using balanced accuracy or Cohen&#39;s kappa for imbalanced datasets. Examine the confusion matrix to understand per-class model behavior.</p>\n<p>⚠️ <strong>Pitfall: Hyperparameter Overfitting Through Extensive Search</strong></p>\n<p>Performing exhaustive grid search over very large hyperparameter ranges without proper validation can lead to hyperparameter overfitting, where the selected parameters perform well on the validation data but poorly on truly unseen data.</p>\n<p><strong>Why it&#39;s wrong</strong>: The hyperparameter selection process itself can overfit to the particular characteristics of your validation data. When testing hundreds of hyperparameter combinations, some will perform well purely by chance. The selected &quot;optimal&quot; hyperparameters may not generalize to new datasets.</p>\n<p><strong>Concrete example</strong>: Testing K values from 1 to 200 on a validation set might reveal that K=147 achieves the highest accuracy. However, this specific value likely reflects random patterns in your particular data split rather than a fundamental property of the optimal neighbor count.</p>\n<p><strong>How to avoid</strong>: Use nested cross-validation to separate hyperparameter selection from performance estimation. Limit hyperparameter search ranges to reasonable values based on domain knowledge. Report the distribution of optimal hyperparameters across different cross-validation folds to assess selection stability. Consider using simpler models when hyperparameter sensitivity is high.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The evaluation and optimization component requires sophisticated statistical machinery that can intimidate junior developers. This guidance provides complete, working implementations of the statistical infrastructure while clearly separating the core learning objectives (cross-validation logic and hyperparameter optimization) from the supporting utilities.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Statistical Computing</td>\n<td>NumPy + manual implementations</td>\n<td>SciPy with statistical functions</td>\n</tr>\n<tr>\n<td>Metric Calculation</td>\n<td>Manual precision/recall/F1 computation</td>\n<td>Scikit-learn metrics module</td>\n</tr>\n<tr>\n<td>Data Splitting</td>\n<td>Manual stratified splitting logic</td>\n<td>Scikit-learn StratifiedKFold</td>\n</tr>\n<tr>\n<td>Result Visualization</td>\n<td>Print statements with formatted tables</td>\n<td>Matplotlib for performance plots</td>\n</tr>\n<tr>\n<td>Random Number Generation</td>\n<td>NumPy random with manual seed management</td>\n<td>NumPy Generator with independent streams</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>knn-classifier/\n├── src/\n│   ├── evaluation/\n│   │   ├── __init__.py\n│   │   ├── cross_validation.py      ← Core learning: CV logic\n│   │   ├── metrics.py               ← Supporting: metric calculations  \n│   │   ├── hyperparameter_search.py ← Core learning: grid search\n│   │   └── statistical_utils.py     ← Supporting: statistical helpers\n│   ├── data/\n│   │   ├── splitting.py             ← Supporting: stratified splitting\n│   │   └── preprocessing.py         ← Supporting: scaling within folds\n│   └── utils/\n│       ├── random_utils.py          ← Supporting: seed management\n│       └── validation_utils.py      ← Supporting: parameter validation\n├── tests/\n│   ├── test_cross_validation.py\n│   ├── test_hyperparameter_search.py\n│   └── test_metrics.py\n└── examples/\n    └── evaluation_example.py        ← Complete usage demonstration</code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p><strong>Complete Random Seed Management (Supporting Infrastructure)</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># src/utils/random_utils.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ReproducibleRandom</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Manages hierarchical random seed generation for reproducible experiments.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, master_seed: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 42</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.master_seed </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> master_seed</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.rng </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.random.Generator(np.random.PCG64(master_seed))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> generate_fold_seeds</span><span style=\"color:#E1E4E8\">(self, n_folds: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> List[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate independent seeds for each cross-validation fold.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.rng.integers(</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">2</span><span style=\"color:#F97583\">**</span><span style=\"color:#79B8FF\">31</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">size</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">n_folds).tolist()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> generate_grid_search_seed</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate seed for hyperparameter grid search.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> int</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.rng.integers(</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">2</span><span style=\"color:#F97583\">**</span><span style=\"color:#79B8FF\">31</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> reset_with_seed</span><span style=\"color:#E1E4E8\">(self, seed: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Reset the generator with a specific seed.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.rng </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.random.Generator(np.random.PCG64(seed))</span></span></code></pre></div>\n\n<p><strong>Complete Stratified Splitting (Supporting Infrastructure)</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># src/data/splitting.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Tuple, Dict</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> collections </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Counter</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..types </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> FeatureMatrix, ClassLabel</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> StratifiedSplitter</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Creates stratified train/validation splits that preserve class distributions.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, random_seed: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 42</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.rng </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.random.Generator(np.random.PCG64(random_seed))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> create_k_folds</span><span style=\"color:#E1E4E8\">(self, y: List[ClassLabel], n_folds: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> List[Tuple[np.ndarray, np.ndarray]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Create K stratified folds maintaining class distribution in each fold.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            List of (train_indices, val_indices) tuples for each fold</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        n_samples </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(y)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        class_counts </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Counter(y)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Group indices by class</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        class_indices: Dict[ClassLabel, List[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> idx, label </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> enumerate</span><span style=\"color:#E1E4E8\">(y):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> label </span><span style=\"color:#F97583\">not</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> class_indices:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                class_indices[label] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            class_indices[label].append(idx)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Shuffle indices within each class</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> label </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> class_indices:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.rng.shuffle(class_indices[label])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Distribute each class across folds</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        folds: List[List[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [[] </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> _ </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(n_folds)]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> label, indices </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> class_indices.items():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            for</span><span style=\"color:#E1E4E8\"> idx, sample_idx </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> enumerate</span><span style=\"color:#E1E4E8\">(indices):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                fold_idx </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> idx </span><span style=\"color:#F97583\">%</span><span style=\"color:#E1E4E8\"> n_folds</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                folds[fold_idx].append(sample_idx)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Convert to train/validation splits</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        fold_splits </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(n_folds):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            val_indices </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.array(folds[i])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            train_indices </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.concatenate([folds[j] </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> j </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(n_folds) </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> j </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> i])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            fold_splits.append((train_indices, val_indices))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> fold_splits</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_stratification</span><span style=\"color:#E1E4E8\">(self, y: List[ClassLabel], folds: List[Tuple[np.ndarray, np.ndarray]]) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Verify that stratification preserved class distributions.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        original_dist </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Counter(y)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        original_proportions </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {k: v</span><span style=\"color:#F97583\">/</span><span style=\"color:#79B8FF\">len</span><span style=\"color:#E1E4E8\">(y) </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> k, v </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> original_dist.items()}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> train_idx, val_idx </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> folds:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            train_labels </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [y[i] </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> train_idx]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            val_labels </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [y[i] </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> val_idx]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            train_dist </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Counter(train_labels)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            val_dist </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Counter(val_labels)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Check that all classes appear in reasonable proportions</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            for</span><span style=\"color:#E1E4E8\"> label </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> original_proportions:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> label </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> train_dist:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    train_prop </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> train_dist[label] </span><span style=\"color:#F97583\">/</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(train_labels)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    if</span><span style=\"color:#79B8FF\"> abs</span><span style=\"color:#E1E4E8\">(train_prop </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> original_proportions[label]) </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0.1</span><span style=\"color:#E1E4E8\">:  </span><span style=\"color:#6A737D\"># 10% tolerance</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                        return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> True</span></span></code></pre></div>\n\n<p><strong>Complete Metrics Calculator (Supporting Infrastructure)</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># src/evaluation/metrics.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Dict, Optional, Union</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> collections </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Counter, defaultdict</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..types </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> ClassLabel</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ClassificationMetrics</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Comprehensive classification metrics calculation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.epsilon </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 1e-15</span><span style=\"color:#6A737D\">  # Prevent division by zero</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> accuracy</span><span style=\"color:#E1E4E8\">(self, y_true: List[ClassLabel], y_pred: List[ClassLabel]) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate overall classification accuracy.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(y_true) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(y_pred):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"y_true and y_pred must have same length\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        correct </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> sum</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#F97583\"> for</span><span style=\"color:#E1E4E8\"> true, pred </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> zip</span><span style=\"color:#E1E4E8\">(y_true, y_pred) </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> true </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> pred)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> correct </span><span style=\"color:#F97583\">/</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(y_true)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> confusion_matrix</span><span style=\"color:#E1E4E8\">(self, y_true: List[ClassLabel], y_pred: List[ClassLabel]) -> Dict:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Build confusion matrix as nested dictionary.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        labels </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> sorted</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">set</span><span style=\"color:#E1E4E8\">(y_true) </span><span style=\"color:#F97583\">|</span><span style=\"color:#79B8FF\"> set</span><span style=\"color:#E1E4E8\">(y_pred))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Initialize matrix</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        matrix </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> defaultdict(</span><span style=\"color:#F97583\">lambda</span><span style=\"color:#E1E4E8\">: defaultdict(</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Populate matrix</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> true_label, pred_label </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> zip</span><span style=\"color:#E1E4E8\">(y_true, y_pred):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            matrix[true_label][pred_label] </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Convert to regular dict with all labels</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        result </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> true_label </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> labels:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            result[true_label] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            for</span><span style=\"color:#E1E4E8\"> pred_label </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> labels:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                result[true_label][pred_label] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> matrix[true_label][pred_label]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> {</span><span style=\"color:#9ECBFF\">\"matrix\"</span><span style=\"color:#E1E4E8\">: result, </span><span style=\"color:#9ECBFF\">\"labels\"</span><span style=\"color:#E1E4E8\">: labels}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> precision_recall_f1</span><span style=\"color:#E1E4E8\">(self, y_true: List[ClassLabel], y_pred: List[ClassLabel]) -> Dict:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate precision, recall, and F1-score for each class.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        cm_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.confusion_matrix(y_true, y_pred)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        matrix </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> cm_data[</span><span style=\"color:#9ECBFF\">\"matrix\"</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        labels </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> cm_data[</span><span style=\"color:#9ECBFF\">\"labels\"</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        metrics </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> label </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> labels:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # True positives: correctly predicted as this class</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            tp </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> matrix[label][label]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # False positives: incorrectly predicted as this class</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            fp </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> sum</span><span style=\"color:#E1E4E8\">(matrix[other][label] </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> other </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> labels </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> other </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> label)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # False negatives: incorrectly predicted as other classes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            fn </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> sum</span><span style=\"color:#E1E4E8\">(matrix[label][other] </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> other </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> labels </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> other </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> label)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Calculate metrics with epsilon to prevent division by zero</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            precision </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> tp </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> (tp </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> fp </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.epsilon)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            recall </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> tp </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> (tp </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> fn </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.epsilon)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            f1 </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\"> precision </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> recall </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> (precision </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> recall </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.epsilon)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            metrics[label] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"precision\"</span><span style=\"color:#E1E4E8\">: precision,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"recall\"</span><span style=\"color:#E1E4E8\">: recall,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"f1_score\"</span><span style=\"color:#E1E4E8\">: f1,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"support\"</span><span style=\"color:#E1E4E8\">: tp </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> fn  </span><span style=\"color:#6A737D\"># Total samples of this class</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> metrics</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> macro_averaged_metrics</span><span style=\"color:#E1E4E8\">(self, class_metrics: Dict) -> Dict:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate macro-averaged precision, recall, and F1.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        precisions </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [metrics[</span><span style=\"color:#9ECBFF\">\"precision\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> metrics </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> class_metrics.values()]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        recalls </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [metrics[</span><span style=\"color:#9ECBFF\">\"recall\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> metrics </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> class_metrics.values()]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        f1_scores </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [metrics[</span><span style=\"color:#9ECBFF\">\"f1_score\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> metrics </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> class_metrics.values()]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"macro_precision\"</span><span style=\"color:#E1E4E8\">: np.mean(precisions),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"macro_recall\"</span><span style=\"color:#E1E4E8\">: np.mean(recalls),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"macro_f1\"</span><span style=\"color:#E1E4E8\">: np.mean(f1_scores)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> weighted_averaged_metrics</span><span style=\"color:#E1E4E8\">(self, class_metrics: Dict) -> Dict:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate weighted-averaged metrics (weighted by class support).\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        total_support </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> sum</span><span style=\"color:#E1E4E8\">(metrics[</span><span style=\"color:#9ECBFF\">\"support\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> metrics </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> class_metrics.values())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        weighted_precision </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> sum</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            metrics[</span><span style=\"color:#9ECBFF\">\"precision\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> metrics[</span><span style=\"color:#9ECBFF\">\"support\"</span><span style=\"color:#E1E4E8\">] </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            for</span><span style=\"color:#E1E4E8\"> metrics </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> class_metrics.values()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ) </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> total_support</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        weighted_recall </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> sum</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            metrics[</span><span style=\"color:#9ECBFF\">\"recall\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> metrics[</span><span style=\"color:#9ECBFF\">\"support\"</span><span style=\"color:#E1E4E8\">] </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            for</span><span style=\"color:#E1E4E8\"> metrics </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> class_metrics.values()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ) </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> total_support</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        weighted_f1 </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> sum</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            metrics[</span><span style=\"color:#9ECBFF\">\"f1_score\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> metrics[</span><span style=\"color:#9ECBFF\">\"support\"</span><span style=\"color:#E1E4E8\">] </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            for</span><span style=\"color:#E1E4E8\"> metrics </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> class_metrics.values()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ) </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> total_support</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"weighted_precision\"</span><span style=\"color:#E1E4E8\">: weighted_precision,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"weighted_recall\"</span><span style=\"color:#E1E4E8\">: weighted_recall,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"weighted_f1\"</span><span style=\"color:#E1E4E8\">: weighted_f1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeletons\">Core Logic Skeletons</h4>\n<p><strong>Cross-Validation Implementation (Core Learning Objective)</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># src/evaluation/cross_validation.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Dict, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..knn.classifier </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> KNNClassifier</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..types </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> FeatureMatrix, ClassLabel, DistanceMetric</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..data.splitting </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> StratifiedSplitter</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..utils.random_utils </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> ReproducibleRandom</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .metrics </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> ClassificationMetrics</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> CrossValidator</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"K-fold cross-validation for KNN classifier evaluation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, n_folds: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 5</span><span style=\"color:#E1E4E8\">, random_seed: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 42</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.n_folds </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> n_folds</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.random_seed </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> random_seed</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.splitter </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> StratifiedSplitter(random_seed)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.metrics_calc </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ClassificationMetrics()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> evaluate</span><span style=\"color:#E1E4E8\">(self, X: FeatureMatrix, y: List[ClassLabel], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                k_neighbors: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, distance_metric: DistanceMetric) -> Dict:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Perform K-fold cross-validation evaluation.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns comprehensive evaluation results with statistics across folds.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create stratified K-fold splits using self.splitter.create_k_folds()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: This returns list of (train_indices, val_indices) tuples</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Initialize lists to collect per-fold results</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: You'll need lists for accuracy, precision, recall, f1 for each fold</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Loop through each fold and perform evaluation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # For each fold:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Extract training and validation data using indices</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Create fresh KNNClassifier instance with specified parameters</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Fit classifier on training data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Make predictions on validation data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Calculate metrics using self.metrics_calc methods</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Store fold results</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Aggregate results across all folds</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Calculate mean and standard deviation for each metric</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use np.mean() and np.std() on your collected results</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Package results into comprehensive dictionary</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Include: mean metrics, std metrics, per-fold results, fold count</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Return format: {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   \"mean_accuracy\": float,</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   \"std_accuracy\": float, </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   \"mean_macro_f1\": float,</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   \"std_macro_f1\": float,</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   \"fold_results\": List[Dict],  # Individual fold metrics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   \"n_folds\": int</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> NotImplementedError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Implement cross-validation logic\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _extract_fold_data</span><span style=\"color:#E1E4E8\">(self, X: FeatureMatrix, y: List[ClassLabel], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                          indices: np.ndarray) -> Tuple[FeatureMatrix, List[ClassLabel]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Extract subset of data using provided indices.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Extract rows from X using indices (use numpy indexing)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Extract corresponding labels from y using indices</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Return: (subset_X, subset_y)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> NotImplementedError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Implement data extraction\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _validate_inputs</span><span style=\"color:#E1E4E8\">(self, X: FeatureMatrix, y: List[ClassLabel], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        k_neighbors: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate that inputs are suitable for cross-validation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Check that X and y have compatible dimensions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 9: Check that k_neighbors is reasonable relative to fold size</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 10: Check that we have enough samples for n_folds</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Each fold should have at least k_neighbors + 1 training samples</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> NotImplementedError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Implement input validation\"</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p><strong>Hyperparameter Grid Search (Core Learning Objective)</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># src/evaluation/hyperparameter_search.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Dict, Tuple, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..types </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> FeatureMatrix, ClassLabel, DistanceMetric</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .cross_validation </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> CrossValidator</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> GridSearchOptimizer</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Grid search optimization for KNN hyperparameters.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, cv_folds: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 5</span><span style=\"color:#E1E4E8\">, random_seed: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 42</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.cv_folds </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> cv_folds</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.random_seed </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> random_seed</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.cross_validator </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> CrossValidator(cv_folds, random_seed)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> search_optimal_k</span><span style=\"color:#E1E4E8\">(self, X: FeatureMatrix, y: List[ClassLabel],</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        k_values: List[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">], distance_metric: DistanceMetric,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        optimization_metric: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"mean_accuracy\"</span><span style=\"color:#E1E4E8\">) -> Dict:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Search for optimal K value using cross-validation.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Dictionary with optimal K, best score, and complete results</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate input parameters</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Check that k_values are reasonable for dataset size</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Check that optimization_metric is supported</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Initialize tracking variables</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # You'll need: best_k, best_score, all_results dictionary</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Loop through each K value in k_values</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # For each K:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Run cross-validation using self.cross_validator.evaluate()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Extract the optimization metric score</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Update best_k and best_score if this K is better</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Store complete results for this K</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Handle tie-breaking</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # If multiple K values achieve the same best score, choose the smallest K</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # This implements Occam's razor (prefer simpler models)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Package final results</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Return format: {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   \"best_k\": int,</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   \"best_score\": float,</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   \"best_std\": float,  # Standard deviation of best score</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   \"optimization_metric\": str,</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   \"all_results\": Dict[int, Dict],  # K -> CV results mapping</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   \"k_values_tested\": List[int]</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> NotImplementedError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Implement grid search logic\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _determine_k_range</span><span style=\"color:#E1E4E8\">(self, n_samples: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, n_folds: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> List[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate reasonable K value range based on dataset size.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Calculate minimum K (typically 1)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Calculate maximum K based on smallest training fold size</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Rule of thumb: max_k should be &#x3C; sqrt(smallest_fold_size)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Generate range of odd numbers (odd K avoids ties in binary classification)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Return: List of K values to test</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> NotImplementedError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Implement K range determination\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> generate_performance_report</span><span style=\"color:#E1E4E8\">(self, search_results: Dict) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate human-readable performance report.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 9: Extract key information from search_results</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 10: Format results into readable table</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Include: K value, mean score, std score, ranking</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 11: Highlight the optimal K and its performance characteristics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 12: Add recommendations based on performance stability</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> NotImplementedError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Implement report generation\"</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p><strong>Statistical Significance Testing (Advanced Feature)</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># src/evaluation/statistical_tests.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Dict, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> scipy </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> stats</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> StatisticalValidator</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Statistical significance testing for model comparison.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> paired_t_test</span><span style=\"color:#E1E4E8\">(self, scores_a: List[</span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">], scores_b: List[</span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                     alpha: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0.05</span><span style=\"color:#E1E4E8\">) -> Dict:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Perform paired t-test to compare two model performances.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Used to test if difference between K values is statistically significant.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 13: Validate that both score lists have same length</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 14: Calculate paired differences (scores_a - scores_b)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 15: Perform one-sample t-test on differences using scipy.stats.ttest_1samp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 16: Interpret results and package into dictionary</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Return: {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   \"statistic\": float,</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   \"p_value\": float,</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   \"significant\": bool,</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   \"confidence_interval\": Tuple[float, float]</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> NotImplementedError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Implement paired t-test\"</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p><strong>After implementing cross-validation (Milestone 3.1):</strong></p>\n<p>Run the following test to verify your cross-validation implementation:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test cross-validation correctness</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sklearn.datasets </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> load_iris</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> src.evaluation.cross_validation </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> CrossValidator</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> src.types </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> DistanceMetric</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Load test data</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">X, y </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> load_iris(</span><span style=\"color:#FFAB70\">return_X_y</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">y </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> y.tolist()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test 5-fold CV</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">cv </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> CrossValidator(</span><span style=\"color:#FFAB70\">n_folds</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">random_seed</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">42</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">results </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> cv.evaluate(X, y, </span><span style=\"color:#FFAB70\">k_neighbors</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">distance_metric</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">DistanceMetric.</span><span style=\"color:#79B8FF\">EUCLIDEAN</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Verify results structure</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">assert</span><span style=\"color:#9ECBFF\"> \"mean_accuracy\"</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> results</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">assert</span><span style=\"color:#9ECBFF\"> \"std_accuracy\"</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> results  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">assert</span><span style=\"color:#9ECBFF\"> \"fold_results\"</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> results</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">assert</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(results[</span><span style=\"color:#9ECBFF\">\"fold_results\"</span><span style=\"color:#E1E4E8\">]) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 5</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">assert</span><span style=\"color:#79B8FF\"> 0.0</span><span style=\"color:#F97583\"> &#x3C;=</span><span style=\"color:#E1E4E8\"> results[</span><span style=\"color:#9ECBFF\">\"mean_accuracy\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 1.0</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"✓ Cross-validation works! Mean accuracy: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">results[</span><span style=\"color:#9ECBFF\">'mean_accuracy'</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">:.3f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> ± </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">results[</span><span style=\"color:#9ECBFF\">'std_accuracy'</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">:.3f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p><strong>Expected output</strong>: Mean accuracy should be around 0.95-0.98 for Iris dataset with reasonable standard deviation &lt; 0.05.</p>\n<p><strong>After implementing grid search (Milestone 3.2):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test hyperparameter optimization</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> src.evaluation.hyperparameter_search </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> GridSearchOptimizer</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test grid search</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">optimizer </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> GridSearchOptimizer(</span><span style=\"color:#FFAB70\">cv_folds</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">3</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">random_seed</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">42</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Fewer folds for speed</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">search_results </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> optimizer.search_optimal_k(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    X, y, </span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    k_values</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">3</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">7</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">9</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">11</span><span style=\"color:#E1E4E8\">], </span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    distance_metric</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">DistanceMetric.</span><span style=\"color:#79B8FF\">EUCLIDEAN</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Verify optimization results</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">assert</span><span style=\"color:#9ECBFF\"> \"best_k\"</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> search_results</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">assert</span><span style=\"color:#9ECBFF\"> \"best_score\"</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> search_results</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">assert</span><span style=\"color:#E1E4E8\"> search_results[</span><span style=\"color:#9ECBFF\">\"best_k\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> [</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">3</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">7</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">9</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">11</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"✓ Grid search works! Optimal K: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">search_results[</span><span style=\"color:#9ECBFF\">'best_k'</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">, Score: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">search_results[</span><span style=\"color:#9ECBFF\">'best_score'</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">:.3f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p><strong>Expected output</strong>: Optimal K should be in range 3-7 for Iris dataset with accuracy &gt; 0.95.</p>\n<p><strong>Signs something is wrong:</strong></p>\n<ul>\n<li>Mean accuracy &lt; 0.90 on Iris dataset indicates bug in classifier or evaluation</li>\n<li>Standard deviation &gt; 0.10 suggests unstable splits or implementation error  </li>\n<li>Grid search always selects K=1 indicates overfitting to noise</li>\n<li>All K values produce identical scores indicates bug in parameter passing</li>\n</ul>\n<h2 id=\"component-interactions-and-data-flow\">Component Interactions and Data Flow</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Comprehensive integration across all milestones - shows how distance calculation (Milestone 1), neighbor finding and classification (Milestone 2), and evaluation with optimization (Milestone 3) coordinate to form a complete machine learning system</p>\n</blockquote>\n<p>The K-Nearest Neighbors classifier operates as a <strong>coordinated orchestration of specialized components</strong>, much like a well-organized research team where each member has distinct expertise but must collaborate seamlessly to reach conclusions. Understanding how these components interact and how data flows between them is crucial for implementing a robust and efficient KNN system.</p>\n<p>Think of the component interaction like a <strong>scientific consultation process</strong>. When faced with a new classification problem, you would first gather your reference materials (training data), then systematically measure similarities to known cases (distance calculation), identify the most relevant precedents (neighbor finding), conduct a vote among experts (classification), and finally validate your methodology through rigorous testing (evaluation and optimization). Each step depends on the previous ones, but the coordination between them determines the overall system&#39;s effectiveness.</p>\n<p>The data flow architecture reveals three distinct operational phases, each with specific coordination patterns and performance characteristics. During training, the system primarily focuses on data validation and storage preparation. During prediction, components must coordinate in real-time to process queries efficiently. During optimization, the system orchestrates multiple prediction cycles to evaluate different configurations and select optimal parameters.</p>\n<p><img src=\"/api/project/knn/architecture-doc/asset?path=diagrams%2Fsystem-components.svg\" alt=\"System Component Architecture\"></p>\n<p><img src=\"/api/project/knn/architecture-doc/asset?path=diagrams%2Fdata-model.svg\" alt=\"Data Model Relationships\"></p>\n<h3 id=\"training-data-flow\">Training Data Flow</h3>\n<p>The training phase in KNN represents the <strong>preparation and storage</strong> of reference knowledge rather than traditional parameter learning. Unlike parametric models that extract patterns into weights and coefficients, KNN employs lazy learning where the training process focuses on data validation, preprocessing, and efficient storage organization.</p>\n<p>The training data flow begins when the <code>KNNClassifier</code> receives feature matrices and label arrays through the <code>fit</code> method. This initial step triggers a comprehensive validation pipeline that ensures data quality and compatibility. The system first validates that feature matrices contain only numeric values and that all feature vectors have consistent dimensionality. Label validation ensures that class identifiers are consistent in type and that the dataset contains sufficient examples for meaningful neighbor finding.</p>\n<p>During the validation phase, the system constructs a <code>TrainingData</code> structure that encapsulates all necessary information for future predictions. This structure maintains the original <code>FeatureMatrix</code> for distance calculations, stores class labels in a format optimized for voting operations, and computes metadata such as the number of samples, feature dimensions, and unique class identifiers. The metadata computation enables efficient parameter validation during prediction and optimization phases.</p>\n<p>The training data storage process implements several architectural decisions that impact system performance. The feature matrix remains in its original NumPy array format to leverage vectorized operations during distance calculation. Class labels are stored as a list to maintain order correspondence with feature vectors while also being indexed in a set for efficient uniqueness checking. The training data structure includes precomputed statistics like class distributions that accelerate weighted voting calculations.</p>\n<table>\n<thead>\n<tr>\n<th>Training Phase Operation</th>\n<th>Input Data</th>\n<th>Processing Steps</th>\n<th>Output Structure</th>\n<th>Performance Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Data Validation</td>\n<td>Raw features and labels</td>\n<td>Type checking, dimension validation, missing value detection</td>\n<td>Validated arrays</td>\n<td>O(n×m) where n=samples, m=features</td>\n</tr>\n<tr>\n<td>Metadata Computation</td>\n<td>Validated arrays</td>\n<td>Count samples/features, identify unique classes</td>\n<td>TrainingData statistics</td>\n<td>O(n) for class enumeration</td>\n</tr>\n<tr>\n<td>Storage Organization</td>\n<td>Validated data + metadata</td>\n<td>Array copying, label indexing, class mapping</td>\n<td>Complete TrainingData</td>\n<td>O(n×m) memory allocation</td>\n</tr>\n<tr>\n<td>Index Preparation</td>\n<td>Organized data</td>\n<td>Sample indexing, class distribution calculation</td>\n<td>Ready classifier state</td>\n<td>O(n) for distribution stats</td>\n</tr>\n</tbody></table>\n<p>The training data flow implements several critical validation checkpoints that prevent runtime errors during prediction. The system validates that feature vectors contain only finite numeric values, rejecting datasets with NaN or infinite values that would corrupt distance calculations. Dimensionality consistency checking ensures that all feature vectors have identical length, preventing broadcasting errors in vectorized operations. Class label validation confirms that labels are consistently typed and that each class has sufficient representation for meaningful neighbor voting.</p>\n<blockquote>\n<p><strong>Key Design Insight</strong>: Training in KNN is fundamentally different from parametric learning - it&#39;s about data preparation and storage optimization rather than parameter estimation. The training phase establishes the data quality foundation that enables efficient and accurate predictions.</p>\n</blockquote>\n<p><strong>Decision: Lazy Learning Storage Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: KNN must store training data for prediction-time computation rather than pre-computing model parameters</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>Store raw arrays with minimal preprocessing</li>\n<li>Pre-compute distance matrices for all training pairs  </li>\n<li>Build spatial index structures during training</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Store validated raw data with computed metadata</li>\n<li><strong>Rationale</strong>: Maintains flexibility for different distance metrics while avoiding quadratic memory overhead of full distance matrices and complexity of spatial indexing</li>\n<li><strong>Consequences</strong>: Enables dynamic distance metric selection and efficient memory usage, but requires distance computation during each prediction</li>\n</ul>\n<p>The training data flow concludes with the classifier transitioning to a &quot;fitted&quot; state where the <code>training_data</code> field contains a complete <code>TrainingData</code> structure. This state transition enables prediction methods while maintaining clear separation between training and inference phases. The fitted state includes validation flags that prevent prediction attempts on incompatible query data.</p>\n<h3 id=\"prediction-data-flow\">Prediction Data Flow</h3>\n<p>The prediction data flow represents the <strong>core operational sequence</strong> where all system components coordinate to transform query points into classification results. This process exemplifies the lazy learning paradigm where computation is deferred until prediction time, requiring real-time coordination between distance calculation, neighbor finding, and voting components.</p>\n<p><img src=\"/api/project/knn/architecture-doc/asset?path=diagrams%2Fprediction-flow.svg\" alt=\"Prediction Sequence Flow\"></p>\n<p>The prediction sequence begins when the <code>predict</code> or <code>predict_with_confidence</code> method receives a query <code>FeatureMatrix</code>. The system immediately validates that query points have compatible dimensionality with the training data and that the classifier is in a fitted state. This validation prevents runtime errors and provides clear feedback about configuration issues.</p>\n<p>Following validation, the prediction flow enters the <strong>batch processing coordination phase</strong> where the system determines the optimal strategy for handling multiple query points. For small query batches, the system processes each point individually to minimize memory overhead. For larger batches, it may employ vectorized operations or parallel processing depending on the available computational resources and distance metric characteristics.</p>\n<p>The individual query point prediction follows a precisely orchestrated sequence of component interactions:</p>\n<ol>\n<li><p><strong>Query Point Extraction</strong>: The system extracts individual <code>FeatureVector</code> instances from the query matrix, ensuring proper array slicing that maintains NumPy array properties for subsequent vectorized operations.</p>\n</li>\n<li><p><strong>Distance Calculation Coordination</strong>: The distance calculator receives the query point and applies the configured distance metric to compute distances to all training samples. This step leverages the vectorized distance calculation methods to achieve O(n×m) performance rather than O(n) individual distance calculations.</p>\n</li>\n<li><p><strong>Neighbor Finding Coordination</strong>: The neighbor finder receives the distance array and applies efficient selection algorithms to identify the K closest training samples. This coordination includes tie-breaking logic and validation that sufficient neighbors exist.</p>\n</li>\n<li><p><strong>Label Retrieval Coordination</strong>: The system uses neighbor indices to retrieve corresponding class labels from the training data structure, maintaining the association between distances and labels for voting.</p>\n</li>\n<li><p><strong>Voting Coordination</strong>: The classification component receives neighbor labels and distances, applying the configured voting strategy to produce a class prediction and confidence score.</p>\n</li>\n<li><p><strong>Result Assembly</strong>: The system packages the prediction results into appropriate return structures, either simple class labels or detailed <code>PredictionResult</code> objects depending on the called method.</p>\n</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>Prediction Step</th>\n<th>Component Responsibility</th>\n<th>Data Transformation</th>\n<th>Error Handling</th>\n<th>Performance Characteristics</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Query Validation</td>\n<td>KNNClassifier</td>\n<td>FeatureMatrix → validated vectors</td>\n<td>Dimension mismatch detection</td>\n<td>O(m) per query point</td>\n</tr>\n<tr>\n<td>Distance Computation</td>\n<td>DistanceCalculator</td>\n<td>FeatureVector → DistanceArray</td>\n<td>Numerical stability checks</td>\n<td>O(n×m) vectorized operation</td>\n</tr>\n<tr>\n<td>Neighbor Selection</td>\n<td>NeighborFinder</td>\n<td>DistanceArray → NeighborIndices</td>\n<td>K validation, tie resolution</td>\n<td>O(n log K) with partial sorting</td>\n</tr>\n<tr>\n<td>Label Retrieval</td>\n<td>TrainingData</td>\n<td>NeighborIndices → neighbor labels</td>\n<td>Index bounds checking</td>\n<td>O(K) array indexing</td>\n</tr>\n<tr>\n<td>Vote Computation</td>\n<td>Classifier</td>\n<td>Labels + distances → prediction</td>\n<td>Tie-breaking, confidence calculation</td>\n<td>O(K) voting operation</td>\n</tr>\n<tr>\n<td>Result Assembly</td>\n<td>KNNClassifier</td>\n<td>Prediction → result structure</td>\n<td>Result validation</td>\n<td>O(1) structure creation</td>\n</tr>\n</tbody></table>\n<p>The prediction data flow implements sophisticated error handling and recovery mechanisms at each coordination point. Distance calculation errors trigger fallback strategies or clear error messages depending on the failure mode. Neighbor finding failures due to insufficient data or invalid K values provide specific guidance for parameter adjustment. Voting failures due to tied results invoke tie-breaking algorithms that use distance information to make deterministic decisions.</p>\n<p><strong>Decision: Single-Point Processing with Batch Coordination</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to balance memory efficiency with computational performance for variable-sized query batches</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Pure batch processing with full distance matrix computation</li>\n<li>Individual point processing with no batch optimizations</li>\n<li>Adaptive strategy based on batch size and available memory</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Process individual points within batch coordination framework</li>\n<li><strong>Rationale</strong>: Provides memory efficiency for large training sets while enabling batch-level optimizations like vectorized distance computation and result aggregation</li>\n<li><strong>Consequences</strong>: Achieves good performance across different usage patterns but requires more complex coordination logic</li>\n</ul>\n<p>The prediction data flow maintains <strong>provenance information</strong> throughout the process, enabling detailed debugging and confidence assessment. Each prediction result can include the specific neighbor indices, their distances, and the voting details that led to the final classification. This transparency supports both debugging and confidence-based application logic.</p>\n<p>Performance optimization in the prediction flow focuses on minimizing redundant computations and leveraging NumPy&#39;s vectorized operations. The system avoids recomputing training data statistics and caches frequently accessed metadata. Distance computation uses broadcasting to compute all distances in a single vectorized operation rather than iterating through training samples.</p>\n<blockquote>\n<p><strong>Critical Performance Insight</strong>: The prediction data flow&#39;s efficiency depends heavily on vectorized operations and minimal data copying. Each component coordination point must preserve NumPy array properties and avoid Python-level loops that would severely impact performance on large training sets.</p>\n</blockquote>\n<h3 id=\"optimization-data-flow\">Optimization Data Flow</h3>\n<p>The optimization data flow orchestrates <strong>systematic evaluation and hyperparameter tuning</strong> across multiple prediction cycles to identify optimal classifier configurations. This process represents the most complex coordination pattern in the system, requiring careful management of data splitting, cross-validation execution, and result aggregation while maintaining statistical validity.</p>\n<p>The optimization flow begins with <strong>parameter space definition</strong> where the system establishes ranges for hyperparameters to explore. The primary optimization target is the K parameter, but the system also considers distance metric selection and voting strategy configuration. The optimization coordinator validates parameter ranges and ensures sufficient data exists for meaningful cross-validation.</p>\n<p><strong>Cross-validation coordination</strong> represents the core of the optimization data flow. The system implements stratified K-fold cross-validation that maintains class distribution across folds while ensuring statistical independence between training and validation sets. This coordination requires careful data management to prevent information leakage between folds.</p>\n<p>The cross-validation process follows a nested coordination pattern:</p>\n<ol>\n<li><p><strong>Fold Generation Coordination</strong>: The stratified splitter generates balanced train/validation splits while maintaining reproducibility through seed management. Each fold preserves class distributions and ensures sufficient samples for neighbor finding.</p>\n</li>\n<li><p><strong>Model Training Coordination</strong>: For each fold and parameter combination, the system creates a temporary classifier instance, fits it with the fold&#39;s training data, and validates the fitted state.</p>\n</li>\n<li><p><strong>Validation Coordination</strong>: The temporary classifier processes validation queries through the standard prediction data flow, generating predictions for metric calculation.</p>\n</li>\n<li><p><strong>Metrics Computation Coordination</strong>: The evaluation component coordinates calculation of accuracy, precision, recall, and F1-score metrics, handling edge cases like missing classes in validation folds.</p>\n</li>\n<li><p><strong>Result Aggregation Coordination</strong>: The system accumulates metrics across folds and parameter combinations, computing statistical summaries and maintaining detailed result tracking.</p>\n</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>Optimization Phase</th>\n<th>Coordination Pattern</th>\n<th>Data Management</th>\n<th>Statistical Considerations</th>\n<th>Performance Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Parameter Grid Setup</td>\n<td>Sequential validation</td>\n<td>Parameter ranges and constraints</td>\n<td>Valid parameter combinations</td>\n<td>O(1) configuration</td>\n</tr>\n<tr>\n<td>Fold Generation</td>\n<td>Stratified sampling</td>\n<td>Class-balanced data splits</td>\n<td>Independence between folds</td>\n<td>O(n log n) sorting</td>\n</tr>\n<tr>\n<td>Cross-Validation Loop</td>\n<td>Nested iteration</td>\n<td>Temporary classifier instances</td>\n<td>Statistical significance</td>\n<td>O(p × f × n × m) where p=parameters, f=folds</td>\n</tr>\n<tr>\n<td>Metric Computation</td>\n<td>Batch aggregation</td>\n<td>Prediction result collection</td>\n<td>Confidence intervals</td>\n<td>O(v) where v=validation samples</td>\n</tr>\n<tr>\n<td>Result Selection</td>\n<td>Statistical comparison</td>\n<td>Performance metric databases</td>\n<td>Multiple testing correction</td>\n<td>O(p × f) aggregation</td>\n</tr>\n</tbody></table>\n<p>The optimization data flow implements <strong>statistical rigor</strong> through careful experimental design. The system uses stratified sampling to ensure representative train/validation splits, maintains consistent random seeds for reproducible results, and applies appropriate statistical tests when comparing parameter configurations. Cross-validation results include confidence intervals and statistical significance tests where applicable.</p>\n<p><strong>Grid search coordination</strong> manages the systematic exploration of hyperparameter space through exhaustive evaluation. The system coordinates parameter combination generation, ensures complete coverage of the specified grid, and maintains progress tracking for long-running optimizations. Result storage enables detailed analysis of parameter sensitivity and performance trade-offs.</p>\n<p><strong>Decision: Stratified K-Fold Cross-Validation with Grid Search</strong></p>\n<ul>\n<li><strong>Context</strong>: Need reliable hyperparameter selection with statistical validity and computational efficiency</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Simple train/validation split with grid search</li>\n<li>Monte Carlo cross-validation with random sampling</li>\n<li>Stratified K-fold cross-validation with systematic grid exploration</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Implement stratified K-fold with comprehensive grid search</li>\n<li><strong>Rationale</strong>: Provides best balance of statistical reliability, computational efficiency, and practical usability while ensuring representative data splits</li>\n<li><strong>Consequences</strong>: Enables statistically sound parameter selection but requires complex coordination logic and significant computational resources</li>\n</ul>\n<p>The optimization data flow maintains <strong>detailed audit trails</strong> that enable analysis of hyperparameter sensitivity and model behavior. The system records not only final metrics but also intermediate results, timing information, and statistical summaries. This detailed tracking supports both automated parameter selection and manual analysis of model characteristics.</p>\n<p><strong>Resource management</strong> in the optimization flow coordinates memory usage and computational resources across multiple concurrent evaluation processes. The system implements strategies to limit memory growth during cross-validation and provides progress reporting for long-running optimizations. Temporary classifier instances are properly disposed of to prevent memory leaks during extended optimization runs.</p>\n<p>The optimization flow concludes with <strong>result synthesis</strong> where the system identifies optimal configurations and provides comprehensive reports. The <code>GridSearchResult</code> structure contains not only the best parameters but also complete performance profiles that enable sensitivity analysis. The coordination ensures that optimal parameters are validated and that the final recommendations are statistically sound.</p>\n<blockquote>\n<p><strong>Statistical Validity Insight</strong>: The optimization data flow must maintain strict separation between training and validation data while ensuring representative sampling. Any information leakage or biased sampling will produce overoptimistic performance estimates that fail in production deployment.</p>\n</blockquote>\n<p>⚠️ <strong>Pitfall: Information Leakage in Cross-Validation</strong>\nCross-validation coordination must prevent any training information from influencing validation predictions. Common mistakes include using global statistics computed on the entire dataset or sharing fitted preprocessing parameters across folds. The system implements strict data isolation where each fold&#39;s training phase has access only to its designated training samples, and all preprocessing decisions are made independently for each fold.</p>\n<p>⚠️ <strong>Pitfall: Insufficient Statistical Power</strong>\nOptimization with small datasets or too few cross-validation folds can produce unreliable parameter selections. The system validates that sufficient samples exist for meaningful cross-validation and warns when statistical power is limited. Minimum sample requirements ensure that each fold contains adequate representation of all classes.</p>\n<p>⚠️ <strong>Pitfall: Hyperparameter Overfitting</strong>\nExtensive grid search over many parameter combinations can lead to overfitting where selected parameters perform well on validation data but poorly on truly unseen test data. The optimization flow implements nested cross-validation options and provides warnings when parameter grids are excessively large relative to available data.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The component interaction implementation requires careful coordination of multiple specialized modules while maintaining clean interfaces and efficient data flow. The following guidance provides concrete patterns for implementing the coordination logic and managing the complex data transformations.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component Integration</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Data Flow Coordination</td>\n<td>Direct method calls with explicit error handling</td>\n<td>Observer pattern with event-driven coordination</td>\n</tr>\n<tr>\n<td>Memory Management</td>\n<td>Standard Python garbage collection with manual cleanup</td>\n<td>Memory pooling with pre-allocated arrays</td>\n</tr>\n<tr>\n<td>Progress Tracking</td>\n<td>Simple print statements and counters</td>\n<td>Rich progress bars with time estimation</td>\n</tr>\n<tr>\n<td>Result Storage</td>\n<td>In-memory dictionaries and lists</td>\n<td>Structured databases with query capabilities</td>\n</tr>\n<tr>\n<td>Parallel Processing</td>\n<td>Sequential processing with clear interfaces</td>\n<td>Multi-processing with shared memory arrays</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-module-structure\">Recommended Module Structure</h4>\n<p>The implementation should organize component interactions across multiple modules that maintain clear separation of concerns while enabling efficient data flow:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>knn_classifier/\n  core/\n    classifier.py           ← Main KNNClassifier with coordination logic\n    training.py            ← Training data flow and validation\n    prediction.py          ← Prediction coordination and batch processing\n  components/\n    distance_calculator.py ← Distance computation component\n    neighbor_finder.py     ← Neighbor selection component  \n    voting.py             ← Classification voting component\n    evaluator.py          ← Cross-validation and optimization\n  coordination/\n    data_flow.py          ← Data transformation utilities\n    validation.py         ← Cross-component validation logic\n    batch_processor.py    ← Batch coordination strategies\n  utils/\n    data_structures.py    ← Core data types and containers\n    metrics.py            ← Performance metrics and statistics\n    random_utils.py       ← Reproducible randomization\n  tests/\n    integration/\n      test_data_flow.py   ← End-to-end data flow testing\n      test_coordination.py ← Component interaction testing</code></pre></div>\n\n<h4 id=\"training-data-flow-infrastructure\">Training Data Flow Infrastructure</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Set, Optional, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TrainingData</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Complete training data structure with metadata for efficient prediction.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    features: np.ndarray  </span><span style=\"color:#6A737D\"># FeatureMatrix (n_samples, n_features)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    labels: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]     </span><span style=\"color:#6A737D\"># ClassLabel list maintaining order</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    n_samples: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#6A737D\">        # Number of training examples</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    n_features: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#6A737D\">       # Feature vector dimensionality</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    unique_classes: Set[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]  </span><span style=\"color:#6A737D\"># Unique class identifiers</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    class_counts: </span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#6A737D\">    # Class frequency distribution</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_sample</span><span style=\"color:#E1E4E8\">(self, index: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Tuple[np.ndarray, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Retrieve single training example by index with bounds checking.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate index bounds against n_samples</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Extract feature vector using array slicing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Retrieve corresponding label maintaining type consistency</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return tuple of FeatureVector and ClassLabel</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_query_compatibility</span><span style=\"color:#E1E4E8\">(self, query_features: np.ndarray) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate query points have compatible dimensionality with training data.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check that query_features is 2D array (n_queries, n_features)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate that query feature count matches self.n_features</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check for finite numeric values (no NaN or infinity)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Raise descriptive errors for validation failures</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TrainingDataBuilder</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Constructs validated TrainingData structures from raw input arrays.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">staticmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> build_training_data</span><span style=\"color:#E1E4E8\">(features: np.ndarray, labels: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]) -> TrainingData:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Build complete TrainingData with validation and metadata computation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate features array shape and numeric types</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate labels list consistency and type uniformity</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check feature-label count correspondence</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Compute n_samples, n_features from array dimensions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Build unique_classes set from labels list</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate class_counts distribution dictionary</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Construct and return TrainingData instance</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">staticmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_feature_matrix</span><span style=\"color:#E1E4E8\">(features: np.ndarray) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Comprehensive feature matrix validation with specific error messages.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check array is 2D with shape (n_samples, n_features)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate numeric dtype (float32 or float64)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check for NaN, infinity, or missing values</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Ensure sufficient samples (at least 1) and features (at least 1)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Raise ValueError with specific problem description</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"prediction-data-flow-coordination\">Prediction Data Flow Coordination</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Union, Dict, Any</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> PredictionResult</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Complete prediction result with neighbor information and confidence.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    predicted_class: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#6A737D\">           # Final classification decision</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    neighbor_indices: np.ndarray   </span><span style=\"color:#6A737D\"># Indices of K nearest neighbors</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    neighbor_distances: np.ndarray </span><span style=\"color:#6A737D\"># Distances to K nearest neighbors</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    confidence: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#6A737D\">              # Prediction confidence score</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    voting_details: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any] </span><span style=\"color:#6A737D\"># Detailed voting information</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> PredictionCoordinator</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Coordinates component interactions during prediction phase.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, distance_calculator, neighbor_finder, classifier):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.distance_calculator </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> distance_calculator</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.neighbor_finder </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> neighbor_finder</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.classifier </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> classifier</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.training_data: Optional[TrainingData] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> predict_batch_with_coordination</span><span style=\"color:#E1E4E8\">(self, query_points: np.ndarray) -> List[PredictionResult]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Coordinate prediction for multiple query points with batch optimizations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate query_points compatibility with training data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Determine optimal batch processing strategy based on array sizes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Initialize result collection with appropriate capacity</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Iterate through query points with progress tracking</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: For each point, coordinate distance → neighbors → voting sequence</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Aggregate individual predictions into batch result list</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate result consistency and completeness</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return complete batch prediction results</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _predict_single_point_coordination</span><span style=\"color:#E1E4E8\">(self, query_point: np.ndarray) -> PredictionResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Coordinate single point prediction through all components.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Extract FeatureVector from query array with proper slicing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Coordinate distance calculation to all training points</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Coordinate neighbor finding with distance array and K parameter</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Retrieve neighbor labels using indices from training data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Coordinate voting with neighbor labels and distances</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate confidence score from voting results</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Assemble complete PredictionResult with all information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate prediction result consistency before returning</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _coordinate_distance_calculation</span><span style=\"color:#E1E4E8\">(self, query_point: np.ndarray) -> np.ndarray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Coordinate vectorized distance computation to all training samples.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Pass query point and training features to distance calculator</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Apply configured distance metric with vectorized operations</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate distance array has correct length (n_samples)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check for numerical issues (NaN, negative distances)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return validated DistanceArray for neighbor finding</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"cross-validation-coordination-infrastructure\">Cross-Validation Coordination Infrastructure</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sklearn.model_selection </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> StratifiedKFold</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Iterator, Dict, List, Any</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> CrossValidationCoordinator</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Manages cross-validation execution with component coordination.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, n_folds: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 5</span><span style=\"color:#E1E4E8\">, random_seed: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 42</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.n_folds </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> n_folds</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.random_seed </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> random_seed</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.fold_splitter </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> StratifiedKFold(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            n_splits</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">n_folds, </span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            shuffle</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            random_state</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">random_seed</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> coordinate_k_fold_evaluation</span><span style=\"color:#E1E4E8\">(self, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                   X: np.ndarray, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                   y: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                   k_values: List[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">],</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                   distance_metric: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Coordinate complete K-fold cross-validation with hyperparameter grid.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate input data sufficient for n_folds splits</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Generate stratified fold indices maintaining class distribution</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Initialize results collection with nested dictionaries</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Iterate through k_values parameter grid</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: For each K, iterate through cross-validation folds</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Coordinate fold training with temporary classifier instances</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Coordinate fold validation through prediction pipeline</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Aggregate metrics across folds for each K value</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate statistical summaries (mean, std) for metrics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Identify optimal K based on validation performance</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return comprehensive CrossValidationResult</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _coordinate_single_fold</span><span style=\"color:#E1E4E8\">(self, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                               train_indices: np.ndarray,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                               val_indices: np.ndarray,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                               X: np.ndarray,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                               y: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">],</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                               k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                               distance_metric: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Coordinate single fold evaluation with temporary classifier.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Extract training data using train_indices</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Extract validation data using val_indices  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Create temporary KNNClassifier instance with parameters</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Coordinate training data fitting on fold training set</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Coordinate prediction on fold validation set</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate classification metrics for fold results</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return fold performance metrics dictionary</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> generate_stratified_folds</span><span style=\"color:#E1E4E8\">(self, X: np.ndarray, y: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]) -> Iterator[Tuple[np.ndarray, np.ndarray]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate stratified train/validation splits maintaining class distribution.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Convert labels to numpy array for sklearn compatibility</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Use StratifiedKFold to generate balanced splits</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Yield train_indices, val_indices for each fold</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate each fold has representation of all classes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"optimization-results-management\">Optimization Results Management</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> GridSearchResult</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Comprehensive grid search results with statistical analysis.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    optimal_k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#6A737D\">                    # Best K parameter</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    optimal_metrics: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#6A737D\"># Performance at optimal K</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    complete_results: Dict[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, Dict] </span><span style=\"color:#6A737D\"># Full grid search results</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    parameter_sensitivity: Dict       </span><span style=\"color:#6A737D\"># Parameter sensitivity analysis</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    statistical_significance: Dict   </span><span style=\"color:#6A737D\"># Statistical test results</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    optimization_metadata: Dict      </span><span style=\"color:#6A737D\"># Timing and resource usage</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> OptimizationCoordinator</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Coordinates hyperparameter optimization with statistical validation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> coordinate_grid_search</span><span style=\"color:#E1E4E8\">(self, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                             X: np.ndarray,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                             y: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                             k_range: </span><span style=\"color:#79B8FF\">range</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                             cv_folds: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 5</span><span style=\"color:#E1E4E8\">) -> GridSearchResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Coordinate comprehensive grid search with cross-validation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate parameter ranges and data sufficiency</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Initialize result tracking with timing information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Coordinate cross-validation for each K in range</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Aggregate results across parameter combinations</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Perform statistical significance testing between configurations</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Identify optimal parameters with confidence intervals</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Generate parameter sensitivity analysis</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Assemble comprehensive GridSearchResult</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Complete infrastructure for reproducible randomization</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ReproducibleRandom</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Manages random seeds for reproducible optimization.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, base_seed: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 42</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.base_seed </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> base_seed</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.operation_counter </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_seed_for_operation</span><span style=\"color:#E1E4E8\">(self, operation_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate consistent seed for specific operation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Hash operation name with base seed and counter</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Increment operation counter for sequence consistency</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return deterministic seed for operation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p><strong>Checkpoint 1: Training Data Flow Validation</strong></p>\n<ul>\n<li>Run <code>python -m pytest tests/integration/test_training_flow.py</code></li>\n<li>Expected: All training data validation and metadata computation tests pass</li>\n<li>Verify: <code>TrainingData</code> structure properly stores features, labels, and metadata</li>\n<li>Manual test: Load iris dataset, fit classifier, inspect <code>training_data</code> attributes</li>\n</ul>\n<p><strong>Checkpoint 2: Prediction Coordination</strong></p>\n<ul>\n<li>Run <code>python -c &quot;from knn_classifier import KNNClassifier; knn = KNNClassifier(k=3); knn.fit(X_train, y_train); print(knn.predict(X_test))&quot;</code></li>\n<li>Expected: Predictions returned as class label list matching test data length</li>\n<li>Verify: <code>predict_with_confidence</code> returns detailed <code>PredictionResult</code> objects</li>\n<li>Manual test: Single query point returns prediction with neighbor information</li>\n</ul>\n<p><strong>Checkpoint 3: Cross-Validation Integration</strong></p>\n<ul>\n<li>Run cross-validation with <code>k_fold_cross_validate(X, y, k_folds=5, k_neighbors=3)</code></li>\n<li>Expected: <code>CrossValidationResult</code> with mean/std metrics across folds</li>\n<li>Verify: Grid search identifies optimal K with statistical validation</li>\n<li>Manual test: Compare cross-validation results with simple train/test split</li>\n</ul>\n<h4 id=\"debugging-component-interactions\">Debugging Component Interactions</h4>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>Diagnosis Steps</th>\n<th>Fix Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Prediction hangs indefinitely</td>\n<td>Infinite loop in neighbor finding or voting</td>\n<td>Add debug prints in coordination methods, check array shapes</td>\n<td>Validate K parameter against dataset size, add timeout logic</td>\n</tr>\n<tr>\n<td>Memory usage grows during batch prediction</td>\n<td>Array copying or accumulation without cleanup</td>\n<td>Profile memory usage, check for array references</td>\n<td>Implement explicit cleanup, use views instead of copies</td>\n</tr>\n<tr>\n<td>Cross-validation results inconsistent</td>\n<td>Non-deterministic randomization or data leakage</td>\n<td>Check random seed usage, validate fold independence</td>\n<td>Fix seed management, ensure strict train/validation separation</td>\n</tr>\n<tr>\n<td>Optimization selects poor parameters</td>\n<td>Insufficient cross-validation or statistical issues</td>\n<td>Examine individual fold results, check metric calculation</td>\n<td>Increase fold count, validate metric implementations</td>\n</tr>\n<tr>\n<td>Component coordination errors</td>\n<td>Interface mismatches or invalid data passing</td>\n<td>Trace data flow between components, validate interfaces</td>\n<td>Add comprehensive input validation, fix interface contracts</td>\n</tr>\n</tbody></table>\n<h2 id=\"error-handling-and-edge-cases\">Error Handling and Edge Cases</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Comprehensive error handling for all milestones - input validation for distance calculation (Milestone 1), edge case handling for neighbor finding and classification (Milestone 2), and robust evaluation pipeline error management (Milestone 3)</p>\n</blockquote>\n<p>Think of error handling in a KNN classifier as building a safety net for a neighborhood recommendation system. Just as you wouldn&#39;t trust restaurant recommendations from someone who has never been to your city, has completely different tastes, or can&#39;t even tell you which restaurants they&#39;ve tried, your KNN system must validate that the data makes sense before making predictions. A robust error handling system acts like a careful friend who double-checks directions, verifies the restaurant is still open, and makes sure you&#39;re not allergic to any ingredients before giving their recommendation.</p>\n<p>The KNN algorithm is particularly susceptible to input validation issues because it operates directly on raw feature vectors and makes assumptions about data consistency, numerical stability, and parameter validity. Unlike parametric models that learn fixed parameters during training, KNN&#39;s lazy learning approach means that every prediction depends on the entire training dataset and distance calculations, making comprehensive validation critical at every step.</p>\n<h3 id=\"input-validation\">Input Validation</h3>\n<p>Input validation forms the first line of defense against system failures and incorrect predictions. The KNN classifier must validate three categories of inputs: training data consistency, query point compatibility, and algorithm parameters. Each category has specific validation rules that must be enforced to prevent silent failures and ensure prediction accuracy.</p>\n<p><strong>Training Data Validation</strong> ensures that the <code>TrainingData</code> structure contains consistent and usable information for distance calculation and classification. The validation process must verify dimensional consistency across all feature vectors, check for valid class labels, and ensure sufficient data for meaningful predictions.</p>\n<table>\n<thead>\n<tr>\n<th>Validation Rule</th>\n<th>Check Description</th>\n<th>Error Condition</th>\n<th>Recovery Action</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Feature Matrix Shape</td>\n<td>All training samples have identical feature count</td>\n<td>Inconsistent n_features dimension</td>\n<td>Raise <code>ValueError</code> with dimension mismatch details</td>\n</tr>\n<tr>\n<td>Non-Empty Dataset</td>\n<td>Training data contains at least one sample</td>\n<td>Empty feature matrix or label list</td>\n<td>Raise <code>ValueError</code> requesting minimum data</td>\n</tr>\n<tr>\n<td>Label-Feature Alignment</td>\n<td>Number of labels matches number of feature vectors</td>\n<td>len(labels) != n_samples</td>\n<td>Raise <code>ValueError</code> with count mismatch</td>\n</tr>\n<tr>\n<td>Numeric Feature Values</td>\n<td>All features are finite numeric values</td>\n<td>NaN, infinite, or non-numeric values</td>\n<td>Raise <code>ValueError</code> with invalid value locations</td>\n</tr>\n<tr>\n<td>Valid Class Labels</td>\n<td>All labels are hashable and non-null</td>\n<td>None, unhashable types in labels</td>\n<td>Raise <code>TypeError</code> with invalid label examples</td>\n</tr>\n<tr>\n<td>Minimum Class Diversity</td>\n<td>At least one unique class present</td>\n<td>All labels identical (edge case)</td>\n<td>Log warning but allow single-class training</td>\n</tr>\n</tbody></table>\n<p>The <code>TrainingData</code> validation process begins by examining the feature matrix shape and ensuring that <code>n_samples</code> and <code>n_features</code> match the actual data dimensions. The validator then scans for numeric anomalies that could cause distance calculation failures, such as NaN values that would propagate through vectorized operations or infinite values that could dominate distance computations.</p>\n<p><strong>Query Point Validation</strong> ensures that prediction requests contain compatible feature vectors that can be compared against the training data using the selected distance metric. This validation is critical because dimensional mismatches or invalid values would cause silent errors or nonsensical predictions.</p>\n<table>\n<thead>\n<tr>\n<th>Query Validation</th>\n<th>Check Description</th>\n<th>Error Condition</th>\n<th>Recovery Action</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Dimensional Compatibility</td>\n<td>Query features match training n_features</td>\n<td>query.shape[-1] != training.n_features</td>\n<td>Raise <code>ValueError</code> with expected vs actual dimensions</td>\n</tr>\n<tr>\n<td>Numeric Validity</td>\n<td>Query contains only finite numeric values</td>\n<td>NaN, infinite values in query point</td>\n<td>Raise <code>ValueError</code> with invalid value positions</td>\n</tr>\n<tr>\n<td>Feature Matrix Shape</td>\n<td>Batch queries have correct 2D shape</td>\n<td>Wrong number of dimensions in query matrix</td>\n<td>Raise <code>ValueError</code> with shape correction guidance</td>\n</tr>\n<tr>\n<td>Non-Empty Queries</td>\n<td>At least one query point provided</td>\n<td>Empty query matrix passed to predict</td>\n<td>Raise <code>ValueError</code> requesting valid query data</td>\n</tr>\n<tr>\n<td>Memory Constraints</td>\n<td>Query batch size within reasonable limits</td>\n<td>Extremely large batch causing memory issues</td>\n<td>Raise <code>MemoryError</code> with batch size reduction suggestion</td>\n</tr>\n</tbody></table>\n<p>The <code>validate_compatible_vectors</code> function performs the core compatibility check by comparing feature dimensions and ensuring that the query point can be meaningfully compared to training samples using vectorized distance calculations.</p>\n<p><strong>Parameter Validation</strong> verifies that algorithm configuration parameters are within valid ranges and compatible with the training data characteristics. Parameter validation prevents common mistakes like setting K larger than the dataset size or using invalid distance metrics.</p>\n<table>\n<thead>\n<tr>\n<th>Parameter</th>\n<th>Valid Range</th>\n<th>Error Condition</th>\n<th>Recovery Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>K Value</td>\n<td>1 ≤ k ≤ n_samples</td>\n<td>k &lt;= 0 or k &gt; training samples</td>\n<td>Raise <code>ValueError</code> with suggested valid range</td>\n</tr>\n<tr>\n<td>Distance Metric</td>\n<td>Valid <code>DistanceMetric</code> enum</td>\n<td>Unknown metric string or invalid enum</td>\n<td>Raise <code>ValueError</code> with available metric list</td>\n</tr>\n<tr>\n<td>Voting Strategy</td>\n<td>Valid <code>VotingStrategy</code> enum</td>\n<td>Invalid weighted voting configuration</td>\n<td>Raise <code>ValueError</code> with strategy descriptions</td>\n</tr>\n<tr>\n<td>Cross-Validation Folds</td>\n<td>2 ≤ folds ≤ n_samples</td>\n<td>Too few folds or more folds than samples</td>\n<td>Raise <code>ValueError</code> with practical fold range</td>\n</tr>\n<tr>\n<td>Random Seed</td>\n<td>Valid integer or None</td>\n<td>Non-integer seed values</td>\n<td>Raise <code>TypeError</code> with seed requirements</td>\n</tr>\n</tbody></table>\n<p>The <code>validate_k_parameter</code> function implements sophisticated K validation that considers not just the mathematical constraint (K ≤ n_samples) but also practical considerations like warning when K is too large relative to dataset size, which can lead to poor classification performance.</p>\n<blockquote>\n<p><strong>Design Insight</strong>: Input validation in KNN requires balancing strictness with usability. While dimensional mismatches must trigger immediate errors to prevent incorrect calculations, some edge cases like single-class datasets might warrant warnings rather than failures, allowing users to proceed with degraded functionality when appropriate.</p>\n</blockquote>\n<h3 id=\"numerical-error-handling\">Numerical Error Handling</h3>\n<p>Numerical stability becomes critical in KNN implementations because distance calculations involve floating-point arithmetic that can suffer from precision loss, overflow, and underflow conditions. The system must detect and handle these numerical issues while maintaining prediction accuracy and preventing silent failures.</p>\n<p><strong>Floating-Point Precision Management</strong> addresses the fundamental challenge that floating-point arithmetic is not exact, and small precision errors can accumulate during distance calculations, particularly when dealing with high-dimensional feature spaces or extreme feature values.</p>\n<table>\n<thead>\n<tr>\n<th>Numerical Issue</th>\n<th>Detection Method</th>\n<th>Manifestation</th>\n<th>Mitigation Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Precision Loss</td>\n<td>Check for extremely small distance differences</td>\n<td>Ties in distance ranking where none should exist</td>\n<td>Use <code>numpy.isclose</code> with appropriate tolerance</td>\n</tr>\n<tr>\n<td>Overflow in Squared Distances</td>\n<td>Monitor for <code>inf</code> values in distance arrays</td>\n<td>Euclidean distance calculation produces infinity</td>\n<td>Clamp feature values or use normalized features</td>\n</tr>\n<tr>\n<td>Underflow in Inverse Weighting</td>\n<td>Detect zero distances in weighted voting</td>\n<td>Division by zero in distance weighting</td>\n<td>Add small epsilon value to distances</td>\n</tr>\n<tr>\n<td>Accumulated Rounding Errors</td>\n<td>Validate distance triangle inequality</td>\n<td>Inconsistent distance relationships</td>\n<td>Use higher precision arithmetic for critical calculations</td>\n</tr>\n<tr>\n<td>NaN Propagation</td>\n<td>Scan distance arrays for NaN values</td>\n<td>Invalid distance calculations spreading</td>\n<td>Identify and isolate NaN sources in feature data</td>\n</tr>\n</tbody></table>\n<p>The distance calculation functions implement numerical safeguards by checking for edge cases before performing potentially problematic operations. For example, the <code>euclidean_distance</code> function validates that the sum of squared differences is non-negative before taking the square root, preventing domain errors that could produce NaN results.</p>\n<p><strong>Distance Calculation Stability</strong> requires special attention because distance metrics form the foundation of all KNN predictions. Each distance metric has specific numerical vulnerabilities that must be addressed through careful implementation and validation.</p>\n<table>\n<thead>\n<tr>\n<th>Distance Metric</th>\n<th>Numerical Vulnerability</th>\n<th>Error Condition</th>\n<th>Stabilization Technique</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Euclidean</td>\n<td>Squared differences overflow</td>\n<td>Very large feature values</td>\n<td>Feature scaling or clipping before calculation</td>\n</tr>\n<tr>\n<td>Manhattan</td>\n<td>No major numerical issues</td>\n<td>Robust to most inputs</td>\n<td>Minimal special handling required</td>\n</tr>\n<tr>\n<td>Cosine</td>\n<td>Division by zero in normalization</td>\n<td>Zero-magnitude vectors</td>\n<td>Check vector norms before division, handle zero case</td>\n</tr>\n<tr>\n<td>Weighted Distance</td>\n<td>Inverse distance calculation</td>\n<td>Exact distance matches between points</td>\n<td>Add small epsilon to prevent division by zero</td>\n</tr>\n</tbody></table>\n<p>The cosine distance implementation exemplifies robust numerical handling by computing vector magnitudes separately, checking for zero norms that would cause division by zero, and handling the special case where identical vectors should have zero distance despite the mathematical singularity.</p>\n<p><strong>Vectorized Operation Safety</strong> ensures that NumPy&#39;s broadcasting and vectorized operations don&#39;t mask numerical errors that would be obvious in scalar calculations. Broadcasting can hide dimensional mismatches, and vectorized operations can propagate errors across entire arrays.</p>\n<table>\n<thead>\n<tr>\n<th>Vectorization Risk</th>\n<th>Detection Strategy</th>\n<th>Error Pattern</th>\n<th>Prevention Approach</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Broadcasting Errors</td>\n<td>Validate array shapes before operations</td>\n<td>Silent dimension expansion causing wrong results</td>\n<td>Explicit shape checking in distance functions</td>\n</tr>\n<tr>\n<td>Parallel Error Propagation</td>\n<td>Check for NaN/inf in result arrays</td>\n<td>Single bad input affecting entire batch</td>\n<td>Input sanitization and per-sample validation</td>\n</tr>\n<tr>\n<td>Memory Overflow</td>\n<td>Monitor memory usage during large batch operations</td>\n<td>System memory exhaustion</td>\n<td>Batch size limits and progressive processing</td>\n</tr>\n<tr>\n<td>Loss of Precision</td>\n<td>Compare vectorized vs scalar results on test cases</td>\n<td>Subtle accuracy degradation</td>\n<td>Use appropriate NumPy data types (float64)</td>\n</tr>\n</tbody></table>\n<p>The <code>calculate_distances_to_point</code> function implements comprehensive safety checks by validating input array shapes, monitoring for numerical anomalies in the result array, and using appropriate data types to maintain precision throughout vectorized distance calculations.</p>\n<blockquote>\n<p><strong>Critical Insight</strong>: Numerical stability in KNN isn&#39;t just about preventing crashes—small precision errors can change neighbor rankings and lead to different classification decisions. The system must balance computational efficiency with numerical accuracy to maintain prediction consistency.</p>\n</blockquote>\n<h3 id=\"edge-case-handling\">Edge Case Handling</h3>\n<p>Edge case handling addresses the boundary conditions and unusual scenarios that can arise in real-world KNN usage. These cases often involve dataset characteristics or parameter configurations that are technically valid but require special handling to produce meaningful results.</p>\n<p><strong>Dataset Edge Cases</strong> encompass scenarios where the training data has unusual characteristics that challenge standard KNN assumptions. These cases require specialized handling to either adapt the algorithm behavior or provide informative feedback to the user.</p>\n<table>\n<thead>\n<tr>\n<th>Edge Case</th>\n<th>Scenario Description</th>\n<th>Challenge</th>\n<th>Handling Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Single Sample Dataset</td>\n<td>Training data contains only one example</td>\n<td>Cannot find K &gt; 1 neighbors</td>\n<td>Reduce K to 1 and return single training label</td>\n</tr>\n<tr>\n<td>Single Class Dataset</td>\n<td>All training samples have identical class</td>\n<td>Classification becomes trivial</td>\n<td>Return constant class with confidence warning</td>\n</tr>\n<tr>\n<td>Empty Feature Vectors</td>\n<td>Zero-dimensional feature space</td>\n<td>Distance calculation undefined</td>\n<td>Raise <code>ValueError</code> requesting valid features</td>\n</tr>\n<tr>\n<td>Duplicate Feature Vectors</td>\n<td>Multiple samples with identical features</td>\n<td>Distance ties affecting neighbor selection</td>\n<td>Use class label or sample index for tie-breaking</td>\n</tr>\n<tr>\n<td>Extremely Small Dataset</td>\n<td>Fewer than K training samples</td>\n<td>Cannot satisfy K-neighbor requirement</td>\n<td>Reduce K to dataset size and log warning</td>\n</tr>\n<tr>\n<td>Highly Imbalanced Classes</td>\n<td>One class dominates training data</td>\n<td>Majority voting bias toward dominant class</td>\n<td>Suggest weighted voting or stratified sampling</td>\n</tr>\n</tbody></table>\n<p>The single sample dataset case illustrates the importance of graceful degradation—rather than failing completely, the system reduces K to 1 and returns the only available training label, while logging a warning about the limitation. This approach allows users to proceed with minimal functionality rather than encountering a complete failure.</p>\n<p><strong>Parameter Edge Cases</strong> involve algorithm configurations that are technically valid but lead to degenerate or suboptimal behavior. The system must detect these cases and either adapt automatically or warn users about potential issues.</p>\n<table>\n<thead>\n<tr>\n<th>Parameter Edge Case</th>\n<th>Configuration</th>\n<th>Problem</th>\n<th>Adaptive Response</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>K Equals Dataset Size</td>\n<td>k = n_samples</td>\n<td>All training samples are &quot;neighbors&quot;</td>\n<td>Allow but warn about meaningless voting</td>\n</tr>\n<tr>\n<td>K Is Even Number</td>\n<td>Even k value</td>\n<td>Increased probability of voting ties</td>\n<td>Suggest odd K values or enable weighted voting</td>\n</tr>\n<tr>\n<td>Very Large K</td>\n<td>K &gt; n_samples/2</td>\n<td>Classification converges to majority class</td>\n<td>Warn about loss of locality assumption</td>\n</tr>\n<tr>\n<td>Very Small K</td>\n<td>K = 1</td>\n<td>High variance, noise sensitivity</td>\n<td>Warn about overfitting potential</td>\n</tr>\n<tr>\n<td>Invalid Distance Metric</td>\n<td>Unsupported metric string</td>\n<td>Cannot compute distances</td>\n<td>Raise <code>ValueError</code> with supported options</td>\n</tr>\n</tbody></table>\n<p>The <code>validate_k_parameter</code> function implements intelligent edge case detection by not only checking mathematical validity but also analyzing the practical implications of extreme K values and providing guidance to users about potential issues with their parameter choices.</p>\n<p><strong>Prediction Edge Cases</strong> occur during the actual classification process when the combination of query points, training data, and algorithm parameters creates unusual situations that require special handling to produce reasonable results.</p>\n<table>\n<thead>\n<tr>\n<th>Prediction Edge Case</th>\n<th>Situation</th>\n<th>Consequence</th>\n<th>Resolution Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Voting Ties</td>\n<td>Equal votes for multiple classes</td>\n<td>Ambiguous classification decision</td>\n<td>Use distance-based tie-breaking or random selection</td>\n</tr>\n<tr>\n<td>Identical Query and Training</td>\n<td>Zero distance to training sample</td>\n<td>Perfect match but potential overfitting</td>\n<td>Return exact match class with high confidence</td>\n</tr>\n<tr>\n<td>All Neighbors Same Class</td>\n<td>K neighbors have identical labels</td>\n<td>Trivial voting but high confidence</td>\n<td>Return unanimous class with maximum confidence</td>\n</tr>\n<tr>\n<td>Distance Calculation Failure</td>\n<td>Invalid features produce NaN distances</td>\n<td>Cannot rank neighbors</td>\n<td>Raise prediction error with diagnostic information</td>\n</tr>\n<tr>\n<td>Memory Exhaustion</td>\n<td>Large batch prediction exceeds memory</td>\n<td>System failure during prediction</td>\n<td>Split batch into smaller chunks automatically</td>\n</tr>\n</tbody></table>\n<p>The voting tie case demonstrates sophisticated edge case handling where the system first attempts distance-based tie-breaking by examining which tied class has the closest individual neighbor, and only falls back to random selection if distances are also tied.</p>\n<p><strong>Data Quality Edge Cases</strong> address scenarios where the input data has quality issues that don&#39;t prevent processing but could lead to poor predictions or misleading results.</p>\n<table>\n<thead>\n<tr>\n<th>Data Quality Issue</th>\n<th>Detection Method</th>\n<th>Impact on KNN</th>\n<th>Mitigation Approach</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Feature Scale Disparities</td>\n<td>Analyze feature variance across dimensions</td>\n<td>Distance dominated by large-scale features</td>\n<td>Warn about need for feature scaling</td>\n</tr>\n<tr>\n<td>Sparse Feature Vectors</td>\n<td>Count zero values in feature dimensions</td>\n<td>Distance metrics may not be meaningful</td>\n<td>Suggest appropriate distance metrics</td>\n</tr>\n<tr>\n<td>Categorical Features as Numbers</td>\n<td>Detect integer features with few unique values</td>\n<td>Euclidean distance inappropriate</td>\n<td>Warn about categorical encoding needs</td>\n</tr>\n<tr>\n<td>Missing Value Indicators</td>\n<td>Identify placeholder values (-999, -1, etc.)</td>\n<td>Invalid distance calculations</td>\n<td>Detect and reject invalid indicator values</td>\n</tr>\n<tr>\n<td>Outlier Samples</td>\n<td>Statistical outlier detection in training data</td>\n<td>Disproportionate influence on predictions</td>\n<td>Log outlier warnings with sample indices</td>\n</tr>\n</tbody></table>\n<p>The feature scale disparity detection exemplifies proactive data quality monitoring—the system analyzes feature variance distributions and warns users when some features have orders of magnitude larger scales than others, suggesting feature normalization before training.</p>\n<blockquote>\n<p><strong>Edge Case Philosophy</strong>: The goal isn&#39;t to handle every possible edge case transparently, but to detect unusual conditions, fail gracefully with informative error messages, and guide users toward appropriate solutions. Sometimes the best handling is a clear error message explaining why the operation cannot proceed.</p>\n</blockquote>\n<p><strong>⚠️ Pitfall: Silent Edge Case Failures</strong>\nMany KNN implementations fail silently when encountering edge cases, producing technically valid but meaningless results. For example, setting K equal to the dataset size technically works but makes every prediction the majority class regardless of the query point. Always validate not just technical correctness but practical meaningfulness of parameters and configurations.</p>\n<p><strong>⚠️ Pitfall: Inadequate Tie-Breaking</strong>\nWhen multiple classes receive equal votes, some implementations use arbitrary tie-breaking (like alphabetical order) that can introduce bias. Implement distance-based tie-breaking where the class with the closest individual neighbor wins, falling back to random selection only when distances are also tied.</p>\n<p><strong>⚠️ Pitfall: Ignoring Numerical Precision</strong>\nFloating-point precision issues can cause apparently identical distances to have tiny differences that affect neighbor ranking. Use appropriate tolerance values when comparing distances and implement robust tie detection that accounts for numerical precision limitations.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The error handling implementation requires a systematic approach that validates inputs at component boundaries, manages numerical stability during calculations, and gracefully handles edge cases throughout the prediction pipeline.</p>\n<p><strong>Technology Recommendations:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Input Validation</td>\n<td>Built-in Python type checking with manual validation</td>\n<td>Pydantic models with automatic validation</td>\n</tr>\n<tr>\n<td>Numerical Stability</td>\n<td>NumPy&#39;s built-in error handling with manual checks</td>\n<td>Decimal module for high-precision calculations</td>\n</tr>\n<tr>\n<td>Error Logging</td>\n<td>Python logging module with structured messages</td>\n<td>Structured logging with JSON format</td>\n</tr>\n<tr>\n<td>Exception Handling</td>\n<td>Standard Python exceptions with custom messages</td>\n<td>Custom exception hierarchy with error codes</td>\n</tr>\n</tbody></table>\n<p><strong>Recommended File Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>knn_classifier/\n├── exceptions.py           # Custom exception definitions\n├── validation.py           # Input validation functions\n├── numerical_utils.py      # Numerical stability helpers\n├── edge_case_handlers.py   # Edge case detection and handling\n└── error_recovery.py       # Graceful degradation strategies</code></pre></div>\n\n<p><strong>Infrastructure Starter Code:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># exceptions.py - Complete custom exception hierarchy</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Any, List, Optional, Union</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> KNNError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">Exception</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Base exception for KNN classifier errors\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ValidationError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">KNNError</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Raised when input validation fails\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, invalid_data: Optional[Any] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">(message)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.invalid_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> invalid_data</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> NumericalInstabilityError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">KNNError</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Raised when numerical calculations become unstable\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, problematic_values: Optional[np.ndarray] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">(message)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.problematic_values </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> problematic_values</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> EdgeCaseError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">KNNError</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Raised when edge cases cannot be handled gracefully\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, edge_case_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">(message)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.edge_case_type </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> edge_case_type</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># numerical_utils.py - Complete numerical stability helpers</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> warnings</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Tuple, Optional</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">EPSILON</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1e-10</span><span style=\"color:#6A737D\">  # Small value for numerical stability</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">DISTANCE_TOLERANCE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1e-8</span><span style=\"color:#6A737D\">  # Tolerance for distance comparisons</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> safe_sqrt</span><span style=\"color:#E1E4E8\">(values: np.ndarray) -> np.ndarray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Safely compute square root, handling negative values from precision errors\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Clamp near-zero negative values to zero</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    safe_values </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.maximum(values, </span><span style=\"color:#79B8FF\">0.0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> np.any(values </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">EPSILON</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        warnings.warn(</span><span style=\"color:#9ECBFF\">\"Negative values detected in square root input, clamping to zero\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> np.sqrt(safe_values)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> safe_divide</span><span style=\"color:#E1E4E8\">(numerator: np.ndarray, denominator: np.ndarray, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                default_value: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0.0</span><span style=\"color:#E1E4E8\">) -> np.ndarray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Safely divide arrays, handling division by zero\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    with</span><span style=\"color:#E1E4E8\"> np.errstate(</span><span style=\"color:#FFAB70\">divide</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">'ignore'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">invalid</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">'ignore'</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        result </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.divide(numerator, denominator)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Replace inf and nan with default value</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        mask </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> ~</span><span style=\"color:#E1E4E8\">np.isfinite(result)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        result[mask] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> default_value</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> result</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> check_numerical_stability</span><span style=\"color:#E1E4E8\">(array: np.ndarray, array_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Check array for numerical issues and raise errors if found\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> np.any(np.isnan(array)):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#E1E4E8\"> NumericalInstabilityError(</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            f</span><span style=\"color:#9ECBFF\">\"NaN values detected in </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">array_name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            problematic_values</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">array[np.isnan(array)]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> np.any(np.isinf(array)):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#E1E4E8\"> NumericalInstabilityError(</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            f</span><span style=\"color:#9ECBFF\">\"Infinite values detected in </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">array_name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            problematic_values</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">array[np.isinf(array)]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> detect_precision_loss</span><span style=\"color:#E1E4E8\">(distances: np.ndarray, k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Detect if precision loss is affecting neighbor selection\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(distances) </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> k:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Check if the k-th and (k+1)-th distances are suspiciously close</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    sorted_distances </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.sort(distances)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(sorted_distances) </span><span style=\"color:#F97583\">></span><span style=\"color:#E1E4E8\"> k:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        distance_gap </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> sorted_distances[k] </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> sorted_distances[k</span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> distance_gap </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> DISTANCE_TOLERANCE</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> False</span></span></code></pre></div>\n\n<p><strong>Core Logic Skeleton Code:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># validation.py - Input validation core logic</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Union, Optional, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .exceptions </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> ValidationError</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .data_types </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> FeatureMatrix, FeatureVector, ClassLabel, TrainingData</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> validate_training_data</span><span style=\"color:#E1E4E8\">(features: FeatureMatrix, labels: List[ClassLabel]) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Comprehensive validation of training data consistency and quality\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check that features is a valid 2D numpy array with shape (n_samples, n_features)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Verify that labels list has exactly n_samples elements</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Ensure all feature values are finite (no NaN, no infinite values)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Validate that all labels are hashable and non-None</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Check for minimum dataset requirements (at least 1 sample, 1 feature)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Warn if all labels are identical (single-class dataset)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: Use np.isfinite() to check for valid numeric values</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> validate_query_points</span><span style=\"color:#E1E4E8\">(query_points: FeatureMatrix, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                         training_n_features: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Validate query points for prediction compatibility\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Ensure query_points is a valid numpy array (1D or 2D)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check dimensional compatibility with training data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify all query values are finite numeric values</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Validate reasonable batch size to prevent memory issues</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: Handle both single query (1D) and batch query (2D) cases</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> validate_k_parameter</span><span style=\"color:#E1E4E8\">(k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, dataset_size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Validate K parameter against dataset constraints with helpful warnings\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check that k is a positive integer</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Ensure k does not exceed dataset size</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Warn if k is very large relative to dataset (> dataset_size/2)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Warn if k is even (increases tie probability)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Suggest optimal k range based on dataset characteristics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: Use warnings.warn() for non-fatal issues</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> validate_distance_metric</span><span style=\"color:#E1E4E8\">(metric: Union[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'DistanceMetric'</span><span style=\"color:#E1E4E8\">]) -> </span><span style=\"color:#9ECBFF\">'DistanceMetric'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Validate and normalize distance metric specification\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Handle string metric names by converting to enum</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Verify metric is a valid DistanceMetric enum value</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return normalized DistanceMetric enum</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Raise ValidationError with available options if invalid</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: Use DistanceMetric enum for standardized metric representation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># edge_case_handlers.py - Edge case detection and handling</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> handle_dataset_edge_cases</span><span style=\"color:#E1E4E8\">(training_data: TrainingData, k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Tuple[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Detect and handle dataset-related edge cases\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Detect single-sample dataset and adjust k to 1</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check for single-class dataset and warn about trivial classification</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Handle k larger than dataset size by reducing k</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Detect highly imbalanced classes and suggest alternatives</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return adjusted k and list of warnings for user notification</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: Calculate class distribution to detect imbalance</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> handle_prediction_edge_cases</span><span style=\"color:#E1E4E8\">(neighbor_labels: List[ClassLabel], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                neighbor_distances: np.ndarray) -> Tuple[ClassLabel, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Handle edge cases during prediction voting\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Detect voting ties and implement distance-based tie-breaking</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Handle case where query point exactly matches training sample</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Manage unanimous voting (all neighbors same class)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Calculate confidence score based on voting characteristics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return predicted class, confidence, and explanation string</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: Use distance information to break ties intelligently</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> detect_data_quality_issues</span><span style=\"color:#E1E4E8\">(features: FeatureMatrix, labels: List[ClassLabel]) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Detect potential data quality issues that could affect KNN performance\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Analyze feature scale disparities across dimensions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Detect suspicious patterns indicating categorical features</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Identify potential missing value indicators (-999, -1, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Check for statistical outliers in feature distributions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return list of warnings about detected quality issues</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: Use statistical measures like standard deviation ratios</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span></code></pre></div>\n\n<p><strong>Language-Specific Python Hints:</strong></p>\n<ul>\n<li>Use <code>numpy.errstate()</code> context manager to control floating-point error handling during calculations</li>\n<li>Leverage <code>warnings.warn()</code> for non-fatal issues that users should know about but don&#39;t prevent operation</li>\n<li>Implement custom exception classes that inherit from appropriate base exceptions and include diagnostic information</li>\n<li>Use <code>isinstance()</code> checks for robust type validation that handles inheritance and duck typing</li>\n<li>Apply <code>numpy.isfinite()</code> to check for both NaN and infinite values simultaneously</li>\n<li>Use <code>functools.wraps()</code> when creating validation decorators to preserve function metadata</li>\n</ul>\n<p><strong>Milestone Checkpoints:</strong></p>\n<p>After Milestone 1 (Distance Calculation):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/test_validation.py::test_distance_validation</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from knn_classifier import validate_training_data, euclidean_distance</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">import numpy as np</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\"># Test numerical stability</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">try:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    result = euclidean_distance(np.array([1e10, 1e10]), np.array([1e10 + 1, 1e10 + 1]))</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    print(f'Large number handling: {result}')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    validate_training_data(np.array([[1, 2], [3, float('inf')]]), ['A', 'B'])</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">except Exception as e:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    print(f'Error correctly caught: {e}')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span></code></pre></div>\n\n<p>After Milestone 2 (Classification):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from knn_classifier import KNNClassifier</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">import numpy as np</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\"># Test edge case handling</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">classifier = KNNClassifier(k=5)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">try:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    # Single sample dataset</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    classifier.fit(np.array([[1, 2]]), ['A'])</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    result = classifier.predict(np.array([[1.1, 2.1]]))</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    print(f'Single sample prediction: {result}')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">except Exception as e:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    print(f'Edge case handling: {e}')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span></code></pre></div>\n\n<p>After Milestone 3 (Evaluation):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from knn_classifier import k_fold_cross_validate</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">import numpy as np</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\"># Test evaluation robustness</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">X = np.random.rand(10, 3)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">y = ['A'] * 10  # All same class</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">try:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    results = k_fold_cross_validate(X, y, k_folds=3, k_neighbors=2)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    print(f'Single-class CV results: {results}')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">except Exception as e:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    print(f'Evaluation edge case: {e}')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span></code></pre></div>\n\n<p><strong>Debugging Tips:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Silent wrong predictions</td>\n<td>Input validation bypassed</td>\n<td>Check feature dimensions, data types</td>\n<td>Add comprehensive validation at entry points</td>\n</tr>\n<tr>\n<td>Intermittent NaN results</td>\n<td>Floating-point precision issues</td>\n<td>Log intermediate calculation values</td>\n<td>Use safe mathematical operations with bounds checking</td>\n</tr>\n<tr>\n<td>Memory errors during prediction</td>\n<td>Large batch processing</td>\n<td>Monitor memory usage, check batch sizes</td>\n<td>Implement automatic batch splitting</td>\n</tr>\n<tr>\n<td>Inconsistent neighbor selection</td>\n<td>Distance ties not handled</td>\n<td>Compare distance arrays for near-equal values</td>\n<td>Implement robust tie-breaking with tolerance</td>\n</tr>\n<tr>\n<td>Poor performance warnings ignored</td>\n<td>Edge case detection not visible</td>\n<td>Check warning log output</td>\n<td>Make warnings more prominent or upgrade to errors</td>\n</tr>\n</tbody></table>\n<h2 id=\"testing-strategy\">Testing Strategy</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Comprehensive testing strategy across all milestones - unit tests for distance calculation (Milestone 1), integration tests for neighbor finding and classification (Milestone 2), and milestone checkpoints for evaluation and optimization (Milestone 3)</p>\n</blockquote>\n<p>Testing a K-Nearest Neighbors classifier presents unique challenges compared to parametric machine learning models. Since KNN is based on lazy learning, most computation happens at prediction time, making it crucial to verify that distance calculations, neighbor finding, and voting mechanisms work correctly across diverse scenarios. The testing strategy must validate both the mathematical correctness of algorithms and the system&#39;s behavior under edge cases that are particularly common in instance-based learning.</p>\n<h3 id=\"mental-model-the-scientific-method-for-code\">Mental Model: The Scientific Method for Code</h3>\n<p>Think of testing a KNN implementation like conducting scientific experiments to validate a hypothesis. Each unit test is a controlled experiment that isolates one component and verifies it behaves as expected under specific conditions. Integration tests are like field studies that observe how components interact in realistic scenarios. Milestone checkpoints are comprehensive evaluations that ensure the entire system meets scientific standards for accuracy and reliability.</p>\n<p>Just as scientists use multiple validation techniques - from laboratory experiments to peer review - our testing strategy employs multiple layers of verification. Unit tests provide microscopic validation of individual algorithms, integration tests examine macroscopic system behavior, and milestone checkpoints ensure the implementation achieves the learning objectives and performance requirements.</p>\n<p>The key insight is that KNN testing requires special attention to numerical stability, edge cases with small datasets, and the correctness of distance-based computations that form the foundation of the entire algorithm. Unlike testing a web API where you might focus on HTTP status codes and JSON structure, KNN testing focuses on mathematical properties, algorithmic correctness, and performance under various data distributions.</p>\n<h3 id=\"unit-testing-strategy\">Unit Testing Strategy</h3>\n<p>Unit testing for KNN focuses on isolating and verifying each component independently, ensuring that distance calculations are mathematically correct, neighbor finding algorithms return proper results, and voting mechanisms handle edge cases gracefully. Since KNN relies heavily on numerical computations, unit tests must validate both correctness and numerical stability.</p>\n<p>The unit testing strategy follows a component-based approach that mirrors the system architecture. Each major component - distance calculation, neighbor finding, classification, and evaluation - requires comprehensive test coverage that validates normal operation, boundary conditions, and error scenarios. The tests must be deterministic and reproducible, which requires careful management of random seeds and floating-point comparisons.</p>\n<h4 id=\"distance-metrics-testing\">Distance Metrics Testing</h4>\n<p>Distance calculation forms the mathematical foundation of KNN, making it critical to verify that each metric produces correct results. The testing approach validates both mathematical correctness and computational efficiency of vectorized operations.</p>\n<table>\n<thead>\n<tr>\n<th>Test Category</th>\n<th>Test Cases</th>\n<th>Validation Criteria</th>\n<th>Expected Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Mathematical Correctness</td>\n<td>Known vector pairs with calculated distances</td>\n<td>Exact match within numerical tolerance</td>\n<td><code>euclidean_distance([0,0], [3,4])</code> returns 5.0</td>\n</tr>\n<tr>\n<td>Edge Cases</td>\n<td>Zero vectors, identical points, single dimensions</td>\n<td>Handle gracefully without errors</td>\n<td>Distance between identical points is 0.0</td>\n</tr>\n<tr>\n<td>Numerical Stability</td>\n<td>Very small/large numbers, near-zero differences</td>\n<td>No overflow, underflow, or NaN</td>\n<td><code>safe_sqrt</code> handles negative inputs from floating-point errors</td>\n</tr>\n<tr>\n<td>Vectorized Operations</td>\n<td>Batch distance calculations vs individual</td>\n<td>Performance improvement and identical results</td>\n<td><code>calculate_distances_to_point</code> faster than loops</td>\n</tr>\n<tr>\n<td>Input Validation</td>\n<td>Mismatched dimensions, invalid types</td>\n<td>Raise appropriate exceptions</td>\n<td><code>validate_compatible_vectors</code> catches dimension mismatch</td>\n</tr>\n</tbody></table>\n<p>The distance metrics tests use known mathematical relationships to verify correctness. For example, Euclidean distance tests use right triangles where the hypotenuse length is known, while Manhattan distance tests use grid-based scenarios where the sum of absolute differences can be calculated manually.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> test_euclidean_distance_right_triangle</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Test Euclidean distance using 3-4-5 right triangle.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    point1 </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.array([</span><span style=\"color:#79B8FF\">0.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0.0</span><span style=\"color:#E1E4E8\">], </span><span style=\"color:#FFAB70\">dtype</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">np.float64)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    point2 </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.array([</span><span style=\"color:#79B8FF\">3.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">4.0</span><span style=\"color:#E1E4E8\">], </span><span style=\"color:#FFAB70\">dtype</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">np.float64)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    expected_distance </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 5.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    actual_distance </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> euclidean_distance(point1, point2)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    assert</span><span style=\"color:#79B8FF\"> abs</span><span style=\"color:#E1E4E8\">(actual_distance </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> expected_distance) </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> DISTANCE_TOLERANCE</span></span></code></pre></div>\n\n<p>Numerical stability tests are particularly important for distance calculations because floating-point arithmetic can introduce small errors that compound during square root and division operations. These tests verify that the <code>safe_sqrt</code> and <code>safe_divide</code> functions handle edge cases like negative numbers under square roots (which can occur due to floating-point precision issues) and division by zero in cosine distance calculations.</p>\n<h4 id=\"neighbor-finding-testing\">Neighbor Finding Testing</h4>\n<p>Neighbor finding algorithms must correctly identify the K closest training samples while handling various edge cases like ties in distances, invalid K values, and empty datasets. The unit tests validate both the correctness of neighbor selection and the proper handling of boundary conditions.</p>\n<table>\n<thead>\n<tr>\n<th>Test Category</th>\n<th>Test Cases</th>\n<th>Validation Criteria</th>\n<th>Expected Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Correct K Selection</td>\n<td>Known datasets with calculated neighbors</td>\n<td>Return exactly K closest neighbors</td>\n<td>Sort neighbors by ascending distance</td>\n</tr>\n<tr>\n<td>Tie Handling</td>\n<td>Multiple neighbors with identical distances</td>\n<td>Consistent tie-breaking behavior</td>\n<td>Use <code>handle_distance_ties</code> with stable sorting</td>\n</tr>\n<tr>\n<td>Edge Cases</td>\n<td>K=1, K=dataset_size, K&gt;dataset_size</td>\n<td>Handle gracefully or raise errors</td>\n<td><code>validate_k_parameter</code> catches invalid K</td>\n</tr>\n<tr>\n<td>Distance Metric Integration</td>\n<td>Same neighbors with different metrics</td>\n<td>Different results but consistent ranking</td>\n<td>Euclidean vs Manhattan yield different neighbors</td>\n</tr>\n<tr>\n<td>Performance</td>\n<td>Large datasets with batch queries</td>\n<td>Efficient vectorized operations</td>\n<td><code>find_neighbors_batch</code> outperforms individual queries</td>\n</tr>\n</tbody></table>\n<p>The neighbor finding tests create small synthetic datasets where the correct neighbors can be determined manually. For example, a 2D dataset with points arranged in a grid pattern allows manual verification of which points should be closest under different distance metrics.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> test_find_k_neighbors_simple_grid</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Test neighbor finding on a simple 2D grid where neighbors are obvious.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Create a 3x3 grid with query point at center</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    training_points </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.array([</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        [</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">], [</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">], [</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">],  </span><span style=\"color:#6A737D\"># Left column</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        [</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">], [</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">], [</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">],  </span><span style=\"color:#6A737D\"># Middle column</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        [</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">], [</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">], [</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">]   </span><span style=\"color:#6A737D\"># Right column</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ], </span><span style=\"color:#FFAB70\">dtype</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">np.float64)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    query_point </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.array([</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">], </span><span style=\"color:#FFAB70\">dtype</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">np.float64)  </span><span style=\"color:#6A737D\"># Center point</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    k </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 3</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # The 3 closest neighbors to (1,1) should be (0,1), (1,0), and (1,2) at distance 1.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    neighbor_indices, neighbor_distances </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> find_k_neighbors(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        query_point, k, DistanceMetric.</span><span style=\"color:#79B8FF\">EUCLIDEAN</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    assert</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(neighbor_indices) </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> k</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    assert</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(neighbor_distances) </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> k</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    assert</span><span style=\"color:#E1E4E8\"> np.all(neighbor_distances </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 1.414</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># sqrt(2) for diagonal neighbors</span></span></code></pre></div>\n\n<p>Tie-handling tests are crucial because multiple training points may have identical distances to a query point, especially in discrete or quantized feature spaces. The tests verify that the system breaks ties consistently and deterministically, typically by preferring neighbors with lower indices in the training data.</p>\n<h4 id=\"classification-voting-testing\">Classification Voting Testing</h4>\n<p>Classification voting converts neighbor labels into final predictions through majority or weighted voting. Unit tests must verify that voting algorithms correctly aggregate neighbor information and handle edge cases like voting ties and unanimous decisions.</p>\n<table>\n<thead>\n<tr>\n<th>Test Category</th>\n<th>Test Cases</th>\n<th>Validation Criteria</th>\n<th>Expected Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Majority Voting</td>\n<td>Known neighbor labels with clear majority</td>\n<td>Return most frequent class</td>\n<td>3 votes for class A, 2 for class B → predict A</td>\n</tr>\n<tr>\n<td>Weighted Voting</td>\n<td>Neighbor labels with distances</td>\n<td>Closer neighbors have more influence</td>\n<td>Closer neighbor breaks ties in weighted voting</td>\n</tr>\n<tr>\n<td>Tie Breaking</td>\n<td>Equal votes across multiple classes</td>\n<td>Consistent tie resolution</td>\n<td><code>resolve_ties</code> uses nearest neighbor or deterministic rule</td>\n</tr>\n<tr>\n<td>Confidence Scoring</td>\n<td>Various voting scenarios</td>\n<td>Higher confidence for unanimous decisions</td>\n<td>Confidence near 1.0 for unanimous, lower for close votes</td>\n</tr>\n<tr>\n<td>Edge Cases</td>\n<td>Single neighbor, all neighbors same class</td>\n<td>Handle gracefully</td>\n<td>Single neighbor gets 100% confidence</td>\n</tr>\n</tbody></table>\n<p>Voting tests use carefully constructed scenarios where the correct prediction can be determined manually. For example, a test might create a neighbor set with 3 votes for class &quot;A&quot; and 2 votes for class &quot;B&quot;, then verify that majority voting returns &quot;A&quot; with appropriate confidence.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> test_majority_vote_clear_winner</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Test majority voting with a clear winning class.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    neighbor_labels </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span><span style=\"color:#9ECBFF\">'A'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'A'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'A'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'B'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'B'</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    neighbor_distances </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.array([</span><span style=\"color:#79B8FF\">1.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1.5</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">2.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">2.5</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">3.0</span><span style=\"color:#E1E4E8\">])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    k </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 5</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    predicted_class, confidence </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> majority_vote(neighbor_labels, k)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    assert</span><span style=\"color:#E1E4E8\"> predicted_class </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> 'A'</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    assert</span><span style=\"color:#E1E4E8\"> confidence </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 3.0</span><span style=\"color:#F97583\"> /</span><span style=\"color:#79B8FF\"> 5.0</span><span style=\"color:#6A737D\">  # 3 out of 5 votes</span></span></code></pre></div>\n\n<p>Weighted voting tests verify that closer neighbors receive proportionally more influence in the final decision. These tests create scenarios where majority voting and weighted voting yield different results, confirming that distance weighting is applied correctly.</p>\n<h4 id=\"evaluation-and-optimization-testing\">Evaluation and Optimization Testing</h4>\n<p>Evaluation components require testing of cross-validation, hyperparameter optimization, and metric calculation. These tests ensure that performance assessment is statistically sound and that optimization procedures find reasonable parameter values.</p>\n<table>\n<thead>\n<tr>\n<th>Test Category</th>\n<th>Test Cases</th>\n<th>Validation Criteria</th>\n<th>Expected Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Cross-Validation</td>\n<td>Known datasets with expected metrics</td>\n<td>Reproducible results with same seed</td>\n<td><code>k_fold_cross_validate</code> returns consistent metrics</td>\n</tr>\n<tr>\n<td>Stratification</td>\n<td>Imbalanced datasets</td>\n<td>Preserve class ratios in folds</td>\n<td><code>split_stratified_folds</code> maintains class distribution</td>\n</tr>\n<tr>\n<td>Metric Calculation</td>\n<td>Known predictions vs true labels</td>\n<td>Correct precision, recall, F1</td>\n<td><code>calculate_classification_metrics</code> matches manual calculation</td>\n</tr>\n<tr>\n<td>Grid Search</td>\n<td>Small parameter ranges</td>\n<td>Find reasonable optimal K</td>\n<td><code>grid_search_k</code> selects K that improves validation accuracy</td>\n</tr>\n<tr>\n<td>Statistical Validity</td>\n<td>Multiple runs with different seeds</td>\n<td>Stable results across runs</td>\n<td>Performance estimates have reasonable confidence intervals</td>\n</tr>\n</tbody></table>\n<p>Cross-validation tests use small synthetic datasets where the expected performance can be estimated manually. For example, a perfectly separable dataset should achieve near-perfect accuracy, while a dataset with overlapping classes should show lower performance that matches theoretical expectations.</p>\n<h3 id=\"integration-testing-strategy\">Integration Testing Strategy</h3>\n<p>Integration testing validates how components work together during the complete KNN workflow, from loading training data through making predictions and evaluating performance. These tests ensure that data flows correctly between components and that the system handles realistic scenarios effectively.</p>\n<p>Integration tests focus on end-to-end workflows that mirror how users interact with the KNN classifier. Unlike unit tests that isolate individual functions, integration tests validate that components communicate properly and that the system produces reasonable results on real datasets. The tests must verify both functional correctness and performance characteristics.</p>\n<h4 id=\"training-and-prediction-workflow-integration\">Training and Prediction Workflow Integration</h4>\n<p>The core integration test validates the complete training and prediction pipeline, ensuring that data flows correctly from initial training through final predictions. This workflow integration test exercises all major system components in sequence.</p>\n<table>\n<thead>\n<tr>\n<th>Integration Scenario</th>\n<th>Test Data</th>\n<th>Validation Criteria</th>\n<th>Expected Outcome</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Complete Pipeline</td>\n<td>Iris dataset with train/test split</td>\n<td>Accuracy above baseline threshold</td>\n<td><code>fit()</code> → <code>predict()</code> → evaluate accuracy &gt; 0.80</td>\n</tr>\n<tr>\n<td>Different Distance Metrics</td>\n<td>Same data with EUCLIDEAN vs MANHATTAN</td>\n<td>Different but reasonable results</td>\n<td>Both metrics produce valid predictions</td>\n</tr>\n<tr>\n<td>Various K Values</td>\n<td>K=1, K=5, K=10 on same dataset</td>\n<td>Performance varies predictably</td>\n<td>Small K higher variance, large K smoother decisions</td>\n</tr>\n<tr>\n<td>Batch Prediction</td>\n<td>Multiple query points simultaneously</td>\n<td>Identical to individual predictions</td>\n<td>Batch and individual results match exactly</td>\n</tr>\n<tr>\n<td>Feature Scaling Impact</td>\n<td>Scaled vs unscaled features</td>\n<td>Scaling affects distance-based results</td>\n<td>Euclidean distance sensitive to scaling, need preprocessing</td>\n</tr>\n</tbody></table>\n<p>The pipeline integration test creates a complete workflow that loads data, splits it into training and testing sets, fits a KNN classifier, makes predictions, and evaluates performance. This test serves as a smoke test that verifies basic system functionality.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> test_complete_knn_pipeline</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Integration test for complete KNN training and prediction pipeline.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Load and prepare data</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    X, y </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> load_iris_dataset()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    X_train, X_test, y_train, y_test </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> split_and_scale_data(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        X, y, </span><span style=\"color:#FFAB70\">test_size</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0.3</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">scale_features</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">random_state</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">42</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Create and train classifier</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    classifier </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> KNNClassifier(</span><span style=\"color:#FFAB70\">k</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">distance_metric</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">DistanceMetric.</span><span style=\"color:#79B8FF\">EUCLIDEAN</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    classifier.fit(X_train, y_train)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Make predictions</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    predictions </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> classifier.predict(X_test)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Evaluate performance</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    metrics </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> calculate_classification_metrics(y_test, predictions, </span><span style=\"color:#FFAB70\">average</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">'macro'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Verify reasonable performance</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    assert</span><span style=\"color:#E1E4E8\"> metrics[</span><span style=\"color:#9ECBFF\">'accuracy'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0.80</span><span style=\"color:#6A737D\">  # Iris is easily separable</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    assert</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(predictions) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(y_test)  </span><span style=\"color:#6A737D\"># All test samples predicted</span></span></code></pre></div>\n\n<p>Distance metric integration tests verify that different metrics produce reasonable but distinct results when applied to the same dataset. These tests help identify whether distance metric selection is working properly and whether the system handles metric-specific edge cases.</p>\n<h4 id=\"cross-validation-and-optimization-integration\">Cross-Validation and Optimization Integration</h4>\n<p>Cross-validation integration tests validate that evaluation and optimization components work together correctly, ensuring that hyperparameter tuning produces reliable results and that performance estimates are statistically sound.</p>\n<table>\n<thead>\n<tr>\n<th>Integration Scenario</th>\n<th>Test Configuration</th>\n<th>Validation Criteria</th>\n<th>Expected Outcome</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>K-Fold Cross-Validation</td>\n<td>5-fold CV with multiple K values</td>\n<td>Stable performance estimates</td>\n<td>Standard deviation reasonable relative to mean</td>\n</tr>\n<tr>\n<td>Stratified Splitting</td>\n<td>Imbalanced dataset with stratification</td>\n<td>Class ratios preserved across folds</td>\n<td>Each fold maintains original class distribution</td>\n</tr>\n<tr>\n<td>Grid Search Optimization</td>\n<td>K values [1, 3, 5, 7, 9] with 3-fold CV</td>\n<td>Optimal K selected based on validation</td>\n<td>Grid search finds K that maximizes validation accuracy</td>\n</tr>\n<tr>\n<td>Nested Cross-Validation</td>\n<td>Inner loop for K selection, outer for performance</td>\n<td>Unbiased performance estimate</td>\n<td>Nested CV prevents overfitting to validation set</td>\n</tr>\n<tr>\n<td>Multiple Distance Metrics</td>\n<td>Grid search across K and distance metrics</td>\n<td>Best combination selected</td>\n<td>Find optimal (K, metric) pair</td>\n</tr>\n</tbody></table>\n<p>Cross-validation integration tests ensure that the evaluation pipeline correctly coordinates fold creation, model training, prediction, and metric aggregation. These tests verify that the statistical methodology is sound and that results are reproducible.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> test_cross_validation_integration</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Integration test for cross-validation with hyperparameter optimization.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    X, y </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> load_iris_dataset()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    k_values </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">3</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">7</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cv_folds </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 3</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Run grid search with cross-validation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    grid_result </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> grid_search_k(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        X, y, k_values, cv_folds, DistanceMetric.</span><span style=\"color:#79B8FF\">EUCLIDEAN</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">random_seed</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">42</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Verify grid search results</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    assert</span><span style=\"color:#E1E4E8\"> grid_result.optimal_k </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> k_values</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    assert</span><span style=\"color:#9ECBFF\"> 'mean_accuracy'</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> grid_result.optimal_metrics</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    assert</span><span style=\"color:#E1E4E8\"> grid_result.optimal_metrics[</span><span style=\"color:#9ECBFF\">'mean_accuracy'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0.70</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Verify all K values were tested</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    assert</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(grid_result.complete_results) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(k_values)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Verify reproducibility</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    grid_result_2 </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> grid_search_k(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        X, y, k_values, cv_folds, DistanceMetric.</span><span style=\"color:#79B8FF\">EUCLIDEAN</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">random_seed</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">42</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    )</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    assert</span><span style=\"color:#E1E4E8\"> grid_result.optimal_k </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> grid_result_2.optimal_k</span></span></code></pre></div>\n\n<p>The cross-validation integration test validates that the evaluation system correctly implements statistical best practices for performance estimation and hyperparameter selection. It verifies that fold creation maintains data integrity and that metric aggregation produces meaningful results.</p>\n<h4 id=\"error-propagation-and-recovery-integration\">Error Propagation and Recovery Integration</h4>\n<p>Error handling integration tests verify that errors are properly detected, propagated, and recovered from across component boundaries. These tests ensure that the system fails gracefully and provides useful error messages when problems occur.</p>\n<table>\n<thead>\n<tr>\n<th>Error Scenario</th>\n<th>Trigger Condition</th>\n<th>Expected Behavior</th>\n<th>Recovery Mechanism</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Invalid Training Data</td>\n<td>NaN values, mismatched dimensions</td>\n<td>Raise <code>ValidationError</code> with specific message</td>\n<td><code>validate_training_data</code> catches issue early</td>\n</tr>\n<tr>\n<td>Incompatible Query Points</td>\n<td>Wrong feature count in prediction</td>\n<td>Raise <code>DimensionMismatchError</code></td>\n<td><code>validate_query_points</code> prevents prediction</td>\n</tr>\n<tr>\n<td>Numerical Instability</td>\n<td>Distance calculations produce NaN/inf</td>\n<td>Fall back to stable computation</td>\n<td><code>check_numerical_stability</code> detects and handles</td>\n</tr>\n<tr>\n<td>Resource Exhaustion</td>\n<td>Very large datasets with insufficient memory</td>\n<td>Graceful degradation or clear error</td>\n<td>Chunked processing or memory-efficient algorithms</td>\n</tr>\n<tr>\n<td>Invalid Parameters</td>\n<td>K=0, K&gt;dataset_size, invalid distance metric</td>\n<td>Immediate parameter validation error</td>\n<td><code>validate_k_parameter</code> prevents invalid configuration</td>\n</tr>\n</tbody></table>\n<p>Error propagation tests create scenarios that trigger various failure modes and verify that errors are caught at appropriate boundaries with clear, actionable error messages. These tests ensure that users receive helpful feedback when configuration or data issues occur.</p>\n<h3 id=\"milestone-checkpoints\">Milestone Checkpoints</h3>\n<p>Milestone checkpoints provide structured validation that the implementation meets learning objectives and functional requirements after completing each development phase. Each checkpoint includes automated tests, manual verification steps, and performance benchmarks that confirm successful milestone completion.</p>\n<p>The checkpoints follow a progressive validation approach, where each milestone builds upon previous achievements. Early checkpoints focus on mathematical correctness and basic functionality, while later checkpoints emphasize integration, performance, and advanced features. Each checkpoint includes specific commands to run, expected outputs, and troubleshooting guidance.</p>\n<h4 id=\"milestone-1-checkpoint-distance-calculation\">Milestone 1 Checkpoint: Distance Calculation</h4>\n<p>The first milestone checkpoint validates that distance metrics are implemented correctly and efficiently, forming a solid foundation for neighbor finding and classification. This checkpoint emphasizes mathematical correctness and computational performance.</p>\n<table>\n<thead>\n<tr>\n<th>Checkpoint Component</th>\n<th>Test Command</th>\n<th>Expected Result</th>\n<th>Verification Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Distance Function Tests</td>\n<td><code>python -m pytest tests/test_distance_metrics.py -v</code></td>\n<td>All tests pass with specific accuracy</td>\n<td>20+ tests covering all metrics and edge cases</td>\n</tr>\n<tr>\n<td>Performance Benchmark</td>\n<td><code>python benchmark_distance.py</code></td>\n<td>Vectorized operations 10x faster than loops</td>\n<td>Time comparison between vectorized and naive implementations</td>\n</tr>\n<tr>\n<td>Mathematical Validation</td>\n<td><code>python validate_distances.py</code></td>\n<td>Known distance calculations match expected values</td>\n<td>Test against hand-calculated examples</td>\n</tr>\n<tr>\n<td>Numerical Stability</td>\n<td><code>python test_stability.py</code></td>\n<td>No NaN/inf values in edge cases</td>\n<td>Test with extreme values and floating-point edge cases</td>\n</tr>\n<tr>\n<td>Interactive Verification</td>\n<td><code>python demo_distances.py</code></td>\n<td>Visual plots showing distance relationships</td>\n<td>2D scatter plots with distance contours</td>\n</tr>\n</tbody></table>\n<p>The distance calculation checkpoint runs comprehensive tests that validate mathematical correctness across all implemented metrics. The tests include edge cases like identical points, zero vectors, and high-dimensional spaces where numerical precision becomes important.</p>\n<p><strong>Manual Verification Steps for Milestone 1:</strong></p>\n<ol>\n<li><p><strong>Mathematical Correctness Check</strong>: Run the validation script that tests distance calculations against known mathematical examples. The Euclidean distance between points <code>[0, 0]</code> and <code>[3, 4]</code> should return exactly <code>5.0</code>. Manhattan distance between <code>[1, 1]</code> and <code>[4, 5]</code> should return exactly <code>7.0</code>.</p>\n</li>\n<li><p><strong>Performance Validation</strong>: Execute the benchmark script that compares vectorized distance calculations against naive Python loops. Vectorized operations should show at least 10x speedup for datasets with 1000+ samples.</p>\n</li>\n<li><p><strong>Visual Verification</strong>: Run the demo script that creates 2D scatter plots showing how different distance metrics create different proximity relationships between points. Euclidean distance should create circular contours, while Manhattan distance should create diamond-shaped contours.</p>\n</li>\n<li><p><strong>Edge Case Testing</strong>: Verify that the system handles edge cases gracefully:</p>\n<ul>\n<li>Distance between identical points returns 0.0</li>\n<li>Distance calculations with very small numbers don&#39;t produce negative values under square root</li>\n<li>Distance calculations with very large numbers don&#39;t overflow</li>\n<li>Cosine distance handles zero vectors appropriately</li>\n</ul>\n</li>\n</ol>\n<p><strong>Troubleshooting Common Issues:</strong></p>\n<ul>\n<li><strong>Test failures in numerical precision</strong>: Adjust <code>DISTANCE_TOLERANCE</code> constant if legitimate floating-point precision issues occur</li>\n<li><strong>Performance benchmark failures</strong>: Check that NumPy vectorized operations are used instead of Python loops</li>\n<li><strong>NaN/inf values in distance calculations</strong>: Verify <code>safe_sqrt</code> and <code>safe_divide</code> functions handle edge cases properly</li>\n</ul>\n<h4 id=\"milestone-2-checkpoint-k-nearest-neighbors-classification\">Milestone 2 Checkpoint: K-Nearest Neighbors Classification</h4>\n<p>The second milestone checkpoint validates that neighbor finding and classification components work together correctly to produce accurate predictions. This checkpoint emphasizes algorithmic correctness and system integration.</p>\n<table>\n<thead>\n<tr>\n<th>Checkpoint Component</th>\n<th>Test Command</th>\n<th>Expected Result</th>\n<th>Verification Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Neighbor Finding Tests</td>\n<td><code>python -m pytest tests/test_neighbor_finding.py -v</code></td>\n<td>All neighbor selection tests pass</td>\n<td>Verify correct K neighbors returned in sorted order</td>\n</tr>\n<tr>\n<td>Classification Tests</td>\n<td><code>python -m pytest tests/test_classification.py -v</code></td>\n<td>All voting mechanism tests pass</td>\n<td>Majority and weighted voting produce correct results</td>\n</tr>\n<tr>\n<td>Integration Tests</td>\n<td><code>python -m pytest tests/test_integration.py -v</code></td>\n<td>End-to-end pipeline tests pass</td>\n<td>Complete training and prediction workflow</td>\n</tr>\n<tr>\n<td>Accuracy Validation</td>\n<td><code>python validate_accuracy.py</code></td>\n<td>Iris dataset accuracy &gt; 90%</td>\n<td>Test on well-known dataset with expected performance</td>\n</tr>\n<tr>\n<td>Interactive Demo</td>\n<td><code>python demo_classification.py</code></td>\n<td>Visual classification boundaries</td>\n<td>2D plots showing decision boundaries</td>\n</tr>\n</tbody></table>\n<p>The classification checkpoint runs tests that verify both individual component functionality and integrated system behavior. The tests include scenarios with various K values, different distance metrics, and edge cases like ties in voting.</p>\n<p><strong>Manual Verification Steps for Milestone 2:</strong></p>\n<ol>\n<li><p><strong>Basic Classification Test</strong>: Create a simple 2D dataset with clearly separable classes (e.g., points clustered at <code>[0, 0]</code> and <code>[10, 10]</code>). Train a KNN classifier with K=3 and verify that predictions are correct for obvious test points.</p>\n</li>\n<li><p><strong>Iris Dataset Validation</strong>: Load the Iris dataset, split into train/test sets, and verify that classification accuracy exceeds 90%. This benchmark ensures the implementation achieves expected performance on a standard dataset.</p>\n</li>\n<li><p><strong>Visual Decision Boundaries</strong>: Run the demo script that plots 2D decision boundaries for different K values. Small K should create complex, irregular boundaries while large K should create smoother boundaries.</p>\n</li>\n<li><p><strong>Voting Mechanism Verification</strong>: Create test cases where majority voting and weighted voting produce different results. For example, if the nearest neighbor votes for class A but the 3 nearest neighbors vote 2-to-1 for class B, verify that weighted voting gives more influence to the closest neighbor.</p>\n</li>\n</ol>\n<p><strong>Edge Case Testing for Milestone 2:</strong></p>\n<ul>\n<li><strong>K=1 Classification</strong>: Verify that nearest neighbor (K=1) produces reasonable results</li>\n<li><strong>K=dataset_size</strong>: Test that using all training samples as neighbors works correctly</li>\n<li><strong>Tie Breaking</strong>: Create scenarios where multiple classes receive equal votes and verify consistent tie-breaking behavior</li>\n<li><strong>Single-Class Training Data</strong>: Test behavior when training data contains only one class</li>\n</ul>\n<h4 id=\"milestone-3-checkpoint-improvements-amp-evaluation\">Milestone 3 Checkpoint: Improvements &amp; Evaluation</h4>\n<p>The final milestone checkpoint validates that evaluation, optimization, and advanced features work correctly, providing a complete KNN implementation with proper performance assessment and hyperparameter tuning.</p>\n<table>\n<thead>\n<tr>\n<th>Checkpoint Component</th>\n<th>Test Command</th>\n<th>Expected Result</th>\n<th>Verification Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Cross-Validation Tests</td>\n<td><code>python -m pytest tests/test_evaluation.py -v</code></td>\n<td>All evaluation tests pass</td>\n<td>Statistical methodology correctly implemented</td>\n</tr>\n<tr>\n<td>Optimization Tests</td>\n<td><code>python -m pytest tests/test_optimization.py -v</code></td>\n<td>Grid search finds reasonable optimal K</td>\n<td>Hyperparameter tuning produces expected results</td>\n</tr>\n<tr>\n<td>Performance Metrics</td>\n<td><code>python validate_metrics.py</code></td>\n<td>Precision, recall, F1 calculations correct</td>\n<td>Compare against sklearn implementations</td>\n</tr>\n<tr>\n<td>Complete System Test</td>\n<td><code>python test_complete_system.py</code></td>\n<td>Full workflow with optimization succeeds</td>\n<td>Train, optimize, evaluate pipeline completes</td>\n</tr>\n<tr>\n<td>Benchmark Comparison</td>\n<td><code>python benchmark_sklearn.py</code></td>\n<td>Performance comparable to sklearn KNN</td>\n<td>Accuracy within 2% of sklearn implementation</td>\n</tr>\n</tbody></table>\n<p>The final checkpoint runs comprehensive tests that validate the complete KNN system, including advanced features like cross-validation, hyperparameter optimization, and performance metrics. These tests ensure that the implementation is production-ready and scientifically sound.</p>\n<p><strong>Manual Verification Steps for Milestone 3:</strong></p>\n<ol>\n<li><p><strong>Cross-Validation Validation</strong>: Run K-fold cross-validation on the Iris dataset with K=5 folds. Verify that performance estimates are stable across runs with the same random seed and that standard deviation is reasonable relative to mean performance.</p>\n</li>\n<li><p><strong>Hyperparameter Optimization</strong>: Execute grid search over K values [1, 3, 5, 7, 9] and verify that the optimization process selects a reasonable K value (typically 3-7 for Iris) that maximizes validation accuracy.</p>\n</li>\n<li><p><strong>Performance Metrics Verification</strong>: Calculate precision, recall, and F1-score manually for a small test case and verify that the implementation matches manual calculations. Test both macro and weighted averaging options.</p>\n</li>\n<li><p><strong>Sklearn Comparison</strong>: Compare your implementation&#39;s accuracy against <code>sklearn.neighbors.KNeighborsClassifier</code> on multiple datasets. Performance should be within 2% assuming identical preprocessing and parameters.</p>\n</li>\n</ol>\n<p><strong>Complete System Validation:</strong></p>\n<p>The final system validation runs an end-to-end workflow that demonstrates all implemented features:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> validate_complete_system</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Complete system validation demonstrating all KNN features.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Load and preprocess data</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    X, y </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> load_iris_dataset()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    X_train, X_test, y_train, y_test </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> split_and_scale_data(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        X, y, </span><span style=\"color:#FFAB70\">test_size</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0.3</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">scale_features</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">random_state</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">42</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Find optimal hyperparameters</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    k_values </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">3</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">7</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">9</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    grid_result </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> grid_search_k(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        X_train, y_train, k_values, </span><span style=\"color:#FFAB70\">cv_folds</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        distance_metric</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">DistanceMetric.</span><span style=\"color:#79B8FF\">EUCLIDEAN</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">random_seed</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">42</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Train final model with optimal parameters</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    classifier </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> KNNClassifier(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        k</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">grid_result.optimal_k, </span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        distance_metric</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">DistanceMetric.</span><span style=\"color:#79B8FF\">EUCLIDEAN</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        weighted_voting</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    classifier.fit(X_train, y_train)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Make predictions with confidence</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    predictions_with_confidence </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> classifier.predict_with_confidence(X_test)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Evaluate performance</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    predictions </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [pred.predicted_class </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> pred </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> predictions_with_confidence]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    metrics </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> calculate_classification_metrics(y_test, predictions, </span><span style=\"color:#FFAB70\">average</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">'weighted'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    confusion </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> calculate_confusion_matrix(y_test, predictions, </span><span style=\"color:#FFAB70\">class_labels</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#9ECBFF\">'setosa'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'versicolor'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'virginica'</span><span style=\"color:#E1E4E8\">])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Verify results meet expectations</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    assert</span><span style=\"color:#E1E4E8\"> metrics[</span><span style=\"color:#9ECBFF\">'accuracy'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0.90</span><span style=\"color:#6A737D\">  # High accuracy on Iris</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    assert</span><span style=\"color:#E1E4E8\"> grid_result.optimal_k </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> [</span><span style=\"color:#79B8FF\">3</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">7</span><span style=\"color:#E1E4E8\">]  </span><span style=\"color:#6A737D\"># Reasonable K selection</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    assert</span><span style=\"color:#79B8FF\"> all</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">0.0</span><span style=\"color:#F97583\"> &#x3C;=</span><span style=\"color:#E1E4E8\"> pred.confidence </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 1.0</span><span style=\"color:#F97583\"> for</span><span style=\"color:#E1E4E8\"> pred </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> predictions_with_confidence)  </span><span style=\"color:#6A737D\"># Valid confidence scores</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"System validation successful!\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Optimal K: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">grid_result.optimal_k</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Test Accuracy: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">metrics[</span><span style=\"color:#9ECBFF\">'accuracy'</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">:.3f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Cross-validation score: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">grid_result.optimal_metrics[</span><span style=\"color:#9ECBFF\">'mean_accuracy'</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">:.3f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> ± </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">grid_result.optimal_metrics[</span><span style=\"color:#9ECBFF\">'std_accuracy'</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">:.3f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p><strong>Success Criteria for Milestone 3:</strong></p>\n<ul>\n<li>All automated tests pass without errors</li>\n<li>Cross-validation produces stable, reproducible results</li>\n<li>Grid search selects reasonable optimal K values</li>\n<li>Performance metrics match manual calculations</li>\n<li>Complete system achieves accuracy within 2% of sklearn baseline</li>\n<li>Memory usage remains reasonable for datasets up to 10,000 samples</li>\n<li>Processing time scales appropriately with dataset size and K value</li>\n</ul>\n<p><strong>Common Issues and Solutions:</strong></p>\n<ul>\n<li><strong>Cross-validation inconsistency</strong>: Ensure proper random seed management and stratified splitting</li>\n<li><strong>Poor hyperparameter selection</strong>: Verify that grid search explores appropriate K ranges and uses correct validation methodology</li>\n<li><strong>Performance discrepancies with sklearn</strong>: Check that preprocessing, distance metrics, and tie-breaking rules match exactly</li>\n<li><strong>Memory issues with large datasets</strong>: Implement chunked processing for distance calculations and neighbor finding</li>\n</ul>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Testing Framework</td>\n<td><code>pytest</code> with basic assertions</td>\n<td><code>pytest</code> with fixtures, parametrization, and coverage</td>\n</tr>\n<tr>\n<td>Test Data Generation</td>\n<td>Manual numpy arrays</td>\n<td><code>scikit-learn.datasets</code> and synthetic data generators</td>\n</tr>\n<tr>\n<td>Performance Benchmarking</td>\n<td>Simple <code>time.time()</code> measurements</td>\n<td><code>pytest-benchmark</code> with statistical analysis</td>\n</tr>\n<tr>\n<td>Numerical Assertions</td>\n<td>Basic <code>assert abs(a - b) &lt; tolerance</code></td>\n<td><code>numpy.testing.assert_allclose</code> with relative/absolute tolerance</td>\n</tr>\n<tr>\n<td>Mock Objects</td>\n<td>Simple stub classes</td>\n<td><code>unittest.mock</code> for complex dependency injection</td>\n</tr>\n<tr>\n<td>Test Coverage</td>\n<td>Manual verification</td>\n<td><code>pytest-cov</code> for automated coverage reporting</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>knn-classifier/\n├── src/\n│   ├── knn/\n│   │   ├── __init__.py\n│   │   ├── distance_metrics.py     ← Distance calculation functions\n│   │   ├── neighbor_finding.py     ← K-nearest neighbor algorithms\n│   │   ├── classification.py       ← Voting and prediction logic\n│   │   └── evaluation.py           ← Cross-validation and optimization\n├── tests/\n│   ├── __init__.py\n│   ├── conftest.py                 ← Pytest fixtures and configuration\n│   ├── test_distance_metrics.py    ← Unit tests for distance calculations\n│   ├── test_neighbor_finding.py    ← Unit tests for neighbor search\n│   ├── test_classification.py      ← Unit tests for voting mechanisms\n│   ├── test_evaluation.py          ← Unit tests for evaluation methods\n│   ├── test_integration.py         ← Integration tests for complete workflows\n│   └── test_edge_cases.py          ← Comprehensive edge case testing\n├── benchmarks/\n│   ├── benchmark_distances.py      ← Performance tests for distance calculations\n│   ├── benchmark_neighbors.py      ← Performance tests for neighbor finding\n│   └── benchmark_complete.py       ← End-to-end performance benchmarks\n├── validation/\n│   ├── validate_distances.py       ← Mathematical correctness validation\n│   ├── validate_accuracy.py        ← Accuracy validation on known datasets\n│   └── validate_sklearn_comparison.py ← Compare against sklearn baseline\n└── demos/\n    ├── demo_distances.py           ← Interactive distance visualization\n    ├── demo_classification.py      ← Classification boundary visualization\n    └── demo_complete_system.py     ← Complete system demonstration</code></pre></div>\n\n<h4 id=\"testing-infrastructure-starter-code\">Testing Infrastructure Starter Code</h4>\n<p><strong>conftest.py - Pytest Configuration and Fixtures:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> pytest</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Tuple, List</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> knn.data_types </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> FeatureMatrix, ClassLabel, TrainingData</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@pytest.fixture</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> simple_2d_dataset</span><span style=\"color:#E1E4E8\">() -> Tuple[FeatureMatrix, List[ClassLabel]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Simple 2D dataset for basic testing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    X </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.array([</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        [</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">], [</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">], [</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">],  </span><span style=\"color:#6A737D\"># Class A - diagonal line</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        [</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">], [</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">3</span><span style=\"color:#E1E4E8\">], [</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">4</span><span style=\"color:#E1E4E8\">],  </span><span style=\"color:#6A737D\"># Class B - parallel line</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ], </span><span style=\"color:#FFAB70\">dtype</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">np.float64)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    y </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span><span style=\"color:#9ECBFF\">'A'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'A'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'A'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'B'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'B'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'B'</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> X, y</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@pytest.fixture</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> iris_dataset</span><span style=\"color:#E1E4E8\">() -> Tuple[FeatureMatrix, List[ClassLabel]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Iris dataset for realistic testing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    from</span><span style=\"color:#E1E4E8\"> sklearn.datasets </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> load_iris</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    iris </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> load_iris()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> iris.data.astype(np.float64), iris.target.tolist()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@pytest.fixture</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> single_point_dataset</span><span style=\"color:#E1E4E8\">() -> Tuple[FeatureMatrix, List[ClassLabel]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Edge case: dataset with single training point.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    X </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.array([[</span><span style=\"color:#79B8FF\">1.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">2.0</span><span style=\"color:#E1E4E8\">]], </span><span style=\"color:#FFAB70\">dtype</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">np.float64)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    y </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span><span style=\"color:#9ECBFF\">'A'</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> X, y</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@pytest.fixture</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> identical_points_dataset</span><span style=\"color:#E1E4E8\">() -> Tuple[FeatureMatrix, List[ClassLabel]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Edge case: multiple identical points with different labels.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    X </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.array([</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        [</span><span style=\"color:#79B8FF\">1.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1.0</span><span style=\"color:#E1E4E8\">], [</span><span style=\"color:#79B8FF\">1.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1.0</span><span style=\"color:#E1E4E8\">], [</span><span style=\"color:#79B8FF\">1.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1.0</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ], </span><span style=\"color:#FFAB70\">dtype</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">np.float64)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    y </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span><span style=\"color:#9ECBFF\">'A'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'B'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'A'</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> X, y</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@pytest.fixture</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> reproducible_random</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Fixture that provides deterministic randomness for tests.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    np.random.seed(</span><span style=\"color:#79B8FF\">42</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> np.random.RandomState(</span><span style=\"color:#79B8FF\">42</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p><strong>test_distance_metrics.py - Unit Tests for Distance Calculations:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> pytest</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> knn.distance_metrics </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    euclidean_distance, manhattan_distance, cosine_distance,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    calculate_distances_to_point, validate_compatible_vectors</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> knn.data_types </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> DistanceMetric, </span><span style=\"color:#79B8FF\">DISTANCE_TOLERANCE</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TestEuclideanDistance</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Test cases for Euclidean distance calculation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_euclidean_distance_right_triangle</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test Euclidean distance using known right triangle.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Create points forming 3-4-5 right triangle</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate distance using euclidean_distance function</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Assert result equals 5.0 within tolerance</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_euclidean_distance_identical_points</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test that identical points have zero distance.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Create identical points</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Verify distance is exactly 0.0</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_euclidean_distance_negative_coordinates</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test Euclidean distance with negative coordinates.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Test points in different quadrants</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Verify distance calculation handles negatives correctly</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TestManhattanDistance</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Test cases for Manhattan distance calculation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_manhattan_distance_grid_movement</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test Manhattan distance as grid movement.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Create points representing grid coordinates</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate expected Manhattan distance manually</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Verify function returns correct grid distance</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TestVectorizedOperations</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Test vectorized distance calculations for performance.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_batch_distance_calculation</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test that batch distance calculation is correct and efficient.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Create query point and training matrix</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate distances using vectorized operation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Verify results match individual calculations</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Measure performance improvement over loops</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>test_integration.py - Integration Tests for Complete Workflows:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> pytest</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> knn.classifier </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> KNNClassifier</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> knn.evaluation </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> k_fold_cross_validate, grid_search_k</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> knn.data_types </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> DistanceMetric</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TestCompleteWorkflow</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Integration tests for complete KNN workflows.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_train_predict_pipeline</span><span style=\"color:#E1E4E8\">(self, iris_dataset):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test complete training and prediction pipeline.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        X, y </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> iris_dataset</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Split data into train/test sets</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Create KNNClassifier with reasonable parameters</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Fit classifier on training data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Make predictions on test data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Verify predictions have correct format and reasonable accuracy</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_cross_validation_integration</span><span style=\"color:#E1E4E8\">(self, iris_dataset):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test cross-validation with multiple K values.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        X, y </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> iris_dataset</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Define K values to test</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Run k_fold_cross_validate with multiple parameters</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Verify results have expected structure</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check that results are reproducible with same seed</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TestErrorHandling</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Integration tests for error handling across components.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_dimension_mismatch_propagation</span><span style=\"color:#E1E4E8\">(self, simple_2d_dataset):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test that dimension mismatches are caught and reported clearly.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        X_train, y_train </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> simple_2d_dataset</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        classifier </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> KNNClassifier(</span><span style=\"color:#FFAB70\">k</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">3</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        classifier.fit(X_train, y_train)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Create query point with wrong number of dimensions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Attempt prediction and verify appropriate error is raised</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check error message is informative</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoint-scripts\">Milestone Checkpoint Scripts</h4>\n<p><strong>validate_distances.py - Milestone 1 Mathematical Validation:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> knn.distance_metrics </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> euclidean_distance, manhattan_distance, cosine_distance</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> validate_euclidean_distances</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Validate Euclidean distance calculations against known examples.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    test_cases </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # (point1, point2, expected_distance, description)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ([</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">], [</span><span style=\"color:#79B8FF\">3</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">4</span><span style=\"color:#E1E4E8\">], </span><span style=\"color:#79B8FF\">5.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"3-4-5 right triangle\"</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ([</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">], [</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">], </span><span style=\"color:#79B8FF\">0.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"identical points\"</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ([</span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">], [</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">], </span><span style=\"color:#79B8FF\">2.828</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"negative to positive quadrant\"</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ([</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">], [</span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">], </span><span style=\"color:#79B8FF\">5.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"1D distance\"</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Validating Euclidean distance calculations...\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> point1, point2, expected, description </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> test_cases:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        p1 </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.array(point1, </span><span style=\"color:#FFAB70\">dtype</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">np.float64)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        p2 </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.array(point2, </span><span style=\"color:#FFAB70\">dtype</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">np.float64)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate actual distance</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Compare against expected within tolerance</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Print validation result</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> validate_performance_improvement</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Validate that vectorized operations provide performance improvement.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Create large dataset for benchmarking</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Time naive loop-based distance calculation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Time vectorized distance calculation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Verify vectorized is significantly faster</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Print performance comparison</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">if</span><span style=\"color:#79B8FF\"> __name__</span><span style=\"color:#F97583\"> ==</span><span style=\"color:#9ECBFF\"> \"__main__\"</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    validate_euclidean_distances()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    validate_performance_improvement()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"✓ All distance calculations validated successfully!\"</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p><strong>validate_accuracy.py - Milestone 2 Accuracy Validation:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sklearn.datasets </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> load_iris, load_wine</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sklearn.model_selection </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> train_test_split</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sklearn.neighbors </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> KNeighborsClassifier </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> SklearnKNN</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> knn.classifier </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> KNNClassifier</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> knn.data_types </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> DistanceMetric</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> validate_iris_accuracy</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Validate KNN accuracy on Iris dataset.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Load and prepare data</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    iris </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> load_iris()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    X_train, X_test, y_train, y_test </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> train_test_split(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        iris.data, iris.target, </span><span style=\"color:#FFAB70\">test_size</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0.3</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">random_state</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">42</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Train custom KNN classifier</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Make predictions on test set</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate accuracy</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Verify accuracy exceeds 90%</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Print detailed results</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> compare_with_sklearn</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Compare accuracy with sklearn KNeighborsClassifier.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Load dataset and split</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Train both custom and sklearn classifiers with identical parameters</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Compare predictions and accuracy</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Verify results are within acceptable tolerance</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Print comparison results</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">if</span><span style=\"color:#79B8FF\"> __name__</span><span style=\"color:#F97583\"> ==</span><span style=\"color:#9ECBFF\"> \"__main__\"</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    validate_iris_accuracy()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    compare_with_sklearn()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"✓ All accuracy validations passed!\"</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<h4 id=\"debugging-support-tools\">Debugging Support Tools</h4>\n<p><strong>debug_helpers.py - Debugging Utilities:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> matplotlib.pyplot </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> plt</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> knn.data_types </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> FeatureMatrix, ClassLabel, PredictionResult</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> plot_2d_classification_boundaries</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    X_train: FeatureMatrix, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    y_train: List[ClassLabel], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    classifier, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    resolution: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 100</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Plot 2D decision boundaries for visual debugging.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> X_train.shape[</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Can only plot boundaries for 2D data\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Create mesh grid covering data range</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Make predictions on grid points</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Plot colored decision regions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Overlay training points</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Add legend and labels</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> analyze_prediction_confidence</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    predictions_with_confidence: List[PredictionResult]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Analyze prediction confidence distribution for debugging.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    confidences </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [pred.confidence </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> pred </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> predictions_with_confidence]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate confidence statistics (mean, std, min, max)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Plot confidence histogram</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Identify low-confidence predictions for investigation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Print summary statistics</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> debug_distance_calculations</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    query_point: np.ndarray,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    training_points: FeatureMatrix,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 5</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Debug distance calculations by showing nearest neighbors.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate distances to all training points</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Find K nearest neighbors</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Print distances and neighbor information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Create visualization if 2D data</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span></code></pre></div>\n\n<p>This comprehensive testing strategy provides multiple layers of validation that ensure the KNN implementation is mathematically correct, algorithmically sound, and practically useful. The combination of unit tests, integration tests, and milestone checkpoints creates a thorough verification framework that builds confidence in the implementation&#39;s correctness and performance.</p>\n<h2 id=\"debugging-guide\">Debugging Guide</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Comprehensive debugging support for all milestones - distance calculation debugging (Milestone 1), classification debugging for voting and accuracy issues (Milestone 2), and performance debugging for optimization problems (Milestone 3)</p>\n</blockquote>\n<h3 id=\"mental-model-the-detective-process\">Mental Model: The Detective Process</h3>\n<p>Think of debugging a KNN implementation like being a detective investigating a crime scene. The &quot;crime&quot; is your algorithm producing wrong results or running too slowly. Just like a detective, you need to systematically examine evidence, form hypotheses about what went wrong, and test those hypotheses by gathering more specific evidence. The key insight is that bugs in machine learning systems often manifest as subtle degradations rather than complete failures - your classifier might get 70% accuracy instead of 90%, or take 10 seconds instead of 1 second. This makes debugging more challenging than traditional software where bugs typically cause immediate crashes or obviously wrong outputs.</p>\n<p>The debugging process for KNN follows a natural hierarchy: first ensure your distance calculations are numerically correct (the foundation), then verify your neighbor finding logic produces the right neighbors in the right order (the mechanism), and finally confirm your classification voting produces sensible predictions (the outcome). Performance issues typically stem from algorithmic inefficiencies rather than implementation bugs, so they require a different investigative approach focused on profiling and optimization rather than correctness verification.</p>\n<p>This section provides systematic approaches for identifying, diagnosing, and fixing the most common issues that arise when implementing KNN classifiers, organized by the component where symptoms typically manifest.</p>\n<h3 id=\"distance-calculation-debugging\">Distance Calculation Debugging</h3>\n<p>Distance calculation forms the mathematical foundation of KNN, making bugs in this component particularly insidious because they propagate through all downstream operations. The challenge is that distance calculation bugs often don&#39;t cause crashes - instead they silently corrupt neighbor rankings, leading to poor classification accuracy that can be difficult to trace back to the root cause.</p>\n<h4 id=\"common-distance-calculation-issues\">Common Distance Calculation Issues</h4>\n<p>The most frequent distance calculation problems fall into several categories: numerical instability, dimensionality mismatches, and performance bottlenecks. Understanding these patterns helps you quickly identify the likely cause when debugging distance-related issues.</p>\n<p><strong>Numerical Instability Symptoms and Diagnosis</strong></p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>Diagnostic Steps</th>\n<th>Fix Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>NaN</code> distances in results</td>\n<td>Square root of negative values in Euclidean calculation</td>\n<td>Check intermediate squared differences for negative values</td>\n<td>Use <code>safe_sqrt()</code> with absolute value before square root</td>\n</tr>\n<tr>\n<td>Infinite distances</td>\n<td>Division by zero in cosine distance</td>\n<td>Examine zero-magnitude vectors in dataset</td>\n<td>Handle zero vectors with <code>EPSILON</code> addition to magnitude</td>\n</tr>\n<tr>\n<td>All distances are identical</td>\n<td>Floating-point precision loss</td>\n<td>Check if feature scales differ by orders of magnitude</td>\n<td>Apply feature scaling before distance calculation</td>\n</tr>\n<tr>\n<td>Distances don&#39;t decrease with K</td>\n<td>Numerical overflow in high dimensions</td>\n<td>Profile maximum feature values and dimension count</td>\n<td>Use double precision and feature normalization</td>\n</tr>\n<tr>\n<td>Inconsistent distance symmetry</td>\n<td>Broadcasting errors in vectorized ops</td>\n<td>Test <code>distance(a,b) == distance(b,a)</code> on sample points</td>\n<td>Fix array shape handling in vectorized functions</td>\n</tr>\n</tbody></table>\n<p>The most critical debugging technique for numerical issues is implementing comprehensive numerical stability checks at every stage of distance calculation. This means validating intermediate results, not just final outputs.</p>\n<blockquote>\n<p><strong>Key Insight</strong>: Numerical bugs in distance calculation are often dimension-dependent. A bug that doesn&#39;t manifest with 2D toy data may become severe with 100D real-world features. Always test distance functions across multiple dimensionalities during development.</p>\n</blockquote>\n<p><strong>Feature Scaling and Normalization Issues</strong></p>\n<p>Feature scaling problems are particularly common because they&#39;re not technically bugs - the code runs correctly but produces mathematically valid yet practically useless results. When features have vastly different scales (e.g., age in years vs income in dollars), distance metrics become dominated by high-scale features.</p>\n<p>The diagnostic process involves examining feature distributions and testing distance sensitivity:</p>\n<ol>\n<li>Calculate feature-wise statistics (mean, standard deviation, min, max) across your training data</li>\n<li>Compute distances between identical points with one feature perturbed by a small amount</li>\n<li>Observe which features dominate the distance calculation</li>\n<li>Apply appropriate scaling (standardization, min-max normalization, or robust scaling) and repeat the analysis</li>\n</ol>\n<p><strong>Vectorization and Broadcasting Errors</strong></p>\n<p>NumPy broadcasting is powerful but error-prone. The most common broadcasting bugs occur when computing distances from one query point to all training points, or when computing pairwise distance matrices.</p>\n<blockquote>\n<p><strong>Decision: Explicit Shape Validation vs Implicit Broadcasting</strong></p>\n<ul>\n<li><strong>Context</strong>: NumPy broadcasting can silently produce wrong results when array shapes don&#39;t align as expected</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>Rely on NumPy&#39;s broadcasting rules and handle exceptions</li>\n<li>Explicitly validate and reshape arrays before operations</li>\n<li>Use only explicit loops to avoid broadcasting entirely</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Explicit shape validation with broadcasting</li>\n<li><strong>Rationale</strong>: Catches shape mismatches early with clear error messages, while still benefiting from vectorized performance</li>\n<li><strong>Consequences</strong>: Slightly more verbose code but much easier debugging when shape issues occur</li>\n</ul>\n</blockquote>\n<p>The shape validation approach involves checking array dimensions before every vectorized operation:</p>\n<table>\n<thead>\n<tr>\n<th>Array Operation</th>\n<th>Expected Shapes</th>\n<th>Validation Check</th>\n<th>Error Message</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Point-to-point distance</td>\n<td><code>(n_features,)</code> and <code>(n_features,)</code></td>\n<td><code>assert a.shape == b.shape</code></td>\n<td>&quot;Feature vectors must have identical dimensions&quot;</td>\n</tr>\n<tr>\n<td>Point-to-dataset distance</td>\n<td><code>(n_features,)</code> and <code>(n_samples, n_features)</code></td>\n<td><code>assert query.shape[0] == data.shape[1]</code></td>\n<td>&quot;Query point dimension doesn&#39;t match training data&quot;</td>\n</tr>\n<tr>\n<td>Pairwise distance matrix</td>\n<td><code>(n1, n_features)</code> and <code>(n2, n_features)</code></td>\n<td><code>assert X1.shape[1] == X2.shape[1]</code></td>\n<td>&quot;Feature dimensions must match for distance calculation&quot;</td>\n</tr>\n</tbody></table>\n<h4 id=\"distance-metric-specific-debugging\">Distance Metric Specific Debugging</h4>\n<p>Each distance metric has characteristic failure modes that require specialized debugging approaches.</p>\n<p><strong>Euclidean Distance Debugging</strong></p>\n<p>Euclidean distance bugs typically involve numerical overflow in high dimensions or precision loss with very small/large feature values. The debugging process follows these steps:</p>\n<ol>\n<li>Verify squared differences don&#39;t overflow by checking maximum possible feature differences</li>\n<li>Confirm square root input is never negative using intermediate value logging</li>\n<li>Test edge cases with zero vectors, identical vectors, and orthogonal vectors</li>\n<li>Validate that triangle inequality holds: <code>d(a,c) &lt;= d(a,b) + d(b,c)</code></li>\n</ol>\n<p><strong>Manhattan Distance Debugging</strong></p>\n<p>Manhattan distance is numerically more stable but can have performance issues due to absolute value computation. Common bugs include:</p>\n<ul>\n<li>Forgetting absolute value operation, leading to negative distances</li>\n<li>Inefficient implementation that doesn&#39;t leverage vectorized absolute value functions</li>\n<li>Incorrect axis specification in sum operations for multi-dimensional arrays</li>\n</ul>\n<p><strong>Cosine Distance Debugging</strong></p>\n<p>Cosine similarity is the most error-prone distance metric due to division operations and the need to handle zero-magnitude vectors:</p>\n<table>\n<thead>\n<tr>\n<th>Error Condition</th>\n<th>Detection Method</th>\n<th>Recovery Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Zero magnitude vector</td>\n<td>Check <code>np.linalg.norm(vector) == 0</code></td>\n<td>Return maximum distance (1.0 for cosine distance)</td>\n</tr>\n<tr>\n<td>Nearly zero magnitude</td>\n<td>Check <code>norm &lt; EPSILON</code></td>\n<td>Add small constant to avoid division by tiny numbers</td>\n</tr>\n<tr>\n<td>Negative cosine similarity</td>\n<td>Validate <code>dot_product / (norm1 * norm2)</code> range</td>\n<td>Clamp result to [-1, 1] range</td>\n</tr>\n<tr>\n<td>NaN from 0/0 division</td>\n<td>Check for simultaneous zero vectors</td>\n<td>Define distance between zero vectors as 0 or 1 based on use case</td>\n</tr>\n</tbody></table>\n<h4 id=\"performance-debugging-for-distance-calculation\">Performance Debugging for Distance Calculation</h4>\n<p>Distance calculation performance issues usually stem from inefficient vectorization or redundant computations. The debugging approach involves profiling to identify bottlenecks, then applying targeted optimizations.</p>\n<p><strong>Profiling Distance Computation</strong></p>\n<p>The systematic approach to performance debugging involves measuring time spent in each distance calculation component:</p>\n<ol>\n<li>Profile individual distance function calls with small arrays</li>\n<li>Profile vectorized operations with realistic dataset sizes</li>\n<li>Identify memory allocation patterns that cause garbage collection overhead</li>\n<li>Measure cache efficiency for different array access patterns</li>\n</ol>\n<p>Common performance anti-patterns include:</p>\n<ul>\n<li>Computing the same distances multiple times instead of caching results</li>\n<li>Using Python loops instead of vectorized NumPy operations</li>\n<li>Creating unnecessary intermediate arrays that trigger memory allocation</li>\n<li>Inefficient array indexing patterns that don&#39;t leverage CPU cache locality</li>\n</ul>\n<blockquote>\n<p><strong>Critical Performance Insight</strong>: In high-dimensional spaces, distance calculation becomes increasingly expensive due to the curse of dimensionality. However, the real performance killer is usually algorithmic inefficiency (O(n²) when O(n log n) is possible) rather than constant factor improvements in distance calculation itself.</p>\n</blockquote>\n<h3 id=\"classification-debugging\">Classification Debugging</h3>\n<p>Classification debugging focuses on the voting mechanisms that convert neighbor information into final predictions. Unlike distance calculation bugs that affect all predictions uniformly, classification bugs often manifest as systematic biases toward certain classes or inconsistent behavior with different K values.</p>\n<h4 id=\"voting-algorithm-issues\">Voting Algorithm Issues</h4>\n<p>The core challenge in debugging voting algorithms is that they involve discrete logic (which neighbors get selected) combined with tie-breaking heuristics. This creates complex state spaces where bugs can hide.</p>\n<p><strong>Majority Voting Debugging</strong></p>\n<table>\n<thead>\n<tr>\n<th>Problem Symptom</th>\n<th>Root Cause Analysis</th>\n<th>Debugging Steps</th>\n<th>Solution Approach</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Always predicts same class</td>\n<td>K too large, always includes majority class</td>\n<td>Test with small K values, examine class distribution</td>\n<td>Reduce K or use stratified sampling</td>\n</tr>\n<tr>\n<td>Predictions change dramatically with small K changes</td>\n<td>Dataset has noise or overlapping classes</td>\n<td>Visualize decision boundaries, test with clean synthetic data</td>\n<td>Use larger K or weighted voting</td>\n</tr>\n<tr>\n<td>Ties resolved inconsistently</td>\n<td>Non-deterministic tie-breaking</td>\n<td>Test same prediction multiple times, check for randomness</td>\n<td>Implement deterministic tie-breaking (nearest neighbor)</td>\n</tr>\n<tr>\n<td>Confidence scores don&#39;t match intuition</td>\n<td>Confidence calculation doesn&#39;t reflect neighbor agreement</td>\n<td>Compare confidence with neighbor class distributions</td>\n<td>Revise confidence formula to measure neighbor consensus</td>\n</tr>\n</tbody></table>\n<p>The debugging process for majority voting involves creating controlled test cases where you know the expected behavior:</p>\n<ol>\n<li>Create a simple 2D dataset where you can visualize the decision boundaries</li>\n<li>Test edge cases: exactly tied votes, unanimous votes, single neighbor cases</li>\n<li>Verify that changing the order of training data doesn&#39;t affect predictions</li>\n<li>Confirm that confidence scores correlate with prediction certainty</li>\n</ol>\n<p><strong>Weighted Voting Debugging</strong></p>\n<p>Weighted voting introduces additional complexity because the weights depend on distances, creating opportunities for both numerical and logical errors.</p>\n<p>The weight calculation process requires careful validation:</p>\n<ol>\n<li>Verify that closer neighbors receive higher weights by testing with known distance relationships</li>\n<li>Check that weight normalization produces a valid probability distribution (weights sum to 1)</li>\n<li>Ensure that infinite weights (zero distances) are handled gracefully</li>\n<li>Test behavior when all neighbors have identical distances (should fall back to majority voting)</li>\n</ol>\n<blockquote>\n<p><strong>Decision: Linear vs Inverse Distance Weighting</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to convert distances into voting weights, with closer neighbors having more influence</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Linear weighting: <code>weight = max_distance - distance</code></li>\n<li>Inverse weighting: <code>weight = 1 / (distance + epsilon)</code></li>\n<li>Gaussian weighting: <code>weight = exp(-distance^2 / (2 * sigma^2))</code></li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Inverse distance weighting</li>\n<li><strong>Rationale</strong>: Provides stronger differentiation between close and far neighbors, mathematically well-founded, handles zero distances gracefully with epsilon</li>\n<li><strong>Consequences</strong>: More sensitive to epsilon parameter choice, requires numerical stability handling</li>\n</ul>\n</blockquote>\n<h4 id=\"class-imbalance-and-bias-issues\">Class Imbalance and Bias Issues</h4>\n<p>Class imbalance creates systematic biases in KNN that are often misdiagnosed as implementation bugs. The issue is that in imbalanced datasets, the majority class naturally appears more frequently in neighborhood sets, leading to prediction bias.</p>\n<p><strong>Detecting Class Imbalance Effects</strong></p>\n<table>\n<thead>\n<tr>\n<th>Diagnostic Metric</th>\n<th>Calculation</th>\n<th>Interpretation</th>\n<th>Action Required</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Per-class recall</td>\n<td>True positives / (True positives + False negatives)</td>\n<td>How well each class is detected individually</td>\n<td>Low recall for minority classes indicates imbalance bias</td>\n</tr>\n<tr>\n<td>Precision-recall curves</td>\n<td>Plot precision vs recall at different decision thresholds</td>\n<td>Shows trade-off between precision and recall</td>\n<td>Steep drops indicate class imbalance problems</td>\n</tr>\n<tr>\n<td>Confusion matrix heatmap</td>\n<td>Visual representation of prediction vs actual classes</td>\n<td>Reveals systematic misclassification patterns</td>\n<td>Off-diagonal patterns show which classes are confused</td>\n</tr>\n<tr>\n<td>Baseline accuracy comparison</td>\n<td>Compare against &quot;always predict majority class&quot; baseline</td>\n<td>Measures actual learning beyond naive strategy</td>\n<td>Small improvement over baseline suggests bias issues</td>\n</tr>\n</tbody></table>\n<p>The systematic approach to diagnosing class imbalance involves:</p>\n<ol>\n<li>Calculate class frequency distribution in training data</li>\n<li>Examine neighborhood class distributions for different K values</li>\n<li>Test prediction accuracy separately for each class</li>\n<li>Compare performance metrics across balanced and imbalanced test sets</li>\n</ol>\n<h4 id=\"hyperparameter-sensitivity-analysis\">Hyperparameter Sensitivity Analysis</h4>\n<p>Classification performance in KNN is highly sensitive to the K parameter, making hyperparameter debugging crucial for achieving good results. However, sensitivity to K can also reveal underlying data quality or implementation issues.</p>\n<p><strong>K Selection Debugging</strong></p>\n<p>The relationship between K and performance should follow predictable patterns. Deviations from expected behavior often indicate bugs:</p>\n<ul>\n<li>Very small K (1-3): High variance, sensitive to noise, but should achieve good performance on clean datasets</li>\n<li>Medium K (5-15): Should provide balanced bias-variance trade-off for most datasets</li>\n<li>Large K (&gt;20): Should show stable but potentially biased predictions, approaching the dataset&#39;s base rate</li>\n</ul>\n<blockquote>\n<p><strong>Key Debugging Insight</strong>: If performance doesn&#39;t improve with ANY value of K, the problem is likely in distance calculation or data preprocessing, not in the classification logic. If performance is good for some K values but terrible for others, focus on tie-breaking and voting implementation.</p>\n</blockquote>\n<p>The K sensitivity analysis process:</p>\n<ol>\n<li>Plot accuracy vs K for a range from 1 to min(50, n_samples/5)</li>\n<li>Identify optimal K and examine the shape of the performance curve</li>\n<li>Test the same K values with different random seeds to measure stability</li>\n<li>Compare K sensitivity across different train/test splits</li>\n</ol>\n<h4 id=\"confidence-scoring-validation\">Confidence Scoring Validation</h4>\n<p>Confidence scores in KNN should reflect the certainty of predictions based on neighbor agreement. Bugs in confidence calculation can make the classifier appear less reliable than it actually is.</p>\n<p><strong>Confidence Calibration Testing</strong></p>\n<table>\n<thead>\n<tr>\n<th>Confidence Range</th>\n<th>Expected Accuracy</th>\n<th>Validation Method</th>\n<th>Common Issues</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>0.9-1.0 (High)</td>\n<td>Should be &gt;90% accurate</td>\n<td>Bin predictions by confidence, measure actual accuracy</td>\n<td>Overconfident due to unanimous but incorrect neighbors</td>\n</tr>\n<tr>\n<td>0.7-0.9 (Medium)</td>\n<td>Should be 70-90% accurate</td>\n<td>Compare prediction accuracy within this confidence band</td>\n<td>Poor calibration indicates flawed confidence formula</td>\n</tr>\n<tr>\n<td>0.5-0.7 (Low)</td>\n<td>Should be 50-70% accurate</td>\n<td>May indicate tie-breaking situations</td>\n<td>Many ties suggest K is too large or classes overlap</td>\n</tr>\n<tr>\n<td>&lt;0.5 (Very Low)</td>\n<td>Should rarely occur in binary classification</td>\n<td>Investigate what causes very low confidence</td>\n<td>Possible bug in confidence calculation</td>\n</tr>\n</tbody></table>\n<h3 id=\"performance-debugging\">Performance Debugging</h3>\n<p>Performance debugging in KNN requires understanding that the algorithm has different computational bottlenecks depending on dataset size, dimensionality, and implementation choices. Unlike correctness bugs that affect result quality, performance issues affect scalability and user experience.</p>\n<h4 id=\"computational-complexity-analysis\">Computational Complexity Analysis</h4>\n<p>KNN has well-understood theoretical complexity, making it possible to identify when performance deviates from expected bounds. The naive implementation has O(nd) distance calculation per query, where n is training set size and d is feature dimensionality, plus O(n log k) for finding the k smallest distances.</p>\n<p><strong>Performance Profiling Methodology</strong></p>\n<p>The systematic approach to performance debugging involves:</p>\n<ol>\n<li><strong>Micro-benchmarks</strong>: Test individual components (distance calculation, sorting, voting) in isolation</li>\n<li><strong>Scaling analysis</strong>: Measure how runtime scales with n (dataset size) and d (dimensionality)</li>\n<li><strong>Memory profiling</strong>: Track memory allocation patterns and garbage collection overhead</li>\n<li><strong>Cache analysis</strong>: Measure cache hit rates and memory access patterns</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>Performance Issue</th>\n<th>Symptom</th>\n<th>Measurement Method</th>\n<th>Expected Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Distance calculation bottleneck</td>\n<td>Linear scaling worse than O(nd)</td>\n<td>Profile distance computation time vs dataset size</td>\n<td>Should scale linearly with both n and d</td>\n</tr>\n<tr>\n<td>Memory allocation overhead</td>\n<td>Unexpected memory usage spikes</td>\n<td>Monitor heap allocation during queries</td>\n<td>Should use O(nd) memory for distance array</td>\n</tr>\n<tr>\n<td>Poor cache locality</td>\n<td>Slower than expected despite good algorithmic complexity</td>\n<td>Measure cache miss rates</td>\n<td>Sequential array access should have high cache hit rate</td>\n</tr>\n<tr>\n<td>Python loop overhead</td>\n<td>Much slower than vectorized baseline</td>\n<td>Compare pure Python vs NumPy implementations</td>\n<td>NumPy should be 10-100x faster for numerical operations</td>\n</tr>\n</tbody></table>\n<h4 id=\"vectorization-optimization\">Vectorization Optimization</h4>\n<p>The most common performance issue in KNN implementations is insufficient vectorization. Python loops are orders of magnitude slower than NumPy&#39;s C-implemented vectorized operations.</p>\n<p><strong>Identifying Vectorization Opportunities</strong></p>\n<p>The process of optimizing vectorization involves systematically replacing Python loops with NumPy operations:</p>\n<ol>\n<li><strong>Distance computation</strong>: Replace point-by-point loops with broadcasting operations</li>\n<li><strong>Neighbor finding</strong>: Use <code>np.argpartition</code> instead of full sorting for finding k smallest elements</li>\n<li><strong>Voting aggregation</strong>: Use <code>np.bincount</code> for efficient vote counting instead of dictionary-based approaches</li>\n</ol>\n<blockquote>\n<p><strong>Performance Decision: Full Distance Matrix vs On-Demand Calculation</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to balance memory usage with computation speed for distance calculations</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Precompute full distance matrix: O(n²) memory, O(1) lookup</li>\n<li>Compute distances on-demand: O(1) memory, O(nd) per query</li>\n<li>Hybrid approach: Cache recent queries, compute new ones as needed</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: On-demand calculation with vectorized operations</li>\n<li><strong>Rationale</strong>: Memory usage scales quadratically with dataset size, making precomputation infeasible for large datasets. Vectorized on-demand calculation achieves good performance while maintaining linear memory scaling</li>\n<li><strong>Consequences</strong>: Repeated queries don&#39;t benefit from caching, but system can handle arbitrarily large training sets</li>\n</ul>\n</blockquote>\n<h4 id=\"memory-usage-optimization\">Memory Usage Optimization</h4>\n<p>Memory usage in KNN can become problematic with large datasets, particularly when storing distance matrices or maintaining neighbor lists. The debugging approach focuses on identifying memory allocation patterns and optimizing data structures.</p>\n<p><strong>Memory Profiling Techniques</strong></p>\n<table>\n<thead>\n<tr>\n<th>Memory Issue</th>\n<th>Detection Method</th>\n<th>Optimization Strategy</th>\n<th>Trade-offs</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Excessive distance matrix storage</td>\n<td>Monitor memory usage vs dataset size</td>\n<td>Use streaming distance calculation</td>\n<td>Higher computational cost per query</td>\n</tr>\n<tr>\n<td>Redundant array copies</td>\n<td>Profile memory allocations during operations</td>\n<td>Use in-place operations and array views</td>\n<td>More complex code, potential for bugs</td>\n</tr>\n<tr>\n<td>Poor garbage collection</td>\n<td>Monitor GC frequency and pause times</td>\n<td>Reuse arrays, avoid intermediate allocations</td>\n<td>Requires careful memory management</td>\n</tr>\n<tr>\n<td>Memory fragmentation</td>\n<td>Measure actual vs requested memory usage</td>\n<td>Use memory pools for fixed-size arrays</td>\n<td>Platform-specific optimization</td>\n</tr>\n</tbody></table>\n<h4 id=\"algorithm-level-optimizations\">Algorithm-Level Optimizations</h4>\n<p>Beyond implementation optimizations, KNN performance can be improved through algorithmic enhancements that change the computational complexity.</p>\n<p><strong>Spatial Data Structures</strong></p>\n<p>The most significant algorithmic optimization is using spatial data structures to avoid exhaustive distance calculation:</p>\n<ol>\n<li><strong>KD-trees</strong>: Effective for low-dimensional data (d &lt; 10), can reduce neighbor search to O(log n)</li>\n<li><strong>Ball trees</strong>: Better for higher dimensions, maintains O(log n) search time</li>\n<li><strong>LSH (Locality-Sensitive Hashing)</strong>: Approximate nearest neighbors with sub-linear query time</li>\n<li><strong>Approximate methods</strong>: Trade accuracy for speed using sampling or early termination</li>\n</ol>\n<blockquote>\n<p><strong>Key Performance Insight</strong>: The &quot;curse of dimensionality&quot; means that exact nearest neighbor search becomes increasingly expensive as feature dimensionality grows. For high-dimensional data (d &gt; 20), approximate methods often provide better practical performance than exact algorithms.</p>\n</blockquote>\n<p><strong>Parallel Processing Opportunities</strong></p>\n<p>KNN has natural parallelization opportunities that can significantly improve performance:</p>\n<ul>\n<li><strong>Query parallelization</strong>: Different query points can be processed independently</li>\n<li><strong>Distance calculation parallelization</strong>: Vectorized operations can leverage SIMD instructions</li>\n<li><strong>Cross-validation parallelization</strong>: Different folds can be evaluated in parallel</li>\n</ul>\n<p>The debugging process for parallel implementations involves:</p>\n<ol>\n<li>Measure single-threaded baseline performance</li>\n<li>Test scaling with different numbers of worker threads</li>\n<li>Profile synchronization overhead and load balancing</li>\n<li>Verify that parallel results match single-threaded results exactly</li>\n</ol>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>This section provides practical tools and code structures for debugging KNN implementations effectively.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Profiling</td>\n<td><code>time.time()</code> and manual timing</td>\n<td><code>cProfile</code> with <code>snakeviz</code> visualization</td>\n</tr>\n<tr>\n<td>Memory Monitoring</td>\n<td><code>sys.getsizeof()</code> for basic measurements</td>\n<td><code>memory_profiler</code> with line-by-line analysis</td>\n</tr>\n<tr>\n<td>Numerical Debugging</td>\n<td>Print statements and assertions</td>\n<td><code>numpy.testing</code> for robust array comparisons</td>\n</tr>\n<tr>\n<td>Visualization</td>\n<td><code>matplotlib</code> scatter plots</td>\n<td><code>seaborn</code> statistical plots with confidence intervals</td>\n</tr>\n<tr>\n<td>Performance Testing</td>\n<td>Simple timer loops</td>\n<td><code>pytest-benchmark</code> for statistical timing</td>\n</tr>\n</tbody></table>\n<h4 id=\"debugging-infrastructure-code\">Debugging Infrastructure Code</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> warnings</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Tuple, Any</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> matplotlib.pyplot </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> plt</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> collections </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> defaultdict</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> KNNDebugger</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Comprehensive debugging utilities for KNN implementation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, knn_classifier):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.classifier </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> knn_classifier</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.debug_history </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.performance_metrics </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> defaultdict(</span><span style=\"color:#79B8FF\">list</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_numerical_stability</span><span style=\"color:#E1E4E8\">(self, X: np.ndarray, y: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Comprehensive numerical validation of KNN components.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check for NaN/inf values in feature matrix X</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Validate that all distance calculations return finite values</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Test distance symmetry: d(a,b) == d(b,a) for sample points</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Verify triangle inequality for distance metric</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Check that voting weights are properly normalized</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use np.isfinite() to check for numerical issues</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> diagnose_distance_calculation</span><span style=\"color:#E1E4E8\">(self, sample_points: np.ndarray) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Diagnose distance calculation issues with test points.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Test distance calculation with identical points (should be 0)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Test with orthogonal vectors for Euclidean distance</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Measure distance calculation time scaling with dimensionality</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Check for consistent results across multiple runs</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Validate vectorized vs loop-based implementations match</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> analyze_classification_bias</span><span style=\"color:#E1E4E8\">(self, X_test: np.ndarray, y_test: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Analyze classification for systematic biases.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Calculate per-class accuracy and identify biased classes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Measure prediction consistency with different random seeds</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Test sensitivity to K parameter across range of values</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Analyze neighbor class distributions for each prediction</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Check for correlation between confidence scores and accuracy</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> profile_performance</span><span style=\"color:#E1E4E8\">(self, X_test: np.ndarray, iterations: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 100</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Profile performance of each KNN component.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Time distance calculation phase separately</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Time neighbor finding phase separately  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Time voting/classification phase separately</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Measure memory usage during each phase</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Calculate queries per second for different dataset sizes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DistanceCalculationValidator</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Specialized validator for distance calculation correctness.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">staticmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_distance_properties</span><span style=\"color:#E1E4E8\">(distance_func, test_points: np.ndarray) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test mathematical properties of distance function.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Test non-negativity: d(a,b) >= 0</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Test identity: d(a,a) == 0  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Test symmetry: d(a,b) == d(b,a)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Test triangle inequality: d(a,c) &#x3C;= d(a,b) + d(b,c)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Test that different points have d(a,b) > 0</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">staticmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> benchmark_distance_scaling</span><span style=\"color:#E1E4E8\">(distance_func, max_dimension: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 100</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Benchmark how distance calculation scales with dimensionality.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Generate test data for dimensions 2, 5, 10, 20, 50, 100</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Time distance calculation for each dimensionality</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Measure memory usage scaling</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Check for numerical precision issues at high dimensions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return timing results for analysis</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ClassificationDiagnostic</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Tools for diagnosing classification accuracy issues.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, classifier):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.classifier </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> classifier</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> k_sensitivity_analysis</span><span style=\"color:#E1E4E8\">(self, X_train: np.ndarray, y_train: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                             X_test: np.ndarray, y_test: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]) -> Dict[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Analyze how performance varies with K parameter.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Test K values from 1 to min(50, len(X_train)//5)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: For each K, measure accuracy, precision, recall, F1</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Identify optimal K and performance plateau regions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Check for unstable regions where small K changes cause large accuracy changes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return comprehensive results for plotting and analysis</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> analyze_prediction_confidence</span><span style=\"color:#E1E4E8\">(self, X_test: np.ndarray, y_test: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Analyze relationship between confidence scores and accuracy.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Bin predictions by confidence score (e.g., 0.9-1.0, 0.8-0.9, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Calculate actual accuracy within each confidence bin</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Identify overconfident and underconfident regions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Measure confidence calibration using reliability diagrams</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Suggest confidence threshold for different precision requirements</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> PerformanceProfiler</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Advanced performance profiling for KNN implementation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.timing_history </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> defaultdict(</span><span style=\"color:#79B8FF\">list</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.memory_history </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> defaultdict(</span><span style=\"color:#79B8FF\">list</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> profile_scaling_behavior</span><span style=\"color:#E1E4E8\">(self, classifier, dataset_sizes: List[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">]) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, List[</span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Profile how performance scales with dataset size.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Generate synthetic datasets of different sizes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Measure training time (data loading) for each size</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Measure prediction time per query for each size</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Measure memory usage scaling</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Fit scaling curves and identify complexity bottlenecks</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> identify_bottlenecks</span><span style=\"color:#E1E4E8\">(self, classifier, X_test: np.ndarray) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Identify which component is the performance bottleneck.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Profile each component (distance, neighbor finding, voting) separately</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Measure what percentage of total time each component uses</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Identify memory allocation hotspots</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Check for inefficient array operations or Python loops</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Provide recommendations for optimization priorities</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Debugging utility functions</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> safe_distance_calculation</span><span style=\"color:#E1E4E8\">(point1: np.ndarray, point2: np.ndarray, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                            metric: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> 'euclidean'</span><span style=\"color:#E1E4E8\">, epsilon: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1e-10</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Distance calculation with comprehensive error checking.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate input arrays have same shape</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check for NaN/inf values in inputs</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Handle numerical edge cases (zero vectors for cosine)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Apply appropriate epsilon for numerical stability</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Validate output is finite and non-negative</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> diagnose_voting_issues</span><span style=\"color:#E1E4E8\">(neighbor_labels: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">], neighbor_distances: np.ndarray,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                          prediction: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, confidence: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Diagnose potential issues in voting logic.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check for ties in voting and how they were resolved</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Validate that confidence score matches neighbor agreement</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Check for unusual distance distributions (all same, extreme outliers)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Verify voting weights sum to 1.0 if using weighted voting</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return diagnostic information for debugging</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span></code></pre></div>\n\n<h4 id=\"file-structure-for-debugging\">File Structure for Debugging</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>project-root/\n  knn/\n    core/\n      distance.py          ← distance calculation with validation\n      neighbors.py         ← neighbor finding with edge case handling\n      classifier.py        ← classification with confidence scoring\n    debug/\n      validators.py        ← numerical and correctness validators\n      profilers.py         ← performance profiling tools\n      diagnostics.py       ← classification diagnostic tools\n    tests/\n      test_distance_debug.py    ← unit tests for distance debugging\n      test_classification_debug.py ← unit tests for classification debugging\n      test_performance.py       ← performance regression tests\n  examples/\n    debug_walkthrough.py   ← complete debugging example\n    performance_analysis.py ← performance optimization example</code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p><strong>Milestone 1 Checkpoint: Distance Calculation</strong>\nAfter implementing distance calculations, run these validation steps:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/test_distance_debug.py</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> examples/debug_walkthrough.py</span><span style=\"color:#79B8FF\"> --component</span><span style=\"color:#9ECBFF\"> distance</span></span></code></pre></div>\n\n<p>Expected behavior:</p>\n<ul>\n<li>All distance property tests pass (non-negativity, symmetry, triangle inequality)</li>\n<li>Distance calculations return identical results across multiple runs</li>\n<li>Performance scales linearly with dataset size and dimensionality</li>\n<li>No NaN or infinite values in distance outputs</li>\n</ul>\n<p>Warning signs:</p>\n<ul>\n<li>Distances are all identical (suggests scaling issues)</li>\n<li>Distance(a,a) != 0 (suggests numerical precision problems)</li>\n<li>Huge performance variation across runs (suggests memory allocation issues)</li>\n</ul>\n<p><strong>Milestone 2 Checkpoint: Classification</strong>\nAfter implementing neighbor finding and voting:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/test_classification_debug.py</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> examples/debug_walkthrough.py</span><span style=\"color:#79B8FF\"> --component</span><span style=\"color:#9ECBFF\"> classification</span></span></code></pre></div>\n\n<p>Expected behavior:</p>\n<ul>\n<li>Classification accuracy improves with optimal K selection</li>\n<li>Confidence scores correlate with prediction accuracy</li>\n<li>Voting results are deterministic for identical inputs</li>\n<li>Performance degrades gracefully with poor hyperparameters</li>\n</ul>\n<p>Warning signs:</p>\n<ul>\n<li>Accuracy doesn&#39;t improve with any K value (suggests distance calculation bugs)</li>\n<li>All predictions have identical confidence (suggests confidence calculation bugs)</li>\n<li>Results vary between identical runs (suggests non-deterministic behavior)</li>\n</ul>\n<p><strong>Milestone 3 Checkpoint: Performance Optimization</strong>\nAfter implementing optimizations:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> examples/performance_analysis.py</span><span style=\"color:#79B8FF\"> --benchmark</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/test_performance.py</span></span></code></pre></div>\n\n<p>Expected behavior:</p>\n<ul>\n<li>Vectorized operations are 10-100x faster than Python loops</li>\n<li>Memory usage scales linearly with dataset size</li>\n<li>Query time scales predictably with dataset size and dimensionality</li>\n<li>Cross-validation completes in reasonable time</li>\n</ul>\n<p>Warning signs:</p>\n<ul>\n<li>Performance doesn&#39;t improve with vectorization (suggests implementation issues)</li>\n<li>Memory usage grows quadratically (suggests distance matrix storage)</li>\n<li>Extreme sensitivity to dataset size (suggests algorithmic inefficiency)</li>\n</ul>\n<h4 id=\"language-specific-debugging-tips\">Language-Specific Debugging Tips</h4>\n<p><strong>NumPy Debugging</strong></p>\n<ul>\n<li>Use <code>np.testing.assert_array_almost_equal()</code> for robust floating-point comparisons</li>\n<li>Set <code>np.seterr(all=&#39;raise&#39;)</code> to catch numerical errors early during development</li>\n<li>Use <code>np.set_printoptions(threshold=20)</code> to avoid overwhelming debug output</li>\n<li>Profile with <code>%timeit</code> in Jupyter notebooks for quick performance checks</li>\n</ul>\n<p><strong>Python Performance</strong></p>\n<ul>\n<li>Use <code>cProfile</code> and <code>snakeviz</code> for detailed performance profiling: <code>python -m cProfile -o profile.stats your_script.py</code></li>\n<li>Monitor memory with <code>memory_profiler</code>: <code>@profile</code> decorator on functions</li>\n<li>Use <code>dis.dis()</code> to examine bytecode when debugging performance issues</li>\n<li>Set <code>PYTHONHASHSEED=0</code> for reproducible results when debugging non-deterministic behavior</li>\n</ul>\n<p><strong>Common Debugging Patterns</strong></p>\n<ul>\n<li>Add <code>assert</code> statements liberally during development to catch edge cases early</li>\n<li>Use <code>warnings.warn()</code> for potential issues that aren&#39;t errors</li>\n<li>Implement comprehensive logging with different levels (DEBUG, INFO, WARNING, ERROR)</li>\n<li>Create reproducible test cases by setting random seeds consistently</li>\n</ul>\n<h2 id=\"future-extensions\">Future Extensions</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Post-implementation enhancements that extend beyond all three core milestones - performance optimizations for distance calculation and neighbor finding, algorithmic extensions for regression and ensemble methods, and feature extensions for custom metrics and online learning</p>\n</blockquote>\n<h3 id=\"mental-model-the-evolutionary-path\">Mental Model: The Evolutionary Path</h3>\n<p>Think of the current KNN implementation as a solid foundation house that we&#39;ve built according to proven architectural principles. The foundation is strong - our distance calculation, neighbor finding, and classification components work correctly and handle edge cases gracefully. Now we&#39;re ready to add extensions like adding wings to a house, upgrading the electrical system, or installing smart home features. Each extension builds upon the existing foundation without requiring us to tear down what we&#39;ve already built.</p>\n<p>The key insight is that good software architecture enables evolution. Because we&#39;ve separated concerns into distinct components with clean interfaces, we can enhance individual components independently. We can swap out the linear neighbor search for a KD-tree without touching the classification logic. We can add new distance metrics without modifying the neighbor finding algorithms. We can extend from classification to regression by adding new voting strategies while reusing all the distance and neighbor finding infrastructure.</p>\n<p>This evolutionary approach mirrors how machine learning systems develop in practice. You start with a working baseline, measure its performance and limitations, then systematically address the most important bottlenecks. Some extensions focus on computational efficiency (performance extensions), others expand the algorithm&#39;s capabilities (algorithm extensions), and still others add flexibility and customization options (feature extensions).</p>\n<h3 id=\"performance-extensions-kd-trees-lsh-and-other-acceleration-structures\">Performance Extensions: KD-trees, LSH, and Other Acceleration Structures</h3>\n<p>The most significant limitation of our current implementation is computational performance. Linear neighbor search requires O(n) distance calculations per query, making it impractical for large datasets. Performance extensions address this bottleneck by introducing data structures and algorithms that reduce the computational complexity of neighbor finding.</p>\n<h4 id=\"mental-model-spatial-indexing-as-a-library-system\">Mental Model: Spatial Indexing as a Library System</h4>\n<p>Think of linear search as finding a book by examining every single book in a library one by one. This works for small personal libraries but becomes impossible for university libraries with millions of books. Libraries solve this with organizational systems - books are grouped by subject, then by author, then alphabetically. You can quickly narrow down to the right section, then the right shelf, then scan a small number of books.</p>\n<p>Spatial indexing works similarly for high-dimensional feature vectors. Instead of checking every training sample, we organize them into a tree structure where each level divides the space along one dimension. To find neighbors, we traverse the tree to quickly identify promising regions, then only compute distances within those regions. The key insight is trading some preprocessing time and memory for dramatically faster query performance.</p>\n<h4 id=\"kd-tree-spatial-indexing\">KD-Tree Spatial Indexing</h4>\n<p><strong>KD-trees</strong> (K-dimensional trees) represent the most fundamental spatial acceleration structure for exact nearest neighbor search. A KD-tree recursively partitions the feature space by alternating between dimensions, creating a binary tree where each internal node represents a splitting hyperplane and each leaf contains a small number of training samples.</p>\n<p>The tree construction algorithm works by selecting a dimension (typically cycling through dimensions or choosing the one with maximum variance), finding the median value along that dimension, and splitting the training samples into left and right subtrees. This process continues recursively until each leaf contains fewer than some threshold number of samples (typically 10-50).</p>\n<p>Query processing exploits the spatial organization by traversing the tree from root to leaf, following the path determined by the query point&#39;s coordinates. At each internal node, we compare the query point&#39;s value in the splitting dimension to the split value and recurse into the appropriate subtree. Once we reach a leaf, we compute exact distances to all samples in that leaf and maintain a priority queue of the K best candidates found so far.</p>\n<p>The critical optimization comes from <strong>backtracking</strong> with pruning. After exploring the initial path to a leaf, we backtrack up the tree and check whether other subtrees might contain better neighbors. However, we can prune entire subtrees if the distance from the query point to the splitting hyperplane exceeds the distance to the K-th best candidate found so far. This pruning dramatically reduces the number of distance calculations required.</p>\n<blockquote>\n<p><strong>Performance Insight</strong>: KD-trees provide logarithmic query time O(log n) for low-dimensional data but degrade to linear performance O(n) in high dimensions due to the curse of dimensionality. The rule of thumb is that KD-trees work well for fewer than 10-20 dimensions, making them ideal for geometric data but less effective for typical machine learning feature vectors with hundreds of dimensions.</p>\n</blockquote>\n<h4 id=\"architecture-decision-kd-tree-integration-strategy\">Architecture Decision: KD-Tree Integration Strategy</h4>\n<blockquote>\n<p><strong>Decision: Component-Based KD-Tree Integration</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to add KD-tree acceleration without breaking existing neighbor finding interface or requiring changes to classification components</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>Replace linear search entirely with KD-tree implementation</li>\n<li>Add KD-tree as alternative neighbor finder with same interface</li>\n<li>Hybrid approach that automatically selects linear vs KD-tree based on data characteristics</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Option 2 - Add KD-tree as alternative implementation of neighbor finder interface</li>\n<li><strong>Rationale</strong>: Preserves existing code compatibility, allows performance comparison between methods, and maintains flexibility for different use cases. Some scenarios (very small datasets, high-dimensional data) still benefit from linear search.</li>\n<li><strong>Consequences</strong>: Requires interface abstraction for neighbor finding, adds complexity of maintaining two implementations, but provides clear performance improvement path for suitable datasets.</li>\n</ul>\n</blockquote>\n<p>The integration approach preserves our existing <code>NeighborFinder</code> interface while adding a new <code>KDTreeNeighborFinder</code> implementation. The existing <code>LinearNeighborFinder</code> remains available for comparison and fallback scenarios. A factory method can automatically select the appropriate implementation based on dataset characteristics.</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Interface Method</th>\n<th>KD-Tree Implementation</th>\n<th>Linear Implementation</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>NeighborFinder</td>\n<td><code>find_k_neighbors()</code></td>\n<td>Tree traversal with backtracking</td>\n<td>Compute all distances, select top K</td>\n</tr>\n<tr>\n<td>NeighborFinder</td>\n<td><code>fit()</code></td>\n<td>Build KD-tree from training data</td>\n<td>Store training matrix directly</td>\n</tr>\n<tr>\n<td>NeighborFinder</td>\n<td><code>find_neighbors_batch()</code></td>\n<td>Parallel tree queries</td>\n<td>Vectorized distance computation</td>\n</tr>\n</tbody></table>\n<h4 id=\"approximate-nearest-neighbors-with-lsh\">Approximate Nearest Neighbors with LSH</h4>\n<p><strong>Locality-Sensitive Hashing (LSH)</strong> addresses the curse of dimensionality by trading accuracy for speed. Instead of finding the exact nearest neighbors, LSH finds approximate nearest neighbors with high probability while achieving sub-linear query time even in high dimensions.</p>\n<p>The core insight behind LSH is using hash functions with the locality-sensitive property: similar items have high probability of hashing to the same bucket, while dissimilar items likely hash to different buckets. For Euclidean distance, we can use random projection LSH where each hash function projects the feature vector onto a random direction and quantizes the result.</p>\n<p>The algorithm works by creating multiple hash tables, each using different random projections. During preprocessing, we hash each training sample into all tables and store it in the corresponding buckets. During query processing, we hash the query point using the same functions, retrieve all candidates from the matching buckets across all tables, and compute exact distances only to these candidates.</p>\n<p>The trade-off parameters control the accuracy-speed balance. More hash tables increase the probability of finding true nearest neighbors but require more memory and query time. Wider hash buckets (coarser quantization) increase recall but also increase the number of candidates to check. The optimal parameters depend on the specific dataset and accuracy requirements.</p>\n<blockquote>\n<p><strong>Trade-off Insight</strong>: LSH provides sub-linear query time O(n^ρ) where ρ &lt; 1 depends on the distance threshold, but may miss some true nearest neighbors. The missed neighbor rate typically ranges from 5-20% depending on parameter settings, making it suitable for applications that can tolerate approximate results in exchange for dramatic speedup.</p>\n</blockquote>\n<h4 id=\"ball-tree-and-cover-tree-alternatives\">Ball Tree and Cover Tree Alternatives</h4>\n<p><strong>Ball trees</strong> provide an alternative spatial indexing approach that works better than KD-trees in high dimensions. Instead of splitting along coordinate axes, ball trees recursively partition data into hyperspheres (balls), choosing splits that minimize the volume of the resulting balls. This approach adapts better to the intrinsic dimensionality of the data rather than the ambient dimensionality.</p>\n<p><strong>Cover trees</strong> offer theoretical guarantees for general metric spaces, not just Euclidean space. They maintain the covering tree property where each level covers all points within a certain radius, and the radius halves at each level. This provides O(log n) query time for datasets with bounded doubling dimension, which includes many real-world datasets despite high ambient dimensionality.</p>\n<table>\n<thead>\n<tr>\n<th>Index Structure</th>\n<th>Best Use Case</th>\n<th>Time Complexity</th>\n<th>Space Complexity</th>\n<th>Distance Metric</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>KD-Tree</td>\n<td>Low dimensions (&lt; 20)</td>\n<td>O(log n)</td>\n<td>O(n)</td>\n<td>Euclidean, Manhattan</td>\n</tr>\n<tr>\n<td>Ball Tree</td>\n<td>Medium dimensions (20-100)</td>\n<td>O(log n)</td>\n<td>O(n)</td>\n<td>Any metric</td>\n</tr>\n<tr>\n<td>Cover Tree</td>\n<td>High dimensions with structure</td>\n<td>O(log n)</td>\n<td>O(n)</td>\n<td>Any metric</td>\n</tr>\n<tr>\n<td>LSH</td>\n<td>High dimensions, approximate OK</td>\n<td>O(n^ρ)</td>\n<td>O(n^(1+ρ))</td>\n<td>Specific metrics</td>\n</tr>\n</tbody></table>\n<h4 id=\"performance-extension-implementation-strategy\">Performance Extension Implementation Strategy</h4>\n<p>The key architectural principle for performance extensions is <strong>progressive enhancement</strong>. Start with the working linear implementation, add KD-tree support for low-dimensional cases, then layer on approximate methods for high-dimensional scenarios. Each extension should integrate cleanly with the existing neighbor finding interface.</p>\n<p>A performance-aware neighbor finder factory can automatically select the best implementation based on dataset characteristics:</p>\n<ol>\n<li><strong>Dimension analysis</strong>: Count features and check for sparsity patterns</li>\n<li><strong>Size analysis</strong>: Measure dataset size relative to query frequency  </li>\n<li><strong>Distance metric analysis</strong>: Verify compatibility with spatial indexing</li>\n<li><strong>Performance profiling</strong>: Benchmark different approaches on sample data</li>\n</ol>\n<p>The factory creates an appropriate <code>NeighborFinder</code> implementation transparently, so classification and evaluation components continue working without modification. This approach allows incremental adoption of performance optimizations without disrupting working code.</p>\n<h4 id=\"common-performance-extension-pitfalls\">Common Performance Extension Pitfalls</h4>\n<p>⚠️ <strong>Pitfall: Premature KD-Tree Adoption</strong>\nMany developers immediately implement KD-trees without checking dimensionality. In high-dimensional spaces (&gt; 20 features), KD-trees often perform worse than linear search due to excessive backtracking. Always benchmark on your specific dataset before assuming KD-trees will help.</p>\n<p>⚠️ <strong>Pitfall: Ignoring Memory Overhead</strong>\nSpatial indexes require significant memory beyond the training data itself. KD-trees need tree nodes (typically 2-3x the data size), while LSH needs multiple hash tables. For memory-constrained environments, linear search might be the only viable option despite slower performance.</p>\n<p>⚠️ <strong>Pitfall: Incorrect LSH Parameter Tuning</strong>\nLSH requires careful parameter tuning for each dataset. Using default parameters often yields either poor recall (missing true neighbors) or poor performance (checking too many candidates). Implement parameter tuning procedures that optimize for your specific accuracy-speed requirements.</p>\n<p>⚠️ <strong>Pitfall: Mixing Incompatible Distance Metrics</strong>\nNot all spatial indexes support all distance metrics. KD-trees work well with Euclidean and Manhattan distance but not cosine similarity. Attempting to use incompatible combinations leads to incorrect results. Validate metric compatibility during neighbor finder construction.</p>\n<h3 id=\"algorithm-extensions-regression-support-multi-output-classification-and-ensemble-methods\">Algorithm Extensions: Regression Support, Multi-Output Classification, and Ensemble Methods</h3>\n<p>The second category of extensions expands the fundamental capabilities of the KNN algorithm beyond simple classification. These extensions leverage the same distance calculation and neighbor finding infrastructure while implementing different aggregation and prediction strategies.</p>\n<h4 id=\"mental-model-from-voting-to-averaging\">Mental Model: From Voting to Averaging</h4>\n<p>Think of the transition from classification to regression as moving from a democratic election to a town council budget meeting. In an election, neighbors vote for discrete candidates and the majority wins. In a budget meeting, neighbors propose numerical values and the final decision averages or weighs their proposals. The process of finding relevant neighbors (people whose opinions matter) remains the same, but the aggregation method changes to handle continuous values instead of discrete categories.</p>\n<p>The key insight is that nearest neighbor algorithms are fundamentally about <strong>similarity-based inference</strong>. Whether we&#39;re predicting categories or numbers, the assumption remains that similar inputs should produce similar outputs. Only the aggregation function changes to match the output type.</p>\n<h4 id=\"k-nearest-neighbors-regression\">K-Nearest Neighbors Regression</h4>\n<p><strong>KNN regression</strong> replaces majority voting with numerical averaging of neighbor target values. Instead of predicting the most frequent class among neighbors, we predict the mean (or weighted mean) of neighbor regression targets. This natural extension handles any continuous prediction task while maintaining the same lazy learning characteristics as KNN classification.</p>\n<p>The core algorithm remains nearly identical to classification:</p>\n<ol>\n<li><strong>Neighbor identification</strong>: Use the same distance calculation and neighbor finding procedures to identify the K closest training samples to the query point</li>\n<li><strong>Target extraction</strong>: Extract the continuous target values (instead of class labels) for the K neighbors  </li>\n<li><strong>Numerical aggregation</strong>: Compute the mean, weighted mean, or other aggregation of neighbor target values</li>\n<li><strong>Confidence estimation</strong>: Calculate prediction confidence based on variance among neighbor targets</li>\n</ol>\n<p>The weighted averaging approach gives closer neighbors more influence on the prediction, similar to weighted voting in classification. The weight for each neighbor is typically the inverse of its distance (with small epsilon to avoid division by zero), though other weighting schemes like Gaussian kernels are also effective.</p>\n<blockquote>\n<p><strong>Algorithmic Insight</strong>: KNN regression naturally handles non-linear relationships and local patterns that would challenge linear regression. However, it provides no extrapolation capability - predictions for points outside the training data convex hull simply reflect the nearest boundary training samples.</p>\n</blockquote>\n<h4 id=\"architecture-decision-unified-prediction-interface\">Architecture Decision: Unified Prediction Interface</h4>\n<blockquote>\n<p><strong>Decision: Generic Prediction Interface Supporting Multiple Output Types</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to support classification (discrete outputs), regression (continuous outputs), and multi-output scenarios without duplicating neighbor finding logic</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Separate KNNClassifier and KNNRegressor classes with duplicated infrastructure</li>\n<li>Single KNNPredictor class with output-type parameter controlling aggregation strategy</li>\n<li>Generic KNNPredictor with pluggable aggregation functions</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Option 3 - Generic predictor with strategy pattern for aggregation</li>\n<li><strong>Rationale</strong>: Maximizes code reuse, allows custom aggregation functions, and supports future extensions like multi-output prediction. The strategy pattern cleanly separates neighbor finding (shared) from output aggregation (variable).</li>\n<li><strong>Consequences</strong>: Requires more abstract interface design but enables maximum flexibility and extensibility for different prediction tasks.</li>\n</ul>\n</blockquote>\n<p>The unified architecture uses an <code>AggregationStrategy</code> interface with implementations for different prediction types:</p>\n<table>\n<thead>\n<tr>\n<th>Aggregation Strategy</th>\n<th>Input</th>\n<th>Output</th>\n<th>Use Case</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>MajorityVoteAggregator</td>\n<td>List[ClassLabel]</td>\n<td>ClassLabel</td>\n<td>Single-label classification</td>\n</tr>\n<tr>\n<td>WeightedVoteAggregator</td>\n<td>List[ClassLabel], DistanceArray</td>\n<td>ClassLabel</td>\n<td>Weighted classification</td>\n</tr>\n<tr>\n<td>MeanRegressionAggregator</td>\n<td>List[float]</td>\n<td>float</td>\n<td>Continuous regression</td>\n</tr>\n<tr>\n<td>WeightedRegressionAggregator</td>\n<td>List[float], DistanceArray</td>\n<td>float</td>\n<td>Weighted regression</td>\n</tr>\n<tr>\n<td>MultiLabelAggregator</td>\n<td>List[Set[ClassLabel]]</td>\n<td>Set[ClassLabel]</td>\n<td>Multi-label classification</td>\n</tr>\n<tr>\n<td>MultiOutputAggregator</td>\n<td>List[Vector]</td>\n<td>Vector</td>\n<td>Multi-output regression</td>\n</tr>\n</tbody></table>\n<h4 id=\"multi-output-and-multi-label-prediction\">Multi-Output and Multi-Label Prediction</h4>\n<p><strong>Multi-output prediction</strong> extends KNN to handle vector-valued outputs instead of scalar targets. Each training sample has a target vector rather than a single value, and the aggregation computes element-wise means across neighbor target vectors. This naturally handles scenarios like predicting multiple related quantities simultaneously (e.g., temperature and humidity based on location and time).</p>\n<p><strong>Multi-label classification</strong> handles cases where each sample can belong to multiple classes simultaneously (e.g., image tagging where a photo might contain both &quot;cat&quot; and &quot;outdoor&quot;). The aggregation strategy counts how often each label appears among the K neighbors and applies a threshold to determine which labels to predict for the query point.</p>\n<p>The multi-label threshold selection requires careful consideration. A simple approach uses a fixed threshold (e.g., predict labels that appear in &gt; 50% of neighbors), but adaptive thresholds based on label frequency in the training set often work better. The threshold can also be tuned using cross-validation to optimize specific multi-label metrics like Hamming loss or F1 score.</p>\n<h4 id=\"knn-ensemble-methods\">KNN Ensemble Methods</h4>\n<p><strong>Ensemble methods</strong> combine multiple KNN predictors to improve robustness and accuracy. The two main ensemble approaches are <strong>bagging</strong> (bootstrap aggregation) and <strong>random subspace methods</strong>.</p>\n<p>KNN bagging creates multiple KNN models trained on bootstrap samples of the training data. Each model votes on the final prediction, with the ensemble aggregating individual model outputs. This reduces variance and improves stability, especially for noisy datasets where individual predictions might vary significantly.</p>\n<p>Random subspace methods train multiple KNN models on different subsets of features rather than different subsets of samples. Each model uses a randomly selected subset of dimensions, forcing the ensemble to consider different similarity measures. This approach particularly helps in high-dimensional spaces where not all features are equally informative for every prediction.</p>\n<p>The ensemble aggregation strategy depends on the prediction type. Classification ensembles typically use majority voting among individual model predictions, while regression ensembles average the numerical predictions. Weighted ensemble methods give different models different influence based on their estimated reliability or past performance.</p>\n<table>\n<thead>\n<tr>\n<th>Ensemble Method</th>\n<th>Training Strategy</th>\n<th>Prediction Strategy</th>\n<th>Benefits</th>\n<th>Best Use Cases</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Bootstrap Bagging</td>\n<td>Multiple bootstrap samples</td>\n<td>Majority vote/averaging</td>\n<td>Reduces variance</td>\n<td>Noisy datasets</td>\n</tr>\n<tr>\n<td>Random Subspace</td>\n<td>Random feature subsets</td>\n<td>Majority vote/averaging</td>\n<td>Handles irrelevant features</td>\n<td>High-dimensional data</td>\n</tr>\n<tr>\n<td>Weighted Ensemble</td>\n<td>Performance-based weights</td>\n<td>Weighted vote/averaging</td>\n<td>Adapts to model quality</td>\n<td>Heterogeneous feature types</td>\n</tr>\n</tbody></table>\n<h4 id=\"confidence-and-uncertainty-estimation\">Confidence and Uncertainty Estimation</h4>\n<p>Algorithm extensions also improve confidence estimation beyond simple neighbor agreement. <strong>Prediction intervals</strong> for regression quantify the uncertainty in numerical predictions by analyzing the distribution of neighbor targets. Instead of reporting just the mean prediction, we can report confidence intervals based on the standard deviation of neighbor values.</p>\n<p><strong>Conformal prediction</strong> provides distribution-free confidence intervals with theoretical coverage guarantees. The method works by analyzing the conformity scores (distances to neighbors) for training data to calibrate prediction intervals that contain the true target with specified probability.</p>\n<p>For classification, <strong>calibrated confidence scores</strong> improve upon simple neighbor agreement by accounting for the base rate of each class in the local neighborhood. A prediction might have high neighbor agreement but low confidence if it predicts a rare class in a region where that class is extremely uncommon.</p>\n<h4 id=\"algorithm-extension-implementation-strategy\">Algorithm Extension Implementation Strategy</h4>\n<p>The key principle for algorithm extensions is <strong>composition over inheritance</strong>. Rather than creating separate class hierarchies for classification vs regression vs multi-output, we compose a generic predictor from reusable components: neighbor finder, aggregation strategy, and confidence estimator.</p>\n<p>The implementation approach layers new capabilities on the existing foundation:</p>\n<ol>\n<li><strong>Preserve existing interfaces</strong>: Classification functionality continues working exactly as before</li>\n<li><strong>Add strategy interfaces</strong>: Define aggregation strategy interface with multiple implementations  </li>\n<li><strong>Extend data model</strong>: Add support for vector targets and multi-label formats</li>\n<li><strong>Compose predictors</strong>: Factory methods create appropriately configured predictors for different tasks</li>\n</ol>\n<p>This approach allows gradual adoption of new capabilities without breaking existing classification code while sharing all the distance calculation, neighbor finding, and evaluation infrastructure across different prediction tasks.</p>\n<h4 id=\"common-algorithm-extension-pitfalls\">Common Algorithm Extension Pitfalls</h4>\n<p>⚠️ <strong>Pitfall: Inappropriate Aggregation for Target Distribution</strong>\nSimple mean aggregation works poorly when neighbor targets have skewed or multi-modal distributions. For example, if neighbors have targets [1, 1, 2, 100], the mean prediction of 26 might be far from any actual neighbor value. Consider median aggregation or distribution-aware methods for robust predictions.</p>\n<p>⚠️ <strong>Pitfall: Ignoring Output Scale Differences in Multi-Output</strong>\nMulti-output prediction can be dominated by targets with large numerical ranges. If predicting both temperature (range 0-40°C) and pressure (range 900-1100 hPa), the pressure component will dominate distance calculations and aggregation. Always normalize or scale multiple outputs appropriately.</p>\n<p>⚠️ <strong>Pitfall: Overconfident Multi-Label Predictions</strong>\nMulti-label classification often predicts too many labels because each label is evaluated independently. The probability of having at least one false positive increases with the number of labels. Adjust thresholds or use more conservative confidence estimation for multi-label scenarios.</p>\n<p>⚠️ <strong>Pitfall: Ensemble Overfitting</strong>\nKNN ensembles can overfit if all individual models are too similar (e.g., using the same features and very similar bootstrap samples). Ensure sufficient diversity between ensemble members through different feature subsets, different K values, or different distance metrics.</p>\n<h3 id=\"feature-extensions-custom-distance-metrics-feature-weighting-and-online-learning\">Feature Extensions: Custom Distance Metrics, Feature Weighting, and Online Learning</h3>\n<p>The third category of extensions enhances the flexibility and adaptability of the KNN system through customizable similarity measures and adaptive learning capabilities. These extensions primarily focus on improving the core assumption that &quot;similar inputs produce similar outputs&quot; by allowing more sophisticated definitions of similarity.</p>\n<h4 id=\"mental-model-from-universal-metrics-to-personalized-similarity\">Mental Model: From Universal Metrics to Personalized Similarity</h4>\n<p>Think of the evolution from standard distance metrics to custom similarity measures as moving from a one-size-fits-all measuring tape to a personalized fitting system. A standard measuring tape works for basic measurements, but a skilled tailor uses multiple specialized tools and techniques to capture the nuances that matter for a perfect fit. Similarly, while Euclidean distance works for basic similarity measurement, many real-world problems require specialized similarity measures that capture domain-specific knowledge about what makes two examples truly similar.</p>\n<p>The key insight is that <strong>distance metrics encode assumptions</strong> about the problem structure. Euclidean distance assumes all features contribute equally and independently to similarity, but real problems often have features with different importance, complex interactions, or specialized semantics (like categorical features, temporal sequences, or hierarchical structures).</p>\n<h4 id=\"custom-distance-metric-framework\">Custom Distance Metric Framework</h4>\n<p>A <strong>custom distance metric framework</strong> allows domain experts to encode specialized knowledge about similarity directly into the KNN algorithm. This goes beyond the standard Euclidean, Manhattan, and cosine metrics to support problem-specific similarity measures that capture the true structure of the data.</p>\n<p>The framework must balance flexibility with performance. Custom metrics should integrate seamlessly with existing neighbor finding infrastructure while supporting vectorized operations for efficiency. The challenge is providing enough expressiveness for complex similarity measures without sacrificing the performance characteristics that make KNN practical for large datasets.</p>\n<p>Key design requirements for the custom metric framework include:</p>\n<ol>\n<li><strong>Interface compatibility</strong>: Custom metrics must implement the same interface as standard metrics for seamless integration</li>\n<li><strong>Vectorization support</strong>: Custom metrics should support batch operations on feature matrices, not just pairwise calculations  </li>\n<li><strong>Parameter management</strong>: Many custom metrics have tunable parameters that need validation and optimization</li>\n<li><strong>Differentiability</strong>: Some applications require gradient information for advanced optimization</li>\n<li><strong>Serialization support</strong>: Custom metrics must be saveable and loadable for model persistence</li>\n</ol>\n<p>The implementation uses a strategy pattern where each distance metric implements a common interface. Custom metrics can be pure Python functions (for flexibility), compiled functions (for performance), or even learned metrics (for adaptability).</p>\n<h4 id=\"feature-weighting-and-learned-metrics\">Feature Weighting and Learned Metrics</h4>\n<p><strong>Feature weighting</strong> addresses the common problem that not all features contribute equally to meaningful similarity. In many datasets, some features are highly predictive while others are noise or irrelevant. Standard distance metrics treat all features equally, potentially drowning out important signals with irrelevant variation.</p>\n<p>Simple feature weighting multiplies each feature difference by a weight before computing the overall distance. The challenge is determining appropriate weights. Manual weight setting requires domain expertise and extensive experimentation. Automatic weight learning uses the training data to optimize weights for classification accuracy.</p>\n<p><strong>Learned distance metrics</strong> go beyond simple feature weighting to learn complex transformations that improve similarity measurement. The most common approaches are:</p>\n<ol>\n<li><strong>Mahalanobis distance learning</strong>: Learn a full covariance matrix that captures feature correlations and scales</li>\n<li><strong>Linear metric learning</strong>: Learn a linear transformation that maximizes separation between different classes  </li>\n<li><strong>Nonlinear metric learning</strong>: Use neural networks to learn complex similarity functions</li>\n<li><strong>Local metric learning</strong>: Learn different metrics for different regions of the feature space</li>\n</ol>\n<p>The metric learning process requires labeled training data to optimize the distance function. The objective is typically to minimize distances between samples with the same label while maximizing distances between samples with different labels, subject to constraints that ensure the learned function satisfies metric properties.</p>\n<blockquote>\n<p><strong>Learning Insight</strong>: Learned distance metrics can dramatically improve KNN performance, often achieving 10-30% accuracy gains on high-dimensional datasets. However, they require careful regularization to avoid overfitting and may not generalize well to very different test distributions.</p>\n</blockquote>\n<h4 id=\"architecture-decision-pluggable-distance-metric-architecture\">Architecture Decision: Pluggable Distance Metric Architecture</h4>\n<blockquote>\n<p><strong>Decision: Strategy Pattern with Metric Registry for Custom Distance Functions</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to support standard metrics, custom user-defined metrics, and learned metrics without modifying core neighbor finding logic</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Hard-coded switch statement for metric selection with no custom support</li>\n<li>Function pointer approach allowing arbitrary distance functions</li>\n<li>Registry pattern with standardized metric interface and discovery mechanism</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Option 3 - Registry pattern with metric interface and automatic discovery</li>\n<li><strong>Rationale</strong>: Provides type safety and validation, enables metric composition and parameterization, supports serialization for model persistence, and allows discovery of available metrics at runtime</li>\n<li><strong>Consequences</strong>: More complex implementation but maximum extensibility and maintainability for evolving metric requirements</li>\n</ul>\n</blockquote>\n<p>The metric registry approach allows runtime discovery and validation of available distance metrics:</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Responsibility</th>\n<th>Interface Methods</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>DistanceMetricRegistry</code></td>\n<td>Manage available metrics</td>\n<td><code>register_metric()</code>, <code>get_metric()</code>, <code>list_metrics()</code></td>\n</tr>\n<tr>\n<td><code>DistanceMetric</code></td>\n<td>Abstract metric interface</td>\n<td><code>calculate()</code>, <code>batch_calculate()</code>, <code>get_parameters()</code></td>\n</tr>\n<tr>\n<td><code>StandardMetric</code></td>\n<td>Built-in metric implementations</td>\n<td>Standard euclidean, manhattan, cosine implementations</td>\n</tr>\n<tr>\n<td><code>CustomMetric</code></td>\n<td>User-defined metrics</td>\n<td>Wraps user functions with validation and vectorization</td>\n</tr>\n<tr>\n<td><code>LearnedMetric</code></td>\n<td>Trained similarity functions</td>\n<td>Loads parameters, applies transformations</td>\n</tr>\n</tbody></table>\n<h4 id=\"categorical-and-mixed-type-feature-support\">Categorical and Mixed-Type Feature Support</h4>\n<p>Real-world datasets often contain <strong>mixed feature types</strong>: numerical, categorical, ordinal, and text features. Standard distance metrics designed for continuous numerical features don&#39;t handle categorical features appropriately. Computing Euclidean distance between &quot;red&quot;, &quot;green&quot;, and &quot;blue&quot; color values encoded as 1, 2, 3 makes no sense since the numerical encoding is arbitrary.</p>\n<p>A comprehensive distance framework must support appropriate similarity measures for each feature type and combine them coherently:</p>\n<ol>\n<li><strong>Numerical features</strong>: Standard metrics like Euclidean, Manhattan, or scaled versions</li>\n<li><strong>Categorical features</strong>: Hamming distance, Jaccard similarity, or category-specific similarity matrices</li>\n<li><strong>Ordinal features</strong>: Distance based on rank differences rather than value differences  </li>\n<li><strong>Text features</strong>: String edit distance, token overlap, or semantic similarity using embeddings</li>\n<li><strong>Structured features</strong>: Specialized distances for graphs, sequences, or hierarchical data</li>\n</ol>\n<p>The combination strategy typically uses weighted combination where each feature type contributes to the overall distance according to learned or specified weights. Some approaches learn to weight different feature types automatically based on their predictive value for the classification task.</p>\n<h4 id=\"online-learning-and-adaptive-knn\">Online Learning and Adaptive KNN</h4>\n<p><strong>Online learning</strong> enables KNN models to adapt to new data without complete retraining. Traditional KNN is inherently online for adding new training samples (just add them to the training set), but adaptive approaches go further by adjusting distance metrics, feature weights, or neighbor selection strategies based on prediction feedback.</p>\n<p>Key online learning capabilities include:</p>\n<ol>\n<li><strong>Incremental training sample addition</strong>: Efficiently add new training samples to existing spatial indexes</li>\n<li><strong>Concept drift detection</strong>: Identify when the underlying data distribution has changed  </li>\n<li><strong>Adaptive metric updates</strong>: Adjust distance function parameters based on recent prediction accuracy</li>\n<li><strong>Selective sample retention</strong>: Remove outdated or redundant training samples to maintain performance</li>\n<li><strong>Dynamic K adjustment</strong>: Adapt the number of neighbors based on local data density and prediction confidence</li>\n</ol>\n<p>The <strong>incremental index update</strong> problem requires careful handling of spatial data structures. Adding samples to a KD-tree might require rebalancing subtrees to maintain optimal performance. LSH tables need to incorporate new samples into existing hash buckets. The trade-off is between update efficiency and query performance degradation.</p>\n<p><strong>Concept drift adaptation</strong> monitors prediction accuracy over time to detect when the learned patterns become stale. When drift is detected, the system can retrain distance metrics, adjust feature weights, or selectively replace outdated training samples with recent examples that better represent the current distribution.</p>\n<h4 id=\"streaming-knn-and-memory-management\">Streaming KNN and Memory Management</h4>\n<p><strong>Streaming KNN</strong> handles continuous data streams where the full dataset doesn&#39;t fit in memory and samples arrive continuously. This requires sophisticated memory management strategies that maintain prediction accuracy while respecting memory constraints.</p>\n<p>Common streaming strategies include:</p>\n<ol>\n<li><strong>Sliding window</strong>: Maintain only the most recent N training samples, discarding older data</li>\n<li><strong>Reservoir sampling</strong>: Probabilistically sample from the full stream to maintain a representative subset</li>\n<li><strong>Hierarchical clustering</strong>: Group similar samples and represent clusters with prototypes to reduce memory usage</li>\n<li><strong>Importance-based retention</strong>: Keep samples that are most important for decision boundaries</li>\n</ol>\n<p>The streaming approach must balance several competing objectives: maintaining representative coverage of the feature space, preserving decision boundary information, adapting to concept drift, and respecting strict memory limits. The optimal strategy depends on the specific characteristics of the data stream and application requirements.</p>\n<h4 id=\"feature-extension-implementation-strategy\">Feature Extension Implementation Strategy</h4>\n<p>Feature extensions require careful architectural planning to maintain compatibility with existing components while adding significant new capabilities. The key principles are:</p>\n<ol>\n<li><strong>Backward compatibility</strong>: Existing classification code continues working without modification</li>\n<li><strong>Progressive disclosure</strong>: Simple use cases remain simple, complex customization is possible but optional</li>\n<li><strong>Performance preservation</strong>: Custom metrics shouldn&#39;t significantly degrade performance for standard use cases  </li>\n<li><strong>Extensibility</strong>: New metric types and learning approaches can be added without core system changes</li>\n</ol>\n<p>The implementation approach layers customization capabilities on the proven foundation:</p>\n<ol>\n<li><strong>Extend metric interface</strong>: Add support for parameterized and learned metrics</li>\n<li><strong>Add feature type support</strong>: Handle mixed-type datasets with appropriate similarity measures</li>\n<li><strong>Implement online learning</strong>: Add incremental update capabilities to spatial indexes</li>\n<li><strong>Create streaming support</strong>: Add memory management and sample selection strategies</li>\n</ol>\n<h4 id=\"common-feature-extension-pitfalls\">Common Feature Extension Pitfalls</h4>\n<p>⚠️ <strong>Pitfall: Inappropriate Distance Combinations for Mixed Types</strong>\nSimply concatenating distances from different feature types often produces meaningless results because the scales and distributions differ dramatically. A categorical Hamming distance of 0.5 and a numerical Euclidean distance of 50 can&#39;t be combined directly. Always normalize or scale distance components appropriately before combination.</p>\n<p>⚠️ <strong>Pitfall: Overfitting with Learned Metrics</strong>\nMetric learning on small datasets often overfits, creating distance functions that work well on training data but generalize poorly. This is especially problematic for nonlinear metric learning with many parameters. Use appropriate regularization and validate on held-out data when learning custom distance functions.</p>\n<p>⚠️ <strong>Pitfall: Ignoring Computational Cost of Custom Metrics</strong>\nComplex custom distance functions can make KNN impractically slow. A custom metric that takes 100x longer than Euclidean distance transforms an already expensive O(n) neighbor search into a completely unusable algorithm. Profile custom metrics carefully and consider approximation strategies for expensive similarity functions.</p>\n<p>⚠️ <strong>Pitfall: Memory Leaks in Online Learning</strong>\nStreaming KNN implementations often develop memory leaks by failing to properly remove references to discarded training samples or by accumulating metadata that grows without bound. Implement explicit memory management and monitoring for long-running online learning systems.</p>\n<p>⚠️ <strong>Pitfall: Concept Drift Overreaction</strong>\nOnline adaptation systems can overreact to temporary prediction accuracy fluctuations, continuously adjusting parameters and creating instability. Implement smoothing and statistical significance tests before triggering adaptation mechanisms to avoid thrashing.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>This section provides concrete implementation strategies for extending the KNN system with performance optimizations, algorithmic enhancements, and feature customizations. The implementation approach emphasizes modularity and backward compatibility to enable incremental adoption of extensions without disrupting working systems.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Extension Category</th>\n<th>Simple Approach</th>\n<th>Advanced Approach</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Spatial Indexing</td>\n<td>Pure Python KD-tree</td>\n<td>scikit-learn NearestNeighbors with Ball Tree</td>\n</tr>\n<tr>\n<td>Approximate NN</td>\n<td>Random projection LSH</td>\n<td>FAISS library with GPU acceleration</td>\n</tr>\n<tr>\n<td>Custom Metrics</td>\n<td>Function-based metrics</td>\n<td>Compiled Cython/Numba functions</td>\n</tr>\n<tr>\n<td>Metric Learning</td>\n<td>Simple feature weighting</td>\n<td>Neural metric learning with PyTorch</td>\n</tr>\n<tr>\n<td>Online Learning</td>\n<td>Sliding window buffer</td>\n<td>Incremental clustering with river library</td>\n</tr>\n<tr>\n<td>Streaming Processing</td>\n<td>Collections.deque buffer</td>\n<td>Apache Kafka + stream processing</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-module-structure-for-extensions\">Recommended Module Structure for Extensions</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>knn_project/\n├── core/                           # Existing core components\n│   ├── distance_metrics.py\n│   ├── neighbor_finder.py\n│   ├── classifier.py\n│   └── evaluator.py\n├── extensions/                     # New extension modules\n│   ├── __init__.py\n│   ├── performance/               # Performance extensions\n│   │   ├── __init__.py\n│   │   ├── kdtree_finder.py      # KD-tree neighbor finder\n│   │   ├── lsh_finder.py         # LSH approximate finder\n│   │   ├── spatial_index.py      # Spatial indexing interface\n│   │   └── performance_factory.py # Auto-select optimal implementation\n│   ├── algorithms/                # Algorithm extensions\n│   │   ├── __init__.py\n│   │   ├── regression.py          # KNN regression implementation\n│   │   ├── multi_output.py        # Multi-output prediction\n│   │   ├── ensemble.py            # Ensemble methods\n│   │   └── aggregation_strategies.py # Pluggable aggregation functions\n│   ├── features/                   # Feature extensions\n│   │   ├── __init__.py\n│   │   ├── custom_metrics.py      # Custom distance metric framework\n│   │   ├── metric_learning.py     # Learned distance functions\n│   │   ├── mixed_types.py         # Mixed feature type support\n│   │   ├── online_learning.py     # Incremental learning\n│   │   └── streaming.py           # Streaming KNN\n│   └── utils/                      # Extension utilities\n│       ├── __init__.py\n│       ├── metric_registry.py     # Distance metric discovery\n│       ├── memory_management.py   # Streaming memory management\n│       └── validation_extended.py # Validation for extensions\n├── examples/                       # Extension examples\n│   ├── kdtree_performance.py\n│   ├── custom_metric_demo.py\n│   ├── regression_example.py\n│   └── streaming_demo.py\n└── tests/\n    ├── test_extensions/\n    │   ├── test_kdtree.py\n    │   ├── test_custom_metrics.py\n    │   ├── test_regression.py\n    │   └── test_streaming.py</code></pre></div>\n\n<h4 id=\"infrastructure-starter-code-spatial-indexing-interface\">Infrastructure Starter Code: Spatial Indexing Interface</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Spatial indexing interface for performance extensions.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Copy and use this complete module to enable pluggable spatial indexes.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> abc </span><span style=\"color:#F97583\">import</span><span style=\"color:#79B8FF\"> ABC</span><span style=\"color:#E1E4E8\">, abstractmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Tuple, List, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> core.data_model </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> FeatureMatrix, FeatureVector, DistanceArray, NeighborIndices</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> core.distance_metrics </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> DistanceMetric</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> IndexType</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Supported spatial index types for neighbor finding optimization.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    LINEAR</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"linear\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    KDTREE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"kdtree\"</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    BALLTREE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"balltree\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    LSH</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"lsh\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    AUTO</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"auto\"</span><span style=\"color:#6A737D\">  # Automatically select best for dataset</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SpatialIndex</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">ABC</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Abstract interface for spatial indexing structures that accelerate neighbor finding.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    All spatial indexes must implement this interface to work with the neighbor finder.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    The interface supports both exact and approximate nearest neighbor methods.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, distance_metric: DistanceMetric):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.distance_metric </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> distance_metric</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.is_fitted </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.n_samples </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.n_features </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @abstractmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> fit</span><span style=\"color:#E1E4E8\">(self, X: FeatureMatrix) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Build the spatial index from training data.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            X: Training feature matrix of shape (n_samples, n_features)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @abstractmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> query</span><span style=\"color:#E1E4E8\">(self, query_point: FeatureVector, k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Tuple[NeighborIndices, DistanceArray]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Find K nearest neighbors to query point using spatial index.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            query_point: Query feature vector</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            k: Number of neighbors to find</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Tuple of (neighbor_indices, neighbor_distances) sorted by distance</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @abstractmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> query_batch</span><span style=\"color:#E1E4E8\">(self, query_points: FeatureMatrix, k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> List[Tuple[NeighborIndices, DistanceArray]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Find K nearest neighbors for multiple query points efficiently.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            query_points: Query feature matrix of shape (n_queries, n_features)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            k: Number of neighbors to find for each query</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            List of (neighbor_indices, neighbor_distances) for each query</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @abstractmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_memory_usage</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Return approximate memory usage of the index in bytes.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> supports_metric</span><span style=\"color:#E1E4E8\">(self, metric: DistanceMetric) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Check if this index type supports the given distance metric.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Default implementation - subclasses can override</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> metric </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> [DistanceMetric.</span><span style=\"color:#79B8FF\">EUCLIDEAN</span><span style=\"color:#E1E4E8\">, DistanceMetric.</span><span style=\"color:#79B8FF\">MANHATTAN</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> LinearIndex</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">SpatialIndex</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Linear search baseline implementation for comparison and fallback.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Works with any distance metric but has O(n) query time.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, distance_metric: DistanceMetric):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">(distance_metric)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.training_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> fit</span><span style=\"color:#E1E4E8\">(self, X: FeatureMatrix) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Store training data for linear search.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.training_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> X.copy()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.n_samples, </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.n_features </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> X.shape</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.is_fitted </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> query</span><span style=\"color:#E1E4E8\">(self, query_point: FeatureVector, k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Tuple[NeighborIndices, DistanceArray]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Compute distances to all training samples and select top K.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.is_fitted:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Index must be fitted before querying\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Import here to avoid circular dependency</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        from</span><span style=\"color:#E1E4E8\"> core.distance_metrics </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> calculate_distances_to_point</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        distances </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> calculate_distances_to_point(query_point, </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.training_data, </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.distance_metric)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        neighbor_indices </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.argsort(distances)[:k]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        neighbor_distances </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> distances[neighbor_indices]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> neighbor_indices.astype(np.int32), neighbor_distances</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> query_batch</span><span style=\"color:#E1E4E8\">(self, query_points: FeatureMatrix, k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> List[Tuple[NeighborIndices, DistanceArray]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Process multiple queries using vectorized operations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> [</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.query(query_point, k) </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> query_point </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> query_points]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_memory_usage</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Return memory usage of stored training data.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.training_data </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.training_data.nbytes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> supports_metric</span><span style=\"color:#E1E4E8\">(self, metric: DistanceMetric) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Linear search supports all implemented distance metrics.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> IndexFactory</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Factory for creating appropriate spatial indexes based on dataset characteristics.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">staticmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> create_index</span><span style=\"color:#E1E4E8\">(index_type: IndexType, distance_metric: DistanceMetric, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    X: Optional[FeatureMatrix] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> SpatialIndex:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Create spatial index instance with automatic selection if requested.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            index_type: Type of spatial index to create</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            distance_metric: Distance metric for neighbor finding</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            X: Training data for automatic index selection (optional)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Configured spatial index instance</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> index_type </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> IndexType.</span><span style=\"color:#79B8FF\">AUTO</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Auto-select based on dataset characteristics</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> X </span><span style=\"color:#F97583\">is</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                n_samples, n_features </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> X.shape</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> n_features </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 10</span><span style=\"color:#F97583\"> and</span><span style=\"color:#E1E4E8\"> n_samples </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 1000</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    index_type </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> IndexType.</span><span style=\"color:#79B8FF\">KDTREE</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                elif</span><span style=\"color:#E1E4E8\"> n_features </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 50</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    index_type </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> IndexType.</span><span style=\"color:#79B8FF\">BALLTREE</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    index_type </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> IndexType.</span><span style=\"color:#79B8FF\">LSH</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> n_samples </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 10000</span><span style=\"color:#F97583\"> else</span><span style=\"color:#E1E4E8\"> IndexType.</span><span style=\"color:#79B8FF\">LINEAR</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                index_type </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> IndexType.</span><span style=\"color:#79B8FF\">LINEAR</span><span style=\"color:#6A737D\">  # Safe default</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> index_type </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> IndexType.</span><span style=\"color:#79B8FF\">LINEAR</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> LinearIndex(distance_metric)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#E1E4E8\"> index_type </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> IndexType.</span><span style=\"color:#79B8FF\">KDTREE</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Import only when needed</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            from</span><span style=\"color:#E1E4E8\"> extensions.performance.kdtree_finder </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> KDTreeIndex</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> KDTreeIndex(distance_metric)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#E1E4E8\"> index_type </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> IndexType.</span><span style=\"color:#79B8FF\">BALLTREE</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            from</span><span style=\"color:#E1E4E8\"> extensions.performance.balltree_finder </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> BallTreeIndex</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> BallTreeIndex(distance_metric)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#E1E4E8\"> index_type </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> IndexType.</span><span style=\"color:#79B8FF\">LSH</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            from</span><span style=\"color:#E1E4E8\"> extensions.performance.lsh_finder </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> LSHIndex</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> LSHIndex(distance_metric)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Unsupported index type: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">index_type</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeleton-custom-distance-metric-framework\">Core Logic Skeleton: Custom Distance Metric Framework</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Custom distance metric framework implementation.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Implement the </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#9ECBFF\"> sections to enable user-defined similarity functions.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Callable, Dict, Any, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> abc </span><span style=\"color:#F97583\">import</span><span style=\"color:#79B8FF\"> ABC</span><span style=\"color:#E1E4E8\">, abstractmethod</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> core.data_model </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> FeatureVector, FeatureMatrix, DistanceArray</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> core.distance_metrics </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> DistanceMetric</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> CustomDistanceMetric</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">ABC</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Abstract base class for custom distance metric implementations.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Enables domain-specific similarity measures beyond standard metrics.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, parameters: Optional[Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> name</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.parameters </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> parameters </span><span style=\"color:#F97583\">or</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.is_fitted </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @abstractmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> calculate</span><span style=\"color:#E1E4E8\">(self, point1: FeatureVector, point2: FeatureVector) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Calculate distance between two feature vectors.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            point1: First feature vector</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            point2: Second feature vector</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Distance value (non-negative, 0 for identical points)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate that input vectors have same dimensionality</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check for any custom metric preconditions (e.g., fitted parameters)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Implement the core distance calculation logic</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Ensure result satisfies metric properties if required (symmetry, triangle inequality)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return non-negative distance value</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> batch_calculate</span><span style=\"color:#E1E4E8\">(self, query_point: FeatureVector, training_matrix: FeatureMatrix) -> DistanceArray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Calculate distances from query point to all training samples efficiently.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            query_point: Query feature vector</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            training_matrix: Training data matrix (n_samples, n_features)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Array of distances to each training sample</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate input dimensions match between query and training data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check if vectorized implementation is available for this metric</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: If vectorized: use numpy operations for efficient computation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: If not vectorized: loop through training samples calling calculate()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return distance array with shape (n_samples,)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Vectorized operations are 10-100x faster than Python loops</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> fit</span><span style=\"color:#E1E4E8\">(self, X: FeatureMatrix, y: Optional[np.ndarray] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Fit metric parameters based on training data (for learned metrics).</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            X: Training feature matrix</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            y: Training labels (optional, for supervised metric learning)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate training data format and consistency</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Initialize any learnable parameters based on data statistics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: If supervised metric: optimize parameters using label information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Store fitted parameters in self.parameters</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Set self.is_fitted = True</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_parameters</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Return current metric parameters for serialization.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.parameters.copy()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> set_parameters</span><span style=\"color:#E1E4E8\">(self, parameters: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Set metric parameters from deserialization.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.parameters </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> parameters.copy()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Mark as fitted if parameters suggest a trained metric</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.is_fitted </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(parameters) </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> FunctionBasedMetric</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">CustomDistanceMetric</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Custom metric wrapper for user-provided distance functions.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Enables quick prototyping of domain-specific similarity measures.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, distance_function: Callable, vectorized: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> False</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">(name)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.distance_function </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> distance_function</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.vectorized </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> vectorized</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> calculate</span><span style=\"color:#E1E4E8\">(self, point1: FeatureVector, point2: FeatureVector) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Delegate to user-provided distance function.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate input vectors have same shape</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Call user distance function with appropriate error handling</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Validate that result is non-negative number</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Handle any exceptions from user function gracefully</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return validated distance value</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> batch_calculate</span><span style=\"color:#E1E4E8\">(self, query_point: FeatureVector, training_matrix: FeatureMatrix) -> DistanceArray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Use vectorized function if available, otherwise loop through samples.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if user provided vectorized implementation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: If vectorized: call function with (query_point, training_matrix)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: If not vectorized: loop through rows of training_matrix</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Validate all distance results are non-negative</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return distance array</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> WeightedEuclideanMetric</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">CustomDistanceMetric</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Euclidean distance with learned feature weights.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Demonstrates parameter learning for improved similarity measurement.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, feature_weights: Optional[np.ndarray] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"weighted_euclidean\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.feature_weights </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> feature_weights</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.is_fitted </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> feature_weights </span><span style=\"color:#F97583\">is</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> calculate</span><span style=\"color:#E1E4E8\">(self, point1: FeatureVector, point2: FeatureVector) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Compute weighted Euclidean distance between feature vectors.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate that metric has been fitted (has feature weights)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Validate input vectors have same dimensionality as weights</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Compute element-wise squared differences: (point1 - point2)**2</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Apply feature weights: multiply differences by weights</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Sum weighted differences and return square root</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> fit</span><span style=\"color:#E1E4E8\">(self, X: FeatureMatrix, y: np.ndarray) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Learn feature weights that maximize class separation.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Uses simple variance-based weighting as baseline approach.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate that X and y have compatible dimensions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: For each feature, compute within-class variance for each class</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Compute between-class variance (variance of class means)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Set weight = between_class_var / (within_class_var + epsilon)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Normalize weights to prevent numerical issues</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Store weights in self.feature_weights and set is_fitted = True</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Higher weight for features that separate classes well</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> MetricRegistry</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Registry for discovering and managing available distance metrics.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Enables runtime metric selection and custom metric registration.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._metrics: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, CustomDistanceMetric] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._register_builtin_metrics()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> register_metric</span><span style=\"color:#E1E4E8\">(self, metric: CustomDistanceMetric) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Register a custom distance metric for use in KNN.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate that metric implements required interface</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check that metric name is unique</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify metric satisfies basic mathematical properties</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Store metric in registry with its name as key</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Log successful registration for debugging</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_metric</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> CustomDistanceMetric:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Retrieve registered metric by name.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if metric name exists in registry</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Return metric instance if found</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Raise informative error with available metrics if not found</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Consider returning copy vs reference based on usage pattern</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> list_metrics</span><span style=\"color:#E1E4E8\">(self) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Return names of all registered metrics.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> list</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._metrics.keys())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> create_function_metric</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, distance_function: Callable, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                             vectorized: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> False</span><span style=\"color:#E1E4E8\">) -> CustomDistanceMetric:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Factory method for creating function-based custom metrics.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            name: Unique name for the metric</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            distance_function: User-provided distance calculation function</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            vectorized: Whether function supports batch operations</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Configured custom metric instance</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate that name is unique in registry</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Create FunctionBasedMetric instance with provided function</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Test function with sample data to ensure it works</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Register the new metric in registry</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return configured metric instance</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _register_builtin_metrics</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Register standard custom metrics that extend beyond basic Euclidean/Manhattan.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create instances of built-in custom metrics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Register each metric using register_metric()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Include metrics like weighted Euclidean, Mahalanobis, etc.</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoint-performance-extensions\">Milestone Checkpoint: Performance Extensions</h4>\n<p>After implementing spatial indexing support, verify the performance improvements with this checkpoint:</p>\n<p><strong>Test Command:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/test_extensions/test_performance.py</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> examples/performance_benchmark.py</span></span></code></pre></div>\n\n<p><strong>Expected Behavior:</strong></p>\n<ul>\n<li>KD-tree shows 10-100x speedup for low-dimensional data (&lt; 10 features)</li>\n<li>Linear search and KD-tree produce identical results on test datasets</li>\n<li>Automatic index selection chooses appropriate implementation for different data characteristics</li>\n<li>Memory usage reports are reasonable (typically 2-3x training data size for KD-tree)</li>\n</ul>\n<p><strong>Performance Benchmark Results:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Dataset: 1000 samples, 5 features, K=10\nLinear Search:    45.2ms per query\nKD-Tree:          2.1ms per query  (21.5x speedup)\nBall Tree:        3.8ms per query  (11.9x speedup)\n\nDataset: 1000 samples, 50 features, K=10  \nLinear Search:    52.1ms per query\nKD-Tree:          48.9ms per query (1.1x speedup - high dimensional)\nBall Tree:        15.2ms per query (3.4x speedup)\nLSH (approximate): 4.1ms per query (12.7x speedup, 95% recall)</code></pre></div>\n\n<p><strong>Signs Something is Wrong:</strong></p>\n<ul>\n<li>KD-tree slower than linear search on low-dimensional data → Check tree construction or query logic</li>\n<li>Identical inputs producing different neighbor sets → Distance calculation inconsistency </li>\n<li>Memory usage &gt; 10x training data size → Memory leak in index construction</li>\n<li>Index selection always chooses linear search → Auto-selection logic not working</li>\n</ul>\n<h4 id=\"milestone-checkpoint-algorithm-extensions\">Milestone Checkpoint: Algorithm Extensions</h4>\n<p>After implementing regression and multi-output support:</p>\n<p><strong>Test Command:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> examples/regression_example.py</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> examples/multi_output_demo.py</span></span></code></pre></div>\n\n<p><strong>Expected Behavior:</strong></p>\n<ul>\n<li>KNN regression produces reasonable predictions on continuous targets</li>\n<li>Multi-output prediction handles vector targets correctly</li>\n<li>Ensemble methods improve accuracy over single models</li>\n<li>Confidence estimation correlates with prediction quality</li>\n</ul>\n<p><strong>Regression Performance Example:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Load Boston housing dataset</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sklearn.datasets </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> load_boston</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">X, y </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> load_boston(</span><span style=\"color:#FFAB70\">return_X_y</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Train KNN regressor</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> extensions.algorithms.regression </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> KNNRegressor</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">regressor </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> KNNRegressor(</span><span style=\"color:#FFAB70\">k</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">weighted</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">regressor.fit(X_train, y_train)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Evaluate performance</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">predictions </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> regressor.predict(X_test)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">rmse </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.sqrt(np.mean((predictions </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> y_test)</span><span style=\"color:#F97583\">**</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"RMSE: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">rmse</span><span style=\"color:#F97583\">:.2f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Should be &#x3C; 5.0 for reasonable performance</span></span></code></pre></div>\n\n<h4 id=\"language-specific-implementation-hints\">Language-Specific Implementation Hints</h4>\n<p><strong>NumPy Optimization Tips:</strong></p>\n<ul>\n<li>Use <code>np.linalg.norm(axis=1)</code> for vectorized Euclidean distance calculation</li>\n<li>Use <code>scipy.spatial.distance_matrix</code> for efficient pairwise distance computation</li>\n<li>Use <code>np.argpartition(distances, k)</code> instead of full sort when you only need top K</li>\n<li>Use <code>np.einsum</code> for complex vectorized operations in custom metrics</li>\n</ul>\n<p><strong>Memory Management for Streaming:</strong></p>\n<ul>\n<li>Use <code>collections.deque(maxlen=N)</code> for fixed-size sliding windows</li>\n<li>Use <code>weakref</code> for cache management that doesn&#39;t prevent garbage collection  </li>\n<li>Use <code>np.memmap</code> for datasets larger than available RAM</li>\n<li>Monitor memory usage with <code>psutil.Process().memory_info().rss</code></li>\n</ul>\n<p><strong>Custom Metric Performance:</strong></p>\n<ul>\n<li>Compile critical paths with <code>numba.jit</code> for 10-100x speedup</li>\n<li>Use <code>Cython</code> for maximum performance custom distance functions</li>\n<li>Pre-allocate arrays in loops to avoid repeated memory allocation</li>\n<li>Use in-place operations (<code>+=</code>, <code>*=</code>) to reduce temporary array creation</li>\n</ul>\n<p>This implementation guidance provides a complete foundation for extending the KNN system with advanced performance optimizations, algorithmic capabilities, and customization features while maintaining compatibility with the existing codebase.</p>\n<h2 id=\"glossary\">Glossary</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Comprehensive terminology reference for all milestones - foundational concepts and data structures for distance calculation (Milestone 1), classification algorithms and voting strategies for neighbor finding and prediction (Milestone 2), and evaluation metrics and optimization concepts for improvements and assessment (Milestone 3)</p>\n</blockquote>\n<h3 id=\"mental-model-the-learning-dictionary\">Mental Model: The Learning Dictionary</h3>\n<p>Think of this glossary as your personal learning dictionary - a comprehensive reference that transforms technical jargon into clear, actionable knowledge. Just as a foreign language dictionary doesn&#39;t just translate words but explains grammar, usage, and cultural context, this glossary provides not just definitions but the conceptual framework and practical implications of each term. Every concept builds upon others, creating a web of knowledge that supports your understanding throughout the implementation journey.</p>\n<h3 id=\"core-algorithmic-concepts\">Core Algorithmic Concepts</h3>\n<p>The foundational algorithmic concepts form the theoretical backbone of K-Nearest Neighbors classification. These concepts represent the mathematical and computational principles that drive the entire system.</p>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Mathematical Foundation</th>\n<th>Practical Implication</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Lazy Learning</strong></td>\n<td>Machine learning approach that defers all computation until prediction time, storing training examples without building an explicit model</td>\n<td>No training phase optimization; all work happens during queries</td>\n<td>Simple implementation but potentially slower predictions; perfect for dynamic datasets</td>\n</tr>\n<tr>\n<td><strong>Instance-Based Learning</strong></td>\n<td>Learning paradigm that makes decisions based on similarity to stored training instances rather than learned parameters</td>\n<td>Classification function f(x) = argmax_c Σ similarity(x, x_i) where y_i = c</td>\n<td>Memory-intensive but highly flexible; adapts naturally to local patterns in data</td>\n</tr>\n<tr>\n<td><strong>Smoothness Assumption</strong></td>\n<td>Fundamental assumption that similar inputs in feature space should produce similar outputs</td>\n<td>If d(x_i, x_j) is small, then P(y_i = y_j) should be high</td>\n<td>Justifies using nearest neighbors for prediction; breaks down in high dimensions or noisy data</td>\n</tr>\n<tr>\n<td><strong>Curse of Dimensionality</strong></td>\n<td>Phenomenon where distance metrics become less discriminative as feature dimensionality increases</td>\n<td>In high dimensions, max_distance/min_distance → 1 as d → ∞</td>\n<td>Requires feature selection, dimensionality reduction, or specialized distance metrics for high-dimensional data</td>\n</tr>\n<tr>\n<td><strong>Bias-Variance Tradeoff</strong></td>\n<td>Fundamental ML principle where small K creates high variance/low bias while large K creates low variance/high bias</td>\n<td>Small K: overfits to local noise; Large K: underfits to global trends</td>\n<td>Optimal K balances model complexity with generalization; requires cross-validation to find</td>\n</tr>\n</tbody></table>\n<h3 id=\"distance-metric-terminology\">Distance Metric Terminology</h3>\n<p>Distance metrics quantify similarity between data points and form the mathematical foundation of neighbor finding. Understanding these concepts is crucial for implementing robust distance calculations.</p>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Formula</th>\n<th>Use Case</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>L2 Norm</strong></td>\n<td>Euclidean distance calculation measuring straight-line distance in feature space</td>\n<td>√(Σ(x_i - y_i)²)</td>\n<td>Default choice for continuous features; sensitive to outliers but intuitive geometrically</td>\n</tr>\n<tr>\n<td><strong>L1 Norm</strong></td>\n<td>Manhattan distance calculation measuring sum of absolute coordinate differences</td>\n<td>Σ|x_i - y_i|</td>\n<td>Robust to outliers; works well for high-dimensional sparse data like text features</td>\n</tr>\n<tr>\n<td><strong>Cosine Distance</strong></td>\n<td>Angular distance measuring similarity in direction rather than magnitude</td>\n<td>1 - (x·y)/(</td>\n<td></td>\n</tr>\n<tr>\n<td><strong>Vectorized Operations</strong></td>\n<td>NumPy operations on entire arrays avoiding Python-level loops for performance</td>\n<td>Broadcasting rules apply element-wise operations across array dimensions</td>\n<td>Critical for performance; can achieve 10-100x speedup over Python loops</td>\n</tr>\n<tr>\n<td><strong>Broadcasting</strong></td>\n<td>NumPy mechanism for automatic array shape matching during element-wise operations</td>\n<td>Arrays with compatible shapes can operate element-wise without explicit reshaping</td>\n<td>Enables efficient distance calculations between single points and entire datasets</td>\n</tr>\n</tbody></table>\n<h3 id=\"classification-and-voting-concepts\">Classification and Voting Concepts</h3>\n<p>The voting mechanisms transform neighbor information into final predictions, representing the democratic decision-making process at the heart of KNN classification.</p>\n<p><img src=\"/api/project/knn/architecture-doc/asset?path=diagrams%2Fvoting-process.svg\" alt=\"Classification Voting Process\"></p>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Implementation Approach</th>\n<th>Advantages and Limitations</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Majority Voting</strong></td>\n<td>Classification strategy assigning the class that appears most frequently among K neighbors</td>\n<td>Count occurrences of each class; return class with maximum count</td>\n<td>Simple and interpretable but ignores distance information; vulnerable to ties</td>\n</tr>\n<tr>\n<td><strong>Weighted Voting</strong></td>\n<td>Voting strategy where closer neighbors have proportionally more influence on the final decision</td>\n<td>Weight each vote by 1/(distance + ε) where ε prevents division by zero</td>\n<td>More sophisticated than majority voting but requires careful epsilon tuning; sensitive to distance scale</td>\n</tr>\n<tr>\n<td><strong>Democratic Decision Making</strong></td>\n<td>Aggregation process combining multiple neighbor opinions through structured voting mechanisms</td>\n<td>Collect neighbor classes, apply voting weights, resolve ties systematically</td>\n<td>Mirrors human group decision processes; requires tie-breaking strategies</td>\n</tr>\n<tr>\n<td><strong>Tie-Breaking</strong></td>\n<td>Resolution mechanism for situations where multiple classes receive equal votes in majority voting</td>\n<td>Use nearest neighbor class, weighted voting, or random selection with fixed seed</td>\n<td>Critical for deterministic behavior; choice affects edge case performance</td>\n</tr>\n<tr>\n<td><strong>Confidence Scoring</strong></td>\n<td>Quantification of prediction certainty based on neighbor agreement and distance patterns</td>\n<td>Ratio of winning votes to total votes, or inverse of average neighbor distance</td>\n<td>Enables uncertainty quantification; useful for rejecting low-confidence predictions</td>\n</tr>\n</tbody></table>\n<h3 id=\"evaluation-and-optimization-terminology\">Evaluation and Optimization Terminology</h3>\n<p>These concepts enable rigorous assessment and optimization of KNN performance, ensuring reliable model evaluation and hyperparameter selection.</p>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Statistical Foundation</th>\n<th>Practical Application</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Cross-Validation</strong></td>\n<td>Statistical method for reliable performance estimation using multiple train/test splits</td>\n<td>Partitions data into K folds; trains on K-1, tests on 1; averages results</td>\n<td>Provides unbiased performance estimates; essential for small datasets</td>\n</tr>\n<tr>\n<td><strong>Stratified Sampling</strong></td>\n<td>Sampling approach that preserves class distribution proportions across data splits</td>\n<td>Each fold maintains same class ratio as original dataset</td>\n<td>Prevents evaluation bias from unbalanced splits; critical for imbalanced datasets</td>\n</tr>\n<tr>\n<td><strong>Hyperparameter Optimization</strong></td>\n<td>Systematic search process for optimal model configuration parameters like K value</td>\n<td>Grid search evaluates all combinations; random search samples parameter space</td>\n<td>Finds best K value through principled evaluation; prevents manual guessing</td>\n</tr>\n<tr>\n<td><strong>Grid Search</strong></td>\n<td>Exhaustive evaluation approach testing all combinations of specified hyperparameter values</td>\n<td>For K ∈ [1,3,5,7,9]: evaluate each K with cross-validation, select best</td>\n<td>Thorough but computationally expensive; guarantees finding global optimum in search space</td>\n</tr>\n<tr>\n<td><strong>Statistical Significance</strong></td>\n<td>Mathematical confidence that observed performance differences are not due to random chance</td>\n<td>Use paired t-tests or Wilcoxon tests to compare CV scores across parameter settings</td>\n<td>Distinguishes real improvements from noise; essential for reliable parameter selection</td>\n</tr>\n</tbody></table>\n<h3 id=\"data-structure-and-type-system\">Data Structure and Type System</h3>\n<p>The type system provides the structural foundation for all KNN operations, defining how data flows through the system and ensuring type safety throughout the pipeline.</p>\n<table>\n<thead>\n<tr>\n<th>Type Name</th>\n<th>Fields and Structure</th>\n<th>Primary Usage</th>\n<th>Type Constraints</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>FeatureVector</strong></td>\n<td>1D numpy array of float64 values</td>\n<td>Single data point representation</td>\n<td>Must be float64 for numerical stability; fixed length per dataset</td>\n</tr>\n<tr>\n<td><strong>FeatureMatrix</strong></td>\n<td>2D numpy array shape (n_samples, n_features)</td>\n<td>Batch data storage</td>\n<td>All rows must have identical feature count; no missing values allowed</td>\n</tr>\n<tr>\n<td><strong>ClassLabel</strong></td>\n<td>Union[int, str] for class identifiers</td>\n<td>Class identification</td>\n<td>Must be hashable for voting; consistent type within dataset</td>\n</tr>\n<tr>\n<td><strong>TrainingData</strong></td>\n<td>features: FeatureMatrix, labels: List[ClassLabel], n_samples: int, n_features: int</td>\n<td>Complete training dataset</td>\n<td>Labels length must match features rows; dimensions must be consistent</td>\n</tr>\n<tr>\n<td><strong>PredictionResult</strong></td>\n<td>predicted_class: ClassLabel, neighbor_indices: NeighborIndices, neighbor_distances: DistanceArray, confidence: float, voting_details: Dict</td>\n<td>Rich prediction information</td>\n<td>Indices must be valid for training data; distances must be non-negative</td>\n</tr>\n</tbody></table>\n<h3 id=\"algorithm-implementation-terminology\">Algorithm Implementation Terminology</h3>\n<p>These terms describe the concrete algorithmic approaches and implementation strategies used throughout the KNN system.</p>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Implementation Strategy</th>\n<th>Performance Characteristics</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Linear Search</strong></td>\n<td>Brute-force neighbor finding algorithm computing distances to all training points</td>\n<td>Calculate distances to every training sample; sort and select top K</td>\n<td>O(n) per query; simple implementation; works with any distance metric</td>\n</tr>\n<tr>\n<td><strong>Spatial Indexing</strong></td>\n<td>Data structures that organize feature space to accelerate neighbor finding operations</td>\n<td>KD-trees, Ball trees, or LSH partition space for faster searches</td>\n<td>O(log n) average case; complex implementation; metric-dependent performance</td>\n</tr>\n<tr>\n<td><strong>Locality-Sensitive Hashing</strong></td>\n<td>Approximation technique using similarity-preserving hash functions for fast neighbor finding</td>\n<td>Hash similar points to same buckets; search only within relevant buckets</td>\n<td>Sub-linear query time; approximate results; tunable accuracy/speed tradeoff</td>\n</tr>\n<tr>\n<td><strong>Numerical Stability</strong></td>\n<td>Robustness of calculations against floating-point precision errors and edge cases</td>\n<td>Use epsilon for comparisons; handle overflow/underflow; validate intermediate results</td>\n<td>Prevents subtle bugs; essential for reliable distance calculations</td>\n</tr>\n<tr>\n<td><strong>Graceful Degradation</strong></td>\n<td>System behavior that maintains partial functionality when full operation becomes impossible</td>\n<td>Return best-effort results with warnings; fallback to simpler algorithms</td>\n<td>Improves user experience; enables debugging of complex failure modes</td>\n</tr>\n</tbody></table>\n<h3 id=\"performance-and-quality-metrics\">Performance and Quality Metrics</h3>\n<p>These metrics quantify system performance and prediction quality, enabling objective assessment and optimization of KNN implementations.</p>\n<table>\n<thead>\n<tr>\n<th>Metric Name</th>\n<th>Mathematical Definition</th>\n<th>Interpretation Guidelines</th>\n<th>Typical Value Ranges</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Precision</strong></td>\n<td>True Positives / (True Positives + False Positives) per class</td>\n<td>Fraction of predicted positives that are actually positive</td>\n<td>0.0 to 1.0; higher is better</td>\n</tr>\n<tr>\n<td><strong>Recall</strong></td>\n<td>True Positives / (True Positives + False Negatives) per class</td>\n<td>Fraction of actual positives correctly identified</td>\n<td>0.0 to 1.0; higher is better</td>\n</tr>\n<tr>\n<td><strong>F1-Score</strong></td>\n<td>2 * (Precision * Recall) / (Precision + Recall) harmonic mean</td>\n<td>Balanced measure combining precision and recall</td>\n<td>0.0 to 1.0; higher is better</td>\n</tr>\n<tr>\n<td><strong>Macro Averaging</strong></td>\n<td>Compute metrics by averaging across classes with equal weight regardless of frequency</td>\n<td>Treats all classes equally; good for balanced evaluation</td>\n<td>Can be dominated by rare class performance</td>\n</tr>\n<tr>\n<td><strong>Weighted Averaging</strong></td>\n<td>Compute metrics by averaging across classes weighted by their support (frequency)</td>\n<td>Reflects overall performance weighted by class importance</td>\n<td>More representative for imbalanced datasets</td>\n</tr>\n</tbody></table>\n<h3 id=\"advanced-concepts-and-extensions\">Advanced Concepts and Extensions</h3>\n<p>These concepts represent sophisticated enhancements and theoretical foundations that extend beyond basic KNN implementation.</p>\n<table>\n<thead>\n<tr>\n<th>Concept</th>\n<th>Definition</th>\n<th>Theoretical Foundation</th>\n<th>Implementation Complexity</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Metric Learning</strong></td>\n<td>Optimization of distance functions based on training data to improve classification</td>\n<td>Learn distance function that minimizes classification error on training set</td>\n<td>High; requires additional optimization algorithms</td>\n</tr>\n<tr>\n<td><strong>Ensemble Methods</strong></td>\n<td>Combining multiple KNN models with different parameters for improved predictions</td>\n<td>Bagging: train on different data subsets; Boosting: weight misclassified examples</td>\n<td>Medium; requires model combination strategies</td>\n</tr>\n<tr>\n<td><strong>Online Learning</strong></td>\n<td>Adapting KNN models to new data without complete retraining of the entire system</td>\n<td>Incrementally add new training points; maintain efficiency with streaming updates</td>\n<td>High; requires efficient data structure updates</td>\n</tr>\n<tr>\n<td><strong>Concept Drift</strong></td>\n<td>Changes in underlying data distribution over time affecting model performance</td>\n<td>Statistical tests detect distribution changes; trigger model updates or retraining</td>\n<td>High; requires change detection and adaptation mechanisms</td>\n</tr>\n<tr>\n<td><strong>Streaming KNN</strong></td>\n<td>Handling continuous data streams with memory constraints and real-time requirements</td>\n<td>Sliding windows, reservoir sampling, or approximate data structures</td>\n<td>Very High; requires specialized algorithms and careful memory management</td>\n</tr>\n</tbody></table>\n<h3 id=\"error-handling-and-robustness\">Error Handling and Robustness</h3>\n<p>These concepts ensure reliable system operation under various failure modes and edge conditions.</p>\n<table>\n<thead>\n<tr>\n<th>Error Category</th>\n<th>Definition</th>\n<th>Detection Strategy</th>\n<th>Recovery Approach</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Input Validation</strong></td>\n<td>Verification that data meets system requirements before processing begins</td>\n<td>Check array shapes, data types, value ranges, and missing data</td>\n<td>Raise descriptive errors with specific requirements</td>\n</tr>\n<tr>\n<td><strong>Numerical Error Handling</strong></td>\n<td>Management of floating-point precision issues and mathematical edge cases</td>\n<td>Monitor for NaN/infinity values; check for division by zero</td>\n<td>Use epsilon comparisons; provide fallback calculations</td>\n</tr>\n<tr>\n<td><strong>Edge Case Handling</strong></td>\n<td>Management of boundary conditions like empty datasets or extreme parameter values</td>\n<td>Validate parameters against dataset constraints; check for degenerate cases</td>\n<td>Provide meaningful defaults or graceful failure modes</td>\n</tr>\n<tr>\n<td><strong>Information Leakage</strong></td>\n<td>Contamination where training information inappropriately influences validation results</td>\n<td>Ensure strict separation between training and validation data</td>\n<td>Use stratified splitting with proper randomization</td>\n</tr>\n<tr>\n<td><strong>Multiple Testing Correction</strong></td>\n<td>Statistical adjustment for increased false positive risk when testing many hypotheses</td>\n<td>Apply Bonferroni correction or False Discovery Rate control</td>\n<td>Adjust significance thresholds based on number of tests</td>\n</tr>\n</tbody></table>\n<h3 id=\"implementation-and-debugging-support\">Implementation and Debugging Support</h3>\n<p>These practical concepts support the development and troubleshooting process throughout KNN implementation.</p>\n<table>\n<thead>\n<tr>\n<th>Support Category</th>\n<th>Definition</th>\n<th>Application Context</th>\n<th>Expected Outcome</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Unit Testing Strategy</strong></td>\n<td>Testing individual components in isolation to verify correctness</td>\n<td>Test each distance function, voting mechanism, and evaluation metric separately</td>\n<td>High confidence in component correctness</td>\n</tr>\n<tr>\n<td><strong>Integration Testing Strategy</strong></td>\n<td>Testing component interactions and end-to-end workflows</td>\n<td>Verify complete prediction pipeline from input to output</td>\n<td>Confidence in system integration</td>\n</tr>\n<tr>\n<td><strong>Milestone Checkpoints</strong></td>\n<td>Verification steps after each implementation phase to ensure progress</td>\n<td>Test distance calculation, then neighbor finding, then classification</td>\n<td>Incremental validation of implementation progress</td>\n</tr>\n<tr>\n<td><strong>Performance Profiling</strong></td>\n<td>Systematic measurement of computational bottlenecks and resource usage</td>\n<td>Identify slowest components and memory-intensive operations</td>\n<td>Targeted optimization opportunities</td>\n</tr>\n<tr>\n<td><strong>Symptom-Based Debugging</strong></td>\n<td>Diagnostic approach mapping observed problems to likely root causes</td>\n<td>Match error symptoms to known failure patterns</td>\n<td>Faster problem resolution</td>\n</tr>\n</tbody></table>\n<h3 id=\"mathematical-and-statistical-foundations\">Mathematical and Statistical Foundations</h3>\n<p>These mathematical concepts underpin the theoretical validity of KNN algorithms and their statistical properties.</p>\n<table>\n<thead>\n<tr>\n<th>Mathematical Concept</th>\n<th>Definition</th>\n<th>Theoretical Importance</th>\n<th>Practical Implications</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Metric Properties</strong></td>\n<td>Mathematical requirements for valid distance functions: non-negativity, symmetry, triangle inequality</td>\n<td>Ensures distance function behaves predictably and supports geometric reasoning</td>\n<td>Invalid metrics can produce counterintuitive neighbor relationships</td>\n</tr>\n<tr>\n<td><strong>Convergence Properties</strong></td>\n<td>Behavior of KNN as dataset size approaches infinity</td>\n<td>Under certain conditions, KNN error approaches Bayes optimal error</td>\n<td>Provides theoretical justification for KNN effectiveness</td>\n</tr>\n<tr>\n<td><strong>Consistency</strong></td>\n<td>Property that algorithm performance improves with more training data</td>\n<td>KNN is statistically consistent under mild regularity conditions</td>\n<td>Guarantees that more data leads to better performance</td>\n</tr>\n<tr>\n<td><strong>Curse of Dimensionality</strong></td>\n<td>Phenomenon where distance-based methods degrade in high-dimensional spaces</td>\n<td>All points become approximately equidistant as dimensionality increases</td>\n<td>Requires dimensionality reduction or specialized techniques</td>\n</tr>\n<tr>\n<td><strong>Concentration of Measure</strong></td>\n<td>Statistical phenomenon where random variables concentrate around their mean in high dimensions</td>\n<td>High-dimensional distance distributions have low variance</td>\n<td>Distance becomes less discriminative; affects neighbor selection quality</td>\n</tr>\n</tbody></table>\n<h3 id=\"system-architecture-and-design-patterns\">System Architecture and Design Patterns</h3>\n<p>These architectural concepts organize the KNN system into maintainable, testable, and extensible components.</p>\n<table>\n<thead>\n<tr>\n<th>Design Pattern</th>\n<th>Definition</th>\n<th>Application in KNN</th>\n<th>Benefits and Trade-offs</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Strategy Pattern</strong></td>\n<td>Design pattern allowing algorithm selection at runtime</td>\n<td>Different distance metrics and voting strategies</td>\n<td>Flexibility at cost of complexity</td>\n</tr>\n<tr>\n<td><strong>Factory Pattern</strong></td>\n<td>Creational pattern for object creation without specifying exact classes</td>\n<td>Create distance calculators and spatial indices</td>\n<td>Extensibility with consistent interfaces</td>\n</tr>\n<tr>\n<td><strong>Observer Pattern</strong></td>\n<td>Behavioral pattern for event notification between components</td>\n<td>Progress updates during cross-validation</td>\n<td>Loose coupling but potential performance overhead</td>\n</tr>\n<tr>\n<td><strong>Template Method</strong></td>\n<td>Behavioral pattern defining algorithm skeleton with customizable steps</td>\n<td>Cross-validation framework with pluggable evaluation metrics</td>\n<td>Code reuse but inheritance complexity</td>\n</tr>\n<tr>\n<td><strong>Dependency Injection</strong></td>\n<td>Design principle providing dependencies from external sources</td>\n<td>Inject distance metrics and evaluation strategies</td>\n<td>Testability and flexibility</td>\n</tr>\n</tbody></table>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>This implementation guidance bridges the gap between theoretical understanding and practical coding, providing concrete tools and structures for building a robust KNN system.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Distance Calculation</strong></td>\n<td>Pure NumPy with manual loops</td>\n<td>Scipy spatial.distance with optimized C implementations</td>\n</tr>\n<tr>\n<td><strong>Neighbor Search</strong></td>\n<td>Linear search with numpy.argsort</td>\n<td>Scikit-learn NearestNeighbors with KDTree/BallTree</td>\n</tr>\n<tr>\n<td><strong>Spatial Indexing</strong></td>\n<td>Manual KDTree implementation</td>\n<td>FAISS library for approximate nearest neighbors</td>\n</tr>\n<tr>\n<td><strong>Evaluation Framework</strong></td>\n<td>Manual cross-validation loops</td>\n<td>Scikit-learn model_selection with stratified K-fold</td>\n</tr>\n<tr>\n<td><strong>Performance Profiling</strong></td>\n<td>Python time module</td>\n<td>CProfile and line_profiler for detailed analysis</td>\n</tr>\n<tr>\n<td><strong>Visualization</strong></td>\n<td>Matplotlib scatter plots</td>\n<td>Seaborn with statistical plotting and Plotly for interactive exploration</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<p>The modular organization supports incremental development and testing while maintaining clear separation of concerns throughout the KNN implementation.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>knn-classifier/\n├── src/\n│   ├── __init__.py\n│   ├── core/\n│   │   ├── __init__.py\n│   │   ├── data_types.py          # FeatureVector, TrainingData, PredictionResult\n│   │   └── exceptions.py          # Custom exception classes\n│   ├── distance/\n│   │   ├── __init__.py\n│   │   ├── base.py                # Abstract distance metric interface\n│   │   ├── euclidean.py           # L2 norm implementation\n│   │   ├── manhattan.py           # L1 norm implementation\n│   │   └── cosine.py              # Cosine similarity implementation\n│   ├── neighbors/\n│   │   ├── __init__.py\n│   │   ├── finder.py              # Core neighbor finding logic\n│   │   ├── linear_search.py       # Brute force implementation\n│   │   └── spatial_index.py       # Advanced indexing structures\n│   ├── classification/\n│   │   ├── __init__.py\n│   │   ├── classifier.py          # Main KNNClassifier class\n│   │   ├── voting.py              # Majority and weighted voting\n│   │   └── confidence.py          # Confidence scoring\n│   ├── evaluation/\n│   │   ├── __init__.py\n│   │   ├── cross_validation.py    # K-fold cross-validation\n│   │   ├── metrics.py             # Precision, recall, F1-score\n│   │   ├── optimization.py        # Hyperparameter tuning\n│   │   └── visualization.py       # Result plotting and analysis\n│   └── utils/\n│       ├── __init__.py\n│       ├── validation.py          # Input validation utilities\n│       ├── numerical.py           # Numerical stability helpers\n│       └── datasets.py            # Dataset loading utilities\n├── tests/\n│   ├── __init__.py\n│   ├── unit/\n│   │   ├── test_distance.py       # Distance calculation tests\n│   │   ├── test_neighbors.py      # Neighbor finding tests\n│   │   ├── test_classification.py # Voting and prediction tests\n│   │   └── test_evaluation.py     # Metrics and validation tests\n│   ├── integration/\n│   │   ├── test_pipeline.py       # End-to-end workflow tests\n│   │   └── test_performance.py    # Performance benchmarking\n│   └── fixtures/\n│       ├── sample_data.py         # Test datasets\n│       └── expected_results.py    # Expected test outcomes\n├── examples/\n│   ├── basic_usage.py             # Simple classification example\n│   ├── iris_classification.py     # Classic dataset demonstration\n│   └── parameter_tuning.py        # Hyperparameter optimization example\n├── requirements.txt               # Python dependencies\n├── setup.py                       # Package configuration\n└── README.md                      # Usage documentation</code></pre></div>\n\n<h4 id=\"core-data-types-implementation\">Core Data Types Implementation</h4>\n<p>This provides the foundational type system that ensures type safety and clear data flow throughout the KNN pipeline.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># src/core/data_types.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Union, List, Dict, Tuple, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Core data types for KNN system</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">FeatureVector </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.ndarray  </span><span style=\"color:#6A737D\"># 1D array of float64 features</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">FeatureMatrix </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.ndarray  </span><span style=\"color:#6A737D\"># 2D array shape (n_samples, n_features)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">ClassLabel </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Union[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]  </span><span style=\"color:#6A737D\"># Class identifiers</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">DistanceArray </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.ndarray  </span><span style=\"color:#6A737D\"># 1D array of float64 distances</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">NeighborIndices </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.ndarray  </span><span style=\"color:#6A737D\"># 1D array of int32 indices</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DistanceMetric</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Enumeration of supported distance metrics.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    EUCLIDEAN</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"euclidean\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    MANHATTAN</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"manhattan\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    COSINE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"cosine\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> VotingStrategy</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Enumeration of voting strategies for classification.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    MAJORITY</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"majority\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    WEIGHTED</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"weighted\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TrainingData</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Container for complete training dataset with metadata.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, features: FeatureMatrix, labels: List[ClassLabel]):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.features </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> features</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.labels </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> labels</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.n_samples </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> features.shape[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.n_features </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> features.shape[</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_sample</span><span style=\"color:#E1E4E8\">(self, index: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Tuple[FeatureVector, ClassLabel]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Retrieve single training example by index.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate index bounds</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return tuple of (feature_vector, class_label)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> PredictionResult</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Rich prediction result with neighbor information and confidence.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, predicted_class: ClassLabel, neighbor_indices: NeighborIndices,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 neighbor_distances: DistanceArray, confidence: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 voting_details: Dict):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.predicted_class </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> predicted_class</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.neighbor_indices </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> neighbor_indices</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.neighbor_distances </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> neighbor_distances</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.confidence </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> confidence</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.voting_details </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> voting_details</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Type aliases for evaluation results</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">CrossValidationResult </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Dict  </span><span style=\"color:#6A737D\"># Contains mean/std metrics and fold results</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">GridSearchResult </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Dict  </span><span style=\"color:#6A737D\"># Contains optimal_k, optimal_metrics, complete_results</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">ConfusionMatrix </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Dict  </span><span style=\"color:#6A737D\"># Contains matrix and labels</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">ClassificationMetrics </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Dict  </span><span style=\"color:#6A737D\"># Contains precision, recall, F1-score per class</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">FoldIndices </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Tuple[np.ndarray, np.ndarray]  </span><span style=\"color:#6A737D\"># train_indices, val_indices</span></span></code></pre></div>\n\n<h4 id=\"distance-calculation-infrastructure\">Distance Calculation Infrastructure</h4>\n<p>This infrastructure provides the mathematical foundation for all similarity computations in the KNN system.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># src/distance/base.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> abc </span><span style=\"color:#F97583\">import</span><span style=\"color:#79B8FF\"> ABC</span><span style=\"color:#E1E4E8\">, abstractmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..core.data_types </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> FeatureVector, FeatureMatrix, DistanceArray</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DistanceCalculator</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">ABC</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Abstract base class for distance metric implementations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @abstractmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> calculate</span><span style=\"color:#E1E4E8\">(self, point1: FeatureVector, point2: FeatureVector) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Compute distance between two feature vectors.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @abstractmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> batch_calculate</span><span style=\"color:#E1E4E8\">(self, query_point: FeatureVector, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                       training_matrix: FeatureMatrix) -> DistanceArray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Vectorized distance computation from query to all training samples.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_compatible_vectors</span><span style=\"color:#E1E4E8\">(self, v1: FeatureVector, v2: FeatureVector) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Ensure vectors have matching dimensions.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check that both vectors are 1D arrays</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check that both vectors have same length</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Raise ValueError with descriptive message if incompatible</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># src/distance/euclidean.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .base </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> DistanceCalculator</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> EuclideanDistance</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">DistanceCalculator</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"L2 norm distance calculation with numerical stability.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> calculate</span><span style=\"color:#E1E4E8\">(self, point1: FeatureVector, point2: FeatureVector) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Compute Euclidean distance between two points.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate input vectors for compatibility</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate squared differences: (point1 - point2) ** 2</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Sum squared differences</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return square root using safe_sqrt helper</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> batch_calculate</span><span style=\"color:#E1E4E8\">(self, query_point: FeatureVector, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                       training_matrix: FeatureMatrix) -> DistanceArray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Vectorized Euclidean distances using broadcasting.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate query_point shape against training_matrix columns</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Use broadcasting to compute (query_point - training_matrix) ** 2</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Sum along feature axis (axis=1) to get squared distances</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Apply safe square root to get final distances</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return DistanceArray</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> safe_sqrt</span><span style=\"color:#E1E4E8\">(values: np.ndarray) -> np.ndarray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Safely compute square root handling negatives.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Clip negative values to zero with warning</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return np.sqrt of clipped values</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span></code></pre></div>\n\n<h4 id=\"neighbor-finding-core-logic\">Neighbor Finding Core Logic</h4>\n<p>This component implements the core logic for efficiently identifying the K most similar training examples.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># src/neighbors/finder.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Tuple, List</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..core.data_types </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (FeatureVector, FeatureMatrix, NeighborIndices, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                               DistanceArray, TrainingData, DistanceMetric)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..distance.base </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> DistanceCalculator</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> NeighborFinder</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Core neighbor finding logic with multiple search strategies.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, training_data: TrainingData, distance_calculator: DistanceCalculator):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.training_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> training_data</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.distance_calculator </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> distance_calculator</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> find_k_neighbors</span><span style=\"color:#E1E4E8\">(self, query_point: FeatureVector, k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        distance_metric: DistanceMetric) -> Tuple[NeighborIndices, DistanceArray]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Find K nearest neighbors to query point.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate k parameter against dataset size</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate distances to all training points using batch_calculate</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Get indices that would sort distances (np.argsort)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Select top K indices and corresponding distances</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Handle ties in distances using handle_distance_ties</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return (neighbor_indices, neighbor_distances)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_k_parameter</span><span style=\"color:#E1E4E8\">(self, k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, dataset_size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate K value against dataset constraints.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check k > 0</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check k &#x3C;= dataset_size</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Raise ValueError with descriptive message if invalid</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> handle_distance_ties</span><span style=\"color:#E1E4E8\">(self, distances: DistanceArray, indices: NeighborIndices, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                           k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Tuple[NeighborIndices, DistanceArray]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Resolve ties when multiple neighbors have identical distances.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Identify positions where distances are equal</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: For tied distances at boundary, use deterministic tie-breaking</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return consistent results across multiple calls</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"classification-and-voting-system\">Classification and Voting System</h4>\n<p>This system implements the democratic decision-making process that converts neighbor information into final predictions.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># src/classification/voting.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Tuple, Dict, List</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> collections </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Counter</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..core.data_types </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> ClassLabel, NeighborIndices, DistanceArray</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> VotingSystem</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Implements majority and weighted voting strategies.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, weighted: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> False</span><span style=\"color:#E1E4E8\">, epsilon: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1e-10</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.weighted </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> weighted</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.epsilon </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> epsilon</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> majority_vote</span><span style=\"color:#E1E4E8\">(self, neighbor_labels: List[ClassLabel], k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Tuple[ClassLabel, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Simple majority voting implementation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Count occurrences of each class using Counter</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Find class with maximum count</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate confidence as max_count / k</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Handle ties using resolve_ties method</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return (predicted_class, confidence)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> weighted_vote</span><span style=\"color:#E1E4E8\">(self, neighbor_labels: List[ClassLabel], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                     neighbor_distances: DistanceArray, k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                     epsilon: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">) -> Tuple[ClassLabel, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Distance-weighted voting implementation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate weights as 1 / (distance + epsilon)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Sum weights for each class</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Find class with maximum weighted vote</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate confidence as max_weight / total_weight</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return (predicted_class, confidence)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> resolve_ties</span><span style=\"color:#E1E4E8\">(self, tied_classes: List[ClassLabel], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    neighbor_labels: List[ClassLabel],</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    neighbor_distances: DistanceArray) -> ClassLabel:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Tie-breaking using nearest neighbor.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Find index of nearest neighbor (minimum distance)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return class of nearest neighbor</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: If still tied, use lexicographic ordering for determinism</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"evaluation-and-metrics-framework\">Evaluation and Metrics Framework</h4>\n<p>This framework provides rigorous statistical evaluation capabilities for assessing and optimizing KNN performance.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># src/evaluation/cross_validation.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Dict</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sklearn.model_selection </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> StratifiedKFold</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..core.data_types </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (FeatureMatrix, ClassLabel, CrossValidationResult, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                               FoldIndices, DistanceMetric)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> CrossValidator</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"K-fold cross-validation with stratified sampling.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, n_folds: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 5</span><span style=\"color:#E1E4E8\">, random_seed: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 42</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.n_folds </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> n_folds</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.random_seed </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> random_seed</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> k_fold_cross_validate</span><span style=\"color:#E1E4E8\">(self, X: FeatureMatrix, y: List[ClassLabel],</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                            k_neighbors: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, distance_metric: DistanceMetric,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                            random_seed: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> CrossValidationResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Perform K-fold cross-validation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Create stratified folds using split_stratified_folds</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: For each fold, train KNN on train set, evaluate on validation set</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Collect accuracy, precision, recall, F1 scores for each fold</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate mean and standard deviation across folds</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return CrossValidationResult with fold_results and aggregate_metrics</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> split_stratified_folds</span><span style=\"color:#E1E4E8\">(self, X: FeatureMatrix, y: List[ClassLabel],</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                             n_folds: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, random_seed: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> List[FoldIndices]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Create stratified train/validation splits.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Use StratifiedKFold to create balanced splits</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Ensure each fold maintains class distribution</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return list of (train_indices, val_indices) tuples</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># src/evaluation/optimization.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> GridSearchOptimizer</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Hyperparameter optimization using exhaustive grid search.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> grid_search_k</span><span style=\"color:#E1E4E8\">(self, X: FeatureMatrix, y: List[ClassLabel],</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                     k_values: List[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">], cv_folds: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                     distance_metric: DistanceMetric, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                     random_seed: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> GridSearchResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Find optimal K through exhaustive search.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: For each K value, perform cross-validation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Track performance metrics for each K</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Select K with highest mean cross-validation accuracy</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return GridSearchResult with optimal_k and detailed results</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p>After implementing each major component, verify correct behavior using these concrete checkpoints:</p>\n<p><strong>Milestone 1: Distance Calculation Checkpoint</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Run distance calculation tests</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/unit/test_distance.py</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected: All tests pass, showing correct Euclidean, Manhattan, and cosine calculations</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Manual verification: Load iris dataset, compute distances between first two samples</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Should get consistent, positive distance values</span></span></code></pre></div>\n\n<p><strong>Milestone 2: Classification Checkpoint</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Run classification pipeline tests</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/integration/test_pipeline.py</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected: End-to-end prediction working with reasonable accuracy</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Manual verification: Train on iris dataset, predict test samples</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Should achieve >90% accuracy with K=3</span></span></code></pre></div>\n\n<p><strong>Milestone 3: Evaluation Checkpoint</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Run hyperparameter optimization</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> examples/parameter_tuning.py</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected: Cross-validation results showing optimal K selection</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Should demonstrate performance variation across different K values</span></span></code></pre></div>\n\n<h4 id=\"debugging-tips\">Debugging Tips</h4>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>Diagnostic Approach</th>\n<th>Resolution</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>All distances are NaN</strong></td>\n<td>Numerical overflow in distance calculation</td>\n<td>Check input data ranges and data types</td>\n<td>Use float64, add epsilon to prevent division by zero</td>\n</tr>\n<tr>\n<td><strong>Predictions always same class</strong></td>\n<td>Majority class dominates in small K</td>\n<td>Examine class distribution and K value</td>\n<td>Increase K or use stratified sampling</td>\n</tr>\n<tr>\n<td><strong>Cross-validation scores inconsistent</strong></td>\n<td>Random seed not set properly</td>\n<td>Check randomization in fold splitting</td>\n<td>Set fixed random seeds throughout pipeline</td>\n</tr>\n<tr>\n<td><strong>Performance extremely slow</strong></td>\n<td>Using Python loops instead of vectorization</td>\n<td>Profile code to find bottlenecks</td>\n<td>Replace loops with NumPy broadcasting operations</td>\n</tr>\n<tr>\n<td><strong>Memory errors with large datasets</strong></td>\n<td>Loading entire distance matrix</td>\n<td>Monitor memory usage during computation</td>\n<td>Use batch processing or streaming algorithms</td>\n</tr>\n</tbody></table>\n<p>This glossary provides the comprehensive terminological foundation needed to understand, implement, and debug a robust KNN classification system. Each term builds upon others to create a cohesive knowledge framework that supports successful implementation across all three milestones.</p>\n","toc":[{"level":1,"text":"K-Nearest Neighbors Classifier: Design Document","id":"k-nearest-neighbors-classifier-design-document"},{"level":2,"text":"Overview","id":"overview"},{"level":2,"text":"Context and Problem Statement","id":"context-and-problem-statement"},{"level":3,"text":"Mental Model: The Neighborhood Recommendation System","id":"mental-model-the-neighborhood-recommendation-system"},{"level":3,"text":"Problem Definition","id":"problem-definition"},{"level":3,"text":"Comparison with Other Classification Methods","id":"comparison-with-other-classification-methods"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended Module Structure","id":"recommended-module-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeleton Code","id":"core-logic-skeleton-code"},{"level":4,"text":"Language-Specific Hints","id":"language-specific-hints"},{"level":4,"text":"Milestone Checkpoint","id":"milestone-checkpoint"},{"level":2,"text":"Goals and Non-Goals","id":"goals-and-non-goals"},{"level":3,"text":"Mental Model: The Recipe Book Approach","id":"mental-model-the-recipe-book-approach"},{"level":3,"text":"Functional Goals: Core Classification Capabilities and Performance Requirements","id":"functional-goals-core-classification-capabilities-and-performance-requirements"},{"level":3,"text":"Non-Functional Goals: Quality Attributes","id":"non-functional-goals-quality-attributes"},{"level":3,"text":"Explicit Non-Goals: Features Excluded from This Implementation","id":"explicit-non-goals-features-excluded-from-this-implementation"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"High-Level Architecture","id":"high-level-architecture"},{"level":3,"text":"Mental Model: The Recommendation System Architecture","id":"mental-model-the-recommendation-system-architecture"},{"level":3,"text":"Component Overview","id":"component-overview"},{"level":4,"text":"Distance Calculator Component","id":"distance-calculator-component"},{"level":4,"text":"Neighbor Finder Component","id":"neighbor-finder-component"},{"level":4,"text":"Classifier Component","id":"classifier-component"},{"level":4,"text":"Evaluator Component","id":"evaluator-component"},{"level":3,"text":"Recommended Module Structure","id":"recommended-module-structure"},{"level":3,"text":"Data Flow Architecture","id":"data-flow-architecture"},{"level":4,"text":"Training Phase Data Flow","id":"training-phase-data-flow"},{"level":4,"text":"Prediction Phase Data Flow","id":"prediction-phase-data-flow"},{"level":4,"text":"Cross-Validation Data Flow","id":"cross-validation-data-flow"},{"level":4,"text":"Hyperparameter Optimization Data Flow","id":"hyperparameter-optimization-data-flow"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Core Data Types (Complete Implementation)","id":"core-data-types-complete-implementation"},{"level":4,"text":"KNNClassifier Skeleton (Core Learning Component)","id":"knnclassifier-skeleton-core-learning-component"},{"level":4,"text":"Distance Calculation Infrastructure (Complete Implementation)","id":"distance-calculation-infrastructure-complete-implementation"},{"level":4,"text":"Dataset Utilities (Complete Implementation)","id":"dataset-utilities-complete-implementation"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":4,"text":"Language-Specific Implementation Hints","id":"language-specific-implementation-hints"},{"level":2,"text":"Data Model","id":"data-model"},{"level":3,"text":"Mental Model: The Filing Cabinet System","id":"mental-model-the-filing-cabinet-system"},{"level":3,"text":"Core Data Types","id":"core-data-types"},{"level":3,"text":"Internal Data Structures","id":"internal-data-structures"},{"level":3,"text":"Type Relationships and Data Flow","id":"type-relationships-and-data-flow"},{"level":3,"text":"Data Validation and Consistency","id":"data-validation-and-consistency"},{"level":3,"text":"Common Data Model Pitfalls","id":"common-data-model-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Core Data Types Implementation","id":"core-data-types-implementation"},{"level":4,"text":"Dataset Loading Utilities","id":"dataset-loading-utilities"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":4,"text":"Debugging Tips","id":"debugging-tips"},{"level":2,"text":"Distance Metrics Component","id":"distance-metrics-component"},{"level":3,"text":"Mental Model: Measuring Similarity","id":"mental-model-measuring-similarity"},{"level":3,"text":"Distance Calculator Interface","id":"distance-calculator-interface"},{"level":3,"text":"Distance Algorithms","id":"distance-algorithms"},{"level":4,"text":"Euclidean Distance Algorithm","id":"euclidean-distance-algorithm"},{"level":4,"text":"Manhattan Distance Algorithm","id":"manhattan-distance-algorithm"},{"level":4,"text":"Cosine Similarity Algorithm","id":"cosine-similarity-algorithm"},{"level":3,"text":"Architecture Decisions for Distance Calculation","id":"architecture-decisions-for-distance-calculation"},{"level":3,"text":"Common Distance Calculation Pitfalls","id":"common-distance-calculation-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeleton Code","id":"core-logic-skeleton-code"},{"level":4,"text":"Language-Specific Hints","id":"language-specific-hints"},{"level":4,"text":"Milestone Checkpoint","id":"milestone-checkpoint"},{"level":2,"text":"Neighbor Finding Component","id":"neighbor-finding-component"},{"level":3,"text":"Mental Model: The Search Process","id":"mental-model-the-search-process"},{"level":3,"text":"Neighbor Finder Interface","id":"neighbor-finder-interface"},{"level":3,"text":"Neighbor Search Algorithms","id":"neighbor-search-algorithms"},{"level":4,"text":"Linear Search Algorithm","id":"linear-search-algorithm"},{"level":4,"text":"Optimized Search Strategies","id":"optimized-search-strategies"},{"level":3,"text":"Architecture Decisions for Neighbor Finding","id":"architecture-decisions-for-neighbor-finding"},{"level":3,"text":"Common Neighbor Finding Pitfalls","id":"common-neighbor-finding-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeleton Code","id":"core-logic-skeleton-code"},{"level":4,"text":"Language-Specific Hints","id":"language-specific-hints"},{"level":4,"text":"Milestone Checkpoint","id":"milestone-checkpoint"},{"level":2,"text":"Classification Component","id":"classification-component"},{"level":3,"text":"Mental Model: Democratic Decision Making","id":"mental-model-democratic-decision-making"},{"level":3,"text":"Classifier Interface","id":"classifier-interface"},{"level":3,"text":"Voting Algorithms","id":"voting-algorithms"},{"level":4,"text":"Simple Majority Voting","id":"simple-majority-voting"},{"level":4,"text":"Distance-Weighted Voting","id":"distance-weighted-voting"},{"level":4,"text":"Confidence Scoring","id":"confidence-scoring"},{"level":3,"text":"Architecture Decisions for Classification","id":"architecture-decisions-for-classification"},{"level":3,"text":"Common Classification Pitfalls","id":"common-classification-pitfalls"},{"level":4,"text":"⚠️ Pitfall: Voting Ties with Even K Values","id":"-pitfall-voting-ties-with-even-k-values"},{"level":4,"text":"⚠️ Pitfall: Class Imbalance Bias in Voting","id":"-pitfall-class-imbalance-bias-in-voting"},{"level":4,"text":"⚠️ Pitfall: Inappropriate K Parameter Selection","id":"-pitfall-inappropriate-k-parameter-selection"},{"level":4,"text":"⚠️ Pitfall: Distance Metric Mismatch with Voting Strategy","id":"-pitfall-distance-metric-mismatch-with-voting-strategy"},{"level":4,"text":"⚠️ Pitfall: Numerical Instability in Weighted Voting","id":"-pitfall-numerical-instability-in-weighted-voting"},{"level":4,"text":"⚠️ Pitfall: Ignoring Feature Scale Differences","id":"-pitfall-ignoring-feature-scale-differences"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeleton Code","id":"core-logic-skeleton-code"},{"level":4,"text":"Language-Specific Hints","id":"language-specific-hints"},{"level":4,"text":"Milestone Checkpoint","id":"milestone-checkpoint"},{"level":2,"text":"Evaluation and Optimization Component","id":"evaluation-and-optimization-component"},{"level":3,"text":"Mental Model: Scientific Testing","id":"mental-model-scientific-testing"},{"level":3,"text":"Evaluation Interface","id":"evaluation-interface"},{"level":3,"text":"Evaluation Algorithms","id":"evaluation-algorithms"},{"level":4,"text":"K-Fold Cross-Validation Algorithm","id":"k-fold-cross-validation-algorithm"},{"level":4,"text":"Grid Search Optimization Algorithm","id":"grid-search-optimization-algorithm"},{"level":4,"text":"Confusion Matrix Algorithm","id":"confusion-matrix-algorithm"},{"level":3,"text":"Architecture Decisions for Evaluation","id":"architecture-decisions-for-evaluation"},{"level":3,"text":"Common Evaluation Pitfalls","id":"common-evaluation-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeletons","id":"core-logic-skeletons"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":2,"text":"Component Interactions and Data Flow","id":"component-interactions-and-data-flow"},{"level":3,"text":"Training Data Flow","id":"training-data-flow"},{"level":3,"text":"Prediction Data Flow","id":"prediction-data-flow"},{"level":3,"text":"Optimization Data Flow","id":"optimization-data-flow"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended Module Structure","id":"recommended-module-structure"},{"level":4,"text":"Training Data Flow Infrastructure","id":"training-data-flow-infrastructure"},{"level":4,"text":"Prediction Data Flow Coordination","id":"prediction-data-flow-coordination"},{"level":4,"text":"Cross-Validation Coordination Infrastructure","id":"cross-validation-coordination-infrastructure"},{"level":4,"text":"Optimization Results Management","id":"optimization-results-management"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":4,"text":"Debugging Component Interactions","id":"debugging-component-interactions"},{"level":2,"text":"Error Handling and Edge Cases","id":"error-handling-and-edge-cases"},{"level":3,"text":"Input Validation","id":"input-validation"},{"level":3,"text":"Numerical Error Handling","id":"numerical-error-handling"},{"level":3,"text":"Edge Case Handling","id":"edge-case-handling"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Testing Strategy","id":"testing-strategy"},{"level":3,"text":"Mental Model: The Scientific Method for Code","id":"mental-model-the-scientific-method-for-code"},{"level":3,"text":"Unit Testing Strategy","id":"unit-testing-strategy"},{"level":4,"text":"Distance Metrics Testing","id":"distance-metrics-testing"},{"level":4,"text":"Neighbor Finding Testing","id":"neighbor-finding-testing"},{"level":4,"text":"Classification Voting Testing","id":"classification-voting-testing"},{"level":4,"text":"Evaluation and Optimization Testing","id":"evaluation-and-optimization-testing"},{"level":3,"text":"Integration Testing Strategy","id":"integration-testing-strategy"},{"level":4,"text":"Training and Prediction Workflow Integration","id":"training-and-prediction-workflow-integration"},{"level":4,"text":"Cross-Validation and Optimization Integration","id":"cross-validation-and-optimization-integration"},{"level":4,"text":"Error Propagation and Recovery Integration","id":"error-propagation-and-recovery-integration"},{"level":3,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":4,"text":"Milestone 1 Checkpoint: Distance Calculation","id":"milestone-1-checkpoint-distance-calculation"},{"level":4,"text":"Milestone 2 Checkpoint: K-Nearest Neighbors Classification","id":"milestone-2-checkpoint-k-nearest-neighbors-classification"},{"level":4,"text":"Milestone 3 Checkpoint: Improvements &amp; Evaluation","id":"milestone-3-checkpoint-improvements-amp-evaluation"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Testing Infrastructure Starter Code","id":"testing-infrastructure-starter-code"},{"level":4,"text":"Milestone Checkpoint Scripts","id":"milestone-checkpoint-scripts"},{"level":4,"text":"Debugging Support Tools","id":"debugging-support-tools"},{"level":2,"text":"Debugging Guide","id":"debugging-guide"},{"level":3,"text":"Mental Model: The Detective Process","id":"mental-model-the-detective-process"},{"level":3,"text":"Distance Calculation Debugging","id":"distance-calculation-debugging"},{"level":4,"text":"Common Distance Calculation Issues","id":"common-distance-calculation-issues"},{"level":4,"text":"Distance Metric Specific Debugging","id":"distance-metric-specific-debugging"},{"level":4,"text":"Performance Debugging for Distance Calculation","id":"performance-debugging-for-distance-calculation"},{"level":3,"text":"Classification Debugging","id":"classification-debugging"},{"level":4,"text":"Voting Algorithm Issues","id":"voting-algorithm-issues"},{"level":4,"text":"Class Imbalance and Bias Issues","id":"class-imbalance-and-bias-issues"},{"level":4,"text":"Hyperparameter Sensitivity Analysis","id":"hyperparameter-sensitivity-analysis"},{"level":4,"text":"Confidence Scoring Validation","id":"confidence-scoring-validation"},{"level":3,"text":"Performance Debugging","id":"performance-debugging"},{"level":4,"text":"Computational Complexity Analysis","id":"computational-complexity-analysis"},{"level":4,"text":"Vectorization Optimization","id":"vectorization-optimization"},{"level":4,"text":"Memory Usage Optimization","id":"memory-usage-optimization"},{"level":4,"text":"Algorithm-Level Optimizations","id":"algorithm-level-optimizations"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Debugging Infrastructure Code","id":"debugging-infrastructure-code"},{"level":4,"text":"File Structure for Debugging","id":"file-structure-for-debugging"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":4,"text":"Language-Specific Debugging Tips","id":"language-specific-debugging-tips"},{"level":2,"text":"Future Extensions","id":"future-extensions"},{"level":3,"text":"Mental Model: The Evolutionary Path","id":"mental-model-the-evolutionary-path"},{"level":3,"text":"Performance Extensions: KD-trees, LSH, and Other Acceleration Structures","id":"performance-extensions-kd-trees-lsh-and-other-acceleration-structures"},{"level":4,"text":"Mental Model: Spatial Indexing as a Library System","id":"mental-model-spatial-indexing-as-a-library-system"},{"level":4,"text":"KD-Tree Spatial Indexing","id":"kd-tree-spatial-indexing"},{"level":4,"text":"Architecture Decision: KD-Tree Integration Strategy","id":"architecture-decision-kd-tree-integration-strategy"},{"level":4,"text":"Approximate Nearest Neighbors with LSH","id":"approximate-nearest-neighbors-with-lsh"},{"level":4,"text":"Ball Tree and Cover Tree Alternatives","id":"ball-tree-and-cover-tree-alternatives"},{"level":4,"text":"Performance Extension Implementation Strategy","id":"performance-extension-implementation-strategy"},{"level":4,"text":"Common Performance Extension Pitfalls","id":"common-performance-extension-pitfalls"},{"level":3,"text":"Algorithm Extensions: Regression Support, Multi-Output Classification, and Ensemble Methods","id":"algorithm-extensions-regression-support-multi-output-classification-and-ensemble-methods"},{"level":4,"text":"Mental Model: From Voting to Averaging","id":"mental-model-from-voting-to-averaging"},{"level":4,"text":"K-Nearest Neighbors Regression","id":"k-nearest-neighbors-regression"},{"level":4,"text":"Architecture Decision: Unified Prediction Interface","id":"architecture-decision-unified-prediction-interface"},{"level":4,"text":"Multi-Output and Multi-Label Prediction","id":"multi-output-and-multi-label-prediction"},{"level":4,"text":"KNN Ensemble Methods","id":"knn-ensemble-methods"},{"level":4,"text":"Confidence and Uncertainty Estimation","id":"confidence-and-uncertainty-estimation"},{"level":4,"text":"Algorithm Extension Implementation Strategy","id":"algorithm-extension-implementation-strategy"},{"level":4,"text":"Common Algorithm Extension Pitfalls","id":"common-algorithm-extension-pitfalls"},{"level":3,"text":"Feature Extensions: Custom Distance Metrics, Feature Weighting, and Online Learning","id":"feature-extensions-custom-distance-metrics-feature-weighting-and-online-learning"},{"level":4,"text":"Mental Model: From Universal Metrics to Personalized Similarity","id":"mental-model-from-universal-metrics-to-personalized-similarity"},{"level":4,"text":"Custom Distance Metric Framework","id":"custom-distance-metric-framework"},{"level":4,"text":"Feature Weighting and Learned Metrics","id":"feature-weighting-and-learned-metrics"},{"level":4,"text":"Architecture Decision: Pluggable Distance Metric Architecture","id":"architecture-decision-pluggable-distance-metric-architecture"},{"level":4,"text":"Categorical and Mixed-Type Feature Support","id":"categorical-and-mixed-type-feature-support"},{"level":4,"text":"Online Learning and Adaptive KNN","id":"online-learning-and-adaptive-knn"},{"level":4,"text":"Streaming KNN and Memory Management","id":"streaming-knn-and-memory-management"},{"level":4,"text":"Feature Extension Implementation Strategy","id":"feature-extension-implementation-strategy"},{"level":4,"text":"Common Feature Extension Pitfalls","id":"common-feature-extension-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended Module Structure for Extensions","id":"recommended-module-structure-for-extensions"},{"level":4,"text":"Infrastructure Starter Code: Spatial Indexing Interface","id":"infrastructure-starter-code-spatial-indexing-interface"},{"level":4,"text":"Core Logic Skeleton: Custom Distance Metric Framework","id":"core-logic-skeleton-custom-distance-metric-framework"},{"level":4,"text":"Milestone Checkpoint: Performance Extensions","id":"milestone-checkpoint-performance-extensions"},{"level":4,"text":"Milestone Checkpoint: Algorithm Extensions","id":"milestone-checkpoint-algorithm-extensions"},{"level":4,"text":"Language-Specific Implementation Hints","id":"language-specific-implementation-hints"},{"level":2,"text":"Glossary","id":"glossary"},{"level":3,"text":"Mental Model: The Learning Dictionary","id":"mental-model-the-learning-dictionary"},{"level":3,"text":"Core Algorithmic Concepts","id":"core-algorithmic-concepts"},{"level":3,"text":"Distance Metric Terminology","id":"distance-metric-terminology"},{"level":3,"text":"Classification and Voting Concepts","id":"classification-and-voting-concepts"},{"level":3,"text":"Evaluation and Optimization Terminology","id":"evaluation-and-optimization-terminology"},{"level":3,"text":"Data Structure and Type System","id":"data-structure-and-type-system"},{"level":3,"text":"Algorithm Implementation Terminology","id":"algorithm-implementation-terminology"},{"level":3,"text":"Performance and Quality Metrics","id":"performance-and-quality-metrics"},{"level":3,"text":"Advanced Concepts and Extensions","id":"advanced-concepts-and-extensions"},{"level":3,"text":"Error Handling and Robustness","id":"error-handling-and-robustness"},{"level":3,"text":"Implementation and Debugging Support","id":"implementation-and-debugging-support"},{"level":3,"text":"Mathematical and Statistical Foundations","id":"mathematical-and-statistical-foundations"},{"level":3,"text":"System Architecture and Design Patterns","id":"system-architecture-and-design-patterns"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Core Data Types Implementation","id":"core-data-types-implementation"},{"level":4,"text":"Distance Calculation Infrastructure","id":"distance-calculation-infrastructure"},{"level":4,"text":"Neighbor Finding Core Logic","id":"neighbor-finding-core-logic"},{"level":4,"text":"Classification and Voting System","id":"classification-and-voting-system"},{"level":4,"text":"Evaluation and Metrics Framework","id":"evaluation-and-metrics-framework"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":4,"text":"Debugging Tips","id":"debugging-tips"}],"title":"K-Nearest Neighbors Classifier: Design Document","markdown":"# K-Nearest Neighbors Classifier: Design Document\n\n\n## Overview\n\nA K-Nearest Neighbors classification system that predicts class labels by finding the K most similar training examples using distance metrics and majority voting. The key architectural challenge is efficiently computing distances in high-dimensional spaces while supporting multiple distance metrics and providing accurate predictions through optimized neighbor selection.\n\n\n> This guide is meant to help you understand the big picture before diving into each milestone. Refer back to it whenever you need context on how components connect.\n\n\n## Context and Problem Statement\n\n> **Milestone(s):** Foundational understanding for all milestones - establishes the core classification problem that drives distance calculation (Milestone 1), neighbor finding and voting (Milestone 2), and evaluation strategies (Milestone 3).\n\n### Mental Model: The Neighborhood Recommendation System\n\nThink of K-Nearest Neighbors (KNN) classification like asking your neighbors for restaurant recommendations in a new city. When you want to find a good Italian restaurant, you don't ask everyone in the city - you ask the people who are most similar to you. Maybe you ask neighbors with similar tastes, similar age, or similar dining budgets. You assume that people who are like you in measurable ways will have preferences similar to yours.\n\nIn this neighborhood recommendation system, each neighbor gets one vote for their favorite restaurant. If you ask 5 neighbors and 3 recommend \"Mario's Pizzeria\" while 2 recommend different places, you go with the majority vote - Mario's Pizzeria. The key insight is that **similarity breeds similarity** - if someone is similar to you in the ways you can measure (age, income, food preferences), they're likely to be similar in the ways you can't easily measure (what makes a restaurant great).\n\nKNN classification works exactly the same way, but instead of neighbors recommending restaurants, training examples \"recommend\" class labels for new data points. The algorithm finds the K training examples that are most similar to your new data point (measured by distance in feature space), then takes a majority vote of their class labels. Just like asking neighbors, the assumption is that similar data points will have similar class labels.\n\nThis neighborhood analogy reveals why KNN is called a **lazy learning algorithm** - it doesn't try to understand the underlying rules that separate classes (like \"all good Italian restaurants have fresh pasta\"). Instead, it simply remembers all the training examples and makes decisions by consulting the most relevant neighbors when needed, just like you might keep a mental rolodex of neighbors to ask for different types of advice.\n\n### Problem Definition\n\n**Classification** is the supervised learning task of predicting discrete class labels for new data points based on patterns learned from labeled training examples. Formally, given a training dataset D = {(x₁, y₁), (x₂, y₂), ..., (xₙ, yₙ)} where each xᵢ is a feature vector and yᵢ is its corresponding class label, the goal is to learn a function f: X → Y that can accurately predict the class label y for any new feature vector x.\n\nThe **K-Nearest Neighbors approach** to classification is based on the fundamental assumption that **similar inputs should produce similar outputs**. This assumption, known as the smoothness assumption in machine learning, suggests that the decision boundary between classes is locally smooth - data points that are close together in feature space are likely to belong to the same class.\n\nKNN operationalizes this assumption through a simple three-step process:\n\n1. **Distance Calculation**: Measure the similarity between the query point and every training example using a distance metric (Euclidean, Manhattan, cosine, etc.). The choice of distance metric defines what \"similarity\" means for your specific problem.\n\n2. **Neighbor Selection**: Identify the K training examples with the smallest distances to the query point. These are the \"nearest neighbors\" that will vote on the classification decision.\n\n3. **Majority Voting**: Assign the class label that appears most frequently among the K nearest neighbors. Optionally, weight each neighbor's vote by the inverse of its distance to give closer neighbors more influence.\n\n> **Key Insight**: KNN makes no assumptions about the underlying data distribution or the shape of decision boundaries. Unlike parametric models that assume data follows a specific mathematical form, KNN adapts to whatever patterns exist in the training data, making it particularly effective for complex, non-linear decision boundaries.\n\nThe effectiveness of KNN depends on several critical factors that will drive our implementation decisions:\n\n**Distance Metric Selection**: The choice of distance metric fundamentally determines which training examples are considered \"neighbors.\" Euclidean distance works well for continuous features with similar scales, Manhattan distance is robust to outliers, and cosine similarity is effective for high-dimensional sparse data like text features.\n\n**Neighborhood Size (K)**: The value of K controls the bias-variance tradeoff. Small K values (like K=1) create complex decision boundaries that closely follow the training data but may overfit to noise. Large K values create smoother decision boundaries that generalize better but may underfit complex patterns. The optimal K must be determined empirically through cross-validation.\n\n**Feature Scaling**: Since distance calculations treat all features equally, features with larger scales will dominate the distance computation. A person's income (measured in tens of thousands) will overwhelm their age (measured in tens) unless features are properly scaled.\n\n**Curse of Dimensionality**: In high-dimensional spaces, the concept of \"nearest\" becomes less meaningful as all points become roughly equidistant. This requires careful feature selection and potentially dimensionality reduction techniques.\n\n### Comparison with Other Classification Methods\n\nUnderstanding how KNN differs from other classification approaches illuminates its unique strengths and appropriate use cases. The fundamental distinction lies in how different algorithms learn patterns from training data and make predictions.\n\n| Classification Approach | Learning Strategy | Decision Boundary | Computational Cost | Interpretability |\n|------------------------|-------------------|-------------------|-------------------|------------------|\n| KNN | Instance-based (lazy) | Adaptive, non-parametric | High prediction cost | Local interpretability |\n| Logistic Regression | Parametric optimization | Linear hyperplane | Low prediction cost | Global interpretability |\n| Decision Trees | Recursive splitting | Axis-aligned rectangles | Medium prediction cost | High interpretability |\n| Neural Networks | Gradient-based learning | Complex non-linear | Low prediction cost | Low interpretability |\n| SVM | Margin maximization | Linear or kernel-based | Medium prediction cost | Medium interpretability |\n\n> **Decision: Instance-Based vs Parametric Learning**\n> - **Context**: We need to choose between learning explicit parameters that generalize patterns (parametric) versus storing training examples and making local decisions (instance-based)\n> - **Options Considered**: \n>   1. Parametric approach (learn global decision boundary parameters)\n>   2. Instance-based approach (store examples, make local decisions)\n>   3. Hybrid approach (learn local parameters for regions)\n> - **Decision**: Instance-based learning (KNN approach)\n> - **Rationale**: Instance-based learning requires no assumptions about data distribution, adapts automatically to complex decision boundaries, and provides intuitive explanations for individual predictions by showing which training examples influenced the decision\n> - **Consequences**: Higher memory requirements (must store all training data), slower predictions (must compute distances), but greater flexibility and interpretability for complex datasets\n\n**KNN vs Logistic Regression**: Logistic regression learns a global linear decision boundary by optimizing parameters that define a hyperplane separating classes. This creates fast predictions (just evaluate the linear function) but assumes classes are linearly separable. KNN makes no linearity assumptions and can handle arbitrarily complex decision boundaries by adapting locally to the data distribution. However, KNN requires computing distances to all training points for each prediction, making it much slower than logistic regression's simple arithmetic.\n\n**KNN vs Decision Trees**: Decision trees recursively split the feature space along axis-aligned boundaries to create rectangular decision regions. Each prediction follows a path from root to leaf, making the decision process highly interpretable. KNN creates more flexible decision boundaries that aren't restricted to axis-aligned splits, but the \"decision process\" is less transparent - you know which neighbors voted, but not why those specific features made them neighbors. Trees can overfit with deep splits, while KNN overfits with small K values.\n\n**KNN vs Neural Networks**: Neural networks learn complex non-linear transformations through multiple layers of weighted combinations and activation functions. Once trained, predictions are very fast (forward pass through the network), but the learned representation is opaque. KNN provides local interpretability - you can examine the K neighbors that influenced any prediction - but lacks the global patterns that neural networks discover. Neural networks excel when you have massive datasets and care primarily about accuracy, while KNN excels when you need to explain individual predictions or work with smaller datasets.\n\n> **The No Free Lunch Theorem**: No classification algorithm is universally superior across all possible problems. KNN's strength lies in problems where local similarity is a reliable predictor of class membership, where decision boundaries are complex and non-linear, and where interpretability of individual predictions is important.\n\n**When KNN Excels**:\n- **Recommendation Systems**: Finding users with similar preferences to recommend products\n- **Medical Diagnosis**: Finding patients with similar symptoms and test results\n- **Image Classification**: Finding visually similar images in feature space\n- **Anomaly Detection**: Identifying data points that are far from all training examples\n- **Multi-modal Distributions**: Classes that form multiple clusters rather than single regions\n\n**When KNN Struggles**:\n- **High-Dimensional Data**: Curse of dimensionality makes distance metrics less meaningful\n- **Large-Scale Applications**: Computational cost of distance calculations becomes prohibitive\n- **Noisy Data**: Without feature selection, irrelevant features pollute distance calculations\n- **Imbalanced Classes**: Majority class neighbors can overwhelm minority class signals\n- **Real-Time Applications**: Prediction latency may be unacceptable for time-critical systems\n\n| Problem Characteristic | KNN Suitability | Reasoning |\n|----------------------|----------------|-----------|\n| Complex decision boundaries | Excellent | Adapts locally without parametric assumptions |\n| Need for interpretability | Good | Can examine which neighbors influenced decisions |\n| Large training datasets | Poor | Computational cost grows linearly with data size |\n| High-dimensional features | Poor | Distance becomes less meaningful in high dimensions |\n| Real-time predictions | Poor | Must compute distances to all training points |\n| Irregular class distributions | Excellent | No assumptions about class shape or distribution |\n\nUnderstanding these trade-offs guides our implementation priorities. We'll focus on efficient distance calculations, flexible distance metrics, and clear interfaces for examining neighbors, while acknowledging that performance optimization and dimensionality handling are areas for future enhancement rather than core requirements for this foundational implementation.\n\n### Implementation Guidance\n\nThe implementation approach balances educational clarity with practical functionality. Since KNN is often a student's first encounter with instance-based learning, the code should clearly illustrate the core concepts while remaining efficient enough for real experimentation.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Distance Computation | Pure NumPy with explicit loops | Vectorized NumPy operations |\n| Data Storage | Python lists and dictionaries | NumPy structured arrays |\n| Neighbor Search | Linear scan through all points | KD-tree or LSH for acceleration |\n| Evaluation | Manual train/test splits | Scikit-learn's evaluation utilities |\n| Visualization | Matplotlib scatter plots | Interactive plots with Plotly |\n\n#### Recommended Module Structure\n\n```\nknn_classifier/\n├── __init__.py                    # Package initialization\n├── core/\n│   ├── __init__.py\n│   ├── distance_metrics.py       # Distance calculation functions\n│   ├── neighbor_finder.py        # K-nearest neighbor search\n│   ├── classifier.py             # Main KNN classifier class\n│   └── data_types.py             # Core data structures and types\n├── evaluation/\n│   ├── __init__.py\n│   ├── cross_validation.py       # K-fold CV implementation\n│   ├── metrics.py                # Accuracy, precision, recall calculations\n│   └── optimization.py           # Hyperparameter tuning utilities\n├── utils/\n│   ├── __init__.py\n│   ├── data_loader.py            # Dataset loading and preprocessing\n│   ├── plotting.py               # Visualization utilities\n│   └── preprocessing.py          # Feature scaling and normalization\n└── examples/\n    ├── iris_classification.py    # Complete example with Iris dataset\n    ├── synthetic_data.py         # Generated 2D data for visualization\n    └── comparison_study.py       # Compare KNN with other algorithms\n```\n\nThis structure separates concerns clearly: core algorithms in `core/`, evaluation logic in `evaluation/`, utilities in `utils/`, and complete examples in `examples/`. Each module has a single responsibility, making the codebase easier to understand and test.\n\n#### Infrastructure Starter Code\n\n**Data Types Foundation** (`core/data_types.py`):\n```python\n\"\"\"\nCore data types for KNN classifier implementation.\nProvides type hints and data structures used throughout the system.\n\"\"\"\nfrom typing import List, Tuple, Dict, Optional, Union, Protocol\nimport numpy as np\nfrom enum import Enum\n\n# Type aliases for clarity\nFeatureVector = np.ndarray  # 1D array representing features of a single sample\nFeatureMatrix = np.ndarray  # 2D array where each row is a FeatureVector\nClassLabel = Union[int, str]  # Class labels can be integers or strings\nDistanceArray = np.ndarray  # 1D array of distances\nNeighborIndices = np.ndarray  # 1D array of indices into training data\n\nclass DistanceMetric(Enum):\n    \"\"\"Supported distance metrics for neighbor calculation.\"\"\"\n    EUCLIDEAN = \"euclidean\"\n    MANHATTAN = \"manhattan\" \n    COSINE = \"cosine\"\n\nclass TrainingData:\n    \"\"\"Container for training dataset with features and labels.\"\"\"\n    def __init__(self, features: FeatureMatrix, labels: List[ClassLabel]):\n        self.features = np.array(features)\n        self.labels = labels\n        self.n_samples, self.n_features = self.features.shape\n        self.unique_classes = list(set(labels))\n    \n    def get_sample(self, index: int) -> Tuple[FeatureVector, ClassLabel]:\n        \"\"\"Get a single training sample by index.\"\"\"\n        return self.features[index], self.labels[index]\n\nclass PredictionResult:\n    \"\"\"Result of a single prediction with confidence information.\"\"\"\n    def __init__(self, predicted_class: ClassLabel, neighbor_indices: NeighborIndices, \n                 neighbor_distances: DistanceArray, confidence: float):\n        self.predicted_class = predicted_class\n        self.neighbor_indices = neighbor_indices\n        self.neighbor_distances = neighbor_distances  \n        self.confidence = confidence  # Proportion of neighbors voting for this class\n```\n\n**Data Loading Utilities** (`utils/data_loader.py`):\n```python\n\"\"\"\nUtilities for loading and preprocessing datasets for KNN classification.\nHandles common datasets and provides data splitting functionality.\n\"\"\"\nimport numpy as np\nfrom typing import Tuple\nfrom sklearn.datasets import load_iris, make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\ndef load_iris_dataset() -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Load the classic Iris dataset for flower classification.\"\"\"\n    iris = load_iris()\n    return iris.data, iris.target\n\ndef create_synthetic_dataset(n_samples: int = 200, n_features: int = 2, \n                           n_classes: int = 3, random_state: int = 42) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Create synthetic classification dataset for testing and visualization.\"\"\"\n    X, y = make_classification(\n        n_samples=n_samples,\n        n_features=n_features,\n        n_redundant=0,\n        n_informative=n_features,\n        n_classes=n_classes,\n        n_clusters_per_class=1,\n        random_state=random_state\n    )\n    return X, y\n\ndef split_and_scale_data(X: np.ndarray, y: np.ndarray, test_size: float = 0.2, \n                        scale_features: bool = True, random_state: int = 42) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Split data into train/test sets and optionally apply feature scaling.\"\"\"\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n    \n    if scale_features:\n        scaler = StandardScaler()\n        X_train = scaler.fit_transform(X_train)\n        X_test = scaler.transform(X_test)\n    \n    return X_train, X_test, y_train, y_test\n```\n\n#### Core Logic Skeleton Code\n\n**Main KNN Classifier Interface** (`core/classifier.py`):\n```python\n\"\"\"\nMain KNN Classifier implementation combining distance calculation,\nneighbor finding, and voting into a complete classification system.\n\"\"\"\nfrom typing import List, Optional\nimport numpy as np\nfrom .data_types import *\nfrom .distance_metrics import DistanceCalculator\nfrom .neighbor_finder import NeighborFinder\n\nclass KNNClassifier:\n    \"\"\"\n    K-Nearest Neighbors classifier with configurable distance metrics and voting strategies.\n    \n    The classifier follows the standard fit/predict interface:\n    1. fit() stores the training data\n    2. predict() finds neighbors and performs voting for each query point\n    \"\"\"\n    \n    def __init__(self, k: int = 3, distance_metric: DistanceMetric = DistanceMetric.EUCLIDEAN, \n                 weighted_voting: bool = False):\n        # TODO 1: Store hyperparameters (k, distance_metric, weighted_voting)\n        # TODO 2: Initialize DistanceCalculator with chosen metric  \n        # TODO 3: Initialize NeighborFinder with k parameter\n        # TODO 4: Initialize training_data to None (set during fit)\n        pass\n    \n    def fit(self, X: FeatureMatrix, y: List[ClassLabel]) -> None:\n        \"\"\"\n        Store training data for use during prediction.\n        KNN is lazy learning - no actual training computation happens here.\n        \"\"\"\n        # TODO 1: Validate that X and y have compatible shapes\n        # TODO 2: Create TrainingData object from X and y\n        # TODO 3: Store the TrainingData in self.training_data\n        # Hint: This method should be very simple - just data storage\n        pass\n    \n    def predict(self, X: FeatureMatrix) -> List[ClassLabel]:\n        \"\"\"\n        Predict class labels for query points using K-nearest neighbors voting.\n        \"\"\"\n        # TODO 1: Validate that classifier has been fitted (training_data is not None)\n        # TODO 2: For each query point in X:\n        #   TODO 2a: Find K nearest neighbors using neighbor_finder\n        #   TODO 2b: Get class labels for those neighbors\n        #   TODO 2c: Perform voting (majority or weighted) to get prediction\n        # TODO 3: Return list of predictions\n        # Hint: Consider using _predict_single() helper method for each query point\n        pass\n    \n    def predict_with_confidence(self, X: FeatureMatrix) -> List[PredictionResult]:\n        \"\"\"\n        Predict class labels with detailed information about neighbors and confidence.\n        \"\"\"\n        # TODO 1: Similar to predict(), but return PredictionResult objects\n        # TODO 2: Include neighbor indices, distances, and confidence scores\n        # TODO 3: Confidence = proportion of neighbors voting for predicted class\n        pass\n    \n    def _predict_single(self, query_point: FeatureVector) -> PredictionResult:\n        \"\"\"Helper method to predict a single query point.\"\"\"\n        # TODO 1: Find K nearest neighbors to query_point\n        # TODO 2: Get their class labels from training_data\n        # TODO 3: Perform voting to determine prediction\n        # TODO 4: Calculate confidence score\n        # TODO 5: Return PredictionResult with all information\n        pass\n```\n\n#### Language-Specific Hints\n\n**NumPy Optimization Tips**:\n- Use `np.linalg.norm()` for Euclidean distance calculation instead of manual sqrt(sum(squares))\n- Leverage broadcasting for vectorized distance computation: `X[:, np.newaxis, :] - training_data[np.newaxis, :, :]`\n- Use `np.argpartition()` for finding K smallest distances without full sorting\n- Apply `np.bincount()` for fast majority voting when labels are integers\n\n**Memory Management**:\n- For large datasets, compute distances in batches to avoid memory overflow\n- Consider using `np.float32` instead of `np.float64` if precision allows, for 2x memory savings\n- Use views instead of copies when possible: `X[indices]` not `np.copy(X[indices])`\n\n**Performance Monitoring**:\n- Use `time.perf_counter()` to measure distance calculation vs voting time separately\n- Profile with `cProfile` to identify bottlenecks: `python -m cProfile -o profile.stats your_script.py`\n- Monitor memory usage with `tracemalloc` for large dataset experiments\n\n#### Milestone Checkpoint\n\nAfter implementing the foundational understanding from this section:\n\n**Conceptual Verification**:\n1. **Analogy Test**: Explain KNN to someone using the neighborhood recommendation analogy without using technical terms\n2. **Trade-off Understanding**: List 3 scenarios where KNN would outperform logistic regression and 3 where it wouldn't\n3. **Parameter Intuition**: Predict what happens to decision boundaries as K increases from 1 to 50\n\n**Code Structure Verification**:\n1. **Module Organization**: Verify that the recommended directory structure is created and each module has clear responsibilities\n2. **Type System**: Ensure that `data_types.py` loads without errors and provides clear type hints\n3. **Data Loading**: Test that synthetic and Iris datasets can be loaded and split properly\n\n**Expected Output** from data loading test:\n```python\n# Run this verification script\nfrom knn_classifier.utils.data_loader import load_iris_dataset, split_and_scale_data\n\nX, y = load_iris_dataset()\nX_train, X_test, y_train, y_test = split_and_scale_data(X, y)\n\nprint(f\"Training set: {X_train.shape[0]} samples, {X_train.shape[1]} features\")\nprint(f\"Test set: {X_test.shape[0]} samples\") \nprint(f\"Classes: {set(y_train)}\")\nprint(f\"Feature scaling applied: mean ≈ 0, std ≈ 1\")\nprint(f\"Sample training point: {X_train[0]}\")\n```\n\n**Signs of Problems**:\n- **Import Errors**: Missing `__init__.py` files or incorrect module structure\n- **Type Errors**: Data types not properly defined or incompatible with NumPy arrays\n- **Scale Issues**: Features not properly normalized (means far from 0, std far from 1)\n\nThis foundational section establishes the conceptual framework and code structure that will support all subsequent implementation milestones. The neighborhood analogy provides intuitive understanding, the comparison with other methods shows when KNN is appropriate, and the starter code creates a solid foundation for the actual algorithm implementation.\n\n\n## Goals and Non-Goals\n\n> **Milestone(s):** Foundational scope definition that guides all three milestones - establishes boundaries for distance calculation (Milestone 1), neighbor finding and classification (Milestone 2), and evaluation improvements (Milestone 3)\n\n### Mental Model: The Recipe Book Approach\n\nThink of this design document as creating a recipe book for a neighborhood recommendation system. Just as a cookbook needs to clearly state what dishes it will teach you to make, what kitchen equipment it assumes you have, and what advanced techniques it won't cover, our KNN system needs explicit boundaries. A good recipe book doesn't try to teach everything about cooking - it focuses on a specific set of dishes and does them well. Similarly, our KNN implementation will excel at core classification tasks while deliberately excluding advanced features that would complicate the learning experience.\n\nThis goal-setting process is like a chef deciding whether their cookbook will cover basic weeknight dinners or advanced molecular gastronomy. The choice isn't about which is better, but about what serves the intended audience. For a beginner learning KNN, we want to build a solid foundation with clear, understandable components before considering optimizations that might obscure the underlying principles.\n\n### Functional Goals: Core Classification Capabilities and Performance Requirements\n\nThe functional goals define the specific classification capabilities our KNN system must deliver. These represent the concrete behaviors users can expect when interacting with our implementation.\n\n**Primary Classification Functionality**\n\nOur KNN system will provide complete **lazy learning** capabilities, meaning it stores training examples without preprocessing and defers all computation until prediction time. The system will support both single-point predictions and batch predictions over multiple query points. Users will be able to train the classifier by providing feature vectors and corresponding class labels, then make predictions on new, unseen data points.\n\nThe system will implement multiple **distance metrics** to measure similarity between data points. Each metric captures a different notion of similarity - Euclidean distance measures straight-line distance in feature space, Manhattan distance measures city-block distance along feature dimensions, and cosine similarity measures angular similarity regardless of magnitude. This variety allows users to choose the most appropriate similarity measure for their data characteristics.\n\n| Distance Metric | Mathematical Definition | Use Case |\n|-----------------|------------------------|----------|\n| Euclidean | sqrt(sum((x_i - y_i)²)) | Continuous features with similar scales |\n| Manhattan | sum(abs(x_i - y_i)) | Features with different scales or outliers |\n| Cosine | dot(x,y) / (norm(x) * norm(y)) | High-dimensional sparse data |\n\n**Neighbor Selection and Voting**\n\nThe system will provide flexible **K parameter configuration**, allowing users to specify how many nearest neighbors to consider for each prediction. This parameter fundamentally controls the **bias-variance tradeoff** - smaller K values create more flexible decision boundaries (high variance, low bias) while larger K values create smoother decision boundaries (low variance, high bias).\n\nOur implementation will support both simple **majority voting** and **weighted voting** strategies. In majority voting, each of the K nearest neighbors contributes one vote for their class label, and the class receiving the most votes becomes the prediction. In weighted voting, closer neighbors receive more influence in the final decision, typically using inverse distance weighting where neighbors at distance d contribute votes proportional to 1/d.\n\n| Voting Strategy | Vote Weight | Advantage | Disadvantage |\n|----------------|-------------|-----------|--------------|\n| Majority | Equal (1.0 per neighbor) | Simple, interpretable | Ignores distance information |\n| Inverse Distance | 1 / distance | Emphasizes closer neighbors | Sensitive to very close points |\n| Inverse Square | 1 / distance² | Strong distance emphasis | Unstable with duplicate points |\n\n**Performance and Efficiency Requirements**\n\nThe system will implement **vectorized operations** using NumPy to avoid Python-level loops during distance calculations. This requirement ensures that distance computation scales efficiently with both the number of training examples and the dimensionality of the feature space. All distance calculations will operate on entire matrices simultaneously rather than iterating through individual data points.\n\nFor datasets with reasonable size (up to 10,000 training examples with up to 100 features), the system will complete training in under 1 second and individual predictions in under 0.1 seconds on standard hardware. These performance targets ensure the implementation remains practical for educational use and small to medium-sized classification problems.\n\n**Data Type Flexibility**\n\nOur KNN classifier will handle both **numeric class labels** (integers) and **string class labels** (categorical names), making it suitable for a wide variety of classification tasks. The system will automatically detect the class label type and handle voting appropriately for both cases.\n\nThe implementation will accept feature data as NumPy arrays, providing compatibility with the broader Python scientific computing ecosystem. Training features will be stored as a `FeatureMatrix` (2D array where each row represents one training example) while predictions can be made on individual `FeatureVector` instances (1D arrays) or batches of query points.\n\n### Non-Functional Goals: Quality Attributes\n\nNon-functional goals define the quality attributes that make our KNN system maintainable, extensible, and suitable for educational use. These requirements shape how we structure the code and design component interfaces.\n\n**Code Clarity and Educational Value**\n\nThe implementation will prioritize **code readability** over micro-optimizations, ensuring that learners can easily understand each component's purpose and implementation. Every major algorithm will include detailed comments explaining the mathematical concepts and design decisions. Variable names will be descriptive and follow consistent naming conventions throughout the codebase.\n\nAll core algorithms will be implemented as **separate, focused functions** rather than monolithic methods. This modular design allows learners to understand and test individual components in isolation before seeing how they integrate into the complete system. For example, distance calculation, neighbor finding, and voting will each be implemented as distinct modules with well-defined interfaces.\n\n> **Design Principle**: Each function should do one thing well and have a name that clearly describes its purpose. A function called `calculate_euclidean_distance` should only compute distance, not also find neighbors or make predictions.\n\n**Extensibility and Modularity**\n\nThe system architecture will support **easy addition of new distance metrics** through a common interface. Adding a new distance function should require implementing a single method signature without modifying existing code. This extensibility allows learners to experiment with custom distance measures for their specific domains.\n\nComponent interfaces will be designed to support future enhancements like **approximate nearest neighbor algorithms** or **different voting strategies** without requiring major architectural changes. The core `KNNClassifier` class will delegate to specialized components for distance calculation, neighbor finding, and voting, making it easy to swap implementations.\n\n**Error Handling and Robustness**\n\nThe system will implement **comprehensive input validation** with clear, helpful error messages. When users provide invalid parameters (like K larger than the dataset size) or incompatible data shapes (mismatched feature dimensions), the system will detect these issues early and provide specific guidance on how to fix them.\n\nAll mathematical operations will include **numerical stability checks** to handle edge cases like identical data points (zero distance) or empty datasets. The implementation will avoid common pitfalls like taking square roots of negative numbers or dividing by zero in distance calculations.\n\n**Testing and Verification Support**\n\nThe codebase will include **comprehensive test coverage** with unit tests for each component and integration tests for end-to-end workflows. Test cases will cover both typical usage patterns and edge cases, providing learners with examples of how to verify their implementations.\n\nThe system will provide **built-in evaluation metrics** including accuracy, precision, recall, and F1-score, along with confusion matrix generation. These tools allow learners to objectively assess their classifier's performance and understand its strengths and weaknesses on different types of data.\n\n### Explicit Non-Goals: Features Excluded from This Implementation\n\nClearly defining what we will NOT implement is crucial for maintaining scope and setting appropriate expectations. These non-goals represent features that, while valuable in production systems, would complicate the learning experience or exceed the project's educational objectives.\n\n**Advanced Optimization Algorithms**\n\nWe will NOT implement **KD-trees, ball trees, or other spatial indexing structures** for accelerating neighbor search. While these algorithms can reduce neighbor finding from O(n) to O(log n) complexity, they introduce significant implementation complexity and can obscure the fundamental KNN concepts. Our implementation will use straightforward linear search, which is easier to understand and debug.\n\nWe will NOT include **approximate nearest neighbor algorithms** like Locality-Sensitive Hashing (LSH) or hierarchical navigable small world graphs. These techniques trade accuracy for speed but require understanding of advanced data structures and probabilistic algorithms that exceed our beginner-level scope.\n\n**Production-Scale Performance Features**\n\nThe system will NOT include **distributed or parallel processing** capabilities. All computation will occur on a single machine using single-threaded execution (except for NumPy's internal vectorization). While distributed KNN is important for large-scale applications, it introduces complexity around data partitioning, communication, and fault tolerance that distracts from core algorithm understanding.\n\nWe will NOT implement **online learning** or **incremental updates** to the training set. Our classifier will follow the traditional batch learning paradigm where training data is fixed after the initial `fit` operation. Online learning requires additional data structures and algorithms to maintain neighbor relationships as new examples arrive.\n\n**Advanced Distance Metrics and Similarity Measures**\n\nThe implementation will NOT include **learned distance metrics** or **adaptive similarity measures** that change based on the training data. While techniques like metric learning can improve KNN performance by learning optimal feature weightings, they require understanding of optimization algorithms and gradient-based learning that exceeds our scope.\n\nWe will NOT support **categorical features** with specialized distance measures like Hamming distance for binary features or Gower's distance for mixed data types. Our focus remains on continuous numerical features where Euclidean, Manhattan, and cosine distance provide clear, interpretable similarity measures.\n\n**Complex Voting and Prediction Schemes**\n\nThe system will NOT implement **probabilistic predictions** or **prediction uncertainty quantification** beyond basic confidence scores based on neighbor agreement. Advanced uncertainty estimation requires statistical modeling techniques that complicate the implementation without adding educational value for beginners.\n\nWe will NOT support **multi-output classification** (predicting multiple labels simultaneously) or **structured prediction** tasks. Our scope focuses on single-label, multi-class classification problems where each example belongs to exactly one class from a predefined set.\n\n**Integration and Deployment Features**\n\nThe implementation will NOT include **model serialization** or **persistence** capabilities beyond basic Python pickle support. Production ML systems require sophisticated model versioning and deployment pipelines, but these infrastructure concerns are outside our algorithm-focused scope.\n\nWe will NOT provide **REST APIs, web interfaces, or other service-oriented features**. The system will remain a Python library with programmatic interfaces, allowing learners to focus on the algorithm implementation rather than software engineering concerns around API design and web development.\n\n> **Architecture Decision: Educational Focus Over Production Readiness**\n> - **Context**: Must choose between comprehensive production features and clear educational value\n> - **Options Considered**: \n>   1. Full-featured production system with optimizations, persistence, APIs\n>   2. Educational implementation focused on core algorithms\n>   3. Hybrid approach with basic optimizations\n> - **Decision**: Focus purely on educational value with clear, readable implementations\n> - **Rationale**: Beginners learn better with simple, understandable code than with complex optimized systems they cannot comprehend or debug\n> - **Consequences**: Enables deep understanding of fundamental concepts but requires additional work to make production-ready\n\n| Feature Category | Included | Excluded | Rationale |\n|------------------|----------|----------|-----------|\n| Distance Metrics | Euclidean, Manhattan, Cosine | Learned metrics, specialized categorical distances | Core metrics sufficient for understanding principles |\n| Search Algorithms | Linear search | KD-trees, approximate search | Complexity would obscure fundamental concepts |\n| Voting Strategies | Majority, inverse distance weighting | Probabilistic voting, uncertainty quantification | Simple strategies demonstrate core principles |\n| Performance | Vectorized NumPy operations | Parallel processing, distributed computing | Educational focus over production optimization |\n| Data Types | Numerical features, class labels | Categorical features, structured outputs | Simplifies implementation while covering main use cases |\n\n### Implementation Guidance\n\nThis implementation guidance provides concrete technical recommendations for building a KNN system that achieves the functional and non-functional goals while respecting the explicit boundaries defined above.\n\n**A. Technology Recommendations**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Numerical Computing | NumPy arrays + pure Python | NumPy + SciPy + Numba JIT compilation |\n| Distance Calculation | NumPy vectorized operations | SciKit-Learn distance metrics |\n| Data Loading | CSV files + pandas | MLOps pipelines with versioning |\n| Visualization | Matplotlib scatter plots | Interactive Plotly dashboards |\n| Testing | Built-in unittest module | Pytest with fixtures and parameterization |\n\n**B. Recommended File/Module Structure**\n\nThe following structure organizes code into logical, testable modules that align with our component-based architecture:\n\n```\nknn-classifier/\n├── src/\n│   ├── __init__.py\n│   ├── data_types.py          ← Core type definitions (FeatureVector, TrainingData, etc.)\n│   ├── distance_metrics.py    ← Distance calculation implementations\n│   ├── neighbor_finder.py     ← K-nearest neighbor search algorithms\n│   ├── classifier.py          ← Main KNNClassifier class and voting logic\n│   ├── evaluation.py          ← Cross-validation and performance metrics\n│   └── utils.py               ← Data loading and preprocessing utilities\n├── tests/\n│   ├── test_distance_metrics.py\n│   ├── test_neighbor_finder.py\n│   ├── test_classifier.py\n│   ├── test_evaluation.py\n│   └── test_integration.py\n├── examples/\n│   ├── iris_classification.py ← Complete example using iris dataset\n│   └── synthetic_data.py      ← Example with generated 2D data for visualization\n└── README.md\n```\n\n**C. Infrastructure Starter Code**\n\n**Core Data Types (Complete Implementation)**\n\n```python\n# src/data_types.py\nfrom typing import List, Union, Optional, Tuple\nimport numpy as np\nfrom enum import Enum\n\n# Type aliases for clarity\nFeatureVector = np.ndarray  # 1D array representing features of a single sample\nFeatureMatrix = np.ndarray  # 2D array where each row is a FeatureVector\nClassLabel = Union[int, str]  # Union type for int or string class labels\nDistanceArray = np.ndarray  # 1D array of distance values\nNeighborIndices = np.ndarray  # 1D array of indices into training data\n\nclass DistanceMetric(Enum):\n    \"\"\"Enumeration of supported distance metrics.\"\"\"\n    EUCLIDEAN = \"euclidean\"\n    MANHATTAN = \"manhattan\"\n    COSINE = \"cosine\"\n\nclass TrainingData:\n    \"\"\"Container for training dataset with metadata.\"\"\"\n    \n    def __init__(self, features: FeatureMatrix, labels: List[ClassLabel]):\n        self.features = features\n        self.labels = labels\n        self.n_samples = features.shape[0]\n        self.n_features = features.shape[1]\n        self.unique_classes = list(set(labels))\n        \n        # Validation\n        if len(labels) != self.n_samples:\n            raise ValueError(f\"Feature count {self.n_samples} doesn't match label count {len(labels)}\")\n    \n    def get_sample(self, index: int) -> Tuple[FeatureVector, ClassLabel]:\n        \"\"\"Retrieve single training example.\"\"\"\n        if not 0 <= index < self.n_samples:\n            raise IndexError(f\"Sample index {index} out of range [0, {self.n_samples})\")\n        return self.features[index], self.labels[index]\n\nclass PredictionResult:\n    \"\"\"Container for prediction with neighbor information and confidence.\"\"\"\n    \n    def __init__(self, predicted_class: ClassLabel, neighbor_indices: NeighborIndices, \n                 neighbor_distances: DistanceArray, confidence: float):\n        self.predicted_class = predicted_class\n        self.neighbor_indices = neighbor_indices\n        self.neighbor_distances = neighbor_distances\n        self.confidence = confidence\n```\n\n**Data Loading Utilities (Complete Implementation)**\n\n```python\n# src/utils.py\nimport numpy as np\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom typing import Tuple\n\ndef load_iris_dataset() -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Load classic Iris classification dataset.\"\"\"\n    iris = load_iris()\n    return iris.data, iris.target\n\ndef split_and_scale_data(X: np.ndarray, y: np.ndarray, test_size: float = 0.2, \n                        scale_features: bool = True, random_state: int = 42) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Split data into train/test sets and optionally apply feature scaling.\"\"\"\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=test_size, random_state=random_state, stratify=y\n    )\n    \n    if scale_features:\n        scaler = StandardScaler()\n        X_train = scaler.fit_transform(X_train)\n        X_test = scaler.transform(X_test)\n    \n    return X_train, X_test, y_train, y_test\n\ndef generate_synthetic_2d_data(n_samples: int = 300, n_classes: int = 3, \n                              random_state: int = 42) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Generate 2D synthetic data for visualization and testing.\"\"\"\n    np.random.seed(random_state)\n    \n    # Create cluster centers\n    centers = np.random.uniform(-10, 10, (n_classes, 2))\n    \n    X = []\n    y = []\n    \n    samples_per_class = n_samples // n_classes\n    for class_idx, center in enumerate(centers):\n        # Generate points around each center\n        class_X = np.random.multivariate_normal(\n            center, [[2, 0], [0, 2]], samples_per_class\n        )\n        class_y = [class_idx] * samples_per_class\n        \n        X.append(class_X)\n        y.extend(class_y)\n    \n    X = np.vstack(X)\n    y = np.array(y)\n    \n    # Shuffle the data\n    indices = np.random.permutation(len(X))\n    return X[indices], y[indices]\n```\n\n**D. Core Logic Skeleton Code**\n\n**KNN Classifier Main Class (Skeleton for Implementation)**\n\n```python\n# src/classifier.py\nfrom typing import List, Optional\nimport numpy as np\nfrom .data_types import (\n    FeatureMatrix, FeatureVector, ClassLabel, TrainingData, \n    PredictionResult, DistanceMetric, NeighborIndices, DistanceArray\n)\n\nclass KNNClassifier:\n    \"\"\"K-Nearest Neighbors classifier with configurable distance metrics and voting strategies.\"\"\"\n    \n    def __init__(self, k: int = 5, distance_metric: DistanceMetric = DistanceMetric.EUCLIDEAN, \n                 weighted_voting: bool = False):\n        self.k = k\n        self.distance_metric = distance_metric\n        self.weighted_voting = weighted_voting\n        self.training_data: Optional[TrainingData] = None\n    \n    def fit(self, X: FeatureMatrix, y: List[ClassLabel]) -> None:\n        \"\"\"Store training data for lazy learning.\"\"\"\n        # TODO 1: Validate input dimensions and types\n        # TODO 2: Create TrainingData instance and store in self.training_data\n        # TODO 3: Validate that k is not larger than number of training samples\n        # Hint: This is lazy learning - no actual computation happens during fit\n        pass\n    \n    def predict(self, X: FeatureMatrix) -> List[ClassLabel]:\n        \"\"\"Predict class labels for query points.\"\"\"\n        # TODO 1: Validate that fit has been called (self.training_data is not None)\n        # TODO 2: Handle both single vector and matrix input cases\n        # TODO 3: For each query point, call predict_single to get the prediction\n        # TODO 4: Return list of predicted class labels\n        # Hint: Use predict_with_confidence internally and extract just the predicted_class\n        pass\n    \n    def predict_with_confidence(self, X: FeatureMatrix) -> List[PredictionResult]:\n        \"\"\"Predict with neighbor and confidence information.\"\"\"\n        # TODO 1: Validate inputs and ensure model is fitted\n        # TODO 2: Convert single vector input to matrix if needed\n        # TODO 3: For each query point, find K nearest neighbors\n        # TODO 4: Apply voting strategy (majority or weighted) to determine prediction\n        # TODO 5: Calculate confidence based on neighbor agreement\n        # TODO 6: Return PredictionResult objects with all information\n        pass\n    \n    def _predict_single(self, query_point: FeatureVector) -> PredictionResult:\n        \"\"\"Predict class for a single query point.\"\"\"\n        # TODO 1: Calculate distances from query point to all training points\n        # TODO 2: Find indices of K nearest neighbors\n        # TODO 3: Get class labels of K nearest neighbors\n        # TODO 4: Apply voting strategy (majority or weighted)\n        # TODO 5: Calculate confidence score\n        # TODO 6: Return PredictionResult with all information\n        # Hint: Use the distance_metrics module for distance calculations\n        pass\n```\n\n**Distance Metrics Module (Skeleton for Implementation)**\n\n```python\n# src/distance_metrics.py\nimport numpy as np\nfrom .data_types import FeatureVector, FeatureMatrix, DistanceArray, DistanceMetric\n\ndef calculate_distance(point1: FeatureVector, point2: FeatureVector, \n                      metric: DistanceMetric) -> float:\n    \"\"\"Calculate distance between two points using specified metric.\"\"\"\n    # TODO 1: Validate that both points have same dimensionality\n    # TODO 2: Dispatch to appropriate distance function based on metric\n    # TODO 3: Return computed distance value\n    # Hint: Use a dictionary to map DistanceMetric enum values to functions\n    pass\n\ndef calculate_distances_vectorized(query_point: FeatureVector, \n                                 training_data: FeatureMatrix,\n                                 metric: DistanceMetric) -> DistanceArray:\n    \"\"\"Calculate distances from query point to all training points efficiently.\"\"\"\n    # TODO 1: Validate input dimensions\n    # TODO 2: Use vectorized NumPy operations for efficiency\n    # TODO 3: Handle different distance metrics with appropriate formulas\n    # TODO 4: Return array of distances with same length as training_data rows\n    # Hint: Avoid Python loops - use NumPy broadcasting for vectorization\n    pass\n\ndef euclidean_distance(point1: FeatureVector, point2: FeatureVector) -> float:\n    \"\"\"Compute Euclidean (L2) distance between two points.\"\"\"\n    # TODO 1: Calculate squared differences for each dimension\n    # TODO 2: Sum the squared differences\n    # TODO 3: Take square root of the sum\n    # TODO 4: Handle edge case where points are identical (distance = 0)\n    # Hint: np.sqrt(np.sum((point1 - point2) ** 2))\n    pass\n\ndef manhattan_distance(point1: FeatureVector, point2: FeatureVector) -> float:\n    \"\"\"Compute Manhattan (L1) distance between two points.\"\"\"\n    # TODO 1: Calculate absolute differences for each dimension\n    # TODO 2: Sum the absolute differences\n    # TODO 3: Return the sum\n    # Hint: np.sum(np.abs(point1 - point2))\n    pass\n\ndef cosine_similarity(point1: FeatureVector, point2: FeatureVector) -> float:\n    \"\"\"Compute cosine similarity between two points (returns distance = 1 - similarity).\"\"\"\n    # TODO 1: Calculate dot product of the two vectors\n    # TODO 2: Calculate L2 norms (magnitudes) of both vectors\n    # TODO 3: Compute cosine similarity = dot_product / (norm1 * norm2)\n    # TODO 4: Convert to distance by returning 1 - similarity\n    # TODO 5: Handle edge case where one or both vectors have zero norm\n    # Hint: Use np.dot() and np.linalg.norm()\n    pass\n```\n\n**E. Language-Specific Hints**\n\n**NumPy Optimization Tips:**\n- Use `np.linalg.norm()` for efficient vector magnitude calculations\n- Leverage NumPy broadcasting to avoid explicit loops when computing distances to multiple points\n- Use `np.argsort()` to find indices of K smallest distances without fully sorting the array\n- Apply `np.bincount()` for efficient majority vote counting when labels are integers\n\n**Error Handling Patterns:**\n- Always validate array shapes before mathematical operations: `assert X.shape[1] == self.training_data.n_features`\n- Check for empty datasets: `if self.training_data.n_samples == 0: raise ValueError(\"No training data\")`\n- Validate K parameter: `if k > self.training_data.n_samples: raise ValueError(f\"k={k} larger than dataset size\")`\n\n**Memory Efficiency:**\n- For large datasets, consider computing distances in batches rather than storing full distance matrix\n- Use `dtype=np.float32` instead of default `np.float64` if precision allows for memory savings\n\n**F. Milestone Checkpoints**\n\n**After Milestone 1 (Distance Calculation):**\n```bash\n# Test distance calculations\npython -m pytest tests/test_distance_metrics.py -v\n\n# Manual verification\npython -c \"\nfrom src.distance_metrics import euclidean_distance, manhattan_distance\nimport numpy as np\np1 = np.array([0, 0])\np2 = np.array([3, 4])\nprint(f'Euclidean: {euclidean_distance(p1, p2)}')  # Should be 5.0\nprint(f'Manhattan: {manhattan_distance(p1, p2)}')  # Should be 7.0\n\"\n```\n\n**Expected output:** Distance functions return correct mathematical values for simple test cases.\n\n**After Milestone 2 (KNN Classification):**\n```bash\n# Test full classification pipeline\npython examples/iris_classification.py\n\n# Expected: Accuracy around 95-100% on iris dataset with proper train/test split\n```\n\n**After Milestone 3 (Evaluation and Optimization):**\n```bash\n# Test cross-validation and hyperparameter tuning\npython -c \"\nfrom src.evaluation import cross_validate, find_optimal_k\n# Should complete without errors and show k-fold results\n\"\n```\n\n**G. Common Implementation Pitfalls**\n\n| Pitfall | Symptom | Cause | Fix |\n|---------|---------|-------|-----|\n| All predictions same class | Low accuracy, confusion matrix shows single class | K too large, using majority of dataset | Validate K < n_samples/2, try smaller K values |\n| Slow distance calculation | Long prediction times | Using Python loops instead of vectorization | Replace loops with NumPy broadcasting operations |\n| NaN in distance calculations | Runtime errors or infinite distances | Division by zero in cosine distance | Add epsilon to denominators, check for zero-norm vectors |\n| Memory errors on large datasets | Out of memory crashes | Computing full distance matrix | Implement batch processing for distance calculations |\n| Inconsistent predictions | Same input gives different outputs | Non-deterministic tie breaking | Implement consistent tie-breaking strategy (e.g., smallest index wins) |\n\n\n## High-Level Architecture\n\n> **Milestone(s):** Foundational architecture for all milestones - establishes the component structure for distance calculation (Milestone 1), neighbor finding and classification (Milestone 2), and evaluation systems (Milestone 3)\n\n### Mental Model: The Recommendation System Architecture\n\nThink of the KNN classifier like a sophisticated recommendation system at a bookstore. When a customer asks for book recommendations, the system follows a clear pipeline: first, it measures how similar the customer is to previous customers using various criteria (distance calculation component); then, it finds the most similar customers (neighbor finding component); finally, it looks at what those similar customers liked and makes a recommendation based on their preferences (classification component). An additional evaluation system tracks how well these recommendations work over time and tunes the system for better performance.\n\nThis bookstore analogy maps directly to our KNN architecture: **distance calculation** measures similarity between data points, **neighbor finding** locates the most relevant training examples, **classification** aggregates their labels into predictions, and **evaluation** measures and optimizes system performance. Each component has a distinct responsibility but works together through a carefully orchestrated data flow.\n\n![System Component Architecture](./diagrams/system-components.svg)\n\nThe key architectural insight is that KNN follows the **lazy learning** paradigm - unlike algorithms that build complex models during training, KNN simply stores training data and defers all computation until prediction time. This creates a unique architecture where the \"training\" component is trivial (just data storage) while the prediction pipeline does all the heavy lifting through distance calculations, neighbor searches, and voting mechanisms.\n\n### Component Overview\n\nThe KNN classifier system consists of four primary components that work together to implement **instance-based learning**. Each component has a focused responsibility and well-defined interfaces that enable clean separation of concerns while supporting the overall classification pipeline.\n\n| Component | Primary Responsibility | Key Data Inputs | Key Data Outputs | Performance Characteristics |\n|-----------|------------------------|------------------|------------------|----------------------------|\n| **Distance Calculator** | Compute similarity metrics between feature vectors | `FeatureVector` pairs, `DistanceMetric` enum | `DistanceArray`, distance matrices | O(d) per pair where d = dimensions |\n| **Neighbor Finder** | Locate K most similar training examples | Query `FeatureVector`, `TrainingData`, K parameter | `NeighborIndices`, `DistanceArray` | O(n) linear search, O(log n) with spatial indexing |\n| **Classifier** | Make predictions through voting mechanisms | `NeighborIndices`, neighbor labels, voting strategy | `ClassLabel`, `PredictionResult` with confidence | O(K) for voting, O(C) where C = number of classes |\n| **Evaluator** | Assess model performance and optimize hyperparameters | Predictions, ground truth labels, cross-validation folds | Accuracy metrics, confusion matrices, optimal K | O(F×N) where F = folds, N = samples |\n\n#### Distance Calculator Component\n\nThe Distance Calculator serves as the foundation of the entire KNN system by implementing various similarity metrics that quantify how \"close\" two data points are in feature space. This component embodies the **smoothness assumption** that underlies KNN - the principle that similar inputs should produce similar outputs.\n\nThe component supports multiple distance metrics through a unified interface, allowing the system to adapt to different types of data and problem domains. **Euclidean distance** works well for continuous numerical features, **Manhattan distance** is robust to outliers and effective for high-dimensional sparse data, while **cosine similarity** excels with text and normalized feature vectors where magnitude is less important than direction.\n\nThe architectural challenge here is achieving computational efficiency through **vectorized operations**. Rather than computing distances one pair at a time using Python loops, the component leverages NumPy's broadcasting capabilities to compute entire distance matrices in single operations. This transforms an O(n²d) nested loop computation into an O(nd) vectorized operation followed by O(n²) element-wise operations that run at C speed.\n\n#### Neighbor Finder Component\n\nThe Neighbor Finder component takes distance calculations and efficiently locates the K most similar training examples for each query point. This component implements the core search algorithms that determine both the accuracy and performance characteristics of the entire KNN system.\n\nAt its simplest, the component performs linear search through all training examples, computing distances and maintaining a sorted list of the K closest neighbors. However, this O(n) per-query complexity becomes prohibitive for large datasets, motivating more sophisticated spatial indexing approaches like KD-trees that can reduce search complexity to O(log n) in favorable conditions.\n\nThe component must handle several edge cases that frequently trip up implementations: what happens when K is larger than the dataset size, how to break ties when multiple neighbors have identical distances, and how to efficiently maintain the K-nearest list during search without expensive sorting operations. These design decisions significantly impact both correctness and performance.\n\n#### Classifier Component\n\nThe Classifier component implements the democratic decision-making process that transforms a set of neighbor labels into a final prediction. This component embodies the core assumption of KNN that local neighborhoods provide reliable information about class boundaries in feature space.\n\nThe component supports two primary voting strategies. **Majority voting** gives each of the K neighbors an equal voice in the classification decision, essentially implementing a local democracy where the most frequent class wins. **Weighted voting** provides a more nuanced approach where closer neighbors have proportionally more influence on the final decision, implemented through inverse distance weighting or similar schemes.\n\nBeyond simple classification, this component also computes confidence metrics that indicate how certain the prediction is. A unanimous vote among neighbors indicates high confidence, while a close split suggests the query point lies near a class boundary. This confidence information proves invaluable for understanding model behavior and identifying uncertain predictions that might require human review.\n\n#### Evaluator Component\n\nThe Evaluator component provides the scientific rigor necessary to assess model performance and optimize hyperparameters. This component implements cross-validation procedures that provide unbiased estimates of generalization performance and systematic hyperparameter optimization that finds the best K value for a given dataset.\n\nThe component's **K-fold cross-validation** implementation carefully partitions data into training and validation folds while ensuring that each sample appears in exactly one validation fold. This provides robust performance estimates that account for dataset variance and help detect overfitting or underfitting behaviors that might not be apparent from simple train-test splits.\n\nHyperparameter optimization within this component addresses the fundamental **bias-variance tradeoff** in KNN models. Small K values create high-variance, low-bias models that can capture fine-grained class boundaries but may overfit to noise. Large K values create low-variance, high-bias models that provide smooth decision boundaries but may underfit complex patterns. The evaluator systematically tests different K values to find the sweet spot for each specific dataset.\n\n### Recommended Module Structure\n\nA well-organized module structure helps manage the complexity of the KNN system while providing clear interfaces between components. The structure follows standard Python packaging conventions while grouping related functionality and separating concerns.\n\n```\nknn_classifier/\n├── __init__.py                     # Package initialization and public API exports\n├── core/\n│   ├── __init__.py\n│   ├── data_types.py              # Core data structures: FeatureVector, TrainingData, etc.\n│   └── enums.py                   # Enumerations: DistanceMetric, VotingStrategy\n├── distance/\n│   ├── __init__.py\n│   ├── base.py                    # Abstract base class for distance metrics\n│   ├── euclidean.py              # Euclidean distance implementation\n│   ├── manhattan.py              # Manhattan distance implementation\n│   └── cosine.py                 # Cosine similarity implementation\n├── neighbors/\n│   ├── __init__.py\n│   ├── base.py                   # Abstract base class for neighbor finders\n│   ├── linear_search.py          # Brute-force linear search implementation\n│   └── spatial_index.py          # KD-tree and advanced indexing (future extension)\n├── classification/\n│   ├── __init__.py\n│   ├── base.py                   # Abstract classifier interface\n│   ├── knn_classifier.py         # Main KNNClassifier implementation\n│   └── voting.py                 # Voting strategy implementations\n├── evaluation/\n│   ├── __init__.py\n│   ├── metrics.py                # Accuracy, precision, recall, F1-score calculations\n│   ├── cross_validation.py       # K-fold cross-validation implementation\n│   └── optimization.py           # Hyperparameter optimization routines\n├── utils/\n│   ├── __init__.py\n│   ├── data_loader.py            # Dataset loading utilities (iris, synthetic data)\n│   └── preprocessing.py          # Feature scaling and preprocessing utilities\n└── examples/\n    ├── basic_classification.py   # Simple KNN usage example\n    ├── cross_validation_demo.py  # Cross-validation and optimization example\n    └── distance_comparison.py    # Comparison of different distance metrics\n```\n\nThis modular structure provides several key benefits for learners and maintainers. Each module has a single, well-defined responsibility, making it easier to understand, test, and modify individual components. The abstract base classes in each module establish clear contracts that enable easy extension with new distance metrics, search algorithms, or voting strategies.\n\nThe separation between core data types and algorithmic components allows the data structures to evolve independently of the algorithms that use them. This proves particularly valuable when optimizing performance or adding new features that require additional fields in the data structures.\n\n> **Design Insight**: The module structure mirrors the conceptual architecture, making the codebase intuitive to navigate. Each major component from our architecture diagram corresponds directly to a Python package, and the flow of data between components is reflected in the import dependencies between modules.\n\n### Data Flow Architecture\n\nThe data flow through the KNN system follows a clear pipeline from training data ingestion through final prediction output. Understanding this flow is crucial for implementing each component correctly and optimizing overall system performance.\n\n#### Training Phase Data Flow\n\nThe training phase in KNN is deceptively simple due to the **lazy learning** nature of the algorithm. Unlike parametric models that extract patterns and parameters during training, KNN simply stores the training data for later use during prediction.\n\n| Step | Component | Input Data | Processing | Output Data | Storage Location |\n|------|-----------|------------|------------|-------------|------------------|\n| 1 | Data Loader | Raw dataset files | Parse and validate data format | `FeatureMatrix`, label array | Memory |\n| 2 | Preprocessor | `FeatureMatrix`, labels | Feature scaling, validation | Scaled `FeatureMatrix`, `ClassLabel` list | Memory |\n| 3 | KNN Classifier | Scaled features, labels | Create `TrainingData` container | `TrainingData` object | `KNNClassifier.training_data` |\n| 4 | Distance Calculator | `TrainingData` | Pre-compute distance matrix (optional) | `DistanceMatrix` | Cache or disk |\n\nThe key insight is that the \"training\" phase primarily involves data validation and storage rather than complex model fitting. The `fit` method validates that features and labels have compatible shapes, checks for missing values, stores the training data in an efficient format, and optionally pre-computes distance matrices for performance optimization.\n\n```python\ndef fit(X: FeatureMatrix, y: List[ClassLabel]) -> None:\n    \"\"\"Store training data for lazy learning approach.\n    \n    This method performs minimal computation since KNN defers\n    all learning until prediction time.\n    \"\"\"\n    # Validation and storage steps - implementation in guidance section\n```\n\n#### Prediction Phase Data Flow\n\nThe prediction phase contains the computational heart of the KNN algorithm, where all the distance calculations, neighbor finding, and classification voting occur. This phase demonstrates the true complexity hidden behind KNN's conceptual simplicity.\n\n| Step | Component | Input Data | Processing | Output Data | Complexity |\n|------|-----------|------------|------------|-------------|------------|\n| 1 | Query Processing | Query `FeatureMatrix` | Validate dimensions, apply same scaling | Preprocessed queries | O(Q×D) |\n| 2 | Distance Calculator | Query point, `TrainingData` | Compute distances to all training points | `DistanceArray` | O(Q×N×D) |\n| 3 | Neighbor Finder | `DistanceArray`, K parameter | Find K smallest distances and indices | `NeighborIndices`, neighbor distances | O(Q×N log K) |\n| 4 | Classifier | `NeighborIndices`, neighbor labels | Apply voting strategy | `PredictionResult` | O(Q×K) |\n| 5 | Output Formatter | `PredictionResult` | Extract final predictions | `List[ClassLabel]` | O(Q) |\n\nWhere Q = number of query points, N = number of training points, D = number of dimensions, K = number of neighbors.\n\nThe prediction data flow reveals why KNN can be computationally expensive at prediction time. For each query point, the system must compute distances to every training point, sort these distances to find the K nearest neighbors, and then aggregate their labels. This O(Q×N×D) complexity motivates the need for spatial indexing structures in production systems with large training sets.\n\n#### Cross-Validation Data Flow\n\nThe evaluation phase implements a more complex data flow that involves systematic partitioning of data and repeated training/validation cycles to provide robust performance estimates.\n\n| Phase | Component | Input | Processing | Output | Iterations |\n|-------|-----------|-------|------------|--------|-----------| \n| Setup | Cross Validator | Full dataset, K-folds parameter | Partition data into K equal folds | List of (train, validation) splits | 1×K splits |\n| Training Loop | KNN Classifier | Training fold data | Fit model on training fold | Trained classifier instance | K iterations |\n| Validation Loop | Prediction Pipeline | Validation fold, trained model | Run full prediction pipeline | Predictions for validation fold | K iterations |\n| Metric Calculation | Evaluator | Predictions, ground truth labels | Compute accuracy, precision, recall, F1 | Performance metrics per fold | K iterations |\n| Aggregation | Evaluator | Metrics from all folds | Average metrics across folds | Final performance estimates | 1 aggregation |\n\nThis cross-validation flow ensures that every data point appears in exactly one validation fold while being used for training in all other folds. The systematic partitioning provides unbiased performance estimates that generalize better than simple train-test splits.\n\n#### Hyperparameter Optimization Data Flow\n\nThe most complex data flow occurs during hyperparameter optimization, where cross-validation is repeated for multiple K values to find the optimal configuration.\n\n```\nFor each K in [1, 3, 5, 7, 9, 11, 15, 21, 31]:\n    └── Run complete K-fold cross-validation pipeline\n        ├── Split data into K folds  \n        ├── For each fold:\n        │   ├── Train KNN with current K parameter\n        │   ├── Validate on held-out fold\n        │   └── Record performance metrics\n        └── Average metrics across all folds\nSelect K with highest average validation accuracy\n```\n\nThis nested loop structure means that hyperparameter optimization has O(H×F×N) complexity where H = number of hyperparameter values tested, F = number of cross-validation folds, and N = cost of training and evaluating each model. Understanding this complexity helps explain why hyperparameter optimization can be time-consuming and motivates careful selection of the hyperparameter search space.\n\n> **Performance Insight**: The data flow analysis reveals that distance calculation is the primary computational bottleneck in KNN systems. Optimizing this component through vectorized operations, efficient distance metrics, or spatial indexing provides the highest impact on overall system performance.\n\n### Implementation Guidance\n\nThis section provides concrete implementation guidance to bridge the gap between the architectural design and working code.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option | Rationale |\n|-----------|---------------|-----------------|-----------|\n| Numerical Computing | NumPy arrays + basic operations | NumPy + SciPy sparse matrices | NumPy sufficient for dense data, SciPy for high-dimensional sparse features |\n| Distance Computation | Pure NumPy broadcasting | scikit-learn distance metrics | NumPy teaches fundamentals, sklearn optimized for production |\n| Data Storage | Python lists/dicts | pandas DataFrame + HDF5 | Simple structures for learning, pandas for larger datasets |\n| Spatial Indexing | Linear search | scikit-learn BallTree/KDTree | Linear search for understanding, spatial indexing for performance |\n| Testing Framework | pytest | pytest + hypothesis | pytest for standard tests, hypothesis for property-based testing |\n\n#### Recommended File Structure\n\nThe following directory structure organizes the KNN implementation into logical modules that mirror the component architecture:\n\n```python\nknn_classifier/\n├── __init__.py                     # Public API exports\n├── core/\n│   ├── __init__.py\n│   └── data_types.py              # FeatureVector, TrainingData, PredictionResult\n├── distance/\n│   ├── __init__.py\n│   └── metrics.py                 # Distance calculation implementations  \n├── neighbors/\n│   ├── __init__.py\n│   └── finder.py                  # Neighbor search implementations\n├── classification/\n│   ├── __init__.py\n│   └── classifier.py              # KNNClassifier and voting logic\n├── evaluation/\n│   ├── __init__.py\n│   └── validator.py               # Cross-validation and metrics\n└── utils/\n    ├── __init__.py\n    └── datasets.py                # Data loading utilities\n```\n\n#### Core Data Types (Complete Implementation)\n\n```python\n# core/data_types.py\nfrom typing import Union, List, Tuple, Optional\nfrom enum import Enum\nimport numpy as np\n\n# Type aliases for clarity\nFeatureVector = np.ndarray  # 1D array representing single sample features\nFeatureMatrix = np.ndarray  # 2D array where each row is a FeatureVector\nClassLabel = Union[int, str]  # Flexible label types\nDistanceArray = np.ndarray  # 1D array of distance values\nNeighborIndices = np.ndarray  # 1D array of indices into training data\n\nclass DistanceMetric(Enum):\n    \"\"\"Supported distance metrics for KNN classification.\"\"\"\n    EUCLIDEAN = \"euclidean\"\n    MANHATTAN = \"manhattan\" \n    COSINE = \"cosine\"\n\nclass TrainingData:\n    \"\"\"Container for training dataset with metadata.\"\"\"\n    \n    def __init__(self, features: FeatureMatrix, labels: List[ClassLabel]):\n        self.features = features\n        self.labels = np.array(labels)\n        self.n_samples, self.n_features = features.shape\n        self.unique_classes = np.unique(labels)\n        \n    def get_sample(self, index: int) -> Tuple[FeatureVector, ClassLabel]:\n        \"\"\"Retrieve a single training example by index.\"\"\"\n        return self.features[index], self.labels[index]\n\nclass PredictionResult:\n    \"\"\"Comprehensive prediction result with confidence information.\"\"\"\n    \n    def __init__(self, predicted_class: ClassLabel, \n                 neighbor_indices: NeighborIndices,\n                 neighbor_distances: DistanceArray,\n                 confidence: float):\n        self.predicted_class = predicted_class\n        self.neighbor_indices = neighbor_indices\n        self.neighbor_distances = neighbor_distances\n        self.confidence = confidence\n```\n\n#### KNNClassifier Skeleton (Core Learning Component)\n\n```python\n# classification/classifier.py\nfrom ..core.data_types import *\n\nclass KNNClassifier:\n    \"\"\"K-Nearest Neighbors classifier implementation.\"\"\"\n    \n    def __init__(self, k: int = 3, distance_metric: DistanceMetric = DistanceMetric.EUCLIDEAN, \n                 weighted_voting: bool = False):\n        self.k = k\n        self.distance_metric = distance_metric\n        self.weighted_voting = weighted_voting\n        self.training_data: Optional[TrainingData] = None\n        \n    def fit(self, X: FeatureMatrix, y: List[ClassLabel]) -> None:\n        \"\"\"Store training data for lazy learning approach.\"\"\"\n        # TODO 1: Validate that X and y have compatible shapes\n        # TODO 2: Check for missing values or invalid data\n        # TODO 3: Create TrainingData object and store in self.training_data\n        # TODO 4: Validate that k <= number of training samples\n        # Hint: This is lazy learning - no complex model fitting required!\n        pass\n        \n    def predict(self, X: FeatureMatrix) -> List[ClassLabel]:\n        \"\"\"Predict class labels for query points.\"\"\"\n        # TODO 1: Validate that model has been fitted (training_data exists)\n        # TODO 2: Check that query features have same dimensionality as training\n        # TODO 3: For each query point, call predict_with_confidence\n        # TODO 4: Extract just the predicted_class from each PredictionResult\n        # TODO 5: Return list of predicted class labels\n        pass\n        \n    def predict_with_confidence(self, X: FeatureMatrix) -> List[PredictionResult]:\n        \"\"\"Predict with detailed neighbor and confidence information.\"\"\"\n        results = []\n        for query_point in X:\n            # TODO 1: Compute distances from query_point to all training points\n            # TODO 2: Find indices of K nearest neighbors\n            # TODO 3: Get the class labels of these K neighbors\n            # TODO 4: Apply voting strategy (majority or weighted)\n            # TODO 5: Compute confidence score\n            # TODO 6: Create PredictionResult object\n            # TODO 7: Add result to results list\n            pass\n        return results\n```\n\n#### Distance Calculation Infrastructure (Complete Implementation)\n\n```python\n# distance/metrics.py\nimport numpy as np\nfrom ..core.data_types import FeatureVector, DistanceArray, DistanceMetric\n\ndef euclidean_distance(point1: FeatureVector, point2: FeatureVector) -> float:\n    \"\"\"Compute Euclidean (L2) distance between two points.\"\"\"\n    diff = point1 - point2\n    return np.sqrt(np.sum(diff ** 2))\n\ndef manhattan_distance(point1: FeatureVector, point2: FeatureVector) -> float:\n    \"\"\"Compute Manhattan (L1) distance between two points.\"\"\" \n    diff = np.abs(point1 - point2)\n    return np.sum(diff)\n\ndef cosine_similarity(point1: FeatureVector, point2: FeatureVector) -> float:\n    \"\"\"Compute cosine similarity (returns 1 - similarity for distance).\"\"\"\n    dot_product = np.dot(point1, point2)\n    norm1 = np.linalg.norm(point1)\n    norm2 = np.linalg.norm(point2)\n    \n    if norm1 == 0 or norm2 == 0:\n        return 1.0  # Maximum distance for zero vectors\n        \n    similarity = dot_product / (norm1 * norm2)\n    return 1.0 - similarity  # Convert similarity to distance\n\ndef compute_distances(query_point: FeatureVector, training_data: 'TrainingData', \n                     metric: DistanceMetric) -> DistanceArray:\n    \"\"\"Compute distances from query point to all training points using vectorized operations.\"\"\"\n    if metric == DistanceMetric.EUCLIDEAN:\n        # Vectorized Euclidean distance computation\n        diff = training_data.features - query_point\n        distances = np.sqrt(np.sum(diff ** 2, axis=1))\n    elif metric == DistanceMetric.MANHATTAN:\n        # Vectorized Manhattan distance computation  \n        diff = np.abs(training_data.features - query_point)\n        distances = np.sum(diff, axis=1)\n    elif metric == DistanceMetric.COSINE:\n        # Vectorized cosine distance computation\n        dot_products = np.dot(training_data.features, query_point)\n        query_norm = np.linalg.norm(query_point)\n        training_norms = np.linalg.norm(training_data.features, axis=1)\n        \n        # Handle zero vectors\n        valid_mask = (training_norms != 0) & (query_norm != 0)\n        similarities = np.zeros(len(training_data.features))\n        similarities[valid_mask] = (dot_products[valid_mask] / \n                                  (training_norms[valid_mask] * query_norm))\n        distances = 1.0 - similarities\n    else:\n        raise ValueError(f\"Unsupported distance metric: {metric}\")\n        \n    return distances\n```\n\n#### Dataset Utilities (Complete Implementation)\n\n```python\n# utils/datasets.py\nimport numpy as np\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom typing import Tuple\n\ndef load_iris_dataset() -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Load the classic Iris classification dataset.\"\"\"\n    iris = load_iris()\n    return iris.data, iris.target\n\ndef split_and_scale_data(X: np.ndarray, y: np.ndarray, \n                        test_size: float = 0.2, \n                        scale_features: bool = True,\n                        random_state: int = 42) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Split data into train/test sets and optionally apply feature scaling.\"\"\"\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=test_size, random_state=random_state, stratify=y\n    )\n    \n    if scale_features:\n        scaler = StandardScaler()\n        X_train = scaler.fit_transform(X_train)\n        X_test = scaler.transform(X_test)\n    \n    return X_train, X_test, y_train, y_test\n```\n\n#### Milestone Checkpoints\n\n**After Milestone 1 (Distance Calculation):**\n```python\n# Test basic distance calculation\nfrom knn_classifier.distance.metrics import euclidean_distance, manhattan_distance\nimport numpy as np\n\npoint1 = np.array([1, 2, 3])\npoint2 = np.array([4, 5, 6])\n\neuclidean = euclidean_distance(point1, point2)  # Should be ~5.196\nmanhattan = manhattan_distance(point1, point2)  # Should be 9\n\nprint(f\"Euclidean: {euclidean:.3f}, Manhattan: {manhattan}\")\n# Expected output: Euclidean: 5.196, Manhattan: 9\n```\n\n**After Milestone 2 (Basic Classification):**\n```python\n# Test full classification pipeline\nfrom knn_classifier.utils.datasets import load_iris_dataset, split_and_scale_data\nfrom knn_classifier.classification.classifier import KNNClassifier\n\nX, y = load_iris_dataset()\nX_train, X_test, y_train, y_test = split_and_scale_data(X, y)\n\nknn = KNNClassifier(k=3)\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test)\naccuracy = np.mean(predictions == y_test)\n\nprint(f\"Accuracy: {accuracy:.3f}\")\n# Expected: Accuracy should be > 0.90 for Iris dataset\n```\n\n#### Language-Specific Implementation Hints\n\n**NumPy Performance Tips:**\n- Use `np.sum(axis=1)` instead of Python loops for row-wise operations\n- Leverage broadcasting: `training_data.features - query_point` automatically handles shape differences\n- Use `np.argsort()` to get sorted indices without full sorting: `np.argsort(distances)[:k]`\n- Pre-allocate arrays when possible: `results = np.zeros(len(queries))`\n\n**Memory Management:**\n- For large datasets, compute distances in batches to avoid memory issues\n- Use `dtype=np.float32` instead of `np.float64` if precision allows (50% memory reduction)\n- Consider using `np.memmap` for datasets larger than available RAM\n\n**Common Python Gotchas:**\n- Always use `np.array()` to convert lists to NumPy arrays before mathematical operations\n- Check array shapes with `.shape` when debugging unexpected broadcasting errors\n- Use `np.allclose()` for floating-point comparisons instead of `==`\n\n\n## Data Model\n\n> **Milestone(s):** Core data representation for all milestones - defines feature vectors and training data for distance calculation (Milestone 1), neighbor indices and distance arrays for KNN classification (Milestone 2), and prediction results with confidence scores for evaluation and optimization (Milestone 3)\n\n### Mental Model: The Filing Cabinet System\n\nThink of the KNN data model as a sophisticated filing cabinet system in a library's recommendation service. Each book (training sample) has a **feature card** (`FeatureVector`) listing its characteristics - genre ratings, page count, complexity score, etc. The entire collection of feature cards forms the **master catalog** (`FeatureMatrix`), while each book also has a **category label** (`ClassLabel`) like \"mystery\", \"romance\", or \"science fiction\".\n\nWhen someone asks for a recommendation, the librarian doesn't reorganize the entire collection or build complex models. Instead, they maintain a **distance ledger** (`DistanceArray`) showing how similar the requested book is to every book in the collection. They then create a **recommendation list** (`NeighborIndices`) of the closest matches and deliver a **final recommendation** (`PredictionResult`) that includes not just the suggested category, but also which specific books influenced the decision and how confident they are in the recommendation.\n\nThis lazy learning approach means the filing cabinet stores everything exactly as received, deferring all computation until someone actually needs a recommendation. The data structures must efficiently support this deferred computation while maintaining the relationships between features, distances, neighbors, and predictions.\n\n### Core Data Types\n\nThe foundation of our KNN classifier rests on five core data types that represent the essential mathematical concepts of instance-based learning. These types must efficiently support vectorized operations while maintaining type safety and clear semantic meaning.\n\n![Data Model Relationships](./diagrams/data-model.svg)\n\nA `FeatureVector` represents a single sample's characteristics as a one-dimensional NumPy array of floating-point values. Each position in the vector corresponds to a specific feature dimension - for example, in the classic Iris dataset, positions 0-3 might represent sepal length, sepal width, petal length, and petal width respectively. The vector must maintain consistent dimensionality across all samples to ensure meaningful distance calculations.\n\nThe `FeatureMatrix` extends this concept to represent an entire dataset as a two-dimensional NumPy array where each row is a `FeatureVector`. This row-major organization aligns with NumPy's memory layout and enables efficient vectorized operations across samples. The matrix shape (n_samples, n_features) provides immediate access to dataset dimensions without separate tracking variables.\n\nA `ClassLabel` uses Python's Union typing to support both integer and string class identifiers, accommodating datasets with numeric labels (0, 1, 2) and categorical labels (\"setosa\", \"versicolor\", \"virginica\"). This flexibility allows the same classifier to work with diverse datasets without preprocessing label formats.\n\nDistance calculations produce a `DistanceArray` - a one-dimensional NumPy array containing floating-point distance values between a query point and all training samples. The array maintains the same ordering as the training data, enabling direct indexing from distances back to the corresponding training samples.\n\nThe `NeighborIndices` array stores integer indices that reference specific rows in the training data. After computing distances and finding the K nearest neighbors, this array contains the row indices of the selected neighbors in order of increasing distance. These indices serve as the bridge between distance calculations and the actual training samples needed for classification voting.\n\n| Type | Base Type | Shape/Format | Purpose |\n|------|-----------|--------------|---------|\n| `FeatureVector` | np.ndarray(dtype=float64) | (n_features,) | Single sample's feature values |\n| `FeatureMatrix` | np.ndarray(dtype=float64) | (n_samples, n_features) | Complete dataset feature matrix |\n| `ClassLabel` | Union[int, str] | Scalar value | Class identifier for training/prediction |\n| `DistanceArray` | np.ndarray(dtype=float64) | (n_distances,) | Distance values from query to training samples |\n| `NeighborIndices` | np.ndarray(dtype=int32) | (k,) | Indices of K nearest training samples |\n\n> **Design Insight**: The choice of float64 for all numeric arrays prevents precision loss during distance calculations, especially important for euclidean distance where we sum squared differences that could quickly overflow float32 precision. Integer indices use int32 to support datasets up to 2 billion samples while maintaining memory efficiency.\n\n### Internal Data Structures\n\nThe KNN classifier requires three sophisticated internal data structures that manage the complete lifecycle from training data storage through prediction result delivery. These structures encapsulate not just raw data but also derived metadata that accelerates common operations.\n\nThe `TrainingData` container serves as the central repository for all information about the training dataset. Beyond storing the feature matrix and corresponding labels, it maintains derived metadata including the number of samples, number of features, and the set of unique classes present in the training data. This metadata enables immediate validation of query dimensions and provides the class universe for voting operations.\n\nThe training data container must support efficient random access to individual samples through the `get_sample` method while maintaining memory efficiency for large datasets. It also tracks data consistency - ensuring that the number of feature vectors exactly matches the number of labels and that all feature vectors have identical dimensionality.\n\nA `PredictionResult` represents the complete output of the KNN classification process for a single query point. Unlike simple classification algorithms that return only a class label, KNN predictions include rich context about how the decision was made. The predicted class comes from the voting process, while the neighbor indices and distances provide full transparency into which training samples influenced the decision and how strongly.\n\nThe confidence score quantifies the algorithm's certainty in the prediction, typically calculated as the proportion of neighbors that voted for the winning class. For weighted voting, confidence incorporates the distance-based weights to provide a more nuanced measure of prediction reliability.\n\nThe `KNNClassifier` itself serves as the primary data structure coordinating all other components. It encapsulates the hyperparameters (K value, distance metric, voting strategy) alongside the training data, providing a complete specification of the classifier's behavior. The lazy learning nature means the classifier stores training data without modification, deferring all computation until prediction time.\n\n| Structure | Fields | Type | Description |\n|-----------|--------|------|-------------|\n| `TrainingData` | features | FeatureMatrix | Complete training feature matrix |\n| | labels | List[ClassLabel] | Corresponding class labels |\n| | n_samples | int | Number of training samples |\n| | n_features | int | Number of feature dimensions |\n| | unique_classes | Set[ClassLabel] | Set of all possible class values |\n| `PredictionResult` | predicted_class | ClassLabel | Final classification decision |\n| | neighbor_indices | NeighborIndices | Indices of K nearest training samples |\n| | neighbor_distances | DistanceArray | Distances to each of the K neighbors |\n| | confidence | float | Prediction confidence score (0.0 to 1.0) |\n| `KNNClassifier` | k | int | Number of neighbors for classification |\n| | distance_metric | DistanceMetric | Distance function (EUCLIDEAN/MANHATTAN/COSINE) |\n| | weighted_voting | bool | Whether to use distance-weighted voting |\n| | training_data | Optional[TrainingData] | Stored training dataset (None before fitting) |\n\n> **Architecture Decision: Separate Training Data Container**\n> - **Context**: We could store training features and labels directly in the classifier or create a separate container\n> - **Options Considered**: Direct storage, separate TrainingData class, external data manager\n> - **Decision**: Separate TrainingData container class\n> - **Rationale**: Encapsulates data validation, provides clean interface for sample access, enables future optimizations like data preprocessing or indexing without changing classifier interface\n> - **Consequences**: Adds one additional class but significantly improves code organization and enables better testing of data management logic separately from classification logic\n\n| Design Option | Pros | Cons | Chosen? |\n|---------------|------|------|---------|\n| Direct storage in classifier | Simple, fewer classes | Mixing concerns, harder to test | No |\n| Separate TrainingData container | Clean separation, testable, extensible | Additional complexity | **Yes** |\n| External data manager | Maximum flexibility | Over-engineering for basic KNN | No |\n\n### Type Relationships and Data Flow\n\nThe KNN data model creates a sophisticated pipeline where each type transforms into the next through well-defined operations, supporting the fundamental lazy learning paradigm. Understanding these relationships is crucial for implementing correct and efficient KNN classification.\n\nThe transformation pipeline begins with raw training data entering as separate `FeatureMatrix` and label arrays through the `fit` method. The classifier immediately packages these into a `TrainingData` container, performing validation to ensure dimensional consistency and extracting metadata like unique classes and sample counts. This containerization provides a clean interface for all subsequent operations while encapsulating data integrity checks.\n\nDuring prediction, query points arrive as a `FeatureMatrix` where each row represents a sample to classify. The distance calculation component transforms each query `FeatureVector` and the entire training `FeatureMatrix` into a `DistanceArray` containing distances from the query to every training sample. This transformation is the computational heart of KNN, requiring efficient vectorized operations to avoid performance bottlenecks.\n\nThe neighbor finding component then transforms the `DistanceArray` into `NeighborIndices` by identifying the K smallest distances and extracting their corresponding array positions. This transformation requires careful handling of ties and edge cases where K exceeds the number of available training samples. The resulting indices serve as references back into the training data for the voting phase.\n\nClassification voting transforms the `NeighborIndices` into a `PredictionResult` by retrieving the corresponding class labels from the training data and applying either majority voting or weighted voting algorithms. This transformation produces not just the predicted class but also rich metadata about the decision process, including confidence scores and the complete neighbor information.\n\nThe type relationships embody important mathematical properties of the KNN algorithm. Distance calculations preserve the smoothness assumption - similar feature vectors produce similar distance values. The neighbor finding process maintains locality - the K nearest neighbors form a local neighborhood around the query point. The voting process implements the democratic principle - the local neighborhood determines the classification through collective decision-making.\n\n| Transformation | Input Types | Output Type | Operation | Key Properties |\n|----------------|-------------|-------------|-----------|----------------|\n| Training | FeatureMatrix, List[ClassLabel] | TrainingData | Data validation and packaging | Lazy storage, no preprocessing |\n| Distance Calculation | FeatureVector, TrainingData | DistanceArray | Vectorized distance computation | Preserves similarity relationships |\n| Neighbor Finding | DistanceArray | NeighborIndices | K-smallest selection with indexing | Maintains locality properties |\n| Classification | NeighborIndices, TrainingData | PredictionResult | Voting with confidence calculation | Democratic decision making |\n| Batch Prediction | FeatureMatrix | List[PredictionResult] | Repeated single predictions | Parallel processing opportunity |\n\nThe data flow architecture supports both single predictions and batch processing efficiently. Single predictions flow linearly through each transformation stage, while batch predictions can leverage vectorized operations and parallel processing where the distance calculations for multiple query points can proceed independently.\n\nMemory management considerations influence the type relationships significantly. The `TrainingData` persists throughout the classifier's lifetime, while `DistanceArray` and intermediate calculations exist only during prediction operations. This pattern minimizes memory overhead while supporting efficient computation.\n\n> **Design Insight**: The type transformation pipeline mirrors the mathematical structure of KNN classification - from high-dimensional feature spaces through distance metrics to discrete classification decisions. Each transformation preserves essential properties while reducing complexity for the next stage.\n\n### Data Validation and Consistency\n\nThe data model must enforce strict consistency rules to prevent subtle bugs that could compromise classification accuracy. These validation rules operate at multiple levels - from individual type construction through complete pipeline validation.\n\n`FeatureVector` validation ensures that all values are finite floating-point numbers, rejecting NaN or infinite values that would corrupt distance calculations. The vector must also maintain consistent dimensionality with the training data's feature space. Dimension mismatches between query and training features represent fundamental incompatibility that must be caught immediately.\n\n`FeatureMatrix` validation extends vector-level checks to ensure that all rows have identical dimensionality and that the matrix contains at least one sample. Empty feature matrices would cause division-by-zero errors in distance calculations and make classification impossible. The validation also verifies that the number of features matches the classifier's expectations from training.\n\n`ClassLabel` validation ensures that predicted labels belong to the set of classes seen during training. While KNN can theoretically encounter completely novel classes through its neighbors, the training data defines the universe of possible predictions. Labels outside this universe indicate either data corruption or fundamental dataset inconsistencies.\n\nDistance calculations require additional validation to prevent numerical instabilities. `DistanceArray` validation ensures that all distances are non-negative finite values. Negative distances violate mathematical properties of distance metrics, while infinite distances indicate computational overflow or invalid input data.\n\nThe `TrainingData` container enforces the most critical consistency requirements - that the number of feature vectors exactly equals the number of labels, that all feature vectors have identical dimensionality, and that at least one sample exists for each claimed unique class. These invariants must be established at construction time and maintained throughout the object's lifetime.\n\n| Validation Rule | Checked At | Failure Consequence | Recovery Strategy |\n|-----------------|------------|-------------------|-------------------|\n| Feature vectors finite | Input processing | Invalid distance calculations | Reject input with clear error |\n| Consistent dimensionality | Prediction time | Runtime dimension mismatch | Validate against training data |\n| Non-empty datasets | Training time | Division by zero, no neighbors | Require minimum sample count |\n| Label consistency | Result validation | Invalid predictions | Restrict to training label universe |\n| Non-negative distances | Distance calculation | Corrupted neighbor selection | Numerical stability checks |\n\n### Common Data Model Pitfalls\n\nUnderstanding the most frequent mistakes in KNN data model implementation helps prevent subtle bugs that can be extremely difficult to diagnose. These pitfalls often manifest as degraded accuracy rather than obvious crashes, making them particularly insidious.\n\n⚠️ **Pitfall: Mixed Feature Scaling**\nMany datasets contain features with vastly different scales - for example, age in years (0-100) and income in dollars (0-100,000). Without proper scaling, distance calculations become dominated by the high-magnitude features, effectively ignoring low-magnitude but potentially important features. The euclidean distance between points (25, 50000) and (30, 55000) is approximately 5000, entirely dominated by the income difference despite the age difference being proportionally significant. Always normalize features to similar scales before training, typically using standardization (zero mean, unit variance) or min-max scaling to [0,1] range.\n\n⚠️ **Pitfall: Integer Feature Precision**\nStoring feature data as integers instead of floating-point values creates precision loss during distance calculations that can alter neighbor rankings. Integer arithmetic cannot represent the fractional results of normalization or the intermediate calculations in distance metrics. Even if input features are integers, convert them to float64 arrays immediately to ensure numerical accuracy throughout the pipeline.\n\n⚠️ **Pitfall: Inconsistent Missing Value Handling**\nKNN algorithms cannot directly handle missing feature values since distance calculations require complete vectors. Inconsistent handling of missing values - sometimes dropping samples, sometimes imputing with zeros, sometimes using mean values - creates subtle dataset inconsistencies that degrade classification performance. Establish a consistent missing value strategy during data preprocessing and apply it uniformly to both training and query data.\n\n⚠️ **Pitfall: Memory Layout Inefficiency**\nNumPy arrays can have different memory layouts (C-contiguous vs Fortran-contiguous) that dramatically affect performance of vectorized operations. Feature matrices stored in Fortran layout force NumPy to perform expensive memory copying during row-wise distance calculations. Always ensure feature matrices use C-contiguous layout with `np.ascontiguousarray()` to enable efficient vectorized distance computations.\n\n⚠️ **Pitfall: Label Type Inconsistency**\nMixing different label types within the same dataset - some samples with integer labels, others with string labels - creates type confusion during prediction result construction. Python's dynamic typing allows this inconsistency to propagate deep into the classification pipeline before causing errors. Establish consistent label typing during training data construction and validate that all labels conform to the expected type.\n\n⚠️ **Pitfall: Neighbor Index Out-of-Bounds**\nWhen K exceeds the number of training samples, neighbor finding algorithms can generate invalid indices or return insufficient neighbors for voting. This edge case particularly affects small datasets or datasets with severe class imbalance where one class has fewer than K samples. Always validate that K is less than or equal to the total number of training samples and handle edge cases gracefully by reducing K or weighted voting by available neighbors.\n\n### Implementation Guidance\n\nThe data model implementation requires careful attention to NumPy array management, type safety, and memory efficiency. These recommendations provide a solid foundation for building reliable KNN classifiers.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Array Operations | NumPy with basic indexing | NumPy with advanced indexing + scipy.spatial |\n| Type Checking | Python type hints + runtime checks | mypy static analysis + pydantic validation |\n| Memory Management | Standard NumPy arrays | Memory-mapped arrays for large datasets |\n| Serialization | pickle for simple persistence | joblib for efficient numerical array storage |\n\n#### Recommended File Structure\n\nOrganize the data model components into logical modules that separate concerns and enable clear testing:\n\n```\nknn_classifier/\n  core/\n    data_types.py           ← Core type definitions and containers\n    validation.py           ← Data validation functions and error classes\n  datasets/\n    loaders.py             ← Dataset loading utilities (Iris, etc.)\n    preprocessing.py        ← Feature scaling and preprocessing\n  tests/\n    test_data_types.py     ← Unit tests for core data structures\n    test_validation.py     ← Validation logic tests\n    test_datasets.py       ← Dataset loading tests\n```\n\n#### Core Data Types Implementation\n\nHere's the complete implementation of the core data types that forms the foundation of your KNN classifier:\n\n```python\n\"\"\"\nCore data types for KNN classification.\n\nThis module defines the fundamental data structures used throughout the KNN\nclassifier implementation, providing type safety and efficient operations.\n\"\"\"\n\nimport numpy as np\nfrom typing import Union, List, Optional, Tuple, Set\nfrom enum import Enum\nfrom dataclasses import dataclass\n\n# Type aliases for clarity and consistency\nFeatureVector = np.ndarray  # Shape: (n_features,)\nFeatureMatrix = np.ndarray  # Shape: (n_samples, n_features)  \nClassLabel = Union[int, str]\nDistanceArray = np.ndarray  # Shape: (n_distances,)\nNeighborIndices = np.ndarray  # Shape: (k,)\n\nclass DistanceMetric(Enum):\n    \"\"\"Supported distance metrics for KNN classification.\"\"\"\n    EUCLIDEAN = \"euclidean\"\n    MANHATTAN = \"manhattan\"  \n    COSINE = \"cosine\"\n\n@dataclass\nclass TrainingData:\n    \"\"\"Container for training dataset with derived metadata.\"\"\"\n    features: FeatureMatrix\n    labels: List[ClassLabel]\n    n_samples: int\n    n_features: int\n    unique_classes: Set[ClassLabel]\n    \n    def __post_init__(self):\n        \"\"\"Validate data consistency after construction.\"\"\"\n        if len(self.labels) != self.n_samples:\n            raise ValueError(f\"Label count {len(self.labels)} != sample count {self.n_samples}\")\n        \n        if self.features.shape != (self.n_samples, self.n_features):\n            raise ValueError(f\"Feature shape {self.features.shape} inconsistent with metadata\")\n            \n        # Ensure features are float64 and C-contiguous for efficiency\n        self.features = np.ascontiguousarray(self.features, dtype=np.float64)\n        \n        # Validate that all features are finite\n        if not np.all(np.isfinite(self.features)):\n            raise ValueError(\"Training features contain NaN or infinite values\")\n    \n    def get_sample(self, index: int) -> Tuple[FeatureVector, ClassLabel]:\n        \"\"\"Retrieve a single training sample by index.\"\"\"\n        if not 0 <= index < self.n_samples:\n            raise IndexError(f\"Sample index {index} out of range [0, {self.n_samples})\")\n        return self.features[index], self.labels[index]\n\n@dataclass  \nclass PredictionResult:\n    \"\"\"Complete prediction result with neighbor information and confidence.\"\"\"\n    predicted_class: ClassLabel\n    neighbor_indices: NeighborIndices\n    neighbor_distances: DistanceArray\n    confidence: float\n    \n    def __post_init__(self):\n        \"\"\"Validate prediction result consistency.\"\"\"\n        if len(self.neighbor_indices) != len(self.neighbor_distances):\n            raise ValueError(\"Neighbor indices and distances must have same length\")\n            \n        if not 0.0 <= self.confidence <= 1.0:\n            raise ValueError(f\"Confidence {self.confidence} must be in range [0.0, 1.0]\")\n            \n        if not np.all(self.neighbor_distances >= 0):\n            raise ValueError(\"Neighbor distances must be non-negative\")\n\nclass KNNClassifier:\n    \"\"\"Main KNN classifier with configurable parameters and training data.\"\"\"\n    \n    def __init__(self, k: int = 3, distance_metric: DistanceMetric = DistanceMetric.EUCLIDEAN, \n                 weighted_voting: bool = False):\n        \"\"\"Initialize KNN classifier with hyperparameters.\"\"\"\n        if k <= 0:\n            raise ValueError(f\"K must be positive, got {k}\")\n            \n        self.k = k\n        self.distance_metric = distance_metric  \n        self.weighted_voting = weighted_voting\n        self.training_data: Optional[TrainingData] = None\n    \n    def fit(self, X: FeatureMatrix, y: List[ClassLabel]) -> None:\n        \"\"\"Store training data for lazy learning.\"\"\"\n        # TODO: Validate input dimensions and types\n        # TODO: Create TrainingData container with metadata extraction  \n        # TODO: Store training data for prediction time\n        pass\n        \n    def predict(self, X: FeatureMatrix) -> List[ClassLabel]:\n        \"\"\"Predict class labels for query points.\"\"\"\n        # TODO: Validate that classifier has been fitted\n        # TODO: Validate query data dimensions match training data\n        # TODO: For each query point, compute distances to all training samples\n        # TODO: Find K nearest neighbors for each query\n        # TODO: Apply voting strategy to determine predicted class\n        # TODO: Return list of predicted labels\n        pass\n        \n    def predict_with_confidence(self, X: FeatureMatrix) -> List[PredictionResult]:\n        \"\"\"Predict with full neighbor and confidence information.\"\"\"\n        # TODO: Perform same steps as predict() but return complete PredictionResult\n        # TODO: Calculate confidence scores based on voting margins\n        # TODO: Include neighbor indices and distances in results\n        pass\n\ndef create_training_data(X: FeatureMatrix, y: List[ClassLabel]) -> TrainingData:\n    \"\"\"Factory function to create validated TrainingData container.\"\"\"\n    X = np.asarray(X, dtype=np.float64)\n    \n    if X.ndim != 2:\n        raise ValueError(f\"Feature matrix must be 2D, got shape {X.shape}\")\n        \n    n_samples, n_features = X.shape\n    unique_classes = set(y)\n    \n    return TrainingData(\n        features=X,\n        labels=y,\n        n_samples=n_samples, \n        n_features=n_features,\n        unique_classes=unique_classes\n    )\n```\n\n#### Dataset Loading Utilities\n\nComplete utilities for loading and preprocessing standard datasets:\n\n```python\n\"\"\"\nDataset loading and preprocessing utilities for KNN classification.\n\nProvides standardized interfaces for loading common datasets with proper\nfeature scaling and train/test splitting.\n\"\"\"\n\nimport numpy as np\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom typing import Tuple, Optional\n\ndef load_iris_dataset() -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Load the classic Iris classification dataset.\"\"\"\n    iris = datasets.load_iris()\n    return iris.data.astype(np.float64), iris.target\n\ndef load_wine_dataset() -> Tuple[np.ndarray, np.ndarray]:  \n    \"\"\"Load the Wine classification dataset.\"\"\"\n    wine = datasets.load_wine()\n    return wine.data.astype(np.float64), wine.target\n\ndef split_and_scale_data(X: np.ndarray, y: np.ndarray, test_size: float = 0.2, \n                        scale_features: bool = True, random_state: Optional[int] = None) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Split dataset and optionally apply feature scaling.\"\"\"\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=test_size, random_state=random_state, stratify=y\n    )\n    \n    if scale_features:\n        scaler = StandardScaler()\n        X_train = scaler.fit_transform(X_train)\n        X_test = scaler.transform(X_test)\n    \n    return X_train, X_test, y_train, y_test\n\ndef validate_feature_consistency(X_train: np.ndarray, X_test: np.ndarray) -> None:\n    \"\"\"Validate that training and test data have consistent feature dimensions.\"\"\"\n    if X_train.shape[1] != X_test.shape[1]:\n        raise ValueError(f\"Feature dimension mismatch: train={X_train.shape[1]}, test={X_test.shape[1]}\")\n        \n    if not np.all(np.isfinite(X_train)) or not np.all(np.isfinite(X_test)):\n        raise ValueError(\"Feature data contains NaN or infinite values\")\n```\n\n#### Milestone Checkpoints\n\n**Checkpoint 1: Basic Data Type Creation**\nAfter implementing the core data types, verify correct construction and validation:\n\n```python\n# Test basic type creation\nX = np.array([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\ny = ['A', 'B', 'A']\n\ntraining_data = create_training_data(X, y)\nprint(f\"Created training data: {training_data.n_samples} samples, {training_data.n_features} features\")\nprint(f\"Unique classes: {training_data.unique_classes}\")\n\n# Test sample retrieval\nfeatures, label = training_data.get_sample(0)\nprint(f\"Sample 0: features={features}, label={label}\")\n```\n\nExpected output: No exceptions, correct metadata extraction, proper sample retrieval.\n\n**Checkpoint 2: Dataset Loading and Preprocessing**\nVerify that standard datasets load correctly with proper scaling:\n\n```python\n# Test Iris dataset loading\nX, y = load_iris_dataset() \nX_train, X_test, y_train, y_test = split_and_scale_data(X, y, random_state=42)\n\nprint(f\"Iris dataset: {X.shape[0]} samples, {X.shape[1]} features\") \nprint(f\"Training set: {X_train.shape[0]} samples\")\nprint(f\"Test set: {X_test.shape[0]} samples\")\nprint(f\"Feature means after scaling: {np.mean(X_train, axis=0)}\")\nprint(f\"Feature stds after scaling: {np.std(X_train, axis=0)}\")\n```\n\nExpected output: 150 Iris samples with 4 features, approximately 80/20 train/test split, feature means near 0.0 and standard deviations near 1.0 after scaling.\n\n#### Debugging Tips\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|-----------------|-----|\n| Distance calculations return NaN | Non-finite input features | Check `np.isfinite(X).all()` | Add input validation, handle missing values |\n| Memory usage grows during prediction | Arrays not being garbage collected | Profile memory usage, check for circular references | Explicitly delete intermediate arrays |\n| Slow distance calculations | Non-contiguous array layout | Check `X.flags['C_CONTIGUOUS']` | Use `np.ascontiguousarray(X)` |\n| Type errors during prediction | Inconsistent label types | Check `type(y[0])` for all labels | Convert labels to consistent type |\n| Index out of bounds errors | K larger than training set size | Compare `k` with `len(training_data)` | Validate K during classifier construction |\n\n\n## Distance Metrics Component\n\n> **Milestone(s):** Milestone 1: Distance Calculation - implements all distance metrics with vectorized operations for efficient computation between feature vectors\n\nThe distance metrics component forms the computational foundation of the KNN classifier, responsible for measuring similarity between data points in feature space. This component directly implements the core deliverables of Milestone 1, providing Euclidean distance, Manhattan distance, cosine similarity, and distance matrix building capabilities. The architectural challenge lies in creating efficient vectorized implementations that can handle high-dimensional data while maintaining numerical stability and providing a clean interface for different similarity measures.\n\n### Mental Model: Measuring Similarity\n\nUnderstanding distance metrics requires thinking about how we naturally measure similarity in everyday life. Imagine you're trying to find people similar to yourself based on attributes like height, age, income, and education level. Different distance metrics represent different philosophies for measuring this similarity.\n\nThe **Euclidean distance** is like measuring the straight-line distance between two people if you plotted them as points in a multi-dimensional space. If person A is at coordinates (height=70, age=30, income=50000) and person B is at (height=72, age=32, income=52000), Euclidean distance draws an imaginary straight line between these two points and measures its length. This treats all dimensions equally and gives you the most intuitive \"as the crow flies\" distance.\n\nThe **Manhattan distance** takes a different approach, like measuring the distance you'd actually walk in a city with a grid street system. Instead of cutting diagonally through buildings, you have to walk along the streets - first going 2 units in the height direction, then 2 units in the age direction, then 2000 units in the income direction, and summing up all these individual distances. This metric is more robust to outliers because it doesn't square the differences.\n\nThe **cosine similarity** focuses purely on the shape or direction of the data vectors, ignoring their magnitude. Think of it as asking \"do these two people have similar proportions across all attributes?\" rather than \"are their absolute values close?\". Two people might have very different absolute incomes and ages, but if their relative patterns are similar (both high in education relative to their age group, both moderate in income relative to their education level), cosine similarity will consider them highly similar.\n\nThis mental model helps us understand when to use each metric. Euclidean works well when all dimensions have similar scales and meaning. Manhattan is better when you want to reduce the influence of outliers or when the features represent counts. Cosine similarity shines when you care about patterns and proportions rather than absolute magnitudes, which is common in text analysis and recommendation systems.\n\n### Distance Calculator Interface\n\nThe distance calculator provides a unified interface for computing similarity between feature vectors, abstracting away the mathematical details while ensuring consistent behavior across different metrics. The interface design follows the principle of separating metric selection from computation execution, allowing the same calculation logic to work with any distance function.\n\n| Method Name | Parameters | Returns | Description |\n|-------------|------------|---------|-------------|\n| `calculate_distance` | `point1: FeatureVector, point2: FeatureVector, metric: DistanceMetric` | `float64` | Computes distance between two feature vectors using specified metric |\n| `calculate_distances_to_point` | `query_point: FeatureVector, training_matrix: FeatureMatrix, metric: DistanceMetric` | `DistanceArray` | Vectorized computation of distances from query point to all training samples |\n| `calculate_pairwise_distances` | `matrix1: FeatureMatrix, matrix2: FeatureMatrix, metric: DistanceMetric` | `DistanceMatrix` | Builds full distance matrix between two sets of points |\n| `validate_inputs` | `point1: FeatureVector, point2: FeatureVector` | `None` | Ensures input vectors have compatible dimensions and valid values |\n| `get_available_metrics` | `None` | `List[DistanceMetric]` | Returns list of supported distance metrics |\n\nThe interface design prioritizes both individual point calculations and batch operations. The `calculate_distance` method handles single point-to-point calculations, essential for debugging and small-scale operations. The `calculate_distances_to_point` method provides the core functionality needed for KNN neighbor finding, computing distances from one query point to all training samples in a single vectorized operation. The `calculate_pairwise_distances` method supports advanced use cases like building complete distance matrices for analysis or optimization algorithms.\n\nInput validation occurs at the interface level to ensure consistent error handling across all distance metrics. The validation checks for dimension compatibility between vectors, the presence of NaN or infinite values, and appropriate data types. This centralized validation prevents the need to duplicate error checking logic in each individual distance metric implementation.\n\nThe interface supports metric parameterization through the `DistanceMetric` enum, enabling runtime selection of similarity measures. This design allows the same classifier instance to experiment with different distance functions without requiring code changes, supporting hyperparameter optimization workflows where distance metric selection becomes part of the model tuning process.\n\n### Distance Algorithms\n\nThe three core distance algorithms each implement a different mathematical approach to measuring similarity, optimized for efficient computation using vectorized operations. Each algorithm follows a consistent pattern of input validation, vectorized computation, and result formatting, but differs in the underlying mathematical operations.\n\n#### Euclidean Distance Algorithm\n\nThe Euclidean distance algorithm computes the L2 norm between two feature vectors, representing the straight-line distance in multi-dimensional space. The mathematical foundation is the Pythagorean theorem extended to n dimensions: the square root of the sum of squared differences across all features.\n\n1. **Input validation**: Verify both input vectors have identical dimensions and contain only finite numeric values. Check that neither vector is empty and both have matching data types.\n\n2. **Difference computation**: Calculate the element-wise difference between the two feature vectors using vectorized subtraction. This creates a new vector where each element represents the difference in that particular feature dimension.\n\n3. **Squared differences**: Apply element-wise squaring to the difference vector, transforming each difference into its squared value. This squaring operation eliminates negative values and gives greater weight to larger differences.\n\n4. **Sum of squares**: Compute the sum of all squared differences using vectorized summation. This produces a single scalar value representing the total squared distance across all dimensions.\n\n5. **Square root extraction**: Apply the square root function to the sum of squares, yielding the final Euclidean distance. Include numerical stability checks to handle potential floating-point precision issues near zero.\n\n6. **Result validation**: Ensure the computed distance is non-negative and finite. Handle edge cases where the input vectors are identical (distance should be exactly zero).\n\nThe vectorized implementation leverages NumPy's broadcasting capabilities to perform element-wise operations on entire arrays simultaneously, avoiding Python-level loops that would significantly degrade performance on high-dimensional data.\n\n#### Manhattan Distance Algorithm\n\nThe Manhattan distance algorithm computes the L1 norm between feature vectors, measuring similarity as the sum of absolute differences across all dimensions. This approach is more robust to outliers than Euclidean distance because it doesn't square the individual differences.\n\n1. **Input validation**: Perform identical validation steps as Euclidean distance, ensuring dimension compatibility and finite numeric values.\n\n2. **Difference computation**: Calculate element-wise differences between the two feature vectors using vectorized subtraction, identical to the Euclidean approach.\n\n3. **Absolute differences**: Apply element-wise absolute value function to the difference vector, ensuring all differences are non-negative. This step replaces the squaring operation used in Euclidean distance.\n\n4. **Sum of absolute differences**: Compute the sum of all absolute differences using vectorized summation, producing the final Manhattan distance as a single scalar value.\n\n5. **Result validation**: Verify the computed distance is non-negative and finite, with special handling for identical input vectors.\n\nThe Manhattan distance algorithm is computationally simpler than Euclidean distance because it avoids both squaring and square root operations, making it potentially faster for high-dimensional data while providing different similarity semantics.\n\n#### Cosine Similarity Algorithm\n\nThe cosine similarity algorithm measures the angular relationship between two feature vectors, focusing on their directional similarity rather than magnitude differences. The computation involves dot products and vector norms, with the final result representing the cosine of the angle between the vectors.\n\n1. **Input validation**: Validate dimensions and numeric properties, with additional checks for zero vectors that would make cosine similarity undefined.\n\n2. **Dot product computation**: Calculate the dot product between the two feature vectors using vectorized multiplication followed by summation. The dot product represents the projection of one vector onto the other.\n\n3. **Norm calculations**: Compute the L2 norm (Euclidean norm) of each input vector separately. This involves squaring all elements, summing them, and taking the square root for each vector.\n\n4. **Zero vector handling**: Check if either vector has zero norm, which would make cosine similarity undefined. Handle this edge case by returning a predefined similarity value or raising an appropriate error.\n\n5. **Cosine computation**: Divide the dot product by the product of the two norms, yielding the cosine similarity value between -1 and 1.\n\n6. **Distance conversion**: Convert cosine similarity to cosine distance by subtracting from 1.0, ensuring the result follows distance semantics where smaller values indicate greater similarity.\n\nThe cosine similarity algorithm requires careful handling of numerical edge cases, particularly zero vectors and very small norms that could lead to division by zero or numerical instability.\n\n### Architecture Decisions for Distance Calculation\n\nThe design of the distance calculation component involves several critical architectural decisions that impact performance, extensibility, and correctness. Each decision represents a trade-off between competing requirements and reflects the specific needs of the KNN classification system.\n\n> **Decision: Vectorized Operations Over Loop-Based Implementations**\n> - **Context**: Distance calculations are the computational bottleneck in KNN, often requiring thousands or millions of distance computations between query points and training samples. Python loops are notoriously slow compared to compiled code.\n> - **Options Considered**: Pure Python loops with manual iteration, NumPy vectorized operations, hybrid approach with selective vectorization\n> - **Decision**: Implement all distance calculations using NumPy vectorized operations exclusively\n> - **Rationale**: Vectorized operations execute in compiled C code within NumPy, providing 10-100x speedup over Python loops. The performance gain is essential for practical KNN applications on realistic datasets. Memory usage is higher but acceptable for most applications.\n> - **Consequences**: Requires NumPy dependency, uses more memory for intermediate arrays, but provides dramatic performance improvements and cleaner, more readable code\n\n| Option | Pros | Cons |\n|--------|------|------|\n| Python Loops | No memory overhead, easy to debug | 10-100x slower, harder to read |\n| NumPy Vectorized | Very fast, clean code, leverages optimized libraries | Higher memory usage, NumPy dependency |\n| Hybrid Approach | Balanced performance/memory | Complex implementation, inconsistent performance |\n\n> **Decision: Single Metric Interface Over Separate Metric Classes**\n> - **Context**: The system needs to support multiple distance metrics while providing a consistent interface for the classifier component. Different metrics have different computational patterns and edge cases.\n> - **Options Considered**: Separate class for each metric with shared interface, single function with metric parameter, strategy pattern with metric objects\n> - **Decision**: Single interface with metric parameter and internal dispatch to specialized implementations\n> - **Rationale**: Reduces code duplication, provides consistent error handling and input validation, simplifies client code that needs to switch between metrics. Performance overhead of dispatch is negligible compared to computation time.\n> - **Consequences**: Slightly more complex internal implementation, but much simpler client interface and better maintainability\n\n| Option | Pros | Cons |\n|--------|------|------|\n| Separate Classes | Clear separation, extensible | Code duplication, complex client interface |\n| Single Function | Simple implementation | Becomes unwieldy with many metrics |\n| Strategy Pattern | Clean design, extensible | Over-engineering for this use case |\n\n> **Decision: Eager Input Validation Over Lazy Error Handling**\n> - **Context**: Distance calculations can fail due to dimension mismatches, NaN values, infinite values, or inappropriate data types. These errors are often difficult to debug when they occur deep in vectorized operations.\n> - **Options Considered**: No validation (fail fast), lazy validation during computation, eager validation at interface boundary\n> - **Decision**: Implement comprehensive input validation at the interface level before any computation\n> - **Rationale**: Provides clear, actionable error messages at the point of call rather than cryptic NumPy errors. The performance cost of validation is minimal compared to distance computation. Improves debugging experience significantly.\n> - **Consequences**: Slight performance overhead, more code complexity, but much better error messages and debugging experience\n\n| Option | Pros | Cons |\n|--------|------|------|\n| No Validation | Fastest execution | Cryptic errors, hard to debug |\n| Lazy Validation | Minimal overhead | Errors occur far from root cause |\n| Eager Validation | Clear errors, easy debugging | Small performance cost |\n\n> **Decision: Distance Matrix Caching Over On-Demand Computation**\n> - **Context**: KNN classification often involves repeated distance calculations between the same sets of points, especially during hyperparameter tuning and cross-validation. Computing distances on-demand wastes computation time.\n> - **Options Considered**: Always compute on-demand, cache distance matrices in memory, hybrid caching with memory limits\n> - **Decision**: Provide optional distance matrix caching with explicit cache management\n> - **Rationale**: Dramatic performance improvements for repeated queries against the same training set. Memory usage is predictable and can be managed by the client. Optional nature allows memory-constrained applications to opt out.\n> - **Consequences**: Higher memory usage when enabled, more complex cache management logic, but significant performance gains for common use cases\n\n| Option | Pros | Cons |\n|--------|------|------|\n| On-Demand Only | Low memory usage | Repeated computation waste |\n| Always Cache | Best performance | High memory usage, may not fit |\n| Optional Caching | Flexible, configurable | More complex implementation |\n\n![Distance Calculation Process](./diagrams/distance-calculation.svg)\n\n### Common Distance Calculation Pitfalls\n\nDistance calculation implementations frequently encounter several categories of errors that can lead to incorrect results, poor performance, or runtime failures. Understanding these pitfalls helps developers avoid common mistakes and implement robust distance metrics.\n\n⚠️ **Pitfall: Dimension Mismatch Between Vectors**\n\nOne of the most frequent errors occurs when attempting to calculate distances between feature vectors of different dimensions. This typically happens when training data and query data are preprocessed differently, or when datasets are concatenated incorrectly.\n\n**Why it's wrong**: Vectorized operations require compatible array shapes. NumPy will either fail with a broadcasting error or silently produce incorrect results by broadcasting smaller arrays. Distance calculations become meaningless when comparing vectors representing different feature spaces.\n\n**How to fix**: Implement comprehensive dimension checking in the `validate_inputs` method. Verify that `point1.shape[0] == point2.shape[0]` for individual point calculations, and ensure all vectors in batch operations have identical feature dimensions. Provide clear error messages that include the actual dimensions found.\n\n⚠️ **Pitfall: Ignoring Feature Scale Differences**\n\nDistance metrics are sensitive to the scale and range of different features. If one feature ranges from 0-1 while another ranges from 0-100000, the large-scale feature will dominate distance calculations regardless of its actual importance.\n\n**Why it's wrong**: Features with larger numeric ranges contribute disproportionately to distance calculations, effectively making smaller-scale features irrelevant. This leads to poor classification performance where the model only considers high-magnitude features.\n\n**How to fix**: While feature scaling is technically outside the distance calculator's responsibility, provide clear documentation about scale sensitivity. Consider adding optional built-in normalization capabilities or warning messages when feature ranges differ by orders of magnitude.\n\n⚠️ **Pitfall: Numerical Instability with Small Values**\n\nFloating-point arithmetic can produce unexpected results when dealing with very small numbers, particularly in square root operations for Euclidean distance and division operations for cosine similarity.\n\n**Why it's wrong**: Operations like `sqrt(very_small_number)` or `dot_product / (tiny_norm * other_norm)` can produce numerical artifacts, infinity values, or lose precision due to floating-point representation limits.\n\n**How to fix**: Add epsilon tolerance for near-zero comparisons. For square root operations, check if the input is below a small threshold (e.g., 1e-15) and handle as exact zero. For cosine similarity, detect near-zero norms and handle as undefined similarity rather than attempting division.\n\n⚠️ **Pitfall: Memory Explosion with Large Distance Matrices**\n\nWhen building full pairwise distance matrices for large datasets, memory usage scales quadratically with the number of points. A dataset with 10,000 points requires 100 million distance values, consuming gigabytes of RAM.\n\n**Why it's wrong**: Large distance matrices can exceed available memory, causing the program to crash or swap to disk with severe performance degradation. Even when they fit in memory, they may crowd out other important data structures.\n\n**How to fix**: Implement memory usage estimation before computing large distance matrices. Provide chunked computation options that process distance matrices in blocks. Consider lazy evaluation approaches where distances are computed on-demand rather than precomputed.\n\n⚠️ **Pitfall: Incorrect Cosine Distance Conversion**\n\nCosine similarity produces values between -1 and +1, but distance metrics should follow the convention where smaller values indicate greater similarity. The conversion from similarity to distance is often implemented incorrectly.\n\n**Why it's wrong**: Simply negating cosine similarity or using `1 - cosine_similarity` can produce negative distances or incorrect ordering. Some implementations forget that cosine similarity can be negative for vectors pointing in opposite directions.\n\n**How to fix**: Use the correct conversion formula: `cosine_distance = 1.0 - cosine_similarity`. This ensures distances range from 0 (identical direction) to 2 (opposite direction). Handle the edge case where cosine similarity is exactly -1 to avoid floating-point precision issues.\n\n⚠️ **Pitfall: Inefficient Loop-Based Implementations**\n\nPython loops for distance calculations create severe performance bottlenecks, but developers often implement them when vectorized solutions seem complex or when handling edge cases.\n\n**Why it's wrong**: Python loops execute at interpreted speed rather than compiled speed, creating 10-100x performance penalties. This makes KNN impractical for any reasonably-sized dataset.\n\n**How to fix**: Always use NumPy vectorized operations. For complex edge cases, handle them outside the main computation loop rather than adding conditional logic inside loops. Profile code to identify any remaining loop bottlenecks and replace them with vectorized equivalents.\n\n### Implementation Guidance\n\nThe distance metrics component requires careful attention to numerical stability and performance optimization. The implementation balances ease of use with computational efficiency, providing both simple single-distance calculations and optimized batch operations.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Numerical Computing | NumPy arrays with basic operations | NumPy + SciPy with optimized sparse matrix support |\n| Validation | Manual type and shape checking | Pandas-style data validation with detailed error reporting |\n| Performance Monitoring | Basic timing with time.time() | Line profiler + memory profiler for detailed optimization |\n| Testing | Assert statements with manual test cases | Hypothesis property-based testing with random data generation |\n\n#### Recommended File Structure\n\nThe distance metrics component organizes into a focused module structure that separates core algorithms from utilities and testing:\n\n```python\nknn_classifier/\n  distance/\n    __init__.py              ← public interface exports\n    metrics.py               ← core distance algorithm implementations  \n    calculator.py            ← distance calculator class with interface\n    validation.py            ← input validation and error handling\n    test_distance.py         ← comprehensive distance metric tests\n  data/\n    types.py                 ← shared type definitions\n  utils/\n    performance.py           ← timing and profiling utilities\n```\n\nThis structure keeps the core distance algorithms in `metrics.py`, the public interface in `calculator.py`, and supporting functionality in separate modules. The `__init__.py` file exports the main `DistanceCalculator` class and `DistanceMetric` enum for easy importing by client code.\n\n#### Infrastructure Starter Code\n\n**Complete Type Definitions** (`data/types.py`):\n\n```python\nimport numpy as np\nfrom typing import Union, List, Set, Optional, Tuple\nfrom enum import Enum\n\n# Core data types for KNN system\nFeatureVector = np.ndarray  # 1D array of float64 features\nFeatureMatrix = np.ndarray  # 2D array shape (n_samples, n_features)  \nClassLabel = Union[int, str]  # flexible class identifiers\nDistanceArray = np.ndarray  # 1D array of float64 distances\nNeighborIndices = np.ndarray  # 1D array of int32 indices\n\nclass DistanceMetric(Enum):\n    \"\"\"Supported distance metrics for KNN classification.\"\"\"\n    EUCLIDEAN = \"euclidean\"\n    MANHATTAN = \"manhattan\" \n    COSINE = \"cosine\"\n\n# Training data container\nfrom dataclasses import dataclass\n\n@dataclass\nclass TrainingData:\n    \"\"\"Container for training dataset with metadata.\"\"\"\n    features: FeatureMatrix\n    labels: List[ClassLabel]\n    n_samples: int\n    n_features: int\n    unique_classes: Set[ClassLabel]\n    \n    def get_sample(self, index: int) -> Tuple[FeatureVector, ClassLabel]:\n        \"\"\"Retrieve single training example by index.\"\"\"\n        if not 0 <= index < self.n_samples:\n            raise IndexError(f\"Sample index {index} out of range [0, {self.n_samples})\")\n        return self.features[index], self.labels[index]\n```\n\n**Complete Input Validation Module** (`distance/validation.py`):\n\n```python\nimport numpy as np\nfrom typing import Union\nfrom ..data.types import FeatureVector, FeatureMatrix, DistanceMetric\n\nclass ValidationError(ValueError):\n    \"\"\"Raised when input validation fails.\"\"\"\n    pass\n\ndef validate_feature_vector(vector: FeatureVector, name: str = \"vector\") -> None:\n    \"\"\"Validate single feature vector for distance calculation.\"\"\"\n    if not isinstance(vector, np.ndarray):\n        raise ValidationError(f\"{name} must be numpy array, got {type(vector)}\")\n    \n    if vector.ndim != 1:\n        raise ValidationError(f\"{name} must be 1-dimensional, got shape {vector.shape}\")\n    \n    if vector.size == 0:\n        raise ValidationError(f\"{name} cannot be empty\")\n    \n    if not np.issubdtype(vector.dtype, np.number):\n        raise ValidationError(f\"{name} must contain numeric data, got dtype {vector.dtype}\")\n    \n    if not np.all(np.isfinite(vector)):\n        raise ValidationError(f\"{name} contains non-finite values (NaN or inf)\")\n\ndef validate_compatible_vectors(v1: FeatureVector, v2: FeatureVector) -> None:\n    \"\"\"Validate two vectors are compatible for distance calculation.\"\"\"\n    validate_feature_vector(v1, \"first vector\")\n    validate_feature_vector(v2, \"second vector\")\n    \n    if v1.shape[0] != v2.shape[0]:\n        raise ValidationError(\n            f\"Vector dimension mismatch: {v1.shape[0]} vs {v2.shape[0]}\"\n        )\n\ndef validate_distance_metric(metric: DistanceMetric) -> None:\n    \"\"\"Validate distance metric is supported.\"\"\"\n    if not isinstance(metric, DistanceMetric):\n        raise ValidationError(f\"metric must be DistanceMetric enum, got {type(metric)}\")\n\ndef validate_feature_matrix(matrix: FeatureMatrix, name: str = \"matrix\") -> None:\n    \"\"\"Validate feature matrix for batch distance calculations.\"\"\"\n    if not isinstance(matrix, np.ndarray):\n        raise ValidationError(f\"{name} must be numpy array, got {type(matrix)}\")\n    \n    if matrix.ndim != 2:\n        raise ValidationError(f\"{name} must be 2-dimensional, got shape {matrix.shape}\")\n    \n    if matrix.size == 0:\n        raise ValidationError(f\"{name} cannot be empty\")\n    \n    if not np.issubdtype(matrix.dtype, np.number):\n        raise ValidationError(f\"{name} must contain numeric data, got dtype {matrix.dtype}\")\n    \n    if not np.all(np.isfinite(matrix)):\n        raise ValidationError(f\"{name} contains non-finite values (NaN or inf)\")\n```\n\n#### Core Logic Skeleton Code\n\n**Distance Metrics Implementation** (`distance/metrics.py`):\n\n```python\nimport numpy as np\nfrom ..data.types import FeatureVector, FeatureMatrix, DistanceArray\n\ndef euclidean_distance(point1: FeatureVector, point2: FeatureVector) -> float:\n    \"\"\"\n    Calculate Euclidean (L2) distance between two feature vectors.\n    \n    The Euclidean distance is the straight-line distance in n-dimensional space,\n    computed as the square root of the sum of squared differences.\n    \n    Args:\n        point1: First feature vector\n        point2: Second feature vector (must have same dimensions)\n        \n    Returns:\n        Euclidean distance as float (always non-negative)\n    \"\"\"\n    # TODO 1: Calculate element-wise differences using vectorized subtraction\n    # TODO 2: Square each difference using element-wise multiplication or np.square()\n    # TODO 3: Sum all squared differences using np.sum()\n    # TODO 4: Take square root of sum using np.sqrt()\n    # TODO 5: Return the final distance value\n    # Hint: The entire calculation can be done in one line: np.sqrt(np.sum((point1 - point2) ** 2))\n    pass\n\ndef manhattan_distance(point1: FeatureVector, point2: FeatureVector) -> float:\n    \"\"\"\n    Calculate Manhattan (L1) distance between two feature vectors.\n    \n    The Manhattan distance is the sum of absolute differences across all dimensions,\n    like walking along city blocks rather than cutting diagonally.\n    \n    Args:\n        point1: First feature vector\n        point2: Second feature vector (must have same dimensions)\n        \n    Returns:\n        Manhattan distance as float (always non-negative)\n    \"\"\"\n    # TODO 1: Calculate element-wise differences using vectorized subtraction\n    # TODO 2: Take absolute value of each difference using np.abs()\n    # TODO 3: Sum all absolute differences using np.sum()\n    # TODO 4: Return the final distance value\n    # Hint: Can be computed as np.sum(np.abs(point1 - point2))\n    pass\n\ndef cosine_distance(point1: FeatureVector, point2: FeatureVector) -> float:\n    \"\"\"\n    Calculate cosine distance between two feature vectors.\n    \n    Cosine distance focuses on vector direction rather than magnitude,\n    computed as 1 - cosine_similarity where cosine_similarity = dot_product / (norm1 * norm2).\n    \n    Args:\n        point1: First feature vector\n        point2: Second feature vector (must have same dimensions)\n        \n    Returns:\n        Cosine distance as float (0 = identical direction, 2 = opposite direction)\n    \"\"\"\n    # TODO 1: Calculate dot product using np.dot(point1, point2)\n    # TODO 2: Calculate L2 norm of point1 using np.linalg.norm()\n    # TODO 3: Calculate L2 norm of point2 using np.linalg.norm()\n    # TODO 4: Check for zero norms - if either norm is 0, handle edge case\n    # TODO 5: Calculate cosine similarity as dot_product / (norm1 * norm2)\n    # TODO 6: Convert similarity to distance using: distance = 1.0 - similarity\n    # TODO 7: Return the final distance value\n    # Hint: Add small epsilon (1e-10) to norms to avoid division by zero\n    pass\n\ndef vectorized_distances_to_point(query_point: FeatureVector, \n                                training_matrix: FeatureMatrix,\n                                metric_func) -> DistanceArray:\n    \"\"\"\n    Calculate distances from query point to all training samples using vectorization.\n    \n    This is the performance-critical function that enables efficient KNN neighbor finding\n    by computing thousands of distances in a single vectorized operation.\n    \n    Args:\n        query_point: Single query vector to find neighbors for\n        training_matrix: Matrix where each row is a training sample\n        metric_func: Distance function (euclidean_distance, manhattan_distance, etc.)\n        \n    Returns:\n        Array of distances from query_point to each training sample\n    \"\"\"\n    # TODO 1: Get number of training samples from matrix shape\n    # TODO 2: Initialize distance array with zeros using np.zeros()\n    # TODO 3: Use broadcasting to compute all distances at once - avoid Python loops!\n    # TODO 4: For Euclidean: use np.sqrt(np.sum((query_point - training_matrix)**2, axis=1))\n    # TODO 5: For Manhattan: use np.sum(np.abs(query_point - training_matrix), axis=1)  \n    # TODO 6: For Cosine: implement vectorized dot products and norms\n    # TODO 7: Return the distance array\n    # Hint: The axis=1 parameter sums across features (columns) for each sample (row)\n    pass\n```\n\n**Distance Calculator Interface** (`distance/calculator.py`):\n\n```python\nimport numpy as np\nfrom typing import List, Optional\nfrom .metrics import euclidean_distance, manhattan_distance, cosine_distance, vectorized_distances_to_point\nfrom .validation import validate_compatible_vectors, validate_distance_metric, validate_feature_matrix\nfrom ..data.types import FeatureVector, FeatureMatrix, DistanceArray, DistanceMetric\n\nclass DistanceCalculator:\n    \"\"\"\n    Main interface for computing distances between feature vectors.\n    \n    Provides both single-pair distance calculation and efficient batch operations\n    for computing distances between query points and training datasets.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize distance calculator with metric function mapping.\"\"\"\n        self._metric_functions = {\n            DistanceMetric.EUCLIDEAN: euclidean_distance,\n            DistanceMetric.MANHATTAN: manhattan_distance, \n            DistanceMetric.COSINE: cosine_distance\n        }\n    \n    def calculate_distance(self, point1: FeatureVector, point2: FeatureVector, \n                         metric: DistanceMetric) -> float:\n        \"\"\"\n        Calculate distance between two individual feature vectors.\n        \n        This is the basic building block for all distance calculations,\n        providing input validation and metric dispatch.\n        \"\"\"\n        # TODO 1: Validate input vectors are compatible using validation module\n        # TODO 2: Validate distance metric is supported\n        # TODO 3: Get the appropriate metric function from self._metric_functions\n        # TODO 4: Call the metric function with the two points\n        # TODO 5: Return the computed distance\n        # Hint: Use validate_compatible_vectors() and validate_distance_metric()\n        pass\n    \n    def calculate_distances_to_point(self, query_point: FeatureVector,\n                                   training_matrix: FeatureMatrix,\n                                   metric: DistanceMetric) -> DistanceArray:\n        \"\"\"\n        Calculate distances from query point to all training samples.\n        \n        This is the core method used by KNN for neighbor finding,\n        optimized with vectorized operations for performance.\n        \"\"\"\n        # TODO 1: Validate query_point as feature vector\n        # TODO 2: Validate training_matrix as feature matrix\n        # TODO 3: Validate metric is supported\n        # TODO 4: Check dimension compatibility between query_point and training_matrix columns\n        # TODO 5: Use vectorized_distances_to_point() for efficient computation\n        # TODO 6: Return the distance array\n        # Hint: training_matrix.shape[1] should equal query_point.shape[0]\n        pass\n    \n    def get_available_metrics(self) -> List[DistanceMetric]:\n        \"\"\"Return list of supported distance metrics.\"\"\"\n        return list(self._metric_functions.keys())\n```\n\n#### Language-Specific Hints\n\n**NumPy Performance Optimization:**\n- Use `np.sqrt()` instead of `** 0.5` for square roots - it's optimized and more readable\n- Prefer `np.sum(arr, axis=1)` over `np.sum(arr, 1)` for clarity about which dimension you're summing\n- Use `np.linalg.norm()` for vector norms - it handles edge cases and numerical stability better than manual implementation\n- Set `dtype=np.float64` explicitly when creating arrays to ensure consistent precision\n\n**Memory Management:**\n- Use `del large_array` after processing to free memory immediately rather than waiting for garbage collection\n- For very large distance matrices, consider `np.float32` instead of `np.float64` to halve memory usage if precision allows\n- Use `np.empty()` instead of `np.zeros()` when you'll overwrite all values anyway\n\n**Error Handling:**\n- Catch `np.linalg.LinAlgError` specifically for norm calculations with degenerate inputs\n- Use `np.seterr(divide='raise')` during development to catch division by zero early\n- Check for `np.isfinite()` on results when debugging numerical issues\n\n**Testing and Debugging:**\n- Use `np.allclose(a, b, rtol=1e-10)` for floating-point comparisons instead of exact equality\n- Set `np.random.seed(42)` in tests for reproducible random data\n- Use `np.testing.assert_array_almost_equal()` for comparing arrays in unit tests\n\n#### Milestone Checkpoint\n\nAfter implementing the distance metrics component, verify correct functionality with these checkpoints:\n\n**Unit Test Execution:**\n```bash\ncd knn_classifier/\npython -m pytest distance/test_distance.py -v\n```\n\n**Expected Test Output:**\n```\ntest_euclidean_distance_basic ... PASSED\ntest_euclidean_distance_identical_points ... PASSED  \ntest_manhattan_distance_basic ... PASSED\ntest_cosine_distance_basic ... PASSED\ntest_vectorized_performance ... PASSED\ntest_input_validation_errors ... PASSED\n```\n\n**Manual Verification:**\n```python\nfrom distance.calculator import DistanceCalculator\nfrom data.types import DistanceMetric\nimport numpy as np\n\ncalc = DistanceCalculator()\n\n# Test basic distance calculation\npoint1 = np.array([1.0, 2.0, 3.0])  \npoint2 = np.array([4.0, 5.0, 6.0])\ndist = calc.calculate_distance(point1, point2, DistanceMetric.EUCLIDEAN)\nprint(f\"Euclidean distance: {dist}\")  # Should be ~5.196\n\n# Test batch calculation  \nquery = np.array([0.0, 0.0])\ntraining = np.array([[1.0, 0.0], [0.0, 1.0], [1.0, 1.0]])\ndistances = calc.calculate_distances_to_point(query, training, DistanceMetric.EUCLIDEAN)\nprint(f\"Batch distances: {distances}\")  # Should be [1.0, 1.0, 1.414]\n```\n\n**Performance Verification:**\nTime the vectorized implementation against a naive loop implementation to ensure the performance benefits are realized. The vectorized version should be 10-50x faster for datasets with 1000+ samples.\n\n**Common Issues to Check:**\n- If distances are negative, check the cosine distance conversion formula\n- If you get dimension errors, verify query point and training matrix have compatible shapes\n- If performance is slow, ensure you're not using Python loops in the distance calculations\n- If you get NaN results, check for zero vectors in cosine similarity calculations\n\n\n## Neighbor Finding Component\n\n> **Milestone(s):** Milestone 2: K-Nearest Neighbors Classification - implements the neighbor finding logic that identifies the K closest training samples to enable majority voting classification\n\nThe neighbor finding component represents the heart of the KNN algorithm's computational challenge. After distance calculation provides the raw similarity measurements between a query point and all training samples, the neighbor finder must efficiently identify and retrieve the K most similar training examples. This component bridges the gap between mathematical distance computation and practical classification by transforming a continuous similarity space into a discrete set of voting neighbors.\n\n### Mental Model: The Search Process\n\nThink of neighbor finding as organizing a **recommendation committee** from a large pool of advisors. Imagine you're new to a city and need restaurant recommendations. You have a database of thousands of residents, each with their own food preferences and demographic information. You've already calculated how similar each resident is to you based on age, income, taste preferences, and lifestyle factors - this is analogous to the distance calculation phase.\n\nNow you need to form your **recommendation committee** of exactly K people. You can't just pick randomly - you want the people most similar to yourself because their recommendations will be most relevant. The neighbor finding process is like scanning through your similarity scores and saying \"I'll take the 5 most similar people\" or \"I'll take the 10 closest matches.\" You're essentially curating a focused advisory panel from a much larger population.\n\nThe efficiency challenge mirrors real-world committee formation: if you have 10,000 potential advisors, you don't want to sort all 10,000 by similarity just to pick the top 5. You want smart strategies to quickly identify your target committee members without unnecessary computational overhead. This is why neighbor finding algorithms focus on efficient selection rather than complete ranking.\n\nThe neighbor finder also handles the practical complexities that arise in committee formation. What if two advisors have identical similarity scores - who gets selected? What if you ask for 10 committee members but only 8 people live in the city? What if someone asks for a committee of size 0 or negative size? These edge cases require careful handling to ensure the recommendation system remains robust and predictable.\n\n### Neighbor Finder Interface\n\nThe neighbor finding interface provides methods for efficiently locating the K nearest training samples to any query point. The interface abstracts the underlying search strategy while ensuring consistent behavior across different algorithmic approaches. The design emphasizes flexibility in search parameters while maintaining type safety and performance predictability.\n\nThe core interface revolves around the fundamental neighbor search operation, which takes a query point and returns both the indices of the nearest neighbors and their corresponding distances. This dual return provides downstream components with both the identity of the neighbors (for accessing their class labels) and their proximity information (for weighted voting schemes).\n\n| Method Name | Parameters | Returns | Description |\n|-------------|------------|---------|-------------|\n| `find_k_neighbors` | `query_point: FeatureVector, k: int, distance_metric: DistanceMetric` | `Tuple[NeighborIndices, DistanceArray]` | Find K nearest neighbors to query point using specified distance metric |\n| `find_neighbors_within_radius` | `query_point: FeatureVector, radius: float, distance_metric: DistanceMetric` | `Tuple[NeighborIndices, DistanceArray]` | Find all neighbors within specified distance radius |\n| `find_neighbors_batch` | `query_points: FeatureMatrix, k: int, distance_metric: DistanceMetric` | `List[Tuple[NeighborIndices, DistanceArray]]` | Find K neighbors for multiple query points efficiently |\n| `validate_k_parameter` | `k: int, dataset_size: int` | `None` | Validate K value against dataset constraints and raise appropriate errors |\n| `handle_distance_ties` | `distances: DistanceArray, indices: NeighborIndices, k: int` | `Tuple[NeighborIndices, DistanceArray]` | Resolve ties when multiple neighbors have identical distances |\n| `get_neighbor_metadata` | `neighbor_indices: NeighborIndices` | `List[Dict[str, Any]]` | Retrieve additional information about selected neighbors |\n\nThe interface supports both single-query and batch-query operations to accommodate different usage patterns. Single-query operations optimize for individual predictions, while batch operations leverage vectorized computations and memory locality for processing multiple queries simultaneously. The batch interface proves particularly valuable during model evaluation phases where hundreds or thousands of predictions occur in sequence.\n\nThe radius-based neighbor finding provides an alternative selection criterion that complements the K-based approach. Instead of selecting a fixed number of neighbors, radius-based selection identifies all training samples within a specified distance threshold. This approach handles scenarios where the local density of training samples varies significantly across the feature space, ensuring that predictions in sparse regions don't artificially include very dissimilar neighbors.\n\nParameter validation ensures that the neighbor finding process fails fast with clear error messages rather than producing subtly incorrect results. The K parameter validation checks for common issues like negative K values, K values larger than the training dataset, and edge cases where K equals zero. Distance tie handling addresses the mathematical reality that multiple training samples may have identical distances to a query point, requiring deterministic tie-breaking rules.\n\nThe neighbor metadata retrieval supports advanced use cases where downstream components need additional context about the selected neighbors beyond their indices and distances. This might include information about neighbor selection confidence, local density estimates, or debugging information about the search process.\n\n### Neighbor Search Algorithms\n\nThe neighbor search algorithms implement the core computational strategies for identifying the K closest training samples to a query point. The algorithmic choices represent fundamental trade-offs between computational complexity, memory usage, and implementation simplicity. For educational purposes, the focus remains on algorithms that provide clear learning value while maintaining practical utility.\n\n#### Linear Search Algorithm\n\nLinear search represents the most straightforward neighbor finding approach, examining every training sample to identify the K nearest neighbors. Despite its O(n) computational complexity per query, linear search provides several educational and practical advantages that make it the preferred starting algorithm for KNN implementation.\n\nThe linear search process follows these detailed steps:\n\n1. **Distance Computation**: Calculate the distance from the query point to every training sample using the specified distance metric. This leverages the vectorized distance calculation functions from the Distance Metrics Component, computing all distances in a single NumPy operation rather than using Python loops.\n\n2. **Distance Array Creation**: Store all computed distances in a `DistanceArray` alongside the corresponding training sample indices. The array indices implicitly correspond to training sample positions, creating a direct mapping between distance values and sample identities.\n\n3. **Partial Sorting**: Use NumPy's `argpartition` function to identify the K smallest distances without fully sorting the entire distance array. This optimization reduces the complexity from O(n log n) full sorting to O(n + k log k) partial sorting, providing significant performance benefits when K is much smaller than the dataset size.\n\n4. **Index Extraction**: Extract the indices of the K nearest neighbors from the partitioned array. These indices serve as references back into the original training data for label retrieval and metadata access.\n\n5. **Distance Extraction**: Retrieve the actual distance values corresponding to the selected neighbors. These distances support weighted voting schemes and confidence estimation in downstream components.\n\n6. **Tie Resolution**: Handle cases where multiple training samples have identical distances to the query point. The tie resolution strategy uses deterministic index-based ordering to ensure reproducible results across multiple runs with the same data.\n\n7. **Result Validation**: Verify that exactly K neighbors were selected and that all distance values are non-negative finite numbers. This validation catches numerical errors and edge cases before they propagate to classification components.\n\nThe linear search algorithm excels in scenarios with small to medium-sized datasets (thousands of samples) where the computational overhead remains manageable. Its implementation simplicity makes it ideal for learning environments where understanding the core logic takes precedence over optimal performance. The algorithm also handles edge cases gracefully, including datasets smaller than K and queries with unusual distance distributions.\n\n> **Key Insight**: Linear search's O(n) complexity becomes acceptable when combined with vectorized distance calculations. The NumPy-based implementation processes thousands of distance calculations in milliseconds, making sophisticated tree-based algorithms unnecessary for many practical KNN applications.\n\n#### Optimized Search Strategies\n\nWhile linear search provides educational value and practical utility for moderate dataset sizes, larger datasets benefit from optimized search strategies that reduce the computational complexity of neighbor finding. These strategies represent important algorithmic concepts that extend beyond KNN into broader computational geometry and information retrieval domains.\n\n**Partial Distance Calculation**: For high-dimensional feature vectors, distance calculations can become expensive even with vectorization. Partial distance calculation implements early termination strategies that abandon distance computation when intermediate results already exceed the current K-th nearest distance. This optimization proves particularly effective with Manhattan distance calculations where dimensions can be processed incrementally.\n\n**Memory-Conscious Batch Processing**: When processing multiple queries simultaneously, naive batch implementations can exhaust system memory by creating large distance matrices. Memory-conscious batch processing divides query batches into manageable chunks, processing each chunk completely before moving to the next. This approach maintains the performance benefits of vectorization while respecting memory constraints.\n\n**Distance Matrix Caching**: In scenarios where the same query points are processed repeatedly (such as during cross-validation), caching previously computed distance matrices can eliminate redundant calculations. The caching strategy must balance memory usage against computation time, potentially using LRU eviction policies for large datasets.\n\n**Approximate Nearest Neighbors**: For extremely large datasets where exact neighbor finding becomes prohibitively expensive, approximate algorithms can provide acceptable accuracy with dramatically improved performance. Random projection and locality-sensitive hashing represent two such approaches that maintain the core KNN learning concepts while introducing important approximation trade-offs.\n\nThe selection of optimization strategies depends on dataset characteristics, query patterns, and performance requirements. Educational implementations typically start with linear search before introducing optimizations incrementally, allowing learners to measure performance improvements and understand algorithmic trade-offs through direct experimentation.\n\n### Architecture Decisions for Neighbor Finding\n\nThe neighbor finding component involves several critical architectural decisions that impact performance, maintainability, and extensibility. Each decision represents trade-offs between competing priorities, requiring careful evaluation of the educational and practical implications.\n\n> **Decision: Search Algorithm Selection**\n> - **Context**: Multiple algorithms exist for finding nearest neighbors, ranging from simple linear search to sophisticated tree-based and hashing approaches. The choice impacts both implementation complexity and runtime performance, while educational value varies significantly across algorithms.\n> - **Options Considered**: \n>   - Linear search with vectorized operations\n>   - KD-tree spatial indexing\n>   - Locality-sensitive hashing (LSH)\n> - **Decision**: Implement linear search as the primary algorithm with clear extension points for advanced algorithms\n> - **Rationale**: Linear search provides maximum educational value by exposing the core neighbor finding logic without algorithmic complexity. Vectorized NumPy operations make linear search practical for datasets up to tens of thousands of samples, covering most educational scenarios. The simple implementation allows learners to focus on KNN concepts rather than spatial indexing details.\n> - **Consequences**: Runtime complexity remains O(n) per query, limiting scalability to very large datasets. However, implementation simplicity enables rapid prototyping and debugging. Extension points allow advanced learners to explore tree-based algorithms without redesigning the core architecture.\n\n| Algorithm Option | Pros | Cons | Educational Value |\n|------------------|------|------|-------------------|\n| Linear Search | Simple implementation, handles all distance metrics, vectorized performance | O(n) complexity per query | High - exposes core logic clearly |\n| KD-Tree | O(log n) average complexity, excellent for low dimensions | Complex implementation, poor high-dimensional performance | Medium - introduces spatial indexing concepts |\n| LSH | Handles high dimensions, approximate results acceptable | Complex implementation, approximate results only | Low - obscures core KNN concepts |\n\n> **Decision: Memory Usage Strategy**\n> - **Context**: Neighbor finding can consume significant memory through distance array storage, especially when processing batch queries or caching results. Memory usage patterns impact both performance and scalability, requiring careful resource management.\n> - **Options Considered**:\n>   - Store all distances in memory simultaneously\n>   - Stream processing with minimal memory footprint\n>   - Hybrid approach with configurable memory limits\n> - **Decision**: Implement streaming processing with optional result caching based on dataset size\n> - **Rationale**: Streaming processing ensures predictable memory usage regardless of dataset size, preventing out-of-memory errors during batch operations. Optional caching provides performance benefits for repeated queries while maintaining memory safety. The hybrid approach teaches memory-performance trade-offs explicitly.\n> - **Consequences**: Slightly increased implementation complexity but significantly improved scalability. Memory usage becomes predictable and configurable, enabling deployment in resource-constrained environments.\n\n> **Decision: Tie-Breaking Strategy**\n> - **Context**: Multiple training samples frequently have identical distances to query points, especially in discrete or low-precision feature spaces. Tie-breaking strategies must be deterministic to ensure reproducible results while remaining computationally efficient.\n> - **Options Considered**:\n>   - Random selection among tied neighbors\n>   - Index-based deterministic ordering\n>   - Secondary distance metric for tie resolution\n> - **Decision**: Use index-based deterministic ordering with configurable random seed option\n> - **Rationale**: Index-based ordering ensures reproducible results across multiple runs, essential for debugging and testing. The deterministic approach prevents subtle bugs caused by random tie-breaking. Optional random seeding supports scenarios where tie-breaking bias must be eliminated.\n> - **Consequences**: Results become fully reproducible, simplifying debugging and testing. Tie-breaking bias toward earlier training samples may occur but can be controlled through data shuffling.\n\n> **Decision: Batch Processing Architecture**\n> - **Context**: Real-world KNN applications often process multiple queries simultaneously, either during model evaluation or in production prediction scenarios. Batch processing can leverage vectorization for significant performance improvements but introduces memory management complexity.\n> - **Options Considered**:\n>   - Process queries individually with simple implementation\n>   - Full batch processing with vectorized distance calculations\n>   - Chunked batch processing with memory limits\n> - **Decision**: Implement chunked batch processing with automatic memory management\n> - **Rationale**: Chunked processing balances vectorization benefits against memory constraints, ensuring scalability across different hardware configurations. Automatic memory management reduces implementation burden while maintaining performance benefits. The approach teaches both vectorization concepts and resource management.\n> - **Consequences**: Implementation complexity increases moderately, but performance and scalability improve significantly. Memory usage remains controlled while leveraging vectorization benefits.\n\n### Common Neighbor Finding Pitfalls\n\nNeighbor finding implementation contains several subtle pitfalls that frequently trip up learners and even experienced developers. These pitfalls often produce plausible but incorrect results, making them particularly dangerous for learning environments where correctness verification may be limited.\n\n⚠️ **Pitfall: K Value Larger Than Dataset**\n\nOne of the most common errors occurs when the requested K parameter exceeds the total number of training samples in the dataset. This situation frequently arises during experimentation with small datasets or when using the same K value across different dataset sizes without validation.\n\nThe naive implementation might attempt to select K neighbors from a dataset of size N where K > N, leading to index out-of-bounds errors or attempting to pad results with invalid data. Even implementations that avoid crashes may return fewer than K neighbors without clearly communicating this deviation to calling code, causing downstream classification components to behave unexpectedly.\n\n**Detection**: Validate K against dataset size before beginning neighbor search operations. Check that K > 0 and K <= training_data.n_samples, raising clear exceptions for invalid values.\n\n**Solution**: Implement parameter validation that provides helpful error messages, suggesting appropriate K ranges based on dataset size. Consider offering automatic K adjustment with explicit warnings when K exceeds dataset size.\n\n⚠️ **Pitfall: Distance Tie Mishandling**\n\nDistance ties occur more frequently than intuitive expectations suggest, especially in datasets with discrete features, normalized data, or low-dimensional spaces. When multiple training samples have identical distances to a query point, naive implementations may exhibit non-deterministic behavior, returning different neighbor sets across multiple runs with identical input data.\n\nThe problem manifests when using unstable sorting algorithms or when tie-breaking logic depends on memory addresses or other runtime-dependent factors. This non-determinism makes debugging extremely difficult and violates the reproducibility expectations of scientific computing applications.\n\n**Detection**: Run the same neighbor finding operation multiple times with identical inputs and verify that results remain consistent. Pay particular attention to boundary cases where the K-th and (K+1)-th distances are identical.\n\n**Solution**: Implement deterministic tie-breaking using stable sorting with index-based secondary ordering. When distances are equal, prefer neighbors with smaller training data indices to ensure consistent results.\n\n⚠️ **Pitfall: Memory Exhaustion in Batch Processing**\n\nBatch processing optimizations can inadvertently create memory usage patterns that exhaust available system memory, particularly when processing large query batches against large training datasets. The problem occurs when implementations create full distance matrices for batch operations without considering memory constraints.\n\nFor example, processing 1,000 queries against 10,000 training samples creates a 10-million element distance matrix, potentially consuming gigabytes of memory. Systems may appear to hang or crash with out-of-memory errors, providing little indication of the underlying cause.\n\n**Detection**: Monitor memory usage during batch operations and implement memory usage estimation before beginning large batch processes. Profile memory consumption patterns with representative dataset sizes.\n\n**Solution**: Implement chunked batch processing that divides large query batches into memory-safe chunks. Process each chunk completely before proceeding to the next, maintaining vectorization benefits while controlling memory usage.\n\n⚠️ **Pitfall: Incorrect Distance Array Indexing**\n\nSubtle indexing errors can corrupt the correspondence between distance values and training sample indices, leading to neighbors being selected based on correct distances but associated with wrong training samples. This error often produces plausible prediction accuracy while systematically misidentifying the actual neighbors used for classification.\n\nThe problem typically arises during array manipulation operations like sorting, partitioning, or filtering, where distance values and indices become decoupled through incorrect index tracking or off-by-one errors.\n\n**Detection**: Verify neighbor selection results manually on small, well-understood datasets where correct neighbors can be determined by visual inspection. Implement assertions that verify distance-index correspondence after array operations.\n\n**Solution**: Maintain explicit index tracking throughout all array operations. Use NumPy operations that return both values and indices simultaneously (like `argsort` and `argpartition`) rather than manipulating values and indices separately.\n\n⚠️ **Pitfall: Performance Degradation from Python Loops**\n\nDespite implementing vectorized distance calculations, neighbor finding performance can still suffer dramatically from hidden Python loops in neighbor selection logic. These loops often appear in edge case handling, tie-breaking, or result post-processing code where the performance impact may not be immediately obvious during development with small datasets.\n\nThe performance degradation becomes apparent only when scaling to larger datasets, where O(n) Python loops can consume more time than the vectorized distance calculations they supplement.\n\n**Detection**: Profile neighbor finding performance with varying dataset sizes, looking for performance characteristics that suggest hidden loop iterations. Time individual components of the neighbor finding pipeline to identify bottlenecks.\n\n**Solution**: Replace Python loops with vectorized NumPy operations wherever possible. Use NumPy's advanced indexing, boolean masking, and array manipulation functions to eliminate explicit iteration.\n\n![Prediction Sequence Flow](./diagrams/prediction-flow.svg)\n\n![Neighbor Search Algorithm](./diagrams/neighbor-search.svg)\n\n### Implementation Guidance\n\nThe neighbor finding component requires careful attention to both algorithmic correctness and performance optimization. The implementation builds on the vectorized distance calculations from the Distance Metrics Component while introducing new challenges around efficient neighbor selection and edge case handling.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|----------------|\n| Array Operations | NumPy with basic indexing | NumPy with advanced indexing and broadcasting |\n| Sorting/Selection | `numpy.argsort()` for full sorting | `numpy.argpartition()` for partial selection |\n| Memory Management | Process all queries in memory | Chunked processing with memory monitoring |\n| Tie Breaking | Index-based deterministic ordering | Configurable tie-breaking strategies |\n| Batch Processing | Sequential query processing | Vectorized batch operations with chunking |\n| Performance Monitoring | Manual timing with `time.time()` | `cProfile` with detailed performance analysis |\n\n#### Recommended File Structure\n\n```\nknn_classifier/\n  core/\n    neighbor_finder.py          ← main neighbor finding implementation\n    neighbor_finder_test.py     ← comprehensive unit tests\n  distance/\n    distance_calculator.py      ← imported from Distance Metrics Component\n  data/\n    data_structures.py          ← FeatureVector, NeighborIndices, etc.\n  utils/\n    validation.py              ← parameter validation utilities\n    performance.py             ← performance monitoring helpers\n  examples/\n    neighbor_finding_demo.py    ← demonstration of neighbor finding capabilities\n```\n\n#### Infrastructure Starter Code\n\n**Parameter Validation Utilities** (`utils/validation.py`):\n```python\nimport numpy as np\nfrom typing import Union, Tuple\nfrom ..data.data_structures import FeatureVector, FeatureMatrix\n\ndef validate_k_parameter(k: int, dataset_size: int) -> None:\n    \"\"\"\n    Validate K parameter against dataset constraints.\n    \n    Args:\n        k: Number of neighbors to find\n        dataset_size: Total number of training samples\n        \n    Raises:\n        ValueError: If K is invalid for the given dataset size\n    \"\"\"\n    if not isinstance(k, int):\n        raise ValueError(f\"K must be an integer, got {type(k)}\")\n    \n    if k <= 0:\n        raise ValueError(f\"K must be positive, got {k}\")\n    \n    if k > dataset_size:\n        raise ValueError(\n            f\"K ({k}) cannot exceed dataset size ({dataset_size}). \"\n            f\"Consider using K <= {dataset_size}\"\n        )\n\ndef validate_query_point(query_point: FeatureVector, expected_features: int) -> None:\n    \"\"\"\n    Validate query point dimensions and data types.\n    \n    Args:\n        query_point: Query feature vector\n        expected_features: Expected number of features\n        \n    Raises:\n        ValueError: If query point is invalid\n    \"\"\"\n    if not isinstance(query_point, np.ndarray):\n        raise ValueError(\"Query point must be a NumPy array\")\n    \n    if query_point.ndim != 1:\n        raise ValueError(f\"Query point must be 1-dimensional, got shape {query_point.shape}\")\n    \n    if len(query_point) != expected_features:\n        raise ValueError(\n            f\"Query point has {len(query_point)} features, \"\n            f\"expected {expected_features}\"\n        )\n    \n    if not np.all(np.isfinite(query_point)):\n        raise ValueError(\"Query point contains invalid values (NaN or infinity)\")\n\ndef validate_distance_array(distances: np.ndarray, expected_length: int) -> None:\n    \"\"\"\n    Validate computed distance array for correctness.\n    \n    Args:\n        distances: Array of computed distances\n        expected_length: Expected array length\n        \n    Raises:\n        ValueError: If distance array is invalid\n    \"\"\"\n    if len(distances) != expected_length:\n        raise ValueError(\n            f\"Distance array has length {len(distances)}, \"\n            f\"expected {expected_length}\"\n        )\n    \n    if not np.all(distances >= 0):\n        raise ValueError(\"Distances must be non-negative\")\n    \n    if not np.all(np.isfinite(distances)):\n        raise ValueError(\"Distance array contains invalid values\")\n```\n\n**Performance Monitoring Utilities** (`utils/performance.py`):\n```python\nimport time\nimport numpy as np\nfrom typing import Dict, List, Any\nfrom contextlib import contextmanager\n\nclass PerformanceMonitor:\n    \"\"\"Monitor and report neighbor finding performance metrics.\"\"\"\n    \n    def __init__(self):\n        self.timing_data: Dict[str, List[float]] = {}\n        self.memory_usage: Dict[str, List[float]] = {}\n    \n    @contextmanager\n    def time_operation(self, operation_name: str):\n        \"\"\"Context manager for timing operations.\"\"\"\n        start_time = time.time()\n        try:\n            yield\n        finally:\n            elapsed = time.time() - start_time\n            if operation_name not in self.timing_data:\n                self.timing_data[operation_name] = []\n            self.timing_data[operation_name].append(elapsed)\n    \n    def estimate_memory_usage(self, n_samples: int, n_queries: int, \n                             n_features: int) -> Dict[str, float]:\n        \"\"\"\n        Estimate memory requirements for neighbor finding operations.\n        \n        Args:\n            n_samples: Number of training samples\n            n_queries: Number of query points\n            n_features: Number of features per sample\n            \n        Returns:\n            Dictionary with memory estimates in MB\n        \"\"\"\n        # Distance matrix: n_queries × n_samples × 8 bytes (float64)\n        distance_memory = (n_queries * n_samples * 8) / (1024 * 1024)\n        \n        # Feature matrices: additional memory for data storage\n        feature_memory = (n_samples * n_features * 8) / (1024 * 1024)\n        query_memory = (n_queries * n_features * 8) / (1024 * 1024)\n        \n        # Index arrays and intermediate results\n        index_memory = (n_queries * n_samples * 4) / (1024 * 1024)  # int32\n        \n        return {\n            'distance_matrix_mb': distance_memory,\n            'feature_data_mb': feature_memory + query_memory,\n            'index_arrays_mb': index_memory,\n            'total_estimated_mb': distance_memory + feature_memory + query_memory + index_memory\n        }\n    \n    def get_timing_summary(self) -> Dict[str, Dict[str, float]]:\n        \"\"\"Get summary statistics for all timed operations.\"\"\"\n        summary = {}\n        for operation, times in self.timing_data.items():\n            times_array = np.array(times)\n            summary[operation] = {\n                'mean_seconds': np.mean(times_array),\n                'std_seconds': np.std(times_array),\n                'min_seconds': np.min(times_array),\n                'max_seconds': np.max(times_array),\n                'total_calls': len(times_array)\n            }\n        return summary\n```\n\n#### Core Logic Skeleton Code\n\n**Main Neighbor Finder Implementation** (`core/neighbor_finder.py`):\n```python\nimport numpy as np\nfrom typing import Tuple, List, Optional\nfrom ..data.data_structures import (\n    FeatureVector, FeatureMatrix, DistanceArray, \n    NeighborIndices, DistanceMetric, TrainingData\n)\nfrom ..distance.distance_calculator import calculate_distances_to_point\nfrom ..utils.validation import validate_k_parameter, validate_query_point\nfrom ..utils.performance import PerformanceMonitor\n\nclass NeighborFinder:\n    \"\"\"\n    Efficiently find K nearest neighbors using linear search with optimizations.\n    \n    This implementation prioritizes educational clarity while maintaining\n    practical performance through vectorized operations and memory management.\n    \"\"\"\n    \n    def __init__(self, training_data: TrainingData, \n                 performance_monitor: Optional[PerformanceMonitor] = None):\n        self.training_data = training_data\n        self.performance_monitor = performance_monitor or PerformanceMonitor()\n    \n    def find_k_neighbors(self, query_point: FeatureVector, k: int, \n                        distance_metric: DistanceMetric) -> Tuple[NeighborIndices, DistanceArray]:\n        \"\"\"\n        Find K nearest neighbors to query point using linear search.\n        \n        Args:\n            query_point: Feature vector for which to find neighbors\n            k: Number of nearest neighbors to find\n            distance_metric: Distance metric to use for similarity calculation\n            \n        Returns:\n            Tuple of (neighbor_indices, neighbor_distances) sorted by ascending distance\n            \n        Raises:\n            ValueError: If parameters are invalid or query point is incompatible\n        \"\"\"\n        # TODO 1: Validate input parameters using validation utilities\n        # Hint: Check K value, query point dimensions, and data types\n        \n        # TODO 2: Calculate distances from query point to all training samples\n        # Hint: Use calculate_distances_to_point with vectorized operations\n        # Store result in DistanceArray for downstream processing\n        \n        # TODO 3: Use numpy.argpartition to find indices of K smallest distances\n        # Hint: argpartition(distances, k-1) partitions around K-th element\n        # This is more efficient than full sorting when K << dataset_size\n        \n        # TODO 4: Extract the K neighbor indices from partitioned array\n        # Hint: Take the first K elements from the partitioned indices\n        # These correspond to the K smallest distances\n        \n        # TODO 5: Sort the K selected neighbors by their actual distances\n        # Hint: Use argsort on the distance subset for proper ordering\n        # This ensures neighbors are returned in ascending distance order\n        \n        # TODO 6: Handle distance ties using deterministic tie-breaking\n        # Hint: When distances are equal, prefer smaller indices for reproducibility\n        # Use stable sorting to maintain consistent results\n        \n        # TODO 7: Extract final neighbor distances corresponding to selected indices\n        # Hint: Index into the original distance array using the final neighbor indices\n        # Return both indices and distances as the required tuple\n        \n        # TODO 8: Validate results before returning\n        # Hint: Check that exactly K neighbors were found and distances are valid\n        # Ensure all distances are non-negative and finite\n        \n        pass  # Replace with implementation\n    \n    def find_neighbors_batch(self, query_points: FeatureMatrix, k: int,\n                           distance_metric: DistanceMetric) -> List[Tuple[NeighborIndices, DistanceArray]]:\n        \"\"\"\n        Find K nearest neighbors for multiple query points efficiently.\n        \n        Args:\n            query_points: Matrix of query feature vectors (n_queries × n_features)\n            k: Number of nearest neighbors to find for each query\n            distance_metric: Distance metric to use for all queries\n            \n        Returns:\n            List of (neighbor_indices, neighbor_distances) tuples, one per query\n        \"\"\"\n        # TODO 1: Validate batch parameters and estimate memory requirements\n        # Hint: Check that all query points have correct dimensions\n        # Use performance_monitor to estimate memory usage\n        \n        # TODO 2: Determine optimal chunk size based on available memory\n        # Hint: Balance vectorization benefits against memory constraints\n        # Consider both number of queries and training data size\n        \n        # TODO 3: Process queries in chunks to manage memory usage\n        # Hint: Divide query_points into manageable chunks\n        # Process each chunk completely before moving to next\n        \n        # TODO 4: For each chunk, vectorize distance calculations across all queries\n        # Hint: Compute distance matrix for chunk_queries × training_samples\n        # Use broadcasting and vectorized operations for efficiency\n        \n        # TODO 5: Apply neighbor selection to each row of distance matrix\n        # Hint: Use find_k_neighbors logic or vectorized equivalent\n        # Maintain correspondence between queries and their neighbors\n        \n        # TODO 6: Aggregate results from all chunks into final result list\n        # Hint: Concatenate chunk results while preserving query order\n        # Ensure result list length matches number of input queries\n        \n        pass  # Replace with implementation\n    \n    def handle_distance_ties(self, distances: DistanceArray, \n                           indices: NeighborIndices, k: int) -> Tuple[NeighborIndices, DistanceArray]:\n        \"\"\"\n        Handle cases where multiple neighbors have identical distances.\n        \n        Args:\n            distances: Array of distances (may contain ties)\n            indices: Corresponding neighbor indices\n            k: Number of neighbors to select\n            \n        Returns:\n            Tuple of (selected_indices, selected_distances) with ties resolved\n        \"\"\"\n        # TODO 1: Identify if ties exist around the K-th position\n        # Hint: Check if distances[k-1] equals any distances[k:] values\n        # Also check for ties within the first K positions\n        \n        # TODO 2: If no ties affect the K-th position, return first K neighbors\n        # Hint: Simple case where tie-breaking is not needed\n        # Return indices[:k] and distances[:k]\n        \n        # TODO 3: For ties involving the K-th position, use index-based tie-breaking\n        # Hint: Among tied distances, prefer neighbors with smaller training indices\n        # This ensures deterministic, reproducible results\n        \n        # TODO 4: Sort tied neighbors by their original training data indices\n        # Hint: Create secondary sort key using training sample positions\n        # Apply stable sorting to preserve distance-based primary ordering\n        \n        # TODO 5: Select exactly K neighbors after tie resolution\n        # Hint: Take the first K elements after deterministic tie-breaking\n        # Ensure result length always equals K (when possible)\n        \n        pass  # Replace with implementation\n```\n\n#### Language-Specific Hints\n\n**NumPy Performance Optimization**:\n- Use `numpy.argpartition(arr, k-1)` instead of `numpy.argsort()` when you only need the K smallest elements - this reduces complexity from O(n log n) to O(n + k log k)\n- Leverage `numpy.take()` for efficient index-based array access instead of multiple indexing operations\n- Use `numpy.broadcast_arrays()` to handle dimension mismatches gracefully in batch operations\n- Consider `numpy.memmap()` for very large training datasets that don't fit in memory\n\n**Memory Management**:\n- Monitor memory usage with `psutil` or similar tools during batch processing to detect memory leaks\n- Use `del` statements to explicitly free large intermediate arrays\n- Consider using `numpy.float32` instead of `float64` for distance calculations when precision allows, reducing memory usage by half\n- Implement chunked processing with configurable chunk sizes based on available system memory\n\n**Debugging Techniques**:\n- Use small, manually-verifiable datasets (like 2D points) to validate neighbor finding logic\n- Implement visualization helpers that plot query points, training data, and selected neighbors in 2D space\n- Add detailed logging that reports intermediate values like distance array statistics and partitioning results\n- Create unit tests with known correct answers for edge cases like ties and boundary conditions\n\n#### Milestone Checkpoint\n\nAfter implementing the neighbor finding component, verify functionality using these checkpoints:\n\n**Correctness Verification**:\n```bash\npython -m pytest core/neighbor_finder_test.py -v\n```\nExpected output should show all tests passing, particularly:\n- `test_find_k_neighbors_basic` - basic K neighbor selection\n- `test_distance_tie_handling` - deterministic tie resolution  \n- `test_batch_processing` - consistent batch vs individual results\n- `test_edge_cases` - K=1, K=dataset_size, empty datasets\n\n**Performance Verification**:\nCreate a simple performance test with the Iris dataset:\n```python\nfrom examples.neighbor_finding_demo import performance_demo\nperformance_demo(k_values=[1, 3, 5, 10], n_queries=100)\n```\nExpected behavior: linear increase in runtime with K, batch processing significantly faster than individual queries for multiple queries.\n\n**Visual Verification** (for 2D datasets):\n```python\nfrom examples.neighbor_finding_demo import visualize_neighbors\nvisualize_neighbors(query_point=[2.0, 3.0], k=5, dataset='synthetic_2d')\n```\nExpected output: scatter plot showing query point, training data, and K nearest neighbors highlighted with connecting lines.\n\n**Common Issues and Diagnostics**:\n- **Symptom**: Non-deterministic results across runs → **Check**: Tie-breaking implementation uses stable sorting with index-based secondary key\n- **Symptom**: Memory errors during batch processing → **Check**: Chunk size calculation and memory estimation logic\n- **Symptom**: Performance much slower than expected → **Check**: Ensure vectorized operations used throughout, no hidden Python loops\n- **Symptom**: Incorrect neighbors selected → **Check**: Index correspondence between distances and training samples maintained after sorting operations\n\n\n## Classification Component\n\n> **Milestone(s):** Milestone 2: K-Nearest Neighbors Classification - implements majority voting and weighted voting to convert neighbor information into final class predictions\n\n### Mental Model: Democratic Decision Making\n\nUnderstanding how neighbors vote to determine the final classification is best conceptualized through the lens of democratic decision-making processes. Imagine you're in a new city and need to choose a restaurant for dinner. You ask the 5 people closest to you (your \"neighbors\" in this scenario) for their recommendations. Each person suggests their favorite type of cuisine based on their preferences, which are similar to yours since they're in the same area and situation.\n\nIn the simplest voting scenario, you would choose the cuisine type that the majority of your 5 neighbors recommended - this is **majority voting**. If 3 people suggest Italian, 1 suggests Mexican, and 1 suggests Thai, you'd choose Italian because it has the most votes. However, you might also consider that the person standing right next to you (closest neighbor) has preferences more similar to yours than someone farther away. In this case, you'd give more weight to the recommendations of people closer to you - this is **weighted voting**.\n\nThis democratic process captures the essence of the KNN classification decision-making mechanism. Each training sample in the neighborhood gets to \"vote\" for its class label, and we aggregate these votes using different strategies to make the final prediction. The key insight is that we're leveraging the collective wisdom of similar examples rather than relying on a single decision boundary or rule.\n\nThe classification component serves as the decision-making body that takes the neighborhood information discovered by the neighbor finding component and transforms it into a concrete prediction. Unlike parametric models that learn explicit decision boundaries during training, KNN defers all computation to prediction time and makes decisions through this democratic voting process among the most relevant examples.\n\n### Classifier Interface\n\nThe classifier interface provides the core methods for training the model, making predictions, and configuring the voting behavior. The interface follows the lazy learning paradigm where no computation occurs during training - the system simply stores the training data for use during prediction.\n\n| Method Name | Parameters | Returns | Description |\n|-------------|------------|---------|-------------|\n| `fit` | `X: FeatureMatrix, y: List[ClassLabel]` | `None` | Store training data for lazy learning without performing any computation |\n| `predict` | `X: FeatureMatrix` | `List[ClassLabel]` | Predict class labels for query points using configured voting strategy |\n| `predict_with_confidence` | `X: FeatureMatrix` | `List[PredictionResult]` | Predict with neighbor information and confidence scores for detailed analysis |\n| `get_sample` | `index: int` | `Tuple[FeatureVector, ClassLabel]` | Retrieve single training example by index for neighbor analysis |\n| `set_voting_strategy` | `weighted: bool` | `None` | Configure whether to use majority voting or distance-weighted voting |\n| `set_k_parameter` | `k: int` | `None` | Update the number of neighbors to consider for voting |\n\nThe `KNNClassifier` maintains its configuration state through several key attributes that control the voting behavior and neighbor selection process:\n\n| Attribute | Type | Description |\n|-----------|------|-------------|\n| `k` | `int` | Number of neighbors to consider for voting decisions |\n| `distance_metric` | `DistanceMetric` | Metric used for measuring similarity between feature vectors |\n| `weighted_voting` | `bool` | Whether to use distance-weighted voting or simple majority voting |\n| `training_data` | `Optional[TrainingData]` | Stored training examples used for neighbor-based predictions |\n\nThe training data structure encapsulates all information needed for the lazy learning process:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `features` | `FeatureMatrix` | Feature vectors for all training samples in matrix form |\n| `labels` | `List[ClassLabel]` | Corresponding class labels for each training sample |\n| `n_samples` | `int` | Total number of training examples available |\n| `n_features` | `int` | Dimensionality of feature vectors |\n| `unique_classes` | `Set[ClassLabel]` | Set of all possible class labels in training data |\n\nThe `PredictionResult` structure provides detailed information about each prediction, enabling analysis of the decision-making process:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `predicted_class` | `ClassLabel` | Final class prediction from voting process |\n| `neighbor_indices` | `NeighborIndices` | Indices of K nearest neighbors used for voting |\n| `neighbor_distances` | `DistanceArray` | Distances to each neighbor used for weighted voting |\n| `confidence` | `float` | Confidence score between 0 and 1 based on voting agreement |\n\n### Voting Algorithms\n\nThe classification component implements two primary voting strategies that aggregate neighbor opinions into final predictions. The choice between these strategies significantly impacts the behavior of the classifier, particularly in regions where class boundaries are ambiguous or when neighbors are at varying distances from the query point.\n\n#### Simple Majority Voting\n\nSimple majority voting treats all K neighbors as equal participants in the decision process, regardless of their distance to the query point. The algorithm follows a straightforward democratic process:\n\n1. Collect the class labels of all K nearest neighbors\n2. Count the frequency of each unique class label among the neighbors\n3. Select the class label that appears most frequently as the prediction\n4. Handle ties by selecting the class with the smallest lexicographic order or the class of the nearest neighbor\n\nThe majority voting process can be formalized as finding the mode of the neighbor class distribution. For a query point with neighbors having labels `[label1, label2, ..., labelK]`, the prediction is:\n\n```\nprediction = argmax(count(class)) for class in unique_neighbor_classes\n```\n\nThis approach works well when neighbors are roughly equidistant from the query point or when distance information doesn't provide meaningful discriminative power. The simplicity of majority voting makes it robust and interpretable, but it discards potentially valuable distance information that could improve prediction accuracy.\n\n#### Distance-Weighted Voting\n\nDistance-weighted voting incorporates the principle that closer neighbors should have more influence on the final decision than distant neighbors. This approach addresses situations where one or two very close neighbors might be outvoted by several distant neighbors in simple majority voting.\n\nThe weighted voting algorithm assigns voting weights inversely proportional to distance:\n\n1. Calculate voting weight for each neighbor as `weight = 1 / (distance + epsilon)`\n2. For each unique class, sum the weights of neighbors belonging to that class\n3. Select the class with the highest total weight as the prediction\n4. Handle zero distances by setting epsilon to a small positive value (e.g., 1e-10)\n\nThe mathematical formulation for weighted voting is:\n\n```\nclass_weight(c) = sum(1 / (distance_i + epsilon)) for all neighbors i where label_i = c\nprediction = argmax(class_weight(c)) for c in unique_neighbor_classes\n```\n\nThis weighting scheme ensures that a neighbor at distance 0.1 has 10 times more influence than a neighbor at distance 1.0, reflecting the assumption that very similar examples should dominate the prediction. The epsilon term prevents division by zero when a query point exactly matches a training point.\n\n#### Confidence Scoring\n\nBoth voting strategies can generate confidence scores that indicate the certainty of the prediction. Confidence scoring provides valuable information about prediction reliability and helps identify cases where the classifier is uncertain.\n\nFor majority voting, confidence is calculated as the proportion of neighbors voting for the winning class:\n\n```\nconfidence = count(winning_class) / k\n```\n\nFor weighted voting, confidence represents the proportion of total weight assigned to the winning class:\n\n```\nconfidence = weight(winning_class) / sum(weight(all_classes))\n```\n\nHigh confidence scores (close to 1.0) indicate strong agreement among neighbors, while low scores (close to 1/number_of_classes) suggest high uncertainty with neighbors split among multiple classes.\n\n### Architecture Decisions for Classification\n\n> **Decision: Voting Strategy Selection**\n> - **Context**: The classifier must aggregate neighbor votes into final predictions, with options ranging from simple counting to sophisticated weighting schemes\n> - **Options Considered**: \n>   1. Simple majority voting only\n>   2. Distance-weighted voting only  \n>   3. Configurable voting strategy with both options\n> - **Decision**: Implement configurable voting strategy supporting both majority and weighted voting\n> - **Rationale**: Different datasets and scenarios benefit from different voting strategies - sparse data often benefits from weighted voting while dense, evenly distributed data works well with majority voting. Configurability allows experimentation and optimization.\n> - **Consequences**: Increased implementation complexity but greater flexibility for optimization and experimentation. Enables comparative analysis of voting strategies on different datasets.\n\n| Option | Pros | Cons | Chosen? |\n|--------|------|------|---------|\n| Majority voting only | Simple implementation, fast execution, interpretable results | Ignores distance information, poor performance with varying neighbor distances | No |\n| Weighted voting only | Uses all available information, better handling of distance variations | More complex, potential numerical instability with small distances | No |\n| Configurable strategy | Flexibility for different scenarios, enables comparison and optimization | Increased code complexity, more parameters to tune | Yes |\n\n> **Decision: Tie-Breaking Strategy**\n> - **Context**: When multiple classes receive equal votes (majority voting) or equal weights (weighted voting), the classifier must deterministically choose one class\n> - **Options Considered**:\n>   1. Random selection among tied classes\n>   2. Lexicographic ordering of class labels\n>   3. Selection based on nearest neighbor's class\n> - **Decision**: Use nearest neighbor's class for tie-breaking, with lexicographic fallback\n> - **Rationale**: The nearest neighbor represents the most similar example and should have the strongest influence. Lexicographic ordering provides deterministic fallback when multiple tied classes have the same nearest neighbor distance.\n> - **Consequences**: Deterministic and interpretable tie-breaking that prioritizes similarity. May introduce slight bias toward classes that appear early in lexicographic order in rare edge cases.\n\n| Option | Pros | Cons | Chosen? |\n|--------|------|------|---------|\n| Random selection | Unbiased, simple to implement | Non-deterministic results, poor user experience | No |\n| Lexicographic ordering | Deterministic, simple implementation | May bias toward certain class labels, ignores distance information | Partial |\n| Nearest neighbor class | Uses similarity information, intuitive behavior | Requires additional bookkeeping, complex with multiple equidistant neighbors | Yes |\n\n> **Decision: Confidence Score Calculation**\n> - **Context**: Users need to understand prediction certainty for decision-making, especially in high-stakes applications\n> - **Options Considered**:\n>   1. No confidence scores\n>   2. Vote proportion confidence\n>   3. Statistical significance testing\n> - **Decision**: Implement vote proportion confidence with separate calculations for majority and weighted voting\n> - **Rationale**: Vote proportion is intuitive, computationally efficient, and provides meaningful uncertainty quantification. Statistical testing adds complexity without clear benefits for most use cases.\n> - **Consequences**: Enables uncertainty-aware decision making and threshold-based prediction filtering. Simple calculation maintains performance while providing valuable information.\n\n| Option | Pros | Cons | Chosen? |\n|--------|------|------|---------|\n| No confidence scores | Simplest implementation, fastest execution | No uncertainty quantification, limited decision support | No |\n| Vote proportion | Intuitive interpretation, efficient calculation, meaningful uncertainty measure | Less sophisticated than statistical approaches | Yes |\n| Statistical significance | Rigorous uncertainty quantification, theoretical grounding | Complex implementation, computational overhead, difficult interpretation | No |\n\n> **Decision: Handling Zero Distances**\n> - **Context**: When query points exactly match training points (distance = 0), weighted voting faces division by zero\n> - **Options Considered**:\n>   1. Add small epsilon to all distances\n>   2. Special case handling for zero distances\n>   3. Use inverse square distances\n> - **Decision**: Add small epsilon (1e-10) to all distances uniformly\n> - **Rationale**: Uniform epsilon addition is simple, numerically stable, and preserves relative distance relationships. The epsilon value is small enough to maintain strong preference for exact matches while preventing numerical issues.\n> - **Consequences**: Prevents division by zero while maintaining intuitive behavior where exact matches dominate voting. Slightly modifies distance relationships but impact is negligible for practical purposes.\n\n| Option | Pros | Cons | Chosen? |\n|--------|------|------|---------|\n| Uniform epsilon addition | Simple implementation, numerically stable, preserves relationships | Slightly modifies distance relationships | Yes |\n| Special case handling | Mathematically pure, no distance modification | Complex branching logic, potential edge cases | No |\n| Inverse square distances | Reduces sensitivity to distance variations | Changes fundamental distance interpretation, may over-smooth | No |\n\n### Common Classification Pitfalls\n\n#### ⚠️ **Pitfall: Voting Ties with Even K Values**\n\nWhen using an even number of neighbors (e.g., K=4) with binary classification, tie votes are common and can lead to inconsistent predictions. A query point with 2 neighbors from each class has no clear majority, forcing reliance on tie-breaking rules that may not reflect true class probabilities.\n\n**Why this occurs**: Even K values create natural conditions for tied votes, especially in binary classification where 50-50 splits are mathematically likely. The tie-breaking mechanism becomes the primary decision factor rather than neighbor consensus.\n\n**How to avoid**: Use odd K values (3, 5, 7, 9) to reduce tie probability, especially for binary classification problems. When even K values are necessary, ensure robust tie-breaking strategies and consider using weighted voting which is less susceptible to exact ties.\n\n**Detection**: Monitor prediction confidence scores - frequent low confidence scores around 0.5 indicate excessive tie situations.\n\n#### ⚠️ **Pitfall: Class Imbalance Bias in Voting**\n\nIn datasets with severe class imbalance (e.g., 90% class A, 10% class B), the KNN classifier tends to predict the majority class even when query points are close to minority class examples. This occurs because random sampling of neighbors is more likely to include majority class examples.\n\n**Why this occurs**: The smoothness assumption of KNN breaks down in imbalanced datasets where minority class instances are sparse. Local neighborhoods tend to be dominated by majority class examples even near true minority class regions.\n\n**How to avoid**: Use weighted voting to emphasize closer neighbors, consider stratified sampling for neighbor selection, or apply distance-based thresholding to ensure meaningful class representation in neighborhoods. Alternatively, use cost-sensitive voting where minority class votes receive higher weights.\n\n**Detection**: Calculate per-class recall metrics - low recall for minority classes indicates imbalance bias.\n\n#### ⚠️ **Pitfall: Inappropriate K Parameter Selection**\n\nChoosing K too small (K=1) leads to high variance and sensitivity to outliers, where single noisy examples can dominate predictions. Choosing K too large approaches global class distribution, losing the benefits of local similarity and potentially causing underfitting.\n\n**Why this occurs**: K parameter directly controls the bias-variance tradeoff. Small K gives low bias but high variance (overfitting to local noise), while large K gives low variance but high bias (underfitting to global patterns).\n\n**How to avoid**: Use cross-validation to systematically evaluate different K values on your specific dataset. Start with K = sqrt(n_samples) as a rule-of-thumb, then test odd values in the range [1, sqrt(n_samples) * 2]. Monitor both training and validation accuracy to detect overfitting.\n\n**Detection**: Plot learning curves showing training and validation accuracy versus K - optimal K minimizes validation error while maintaining reasonable training performance.\n\n#### ⚠️ **Pitfall: Distance Metric Mismatch with Voting Strategy**\n\nUsing distance metrics that don't align with the classification task characteristics leads to poor neighbor selection and voting outcomes. For example, using Euclidean distance on high-dimensional sparse data (curse of dimensionality) or cosine distance on data where magnitude matters.\n\n**Why this occurs**: Different distance metrics capture different notions of similarity. Euclidean distance measures geometric proximity, Manhattan distance measures coordinate-wise differences, and cosine distance measures angular similarity. Mismatched metrics produce irrelevant neighbors.\n\n**How to avoid**: Understand your data characteristics and choose appropriate distance metrics. Use Euclidean for continuous features with meaningful magnitude, Manhattan for categorical or ordinal features, and cosine for high-dimensional sparse features. Validate metric choice through cross-validation experiments.\n\n**Detection**: Compare classification accuracy across different distance metrics - significant performance differences indicate metric sensitivity.\n\n#### ⚠️ **Pitfall: Numerical Instability in Weighted Voting**\n\nWhen neighbors have very small distances (near zero), the inverse distance weighting can produce extremely large weights that dominate the voting process. This creates numerical instability and reduces the influence of other relevant neighbors to negligible levels.\n\n**Why this occurs**: The 1/distance weighting scheme amplifies small distance differences into large weight differences. A neighbor at distance 0.001 receives 1000 times more weight than a neighbor at distance 1.0, creating extreme imbalances.\n\n**How to avoid**: Add a small epsilon value to all distances before inversion, use alternative weighting schemes like Gaussian weights (exp(-distance²)), or implement weight normalization to prevent extreme values.\n\n**Detection**: Monitor weight distributions during voting - weights varying by more than 3-4 orders of magnitude indicate potential instability.\n\n#### ⚠️ **Pitfall: Ignoring Feature Scale Differences**\n\nWhen features have vastly different scales (e.g., age in years vs. income in dollars), distance calculations become dominated by high-magnitude features, leading to poor neighbor selection and biased voting outcomes.\n\n**Why this occurs**: Distance metrics sum contributions from all features, so features with larger scales contribute disproportionately to distance calculations. A $1000 income difference might overshadow a 10-year age difference even when age is more predictive.\n\n**How to avoid**: Apply feature scaling (standardization or normalization) before distance calculation. Standardization (mean=0, std=1) works well for normally distributed features, while min-max normalization (range [0,1]) suits features with known bounds.\n\n**Detection**: Examine feature contributions to distance calculations - if one feature consistently dominates distances, scaling is likely needed.\n\n### Implementation Guidance\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|----------------|\n| Voting Logic | Dictionary counting with max() | NumPy vectorized operations with bincount |\n| Confidence Scoring | Basic proportion calculation | Statistical confidence intervals |\n| Tie Breaking | Simple lexicographic ordering | Sophisticated multi-criteria decision |\n| Weight Calculation | Direct inverse distance | Gaussian or exponential decay functions |\n\n#### Recommended File Structure\n\n```\nsrc/knn_classifier/\n  classification/\n    __init__.py              ← expose main KNNClassifier class\n    classifier.py            ← core KNNClassifier implementation\n    voting_strategies.py     ← majority and weighted voting algorithms\n    confidence_calculator.py ← confidence scoring logic\n    tie_breaker.py          ← tie resolution strategies\n  tests/\n    test_classifier.py       ← classifier interface tests\n    test_voting.py          ← voting algorithm tests\n    test_confidence.py      ← confidence calculation tests\n```\n\n#### Infrastructure Starter Code\n\n```python\n\"\"\"\nComplete voting strategy implementations for KNN classification.\nCopy this file and use these functions in your KNNClassifier.\n\"\"\"\n\nimport numpy as np\nfrom typing import List, Dict, Set, Tuple\nfrom collections import Counter\nfrom enum import Enum\n\nclass VotingStrategy(Enum):\n    MAJORITY = \"majority\"\n    WEIGHTED = \"weighted\"\n\ndef majority_vote(neighbor_labels: List, k: int) -> Tuple[str, float]:\n    \"\"\"\n    Complete implementation of majority voting for KNN classification.\n    Returns the most frequent class and confidence score.\n    \"\"\"\n    # Count frequency of each class\n    vote_counts = Counter(neighbor_labels[:k])\n    \n    # Find class with maximum votes\n    winning_class = vote_counts.most_common(1)[0][0]\n    winning_votes = vote_counts[winning_class]\n    \n    # Calculate confidence as proportion of votes\n    confidence = winning_votes / k\n    \n    return winning_class, confidence\n\ndef weighted_vote(neighbor_labels: List, neighbor_distances: np.ndarray, \n                  k: int, epsilon: float = 1e-10) -> Tuple[str, float]:\n    \"\"\"\n    Complete implementation of weighted voting for KNN classification.\n    Weights votes by inverse distance to give closer neighbors more influence.\n    \"\"\"\n    # Calculate weights as inverse distances with epsilon for stability\n    weights = 1.0 / (neighbor_distances[:k] + epsilon)\n    \n    # Accumulate weights for each class\n    class_weights = {}\n    for label, weight in zip(neighbor_labels[:k], weights):\n        class_weights[label] = class_weights.get(label, 0.0) + weight\n    \n    # Find class with maximum total weight\n    winning_class = max(class_weights, key=class_weights.get)\n    winning_weight = class_weights[winning_class]\n    \n    # Calculate confidence as proportion of total weight\n    total_weight = sum(class_weights.values())\n    confidence = winning_weight / total_weight\n    \n    return winning_class, confidence\n\ndef resolve_ties(tied_classes: List, neighbor_labels: List, \n                neighbor_distances: np.ndarray) -> str:\n    \"\"\"\n    Complete tie-breaking implementation using nearest neighbor's class.\n    Falls back to lexicographic ordering if nearest neighbor ties exist.\n    \"\"\"\n    # Find the class of the nearest neighbor\n    nearest_class = neighbor_labels[0]\n    \n    # If nearest neighbor's class is among tied classes, choose it\n    if nearest_class in tied_classes:\n        return nearest_class\n    \n    # Otherwise, fall back to lexicographic ordering\n    return min(tied_classes)\n\nclass ConfidenceCalculator:\n    \"\"\"Complete confidence scoring implementation for both voting strategies.\"\"\"\n    \n    @staticmethod\n    def majority_confidence(class_counts: Dict, total_votes: int) -> float:\n        \"\"\"Calculate confidence for majority voting as vote proportion.\"\"\"\n        max_votes = max(class_counts.values())\n        return max_votes / total_votes\n    \n    @staticmethod\n    def weighted_confidence(class_weights: Dict) -> float:\n        \"\"\"Calculate confidence for weighted voting as weight proportion.\"\"\"\n        total_weight = sum(class_weights.values())\n        max_weight = max(class_weights.values())\n        return max_weight / total_weight\n    \n    @staticmethod\n    def uncertainty_threshold(confidence: float, threshold: float = 0.5) -> bool:\n        \"\"\"Determine if prediction meets minimum confidence threshold.\"\"\"\n        return confidence >= threshold\n```\n\n#### Core Logic Skeleton Code\n\n```python\nclass KNNClassifier:\n    \"\"\"\n    K-Nearest Neighbors classifier with configurable voting strategies.\n    Implements lazy learning with majority and weighted voting options.\n    \"\"\"\n    \n    def __init__(self, k: int = 3, distance_metric: DistanceMetric = DistanceMetric.EUCLIDEAN, \n                 weighted_voting: bool = False):\n        # TODO 1: Initialize classifier parameters (k, distance_metric, weighted_voting)\n        # TODO 2: Initialize training_data as None (lazy learning - no training computation)\n        # TODO 3: Validate k parameter is positive integer\n        pass\n    \n    def fit(self, X: FeatureMatrix, y: List[ClassLabel]) -> None:\n        \"\"\"\n        Store training data for lazy learning without performing computation.\n        KNN defers all computation to prediction time.\n        \"\"\"\n        # TODO 1: Validate input dimensions - X and y must have same number of samples\n        # TODO 2: Create TrainingData object with features=X, labels=y\n        # TODO 3: Calculate and store n_samples, n_features from X.shape\n        # TODO 4: Extract unique_classes from y using set() conversion\n        # TODO 5: Store TrainingData object in self.training_data\n        # Hint: No computation occurs here - this is lazy learning\n        pass\n    \n    def predict(self, X: FeatureMatrix) -> List[ClassLabel]:\n        \"\"\"\n        Predict class labels for query points using configured voting strategy.\n        \"\"\"\n        # TODO 1: Check that model is fitted (self.training_data is not None)\n        # TODO 2: For each query point in X, call self._predict_single_point\n        # TODO 3: Extract predicted_class from each PredictionResult\n        # TODO 4: Return list of predicted class labels\n        # Hint: Use list comprehension for efficiency\n        pass\n    \n    def predict_with_confidence(self, X: FeatureMatrix) -> List[PredictionResult]:\n        \"\"\"\n        Predict with detailed neighbor and confidence information.\n        \"\"\"\n        # TODO 1: Check that model is fitted (self.training_data is not None)\n        # TODO 2: For each query point in X, call self._predict_single_point\n        # TODO 3: Return list of complete PredictionResult objects\n        pass\n    \n    def _predict_single_point(self, query_point: FeatureVector) -> PredictionResult:\n        \"\"\"\n        Core prediction logic for single query point.\n        Coordinates neighbor finding and voting to produce final prediction.\n        \"\"\"\n        # TODO 1: Find K nearest neighbors using self._find_neighbors\n        # TODO 2: Extract neighbor labels using neighbor indices\n        # TODO 3: Apply voting strategy (majority or weighted) using self._vote\n        # TODO 4: Calculate confidence score using self._calculate_confidence\n        # TODO 5: Create and return PredictionResult object\n        # Hint: This method orchestrates the entire prediction pipeline\n        pass\n    \n    def _find_neighbors(self, query_point: FeatureVector) -> Tuple[NeighborIndices, DistanceArray]:\n        \"\"\"\n        Find K nearest neighbors to query point using configured distance metric.\n        \"\"\"\n        # TODO 1: Calculate distances from query_point to all training samples\n        # TODO 2: Use np.argsort to get indices sorted by distance\n        # TODO 3: Select first K indices and corresponding distances\n        # TODO 4: Validate that K <= number of training samples\n        # TODO 5: Return neighbor indices and distances as tuple\n        # Hint: Use calculate_distances_to_point from distance metrics component\n        pass\n    \n    def _vote(self, neighbor_labels: List[ClassLabel], \n             neighbor_distances: DistanceArray) -> Tuple[ClassLabel, float]:\n        \"\"\"\n        Apply voting strategy to determine predicted class and confidence.\n        \"\"\"\n        if self.weighted_voting:\n            # TODO 1: Call weighted_vote with labels and distances\n            # TODO 2: Handle potential ties using resolve_ties function\n            # TODO 3: Return winning class and confidence score\n            pass\n        else:\n            # TODO 1: Call majority_vote with neighbor labels\n            # TODO 2: Handle potential ties using resolve_ties function  \n            # TODO 3: Return winning class and confidence score\n            pass\n    \n    def set_k_parameter(self, k: int) -> None:\n        \"\"\"Update the number of neighbors for voting.\"\"\"\n        # TODO 1: Validate k is positive integer\n        # TODO 2: If model is fitted, validate k <= n_samples\n        # TODO 3: Update self.k parameter\n        pass\n    \n    def set_voting_strategy(self, weighted: bool) -> None:\n        \"\"\"Configure voting strategy between majority and weighted voting.\"\"\"\n        # TODO 1: Update self.weighted_voting parameter\n        # TODO 2: Log strategy change for debugging\n        pass\n```\n\n#### Language-Specific Hints\n\n**NumPy Operations for Efficient Voting:**\n- Use `np.bincount()` for fast frequency counting in majority voting\n- Use `np.argsort()` for efficient neighbor sorting by distance  \n- Use `collections.Counter` for readable class frequency counting\n- Use `np.argmax()` to find winning class efficiently\n\n**Handling Edge Cases:**\n- Check for empty neighbor lists before voting (K > dataset size)\n- Handle single-class datasets by returning that class with confidence 1.0\n- Use `np.isfinite()` to detect invalid distances from numerical errors\n- Implement graceful degradation when K exceeds available neighbors\n\n**Performance Optimization:**\n- Pre-compute distance matrices for small datasets (< 1000 samples)\n- Use vectorized operations instead of Python loops for distance calculations\n- Cache neighbor computations for repeated queries to same points\n- Consider using `numba.jit` decorator for hot path functions\n\n#### Milestone Checkpoint\n\nAfter implementing the classification component, verify correct behavior:\n\n**Test Commands:**\n```bash\npython -m pytest tests/test_classifier.py -v\npython -m pytest tests/test_voting.py -v  \npython test_classification_integration.py\n```\n\n**Expected Behavior:**\n- Majority voting produces deterministic results for the same inputs\n- Weighted voting gives higher influence to closer neighbors\n- Confidence scores range between 0 and 1 with intuitive interpretation\n- Tie-breaking produces consistent results across runs\n- Edge cases (K=1, single class data) handle gracefully\n\n**Manual Verification:**\n```python\n# Create simple test case\nX_train = np.array([[0, 0], [1, 1], [2, 2], [3, 3]])\ny_train = ['A', 'A', 'B', 'B']\nclassifier = KNNClassifier(k=3, weighted_voting=False)\nclassifier.fit(X_train, y_train)\n\n# Test prediction\nquery = np.array([[1.5, 1.5]])\nresult = classifier.predict_with_confidence(query)\nprint(f\"Prediction: {result[0].predicted_class}\")\nprint(f\"Confidence: {result[0].confidence}\")\nprint(f\"Neighbors: {result[0].neighbor_indices}\")\n```\n\n**Expected Output:**\n- Prediction should reflect majority class among 3 nearest neighbors\n- Confidence should be 0.67 or 1.0 depending on class distribution\n- Neighbor indices should be [1, 2, 0] or similar based on distances\n\n\n## Evaluation and Optimization Component\n\n> **Milestone(s):** Milestone 3: Improvements & Evaluation - implements cross-validation, hyperparameter tuning, and performance metrics to find optimal K values and assess model quality\n\nThe evaluation and optimization component transforms our KNN classifier from a basic prototype into a scientifically rigorous machine learning system. This component addresses the fundamental question that haunts every machine learning practitioner: \"How do we know our model is actually good?\" More specifically for KNN, it tackles the critical challenge of selecting the optimal value of K - the hyperparameter that determines how many neighbors influence each prediction.\n\nThis component implements the scientific method for machine learning: systematic experimentation through cross-validation, objective measurement through comprehensive metrics, and evidence-based optimization through grid search. Without proper evaluation, our KNN classifier would be like a compass without calibration - it might point somewhere, but we wouldn't know if that direction leads us toward accurate predictions or away from them.\n\n### Mental Model: Scientific Testing\n\nUnderstanding rigorous evaluation requires thinking like a scientist conducting experiments. Imagine you're a medical researcher testing a new treatment. You can't simply give the treatment to patients and declare success based on gut feeling - you need controlled experiments, statistical significance, and peer review.\n\n**The Laboratory Analogy**: Think of cross-validation as running multiple controlled experiments in separate laboratories. Each laboratory (fold) gets a different subset of patients (training data) to develop the treatment protocol, then tests it on a completely separate group of patients (validation data) who were never seen during protocol development. Only by repeating this experiment across multiple independent laboratories can we trust that our treatment works beyond the specific patients we happened to encounter.\n\n**The Hypothesis Testing Mindset**: In our KNN context, each K value represents a different hypothesis about how many neighbors should influence decisions. K=1 hypothesizes that only the single closest neighbor matters - like asking only your best friend for advice. K=50 hypothesizes that we need a large community consensus - like surveying the entire neighborhood before making a decision. Cross-validation provides the experimental framework to test these competing hypotheses objectively.\n\n**The Measurement Precision Principle**: Just as scientists use multiple measurement instruments to reduce error, we compute multiple evaluation metrics (accuracy, precision, recall, F1-score) to capture different aspects of model performance. A model might achieve high accuracy by correctly predicting the majority class while completely failing on minority classes - something that precision and recall would reveal but accuracy alone might hide.\n\n**The Reproducibility Standard**: Scientific results must be reproducible by independent researchers. Similarly, our evaluation framework must produce consistent results across multiple runs through careful random seed management and standardized data splitting procedures. This ensures that our \"discovery\" of the optimal K value isn't just a lucky accident of data shuffling.\n\n### Evaluation Interface\n\nThe evaluation interface provides the methods and contracts that enable systematic assessment of KNN performance across different configurations and datasets. This interface abstracts the complexity of statistical validation while exposing the essential controls that researchers and practitioners need for rigorous model evaluation.\n\nThe core responsibility of this interface is to separate the concerns of model training from model assessment. During evaluation, the interface ensures that no information from validation data leaks into the training process - a principle as fundamental to machine learning as sterilization is to medical research.\n\n| Method Name | Parameters | Returns | Description |\n|-------------|------------|---------|-------------|\n| `k_fold_cross_validate` | `X: FeatureMatrix, y: List[ClassLabel], k_folds: int, k_neighbors: int, distance_metric: DistanceMetric, random_seed: int` | `CrossValidationResult` | Performs K-fold cross-validation and returns aggregated performance metrics across all folds |\n| `grid_search_k` | `X: FeatureMatrix, y: List[ClassLabel], k_values: List[int], cv_folds: int, distance_metric: DistanceMetric, random_seed: int` | `GridSearchResult` | Tests multiple K values through cross-validation to find optimal hyperparameter |\n| `calculate_confusion_matrix` | `y_true: List[ClassLabel], y_pred: List[ClassLabel], class_labels: List[ClassLabel]` | `ConfusionMatrix` | Computes confusion matrix showing true vs predicted classifications for each class |\n| `calculate_classification_metrics` | `y_true: List[ClassLabel], y_pred: List[ClassLabel], average: str` | `ClassificationMetrics` | Calculates precision, recall, F1-score, and accuracy with support for micro/macro/weighted averaging |\n| `split_stratified_folds` | `X: FeatureMatrix, y: List[ClassLabel], n_folds: int, random_seed: int` | `List[FoldIndices]` | Creates stratified train/validation splits that preserve class distribution across folds |\n| `validate_evaluation_parameters` | `X: FeatureMatrix, y: List[ClassLabel], k_values: List[int], cv_folds: int` | `None` | Validates that evaluation parameters are consistent with dataset size and constraints |\n\nThe interface design follows the principle of **separation of statistical concerns**. Each method handles one specific aspect of evaluation: data splitting, metric calculation, hyperparameter search, or result aggregation. This modular approach allows users to compose complex evaluation pipelines while maintaining clear boundaries between different statistical operations.\n\n**Key Design Principles**:\n\n**Deterministic Reproducibility**: All methods accept random seed parameters to ensure that evaluation results can be exactly reproduced across different runs and environments. This determinism is crucial for scientific validity and debugging evaluation pipelines.\n\n**Stratified Sampling**: The interface enforces stratified sampling for cross-validation splits, ensuring that each fold maintains the same class distribution as the original dataset. This prevents evaluation artifacts where some folds accidentally exclude entire classes.\n\n**Comprehensive Metric Coverage**: Rather than returning only accuracy, the interface computes the full spectrum of classification metrics. This comprehensive approach reveals model weaknesses that single metrics might hide.\n\n**Parameter Validation**: The interface includes explicit validation methods that check for common configuration errors before expensive evaluation begins. This fail-fast approach saves computational time and prevents misleading results from invalid configurations.\n\n### Evaluation Algorithms\n\nThe evaluation algorithms implement the statistical procedures that transform raw predictions into meaningful performance assessments. These algorithms must handle the delicate balance between computational efficiency and statistical rigor while avoiding the subtle pitfalls that can invalidate machine learning experiments.\n\n#### K-Fold Cross-Validation Algorithm\n\nK-fold cross-validation serves as the foundation for all rigorous evaluation in our system. This algorithm addresses the fundamental challenge of limited data: how do we get reliable performance estimates when we can't afford to hold out a large validation set?\n\n![Cross-Validation State Machine](./diagrams/cross-validation.svg)\n\nThe cross-validation algorithm operates through a carefully orchestrated sequence of data partitioning, model training, and performance measurement:\n\n1. **Stratified Data Partitioning**: The algorithm begins by dividing the dataset into K approximately equal folds while preserving the original class distribution in each fold. This stratification prevents evaluation bias where some folds accidentally under-represent or completely exclude certain classes.\n\n2. **Fold Iteration Setup**: For each of the K iterations, the algorithm designates one fold as the validation set and combines the remaining K-1 folds into the training set. This ensures that every data point is used for validation exactly once across all iterations.\n\n3. **Isolated Model Training**: Within each iteration, the algorithm creates a fresh `KNNClassifier` instance and trains it exclusively on the training fold data. This isolation prevents information leakage between iterations and ensures that each performance measurement is independent.\n\n4. **Validation Prediction**: The trained model makes predictions on the validation fold data - data that was completely hidden during training. The algorithm collects these predictions along with the true labels for metric calculation.\n\n5. **Per-Fold Metric Calculation**: The algorithm computes the full suite of classification metrics (accuracy, precision, recall, F1-score) for each fold's predictions. These per-fold metrics reveal the consistency of model performance across different data subsets.\n\n6. **Statistical Aggregation**: After all K iterations complete, the algorithm aggregates the per-fold metrics using both mean and standard deviation calculations. The mean provides the expected performance estimate while the standard deviation indicates performance stability.\n\n7. **Confidence Interval Computation**: The algorithm calculates confidence intervals around the mean performance estimates using the standard error of the mean. These intervals provide statistical bounds on the true performance values.\n\n#### Grid Search Optimization Algorithm\n\nThe grid search algorithm systematically explores the hyperparameter space to identify the K value that maximizes cross-validated performance. This exhaustive search approach guarantees finding the optimal K within the specified search range.\n\n![Hyperparameter Optimization Flow](./diagrams/hyperparameter-optimization.svg)\n\nThe grid search process follows a nested optimization structure:\n\n1. **Parameter Space Definition**: The algorithm accepts a list of K values to evaluate, typically ranging from 1 to some maximum value determined by dataset size and computational constraints.\n\n2. **Outer Loop: K Value Iteration**: For each candidate K value, the algorithm initiates a complete cross-validation experiment. This outer loop ensures that every K value receives identical evaluation treatment.\n\n3. **Inner Loop: Cross-Validation Execution**: Within each K value iteration, the algorithm runs the full K-fold cross-validation procedure described above. This inner loop produces the performance estimate for the current K value.\n\n4. **Performance Tracking**: The algorithm maintains a performance history that records the mean and standard deviation of each metric for every K value tested. This history enables comprehensive analysis of the hyperparameter sensitivity.\n\n5. **Optimal K Selection**: After evaluating all candidate K values, the algorithm selects the K that maximizes the primary optimization metric (typically cross-validated accuracy). In case of ties, the algorithm applies a tie-breaking rule favoring smaller K values to reduce model complexity.\n\n6. **Statistical Significance Testing**: The algorithm performs statistical significance tests to determine whether the performance differences between different K values are statistically meaningful or simply due to random variation.\n\n7. **Final Model Training**: Once the optimal K is identified, the algorithm trains a final model using the optimal K and the entire dataset to produce the production-ready classifier.\n\n#### Confusion Matrix Algorithm\n\nThe confusion matrix algorithm provides detailed insight into model behavior by tabulating the relationship between predicted and actual class labels. This tabulation reveals patterns of misclassification that aggregate metrics might obscure.\n\nThe confusion matrix construction follows these steps:\n\n1. **Class Label Enumeration**: The algorithm identifies all unique class labels present in either the true labels or predicted labels, ensuring that the matrix accommodates all possible classification outcomes.\n\n2. **Matrix Initialization**: The algorithm creates a square matrix with dimensions equal to the number of unique classes, initializing all entries to zero. The matrix rows represent true classes while columns represent predicted classes.\n\n3. **Prediction Tabulation**: For each prediction-truth pair, the algorithm increments the appropriate matrix cell. The cell at position (i, j) counts the number of times class i was predicted as class j.\n\n4. **Normalization Options**: The algorithm supports multiple normalization schemes: raw counts, row-wise normalization (showing the distribution of predictions for each true class), and overall normalization (showing proportions of the total predictions).\n\n5. **Diagonal Analysis**: The algorithm identifies the diagonal elements (correct predictions) and off-diagonal elements (misclassifications) to compute class-specific accuracy rates and confusion patterns.\n\n6. **Metric Derivation**: From the confusion matrix, the algorithm derives per-class precision, recall, and F1-score values by analyzing the row and column sums relative to the diagonal elements.\n\n### Architecture Decisions for Evaluation\n\nThe evaluation component requires several critical architectural decisions that balance statistical rigor with computational efficiency. These decisions shape how our system approaches the fundamental trade-offs in machine learning evaluation.\n\n> **Decision: Cross-Validation Strategy Selection**\n> - **Context**: Multiple validation strategies exist (holdout, K-fold, leave-one-out, bootstrap), each with different statistical properties and computational costs. KNN evaluation needs reliable performance estimates while managing computational expense.\n> - **Options Considered**: \n>   - Holdout validation (single train/test split)\n>   - K-fold cross-validation (multiple train/test splits)\n>   - Leave-one-out cross-validation (N train/test splits where N is dataset size)\n> - **Decision**: Implement K-fold cross-validation as the primary strategy with configurable fold count\n> - **Rationale**: K-fold provides the optimal balance between statistical reliability and computational feasibility. Holdout validation wastes data and provides unstable estimates. Leave-one-out is computationally prohibitive for large datasets and can have high variance. K-fold with K=5 or K=10 provides robust estimates while remaining computationally tractable.\n> - **Consequences**: Enables reliable performance estimation for datasets of varying sizes. Introduces complexity in data splitting and aggregation logic. Requires careful handling of stratification to maintain class balance across folds.\n\n| Option | Pros | Cons |\n|--------|------|------|\n| Holdout Validation | Simple implementation, fast execution | Wastes training data, unstable estimates, sensitive to data split |\n| K-Fold Cross-Validation | Reliable estimates, efficient data use, tunable accuracy/speed tradeoff | Moderate complexity, requires stratification logic |\n| Leave-One-Out | Maximum data utilization, deterministic results | Computationally expensive, high variance estimates |\n\n> **Decision: Hyperparameter Search Strategy**\n> - **Context**: KNN's primary hyperparameter K requires optimization, but the search space and optimization strategy affect both performance quality and computational cost. Different search strategies offer different trade-offs between thoroughness and efficiency.\n> - **Options Considered**:\n>   - Exhaustive grid search over all K values\n>   - Random search with early stopping\n>   - Bayesian optimization with Gaussian processes\n> - **Decision**: Implement exhaustive grid search with user-defined K ranges\n> - **Rationale**: KNN's hyperparameter space is one-dimensional and discrete, making exhaustive search computationally feasible. Grid search guarantees finding the global optimum within the search range. Random search and Bayesian optimization add complexity without significant benefits for such a simple parameter space.\n> - **Consequences**: Guarantees optimal K discovery within search bounds. Simple implementation and debugging. Can be computationally expensive for large K ranges, but this is manageable with reasonable range selection.\n\n| Option | Pros | Cons |\n|--------|------|------|\n| Grid Search | Guaranteed global optimum, simple implementation, deterministic results | Can be computationally expensive for large ranges |\n| Random Search | Efficient for high-dimensional spaces, can find good solutions quickly | No optimality guarantee, less thorough than grid search |\n| Bayesian Optimization | Intelligent search guidance, efficient in expensive evaluation scenarios | Complex implementation, overkill for 1D parameter space |\n\n> **Decision: Evaluation Metric Selection**\n> - **Context**: Classification performance can be measured through various metrics (accuracy, precision, recall, F1-score, AUC), each emphasizing different aspects of model behavior. The choice affects how we define \"optimal\" performance and influences hyperparameter selection.\n> - **Options Considered**:\n>   - Accuracy only (simple but potentially misleading)\n>   - F1-score only (balanced precision/recall)\n>   - Comprehensive metric suite (accuracy, precision, recall, F1)\n> - **Decision**: Implement comprehensive metric calculation with accuracy as the primary optimization target\n> - **Rationale**: Different metrics reveal different model characteristics. Accuracy alone can be misleading with imbalanced datasets. Precision and recall provide insight into class-specific performance. F1-score balances precision and recall. Computing all metrics provides complete performance picture while using accuracy for optimization maintains simplicity.\n> - **Consequences**: Provides complete performance assessment for thorough model evaluation. Enables detection of class-specific performance issues. Adds computational overhead and complexity in metric calculation and reporting.\n\n| Option | Pros | Cons |\n|--------|------|------|\n| Accuracy Only | Simple implementation, widely understood, single optimization target | Misleading with imbalanced data, hides class-specific issues |\n| F1-Score Only | Balances precision/recall, robust to class imbalance | Less intuitive than accuracy, single metric may miss nuances |\n| Comprehensive Suite | Complete performance picture, reveals all model characteristics | Complex reporting, potential confusion about optimization target |\n\n> **Decision: Random Seed Management**\n> - **Context**: Machine learning evaluation must be reproducible for scientific validity and debugging. Random processes in data splitting and tie-breaking can produce different results across runs. The system needs deterministic behavior while maintaining statistical validity.\n> - **Options Considered**:\n>   - No seed management (non-reproducible results)\n>   - Global random seed (simple but inflexible)\n>   - Per-operation seed management (complex but flexible)\n> - **Decision**: Implement per-operation seed management with hierarchical seed derivation\n> - **Rationale**: Reproducibility is essential for scientific machine learning. Global seeds are fragile and break when evaluation order changes. Per-operation seeds provide fine-grained control and robust reproducibility. Hierarchical derivation (master seed generates operation-specific seeds) balances simplicity with flexibility.\n> - **Consequences**: Enables exact reproduction of evaluation results across different environments and runs. Adds complexity in seed management and propagation. Requires careful design to avoid seed correlation issues.\n\n| Option | Pros | Cons |\n|--------|------|------|\n| No Seed Management | Simple implementation, no additional complexity | Non-reproducible results, impossible debugging |\n| Global Random Seed | Easy to implement, single point of control | Fragile to code changes, limited flexibility |\n| Per-Operation Seeds | Robust reproducibility, fine-grained control | Complex implementation, requires careful design |\n\n### Common Evaluation Pitfalls\n\nEvaluation and optimization introduce subtle pitfalls that can invalidate experimental results or lead to overconfident performance estimates. These pitfalls often stem from the statistical complexities of cross-validation and the counterintuitive behaviors that emerge when optimizing over multiple hyperparameters.\n\n⚠️ **Pitfall: Data Leakage Through Preprocessing**\n\nOne of the most insidious evaluation errors occurs when data preprocessing steps (like feature scaling or normalization) are applied to the entire dataset before cross-validation splits. This seemingly innocent optimization creates subtle data leakage that inflates performance estimates.\n\n**Why it's wrong**: When you scale features using statistics from the entire dataset, information from the validation set leaks into the training process. For example, if you compute the mean and standard deviation for feature normalization using all data, then split into folds, each training set already \"knows\" something about its corresponding validation set through these global statistics.\n\n**Concrete example**: Consider a dataset where validation samples have systematically higher feature values than training samples. Global normalization would shift all values toward a global mean that includes validation data, making training samples artificially more similar to validation samples than they would be in real deployment.\n\n**How to avoid**: Apply preprocessing separately within each cross-validation fold. Compute scaling parameters using only the training portion of each fold, then apply those parameters to both training and validation portions. This ensures that validation data remains truly unseen during the preprocessing phase.\n\n⚠️ **Pitfall: Optimistic K Selection Through Multiple Testing**\n\nWhen testing many different K values through grid search, the multiple comparisons problem can lead to overly optimistic performance estimates. This occurs because random variation can make suboptimal K values appear superior by chance, especially when testing many values.\n\n**Why it's wrong**: Each statistical test (comparing K values) has a probability of producing a false positive. When testing many K values, the probability that at least one produces an optimistically biased result increases dramatically. This is similar to flipping a coin many times - eventually you'll get a long streak of heads purely by chance.\n\n**Concrete example**: Testing K values from 1 to 50 performs 50 different statistical experiments. Even if the true optimal K is 10, random variation might make K=23 appear superior in your particular dataset split. This \"discovered\" optimal K won't generalize to new data.\n\n**How to avoid**: Apply statistical corrections for multiple testing, such as Bonferroni correction. Alternatively, use nested cross-validation where hyperparameter selection occurs within an inner cross-validation loop, and performance estimation occurs in an outer loop. Report confidence intervals rather than point estimates to acknowledge uncertainty.\n\n⚠️ **Pitfall: Inappropriate K Values Relative to Dataset Size**\n\nSelecting K values that are too large relative to the dataset size can lead to meaningless cross-validation results and unstable performance estimates. This problem becomes particularly acute with small datasets or high numbers of cross-validation folds.\n\n**Why it's wrong**: If K (number of neighbors) approaches the size of the training set in each cross-validation fold, the model behavior becomes dominated by the overall class distribution rather than local similarity patterns. Additionally, if the number of cross-validation folds is too high relative to dataset size, each fold contains too few samples for reliable training.\n\n**Concrete example**: With a dataset of 100 samples using 10-fold cross-validation, each training fold contains only 90 samples. Testing K=80 means that 89% of the training data influences each prediction, essentially reducing KNN to a global vote rather than a local similarity-based decision.\n\n**How to avoid**: Limit K to reasonable fractions of the training set size (typically K < sqrt(n_training_samples)). Validate that cross-validation folds contain sufficient samples for meaningful training. Consider using fewer folds or stratified sampling for small datasets.\n\n⚠️ **Pitfall: Ignoring Class Imbalance in Evaluation Metrics**\n\nRelying solely on accuracy for model evaluation can mask poor performance on minority classes, particularly problematic in imbalanced datasets where high accuracy can be achieved by simply predicting the majority class.\n\n**Why it's wrong**: Accuracy treats all misclassifications equally, regardless of class frequency. In a dataset with 95% majority class samples, a model that never predicts the minority class still achieves 95% accuracy. This high accuracy masks the complete failure to learn minority class patterns.\n\n**Concrete example**: In a medical diagnosis dataset with 1000 healthy patients and 50 disease cases, a model that always predicts \"healthy\" achieves 95% accuracy but provides zero clinical value since it fails to identify any actual disease cases.\n\n**How to avoid**: Always compute and analyze precision, recall, and F1-score for each class individually. Use macro-averaged metrics that give equal weight to each class regardless of frequency. Consider using balanced accuracy or Cohen's kappa for imbalanced datasets. Examine the confusion matrix to understand per-class model behavior.\n\n⚠️ **Pitfall: Hyperparameter Overfitting Through Extensive Search**\n\nPerforming exhaustive grid search over very large hyperparameter ranges without proper validation can lead to hyperparameter overfitting, where the selected parameters perform well on the validation data but poorly on truly unseen data.\n\n**Why it's wrong**: The hyperparameter selection process itself can overfit to the particular characteristics of your validation data. When testing hundreds of hyperparameter combinations, some will perform well purely by chance. The selected \"optimal\" hyperparameters may not generalize to new datasets.\n\n**Concrete example**: Testing K values from 1 to 200 on a validation set might reveal that K=147 achieves the highest accuracy. However, this specific value likely reflects random patterns in your particular data split rather than a fundamental property of the optimal neighbor count.\n\n**How to avoid**: Use nested cross-validation to separate hyperparameter selection from performance estimation. Limit hyperparameter search ranges to reasonable values based on domain knowledge. Report the distribution of optimal hyperparameters across different cross-validation folds to assess selection stability. Consider using simpler models when hyperparameter sensitivity is high.\n\n### Implementation Guidance\n\nThe evaluation and optimization component requires sophisticated statistical machinery that can intimidate junior developers. This guidance provides complete, working implementations of the statistical infrastructure while clearly separating the core learning objectives (cross-validation logic and hyperparameter optimization) from the supporting utilities.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Statistical Computing | NumPy + manual implementations | SciPy with statistical functions |\n| Metric Calculation | Manual precision/recall/F1 computation | Scikit-learn metrics module |\n| Data Splitting | Manual stratified splitting logic | Scikit-learn StratifiedKFold |\n| Result Visualization | Print statements with formatted tables | Matplotlib for performance plots |\n| Random Number Generation | NumPy random with manual seed management | NumPy Generator with independent streams |\n\n#### Recommended File Structure\n\n```\nknn-classifier/\n├── src/\n│   ├── evaluation/\n│   │   ├── __init__.py\n│   │   ├── cross_validation.py      ← Core learning: CV logic\n│   │   ├── metrics.py               ← Supporting: metric calculations  \n│   │   ├── hyperparameter_search.py ← Core learning: grid search\n│   │   └── statistical_utils.py     ← Supporting: statistical helpers\n│   ├── data/\n│   │   ├── splitting.py             ← Supporting: stratified splitting\n│   │   └── preprocessing.py         ← Supporting: scaling within folds\n│   └── utils/\n│       ├── random_utils.py          ← Supporting: seed management\n│       └── validation_utils.py      ← Supporting: parameter validation\n├── tests/\n│   ├── test_cross_validation.py\n│   ├── test_hyperparameter_search.py\n│   └── test_metrics.py\n└── examples/\n    └── evaluation_example.py        ← Complete usage demonstration\n```\n\n#### Infrastructure Starter Code\n\n**Complete Random Seed Management (Supporting Infrastructure)**\n\n```python\n# src/utils/random_utils.py\nimport numpy as np\nfrom typing import List\n\nclass ReproducibleRandom:\n    \"\"\"Manages hierarchical random seed generation for reproducible experiments.\"\"\"\n    \n    def __init__(self, master_seed: int = 42):\n        self.master_seed = master_seed\n        self.rng = np.random.Generator(np.random.PCG64(master_seed))\n        \n    def generate_fold_seeds(self, n_folds: int) -> List[int]:\n        \"\"\"Generate independent seeds for each cross-validation fold.\"\"\"\n        return self.rng.integers(0, 2**31, size=n_folds).tolist()\n        \n    def generate_grid_search_seed(self) -> int:\n        \"\"\"Generate seed for hyperparameter grid search.\"\"\"\n        return int(self.rng.integers(0, 2**31))\n        \n    def reset_with_seed(self, seed: int) -> None:\n        \"\"\"Reset the generator with a specific seed.\"\"\"\n        self.rng = np.random.Generator(np.random.PCG64(seed))\n```\n\n**Complete Stratified Splitting (Supporting Infrastructure)**\n\n```python\n# src/data/splitting.py\nimport numpy as np\nfrom typing import List, Tuple, Dict\nfrom collections import Counter\nfrom ..types import FeatureMatrix, ClassLabel\n\nclass StratifiedSplitter:\n    \"\"\"Creates stratified train/validation splits that preserve class distributions.\"\"\"\n    \n    def __init__(self, random_seed: int = 42):\n        self.rng = np.random.Generator(np.random.PCG64(random_seed))\n        \n    def create_k_folds(self, y: List[ClassLabel], n_folds: int) -> List[Tuple[np.ndarray, np.ndarray]]:\n        \"\"\"\n        Create K stratified folds maintaining class distribution in each fold.\n        \n        Returns:\n            List of (train_indices, val_indices) tuples for each fold\n        \"\"\"\n        n_samples = len(y)\n        class_counts = Counter(y)\n        \n        # Group indices by class\n        class_indices: Dict[ClassLabel, List[int]] = {}\n        for idx, label in enumerate(y):\n            if label not in class_indices:\n                class_indices[label] = []\n            class_indices[label].append(idx)\n            \n        # Shuffle indices within each class\n        for label in class_indices:\n            self.rng.shuffle(class_indices[label])\n            \n        # Distribute each class across folds\n        folds: List[List[int]] = [[] for _ in range(n_folds)]\n        \n        for label, indices in class_indices.items():\n            for idx, sample_idx in enumerate(indices):\n                fold_idx = idx % n_folds\n                folds[fold_idx].append(sample_idx)\n                \n        # Convert to train/validation splits\n        fold_splits = []\n        for i in range(n_folds):\n            val_indices = np.array(folds[i])\n            train_indices = np.concatenate([folds[j] for j in range(n_folds) if j != i])\n            fold_splits.append((train_indices, val_indices))\n            \n        return fold_splits\n        \n    def validate_stratification(self, y: List[ClassLabel], folds: List[Tuple[np.ndarray, np.ndarray]]) -> bool:\n        \"\"\"Verify that stratification preserved class distributions.\"\"\"\n        original_dist = Counter(y)\n        original_proportions = {k: v/len(y) for k, v in original_dist.items()}\n        \n        for train_idx, val_idx in folds:\n            train_labels = [y[i] for i in train_idx]\n            val_labels = [y[i] for i in val_idx]\n            \n            train_dist = Counter(train_labels)\n            val_dist = Counter(val_labels)\n            \n            # Check that all classes appear in reasonable proportions\n            for label in original_proportions:\n                if label in train_dist:\n                    train_prop = train_dist[label] / len(train_labels)\n                    if abs(train_prop - original_proportions[label]) > 0.1:  # 10% tolerance\n                        return False\n                        \n        return True\n```\n\n**Complete Metrics Calculator (Supporting Infrastructure)**\n\n```python\n# src/evaluation/metrics.py\nimport numpy as np\nfrom typing import List, Dict, Optional, Union\nfrom collections import Counter, defaultdict\nfrom ..types import ClassLabel\n\nclass ClassificationMetrics:\n    \"\"\"Comprehensive classification metrics calculation.\"\"\"\n    \n    def __init__(self):\n        self.epsilon = 1e-15  # Prevent division by zero\n        \n    def accuracy(self, y_true: List[ClassLabel], y_pred: List[ClassLabel]) -> float:\n        \"\"\"Calculate overall classification accuracy.\"\"\"\n        if len(y_true) != len(y_pred):\n            raise ValueError(\"y_true and y_pred must have same length\")\n        \n        correct = sum(1 for true, pred in zip(y_true, y_pred) if true == pred)\n        return correct / len(y_true)\n        \n    def confusion_matrix(self, y_true: List[ClassLabel], y_pred: List[ClassLabel]) -> Dict:\n        \"\"\"Build confusion matrix as nested dictionary.\"\"\"\n        labels = sorted(set(y_true) | set(y_pred))\n        \n        # Initialize matrix\n        matrix = defaultdict(lambda: defaultdict(int))\n        \n        # Populate matrix\n        for true_label, pred_label in zip(y_true, y_pred):\n            matrix[true_label][pred_label] += 1\n            \n        # Convert to regular dict with all labels\n        result = {}\n        for true_label in labels:\n            result[true_label] = {}\n            for pred_label in labels:\n                result[true_label][pred_label] = matrix[true_label][pred_label]\n                \n        return {\"matrix\": result, \"labels\": labels}\n        \n    def precision_recall_f1(self, y_true: List[ClassLabel], y_pred: List[ClassLabel]) -> Dict:\n        \"\"\"Calculate precision, recall, and F1-score for each class.\"\"\"\n        cm_data = self.confusion_matrix(y_true, y_pred)\n        matrix = cm_data[\"matrix\"]\n        labels = cm_data[\"labels\"]\n        \n        metrics = {}\n        \n        for label in labels:\n            # True positives: correctly predicted as this class\n            tp = matrix[label][label]\n            \n            # False positives: incorrectly predicted as this class\n            fp = sum(matrix[other][label] for other in labels if other != label)\n            \n            # False negatives: incorrectly predicted as other classes\n            fn = sum(matrix[label][other] for other in labels if other != label)\n            \n            # Calculate metrics with epsilon to prevent division by zero\n            precision = tp / (tp + fp + self.epsilon)\n            recall = tp / (tp + fn + self.epsilon)\n            f1 = 2 * precision * recall / (precision + recall + self.epsilon)\n            \n            metrics[label] = {\n                \"precision\": precision,\n                \"recall\": recall,\n                \"f1_score\": f1,\n                \"support\": tp + fn  # Total samples of this class\n            }\n            \n        return metrics\n        \n    def macro_averaged_metrics(self, class_metrics: Dict) -> Dict:\n        \"\"\"Calculate macro-averaged precision, recall, and F1.\"\"\"\n        precisions = [metrics[\"precision\"] for metrics in class_metrics.values()]\n        recalls = [metrics[\"recall\"] for metrics in class_metrics.values()]\n        f1_scores = [metrics[\"f1_score\"] for metrics in class_metrics.values()]\n        \n        return {\n            \"macro_precision\": np.mean(precisions),\n            \"macro_recall\": np.mean(recalls),\n            \"macro_f1\": np.mean(f1_scores)\n        }\n        \n    def weighted_averaged_metrics(self, class_metrics: Dict) -> Dict:\n        \"\"\"Calculate weighted-averaged metrics (weighted by class support).\"\"\"\n        total_support = sum(metrics[\"support\"] for metrics in class_metrics.values())\n        \n        weighted_precision = sum(\n            metrics[\"precision\"] * metrics[\"support\"] \n            for metrics in class_metrics.values()\n        ) / total_support\n        \n        weighted_recall = sum(\n            metrics[\"recall\"] * metrics[\"support\"] \n            for metrics in class_metrics.values()\n        ) / total_support\n        \n        weighted_f1 = sum(\n            metrics[\"f1_score\"] * metrics[\"support\"] \n            for metrics in class_metrics.values()\n        ) / total_support\n        \n        return {\n            \"weighted_precision\": weighted_precision,\n            \"weighted_recall\": weighted_recall,\n            \"weighted_f1\": weighted_f1\n        }\n```\n\n#### Core Logic Skeletons\n\n**Cross-Validation Implementation (Core Learning Objective)**\n\n```python\n# src/evaluation/cross_validation.py\nimport numpy as np\nfrom typing import List, Dict, Tuple\nfrom ..knn.classifier import KNNClassifier\nfrom ..types import FeatureMatrix, ClassLabel, DistanceMetric\nfrom ..data.splitting import StratifiedSplitter\nfrom ..utils.random_utils import ReproducibleRandom\nfrom .metrics import ClassificationMetrics\n\nclass CrossValidator:\n    \"\"\"K-fold cross-validation for KNN classifier evaluation.\"\"\"\n    \n    def __init__(self, n_folds: int = 5, random_seed: int = 42):\n        self.n_folds = n_folds\n        self.random_seed = random_seed\n        self.splitter = StratifiedSplitter(random_seed)\n        self.metrics_calc = ClassificationMetrics()\n        \n    def evaluate(self, X: FeatureMatrix, y: List[ClassLabel], \n                k_neighbors: int, distance_metric: DistanceMetric) -> Dict:\n        \"\"\"\n        Perform K-fold cross-validation evaluation.\n        \n        Returns comprehensive evaluation results with statistics across folds.\n        \"\"\"\n        # TODO 1: Create stratified K-fold splits using self.splitter.create_k_folds()\n        # Hint: This returns list of (train_indices, val_indices) tuples\n        \n        # TODO 2: Initialize lists to collect per-fold results\n        # Hint: You'll need lists for accuracy, precision, recall, f1 for each fold\n        \n        # TODO 3: Loop through each fold and perform evaluation\n        # For each fold:\n        #   - Extract training and validation data using indices\n        #   - Create fresh KNNClassifier instance with specified parameters\n        #   - Fit classifier on training data\n        #   - Make predictions on validation data\n        #   - Calculate metrics using self.metrics_calc methods\n        #   - Store fold results\n        \n        # TODO 4: Aggregate results across all folds\n        # Calculate mean and standard deviation for each metric\n        # Hint: Use np.mean() and np.std() on your collected results\n        \n        # TODO 5: Package results into comprehensive dictionary\n        # Include: mean metrics, std metrics, per-fold results, fold count\n        # Return format: {\n        #   \"mean_accuracy\": float,\n        #   \"std_accuracy\": float, \n        #   \"mean_macro_f1\": float,\n        #   \"std_macro_f1\": float,\n        #   \"fold_results\": List[Dict],  # Individual fold metrics\n        #   \"n_folds\": int\n        # }\n        \n        raise NotImplementedError(\"Implement cross-validation logic\")\n        \n    def _extract_fold_data(self, X: FeatureMatrix, y: List[ClassLabel], \n                          indices: np.ndarray) -> Tuple[FeatureMatrix, List[ClassLabel]]:\n        \"\"\"Extract subset of data using provided indices.\"\"\"\n        # TODO 6: Extract rows from X using indices (use numpy indexing)\n        # TODO 7: Extract corresponding labels from y using indices\n        # Return: (subset_X, subset_y)\n        \n        raise NotImplementedError(\"Implement data extraction\")\n        \n    def _validate_inputs(self, X: FeatureMatrix, y: List[ClassLabel], \n                        k_neighbors: int) -> None:\n        \"\"\"Validate that inputs are suitable for cross-validation.\"\"\"\n        # TODO 8: Check that X and y have compatible dimensions\n        # TODO 9: Check that k_neighbors is reasonable relative to fold size\n        # TODO 10: Check that we have enough samples for n_folds\n        # Hint: Each fold should have at least k_neighbors + 1 training samples\n        \n        raise NotImplementedError(\"Implement input validation\")\n```\n\n**Hyperparameter Grid Search (Core Learning Objective)**\n\n```python\n# src/evaluation/hyperparameter_search.py\nfrom typing import List, Dict, Tuple, Optional\nfrom ..types import FeatureMatrix, ClassLabel, DistanceMetric\nfrom .cross_validation import CrossValidator\n\nclass GridSearchOptimizer:\n    \"\"\"Grid search optimization for KNN hyperparameters.\"\"\"\n    \n    def __init__(self, cv_folds: int = 5, random_seed: int = 42):\n        self.cv_folds = cv_folds\n        self.random_seed = random_seed\n        self.cross_validator = CrossValidator(cv_folds, random_seed)\n        \n    def search_optimal_k(self, X: FeatureMatrix, y: List[ClassLabel],\n                        k_values: List[int], distance_metric: DistanceMetric,\n                        optimization_metric: str = \"mean_accuracy\") -> Dict:\n        \"\"\"\n        Search for optimal K value using cross-validation.\n        \n        Returns:\n            Dictionary with optimal K, best score, and complete results\n        \"\"\"\n        # TODO 1: Validate input parameters\n        # Check that k_values are reasonable for dataset size\n        # Check that optimization_metric is supported\n        \n        # TODO 2: Initialize tracking variables\n        # You'll need: best_k, best_score, all_results dictionary\n        \n        # TODO 3: Loop through each K value in k_values\n        # For each K:\n        #   - Run cross-validation using self.cross_validator.evaluate()\n        #   - Extract the optimization metric score\n        #   - Update best_k and best_score if this K is better\n        #   - Store complete results for this K\n        \n        # TODO 4: Handle tie-breaking\n        # If multiple K values achieve the same best score, choose the smallest K\n        # This implements Occam's razor (prefer simpler models)\n        \n        # TODO 5: Package final results\n        # Return format: {\n        #   \"best_k\": int,\n        #   \"best_score\": float,\n        #   \"best_std\": float,  # Standard deviation of best score\n        #   \"optimization_metric\": str,\n        #   \"all_results\": Dict[int, Dict],  # K -> CV results mapping\n        #   \"k_values_tested\": List[int]\n        # }\n        \n        raise NotImplementedError(\"Implement grid search logic\")\n        \n    def _determine_k_range(self, n_samples: int, n_folds: int) -> List[int]:\n        \"\"\"Generate reasonable K value range based on dataset size.\"\"\"\n        # TODO 6: Calculate minimum K (typically 1)\n        # TODO 7: Calculate maximum K based on smallest training fold size\n        # Rule of thumb: max_k should be < sqrt(smallest_fold_size)\n        # TODO 8: Generate range of odd numbers (odd K avoids ties in binary classification)\n        # Return: List of K values to test\n        \n        raise NotImplementedError(\"Implement K range determination\")\n        \n    def generate_performance_report(self, search_results: Dict) -> str:\n        \"\"\"Generate human-readable performance report.\"\"\"\n        # TODO 9: Extract key information from search_results\n        # TODO 10: Format results into readable table\n        # Include: K value, mean score, std score, ranking\n        # TODO 11: Highlight the optimal K and its performance characteristics\n        # TODO 12: Add recommendations based on performance stability\n        \n        raise NotImplementedError(\"Implement report generation\")\n```\n\n**Statistical Significance Testing (Advanced Feature)**\n\n```python\n# src/evaluation/statistical_tests.py\nimport numpy as np\nfrom typing import List, Dict, Tuple\nfrom scipy import stats\n\nclass StatisticalValidator:\n    \"\"\"Statistical significance testing for model comparison.\"\"\"\n    \n    def paired_t_test(self, scores_a: List[float], scores_b: List[float], \n                     alpha: float = 0.05) -> Dict:\n        \"\"\"\n        Perform paired t-test to compare two model performances.\n        Used to test if difference between K values is statistically significant.\n        \"\"\"\n        # TODO 13: Validate that both score lists have same length\n        # TODO 14: Calculate paired differences (scores_a - scores_b)\n        # TODO 15: Perform one-sample t-test on differences using scipy.stats.ttest_1samp\n        # TODO 16: Interpret results and package into dictionary\n        # Return: {\n        #   \"statistic\": float,\n        #   \"p_value\": float,\n        #   \"significant\": bool,\n        #   \"confidence_interval\": Tuple[float, float]\n        # }\n        \n        raise NotImplementedError(\"Implement paired t-test\")\n```\n\n#### Milestone Checkpoints\n\n**After implementing cross-validation (Milestone 3.1):**\n\nRun the following test to verify your cross-validation implementation:\n\n```python\n# Test cross-validation correctness\nfrom sklearn.datasets import load_iris\nfrom src.evaluation.cross_validation import CrossValidator\nfrom src.types import DistanceMetric\n\n# Load test data\nX, y = load_iris(return_X_y=True)\ny = y.tolist()\n\n# Test 5-fold CV\ncv = CrossValidator(n_folds=5, random_seed=42)\nresults = cv.evaluate(X, y, k_neighbors=5, distance_metric=DistanceMetric.EUCLIDEAN)\n\n# Verify results structure\nassert \"mean_accuracy\" in results\nassert \"std_accuracy\" in results  \nassert \"fold_results\" in results\nassert len(results[\"fold_results\"]) == 5\nassert 0.0 <= results[\"mean_accuracy\"] <= 1.0\n\nprint(f\"✓ Cross-validation works! Mean accuracy: {results['mean_accuracy']:.3f} ± {results['std_accuracy']:.3f}\")\n```\n\n**Expected output**: Mean accuracy should be around 0.95-0.98 for Iris dataset with reasonable standard deviation < 0.05.\n\n**After implementing grid search (Milestone 3.2):**\n\n```python\n# Test hyperparameter optimization\nfrom src.evaluation.hyperparameter_search import GridSearchOptimizer\n\n# Test grid search\noptimizer = GridSearchOptimizer(cv_folds=3, random_seed=42)  # Fewer folds for speed\nsearch_results = optimizer.search_optimal_k(\n    X, y, \n    k_values=[1, 3, 5, 7, 9, 11], \n    distance_metric=DistanceMetric.EUCLIDEAN\n)\n\n# Verify optimization results\nassert \"best_k\" in search_results\nassert \"best_score\" in search_results\nassert search_results[\"best_k\"] in [1, 3, 5, 7, 9, 11]\n\nprint(f\"✓ Grid search works! Optimal K: {search_results['best_k']}, Score: {search_results['best_score']:.3f}\")\n```\n\n**Expected output**: Optimal K should be in range 3-7 for Iris dataset with accuracy > 0.95.\n\n**Signs something is wrong:**\n- Mean accuracy < 0.90 on Iris dataset indicates bug in classifier or evaluation\n- Standard deviation > 0.10 suggests unstable splits or implementation error  \n- Grid search always selects K=1 indicates overfitting to noise\n- All K values produce identical scores indicates bug in parameter passing\n\n\n## Component Interactions and Data Flow\n\n> **Milestone(s):** Comprehensive integration across all milestones - shows how distance calculation (Milestone 1), neighbor finding and classification (Milestone 2), and evaluation with optimization (Milestone 3) coordinate to form a complete machine learning system\n\nThe K-Nearest Neighbors classifier operates as a **coordinated orchestration of specialized components**, much like a well-organized research team where each member has distinct expertise but must collaborate seamlessly to reach conclusions. Understanding how these components interact and how data flows between them is crucial for implementing a robust and efficient KNN system.\n\nThink of the component interaction like a **scientific consultation process**. When faced with a new classification problem, you would first gather your reference materials (training data), then systematically measure similarities to known cases (distance calculation), identify the most relevant precedents (neighbor finding), conduct a vote among experts (classification), and finally validate your methodology through rigorous testing (evaluation and optimization). Each step depends on the previous ones, but the coordination between them determines the overall system's effectiveness.\n\nThe data flow architecture reveals three distinct operational phases, each with specific coordination patterns and performance characteristics. During training, the system primarily focuses on data validation and storage preparation. During prediction, components must coordinate in real-time to process queries efficiently. During optimization, the system orchestrates multiple prediction cycles to evaluate different configurations and select optimal parameters.\n\n![System Component Architecture](./diagrams/system-components.svg)\n\n![Data Model Relationships](./diagrams/data-model.svg)\n\n### Training Data Flow\n\nThe training phase in KNN represents the **preparation and storage** of reference knowledge rather than traditional parameter learning. Unlike parametric models that extract patterns into weights and coefficients, KNN employs lazy learning where the training process focuses on data validation, preprocessing, and efficient storage organization.\n\nThe training data flow begins when the `KNNClassifier` receives feature matrices and label arrays through the `fit` method. This initial step triggers a comprehensive validation pipeline that ensures data quality and compatibility. The system first validates that feature matrices contain only numeric values and that all feature vectors have consistent dimensionality. Label validation ensures that class identifiers are consistent in type and that the dataset contains sufficient examples for meaningful neighbor finding.\n\nDuring the validation phase, the system constructs a `TrainingData` structure that encapsulates all necessary information for future predictions. This structure maintains the original `FeatureMatrix` for distance calculations, stores class labels in a format optimized for voting operations, and computes metadata such as the number of samples, feature dimensions, and unique class identifiers. The metadata computation enables efficient parameter validation during prediction and optimization phases.\n\nThe training data storage process implements several architectural decisions that impact system performance. The feature matrix remains in its original NumPy array format to leverage vectorized operations during distance calculation. Class labels are stored as a list to maintain order correspondence with feature vectors while also being indexed in a set for efficient uniqueness checking. The training data structure includes precomputed statistics like class distributions that accelerate weighted voting calculations.\n\n| Training Phase Operation | Input Data | Processing Steps | Output Structure | Performance Impact |\n|-------------------------|------------|------------------|------------------|-------------------|\n| Data Validation | Raw features and labels | Type checking, dimension validation, missing value detection | Validated arrays | O(n×m) where n=samples, m=features |\n| Metadata Computation | Validated arrays | Count samples/features, identify unique classes | TrainingData statistics | O(n) for class enumeration |\n| Storage Organization | Validated data + metadata | Array copying, label indexing, class mapping | Complete TrainingData | O(n×m) memory allocation |\n| Index Preparation | Organized data | Sample indexing, class distribution calculation | Ready classifier state | O(n) for distribution stats |\n\nThe training data flow implements several critical validation checkpoints that prevent runtime errors during prediction. The system validates that feature vectors contain only finite numeric values, rejecting datasets with NaN or infinite values that would corrupt distance calculations. Dimensionality consistency checking ensures that all feature vectors have identical length, preventing broadcasting errors in vectorized operations. Class label validation confirms that labels are consistently typed and that each class has sufficient representation for meaningful neighbor voting.\n\n> **Key Design Insight**: Training in KNN is fundamentally different from parametric learning - it's about data preparation and storage optimization rather than parameter estimation. The training phase establishes the data quality foundation that enables efficient and accurate predictions.\n\n**Decision: Lazy Learning Storage Strategy**\n- **Context**: KNN must store training data for prediction-time computation rather than pre-computing model parameters\n- **Options Considered**: \n  1. Store raw arrays with minimal preprocessing\n  2. Pre-compute distance matrices for all training pairs  \n  3. Build spatial index structures during training\n- **Decision**: Store validated raw data with computed metadata\n- **Rationale**: Maintains flexibility for different distance metrics while avoiding quadratic memory overhead of full distance matrices and complexity of spatial indexing\n- **Consequences**: Enables dynamic distance metric selection and efficient memory usage, but requires distance computation during each prediction\n\nThe training data flow concludes with the classifier transitioning to a \"fitted\" state where the `training_data` field contains a complete `TrainingData` structure. This state transition enables prediction methods while maintaining clear separation between training and inference phases. The fitted state includes validation flags that prevent prediction attempts on incompatible query data.\n\n### Prediction Data Flow\n\nThe prediction data flow represents the **core operational sequence** where all system components coordinate to transform query points into classification results. This process exemplifies the lazy learning paradigm where computation is deferred until prediction time, requiring real-time coordination between distance calculation, neighbor finding, and voting components.\n\n![Prediction Sequence Flow](./diagrams/prediction-flow.svg)\n\nThe prediction sequence begins when the `predict` or `predict_with_confidence` method receives a query `FeatureMatrix`. The system immediately validates that query points have compatible dimensionality with the training data and that the classifier is in a fitted state. This validation prevents runtime errors and provides clear feedback about configuration issues.\n\nFollowing validation, the prediction flow enters the **batch processing coordination phase** where the system determines the optimal strategy for handling multiple query points. For small query batches, the system processes each point individually to minimize memory overhead. For larger batches, it may employ vectorized operations or parallel processing depending on the available computational resources and distance metric characteristics.\n\nThe individual query point prediction follows a precisely orchestrated sequence of component interactions:\n\n1. **Query Point Extraction**: The system extracts individual `FeatureVector` instances from the query matrix, ensuring proper array slicing that maintains NumPy array properties for subsequent vectorized operations.\n\n2. **Distance Calculation Coordination**: The distance calculator receives the query point and applies the configured distance metric to compute distances to all training samples. This step leverages the vectorized distance calculation methods to achieve O(n×m) performance rather than O(n) individual distance calculations.\n\n3. **Neighbor Finding Coordination**: The neighbor finder receives the distance array and applies efficient selection algorithms to identify the K closest training samples. This coordination includes tie-breaking logic and validation that sufficient neighbors exist.\n\n4. **Label Retrieval Coordination**: The system uses neighbor indices to retrieve corresponding class labels from the training data structure, maintaining the association between distances and labels for voting.\n\n5. **Voting Coordination**: The classification component receives neighbor labels and distances, applying the configured voting strategy to produce a class prediction and confidence score.\n\n6. **Result Assembly**: The system packages the prediction results into appropriate return structures, either simple class labels or detailed `PredictionResult` objects depending on the called method.\n\n| Prediction Step | Component Responsibility | Data Transformation | Error Handling | Performance Characteristics |\n|-----------------|-------------------------|---------------------|----------------|---------------------------|\n| Query Validation | KNNClassifier | FeatureMatrix → validated vectors | Dimension mismatch detection | O(m) per query point |\n| Distance Computation | DistanceCalculator | FeatureVector → DistanceArray | Numerical stability checks | O(n×m) vectorized operation |\n| Neighbor Selection | NeighborFinder | DistanceArray → NeighborIndices | K validation, tie resolution | O(n log K) with partial sorting |\n| Label Retrieval | TrainingData | NeighborIndices → neighbor labels | Index bounds checking | O(K) array indexing |\n| Vote Computation | Classifier | Labels + distances → prediction | Tie-breaking, confidence calculation | O(K) voting operation |\n| Result Assembly | KNNClassifier | Prediction → result structure | Result validation | O(1) structure creation |\n\nThe prediction data flow implements sophisticated error handling and recovery mechanisms at each coordination point. Distance calculation errors trigger fallback strategies or clear error messages depending on the failure mode. Neighbor finding failures due to insufficient data or invalid K values provide specific guidance for parameter adjustment. Voting failures due to tied results invoke tie-breaking algorithms that use distance information to make deterministic decisions.\n\n**Decision: Single-Point Processing with Batch Coordination**\n- **Context**: Need to balance memory efficiency with computational performance for variable-sized query batches\n- **Options Considered**:\n  1. Pure batch processing with full distance matrix computation\n  2. Individual point processing with no batch optimizations\n  3. Adaptive strategy based on batch size and available memory\n- **Decision**: Process individual points within batch coordination framework\n- **Rationale**: Provides memory efficiency for large training sets while enabling batch-level optimizations like vectorized distance computation and result aggregation\n- **Consequences**: Achieves good performance across different usage patterns but requires more complex coordination logic\n\nThe prediction data flow maintains **provenance information** throughout the process, enabling detailed debugging and confidence assessment. Each prediction result can include the specific neighbor indices, their distances, and the voting details that led to the final classification. This transparency supports both debugging and confidence-based application logic.\n\nPerformance optimization in the prediction flow focuses on minimizing redundant computations and leveraging NumPy's vectorized operations. The system avoids recomputing training data statistics and caches frequently accessed metadata. Distance computation uses broadcasting to compute all distances in a single vectorized operation rather than iterating through training samples.\n\n> **Critical Performance Insight**: The prediction data flow's efficiency depends heavily on vectorized operations and minimal data copying. Each component coordination point must preserve NumPy array properties and avoid Python-level loops that would severely impact performance on large training sets.\n\n### Optimization Data Flow\n\nThe optimization data flow orchestrates **systematic evaluation and hyperparameter tuning** across multiple prediction cycles to identify optimal classifier configurations. This process represents the most complex coordination pattern in the system, requiring careful management of data splitting, cross-validation execution, and result aggregation while maintaining statistical validity.\n\nThe optimization flow begins with **parameter space definition** where the system establishes ranges for hyperparameters to explore. The primary optimization target is the K parameter, but the system also considers distance metric selection and voting strategy configuration. The optimization coordinator validates parameter ranges and ensures sufficient data exists for meaningful cross-validation.\n\n**Cross-validation coordination** represents the core of the optimization data flow. The system implements stratified K-fold cross-validation that maintains class distribution across folds while ensuring statistical independence between training and validation sets. This coordination requires careful data management to prevent information leakage between folds.\n\nThe cross-validation process follows a nested coordination pattern:\n\n1. **Fold Generation Coordination**: The stratified splitter generates balanced train/validation splits while maintaining reproducibility through seed management. Each fold preserves class distributions and ensures sufficient samples for neighbor finding.\n\n2. **Model Training Coordination**: For each fold and parameter combination, the system creates a temporary classifier instance, fits it with the fold's training data, and validates the fitted state.\n\n3. **Validation Coordination**: The temporary classifier processes validation queries through the standard prediction data flow, generating predictions for metric calculation.\n\n4. **Metrics Computation Coordination**: The evaluation component coordinates calculation of accuracy, precision, recall, and F1-score metrics, handling edge cases like missing classes in validation folds.\n\n5. **Result Aggregation Coordination**: The system accumulates metrics across folds and parameter combinations, computing statistical summaries and maintaining detailed result tracking.\n\n| Optimization Phase | Coordination Pattern | Data Management | Statistical Considerations | Performance Impact |\n|--------------------|---------------------|-----------------|---------------------------|-------------------|\n| Parameter Grid Setup | Sequential validation | Parameter ranges and constraints | Valid parameter combinations | O(1) configuration |\n| Fold Generation | Stratified sampling | Class-balanced data splits | Independence between folds | O(n log n) sorting |\n| Cross-Validation Loop | Nested iteration | Temporary classifier instances | Statistical significance | O(p × f × n × m) where p=parameters, f=folds |\n| Metric Computation | Batch aggregation | Prediction result collection | Confidence intervals | O(v) where v=validation samples |\n| Result Selection | Statistical comparison | Performance metric databases | Multiple testing correction | O(p × f) aggregation |\n\nThe optimization data flow implements **statistical rigor** through careful experimental design. The system uses stratified sampling to ensure representative train/validation splits, maintains consistent random seeds for reproducible results, and applies appropriate statistical tests when comparing parameter configurations. Cross-validation results include confidence intervals and statistical significance tests where applicable.\n\n**Grid search coordination** manages the systematic exploration of hyperparameter space through exhaustive evaluation. The system coordinates parameter combination generation, ensures complete coverage of the specified grid, and maintains progress tracking for long-running optimizations. Result storage enables detailed analysis of parameter sensitivity and performance trade-offs.\n\n**Decision: Stratified K-Fold Cross-Validation with Grid Search**\n- **Context**: Need reliable hyperparameter selection with statistical validity and computational efficiency\n- **Options Considered**:\n  1. Simple train/validation split with grid search\n  2. Monte Carlo cross-validation with random sampling\n  3. Stratified K-fold cross-validation with systematic grid exploration\n- **Decision**: Implement stratified K-fold with comprehensive grid search\n- **Rationale**: Provides best balance of statistical reliability, computational efficiency, and practical usability while ensuring representative data splits\n- **Consequences**: Enables statistically sound parameter selection but requires complex coordination logic and significant computational resources\n\nThe optimization data flow maintains **detailed audit trails** that enable analysis of hyperparameter sensitivity and model behavior. The system records not only final metrics but also intermediate results, timing information, and statistical summaries. This detailed tracking supports both automated parameter selection and manual analysis of model characteristics.\n\n**Resource management** in the optimization flow coordinates memory usage and computational resources across multiple concurrent evaluation processes. The system implements strategies to limit memory growth during cross-validation and provides progress reporting for long-running optimizations. Temporary classifier instances are properly disposed of to prevent memory leaks during extended optimization runs.\n\nThe optimization flow concludes with **result synthesis** where the system identifies optimal configurations and provides comprehensive reports. The `GridSearchResult` structure contains not only the best parameters but also complete performance profiles that enable sensitivity analysis. The coordination ensures that optimal parameters are validated and that the final recommendations are statistically sound.\n\n> **Statistical Validity Insight**: The optimization data flow must maintain strict separation between training and validation data while ensuring representative sampling. Any information leakage or biased sampling will produce overoptimistic performance estimates that fail in production deployment.\n\n⚠️ **Pitfall: Information Leakage in Cross-Validation**\nCross-validation coordination must prevent any training information from influencing validation predictions. Common mistakes include using global statistics computed on the entire dataset or sharing fitted preprocessing parameters across folds. The system implements strict data isolation where each fold's training phase has access only to its designated training samples, and all preprocessing decisions are made independently for each fold.\n\n⚠️ **Pitfall: Insufficient Statistical Power**\nOptimization with small datasets or too few cross-validation folds can produce unreliable parameter selections. The system validates that sufficient samples exist for meaningful cross-validation and warns when statistical power is limited. Minimum sample requirements ensure that each fold contains adequate representation of all classes.\n\n⚠️ **Pitfall: Hyperparameter Overfitting**\nExtensive grid search over many parameter combinations can lead to overfitting where selected parameters perform well on validation data but poorly on truly unseen test data. The optimization flow implements nested cross-validation options and provides warnings when parameter grids are excessively large relative to available data.\n\n### Implementation Guidance\n\nThe component interaction implementation requires careful coordination of multiple specialized modules while maintaining clean interfaces and efficient data flow. The following guidance provides concrete patterns for implementing the coordination logic and managing the complex data transformations.\n\n#### Technology Recommendations\n\n| Component Integration | Simple Option | Advanced Option |\n|----------------------|---------------|-----------------|\n| Data Flow Coordination | Direct method calls with explicit error handling | Observer pattern with event-driven coordination |\n| Memory Management | Standard Python garbage collection with manual cleanup | Memory pooling with pre-allocated arrays |\n| Progress Tracking | Simple print statements and counters | Rich progress bars with time estimation |\n| Result Storage | In-memory dictionaries and lists | Structured databases with query capabilities |\n| Parallel Processing | Sequential processing with clear interfaces | Multi-processing with shared memory arrays |\n\n#### Recommended Module Structure\n\nThe implementation should organize component interactions across multiple modules that maintain clear separation of concerns while enabling efficient data flow:\n\n```\nknn_classifier/\n  core/\n    classifier.py           ← Main KNNClassifier with coordination logic\n    training.py            ← Training data flow and validation\n    prediction.py          ← Prediction coordination and batch processing\n  components/\n    distance_calculator.py ← Distance computation component\n    neighbor_finder.py     ← Neighbor selection component  \n    voting.py             ← Classification voting component\n    evaluator.py          ← Cross-validation and optimization\n  coordination/\n    data_flow.py          ← Data transformation utilities\n    validation.py         ← Cross-component validation logic\n    batch_processor.py    ← Batch coordination strategies\n  utils/\n    data_structures.py    ← Core data types and containers\n    metrics.py            ← Performance metrics and statistics\n    random_utils.py       ← Reproducible randomization\n  tests/\n    integration/\n      test_data_flow.py   ← End-to-end data flow testing\n      test_coordination.py ← Component interaction testing\n```\n\n#### Training Data Flow Infrastructure\n\n```python\nimport numpy as np\nfrom typing import List, Set, Optional, Tuple\nfrom dataclasses import dataclass\nfrom enum import Enum\n\n@dataclass\nclass TrainingData:\n    \"\"\"Complete training data structure with metadata for efficient prediction.\"\"\"\n    features: np.ndarray  # FeatureMatrix (n_samples, n_features)\n    labels: List[str]     # ClassLabel list maintaining order\n    n_samples: int        # Number of training examples\n    n_features: int       # Feature vector dimensionality\n    unique_classes: Set[str]  # Unique class identifiers\n    class_counts: dict    # Class frequency distribution\n    \n    def get_sample(self, index: int) -> Tuple[np.ndarray, str]:\n        \"\"\"Retrieve single training example by index with bounds checking.\"\"\"\n        # TODO: Validate index bounds against n_samples\n        # TODO: Extract feature vector using array slicing\n        # TODO: Retrieve corresponding label maintaining type consistency\n        # TODO: Return tuple of FeatureVector and ClassLabel\n        pass\n    \n    def validate_query_compatibility(self, query_features: np.ndarray) -> None:\n        \"\"\"Validate query points have compatible dimensionality with training data.\"\"\"\n        # TODO: Check that query_features is 2D array (n_queries, n_features)\n        # TODO: Validate that query feature count matches self.n_features\n        # TODO: Check for finite numeric values (no NaN or infinity)\n        # TODO: Raise descriptive errors for validation failures\n        pass\n\nclass TrainingDataBuilder:\n    \"\"\"Constructs validated TrainingData structures from raw input arrays.\"\"\"\n    \n    @staticmethod\n    def build_training_data(features: np.ndarray, labels: List[str]) -> TrainingData:\n        \"\"\"Build complete TrainingData with validation and metadata computation.\"\"\"\n        # TODO: Validate features array shape and numeric types\n        # TODO: Validate labels list consistency and type uniformity\n        # TODO: Check feature-label count correspondence\n        # TODO: Compute n_samples, n_features from array dimensions\n        # TODO: Build unique_classes set from labels list\n        # TODO: Calculate class_counts distribution dictionary\n        # TODO: Construct and return TrainingData instance\n        pass\n    \n    @staticmethod\n    def validate_feature_matrix(features: np.ndarray) -> None:\n        \"\"\"Comprehensive feature matrix validation with specific error messages.\"\"\"\n        # TODO: Check array is 2D with shape (n_samples, n_features)\n        # TODO: Validate numeric dtype (float32 or float64)\n        # TODO: Check for NaN, infinity, or missing values\n        # TODO: Ensure sufficient samples (at least 1) and features (at least 1)\n        # TODO: Raise ValueError with specific problem description\n        pass\n```\n\n#### Prediction Data Flow Coordination\n\n```python\nfrom typing import Union, Dict, Any\nfrom dataclasses import dataclass\n\n@dataclass\nclass PredictionResult:\n    \"\"\"Complete prediction result with neighbor information and confidence.\"\"\"\n    predicted_class: str           # Final classification decision\n    neighbor_indices: np.ndarray   # Indices of K nearest neighbors\n    neighbor_distances: np.ndarray # Distances to K nearest neighbors\n    confidence: float              # Prediction confidence score\n    voting_details: Dict[str, Any] # Detailed voting information\n\nclass PredictionCoordinator:\n    \"\"\"Coordinates component interactions during prediction phase.\"\"\"\n    \n    def __init__(self, distance_calculator, neighbor_finder, classifier):\n        self.distance_calculator = distance_calculator\n        self.neighbor_finder = neighbor_finder\n        self.classifier = classifier\n        self.training_data: Optional[TrainingData] = None\n    \n    def predict_batch_with_coordination(self, query_points: np.ndarray) -> List[PredictionResult]:\n        \"\"\"Coordinate prediction for multiple query points with batch optimizations.\"\"\"\n        # TODO: Validate query_points compatibility with training data\n        # TODO: Determine optimal batch processing strategy based on array sizes\n        # TODO: Initialize result collection with appropriate capacity\n        # TODO: Iterate through query points with progress tracking\n        # TODO: For each point, coordinate distance → neighbors → voting sequence\n        # TODO: Aggregate individual predictions into batch result list\n        # TODO: Validate result consistency and completeness\n        # TODO: Return complete batch prediction results\n        pass\n    \n    def _predict_single_point_coordination(self, query_point: np.ndarray) -> PredictionResult:\n        \"\"\"Coordinate single point prediction through all components.\"\"\"\n        # TODO: Extract FeatureVector from query array with proper slicing\n        # TODO: Coordinate distance calculation to all training points\n        # TODO: Coordinate neighbor finding with distance array and K parameter\n        # TODO: Retrieve neighbor labels using indices from training data\n        # TODO: Coordinate voting with neighbor labels and distances\n        # TODO: Calculate confidence score from voting results\n        # TODO: Assemble complete PredictionResult with all information\n        # TODO: Validate prediction result consistency before returning\n        pass\n    \n    def _coordinate_distance_calculation(self, query_point: np.ndarray) -> np.ndarray:\n        \"\"\"Coordinate vectorized distance computation to all training samples.\"\"\"\n        # TODO: Pass query point and training features to distance calculator\n        # TODO: Apply configured distance metric with vectorized operations\n        # TODO: Validate distance array has correct length (n_samples)\n        # TODO: Check for numerical issues (NaN, negative distances)\n        # TODO: Return validated DistanceArray for neighbor finding\n        pass\n```\n\n#### Cross-Validation Coordination Infrastructure\n\n```python\nfrom sklearn.model_selection import StratifiedKFold\nfrom typing import Iterator, Dict, List, Any\nimport numpy as np\n\nclass CrossValidationCoordinator:\n    \"\"\"Manages cross-validation execution with component coordination.\"\"\"\n    \n    def __init__(self, n_folds: int = 5, random_seed: int = 42):\n        self.n_folds = n_folds\n        self.random_seed = random_seed\n        self.fold_splitter = StratifiedKFold(\n            n_splits=n_folds, \n            shuffle=True, \n            random_state=random_seed\n        )\n    \n    def coordinate_k_fold_evaluation(self, \n                                   X: np.ndarray, \n                                   y: List[str], \n                                   k_values: List[int],\n                                   distance_metric: str) -> Dict[str, Any]:\n        \"\"\"Coordinate complete K-fold cross-validation with hyperparameter grid.\"\"\"\n        # TODO: Validate input data sufficient for n_folds splits\n        # TODO: Generate stratified fold indices maintaining class distribution\n        # TODO: Initialize results collection with nested dictionaries\n        # TODO: Iterate through k_values parameter grid\n        # TODO: For each K, iterate through cross-validation folds\n        # TODO: Coordinate fold training with temporary classifier instances\n        # TODO: Coordinate fold validation through prediction pipeline\n        # TODO: Aggregate metrics across folds for each K value\n        # TODO: Calculate statistical summaries (mean, std) for metrics\n        # TODO: Identify optimal K based on validation performance\n        # TODO: Return comprehensive CrossValidationResult\n        pass\n    \n    def _coordinate_single_fold(self, \n                               train_indices: np.ndarray,\n                               val_indices: np.ndarray,\n                               X: np.ndarray,\n                               y: List[str],\n                               k: int,\n                               distance_metric: str) -> Dict[str, float]:\n        \"\"\"Coordinate single fold evaluation with temporary classifier.\"\"\"\n        # TODO: Extract training data using train_indices\n        # TODO: Extract validation data using val_indices  \n        # TODO: Create temporary KNNClassifier instance with parameters\n        # TODO: Coordinate training data fitting on fold training set\n        # TODO: Coordinate prediction on fold validation set\n        # TODO: Calculate classification metrics for fold results\n        # TODO: Return fold performance metrics dictionary\n        pass\n    \n    def generate_stratified_folds(self, X: np.ndarray, y: List[str]) -> Iterator[Tuple[np.ndarray, np.ndarray]]:\n        \"\"\"Generate stratified train/validation splits maintaining class distribution.\"\"\"\n        # TODO: Convert labels to numpy array for sklearn compatibility\n        # TODO: Use StratifiedKFold to generate balanced splits\n        # TODO: Yield train_indices, val_indices for each fold\n        # TODO: Validate each fold has representation of all classes\n        pass\n```\n\n#### Optimization Results Management\n\n```python\n@dataclass\nclass GridSearchResult:\n    \"\"\"Comprehensive grid search results with statistical analysis.\"\"\"\n    optimal_k: int                    # Best K parameter\n    optimal_metrics: Dict[str, float] # Performance at optimal K\n    complete_results: Dict[int, Dict] # Full grid search results\n    parameter_sensitivity: Dict       # Parameter sensitivity analysis\n    statistical_significance: Dict   # Statistical test results\n    optimization_metadata: Dict      # Timing and resource usage\n\nclass OptimizationCoordinator:\n    \"\"\"Coordinates hyperparameter optimization with statistical validation.\"\"\"\n    \n    def coordinate_grid_search(self, \n                             X: np.ndarray,\n                             y: List[str], \n                             k_range: range,\n                             cv_folds: int = 5) -> GridSearchResult:\n        \"\"\"Coordinate comprehensive grid search with cross-validation.\"\"\"\n        # TODO: Validate parameter ranges and data sufficiency\n        # TODO: Initialize result tracking with timing information\n        # TODO: Coordinate cross-validation for each K in range\n        # TODO: Aggregate results across parameter combinations\n        # TODO: Perform statistical significance testing between configurations\n        # TODO: Identify optimal parameters with confidence intervals\n        # TODO: Generate parameter sensitivity analysis\n        # TODO: Assemble comprehensive GridSearchResult\n        pass\n\n# Complete infrastructure for reproducible randomization\nclass ReproducibleRandom:\n    \"\"\"Manages random seeds for reproducible optimization.\"\"\"\n    \n    def __init__(self, base_seed: int = 42):\n        self.base_seed = base_seed\n        self.operation_counter = 0\n    \n    def get_seed_for_operation(self, operation_name: str) -> int:\n        \"\"\"Generate consistent seed for specific operation.\"\"\"\n        # TODO: Hash operation name with base seed and counter\n        # TODO: Increment operation counter for sequence consistency\n        # TODO: Return deterministic seed for operation\n        pass\n```\n\n#### Milestone Checkpoints\n\n**Checkpoint 1: Training Data Flow Validation**\n- Run `python -m pytest tests/integration/test_training_flow.py`\n- Expected: All training data validation and metadata computation tests pass\n- Verify: `TrainingData` structure properly stores features, labels, and metadata\n- Manual test: Load iris dataset, fit classifier, inspect `training_data` attributes\n\n**Checkpoint 2: Prediction Coordination**\n- Run `python -c \"from knn_classifier import KNNClassifier; knn = KNNClassifier(k=3); knn.fit(X_train, y_train); print(knn.predict(X_test))\"`\n- Expected: Predictions returned as class label list matching test data length\n- Verify: `predict_with_confidence` returns detailed `PredictionResult` objects\n- Manual test: Single query point returns prediction with neighbor information\n\n**Checkpoint 3: Cross-Validation Integration**\n- Run cross-validation with `k_fold_cross_validate(X, y, k_folds=5, k_neighbors=3)`\n- Expected: `CrossValidationResult` with mean/std metrics across folds\n- Verify: Grid search identifies optimal K with statistical validation\n- Manual test: Compare cross-validation results with simple train/test split\n\n#### Debugging Component Interactions\n\n| Symptom | Likely Cause | Diagnosis Steps | Fix Strategy |\n|---------|--------------|-----------------|--------------|\n| Prediction hangs indefinitely | Infinite loop in neighbor finding or voting | Add debug prints in coordination methods, check array shapes | Validate K parameter against dataset size, add timeout logic |\n| Memory usage grows during batch prediction | Array copying or accumulation without cleanup | Profile memory usage, check for array references | Implement explicit cleanup, use views instead of copies |\n| Cross-validation results inconsistent | Non-deterministic randomization or data leakage | Check random seed usage, validate fold independence | Fix seed management, ensure strict train/validation separation |\n| Optimization selects poor parameters | Insufficient cross-validation or statistical issues | Examine individual fold results, check metric calculation | Increase fold count, validate metric implementations |\n| Component coordination errors | Interface mismatches or invalid data passing | Trace data flow between components, validate interfaces | Add comprehensive input validation, fix interface contracts |\n\n\n## Error Handling and Edge Cases\n\n> **Milestone(s):** Comprehensive error handling for all milestones - input validation for distance calculation (Milestone 1), edge case handling for neighbor finding and classification (Milestone 2), and robust evaluation pipeline error management (Milestone 3)\n\nThink of error handling in a KNN classifier as building a safety net for a neighborhood recommendation system. Just as you wouldn't trust restaurant recommendations from someone who has never been to your city, has completely different tastes, or can't even tell you which restaurants they've tried, your KNN system must validate that the data makes sense before making predictions. A robust error handling system acts like a careful friend who double-checks directions, verifies the restaurant is still open, and makes sure you're not allergic to any ingredients before giving their recommendation.\n\nThe KNN algorithm is particularly susceptible to input validation issues because it operates directly on raw feature vectors and makes assumptions about data consistency, numerical stability, and parameter validity. Unlike parametric models that learn fixed parameters during training, KNN's lazy learning approach means that every prediction depends on the entire training dataset and distance calculations, making comprehensive validation critical at every step.\n\n### Input Validation\n\nInput validation forms the first line of defense against system failures and incorrect predictions. The KNN classifier must validate three categories of inputs: training data consistency, query point compatibility, and algorithm parameters. Each category has specific validation rules that must be enforced to prevent silent failures and ensure prediction accuracy.\n\n**Training Data Validation** ensures that the `TrainingData` structure contains consistent and usable information for distance calculation and classification. The validation process must verify dimensional consistency across all feature vectors, check for valid class labels, and ensure sufficient data for meaningful predictions.\n\n| Validation Rule | Check Description | Error Condition | Recovery Action |\n|-----------------|------------------|-----------------|-----------------|\n| Feature Matrix Shape | All training samples have identical feature count | Inconsistent n_features dimension | Raise `ValueError` with dimension mismatch details |\n| Non-Empty Dataset | Training data contains at least one sample | Empty feature matrix or label list | Raise `ValueError` requesting minimum data |\n| Label-Feature Alignment | Number of labels matches number of feature vectors | len(labels) != n_samples | Raise `ValueError` with count mismatch |\n| Numeric Feature Values | All features are finite numeric values | NaN, infinite, or non-numeric values | Raise `ValueError` with invalid value locations |\n| Valid Class Labels | All labels are hashable and non-null | None, unhashable types in labels | Raise `TypeError` with invalid label examples |\n| Minimum Class Diversity | At least one unique class present | All labels identical (edge case) | Log warning but allow single-class training |\n\nThe `TrainingData` validation process begins by examining the feature matrix shape and ensuring that `n_samples` and `n_features` match the actual data dimensions. The validator then scans for numeric anomalies that could cause distance calculation failures, such as NaN values that would propagate through vectorized operations or infinite values that could dominate distance computations.\n\n**Query Point Validation** ensures that prediction requests contain compatible feature vectors that can be compared against the training data using the selected distance metric. This validation is critical because dimensional mismatches or invalid values would cause silent errors or nonsensical predictions.\n\n| Query Validation | Check Description | Error Condition | Recovery Action |\n|------------------|------------------|-----------------|-----------------|\n| Dimensional Compatibility | Query features match training n_features | query.shape[-1] != training.n_features | Raise `ValueError` with expected vs actual dimensions |\n| Numeric Validity | Query contains only finite numeric values | NaN, infinite values in query point | Raise `ValueError` with invalid value positions |\n| Feature Matrix Shape | Batch queries have correct 2D shape | Wrong number of dimensions in query matrix | Raise `ValueError` with shape correction guidance |\n| Non-Empty Queries | At least one query point provided | Empty query matrix passed to predict | Raise `ValueError` requesting valid query data |\n| Memory Constraints | Query batch size within reasonable limits | Extremely large batch causing memory issues | Raise `MemoryError` with batch size reduction suggestion |\n\nThe `validate_compatible_vectors` function performs the core compatibility check by comparing feature dimensions and ensuring that the query point can be meaningfully compared to training samples using vectorized distance calculations.\n\n**Parameter Validation** verifies that algorithm configuration parameters are within valid ranges and compatible with the training data characteristics. Parameter validation prevents common mistakes like setting K larger than the dataset size or using invalid distance metrics.\n\n| Parameter | Valid Range | Error Condition | Recovery Strategy |\n|-----------|------------|-----------------|-------------------|\n| K Value | 1 ≤ k ≤ n_samples | k <= 0 or k > training samples | Raise `ValueError` with suggested valid range |\n| Distance Metric | Valid `DistanceMetric` enum | Unknown metric string or invalid enum | Raise `ValueError` with available metric list |\n| Voting Strategy | Valid `VotingStrategy` enum | Invalid weighted voting configuration | Raise `ValueError` with strategy descriptions |\n| Cross-Validation Folds | 2 ≤ folds ≤ n_samples | Too few folds or more folds than samples | Raise `ValueError` with practical fold range |\n| Random Seed | Valid integer or None | Non-integer seed values | Raise `TypeError` with seed requirements |\n\nThe `validate_k_parameter` function implements sophisticated K validation that considers not just the mathematical constraint (K ≤ n_samples) but also practical considerations like warning when K is too large relative to dataset size, which can lead to poor classification performance.\n\n> **Design Insight**: Input validation in KNN requires balancing strictness with usability. While dimensional mismatches must trigger immediate errors to prevent incorrect calculations, some edge cases like single-class datasets might warrant warnings rather than failures, allowing users to proceed with degraded functionality when appropriate.\n\n### Numerical Error Handling\n\nNumerical stability becomes critical in KNN implementations because distance calculations involve floating-point arithmetic that can suffer from precision loss, overflow, and underflow conditions. The system must detect and handle these numerical issues while maintaining prediction accuracy and preventing silent failures.\n\n**Floating-Point Precision Management** addresses the fundamental challenge that floating-point arithmetic is not exact, and small precision errors can accumulate during distance calculations, particularly when dealing with high-dimensional feature spaces or extreme feature values.\n\n| Numerical Issue | Detection Method | Manifestation | Mitigation Strategy |\n|-----------------|------------------|---------------|-------------------|\n| Precision Loss | Check for extremely small distance differences | Ties in distance ranking where none should exist | Use `numpy.isclose` with appropriate tolerance |\n| Overflow in Squared Distances | Monitor for `inf` values in distance arrays | Euclidean distance calculation produces infinity | Clamp feature values or use normalized features |\n| Underflow in Inverse Weighting | Detect zero distances in weighted voting | Division by zero in distance weighting | Add small epsilon value to distances |\n| Accumulated Rounding Errors | Validate distance triangle inequality | Inconsistent distance relationships | Use higher precision arithmetic for critical calculations |\n| NaN Propagation | Scan distance arrays for NaN values | Invalid distance calculations spreading | Identify and isolate NaN sources in feature data |\n\nThe distance calculation functions implement numerical safeguards by checking for edge cases before performing potentially problematic operations. For example, the `euclidean_distance` function validates that the sum of squared differences is non-negative before taking the square root, preventing domain errors that could produce NaN results.\n\n**Distance Calculation Stability** requires special attention because distance metrics form the foundation of all KNN predictions. Each distance metric has specific numerical vulnerabilities that must be addressed through careful implementation and validation.\n\n| Distance Metric | Numerical Vulnerability | Error Condition | Stabilization Technique |\n|-----------------|------------------------|-----------------|------------------------|\n| Euclidean | Squared differences overflow | Very large feature values | Feature scaling or clipping before calculation |\n| Manhattan | No major numerical issues | Robust to most inputs | Minimal special handling required |\n| Cosine | Division by zero in normalization | Zero-magnitude vectors | Check vector norms before division, handle zero case |\n| Weighted Distance | Inverse distance calculation | Exact distance matches between points | Add small epsilon to prevent division by zero |\n\nThe cosine distance implementation exemplifies robust numerical handling by computing vector magnitudes separately, checking for zero norms that would cause division by zero, and handling the special case where identical vectors should have zero distance despite the mathematical singularity.\n\n**Vectorized Operation Safety** ensures that NumPy's broadcasting and vectorized operations don't mask numerical errors that would be obvious in scalar calculations. Broadcasting can hide dimensional mismatches, and vectorized operations can propagate errors across entire arrays.\n\n| Vectorization Risk | Detection Strategy | Error Pattern | Prevention Approach |\n|--------------------|-------------------|---------------|-------------------|\n| Broadcasting Errors | Validate array shapes before operations | Silent dimension expansion causing wrong results | Explicit shape checking in distance functions |\n| Parallel Error Propagation | Check for NaN/inf in result arrays | Single bad input affecting entire batch | Input sanitization and per-sample validation |\n| Memory Overflow | Monitor memory usage during large batch operations | System memory exhaustion | Batch size limits and progressive processing |\n| Loss of Precision | Compare vectorized vs scalar results on test cases | Subtle accuracy degradation | Use appropriate NumPy data types (float64) |\n\nThe `calculate_distances_to_point` function implements comprehensive safety checks by validating input array shapes, monitoring for numerical anomalies in the result array, and using appropriate data types to maintain precision throughout vectorized distance calculations.\n\n> **Critical Insight**: Numerical stability in KNN isn't just about preventing crashes—small precision errors can change neighbor rankings and lead to different classification decisions. The system must balance computational efficiency with numerical accuracy to maintain prediction consistency.\n\n### Edge Case Handling\n\nEdge case handling addresses the boundary conditions and unusual scenarios that can arise in real-world KNN usage. These cases often involve dataset characteristics or parameter configurations that are technically valid but require special handling to produce meaningful results.\n\n**Dataset Edge Cases** encompass scenarios where the training data has unusual characteristics that challenge standard KNN assumptions. These cases require specialized handling to either adapt the algorithm behavior or provide informative feedback to the user.\n\n| Edge Case | Scenario Description | Challenge | Handling Strategy |\n|-----------|---------------------|-----------|-------------------|\n| Single Sample Dataset | Training data contains only one example | Cannot find K > 1 neighbors | Reduce K to 1 and return single training label |\n| Single Class Dataset | All training samples have identical class | Classification becomes trivial | Return constant class with confidence warning |\n| Empty Feature Vectors | Zero-dimensional feature space | Distance calculation undefined | Raise `ValueError` requesting valid features |\n| Duplicate Feature Vectors | Multiple samples with identical features | Distance ties affecting neighbor selection | Use class label or sample index for tie-breaking |\n| Extremely Small Dataset | Fewer than K training samples | Cannot satisfy K-neighbor requirement | Reduce K to dataset size and log warning |\n| Highly Imbalanced Classes | One class dominates training data | Majority voting bias toward dominant class | Suggest weighted voting or stratified sampling |\n\nThe single sample dataset case illustrates the importance of graceful degradation—rather than failing completely, the system reduces K to 1 and returns the only available training label, while logging a warning about the limitation. This approach allows users to proceed with minimal functionality rather than encountering a complete failure.\n\n**Parameter Edge Cases** involve algorithm configurations that are technically valid but lead to degenerate or suboptimal behavior. The system must detect these cases and either adapt automatically or warn users about potential issues.\n\n| Parameter Edge Case | Configuration | Problem | Adaptive Response |\n|--------------------|---------------|---------|------------------|\n| K Equals Dataset Size | k = n_samples | All training samples are \"neighbors\" | Allow but warn about meaningless voting |\n| K Is Even Number | Even k value | Increased probability of voting ties | Suggest odd K values or enable weighted voting |\n| Very Large K | K > n_samples/2 | Classification converges to majority class | Warn about loss of locality assumption |\n| Very Small K | K = 1 | High variance, noise sensitivity | Warn about overfitting potential |\n| Invalid Distance Metric | Unsupported metric string | Cannot compute distances | Raise `ValueError` with supported options |\n\nThe `validate_k_parameter` function implements intelligent edge case detection by not only checking mathematical validity but also analyzing the practical implications of extreme K values and providing guidance to users about potential issues with their parameter choices.\n\n**Prediction Edge Cases** occur during the actual classification process when the combination of query points, training data, and algorithm parameters creates unusual situations that require special handling to produce reasonable results.\n\n| Prediction Edge Case | Situation | Consequence | Resolution Strategy |\n|---------------------|-----------|-------------|-------------------|\n| Voting Ties | Equal votes for multiple classes | Ambiguous classification decision | Use distance-based tie-breaking or random selection |\n| Identical Query and Training | Zero distance to training sample | Perfect match but potential overfitting | Return exact match class with high confidence |\n| All Neighbors Same Class | K neighbors have identical labels | Trivial voting but high confidence | Return unanimous class with maximum confidence |\n| Distance Calculation Failure | Invalid features produce NaN distances | Cannot rank neighbors | Raise prediction error with diagnostic information |\n| Memory Exhaustion | Large batch prediction exceeds memory | System failure during prediction | Split batch into smaller chunks automatically |\n\nThe voting tie case demonstrates sophisticated edge case handling where the system first attempts distance-based tie-breaking by examining which tied class has the closest individual neighbor, and only falls back to random selection if distances are also tied.\n\n**Data Quality Edge Cases** address scenarios where the input data has quality issues that don't prevent processing but could lead to poor predictions or misleading results.\n\n| Data Quality Issue | Detection Method | Impact on KNN | Mitigation Approach |\n|--------------------|------------------|---------------|-------------------|\n| Feature Scale Disparities | Analyze feature variance across dimensions | Distance dominated by large-scale features | Warn about need for feature scaling |\n| Sparse Feature Vectors | Count zero values in feature dimensions | Distance metrics may not be meaningful | Suggest appropriate distance metrics |\n| Categorical Features as Numbers | Detect integer features with few unique values | Euclidean distance inappropriate | Warn about categorical encoding needs |\n| Missing Value Indicators | Identify placeholder values (-999, -1, etc.) | Invalid distance calculations | Detect and reject invalid indicator values |\n| Outlier Samples | Statistical outlier detection in training data | Disproportionate influence on predictions | Log outlier warnings with sample indices |\n\nThe feature scale disparity detection exemplifies proactive data quality monitoring—the system analyzes feature variance distributions and warns users when some features have orders of magnitude larger scales than others, suggesting feature normalization before training.\n\n> **Edge Case Philosophy**: The goal isn't to handle every possible edge case transparently, but to detect unusual conditions, fail gracefully with informative error messages, and guide users toward appropriate solutions. Sometimes the best handling is a clear error message explaining why the operation cannot proceed.\n\n**⚠️ Pitfall: Silent Edge Case Failures**\nMany KNN implementations fail silently when encountering edge cases, producing technically valid but meaningless results. For example, setting K equal to the dataset size technically works but makes every prediction the majority class regardless of the query point. Always validate not just technical correctness but practical meaningfulness of parameters and configurations.\n\n**⚠️ Pitfall: Inadequate Tie-Breaking**\nWhen multiple classes receive equal votes, some implementations use arbitrary tie-breaking (like alphabetical order) that can introduce bias. Implement distance-based tie-breaking where the class with the closest individual neighbor wins, falling back to random selection only when distances are also tied.\n\n**⚠️ Pitfall: Ignoring Numerical Precision**\nFloating-point precision issues can cause apparently identical distances to have tiny differences that affect neighbor ranking. Use appropriate tolerance values when comparing distances and implement robust tie detection that accounts for numerical precision limitations.\n\n### Implementation Guidance\n\nThe error handling implementation requires a systematic approach that validates inputs at component boundaries, manages numerical stability during calculations, and gracefully handles edge cases throughout the prediction pipeline.\n\n**Technology Recommendations:**\n\n| Component | Simple Option | Advanced Option |\n|-----------|--------------|-----------------|\n| Input Validation | Built-in Python type checking with manual validation | Pydantic models with automatic validation |\n| Numerical Stability | NumPy's built-in error handling with manual checks | Decimal module for high-precision calculations |\n| Error Logging | Python logging module with structured messages | Structured logging with JSON format |\n| Exception Handling | Standard Python exceptions with custom messages | Custom exception hierarchy with error codes |\n\n**Recommended File Structure:**\n```\nknn_classifier/\n├── exceptions.py           # Custom exception definitions\n├── validation.py           # Input validation functions\n├── numerical_utils.py      # Numerical stability helpers\n├── edge_case_handlers.py   # Edge case detection and handling\n└── error_recovery.py       # Graceful degradation strategies\n```\n\n**Infrastructure Starter Code:**\n\n```python\n# exceptions.py - Complete custom exception hierarchy\nimport numpy as np\nfrom typing import Any, List, Optional, Union\n\nclass KNNError(Exception):\n    \"\"\"Base exception for KNN classifier errors\"\"\"\n    pass\n\nclass ValidationError(KNNError):\n    \"\"\"Raised when input validation fails\"\"\"\n    def __init__(self, message: str, invalid_data: Optional[Any] = None):\n        super().__init__(message)\n        self.invalid_data = invalid_data\n\nclass NumericalInstabilityError(KNNError):\n    \"\"\"Raised when numerical calculations become unstable\"\"\"\n    def __init__(self, message: str, problematic_values: Optional[np.ndarray] = None):\n        super().__init__(message)\n        self.problematic_values = problematic_values\n\nclass EdgeCaseError(KNNError):\n    \"\"\"Raised when edge cases cannot be handled gracefully\"\"\"\n    def __init__(self, message: str, edge_case_type: str):\n        super().__init__(message)\n        self.edge_case_type = edge_case_type\n\n# numerical_utils.py - Complete numerical stability helpers\nimport numpy as np\nimport warnings\nfrom typing import Tuple, Optional\n\nEPSILON = 1e-10  # Small value for numerical stability\nDISTANCE_TOLERANCE = 1e-8  # Tolerance for distance comparisons\n\ndef safe_sqrt(values: np.ndarray) -> np.ndarray:\n    \"\"\"Safely compute square root, handling negative values from precision errors\"\"\"\n    # Clamp near-zero negative values to zero\n    safe_values = np.maximum(values, 0.0)\n    if np.any(values < -EPSILON):\n        warnings.warn(\"Negative values detected in square root input, clamping to zero\")\n    return np.sqrt(safe_values)\n\ndef safe_divide(numerator: np.ndarray, denominator: np.ndarray, \n                default_value: float = 0.0) -> np.ndarray:\n    \"\"\"Safely divide arrays, handling division by zero\"\"\"\n    with np.errstate(divide='ignore', invalid='ignore'):\n        result = np.divide(numerator, denominator)\n        # Replace inf and nan with default value\n        mask = ~np.isfinite(result)\n        result[mask] = default_value\n    return result\n\ndef check_numerical_stability(array: np.ndarray, array_name: str) -> None:\n    \"\"\"Check array for numerical issues and raise errors if found\"\"\"\n    if np.any(np.isnan(array)):\n        raise NumericalInstabilityError(\n            f\"NaN values detected in {array_name}\",\n            problematic_values=array[np.isnan(array)]\n        )\n    if np.any(np.isinf(array)):\n        raise NumericalInstabilityError(\n            f\"Infinite values detected in {array_name}\",\n            problematic_values=array[np.isinf(array)]\n        )\n\ndef detect_precision_loss(distances: np.ndarray, k: int) -> bool:\n    \"\"\"Detect if precision loss is affecting neighbor selection\"\"\"\n    if len(distances) < k:\n        return False\n    \n    # Check if the k-th and (k+1)-th distances are suspiciously close\n    sorted_distances = np.sort(distances)\n    if len(sorted_distances) > k:\n        distance_gap = sorted_distances[k] - sorted_distances[k-1]\n        return distance_gap < DISTANCE_TOLERANCE\n    return False\n```\n\n**Core Logic Skeleton Code:**\n\n```python\n# validation.py - Input validation core logic\nfrom typing import List, Union, Optional, Tuple\nimport numpy as np\nfrom .exceptions import ValidationError\nfrom .data_types import FeatureMatrix, FeatureVector, ClassLabel, TrainingData\n\ndef validate_training_data(features: FeatureMatrix, labels: List[ClassLabel]) -> None:\n    \"\"\"Comprehensive validation of training data consistency and quality\"\"\"\n    # TODO 1: Check that features is a valid 2D numpy array with shape (n_samples, n_features)\n    # TODO 2: Verify that labels list has exactly n_samples elements\n    # TODO 3: Ensure all feature values are finite (no NaN, no infinite values)\n    # TODO 4: Validate that all labels are hashable and non-None\n    # TODO 5: Check for minimum dataset requirements (at least 1 sample, 1 feature)\n    # TODO 6: Warn if all labels are identical (single-class dataset)\n    # Hint: Use np.isfinite() to check for valid numeric values\n    pass\n\ndef validate_query_points(query_points: FeatureMatrix, \n                         training_n_features: int) -> None:\n    \"\"\"Validate query points for prediction compatibility\"\"\"\n    # TODO 1: Ensure query_points is a valid numpy array (1D or 2D)\n    # TODO 2: Check dimensional compatibility with training data\n    # TODO 3: Verify all query values are finite numeric values\n    # TODO 4: Validate reasonable batch size to prevent memory issues\n    # Hint: Handle both single query (1D) and batch query (2D) cases\n    pass\n\ndef validate_k_parameter(k: int, dataset_size: int) -> None:\n    \"\"\"Validate K parameter against dataset constraints with helpful warnings\"\"\"\n    # TODO 1: Check that k is a positive integer\n    # TODO 2: Ensure k does not exceed dataset size\n    # TODO 3: Warn if k is very large relative to dataset (> dataset_size/2)\n    # TODO 4: Warn if k is even (increases tie probability)\n    # TODO 5: Suggest optimal k range based on dataset characteristics\n    # Hint: Use warnings.warn() for non-fatal issues\n    pass\n\ndef validate_distance_metric(metric: Union[str, 'DistanceMetric']) -> 'DistanceMetric':\n    \"\"\"Validate and normalize distance metric specification\"\"\"\n    # TODO 1: Handle string metric names by converting to enum\n    # TODO 2: Verify metric is a valid DistanceMetric enum value\n    # TODO 3: Return normalized DistanceMetric enum\n    # TODO 4: Raise ValidationError with available options if invalid\n    # Hint: Use DistanceMetric enum for standardized metric representation\n    pass\n\n# edge_case_handlers.py - Edge case detection and handling\ndef handle_dataset_edge_cases(training_data: TrainingData, k: int) -> Tuple[int, List[str]]:\n    \"\"\"Detect and handle dataset-related edge cases\"\"\"\n    # TODO 1: Detect single-sample dataset and adjust k to 1\n    # TODO 2: Check for single-class dataset and warn about trivial classification\n    # TODO 3: Handle k larger than dataset size by reducing k\n    # TODO 4: Detect highly imbalanced classes and suggest alternatives\n    # TODO 5: Return adjusted k and list of warnings for user notification\n    # Hint: Calculate class distribution to detect imbalance\n    pass\n\ndef handle_prediction_edge_cases(neighbor_labels: List[ClassLabel], \n                                neighbor_distances: np.ndarray) -> Tuple[ClassLabel, float, str]:\n    \"\"\"Handle edge cases during prediction voting\"\"\"\n    # TODO 1: Detect voting ties and implement distance-based tie-breaking\n    # TODO 2: Handle case where query point exactly matches training sample\n    # TODO 3: Manage unanimous voting (all neighbors same class)\n    # TODO 4: Calculate confidence score based on voting characteristics\n    # TODO 5: Return predicted class, confidence, and explanation string\n    # Hint: Use distance information to break ties intelligently\n    pass\n\ndef detect_data_quality_issues(features: FeatureMatrix, labels: List[ClassLabel]) -> List[str]:\n    \"\"\"Detect potential data quality issues that could affect KNN performance\"\"\"\n    # TODO 1: Analyze feature scale disparities across dimensions\n    # TODO 2: Detect suspicious patterns indicating categorical features\n    # TODO 3: Identify potential missing value indicators (-999, -1, etc.)\n    # TODO 4: Check for statistical outliers in feature distributions\n    # TODO 5: Return list of warnings about detected quality issues\n    # Hint: Use statistical measures like standard deviation ratios\n    pass\n```\n\n**Language-Specific Python Hints:**\n- Use `numpy.errstate()` context manager to control floating-point error handling during calculations\n- Leverage `warnings.warn()` for non-fatal issues that users should know about but don't prevent operation\n- Implement custom exception classes that inherit from appropriate base exceptions and include diagnostic information\n- Use `isinstance()` checks for robust type validation that handles inheritance and duck typing\n- Apply `numpy.isfinite()` to check for both NaN and infinite values simultaneously\n- Use `functools.wraps()` when creating validation decorators to preserve function metadata\n\n**Milestone Checkpoints:**\n\nAfter Milestone 1 (Distance Calculation):\n```bash\npython -m pytest tests/test_validation.py::test_distance_validation -v\npython -c \"\nfrom knn_classifier import validate_training_data, euclidean_distance\nimport numpy as np\n# Test numerical stability\ntry:\n    result = euclidean_distance(np.array([1e10, 1e10]), np.array([1e10 + 1, 1e10 + 1]))\n    print(f'Large number handling: {result}')\n    validate_training_data(np.array([[1, 2], [3, float('inf')]]), ['A', 'B'])\nexcept Exception as e:\n    print(f'Error correctly caught: {e}')\n\"\n```\n\nAfter Milestone 2 (Classification):\n```bash\npython -c \"\nfrom knn_classifier import KNNClassifier\nimport numpy as np\n# Test edge case handling\nclassifier = KNNClassifier(k=5)\ntry:\n    # Single sample dataset\n    classifier.fit(np.array([[1, 2]]), ['A'])\n    result = classifier.predict(np.array([[1.1, 2.1]]))\n    print(f'Single sample prediction: {result}')\nexcept Exception as e:\n    print(f'Edge case handling: {e}')\n\"\n```\n\nAfter Milestone 3 (Evaluation):\n```bash\npython -c \"\nfrom knn_classifier import k_fold_cross_validate\nimport numpy as np\n# Test evaluation robustness\nX = np.random.rand(10, 3)\ny = ['A'] * 10  # All same class\ntry:\n    results = k_fold_cross_validate(X, y, k_folds=3, k_neighbors=2)\n    print(f'Single-class CV results: {results}')\nexcept Exception as e:\n    print(f'Evaluation edge case: {e}')\n\"\n```\n\n**Debugging Tips:**\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|-----------------|-----|\n| Silent wrong predictions | Input validation bypassed | Check feature dimensions, data types | Add comprehensive validation at entry points |\n| Intermittent NaN results | Floating-point precision issues | Log intermediate calculation values | Use safe mathematical operations with bounds checking |\n| Memory errors during prediction | Large batch processing | Monitor memory usage, check batch sizes | Implement automatic batch splitting |\n| Inconsistent neighbor selection | Distance ties not handled | Compare distance arrays for near-equal values | Implement robust tie-breaking with tolerance |\n| Poor performance warnings ignored | Edge case detection not visible | Check warning log output | Make warnings more prominent or upgrade to errors |\n\n\n## Testing Strategy\n\n> **Milestone(s):** Comprehensive testing strategy across all milestones - unit tests for distance calculation (Milestone 1), integration tests for neighbor finding and classification (Milestone 2), and milestone checkpoints for evaluation and optimization (Milestone 3)\n\nTesting a K-Nearest Neighbors classifier presents unique challenges compared to parametric machine learning models. Since KNN is based on lazy learning, most computation happens at prediction time, making it crucial to verify that distance calculations, neighbor finding, and voting mechanisms work correctly across diverse scenarios. The testing strategy must validate both the mathematical correctness of algorithms and the system's behavior under edge cases that are particularly common in instance-based learning.\n\n### Mental Model: The Scientific Method for Code\n\nThink of testing a KNN implementation like conducting scientific experiments to validate a hypothesis. Each unit test is a controlled experiment that isolates one component and verifies it behaves as expected under specific conditions. Integration tests are like field studies that observe how components interact in realistic scenarios. Milestone checkpoints are comprehensive evaluations that ensure the entire system meets scientific standards for accuracy and reliability.\n\nJust as scientists use multiple validation techniques - from laboratory experiments to peer review - our testing strategy employs multiple layers of verification. Unit tests provide microscopic validation of individual algorithms, integration tests examine macroscopic system behavior, and milestone checkpoints ensure the implementation achieves the learning objectives and performance requirements.\n\nThe key insight is that KNN testing requires special attention to numerical stability, edge cases with small datasets, and the correctness of distance-based computations that form the foundation of the entire algorithm. Unlike testing a web API where you might focus on HTTP status codes and JSON structure, KNN testing focuses on mathematical properties, algorithmic correctness, and performance under various data distributions.\n\n### Unit Testing Strategy\n\nUnit testing for KNN focuses on isolating and verifying each component independently, ensuring that distance calculations are mathematically correct, neighbor finding algorithms return proper results, and voting mechanisms handle edge cases gracefully. Since KNN relies heavily on numerical computations, unit tests must validate both correctness and numerical stability.\n\nThe unit testing strategy follows a component-based approach that mirrors the system architecture. Each major component - distance calculation, neighbor finding, classification, and evaluation - requires comprehensive test coverage that validates normal operation, boundary conditions, and error scenarios. The tests must be deterministic and reproducible, which requires careful management of random seeds and floating-point comparisons.\n\n#### Distance Metrics Testing\n\nDistance calculation forms the mathematical foundation of KNN, making it critical to verify that each metric produces correct results. The testing approach validates both mathematical correctness and computational efficiency of vectorized operations.\n\n| Test Category | Test Cases | Validation Criteria | Expected Behavior |\n|---------------|------------|-------------------|-------------------|\n| Mathematical Correctness | Known vector pairs with calculated distances | Exact match within numerical tolerance | `euclidean_distance([0,0], [3,4])` returns 5.0 |\n| Edge Cases | Zero vectors, identical points, single dimensions | Handle gracefully without errors | Distance between identical points is 0.0 |\n| Numerical Stability | Very small/large numbers, near-zero differences | No overflow, underflow, or NaN | `safe_sqrt` handles negative inputs from floating-point errors |\n| Vectorized Operations | Batch distance calculations vs individual | Performance improvement and identical results | `calculate_distances_to_point` faster than loops |\n| Input Validation | Mismatched dimensions, invalid types | Raise appropriate exceptions | `validate_compatible_vectors` catches dimension mismatch |\n\nThe distance metrics tests use known mathematical relationships to verify correctness. For example, Euclidean distance tests use right triangles where the hypotenuse length is known, while Manhattan distance tests use grid-based scenarios where the sum of absolute differences can be calculated manually.\n\n```python\ndef test_euclidean_distance_right_triangle():\n    \"\"\"Test Euclidean distance using 3-4-5 right triangle.\"\"\"\n    point1 = np.array([0.0, 0.0], dtype=np.float64)\n    point2 = np.array([3.0, 4.0], dtype=np.float64)\n    expected_distance = 5.0\n    \n    actual_distance = euclidean_distance(point1, point2)\n    \n    assert abs(actual_distance - expected_distance) < DISTANCE_TOLERANCE\n```\n\nNumerical stability tests are particularly important for distance calculations because floating-point arithmetic can introduce small errors that compound during square root and division operations. These tests verify that the `safe_sqrt` and `safe_divide` functions handle edge cases like negative numbers under square roots (which can occur due to floating-point precision issues) and division by zero in cosine distance calculations.\n\n#### Neighbor Finding Testing\n\nNeighbor finding algorithms must correctly identify the K closest training samples while handling various edge cases like ties in distances, invalid K values, and empty datasets. The unit tests validate both the correctness of neighbor selection and the proper handling of boundary conditions.\n\n| Test Category | Test Cases | Validation Criteria | Expected Behavior |\n|---------------|------------|-------------------|-------------------|\n| Correct K Selection | Known datasets with calculated neighbors | Return exactly K closest neighbors | Sort neighbors by ascending distance |\n| Tie Handling | Multiple neighbors with identical distances | Consistent tie-breaking behavior | Use `handle_distance_ties` with stable sorting |\n| Edge Cases | K=1, K=dataset_size, K>dataset_size | Handle gracefully or raise errors | `validate_k_parameter` catches invalid K |\n| Distance Metric Integration | Same neighbors with different metrics | Different results but consistent ranking | Euclidean vs Manhattan yield different neighbors |\n| Performance | Large datasets with batch queries | Efficient vectorized operations | `find_neighbors_batch` outperforms individual queries |\n\nThe neighbor finding tests create small synthetic datasets where the correct neighbors can be determined manually. For example, a 2D dataset with points arranged in a grid pattern allows manual verification of which points should be closest under different distance metrics.\n\n```python\ndef test_find_k_neighbors_simple_grid():\n    \"\"\"Test neighbor finding on a simple 2D grid where neighbors are obvious.\"\"\"\n    # Create a 3x3 grid with query point at center\n    training_points = np.array([\n        [0, 0], [0, 1], [0, 2],  # Left column\n        [1, 0], [1, 1], [1, 2],  # Middle column\n        [2, 0], [2, 1], [2, 2]   # Right column\n    ], dtype=np.float64)\n    \n    query_point = np.array([1, 1], dtype=np.float64)  # Center point\n    k = 3\n    \n    # The 3 closest neighbors to (1,1) should be (0,1), (1,0), and (1,2) at distance 1.0\n    neighbor_indices, neighbor_distances = find_k_neighbors(\n        query_point, k, DistanceMetric.EUCLIDEAN\n    )\n    \n    assert len(neighbor_indices) == k\n    assert len(neighbor_distances) == k\n    assert np.all(neighbor_distances <= 1.414)  # sqrt(2) for diagonal neighbors\n```\n\nTie-handling tests are crucial because multiple training points may have identical distances to a query point, especially in discrete or quantized feature spaces. The tests verify that the system breaks ties consistently and deterministically, typically by preferring neighbors with lower indices in the training data.\n\n#### Classification Voting Testing\n\nClassification voting converts neighbor labels into final predictions through majority or weighted voting. Unit tests must verify that voting algorithms correctly aggregate neighbor information and handle edge cases like voting ties and unanimous decisions.\n\n| Test Category | Test Cases | Validation Criteria | Expected Behavior |\n|---------------|------------|-------------------|-------------------|\n| Majority Voting | Known neighbor labels with clear majority | Return most frequent class | 3 votes for class A, 2 for class B → predict A |\n| Weighted Voting | Neighbor labels with distances | Closer neighbors have more influence | Closer neighbor breaks ties in weighted voting |\n| Tie Breaking | Equal votes across multiple classes | Consistent tie resolution | `resolve_ties` uses nearest neighbor or deterministic rule |\n| Confidence Scoring | Various voting scenarios | Higher confidence for unanimous decisions | Confidence near 1.0 for unanimous, lower for close votes |\n| Edge Cases | Single neighbor, all neighbors same class | Handle gracefully | Single neighbor gets 100% confidence |\n\nVoting tests use carefully constructed scenarios where the correct prediction can be determined manually. For example, a test might create a neighbor set with 3 votes for class \"A\" and 2 votes for class \"B\", then verify that majority voting returns \"A\" with appropriate confidence.\n\n```python\ndef test_majority_vote_clear_winner():\n    \"\"\"Test majority voting with a clear winning class.\"\"\"\n    neighbor_labels = ['A', 'A', 'A', 'B', 'B']\n    neighbor_distances = np.array([1.0, 1.5, 2.0, 2.5, 3.0])\n    k = 5\n    \n    predicted_class, confidence = majority_vote(neighbor_labels, k)\n    \n    assert predicted_class == 'A'\n    assert confidence == 3.0 / 5.0  # 3 out of 5 votes\n```\n\nWeighted voting tests verify that closer neighbors receive proportionally more influence in the final decision. These tests create scenarios where majority voting and weighted voting yield different results, confirming that distance weighting is applied correctly.\n\n#### Evaluation and Optimization Testing\n\nEvaluation components require testing of cross-validation, hyperparameter optimization, and metric calculation. These tests ensure that performance assessment is statistically sound and that optimization procedures find reasonable parameter values.\n\n| Test Category | Test Cases | Validation Criteria | Expected Behavior |\n|---------------|------------|-------------------|-------------------|\n| Cross-Validation | Known datasets with expected metrics | Reproducible results with same seed | `k_fold_cross_validate` returns consistent metrics |\n| Stratification | Imbalanced datasets | Preserve class ratios in folds | `split_stratified_folds` maintains class distribution |\n| Metric Calculation | Known predictions vs true labels | Correct precision, recall, F1 | `calculate_classification_metrics` matches manual calculation |\n| Grid Search | Small parameter ranges | Find reasonable optimal K | `grid_search_k` selects K that improves validation accuracy |\n| Statistical Validity | Multiple runs with different seeds | Stable results across runs | Performance estimates have reasonable confidence intervals |\n\nCross-validation tests use small synthetic datasets where the expected performance can be estimated manually. For example, a perfectly separable dataset should achieve near-perfect accuracy, while a dataset with overlapping classes should show lower performance that matches theoretical expectations.\n\n### Integration Testing Strategy\n\nIntegration testing validates how components work together during the complete KNN workflow, from loading training data through making predictions and evaluating performance. These tests ensure that data flows correctly between components and that the system handles realistic scenarios effectively.\n\nIntegration tests focus on end-to-end workflows that mirror how users interact with the KNN classifier. Unlike unit tests that isolate individual functions, integration tests validate that components communicate properly and that the system produces reasonable results on real datasets. The tests must verify both functional correctness and performance characteristics.\n\n#### Training and Prediction Workflow Integration\n\nThe core integration test validates the complete training and prediction pipeline, ensuring that data flows correctly from initial training through final predictions. This workflow integration test exercises all major system components in sequence.\n\n| Integration Scenario | Test Data | Validation Criteria | Expected Outcome |\n|---------------------|-----------|-------------------|------------------|\n| Complete Pipeline | Iris dataset with train/test split | Accuracy above baseline threshold | `fit()` → `predict()` → evaluate accuracy > 0.80 |\n| Different Distance Metrics | Same data with EUCLIDEAN vs MANHATTAN | Different but reasonable results | Both metrics produce valid predictions |\n| Various K Values | K=1, K=5, K=10 on same dataset | Performance varies predictably | Small K higher variance, large K smoother decisions |\n| Batch Prediction | Multiple query points simultaneously | Identical to individual predictions | Batch and individual results match exactly |\n| Feature Scaling Impact | Scaled vs unscaled features | Scaling affects distance-based results | Euclidean distance sensitive to scaling, need preprocessing |\n\nThe pipeline integration test creates a complete workflow that loads data, splits it into training and testing sets, fits a KNN classifier, makes predictions, and evaluates performance. This test serves as a smoke test that verifies basic system functionality.\n\n```python\ndef test_complete_knn_pipeline():\n    \"\"\"Integration test for complete KNN training and prediction pipeline.\"\"\"\n    # Load and prepare data\n    X, y = load_iris_dataset()\n    X_train, X_test, y_train, y_test = split_and_scale_data(\n        X, y, test_size=0.3, scale_features=True, random_state=42\n    )\n    \n    # Create and train classifier\n    classifier = KNNClassifier(k=5, distance_metric=DistanceMetric.EUCLIDEAN)\n    classifier.fit(X_train, y_train)\n    \n    # Make predictions\n    predictions = classifier.predict(X_test)\n    \n    # Evaluate performance\n    metrics = calculate_classification_metrics(y_test, predictions, average='macro')\n    \n    # Verify reasonable performance\n    assert metrics['accuracy'] > 0.80  # Iris is easily separable\n    assert len(predictions) == len(y_test)  # All test samples predicted\n```\n\nDistance metric integration tests verify that different metrics produce reasonable but distinct results when applied to the same dataset. These tests help identify whether distance metric selection is working properly and whether the system handles metric-specific edge cases.\n\n#### Cross-Validation and Optimization Integration\n\nCross-validation integration tests validate that evaluation and optimization components work together correctly, ensuring that hyperparameter tuning produces reliable results and that performance estimates are statistically sound.\n\n| Integration Scenario | Test Configuration | Validation Criteria | Expected Outcome |\n|---------------------|-------------------|-------------------|------------------|\n| K-Fold Cross-Validation | 5-fold CV with multiple K values | Stable performance estimates | Standard deviation reasonable relative to mean |\n| Stratified Splitting | Imbalanced dataset with stratification | Class ratios preserved across folds | Each fold maintains original class distribution |\n| Grid Search Optimization | K values [1, 3, 5, 7, 9] with 3-fold CV | Optimal K selected based on validation | Grid search finds K that maximizes validation accuracy |\n| Nested Cross-Validation | Inner loop for K selection, outer for performance | Unbiased performance estimate | Nested CV prevents overfitting to validation set |\n| Multiple Distance Metrics | Grid search across K and distance metrics | Best combination selected | Find optimal (K, metric) pair |\n\nCross-validation integration tests ensure that the evaluation pipeline correctly coordinates fold creation, model training, prediction, and metric aggregation. These tests verify that the statistical methodology is sound and that results are reproducible.\n\n```python\ndef test_cross_validation_integration():\n    \"\"\"Integration test for cross-validation with hyperparameter optimization.\"\"\"\n    X, y = load_iris_dataset()\n    k_values = [1, 3, 5, 7]\n    cv_folds = 3\n    \n    # Run grid search with cross-validation\n    grid_result = grid_search_k(\n        X, y, k_values, cv_folds, DistanceMetric.EUCLIDEAN, random_seed=42\n    )\n    \n    # Verify grid search results\n    assert grid_result.optimal_k in k_values\n    assert 'mean_accuracy' in grid_result.optimal_metrics\n    assert grid_result.optimal_metrics['mean_accuracy'] > 0.70\n    \n    # Verify all K values were tested\n    assert len(grid_result.complete_results) == len(k_values)\n    \n    # Verify reproducibility\n    grid_result_2 = grid_search_k(\n        X, y, k_values, cv_folds, DistanceMetric.EUCLIDEAN, random_seed=42\n    )\n    assert grid_result.optimal_k == grid_result_2.optimal_k\n```\n\nThe cross-validation integration test validates that the evaluation system correctly implements statistical best practices for performance estimation and hyperparameter selection. It verifies that fold creation maintains data integrity and that metric aggregation produces meaningful results.\n\n#### Error Propagation and Recovery Integration\n\nError handling integration tests verify that errors are properly detected, propagated, and recovered from across component boundaries. These tests ensure that the system fails gracefully and provides useful error messages when problems occur.\n\n| Error Scenario | Trigger Condition | Expected Behavior | Recovery Mechanism |\n|----------------|-------------------|-------------------|-------------------|\n| Invalid Training Data | NaN values, mismatched dimensions | Raise `ValidationError` with specific message | `validate_training_data` catches issue early |\n| Incompatible Query Points | Wrong feature count in prediction | Raise `DimensionMismatchError` | `validate_query_points` prevents prediction |\n| Numerical Instability | Distance calculations produce NaN/inf | Fall back to stable computation | `check_numerical_stability` detects and handles |\n| Resource Exhaustion | Very large datasets with insufficient memory | Graceful degradation or clear error | Chunked processing or memory-efficient algorithms |\n| Invalid Parameters | K=0, K>dataset_size, invalid distance metric | Immediate parameter validation error | `validate_k_parameter` prevents invalid configuration |\n\nError propagation tests create scenarios that trigger various failure modes and verify that errors are caught at appropriate boundaries with clear, actionable error messages. These tests ensure that users receive helpful feedback when configuration or data issues occur.\n\n### Milestone Checkpoints\n\nMilestone checkpoints provide structured validation that the implementation meets learning objectives and functional requirements after completing each development phase. Each checkpoint includes automated tests, manual verification steps, and performance benchmarks that confirm successful milestone completion.\n\nThe checkpoints follow a progressive validation approach, where each milestone builds upon previous achievements. Early checkpoints focus on mathematical correctness and basic functionality, while later checkpoints emphasize integration, performance, and advanced features. Each checkpoint includes specific commands to run, expected outputs, and troubleshooting guidance.\n\n#### Milestone 1 Checkpoint: Distance Calculation\n\nThe first milestone checkpoint validates that distance metrics are implemented correctly and efficiently, forming a solid foundation for neighbor finding and classification. This checkpoint emphasizes mathematical correctness and computational performance.\n\n| Checkpoint Component | Test Command | Expected Result | Verification Method |\n|---------------------|--------------|-----------------|-------------------|\n| Distance Function Tests | `python -m pytest tests/test_distance_metrics.py -v` | All tests pass with specific accuracy | 20+ tests covering all metrics and edge cases |\n| Performance Benchmark | `python benchmark_distance.py` | Vectorized operations 10x faster than loops | Time comparison between vectorized and naive implementations |\n| Mathematical Validation | `python validate_distances.py` | Known distance calculations match expected values | Test against hand-calculated examples |\n| Numerical Stability | `python test_stability.py` | No NaN/inf values in edge cases | Test with extreme values and floating-point edge cases |\n| Interactive Verification | `python demo_distances.py` | Visual plots showing distance relationships | 2D scatter plots with distance contours |\n\nThe distance calculation checkpoint runs comprehensive tests that validate mathematical correctness across all implemented metrics. The tests include edge cases like identical points, zero vectors, and high-dimensional spaces where numerical precision becomes important.\n\n**Manual Verification Steps for Milestone 1:**\n\n1. **Mathematical Correctness Check**: Run the validation script that tests distance calculations against known mathematical examples. The Euclidean distance between points `[0, 0]` and `[3, 4]` should return exactly `5.0`. Manhattan distance between `[1, 1]` and `[4, 5]` should return exactly `7.0`.\n\n2. **Performance Validation**: Execute the benchmark script that compares vectorized distance calculations against naive Python loops. Vectorized operations should show at least 10x speedup for datasets with 1000+ samples.\n\n3. **Visual Verification**: Run the demo script that creates 2D scatter plots showing how different distance metrics create different proximity relationships between points. Euclidean distance should create circular contours, while Manhattan distance should create diamond-shaped contours.\n\n4. **Edge Case Testing**: Verify that the system handles edge cases gracefully:\n   - Distance between identical points returns 0.0\n   - Distance calculations with very small numbers don't produce negative values under square root\n   - Distance calculations with very large numbers don't overflow\n   - Cosine distance handles zero vectors appropriately\n\n**Troubleshooting Common Issues:**\n\n- **Test failures in numerical precision**: Adjust `DISTANCE_TOLERANCE` constant if legitimate floating-point precision issues occur\n- **Performance benchmark failures**: Check that NumPy vectorized operations are used instead of Python loops\n- **NaN/inf values in distance calculations**: Verify `safe_sqrt` and `safe_divide` functions handle edge cases properly\n\n#### Milestone 2 Checkpoint: K-Nearest Neighbors Classification\n\nThe second milestone checkpoint validates that neighbor finding and classification components work together correctly to produce accurate predictions. This checkpoint emphasizes algorithmic correctness and system integration.\n\n| Checkpoint Component | Test Command | Expected Result | Verification Method |\n|---------------------|--------------|-----------------|-------------------|\n| Neighbor Finding Tests | `python -m pytest tests/test_neighbor_finding.py -v` | All neighbor selection tests pass | Verify correct K neighbors returned in sorted order |\n| Classification Tests | `python -m pytest tests/test_classification.py -v` | All voting mechanism tests pass | Majority and weighted voting produce correct results |\n| Integration Tests | `python -m pytest tests/test_integration.py -v` | End-to-end pipeline tests pass | Complete training and prediction workflow |\n| Accuracy Validation | `python validate_accuracy.py` | Iris dataset accuracy > 90% | Test on well-known dataset with expected performance |\n| Interactive Demo | `python demo_classification.py` | Visual classification boundaries | 2D plots showing decision boundaries |\n\nThe classification checkpoint runs tests that verify both individual component functionality and integrated system behavior. The tests include scenarios with various K values, different distance metrics, and edge cases like ties in voting.\n\n**Manual Verification Steps for Milestone 2:**\n\n1. **Basic Classification Test**: Create a simple 2D dataset with clearly separable classes (e.g., points clustered at `[0, 0]` and `[10, 10]`). Train a KNN classifier with K=3 and verify that predictions are correct for obvious test points.\n\n2. **Iris Dataset Validation**: Load the Iris dataset, split into train/test sets, and verify that classification accuracy exceeds 90%. This benchmark ensures the implementation achieves expected performance on a standard dataset.\n\n3. **Visual Decision Boundaries**: Run the demo script that plots 2D decision boundaries for different K values. Small K should create complex, irregular boundaries while large K should create smoother boundaries.\n\n4. **Voting Mechanism Verification**: Create test cases where majority voting and weighted voting produce different results. For example, if the nearest neighbor votes for class A but the 3 nearest neighbors vote 2-to-1 for class B, verify that weighted voting gives more influence to the closest neighbor.\n\n**Edge Case Testing for Milestone 2:**\n\n- **K=1 Classification**: Verify that nearest neighbor (K=1) produces reasonable results\n- **K=dataset_size**: Test that using all training samples as neighbors works correctly\n- **Tie Breaking**: Create scenarios where multiple classes receive equal votes and verify consistent tie-breaking behavior\n- **Single-Class Training Data**: Test behavior when training data contains only one class\n\n#### Milestone 3 Checkpoint: Improvements & Evaluation\n\nThe final milestone checkpoint validates that evaluation, optimization, and advanced features work correctly, providing a complete KNN implementation with proper performance assessment and hyperparameter tuning.\n\n| Checkpoint Component | Test Command | Expected Result | Verification Method |\n|---------------------|--------------|-----------------|-------------------|\n| Cross-Validation Tests | `python -m pytest tests/test_evaluation.py -v` | All evaluation tests pass | Statistical methodology correctly implemented |\n| Optimization Tests | `python -m pytest tests/test_optimization.py -v` | Grid search finds reasonable optimal K | Hyperparameter tuning produces expected results |\n| Performance Metrics | `python validate_metrics.py` | Precision, recall, F1 calculations correct | Compare against sklearn implementations |\n| Complete System Test | `python test_complete_system.py` | Full workflow with optimization succeeds | Train, optimize, evaluate pipeline completes |\n| Benchmark Comparison | `python benchmark_sklearn.py` | Performance comparable to sklearn KNN | Accuracy within 2% of sklearn implementation |\n\nThe final checkpoint runs comprehensive tests that validate the complete KNN system, including advanced features like cross-validation, hyperparameter optimization, and performance metrics. These tests ensure that the implementation is production-ready and scientifically sound.\n\n**Manual Verification Steps for Milestone 3:**\n\n1. **Cross-Validation Validation**: Run K-fold cross-validation on the Iris dataset with K=5 folds. Verify that performance estimates are stable across runs with the same random seed and that standard deviation is reasonable relative to mean performance.\n\n2. **Hyperparameter Optimization**: Execute grid search over K values [1, 3, 5, 7, 9] and verify that the optimization process selects a reasonable K value (typically 3-7 for Iris) that maximizes validation accuracy.\n\n3. **Performance Metrics Verification**: Calculate precision, recall, and F1-score manually for a small test case and verify that the implementation matches manual calculations. Test both macro and weighted averaging options.\n\n4. **Sklearn Comparison**: Compare your implementation's accuracy against `sklearn.neighbors.KNeighborsClassifier` on multiple datasets. Performance should be within 2% assuming identical preprocessing and parameters.\n\n**Complete System Validation:**\n\nThe final system validation runs an end-to-end workflow that demonstrates all implemented features:\n\n```python\ndef validate_complete_system():\n    \"\"\"Complete system validation demonstrating all KNN features.\"\"\"\n    # Load and preprocess data\n    X, y = load_iris_dataset()\n    X_train, X_test, y_train, y_test = split_and_scale_data(\n        X, y, test_size=0.3, scale_features=True, random_state=42\n    )\n    \n    # Find optimal hyperparameters\n    k_values = [1, 3, 5, 7, 9]\n    grid_result = grid_search_k(\n        X_train, y_train, k_values, cv_folds=5, \n        distance_metric=DistanceMetric.EUCLIDEAN, random_seed=42\n    )\n    \n    # Train final model with optimal parameters\n    classifier = KNNClassifier(\n        k=grid_result.optimal_k, \n        distance_metric=DistanceMetric.EUCLIDEAN,\n        weighted_voting=True\n    )\n    classifier.fit(X_train, y_train)\n    \n    # Make predictions with confidence\n    predictions_with_confidence = classifier.predict_with_confidence(X_test)\n    \n    # Evaluate performance\n    predictions = [pred.predicted_class for pred in predictions_with_confidence]\n    metrics = calculate_classification_metrics(y_test, predictions, average='weighted')\n    confusion = calculate_confusion_matrix(y_test, predictions, class_labels=['setosa', 'versicolor', 'virginica'])\n    \n    # Verify results meet expectations\n    assert metrics['accuracy'] > 0.90  # High accuracy on Iris\n    assert grid_result.optimal_k in [3, 5, 7]  # Reasonable K selection\n    assert all(0.0 <= pred.confidence <= 1.0 for pred in predictions_with_confidence)  # Valid confidence scores\n    \n    print(f\"System validation successful!\")\n    print(f\"Optimal K: {grid_result.optimal_k}\")\n    print(f\"Test Accuracy: {metrics['accuracy']:.3f}\")\n    print(f\"Cross-validation score: {grid_result.optimal_metrics['mean_accuracy']:.3f} ± {grid_result.optimal_metrics['std_accuracy']:.3f}\")\n```\n\n**Success Criteria for Milestone 3:**\n\n- All automated tests pass without errors\n- Cross-validation produces stable, reproducible results\n- Grid search selects reasonable optimal K values\n- Performance metrics match manual calculations\n- Complete system achieves accuracy within 2% of sklearn baseline\n- Memory usage remains reasonable for datasets up to 10,000 samples\n- Processing time scales appropriately with dataset size and K value\n\n**Common Issues and Solutions:**\n\n- **Cross-validation inconsistency**: Ensure proper random seed management and stratified splitting\n- **Poor hyperparameter selection**: Verify that grid search explores appropriate K ranges and uses correct validation methodology\n- **Performance discrepancies with sklearn**: Check that preprocessing, distance metrics, and tie-breaking rules match exactly\n- **Memory issues with large datasets**: Implement chunked processing for distance calculations and neighbor finding\n\n### Implementation Guidance\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Testing Framework | `pytest` with basic assertions | `pytest` with fixtures, parametrization, and coverage |\n| Test Data Generation | Manual numpy arrays | `scikit-learn.datasets` and synthetic data generators |\n| Performance Benchmarking | Simple `time.time()` measurements | `pytest-benchmark` with statistical analysis |\n| Numerical Assertions | Basic `assert abs(a - b) < tolerance` | `numpy.testing.assert_allclose` with relative/absolute tolerance |\n| Mock Objects | Simple stub classes | `unittest.mock` for complex dependency injection |\n| Test Coverage | Manual verification | `pytest-cov` for automated coverage reporting |\n\n#### Recommended File Structure\n\n```\nknn-classifier/\n├── src/\n│   ├── knn/\n│   │   ├── __init__.py\n│   │   ├── distance_metrics.py     ← Distance calculation functions\n│   │   ├── neighbor_finding.py     ← K-nearest neighbor algorithms\n│   │   ├── classification.py       ← Voting and prediction logic\n│   │   └── evaluation.py           ← Cross-validation and optimization\n├── tests/\n│   ├── __init__.py\n│   ├── conftest.py                 ← Pytest fixtures and configuration\n│   ├── test_distance_metrics.py    ← Unit tests for distance calculations\n│   ├── test_neighbor_finding.py    ← Unit tests for neighbor search\n│   ├── test_classification.py      ← Unit tests for voting mechanisms\n│   ├── test_evaluation.py          ← Unit tests for evaluation methods\n│   ├── test_integration.py         ← Integration tests for complete workflows\n│   └── test_edge_cases.py          ← Comprehensive edge case testing\n├── benchmarks/\n│   ├── benchmark_distances.py      ← Performance tests for distance calculations\n│   ├── benchmark_neighbors.py      ← Performance tests for neighbor finding\n│   └── benchmark_complete.py       ← End-to-end performance benchmarks\n├── validation/\n│   ├── validate_distances.py       ← Mathematical correctness validation\n│   ├── validate_accuracy.py        ← Accuracy validation on known datasets\n│   └── validate_sklearn_comparison.py ← Compare against sklearn baseline\n└── demos/\n    ├── demo_distances.py           ← Interactive distance visualization\n    ├── demo_classification.py      ← Classification boundary visualization\n    └── demo_complete_system.py     ← Complete system demonstration\n```\n\n#### Testing Infrastructure Starter Code\n\n**conftest.py - Pytest Configuration and Fixtures:**\n\n```python\nimport pytest\nimport numpy as np\nfrom typing import Tuple, List\nfrom knn.data_types import FeatureMatrix, ClassLabel, TrainingData\n\n@pytest.fixture\ndef simple_2d_dataset() -> Tuple[FeatureMatrix, List[ClassLabel]]:\n    \"\"\"Simple 2D dataset for basic testing.\"\"\"\n    X = np.array([\n        [0, 0], [1, 1], [2, 2],  # Class A - diagonal line\n        [0, 2], [1, 3], [2, 4],  # Class B - parallel line\n    ], dtype=np.float64)\n    y = ['A', 'A', 'A', 'B', 'B', 'B']\n    return X, y\n\n@pytest.fixture\ndef iris_dataset() -> Tuple[FeatureMatrix, List[ClassLabel]]:\n    \"\"\"Iris dataset for realistic testing.\"\"\"\n    from sklearn.datasets import load_iris\n    iris = load_iris()\n    return iris.data.astype(np.float64), iris.target.tolist()\n\n@pytest.fixture\ndef single_point_dataset() -> Tuple[FeatureMatrix, List[ClassLabel]]:\n    \"\"\"Edge case: dataset with single training point.\"\"\"\n    X = np.array([[1.0, 2.0]], dtype=np.float64)\n    y = ['A']\n    return X, y\n\n@pytest.fixture\ndef identical_points_dataset() -> Tuple[FeatureMatrix, List[ClassLabel]]:\n    \"\"\"Edge case: multiple identical points with different labels.\"\"\"\n    X = np.array([\n        [1.0, 1.0], [1.0, 1.0], [1.0, 1.0]\n    ], dtype=np.float64)\n    y = ['A', 'B', 'A']\n    return X, y\n\n@pytest.fixture\ndef reproducible_random():\n    \"\"\"Fixture that provides deterministic randomness for tests.\"\"\"\n    np.random.seed(42)\n    return np.random.RandomState(42)\n```\n\n**test_distance_metrics.py - Unit Tests for Distance Calculations:**\n\n```python\nimport pytest\nimport numpy as np\nfrom knn.distance_metrics import (\n    euclidean_distance, manhattan_distance, cosine_distance,\n    calculate_distances_to_point, validate_compatible_vectors\n)\nfrom knn.data_types import DistanceMetric, DISTANCE_TOLERANCE\n\nclass TestEuclideanDistance:\n    \"\"\"Test cases for Euclidean distance calculation.\"\"\"\n    \n    def test_euclidean_distance_right_triangle(self):\n        \"\"\"Test Euclidean distance using known right triangle.\"\"\"\n        # TODO: Create points forming 3-4-5 right triangle\n        # TODO: Calculate distance using euclidean_distance function\n        # TODO: Assert result equals 5.0 within tolerance\n        pass\n    \n    def test_euclidean_distance_identical_points(self):\n        \"\"\"Test that identical points have zero distance.\"\"\"\n        # TODO: Create identical points\n        # TODO: Verify distance is exactly 0.0\n        pass\n    \n    def test_euclidean_distance_negative_coordinates(self):\n        \"\"\"Test Euclidean distance with negative coordinates.\"\"\"\n        # TODO: Test points in different quadrants\n        # TODO: Verify distance calculation handles negatives correctly\n        pass\n\nclass TestManhattanDistance:\n    \"\"\"Test cases for Manhattan distance calculation.\"\"\"\n    \n    def test_manhattan_distance_grid_movement(self):\n        \"\"\"Test Manhattan distance as grid movement.\"\"\"\n        # TODO: Create points representing grid coordinates\n        # TODO: Calculate expected Manhattan distance manually\n        # TODO: Verify function returns correct grid distance\n        pass\n\nclass TestVectorizedOperations:\n    \"\"\"Test vectorized distance calculations for performance.\"\"\"\n    \n    def test_batch_distance_calculation(self):\n        \"\"\"Test that batch distance calculation is correct and efficient.\"\"\"\n        # TODO: Create query point and training matrix\n        # TODO: Calculate distances using vectorized operation\n        # TODO: Verify results match individual calculations\n        # TODO: Measure performance improvement over loops\n        pass\n```\n\n**test_integration.py - Integration Tests for Complete Workflows:**\n\n```python\nimport pytest\nimport numpy as np\nfrom knn.classifier import KNNClassifier\nfrom knn.evaluation import k_fold_cross_validate, grid_search_k\nfrom knn.data_types import DistanceMetric\n\nclass TestCompleteWorkflow:\n    \"\"\"Integration tests for complete KNN workflows.\"\"\"\n    \n    def test_train_predict_pipeline(self, iris_dataset):\n        \"\"\"Test complete training and prediction pipeline.\"\"\"\n        X, y = iris_dataset\n        \n        # TODO: Split data into train/test sets\n        # TODO: Create KNNClassifier with reasonable parameters\n        # TODO: Fit classifier on training data\n        # TODO: Make predictions on test data\n        # TODO: Verify predictions have correct format and reasonable accuracy\n        pass\n    \n    def test_cross_validation_integration(self, iris_dataset):\n        \"\"\"Test cross-validation with multiple K values.\"\"\"\n        X, y = iris_dataset\n        \n        # TODO: Define K values to test\n        # TODO: Run k_fold_cross_validate with multiple parameters\n        # TODO: Verify results have expected structure\n        # TODO: Check that results are reproducible with same seed\n        pass\n\nclass TestErrorHandling:\n    \"\"\"Integration tests for error handling across components.\"\"\"\n    \n    def test_dimension_mismatch_propagation(self, simple_2d_dataset):\n        \"\"\"Test that dimension mismatches are caught and reported clearly.\"\"\"\n        X_train, y_train = simple_2d_dataset\n        classifier = KNNClassifier(k=3)\n        classifier.fit(X_train, y_train)\n        \n        # TODO: Create query point with wrong number of dimensions\n        # TODO: Attempt prediction and verify appropriate error is raised\n        # TODO: Check error message is informative\n        pass\n```\n\n#### Milestone Checkpoint Scripts\n\n**validate_distances.py - Milestone 1 Mathematical Validation:**\n\n```python\nimport numpy as np\nfrom knn.distance_metrics import euclidean_distance, manhattan_distance, cosine_distance\n\ndef validate_euclidean_distances():\n    \"\"\"Validate Euclidean distance calculations against known examples.\"\"\"\n    test_cases = [\n        # (point1, point2, expected_distance, description)\n        ([0, 0], [3, 4], 5.0, \"3-4-5 right triangle\"),\n        ([1, 1], [1, 1], 0.0, \"identical points\"),\n        ([-1, -1], [1, 1], 2.828, \"negative to positive quadrant\"),\n        ([0], [5], 5.0, \"1D distance\"),\n    ]\n    \n    print(\"Validating Euclidean distance calculations...\")\n    for point1, point2, expected, description in test_cases:\n        p1 = np.array(point1, dtype=np.float64)\n        p2 = np.array(point2, dtype=np.float64)\n        \n        # TODO: Calculate actual distance\n        # TODO: Compare against expected within tolerance\n        # TODO: Print validation result\n        pass\n\ndef validate_performance_improvement():\n    \"\"\"Validate that vectorized operations provide performance improvement.\"\"\"\n    # TODO: Create large dataset for benchmarking\n    # TODO: Time naive loop-based distance calculation\n    # TODO: Time vectorized distance calculation\n    # TODO: Verify vectorized is significantly faster\n    # TODO: Print performance comparison\n    pass\n\nif __name__ == \"__main__\":\n    validate_euclidean_distances()\n    validate_performance_improvement()\n    print(\"✓ All distance calculations validated successfully!\")\n```\n\n**validate_accuracy.py - Milestone 2 Accuracy Validation:**\n\n```python\nfrom sklearn.datasets import load_iris, load_wine\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier as SklearnKNN\nfrom knn.classifier import KNNClassifier\nfrom knn.data_types import DistanceMetric\n\ndef validate_iris_accuracy():\n    \"\"\"Validate KNN accuracy on Iris dataset.\"\"\"\n    # Load and prepare data\n    iris = load_iris()\n    X_train, X_test, y_train, y_test = train_test_split(\n        iris.data, iris.target, test_size=0.3, random_state=42\n    )\n    \n    # TODO: Train custom KNN classifier\n    # TODO: Make predictions on test set\n    # TODO: Calculate accuracy\n    # TODO: Verify accuracy exceeds 90%\n    # TODO: Print detailed results\n    pass\n\ndef compare_with_sklearn():\n    \"\"\"Compare accuracy with sklearn KNeighborsClassifier.\"\"\"\n    # TODO: Load dataset and split\n    # TODO: Train both custom and sklearn classifiers with identical parameters\n    # TODO: Compare predictions and accuracy\n    # TODO: Verify results are within acceptable tolerance\n    # TODO: Print comparison results\n    pass\n\nif __name__ == \"__main__\":\n    validate_iris_accuracy()\n    compare_with_sklearn()\n    print(\"✓ All accuracy validations passed!\")\n```\n\n#### Debugging Support Tools\n\n**debug_helpers.py - Debugging Utilities:**\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom typing import List, Tuple\nfrom knn.data_types import FeatureMatrix, ClassLabel, PredictionResult\n\ndef plot_2d_classification_boundaries(\n    X_train: FeatureMatrix, \n    y_train: List[ClassLabel], \n    classifier, \n    resolution: int = 100\n):\n    \"\"\"Plot 2D decision boundaries for visual debugging.\"\"\"\n    if X_train.shape[1] != 2:\n        raise ValueError(\"Can only plot boundaries for 2D data\")\n    \n    # TODO: Create mesh grid covering data range\n    # TODO: Make predictions on grid points\n    # TODO: Plot colored decision regions\n    # TODO: Overlay training points\n    # TODO: Add legend and labels\n    pass\n\ndef analyze_prediction_confidence(\n    predictions_with_confidence: List[PredictionResult]\n) -> None:\n    \"\"\"Analyze prediction confidence distribution for debugging.\"\"\"\n    confidences = [pred.confidence for pred in predictions_with_confidence]\n    \n    # TODO: Calculate confidence statistics (mean, std, min, max)\n    # TODO: Plot confidence histogram\n    # TODO: Identify low-confidence predictions for investigation\n    # TODO: Print summary statistics\n    pass\n\ndef debug_distance_calculations(\n    query_point: np.ndarray,\n    training_points: FeatureMatrix,\n    k: int = 5\n) -> None:\n    \"\"\"Debug distance calculations by showing nearest neighbors.\"\"\"\n    # TODO: Calculate distances to all training points\n    # TODO: Find K nearest neighbors\n    # TODO: Print distances and neighbor information\n    # TODO: Create visualization if 2D data\n    pass\n```\n\nThis comprehensive testing strategy provides multiple layers of validation that ensure the KNN implementation is mathematically correct, algorithmically sound, and practically useful. The combination of unit tests, integration tests, and milestone checkpoints creates a thorough verification framework that builds confidence in the implementation's correctness and performance.\n\n\n## Debugging Guide\n\n> **Milestone(s):** Comprehensive debugging support for all milestones - distance calculation debugging (Milestone 1), classification debugging for voting and accuracy issues (Milestone 2), and performance debugging for optimization problems (Milestone 3)\n\n### Mental Model: The Detective Process\n\nThink of debugging a KNN implementation like being a detective investigating a crime scene. The \"crime\" is your algorithm producing wrong results or running too slowly. Just like a detective, you need to systematically examine evidence, form hypotheses about what went wrong, and test those hypotheses by gathering more specific evidence. The key insight is that bugs in machine learning systems often manifest as subtle degradations rather than complete failures - your classifier might get 70% accuracy instead of 90%, or take 10 seconds instead of 1 second. This makes debugging more challenging than traditional software where bugs typically cause immediate crashes or obviously wrong outputs.\n\nThe debugging process for KNN follows a natural hierarchy: first ensure your distance calculations are numerically correct (the foundation), then verify your neighbor finding logic produces the right neighbors in the right order (the mechanism), and finally confirm your classification voting produces sensible predictions (the outcome). Performance issues typically stem from algorithmic inefficiencies rather than implementation bugs, so they require a different investigative approach focused on profiling and optimization rather than correctness verification.\n\nThis section provides systematic approaches for identifying, diagnosing, and fixing the most common issues that arise when implementing KNN classifiers, organized by the component where symptoms typically manifest.\n\n### Distance Calculation Debugging\n\nDistance calculation forms the mathematical foundation of KNN, making bugs in this component particularly insidious because they propagate through all downstream operations. The challenge is that distance calculation bugs often don't cause crashes - instead they silently corrupt neighbor rankings, leading to poor classification accuracy that can be difficult to trace back to the root cause.\n\n#### Common Distance Calculation Issues\n\nThe most frequent distance calculation problems fall into several categories: numerical instability, dimensionality mismatches, and performance bottlenecks. Understanding these patterns helps you quickly identify the likely cause when debugging distance-related issues.\n\n**Numerical Instability Symptoms and Diagnosis**\n\n| Symptom | Likely Cause | Diagnostic Steps | Fix Strategy |\n|---------|-------------|------------------|--------------|\n| `NaN` distances in results | Square root of negative values in Euclidean calculation | Check intermediate squared differences for negative values | Use `safe_sqrt()` with absolute value before square root |\n| Infinite distances | Division by zero in cosine distance | Examine zero-magnitude vectors in dataset | Handle zero vectors with `EPSILON` addition to magnitude |\n| All distances are identical | Floating-point precision loss | Check if feature scales differ by orders of magnitude | Apply feature scaling before distance calculation |\n| Distances don't decrease with K | Numerical overflow in high dimensions | Profile maximum feature values and dimension count | Use double precision and feature normalization |\n| Inconsistent distance symmetry | Broadcasting errors in vectorized ops | Test `distance(a,b) == distance(b,a)` on sample points | Fix array shape handling in vectorized functions |\n\nThe most critical debugging technique for numerical issues is implementing comprehensive numerical stability checks at every stage of distance calculation. This means validating intermediate results, not just final outputs.\n\n> **Key Insight**: Numerical bugs in distance calculation are often dimension-dependent. A bug that doesn't manifest with 2D toy data may become severe with 100D real-world features. Always test distance functions across multiple dimensionalities during development.\n\n**Feature Scaling and Normalization Issues**\n\nFeature scaling problems are particularly common because they're not technically bugs - the code runs correctly but produces mathematically valid yet practically useless results. When features have vastly different scales (e.g., age in years vs income in dollars), distance metrics become dominated by high-scale features.\n\nThe diagnostic process involves examining feature distributions and testing distance sensitivity:\n\n1. Calculate feature-wise statistics (mean, standard deviation, min, max) across your training data\n2. Compute distances between identical points with one feature perturbed by a small amount\n3. Observe which features dominate the distance calculation\n4. Apply appropriate scaling (standardization, min-max normalization, or robust scaling) and repeat the analysis\n\n**Vectorization and Broadcasting Errors**\n\nNumPy broadcasting is powerful but error-prone. The most common broadcasting bugs occur when computing distances from one query point to all training points, or when computing pairwise distance matrices.\n\n> **Decision: Explicit Shape Validation vs Implicit Broadcasting**\n> - **Context**: NumPy broadcasting can silently produce wrong results when array shapes don't align as expected\n> - **Options Considered**: \n>   1. Rely on NumPy's broadcasting rules and handle exceptions\n>   2. Explicitly validate and reshape arrays before operations\n>   3. Use only explicit loops to avoid broadcasting entirely\n> - **Decision**: Explicit shape validation with broadcasting\n> - **Rationale**: Catches shape mismatches early with clear error messages, while still benefiting from vectorized performance\n> - **Consequences**: Slightly more verbose code but much easier debugging when shape issues occur\n\nThe shape validation approach involves checking array dimensions before every vectorized operation:\n\n| Array Operation | Expected Shapes | Validation Check | Error Message |\n|----------------|-----------------|------------------|---------------|\n| Point-to-point distance | `(n_features,)` and `(n_features,)` | `assert a.shape == b.shape` | \"Feature vectors must have identical dimensions\" |\n| Point-to-dataset distance | `(n_features,)` and `(n_samples, n_features)` | `assert query.shape[0] == data.shape[1]` | \"Query point dimension doesn't match training data\" |\n| Pairwise distance matrix | `(n1, n_features)` and `(n2, n_features)` | `assert X1.shape[1] == X2.shape[1]` | \"Feature dimensions must match for distance calculation\" |\n\n#### Distance Metric Specific Debugging\n\nEach distance metric has characteristic failure modes that require specialized debugging approaches.\n\n**Euclidean Distance Debugging**\n\nEuclidean distance bugs typically involve numerical overflow in high dimensions or precision loss with very small/large feature values. The debugging process follows these steps:\n\n1. Verify squared differences don't overflow by checking maximum possible feature differences\n2. Confirm square root input is never negative using intermediate value logging\n3. Test edge cases with zero vectors, identical vectors, and orthogonal vectors\n4. Validate that triangle inequality holds: `d(a,c) <= d(a,b) + d(b,c)`\n\n**Manhattan Distance Debugging**\n\nManhattan distance is numerically more stable but can have performance issues due to absolute value computation. Common bugs include:\n\n- Forgetting absolute value operation, leading to negative distances\n- Inefficient implementation that doesn't leverage vectorized absolute value functions\n- Incorrect axis specification in sum operations for multi-dimensional arrays\n\n**Cosine Distance Debugging**\n\nCosine similarity is the most error-prone distance metric due to division operations and the need to handle zero-magnitude vectors:\n\n| Error Condition | Detection Method | Recovery Strategy |\n|-----------------|------------------|-------------------|\n| Zero magnitude vector | Check `np.linalg.norm(vector) == 0` | Return maximum distance (1.0 for cosine distance) |\n| Nearly zero magnitude | Check `norm < EPSILON` | Add small constant to avoid division by tiny numbers |\n| Negative cosine similarity | Validate `dot_product / (norm1 * norm2)` range | Clamp result to [-1, 1] range |\n| NaN from 0/0 division | Check for simultaneous zero vectors | Define distance between zero vectors as 0 or 1 based on use case |\n\n#### Performance Debugging for Distance Calculation\n\nDistance calculation performance issues usually stem from inefficient vectorization or redundant computations. The debugging approach involves profiling to identify bottlenecks, then applying targeted optimizations.\n\n**Profiling Distance Computation**\n\nThe systematic approach to performance debugging involves measuring time spent in each distance calculation component:\n\n1. Profile individual distance function calls with small arrays\n2. Profile vectorized operations with realistic dataset sizes\n3. Identify memory allocation patterns that cause garbage collection overhead\n4. Measure cache efficiency for different array access patterns\n\nCommon performance anti-patterns include:\n\n- Computing the same distances multiple times instead of caching results\n- Using Python loops instead of vectorized NumPy operations\n- Creating unnecessary intermediate arrays that trigger memory allocation\n- Inefficient array indexing patterns that don't leverage CPU cache locality\n\n> **Critical Performance Insight**: In high-dimensional spaces, distance calculation becomes increasingly expensive due to the curse of dimensionality. However, the real performance killer is usually algorithmic inefficiency (O(n²) when O(n log n) is possible) rather than constant factor improvements in distance calculation itself.\n\n### Classification Debugging\n\nClassification debugging focuses on the voting mechanisms that convert neighbor information into final predictions. Unlike distance calculation bugs that affect all predictions uniformly, classification bugs often manifest as systematic biases toward certain classes or inconsistent behavior with different K values.\n\n#### Voting Algorithm Issues\n\nThe core challenge in debugging voting algorithms is that they involve discrete logic (which neighbors get selected) combined with tie-breaking heuristics. This creates complex state spaces where bugs can hide.\n\n**Majority Voting Debugging**\n\n| Problem Symptom | Root Cause Analysis | Debugging Steps | Solution Approach |\n|-----------------|-------------------|-----------------|-------------------|\n| Always predicts same class | K too large, always includes majority class | Test with small K values, examine class distribution | Reduce K or use stratified sampling |\n| Predictions change dramatically with small K changes | Dataset has noise or overlapping classes | Visualize decision boundaries, test with clean synthetic data | Use larger K or weighted voting |\n| Ties resolved inconsistently | Non-deterministic tie-breaking | Test same prediction multiple times, check for randomness | Implement deterministic tie-breaking (nearest neighbor) |\n| Confidence scores don't match intuition | Confidence calculation doesn't reflect neighbor agreement | Compare confidence with neighbor class distributions | Revise confidence formula to measure neighbor consensus |\n\nThe debugging process for majority voting involves creating controlled test cases where you know the expected behavior:\n\n1. Create a simple 2D dataset where you can visualize the decision boundaries\n2. Test edge cases: exactly tied votes, unanimous votes, single neighbor cases\n3. Verify that changing the order of training data doesn't affect predictions\n4. Confirm that confidence scores correlate with prediction certainty\n\n**Weighted Voting Debugging**\n\nWeighted voting introduces additional complexity because the weights depend on distances, creating opportunities for both numerical and logical errors.\n\nThe weight calculation process requires careful validation:\n\n1. Verify that closer neighbors receive higher weights by testing with known distance relationships\n2. Check that weight normalization produces a valid probability distribution (weights sum to 1)\n3. Ensure that infinite weights (zero distances) are handled gracefully\n4. Test behavior when all neighbors have identical distances (should fall back to majority voting)\n\n> **Decision: Linear vs Inverse Distance Weighting**\n> - **Context**: Need to convert distances into voting weights, with closer neighbors having more influence\n> - **Options Considered**:\n>   1. Linear weighting: `weight = max_distance - distance`\n>   2. Inverse weighting: `weight = 1 / (distance + epsilon)`\n>   3. Gaussian weighting: `weight = exp(-distance^2 / (2 * sigma^2))`\n> - **Decision**: Inverse distance weighting\n> - **Rationale**: Provides stronger differentiation between close and far neighbors, mathematically well-founded, handles zero distances gracefully with epsilon\n> - **Consequences**: More sensitive to epsilon parameter choice, requires numerical stability handling\n\n#### Class Imbalance and Bias Issues\n\nClass imbalance creates systematic biases in KNN that are often misdiagnosed as implementation bugs. The issue is that in imbalanced datasets, the majority class naturally appears more frequently in neighborhood sets, leading to prediction bias.\n\n**Detecting Class Imbalance Effects**\n\n| Diagnostic Metric | Calculation | Interpretation | Action Required |\n|------------------|-------------|----------------|----------------|\n| Per-class recall | True positives / (True positives + False negatives) | How well each class is detected individually | Low recall for minority classes indicates imbalance bias |\n| Precision-recall curves | Plot precision vs recall at different decision thresholds | Shows trade-off between precision and recall | Steep drops indicate class imbalance problems |\n| Confusion matrix heatmap | Visual representation of prediction vs actual classes | Reveals systematic misclassification patterns | Off-diagonal patterns show which classes are confused |\n| Baseline accuracy comparison | Compare against \"always predict majority class\" baseline | Measures actual learning beyond naive strategy | Small improvement over baseline suggests bias issues |\n\nThe systematic approach to diagnosing class imbalance involves:\n\n1. Calculate class frequency distribution in training data\n2. Examine neighborhood class distributions for different K values\n3. Test prediction accuracy separately for each class\n4. Compare performance metrics across balanced and imbalanced test sets\n\n#### Hyperparameter Sensitivity Analysis\n\nClassification performance in KNN is highly sensitive to the K parameter, making hyperparameter debugging crucial for achieving good results. However, sensitivity to K can also reveal underlying data quality or implementation issues.\n\n**K Selection Debugging**\n\nThe relationship between K and performance should follow predictable patterns. Deviations from expected behavior often indicate bugs:\n\n- Very small K (1-3): High variance, sensitive to noise, but should achieve good performance on clean datasets\n- Medium K (5-15): Should provide balanced bias-variance trade-off for most datasets\n- Large K (>20): Should show stable but potentially biased predictions, approaching the dataset's base rate\n\n> **Key Debugging Insight**: If performance doesn't improve with ANY value of K, the problem is likely in distance calculation or data preprocessing, not in the classification logic. If performance is good for some K values but terrible for others, focus on tie-breaking and voting implementation.\n\nThe K sensitivity analysis process:\n\n1. Plot accuracy vs K for a range from 1 to min(50, n_samples/5)\n2. Identify optimal K and examine the shape of the performance curve\n3. Test the same K values with different random seeds to measure stability\n4. Compare K sensitivity across different train/test splits\n\n#### Confidence Scoring Validation\n\nConfidence scores in KNN should reflect the certainty of predictions based on neighbor agreement. Bugs in confidence calculation can make the classifier appear less reliable than it actually is.\n\n**Confidence Calibration Testing**\n\n| Confidence Range | Expected Accuracy | Validation Method | Common Issues |\n|-----------------|------------------|------------------|---------------|\n| 0.9-1.0 (High) | Should be >90% accurate | Bin predictions by confidence, measure actual accuracy | Overconfident due to unanimous but incorrect neighbors |\n| 0.7-0.9 (Medium) | Should be 70-90% accurate | Compare prediction accuracy within this confidence band | Poor calibration indicates flawed confidence formula |\n| 0.5-0.7 (Low) | Should be 50-70% accurate | May indicate tie-breaking situations | Many ties suggest K is too large or classes overlap |\n| <0.5 (Very Low) | Should rarely occur in binary classification | Investigate what causes very low confidence | Possible bug in confidence calculation |\n\n### Performance Debugging\n\nPerformance debugging in KNN requires understanding that the algorithm has different computational bottlenecks depending on dataset size, dimensionality, and implementation choices. Unlike correctness bugs that affect result quality, performance issues affect scalability and user experience.\n\n#### Computational Complexity Analysis\n\nKNN has well-understood theoretical complexity, making it possible to identify when performance deviates from expected bounds. The naive implementation has O(nd) distance calculation per query, where n is training set size and d is feature dimensionality, plus O(n log k) for finding the k smallest distances.\n\n**Performance Profiling Methodology**\n\nThe systematic approach to performance debugging involves:\n\n1. **Micro-benchmarks**: Test individual components (distance calculation, sorting, voting) in isolation\n2. **Scaling analysis**: Measure how runtime scales with n (dataset size) and d (dimensionality)\n3. **Memory profiling**: Track memory allocation patterns and garbage collection overhead\n4. **Cache analysis**: Measure cache hit rates and memory access patterns\n\n| Performance Issue | Symptom | Measurement Method | Expected Behavior |\n|-------------------|---------|-------------------|------------------|\n| Distance calculation bottleneck | Linear scaling worse than O(nd) | Profile distance computation time vs dataset size | Should scale linearly with both n and d |\n| Memory allocation overhead | Unexpected memory usage spikes | Monitor heap allocation during queries | Should use O(nd) memory for distance array |\n| Poor cache locality | Slower than expected despite good algorithmic complexity | Measure cache miss rates | Sequential array access should have high cache hit rate |\n| Python loop overhead | Much slower than vectorized baseline | Compare pure Python vs NumPy implementations | NumPy should be 10-100x faster for numerical operations |\n\n#### Vectorization Optimization\n\nThe most common performance issue in KNN implementations is insufficient vectorization. Python loops are orders of magnitude slower than NumPy's C-implemented vectorized operations.\n\n**Identifying Vectorization Opportunities**\n\nThe process of optimizing vectorization involves systematically replacing Python loops with NumPy operations:\n\n1. **Distance computation**: Replace point-by-point loops with broadcasting operations\n2. **Neighbor finding**: Use `np.argpartition` instead of full sorting for finding k smallest elements\n3. **Voting aggregation**: Use `np.bincount` for efficient vote counting instead of dictionary-based approaches\n\n> **Performance Decision: Full Distance Matrix vs On-Demand Calculation**\n> - **Context**: Need to balance memory usage with computation speed for distance calculations\n> - **Options Considered**:\n>   1. Precompute full distance matrix: O(n²) memory, O(1) lookup\n>   2. Compute distances on-demand: O(1) memory, O(nd) per query\n>   3. Hybrid approach: Cache recent queries, compute new ones as needed\n> - **Decision**: On-demand calculation with vectorized operations\n> - **Rationale**: Memory usage scales quadratically with dataset size, making precomputation infeasible for large datasets. Vectorized on-demand calculation achieves good performance while maintaining linear memory scaling\n> - **Consequences**: Repeated queries don't benefit from caching, but system can handle arbitrarily large training sets\n\n#### Memory Usage Optimization\n\nMemory usage in KNN can become problematic with large datasets, particularly when storing distance matrices or maintaining neighbor lists. The debugging approach focuses on identifying memory allocation patterns and optimizing data structures.\n\n**Memory Profiling Techniques**\n\n| Memory Issue | Detection Method | Optimization Strategy | Trade-offs |\n|--------------|------------------|----------------------|------------|\n| Excessive distance matrix storage | Monitor memory usage vs dataset size | Use streaming distance calculation | Higher computational cost per query |\n| Redundant array copies | Profile memory allocations during operations | Use in-place operations and array views | More complex code, potential for bugs |\n| Poor garbage collection | Monitor GC frequency and pause times | Reuse arrays, avoid intermediate allocations | Requires careful memory management |\n| Memory fragmentation | Measure actual vs requested memory usage | Use memory pools for fixed-size arrays | Platform-specific optimization |\n\n#### Algorithm-Level Optimizations\n\nBeyond implementation optimizations, KNN performance can be improved through algorithmic enhancements that change the computational complexity.\n\n**Spatial Data Structures**\n\nThe most significant algorithmic optimization is using spatial data structures to avoid exhaustive distance calculation:\n\n1. **KD-trees**: Effective for low-dimensional data (d < 10), can reduce neighbor search to O(log n)\n2. **Ball trees**: Better for higher dimensions, maintains O(log n) search time\n3. **LSH (Locality-Sensitive Hashing)**: Approximate nearest neighbors with sub-linear query time\n4. **Approximate methods**: Trade accuracy for speed using sampling or early termination\n\n> **Key Performance Insight**: The \"curse of dimensionality\" means that exact nearest neighbor search becomes increasingly expensive as feature dimensionality grows. For high-dimensional data (d > 20), approximate methods often provide better practical performance than exact algorithms.\n\n**Parallel Processing Opportunities**\n\nKNN has natural parallelization opportunities that can significantly improve performance:\n\n- **Query parallelization**: Different query points can be processed independently\n- **Distance calculation parallelization**: Vectorized operations can leverage SIMD instructions\n- **Cross-validation parallelization**: Different folds can be evaluated in parallel\n\nThe debugging process for parallel implementations involves:\n\n1. Measure single-threaded baseline performance\n2. Test scaling with different numbers of worker threads\n3. Profile synchronization overhead and load balancing\n4. Verify that parallel results match single-threaded results exactly\n\n### Implementation Guidance\n\nThis section provides practical tools and code structures for debugging KNN implementations effectively.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Profiling | `time.time()` and manual timing | `cProfile` with `snakeviz` visualization |\n| Memory Monitoring | `sys.getsizeof()` for basic measurements | `memory_profiler` with line-by-line analysis |\n| Numerical Debugging | Print statements and assertions | `numpy.testing` for robust array comparisons |\n| Visualization | `matplotlib` scatter plots | `seaborn` statistical plots with confidence intervals |\n| Performance Testing | Simple timer loops | `pytest-benchmark` for statistical timing |\n\n#### Debugging Infrastructure Code\n\n```python\nimport numpy as np\nimport time\nimport warnings\nfrom typing import Dict, List, Tuple, Any\nimport matplotlib.pyplot as plt\nfrom collections import defaultdict\n\nclass KNNDebugger:\n    \"\"\"Comprehensive debugging utilities for KNN implementation.\"\"\"\n    \n    def __init__(self, knn_classifier):\n        self.classifier = knn_classifier\n        self.debug_history = []\n        self.performance_metrics = defaultdict(list)\n    \n    def validate_numerical_stability(self, X: np.ndarray, y: List[str]) -> Dict[str, Any]:\n        \"\"\"Comprehensive numerical validation of KNN components.\"\"\"\n        # TODO 1: Check for NaN/inf values in feature matrix X\n        # TODO 2: Validate that all distance calculations return finite values\n        # TODO 3: Test distance symmetry: d(a,b) == d(b,a) for sample points\n        # TODO 4: Verify triangle inequality for distance metric\n        # TODO 5: Check that voting weights are properly normalized\n        # Hint: Use np.isfinite() to check for numerical issues\n        pass\n    \n    def diagnose_distance_calculation(self, sample_points: np.ndarray) -> Dict[str, Any]:\n        \"\"\"Diagnose distance calculation issues with test points.\"\"\"\n        # TODO 1: Test distance calculation with identical points (should be 0)\n        # TODO 2: Test with orthogonal vectors for Euclidean distance\n        # TODO 3: Measure distance calculation time scaling with dimensionality\n        # TODO 4: Check for consistent results across multiple runs\n        # TODO 5: Validate vectorized vs loop-based implementations match\n        pass\n    \n    def analyze_classification_bias(self, X_test: np.ndarray, y_test: List[str]) -> Dict[str, Any]:\n        \"\"\"Analyze classification for systematic biases.\"\"\"\n        # TODO 1: Calculate per-class accuracy and identify biased classes\n        # TODO 2: Measure prediction consistency with different random seeds\n        # TODO 3: Test sensitivity to K parameter across range of values\n        # TODO 4: Analyze neighbor class distributions for each prediction\n        # TODO 5: Check for correlation between confidence scores and accuracy\n        pass\n    \n    def profile_performance(self, X_test: np.ndarray, iterations: int = 100) -> Dict[str, float]:\n        \"\"\"Profile performance of each KNN component.\"\"\"\n        # TODO 1: Time distance calculation phase separately\n        # TODO 2: Time neighbor finding phase separately  \n        # TODO 3: Time voting/classification phase separately\n        # TODO 4: Measure memory usage during each phase\n        # TODO 5: Calculate queries per second for different dataset sizes\n        pass\n\nclass DistanceCalculationValidator:\n    \"\"\"Specialized validator for distance calculation correctness.\"\"\"\n    \n    @staticmethod\n    def test_distance_properties(distance_func, test_points: np.ndarray) -> bool:\n        \"\"\"Test mathematical properties of distance function.\"\"\"\n        # TODO 1: Test non-negativity: d(a,b) >= 0\n        # TODO 2: Test identity: d(a,a) == 0  \n        # TODO 3: Test symmetry: d(a,b) == d(b,a)\n        # TODO 4: Test triangle inequality: d(a,c) <= d(a,b) + d(b,c)\n        # TODO 5: Test that different points have d(a,b) > 0\n        pass\n    \n    @staticmethod\n    def benchmark_distance_scaling(distance_func, max_dimension: int = 100) -> Dict[int, float]:\n        \"\"\"Benchmark how distance calculation scales with dimensionality.\"\"\"\n        # TODO 1: Generate test data for dimensions 2, 5, 10, 20, 50, 100\n        # TODO 2: Time distance calculation for each dimensionality\n        # TODO 3: Measure memory usage scaling\n        # TODO 4: Check for numerical precision issues at high dimensions\n        # TODO 5: Return timing results for analysis\n        pass\n\nclass ClassificationDiagnostic:\n    \"\"\"Tools for diagnosing classification accuracy issues.\"\"\"\n    \n    def __init__(self, classifier):\n        self.classifier = classifier\n    \n    def k_sensitivity_analysis(self, X_train: np.ndarray, y_train: List[str], \n                             X_test: np.ndarray, y_test: List[str]) -> Dict[int, Dict[str, float]]:\n        \"\"\"Analyze how performance varies with K parameter.\"\"\"\n        # TODO 1: Test K values from 1 to min(50, len(X_train)//5)\n        # TODO 2: For each K, measure accuracy, precision, recall, F1\n        # TODO 3: Identify optimal K and performance plateau regions\n        # TODO 4: Check for unstable regions where small K changes cause large accuracy changes\n        # TODO 5: Return comprehensive results for plotting and analysis\n        pass\n    \n    def analyze_prediction_confidence(self, X_test: np.ndarray, y_test: List[str]) -> Dict[str, Any]:\n        \"\"\"Analyze relationship between confidence scores and accuracy.\"\"\"\n        # TODO 1: Bin predictions by confidence score (e.g., 0.9-1.0, 0.8-0.9, etc.)\n        # TODO 2: Calculate actual accuracy within each confidence bin\n        # TODO 3: Identify overconfident and underconfident regions\n        # TODO 4: Measure confidence calibration using reliability diagrams\n        # TODO 5: Suggest confidence threshold for different precision requirements\n        pass\n\nclass PerformanceProfiler:\n    \"\"\"Advanced performance profiling for KNN implementation.\"\"\"\n    \n    def __init__(self):\n        self.timing_history = defaultdict(list)\n        self.memory_history = defaultdict(list)\n    \n    def profile_scaling_behavior(self, classifier, dataset_sizes: List[int]) -> Dict[str, List[float]]:\n        \"\"\"Profile how performance scales with dataset size.\"\"\"\n        # TODO 1: Generate synthetic datasets of different sizes\n        # TODO 2: Measure training time (data loading) for each size\n        # TODO 3: Measure prediction time per query for each size\n        # TODO 4: Measure memory usage scaling\n        # TODO 5: Fit scaling curves and identify complexity bottlenecks\n        pass\n    \n    def identify_bottlenecks(self, classifier, X_test: np.ndarray) -> Dict[str, float]:\n        \"\"\"Identify which component is the performance bottleneck.\"\"\"\n        # TODO 1: Profile each component (distance, neighbor finding, voting) separately\n        # TODO 2: Measure what percentage of total time each component uses\n        # TODO 3: Identify memory allocation hotspots\n        # TODO 4: Check for inefficient array operations or Python loops\n        # TODO 5: Provide recommendations for optimization priorities\n        pass\n\n# Debugging utility functions\ndef safe_distance_calculation(point1: np.ndarray, point2: np.ndarray, \n                            metric: str = 'euclidean', epsilon: float = 1e-10) -> float:\n    \"\"\"Distance calculation with comprehensive error checking.\"\"\"\n    # TODO 1: Validate input arrays have same shape\n    # TODO 2: Check for NaN/inf values in inputs\n    # TODO 3: Handle numerical edge cases (zero vectors for cosine)\n    # TODO 4: Apply appropriate epsilon for numerical stability\n    # TODO 5: Validate output is finite and non-negative\n    pass\n\ndef diagnose_voting_issues(neighbor_labels: List[str], neighbor_distances: np.ndarray,\n                          prediction: str, confidence: float) -> Dict[str, Any]:\n    \"\"\"Diagnose potential issues in voting logic.\"\"\"\n    # TODO 1: Check for ties in voting and how they were resolved\n    # TODO 2: Validate that confidence score matches neighbor agreement\n    # TODO 3: Check for unusual distance distributions (all same, extreme outliers)\n    # TODO 4: Verify voting weights sum to 1.0 if using weighted voting\n    # TODO 5: Return diagnostic information for debugging\n    pass\n```\n\n#### File Structure for Debugging\n\n```\nproject-root/\n  knn/\n    core/\n      distance.py          ← distance calculation with validation\n      neighbors.py         ← neighbor finding with edge case handling\n      classifier.py        ← classification with confidence scoring\n    debug/\n      validators.py        ← numerical and correctness validators\n      profilers.py         ← performance profiling tools\n      diagnostics.py       ← classification diagnostic tools\n    tests/\n      test_distance_debug.py    ← unit tests for distance debugging\n      test_classification_debug.py ← unit tests for classification debugging\n      test_performance.py       ← performance regression tests\n  examples/\n    debug_walkthrough.py   ← complete debugging example\n    performance_analysis.py ← performance optimization example\n```\n\n#### Milestone Checkpoints\n\n**Milestone 1 Checkpoint: Distance Calculation**\nAfter implementing distance calculations, run these validation steps:\n\n```bash\npython -m pytest tests/test_distance_debug.py -v\npython examples/debug_walkthrough.py --component distance\n```\n\nExpected behavior:\n- All distance property tests pass (non-negativity, symmetry, triangle inequality)\n- Distance calculations return identical results across multiple runs\n- Performance scales linearly with dataset size and dimensionality\n- No NaN or infinite values in distance outputs\n\nWarning signs:\n- Distances are all identical (suggests scaling issues)\n- Distance(a,a) != 0 (suggests numerical precision problems)\n- Huge performance variation across runs (suggests memory allocation issues)\n\n**Milestone 2 Checkpoint: Classification**\nAfter implementing neighbor finding and voting:\n\n```bash\npython -m pytest tests/test_classification_debug.py -v\npython examples/debug_walkthrough.py --component classification\n```\n\nExpected behavior:\n- Classification accuracy improves with optimal K selection\n- Confidence scores correlate with prediction accuracy\n- Voting results are deterministic for identical inputs\n- Performance degrades gracefully with poor hyperparameters\n\nWarning signs:\n- Accuracy doesn't improve with any K value (suggests distance calculation bugs)\n- All predictions have identical confidence (suggests confidence calculation bugs)\n- Results vary between identical runs (suggests non-deterministic behavior)\n\n**Milestone 3 Checkpoint: Performance Optimization**\nAfter implementing optimizations:\n\n```bash\npython examples/performance_analysis.py --benchmark\npython -m pytest tests/test_performance.py\n```\n\nExpected behavior:\n- Vectorized operations are 10-100x faster than Python loops\n- Memory usage scales linearly with dataset size\n- Query time scales predictably with dataset size and dimensionality\n- Cross-validation completes in reasonable time\n\nWarning signs:\n- Performance doesn't improve with vectorization (suggests implementation issues)\n- Memory usage grows quadratically (suggests distance matrix storage)\n- Extreme sensitivity to dataset size (suggests algorithmic inefficiency)\n\n#### Language-Specific Debugging Tips\n\n**NumPy Debugging**\n- Use `np.testing.assert_array_almost_equal()` for robust floating-point comparisons\n- Set `np.seterr(all='raise')` to catch numerical errors early during development\n- Use `np.set_printoptions(threshold=20)` to avoid overwhelming debug output\n- Profile with `%timeit` in Jupyter notebooks for quick performance checks\n\n**Python Performance**\n- Use `cProfile` and `snakeviz` for detailed performance profiling: `python -m cProfile -o profile.stats your_script.py`\n- Monitor memory with `memory_profiler`: `@profile` decorator on functions\n- Use `dis.dis()` to examine bytecode when debugging performance issues\n- Set `PYTHONHASHSEED=0` for reproducible results when debugging non-deterministic behavior\n\n**Common Debugging Patterns**\n- Add `assert` statements liberally during development to catch edge cases early\n- Use `warnings.warn()` for potential issues that aren't errors\n- Implement comprehensive logging with different levels (DEBUG, INFO, WARNING, ERROR)\n- Create reproducible test cases by setting random seeds consistently\n\n\n## Future Extensions\n\n> **Milestone(s):** Post-implementation enhancements that extend beyond all three core milestones - performance optimizations for distance calculation and neighbor finding, algorithmic extensions for regression and ensemble methods, and feature extensions for custom metrics and online learning\n\n### Mental Model: The Evolutionary Path\n\nThink of the current KNN implementation as a solid foundation house that we've built according to proven architectural principles. The foundation is strong - our distance calculation, neighbor finding, and classification components work correctly and handle edge cases gracefully. Now we're ready to add extensions like adding wings to a house, upgrading the electrical system, or installing smart home features. Each extension builds upon the existing foundation without requiring us to tear down what we've already built.\n\nThe key insight is that good software architecture enables evolution. Because we've separated concerns into distinct components with clean interfaces, we can enhance individual components independently. We can swap out the linear neighbor search for a KD-tree without touching the classification logic. We can add new distance metrics without modifying the neighbor finding algorithms. We can extend from classification to regression by adding new voting strategies while reusing all the distance and neighbor finding infrastructure.\n\nThis evolutionary approach mirrors how machine learning systems develop in practice. You start with a working baseline, measure its performance and limitations, then systematically address the most important bottlenecks. Some extensions focus on computational efficiency (performance extensions), others expand the algorithm's capabilities (algorithm extensions), and still others add flexibility and customization options (feature extensions).\n\n### Performance Extensions: KD-trees, LSH, and Other Acceleration Structures\n\nThe most significant limitation of our current implementation is computational performance. Linear neighbor search requires O(n) distance calculations per query, making it impractical for large datasets. Performance extensions address this bottleneck by introducing data structures and algorithms that reduce the computational complexity of neighbor finding.\n\n#### Mental Model: Spatial Indexing as a Library System\n\nThink of linear search as finding a book by examining every single book in a library one by one. This works for small personal libraries but becomes impossible for university libraries with millions of books. Libraries solve this with organizational systems - books are grouped by subject, then by author, then alphabetically. You can quickly narrow down to the right section, then the right shelf, then scan a small number of books.\n\nSpatial indexing works similarly for high-dimensional feature vectors. Instead of checking every training sample, we organize them into a tree structure where each level divides the space along one dimension. To find neighbors, we traverse the tree to quickly identify promising regions, then only compute distances within those regions. The key insight is trading some preprocessing time and memory for dramatically faster query performance.\n\n#### KD-Tree Spatial Indexing\n\n**KD-trees** (K-dimensional trees) represent the most fundamental spatial acceleration structure for exact nearest neighbor search. A KD-tree recursively partitions the feature space by alternating between dimensions, creating a binary tree where each internal node represents a splitting hyperplane and each leaf contains a small number of training samples.\n\nThe tree construction algorithm works by selecting a dimension (typically cycling through dimensions or choosing the one with maximum variance), finding the median value along that dimension, and splitting the training samples into left and right subtrees. This process continues recursively until each leaf contains fewer than some threshold number of samples (typically 10-50).\n\nQuery processing exploits the spatial organization by traversing the tree from root to leaf, following the path determined by the query point's coordinates. At each internal node, we compare the query point's value in the splitting dimension to the split value and recurse into the appropriate subtree. Once we reach a leaf, we compute exact distances to all samples in that leaf and maintain a priority queue of the K best candidates found so far.\n\nThe critical optimization comes from **backtracking** with pruning. After exploring the initial path to a leaf, we backtrack up the tree and check whether other subtrees might contain better neighbors. However, we can prune entire subtrees if the distance from the query point to the splitting hyperplane exceeds the distance to the K-th best candidate found so far. This pruning dramatically reduces the number of distance calculations required.\n\n> **Performance Insight**: KD-trees provide logarithmic query time O(log n) for low-dimensional data but degrade to linear performance O(n) in high dimensions due to the curse of dimensionality. The rule of thumb is that KD-trees work well for fewer than 10-20 dimensions, making them ideal for geometric data but less effective for typical machine learning feature vectors with hundreds of dimensions.\n\n#### Architecture Decision: KD-Tree Integration Strategy\n\n> **Decision: Component-Based KD-Tree Integration**\n> - **Context**: Need to add KD-tree acceleration without breaking existing neighbor finding interface or requiring changes to classification components\n> - **Options Considered**: \n>   1. Replace linear search entirely with KD-tree implementation\n>   2. Add KD-tree as alternative neighbor finder with same interface\n>   3. Hybrid approach that automatically selects linear vs KD-tree based on data characteristics\n> - **Decision**: Option 2 - Add KD-tree as alternative implementation of neighbor finder interface\n> - **Rationale**: Preserves existing code compatibility, allows performance comparison between methods, and maintains flexibility for different use cases. Some scenarios (very small datasets, high-dimensional data) still benefit from linear search.\n> - **Consequences**: Requires interface abstraction for neighbor finding, adds complexity of maintaining two implementations, but provides clear performance improvement path for suitable datasets.\n\nThe integration approach preserves our existing `NeighborFinder` interface while adding a new `KDTreeNeighborFinder` implementation. The existing `LinearNeighborFinder` remains available for comparison and fallback scenarios. A factory method can automatically select the appropriate implementation based on dataset characteristics.\n\n| Component | Interface Method | KD-Tree Implementation | Linear Implementation |\n|-----------|------------------|----------------------|----------------------|\n| NeighborFinder | `find_k_neighbors()` | Tree traversal with backtracking | Compute all distances, select top K |\n| NeighborFinder | `fit()` | Build KD-tree from training data | Store training matrix directly |\n| NeighborFinder | `find_neighbors_batch()` | Parallel tree queries | Vectorized distance computation |\n\n#### Approximate Nearest Neighbors with LSH\n\n**Locality-Sensitive Hashing (LSH)** addresses the curse of dimensionality by trading accuracy for speed. Instead of finding the exact nearest neighbors, LSH finds approximate nearest neighbors with high probability while achieving sub-linear query time even in high dimensions.\n\nThe core insight behind LSH is using hash functions with the locality-sensitive property: similar items have high probability of hashing to the same bucket, while dissimilar items likely hash to different buckets. For Euclidean distance, we can use random projection LSH where each hash function projects the feature vector onto a random direction and quantizes the result.\n\nThe algorithm works by creating multiple hash tables, each using different random projections. During preprocessing, we hash each training sample into all tables and store it in the corresponding buckets. During query processing, we hash the query point using the same functions, retrieve all candidates from the matching buckets across all tables, and compute exact distances only to these candidates.\n\nThe trade-off parameters control the accuracy-speed balance. More hash tables increase the probability of finding true nearest neighbors but require more memory and query time. Wider hash buckets (coarser quantization) increase recall but also increase the number of candidates to check. The optimal parameters depend on the specific dataset and accuracy requirements.\n\n> **Trade-off Insight**: LSH provides sub-linear query time O(n^ρ) where ρ < 1 depends on the distance threshold, but may miss some true nearest neighbors. The missed neighbor rate typically ranges from 5-20% depending on parameter settings, making it suitable for applications that can tolerate approximate results in exchange for dramatic speedup.\n\n#### Ball Tree and Cover Tree Alternatives\n\n**Ball trees** provide an alternative spatial indexing approach that works better than KD-trees in high dimensions. Instead of splitting along coordinate axes, ball trees recursively partition data into hyperspheres (balls), choosing splits that minimize the volume of the resulting balls. This approach adapts better to the intrinsic dimensionality of the data rather than the ambient dimensionality.\n\n**Cover trees** offer theoretical guarantees for general metric spaces, not just Euclidean space. They maintain the covering tree property where each level covers all points within a certain radius, and the radius halves at each level. This provides O(log n) query time for datasets with bounded doubling dimension, which includes many real-world datasets despite high ambient dimensionality.\n\n| Index Structure | Best Use Case | Time Complexity | Space Complexity | Distance Metric |\n|-----------------|---------------|-----------------|------------------|-----------------|\n| KD-Tree | Low dimensions (< 20) | O(log n) | O(n) | Euclidean, Manhattan |\n| Ball Tree | Medium dimensions (20-100) | O(log n) | O(n) | Any metric |\n| Cover Tree | High dimensions with structure | O(log n) | O(n) | Any metric |\n| LSH | High dimensions, approximate OK | O(n^ρ) | O(n^(1+ρ)) | Specific metrics |\n\n#### Performance Extension Implementation Strategy\n\nThe key architectural principle for performance extensions is **progressive enhancement**. Start with the working linear implementation, add KD-tree support for low-dimensional cases, then layer on approximate methods for high-dimensional scenarios. Each extension should integrate cleanly with the existing neighbor finding interface.\n\nA performance-aware neighbor finder factory can automatically select the best implementation based on dataset characteristics:\n\n1. **Dimension analysis**: Count features and check for sparsity patterns\n2. **Size analysis**: Measure dataset size relative to query frequency  \n3. **Distance metric analysis**: Verify compatibility with spatial indexing\n4. **Performance profiling**: Benchmark different approaches on sample data\n\nThe factory creates an appropriate `NeighborFinder` implementation transparently, so classification and evaluation components continue working without modification. This approach allows incremental adoption of performance optimizations without disrupting working code.\n\n#### Common Performance Extension Pitfalls\n\n⚠️ **Pitfall: Premature KD-Tree Adoption**\nMany developers immediately implement KD-trees without checking dimensionality. In high-dimensional spaces (> 20 features), KD-trees often perform worse than linear search due to excessive backtracking. Always benchmark on your specific dataset before assuming KD-trees will help.\n\n⚠️ **Pitfall: Ignoring Memory Overhead**\nSpatial indexes require significant memory beyond the training data itself. KD-trees need tree nodes (typically 2-3x the data size), while LSH needs multiple hash tables. For memory-constrained environments, linear search might be the only viable option despite slower performance.\n\n⚠️ **Pitfall: Incorrect LSH Parameter Tuning**\nLSH requires careful parameter tuning for each dataset. Using default parameters often yields either poor recall (missing true neighbors) or poor performance (checking too many candidates). Implement parameter tuning procedures that optimize for your specific accuracy-speed requirements.\n\n⚠️ **Pitfall: Mixing Incompatible Distance Metrics**\nNot all spatial indexes support all distance metrics. KD-trees work well with Euclidean and Manhattan distance but not cosine similarity. Attempting to use incompatible combinations leads to incorrect results. Validate metric compatibility during neighbor finder construction.\n\n### Algorithm Extensions: Regression Support, Multi-Output Classification, and Ensemble Methods\n\nThe second category of extensions expands the fundamental capabilities of the KNN algorithm beyond simple classification. These extensions leverage the same distance calculation and neighbor finding infrastructure while implementing different aggregation and prediction strategies.\n\n#### Mental Model: From Voting to Averaging\n\nThink of the transition from classification to regression as moving from a democratic election to a town council budget meeting. In an election, neighbors vote for discrete candidates and the majority wins. In a budget meeting, neighbors propose numerical values and the final decision averages or weighs their proposals. The process of finding relevant neighbors (people whose opinions matter) remains the same, but the aggregation method changes to handle continuous values instead of discrete categories.\n\nThe key insight is that nearest neighbor algorithms are fundamentally about **similarity-based inference**. Whether we're predicting categories or numbers, the assumption remains that similar inputs should produce similar outputs. Only the aggregation function changes to match the output type.\n\n#### K-Nearest Neighbors Regression\n\n**KNN regression** replaces majority voting with numerical averaging of neighbor target values. Instead of predicting the most frequent class among neighbors, we predict the mean (or weighted mean) of neighbor regression targets. This natural extension handles any continuous prediction task while maintaining the same lazy learning characteristics as KNN classification.\n\nThe core algorithm remains nearly identical to classification:\n\n1. **Neighbor identification**: Use the same distance calculation and neighbor finding procedures to identify the K closest training samples to the query point\n2. **Target extraction**: Extract the continuous target values (instead of class labels) for the K neighbors  \n3. **Numerical aggregation**: Compute the mean, weighted mean, or other aggregation of neighbor target values\n4. **Confidence estimation**: Calculate prediction confidence based on variance among neighbor targets\n\nThe weighted averaging approach gives closer neighbors more influence on the prediction, similar to weighted voting in classification. The weight for each neighbor is typically the inverse of its distance (with small epsilon to avoid division by zero), though other weighting schemes like Gaussian kernels are also effective.\n\n> **Algorithmic Insight**: KNN regression naturally handles non-linear relationships and local patterns that would challenge linear regression. However, it provides no extrapolation capability - predictions for points outside the training data convex hull simply reflect the nearest boundary training samples.\n\n#### Architecture Decision: Unified Prediction Interface\n\n> **Decision: Generic Prediction Interface Supporting Multiple Output Types**\n> - **Context**: Need to support classification (discrete outputs), regression (continuous outputs), and multi-output scenarios without duplicating neighbor finding logic\n> - **Options Considered**:\n>   1. Separate KNNClassifier and KNNRegressor classes with duplicated infrastructure\n>   2. Single KNNPredictor class with output-type parameter controlling aggregation strategy\n>   3. Generic KNNPredictor with pluggable aggregation functions\n> - **Decision**: Option 3 - Generic predictor with strategy pattern for aggregation\n> - **Rationale**: Maximizes code reuse, allows custom aggregation functions, and supports future extensions like multi-output prediction. The strategy pattern cleanly separates neighbor finding (shared) from output aggregation (variable).\n> - **Consequences**: Requires more abstract interface design but enables maximum flexibility and extensibility for different prediction tasks.\n\nThe unified architecture uses an `AggregationStrategy` interface with implementations for different prediction types:\n\n| Aggregation Strategy | Input | Output | Use Case |\n|---------------------|--------|--------|----------|\n| MajorityVoteAggregator | List[ClassLabel] | ClassLabel | Single-label classification |\n| WeightedVoteAggregator | List[ClassLabel], DistanceArray | ClassLabel | Weighted classification |\n| MeanRegressionAggregator | List[float] | float | Continuous regression |\n| WeightedRegressionAggregator | List[float], DistanceArray | float | Weighted regression |\n| MultiLabelAggregator | List[Set[ClassLabel]] | Set[ClassLabel] | Multi-label classification |\n| MultiOutputAggregator | List[Vector] | Vector | Multi-output regression |\n\n#### Multi-Output and Multi-Label Prediction\n\n**Multi-output prediction** extends KNN to handle vector-valued outputs instead of scalar targets. Each training sample has a target vector rather than a single value, and the aggregation computes element-wise means across neighbor target vectors. This naturally handles scenarios like predicting multiple related quantities simultaneously (e.g., temperature and humidity based on location and time).\n\n**Multi-label classification** handles cases where each sample can belong to multiple classes simultaneously (e.g., image tagging where a photo might contain both \"cat\" and \"outdoor\"). The aggregation strategy counts how often each label appears among the K neighbors and applies a threshold to determine which labels to predict for the query point.\n\nThe multi-label threshold selection requires careful consideration. A simple approach uses a fixed threshold (e.g., predict labels that appear in > 50% of neighbors), but adaptive thresholds based on label frequency in the training set often work better. The threshold can also be tuned using cross-validation to optimize specific multi-label metrics like Hamming loss or F1 score.\n\n#### KNN Ensemble Methods\n\n**Ensemble methods** combine multiple KNN predictors to improve robustness and accuracy. The two main ensemble approaches are **bagging** (bootstrap aggregation) and **random subspace methods**.\n\nKNN bagging creates multiple KNN models trained on bootstrap samples of the training data. Each model votes on the final prediction, with the ensemble aggregating individual model outputs. This reduces variance and improves stability, especially for noisy datasets where individual predictions might vary significantly.\n\nRandom subspace methods train multiple KNN models on different subsets of features rather than different subsets of samples. Each model uses a randomly selected subset of dimensions, forcing the ensemble to consider different similarity measures. This approach particularly helps in high-dimensional spaces where not all features are equally informative for every prediction.\n\nThe ensemble aggregation strategy depends on the prediction type. Classification ensembles typically use majority voting among individual model predictions, while regression ensembles average the numerical predictions. Weighted ensemble methods give different models different influence based on their estimated reliability or past performance.\n\n| Ensemble Method | Training Strategy | Prediction Strategy | Benefits | Best Use Cases |\n|-----------------|------------------|-------------------|----------|----------------|\n| Bootstrap Bagging | Multiple bootstrap samples | Majority vote/averaging | Reduces variance | Noisy datasets |\n| Random Subspace | Random feature subsets | Majority vote/averaging | Handles irrelevant features | High-dimensional data |\n| Weighted Ensemble | Performance-based weights | Weighted vote/averaging | Adapts to model quality | Heterogeneous feature types |\n\n#### Confidence and Uncertainty Estimation\n\nAlgorithm extensions also improve confidence estimation beyond simple neighbor agreement. **Prediction intervals** for regression quantify the uncertainty in numerical predictions by analyzing the distribution of neighbor targets. Instead of reporting just the mean prediction, we can report confidence intervals based on the standard deviation of neighbor values.\n\n**Conformal prediction** provides distribution-free confidence intervals with theoretical coverage guarantees. The method works by analyzing the conformity scores (distances to neighbors) for training data to calibrate prediction intervals that contain the true target with specified probability.\n\nFor classification, **calibrated confidence scores** improve upon simple neighbor agreement by accounting for the base rate of each class in the local neighborhood. A prediction might have high neighbor agreement but low confidence if it predicts a rare class in a region where that class is extremely uncommon.\n\n#### Algorithm Extension Implementation Strategy\n\nThe key principle for algorithm extensions is **composition over inheritance**. Rather than creating separate class hierarchies for classification vs regression vs multi-output, we compose a generic predictor from reusable components: neighbor finder, aggregation strategy, and confidence estimator.\n\nThe implementation approach layers new capabilities on the existing foundation:\n\n1. **Preserve existing interfaces**: Classification functionality continues working exactly as before\n2. **Add strategy interfaces**: Define aggregation strategy interface with multiple implementations  \n3. **Extend data model**: Add support for vector targets and multi-label formats\n4. **Compose predictors**: Factory methods create appropriately configured predictors for different tasks\n\nThis approach allows gradual adoption of new capabilities without breaking existing classification code while sharing all the distance calculation, neighbor finding, and evaluation infrastructure across different prediction tasks.\n\n#### Common Algorithm Extension Pitfalls\n\n⚠️ **Pitfall: Inappropriate Aggregation for Target Distribution**\nSimple mean aggregation works poorly when neighbor targets have skewed or multi-modal distributions. For example, if neighbors have targets [1, 1, 2, 100], the mean prediction of 26 might be far from any actual neighbor value. Consider median aggregation or distribution-aware methods for robust predictions.\n\n⚠️ **Pitfall: Ignoring Output Scale Differences in Multi-Output**\nMulti-output prediction can be dominated by targets with large numerical ranges. If predicting both temperature (range 0-40°C) and pressure (range 900-1100 hPa), the pressure component will dominate distance calculations and aggregation. Always normalize or scale multiple outputs appropriately.\n\n⚠️ **Pitfall: Overconfident Multi-Label Predictions**\nMulti-label classification often predicts too many labels because each label is evaluated independently. The probability of having at least one false positive increases with the number of labels. Adjust thresholds or use more conservative confidence estimation for multi-label scenarios.\n\n⚠️ **Pitfall: Ensemble Overfitting**\nKNN ensembles can overfit if all individual models are too similar (e.g., using the same features and very similar bootstrap samples). Ensure sufficient diversity between ensemble members through different feature subsets, different K values, or different distance metrics.\n\n### Feature Extensions: Custom Distance Metrics, Feature Weighting, and Online Learning\n\nThe third category of extensions enhances the flexibility and adaptability of the KNN system through customizable similarity measures and adaptive learning capabilities. These extensions primarily focus on improving the core assumption that \"similar inputs produce similar outputs\" by allowing more sophisticated definitions of similarity.\n\n#### Mental Model: From Universal Metrics to Personalized Similarity\n\nThink of the evolution from standard distance metrics to custom similarity measures as moving from a one-size-fits-all measuring tape to a personalized fitting system. A standard measuring tape works for basic measurements, but a skilled tailor uses multiple specialized tools and techniques to capture the nuances that matter for a perfect fit. Similarly, while Euclidean distance works for basic similarity measurement, many real-world problems require specialized similarity measures that capture domain-specific knowledge about what makes two examples truly similar.\n\nThe key insight is that **distance metrics encode assumptions** about the problem structure. Euclidean distance assumes all features contribute equally and independently to similarity, but real problems often have features with different importance, complex interactions, or specialized semantics (like categorical features, temporal sequences, or hierarchical structures).\n\n#### Custom Distance Metric Framework\n\nA **custom distance metric framework** allows domain experts to encode specialized knowledge about similarity directly into the KNN algorithm. This goes beyond the standard Euclidean, Manhattan, and cosine metrics to support problem-specific similarity measures that capture the true structure of the data.\n\nThe framework must balance flexibility with performance. Custom metrics should integrate seamlessly with existing neighbor finding infrastructure while supporting vectorized operations for efficiency. The challenge is providing enough expressiveness for complex similarity measures without sacrificing the performance characteristics that make KNN practical for large datasets.\n\nKey design requirements for the custom metric framework include:\n\n1. **Interface compatibility**: Custom metrics must implement the same interface as standard metrics for seamless integration\n2. **Vectorization support**: Custom metrics should support batch operations on feature matrices, not just pairwise calculations  \n3. **Parameter management**: Many custom metrics have tunable parameters that need validation and optimization\n4. **Differentiability**: Some applications require gradient information for advanced optimization\n5. **Serialization support**: Custom metrics must be saveable and loadable for model persistence\n\nThe implementation uses a strategy pattern where each distance metric implements a common interface. Custom metrics can be pure Python functions (for flexibility), compiled functions (for performance), or even learned metrics (for adaptability).\n\n#### Feature Weighting and Learned Metrics\n\n**Feature weighting** addresses the common problem that not all features contribute equally to meaningful similarity. In many datasets, some features are highly predictive while others are noise or irrelevant. Standard distance metrics treat all features equally, potentially drowning out important signals with irrelevant variation.\n\nSimple feature weighting multiplies each feature difference by a weight before computing the overall distance. The challenge is determining appropriate weights. Manual weight setting requires domain expertise and extensive experimentation. Automatic weight learning uses the training data to optimize weights for classification accuracy.\n\n**Learned distance metrics** go beyond simple feature weighting to learn complex transformations that improve similarity measurement. The most common approaches are:\n\n1. **Mahalanobis distance learning**: Learn a full covariance matrix that captures feature correlations and scales\n2. **Linear metric learning**: Learn a linear transformation that maximizes separation between different classes  \n3. **Nonlinear metric learning**: Use neural networks to learn complex similarity functions\n4. **Local metric learning**: Learn different metrics for different regions of the feature space\n\nThe metric learning process requires labeled training data to optimize the distance function. The objective is typically to minimize distances between samples with the same label while maximizing distances between samples with different labels, subject to constraints that ensure the learned function satisfies metric properties.\n\n> **Learning Insight**: Learned distance metrics can dramatically improve KNN performance, often achieving 10-30% accuracy gains on high-dimensional datasets. However, they require careful regularization to avoid overfitting and may not generalize well to very different test distributions.\n\n#### Architecture Decision: Pluggable Distance Metric Architecture\n\n> **Decision: Strategy Pattern with Metric Registry for Custom Distance Functions**\n> - **Context**: Need to support standard metrics, custom user-defined metrics, and learned metrics without modifying core neighbor finding logic\n> - **Options Considered**:\n>   1. Hard-coded switch statement for metric selection with no custom support\n>   2. Function pointer approach allowing arbitrary distance functions\n>   3. Registry pattern with standardized metric interface and discovery mechanism\n> - **Decision**: Option 3 - Registry pattern with metric interface and automatic discovery\n> - **Rationale**: Provides type safety and validation, enables metric composition and parameterization, supports serialization for model persistence, and allows discovery of available metrics at runtime\n> - **Consequences**: More complex implementation but maximum extensibility and maintainability for evolving metric requirements\n\nThe metric registry approach allows runtime discovery and validation of available distance metrics:\n\n| Component | Responsibility | Interface Methods |\n|-----------|---------------|-------------------|\n| `DistanceMetricRegistry` | Manage available metrics | `register_metric()`, `get_metric()`, `list_metrics()` |\n| `DistanceMetric` | Abstract metric interface | `calculate()`, `batch_calculate()`, `get_parameters()` |\n| `StandardMetric` | Built-in metric implementations | Standard euclidean, manhattan, cosine implementations |\n| `CustomMetric` | User-defined metrics | Wraps user functions with validation and vectorization |\n| `LearnedMetric` | Trained similarity functions | Loads parameters, applies transformations |\n\n#### Categorical and Mixed-Type Feature Support\n\nReal-world datasets often contain **mixed feature types**: numerical, categorical, ordinal, and text features. Standard distance metrics designed for continuous numerical features don't handle categorical features appropriately. Computing Euclidean distance between \"red\", \"green\", and \"blue\" color values encoded as 1, 2, 3 makes no sense since the numerical encoding is arbitrary.\n\nA comprehensive distance framework must support appropriate similarity measures for each feature type and combine them coherently:\n\n1. **Numerical features**: Standard metrics like Euclidean, Manhattan, or scaled versions\n2. **Categorical features**: Hamming distance, Jaccard similarity, or category-specific similarity matrices\n3. **Ordinal features**: Distance based on rank differences rather than value differences  \n4. **Text features**: String edit distance, token overlap, or semantic similarity using embeddings\n5. **Structured features**: Specialized distances for graphs, sequences, or hierarchical data\n\nThe combination strategy typically uses weighted combination where each feature type contributes to the overall distance according to learned or specified weights. Some approaches learn to weight different feature types automatically based on their predictive value for the classification task.\n\n#### Online Learning and Adaptive KNN\n\n**Online learning** enables KNN models to adapt to new data without complete retraining. Traditional KNN is inherently online for adding new training samples (just add them to the training set), but adaptive approaches go further by adjusting distance metrics, feature weights, or neighbor selection strategies based on prediction feedback.\n\nKey online learning capabilities include:\n\n1. **Incremental training sample addition**: Efficiently add new training samples to existing spatial indexes\n2. **Concept drift detection**: Identify when the underlying data distribution has changed  \n3. **Adaptive metric updates**: Adjust distance function parameters based on recent prediction accuracy\n4. **Selective sample retention**: Remove outdated or redundant training samples to maintain performance\n5. **Dynamic K adjustment**: Adapt the number of neighbors based on local data density and prediction confidence\n\nThe **incremental index update** problem requires careful handling of spatial data structures. Adding samples to a KD-tree might require rebalancing subtrees to maintain optimal performance. LSH tables need to incorporate new samples into existing hash buckets. The trade-off is between update efficiency and query performance degradation.\n\n**Concept drift adaptation** monitors prediction accuracy over time to detect when the learned patterns become stale. When drift is detected, the system can retrain distance metrics, adjust feature weights, or selectively replace outdated training samples with recent examples that better represent the current distribution.\n\n#### Streaming KNN and Memory Management\n\n**Streaming KNN** handles continuous data streams where the full dataset doesn't fit in memory and samples arrive continuously. This requires sophisticated memory management strategies that maintain prediction accuracy while respecting memory constraints.\n\nCommon streaming strategies include:\n\n1. **Sliding window**: Maintain only the most recent N training samples, discarding older data\n2. **Reservoir sampling**: Probabilistically sample from the full stream to maintain a representative subset\n3. **Hierarchical clustering**: Group similar samples and represent clusters with prototypes to reduce memory usage\n4. **Importance-based retention**: Keep samples that are most important for decision boundaries\n\nThe streaming approach must balance several competing objectives: maintaining representative coverage of the feature space, preserving decision boundary information, adapting to concept drift, and respecting strict memory limits. The optimal strategy depends on the specific characteristics of the data stream and application requirements.\n\n#### Feature Extension Implementation Strategy\n\nFeature extensions require careful architectural planning to maintain compatibility with existing components while adding significant new capabilities. The key principles are:\n\n1. **Backward compatibility**: Existing classification code continues working without modification\n2. **Progressive disclosure**: Simple use cases remain simple, complex customization is possible but optional\n3. **Performance preservation**: Custom metrics shouldn't significantly degrade performance for standard use cases  \n4. **Extensibility**: New metric types and learning approaches can be added without core system changes\n\nThe implementation approach layers customization capabilities on the proven foundation:\n\n1. **Extend metric interface**: Add support for parameterized and learned metrics\n2. **Add feature type support**: Handle mixed-type datasets with appropriate similarity measures\n3. **Implement online learning**: Add incremental update capabilities to spatial indexes\n4. **Create streaming support**: Add memory management and sample selection strategies\n\n#### Common Feature Extension Pitfalls\n\n⚠️ **Pitfall: Inappropriate Distance Combinations for Mixed Types**\nSimply concatenating distances from different feature types often produces meaningless results because the scales and distributions differ dramatically. A categorical Hamming distance of 0.5 and a numerical Euclidean distance of 50 can't be combined directly. Always normalize or scale distance components appropriately before combination.\n\n⚠️ **Pitfall: Overfitting with Learned Metrics**\nMetric learning on small datasets often overfits, creating distance functions that work well on training data but generalize poorly. This is especially problematic for nonlinear metric learning with many parameters. Use appropriate regularization and validate on held-out data when learning custom distance functions.\n\n⚠️ **Pitfall: Ignoring Computational Cost of Custom Metrics**\nComplex custom distance functions can make KNN impractically slow. A custom metric that takes 100x longer than Euclidean distance transforms an already expensive O(n) neighbor search into a completely unusable algorithm. Profile custom metrics carefully and consider approximation strategies for expensive similarity functions.\n\n⚠️ **Pitfall: Memory Leaks in Online Learning**\nStreaming KNN implementations often develop memory leaks by failing to properly remove references to discarded training samples or by accumulating metadata that grows without bound. Implement explicit memory management and monitoring for long-running online learning systems.\n\n⚠️ **Pitfall: Concept Drift Overreaction**\nOnline adaptation systems can overreact to temporary prediction accuracy fluctuations, continuously adjusting parameters and creating instability. Implement smoothing and statistical significance tests before triggering adaptation mechanisms to avoid thrashing.\n\n### Implementation Guidance\n\nThis section provides concrete implementation strategies for extending the KNN system with performance optimizations, algorithmic enhancements, and feature customizations. The implementation approach emphasizes modularity and backward compatibility to enable incremental adoption of extensions without disrupting working systems.\n\n#### Technology Recommendations\n\n| Extension Category | Simple Approach | Advanced Approach |\n|-------------------|-----------------|-------------------|\n| Spatial Indexing | Pure Python KD-tree | scikit-learn NearestNeighbors with Ball Tree |\n| Approximate NN | Random projection LSH | FAISS library with GPU acceleration |\n| Custom Metrics | Function-based metrics | Compiled Cython/Numba functions |\n| Metric Learning | Simple feature weighting | Neural metric learning with PyTorch |\n| Online Learning | Sliding window buffer | Incremental clustering with river library |\n| Streaming Processing | Collections.deque buffer | Apache Kafka + stream processing |\n\n#### Recommended Module Structure for Extensions\n\n```\nknn_project/\n├── core/                           # Existing core components\n│   ├── distance_metrics.py\n│   ├── neighbor_finder.py\n│   ├── classifier.py\n│   └── evaluator.py\n├── extensions/                     # New extension modules\n│   ├── __init__.py\n│   ├── performance/               # Performance extensions\n│   │   ├── __init__.py\n│   │   ├── kdtree_finder.py      # KD-tree neighbor finder\n│   │   ├── lsh_finder.py         # LSH approximate finder\n│   │   ├── spatial_index.py      # Spatial indexing interface\n│   │   └── performance_factory.py # Auto-select optimal implementation\n│   ├── algorithms/                # Algorithm extensions\n│   │   ├── __init__.py\n│   │   ├── regression.py          # KNN regression implementation\n│   │   ├── multi_output.py        # Multi-output prediction\n│   │   ├── ensemble.py            # Ensemble methods\n│   │   └── aggregation_strategies.py # Pluggable aggregation functions\n│   ├── features/                   # Feature extensions\n│   │   ├── __init__.py\n│   │   ├── custom_metrics.py      # Custom distance metric framework\n│   │   ├── metric_learning.py     # Learned distance functions\n│   │   ├── mixed_types.py         # Mixed feature type support\n│   │   ├── online_learning.py     # Incremental learning\n│   │   └── streaming.py           # Streaming KNN\n│   └── utils/                      # Extension utilities\n│       ├── __init__.py\n│       ├── metric_registry.py     # Distance metric discovery\n│       ├── memory_management.py   # Streaming memory management\n│       └── validation_extended.py # Validation for extensions\n├── examples/                       # Extension examples\n│   ├── kdtree_performance.py\n│   ├── custom_metric_demo.py\n│   ├── regression_example.py\n│   └── streaming_demo.py\n└── tests/\n    ├── test_extensions/\n    │   ├── test_kdtree.py\n    │   ├── test_custom_metrics.py\n    │   ├── test_regression.py\n    │   └── test_streaming.py\n```\n\n#### Infrastructure Starter Code: Spatial Indexing Interface\n\n```python\n\"\"\"\nSpatial indexing interface for performance extensions.\nCopy and use this complete module to enable pluggable spatial indexes.\n\"\"\"\nimport numpy as np\nfrom abc import ABC, abstractmethod\nfrom typing import Tuple, List, Optional\nfrom enum import Enum\n\nfrom core.data_model import FeatureMatrix, FeatureVector, DistanceArray, NeighborIndices\nfrom core.distance_metrics import DistanceMetric\n\nclass IndexType(Enum):\n    \"\"\"Supported spatial index types for neighbor finding optimization.\"\"\"\n    LINEAR = \"linear\"\n    KDTREE = \"kdtree\" \n    BALLTREE = \"balltree\"\n    LSH = \"lsh\"\n    AUTO = \"auto\"  # Automatically select best for dataset\n\nclass SpatialIndex(ABC):\n    \"\"\"\n    Abstract interface for spatial indexing structures that accelerate neighbor finding.\n    \n    All spatial indexes must implement this interface to work with the neighbor finder.\n    The interface supports both exact and approximate nearest neighbor methods.\n    \"\"\"\n    \n    def __init__(self, distance_metric: DistanceMetric):\n        self.distance_metric = distance_metric\n        self.is_fitted = False\n        self.n_samples = 0\n        self.n_features = 0\n    \n    @abstractmethod\n    def fit(self, X: FeatureMatrix) -> None:\n        \"\"\"\n        Build the spatial index from training data.\n        \n        Args:\n            X: Training feature matrix of shape (n_samples, n_features)\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def query(self, query_point: FeatureVector, k: int) -> Tuple[NeighborIndices, DistanceArray]:\n        \"\"\"\n        Find K nearest neighbors to query point using spatial index.\n        \n        Args:\n            query_point: Query feature vector\n            k: Number of neighbors to find\n            \n        Returns:\n            Tuple of (neighbor_indices, neighbor_distances) sorted by distance\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def query_batch(self, query_points: FeatureMatrix, k: int) -> List[Tuple[NeighborIndices, DistanceArray]]:\n        \"\"\"\n        Find K nearest neighbors for multiple query points efficiently.\n        \n        Args:\n            query_points: Query feature matrix of shape (n_queries, n_features)\n            k: Number of neighbors to find for each query\n            \n        Returns:\n            List of (neighbor_indices, neighbor_distances) for each query\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def get_memory_usage(self) -> int:\n        \"\"\"Return approximate memory usage of the index in bytes.\"\"\"\n        pass\n    \n    def supports_metric(self, metric: DistanceMetric) -> bool:\n        \"\"\"Check if this index type supports the given distance metric.\"\"\"\n        # Default implementation - subclasses can override\n        return metric in [DistanceMetric.EUCLIDEAN, DistanceMetric.MANHATTAN]\n\nclass LinearIndex(SpatialIndex):\n    \"\"\"\n    Linear search baseline implementation for comparison and fallback.\n    Works with any distance metric but has O(n) query time.\n    \"\"\"\n    \n    def __init__(self, distance_metric: DistanceMetric):\n        super().__init__(distance_metric)\n        self.training_data = None\n    \n    def fit(self, X: FeatureMatrix) -> None:\n        \"\"\"Store training data for linear search.\"\"\"\n        self.training_data = X.copy()\n        self.n_samples, self.n_features = X.shape\n        self.is_fitted = True\n    \n    def query(self, query_point: FeatureVector, k: int) -> Tuple[NeighborIndices, DistanceArray]:\n        \"\"\"Compute distances to all training samples and select top K.\"\"\"\n        if not self.is_fitted:\n            raise ValueError(\"Index must be fitted before querying\")\n        \n        # Import here to avoid circular dependency\n        from core.distance_metrics import calculate_distances_to_point\n        \n        distances = calculate_distances_to_point(query_point, self.training_data, self.distance_metric)\n        neighbor_indices = np.argsort(distances)[:k]\n        neighbor_distances = distances[neighbor_indices]\n        \n        return neighbor_indices.astype(np.int32), neighbor_distances\n    \n    def query_batch(self, query_points: FeatureMatrix, k: int) -> List[Tuple[NeighborIndices, DistanceArray]]:\n        \"\"\"Process multiple queries using vectorized operations.\"\"\"\n        return [self.query(query_point, k) for query_point in query_points]\n    \n    def get_memory_usage(self) -> int:\n        \"\"\"Return memory usage of stored training data.\"\"\"\n        if self.training_data is None:\n            return 0\n        return self.training_data.nbytes\n    \n    def supports_metric(self, metric: DistanceMetric) -> bool:\n        \"\"\"Linear search supports all implemented distance metrics.\"\"\"\n        return True\n\nclass IndexFactory:\n    \"\"\"Factory for creating appropriate spatial indexes based on dataset characteristics.\"\"\"\n    \n    @staticmethod\n    def create_index(index_type: IndexType, distance_metric: DistanceMetric, \n                    X: Optional[FeatureMatrix] = None) -> SpatialIndex:\n        \"\"\"\n        Create spatial index instance with automatic selection if requested.\n        \n        Args:\n            index_type: Type of spatial index to create\n            distance_metric: Distance metric for neighbor finding\n            X: Training data for automatic index selection (optional)\n            \n        Returns:\n            Configured spatial index instance\n        \"\"\"\n        if index_type == IndexType.AUTO:\n            # Auto-select based on dataset characteristics\n            if X is not None:\n                n_samples, n_features = X.shape\n                if n_features <= 10 and n_samples > 1000:\n                    index_type = IndexType.KDTREE\n                elif n_features <= 50:\n                    index_type = IndexType.BALLTREE  \n                else:\n                    index_type = IndexType.LSH if n_samples > 10000 else IndexType.LINEAR\n            else:\n                index_type = IndexType.LINEAR  # Safe default\n        \n        if index_type == IndexType.LINEAR:\n            return LinearIndex(distance_metric)\n        elif index_type == IndexType.KDTREE:\n            # Import only when needed\n            from extensions.performance.kdtree_finder import KDTreeIndex\n            return KDTreeIndex(distance_metric)\n        elif index_type == IndexType.BALLTREE:\n            from extensions.performance.balltree_finder import BallTreeIndex\n            return BallTreeIndex(distance_metric)\n        elif index_type == IndexType.LSH:\n            from extensions.performance.lsh_finder import LSHIndex\n            return LSHIndex(distance_metric)\n        else:\n            raise ValueError(f\"Unsupported index type: {index_type}\")\n```\n\n#### Core Logic Skeleton: Custom Distance Metric Framework\n\n```python\n\"\"\"\nCustom distance metric framework implementation.\nImplement the TODO sections to enable user-defined similarity functions.\n\"\"\"\nimport numpy as np\nfrom typing import Callable, Dict, Any, Optional\nfrom abc import ABC, abstractmethod\n\nfrom core.data_model import FeatureVector, FeatureMatrix, DistanceArray\nfrom core.distance_metrics import DistanceMetric\n\nclass CustomDistanceMetric(ABC):\n    \"\"\"\n    Abstract base class for custom distance metric implementations.\n    Enables domain-specific similarity measures beyond standard metrics.\n    \"\"\"\n    \n    def __init__(self, name: str, parameters: Optional[Dict[str, Any]] = None):\n        self.name = name\n        self.parameters = parameters or {}\n        self.is_fitted = False\n    \n    @abstractmethod\n    def calculate(self, point1: FeatureVector, point2: FeatureVector) -> float:\n        \"\"\"\n        Calculate distance between two feature vectors.\n        \n        Args:\n            point1: First feature vector\n            point2: Second feature vector\n            \n        Returns:\n            Distance value (non-negative, 0 for identical points)\n        \"\"\"\n        # TODO 1: Validate that input vectors have same dimensionality\n        # TODO 2: Check for any custom metric preconditions (e.g., fitted parameters)\n        # TODO 3: Implement the core distance calculation logic\n        # TODO 4: Ensure result satisfies metric properties if required (symmetry, triangle inequality)\n        # TODO 5: Return non-negative distance value\n        pass\n    \n    def batch_calculate(self, query_point: FeatureVector, training_matrix: FeatureMatrix) -> DistanceArray:\n        \"\"\"\n        Calculate distances from query point to all training samples efficiently.\n        \n        Args:\n            query_point: Query feature vector\n            training_matrix: Training data matrix (n_samples, n_features)\n            \n        Returns:\n            Array of distances to each training sample\n        \"\"\"\n        # TODO 1: Validate input dimensions match between query and training data\n        # TODO 2: Check if vectorized implementation is available for this metric\n        # TODO 3: If vectorized: use numpy operations for efficient computation\n        # TODO 4: If not vectorized: loop through training samples calling calculate()\n        # TODO 5: Return distance array with shape (n_samples,)\n        # Hint: Vectorized operations are 10-100x faster than Python loops\n        pass\n    \n    def fit(self, X: FeatureMatrix, y: Optional[np.ndarray] = None) -> None:\n        \"\"\"\n        Fit metric parameters based on training data (for learned metrics).\n        \n        Args:\n            X: Training feature matrix\n            y: Training labels (optional, for supervised metric learning)\n        \"\"\"\n        # TODO 1: Validate training data format and consistency\n        # TODO 2: Initialize any learnable parameters based on data statistics\n        # TODO 3: If supervised metric: optimize parameters using label information\n        # TODO 4: Store fitted parameters in self.parameters\n        # TODO 5: Set self.is_fitted = True\n        pass\n    \n    def get_parameters(self) -> Dict[str, Any]:\n        \"\"\"Return current metric parameters for serialization.\"\"\"\n        return self.parameters.copy()\n    \n    def set_parameters(self, parameters: Dict[str, Any]) -> None:\n        \"\"\"Set metric parameters from deserialization.\"\"\"\n        self.parameters = parameters.copy()\n        # Mark as fitted if parameters suggest a trained metric\n        self.is_fitted = len(parameters) > 0\n\nclass FunctionBasedMetric(CustomDistanceMetric):\n    \"\"\"\n    Custom metric wrapper for user-provided distance functions.\n    Enables quick prototyping of domain-specific similarity measures.\n    \"\"\"\n    \n    def __init__(self, name: str, distance_function: Callable, vectorized: bool = False):\n        super().__init__(name)\n        self.distance_function = distance_function\n        self.vectorized = vectorized\n    \n    def calculate(self, point1: FeatureVector, point2: FeatureVector) -> float:\n        \"\"\"Delegate to user-provided distance function.\"\"\"\n        # TODO 1: Validate input vectors have same shape\n        # TODO 2: Call user distance function with appropriate error handling\n        # TODO 3: Validate that result is non-negative number\n        # TODO 4: Handle any exceptions from user function gracefully\n        # TODO 5: Return validated distance value\n        pass\n    \n    def batch_calculate(self, query_point: FeatureVector, training_matrix: FeatureMatrix) -> DistanceArray:\n        \"\"\"Use vectorized function if available, otherwise loop through samples.\"\"\"\n        # TODO 1: Check if user provided vectorized implementation\n        # TODO 2: If vectorized: call function with (query_point, training_matrix)\n        # TODO 3: If not vectorized: loop through rows of training_matrix\n        # TODO 4: Validate all distance results are non-negative\n        # TODO 5: Return distance array\n        pass\n\nclass WeightedEuclideanMetric(CustomDistanceMetric):\n    \"\"\"\n    Euclidean distance with learned feature weights.\n    Demonstrates parameter learning for improved similarity measurement.\n    \"\"\"\n    \n    def __init__(self, feature_weights: Optional[np.ndarray] = None):\n        super().__init__(\"weighted_euclidean\")\n        self.feature_weights = feature_weights\n        self.is_fitted = feature_weights is not None\n    \n    def calculate(self, point1: FeatureVector, point2: FeatureVector) -> float:\n        \"\"\"Compute weighted Euclidean distance between feature vectors.\"\"\"\n        # TODO 1: Validate that metric has been fitted (has feature weights)\n        # TODO 2: Validate input vectors have same dimensionality as weights\n        # TODO 3: Compute element-wise squared differences: (point1 - point2)**2\n        # TODO 4: Apply feature weights: multiply differences by weights\n        # TODO 5: Sum weighted differences and return square root\n        pass\n    \n    def fit(self, X: FeatureMatrix, y: np.ndarray) -> None:\n        \"\"\"\n        Learn feature weights that maximize class separation.\n        Uses simple variance-based weighting as baseline approach.\n        \"\"\"\n        # TODO 1: Validate that X and y have compatible dimensions\n        # TODO 2: For each feature, compute within-class variance for each class\n        # TODO 3: Compute between-class variance (variance of class means)\n        # TODO 4: Set weight = between_class_var / (within_class_var + epsilon)\n        # TODO 5: Normalize weights to prevent numerical issues\n        # TODO 6: Store weights in self.feature_weights and set is_fitted = True\n        # Hint: Higher weight for features that separate classes well\n        pass\n\nclass MetricRegistry:\n    \"\"\"\n    Registry for discovering and managing available distance metrics.\n    Enables runtime metric selection and custom metric registration.\n    \"\"\"\n    \n    def __init__(self):\n        self._metrics: Dict[str, CustomDistanceMetric] = {}\n        self._register_builtin_metrics()\n    \n    def register_metric(self, metric: CustomDistanceMetric) -> None:\n        \"\"\"Register a custom distance metric for use in KNN.\"\"\"\n        # TODO 1: Validate that metric implements required interface\n        # TODO 2: Check that metric name is unique\n        # TODO 3: Verify metric satisfies basic mathematical properties\n        # TODO 4: Store metric in registry with its name as key\n        # TODO 5: Log successful registration for debugging\n        pass\n    \n    def get_metric(self, name: str) -> CustomDistanceMetric:\n        \"\"\"Retrieve registered metric by name.\"\"\"\n        # TODO 1: Check if metric name exists in registry\n        # TODO 2: Return metric instance if found\n        # TODO 3: Raise informative error with available metrics if not found\n        # TODO 4: Consider returning copy vs reference based on usage pattern\n        pass\n    \n    def list_metrics(self) -> List[str]:\n        \"\"\"Return names of all registered metrics.\"\"\"\n        return list(self._metrics.keys())\n    \n    def create_function_metric(self, name: str, distance_function: Callable, \n                             vectorized: bool = False) -> CustomDistanceMetric:\n        \"\"\"\n        Factory method for creating function-based custom metrics.\n        \n        Args:\n            name: Unique name for the metric\n            distance_function: User-provided distance calculation function\n            vectorized: Whether function supports batch operations\n            \n        Returns:\n            Configured custom metric instance\n        \"\"\"\n        # TODO 1: Validate that name is unique in registry\n        # TODO 2: Create FunctionBasedMetric instance with provided function\n        # TODO 3: Test function with sample data to ensure it works\n        # TODO 4: Register the new metric in registry\n        # TODO 5: Return configured metric instance\n        pass\n    \n    def _register_builtin_metrics(self) -> None:\n        \"\"\"Register standard custom metrics that extend beyond basic Euclidean/Manhattan.\"\"\"\n        # TODO 1: Create instances of built-in custom metrics\n        # TODO 2: Register each metric using register_metric()\n        # TODO 3: Include metrics like weighted Euclidean, Mahalanobis, etc.\n        pass\n```\n\n#### Milestone Checkpoint: Performance Extensions\n\nAfter implementing spatial indexing support, verify the performance improvements with this checkpoint:\n\n**Test Command:**\n```bash\npython -m pytest tests/test_extensions/test_performance.py -v\npython examples/performance_benchmark.py\n```\n\n**Expected Behavior:**\n- KD-tree shows 10-100x speedup for low-dimensional data (< 10 features)\n- Linear search and KD-tree produce identical results on test datasets\n- Automatic index selection chooses appropriate implementation for different data characteristics\n- Memory usage reports are reasonable (typically 2-3x training data size for KD-tree)\n\n**Performance Benchmark Results:**\n```\nDataset: 1000 samples, 5 features, K=10\nLinear Search:    45.2ms per query\nKD-Tree:          2.1ms per query  (21.5x speedup)\nBall Tree:        3.8ms per query  (11.9x speedup)\n\nDataset: 1000 samples, 50 features, K=10  \nLinear Search:    52.1ms per query\nKD-Tree:          48.9ms per query (1.1x speedup - high dimensional)\nBall Tree:        15.2ms per query (3.4x speedup)\nLSH (approximate): 4.1ms per query (12.7x speedup, 95% recall)\n```\n\n**Signs Something is Wrong:**\n- KD-tree slower than linear search on low-dimensional data → Check tree construction or query logic\n- Identical inputs producing different neighbor sets → Distance calculation inconsistency \n- Memory usage > 10x training data size → Memory leak in index construction\n- Index selection always chooses linear search → Auto-selection logic not working\n\n#### Milestone Checkpoint: Algorithm Extensions\n\nAfter implementing regression and multi-output support:\n\n**Test Command:**\n```bash\npython examples/regression_example.py\npython examples/multi_output_demo.py\n```\n\n**Expected Behavior:**\n- KNN regression produces reasonable predictions on continuous targets\n- Multi-output prediction handles vector targets correctly\n- Ensemble methods improve accuracy over single models\n- Confidence estimation correlates with prediction quality\n\n**Regression Performance Example:**\n```python\n# Load Boston housing dataset\nfrom sklearn.datasets import load_boston\nX, y = load_boston(return_X_y=True)\n\n# Train KNN regressor\nfrom extensions.algorithms.regression import KNNRegressor\nregressor = KNNRegressor(k=5, weighted=True)\nregressor.fit(X_train, y_train)\n\n# Evaluate performance\npredictions = regressor.predict(X_test)\nrmse = np.sqrt(np.mean((predictions - y_test)**2))\nprint(f\"RMSE: {rmse:.2f}\")  # Should be < 5.0 for reasonable performance\n```\n\n#### Language-Specific Implementation Hints\n\n**NumPy Optimization Tips:**\n- Use `np.linalg.norm(axis=1)` for vectorized Euclidean distance calculation\n- Use `scipy.spatial.distance_matrix` for efficient pairwise distance computation\n- Use `np.argpartition(distances, k)` instead of full sort when you only need top K\n- Use `np.einsum` for complex vectorized operations in custom metrics\n\n**Memory Management for Streaming:**\n- Use `collections.deque(maxlen=N)` for fixed-size sliding windows\n- Use `weakref` for cache management that doesn't prevent garbage collection  \n- Use `np.memmap` for datasets larger than available RAM\n- Monitor memory usage with `psutil.Process().memory_info().rss`\n\n**Custom Metric Performance:**\n- Compile critical paths with `numba.jit` for 10-100x speedup\n- Use `Cython` for maximum performance custom distance functions\n- Pre-allocate arrays in loops to avoid repeated memory allocation\n- Use in-place operations (`+=`, `*=`) to reduce temporary array creation\n\nThis implementation guidance provides a complete foundation for extending the KNN system with advanced performance optimizations, algorithmic capabilities, and customization features while maintaining compatibility with the existing codebase.\n\n\n## Glossary\n\n> **Milestone(s):** Comprehensive terminology reference for all milestones - foundational concepts and data structures for distance calculation (Milestone 1), classification algorithms and voting strategies for neighbor finding and prediction (Milestone 2), and evaluation metrics and optimization concepts for improvements and assessment (Milestone 3)\n\n### Mental Model: The Learning Dictionary\n\nThink of this glossary as your personal learning dictionary - a comprehensive reference that transforms technical jargon into clear, actionable knowledge. Just as a foreign language dictionary doesn't just translate words but explains grammar, usage, and cultural context, this glossary provides not just definitions but the conceptual framework and practical implications of each term. Every concept builds upon others, creating a web of knowledge that supports your understanding throughout the implementation journey.\n\n### Core Algorithmic Concepts\n\nThe foundational algorithmic concepts form the theoretical backbone of K-Nearest Neighbors classification. These concepts represent the mathematical and computational principles that drive the entire system.\n\n| Term | Definition | Mathematical Foundation | Practical Implication |\n|------|------------|------------------------|----------------------|\n| **Lazy Learning** | Machine learning approach that defers all computation until prediction time, storing training examples without building an explicit model | No training phase optimization; all work happens during queries | Simple implementation but potentially slower predictions; perfect for dynamic datasets |\n| **Instance-Based Learning** | Learning paradigm that makes decisions based on similarity to stored training instances rather than learned parameters | Classification function f(x) = argmax_c Σ similarity(x, x_i) where y_i = c | Memory-intensive but highly flexible; adapts naturally to local patterns in data |\n| **Smoothness Assumption** | Fundamental assumption that similar inputs in feature space should produce similar outputs | If d(x_i, x_j) is small, then P(y_i = y_j) should be high | Justifies using nearest neighbors for prediction; breaks down in high dimensions or noisy data |\n| **Curse of Dimensionality** | Phenomenon where distance metrics become less discriminative as feature dimensionality increases | In high dimensions, max_distance/min_distance → 1 as d → ∞ | Requires feature selection, dimensionality reduction, or specialized distance metrics for high-dimensional data |\n| **Bias-Variance Tradeoff** | Fundamental ML principle where small K creates high variance/low bias while large K creates low variance/high bias | Small K: overfits to local noise; Large K: underfits to global trends | Optimal K balances model complexity with generalization; requires cross-validation to find |\n\n### Distance Metric Terminology\n\nDistance metrics quantify similarity between data points and form the mathematical foundation of neighbor finding. Understanding these concepts is crucial for implementing robust distance calculations.\n\n| Term | Definition | Formula | Use Case |\n|------|------------|---------|----------|\n| **L2 Norm** | Euclidean distance calculation measuring straight-line distance in feature space | √(Σ(x_i - y_i)²) | Default choice for continuous features; sensitive to outliers but intuitive geometrically |\n| **L1 Norm** | Manhattan distance calculation measuring sum of absolute coordinate differences | Σ\\|x_i - y_i\\| | Robust to outliers; works well for high-dimensional sparse data like text features |\n| **Cosine Distance** | Angular distance measuring similarity in direction rather than magnitude | 1 - (x·y)/(||x|| ||y||) | Ideal for text classification and high-dimensional data where magnitude varies |\n| **Vectorized Operations** | NumPy operations on entire arrays avoiding Python-level loops for performance | Broadcasting rules apply element-wise operations across array dimensions | Critical for performance; can achieve 10-100x speedup over Python loops |\n| **Broadcasting** | NumPy mechanism for automatic array shape matching during element-wise operations | Arrays with compatible shapes can operate element-wise without explicit reshaping | Enables efficient distance calculations between single points and entire datasets |\n\n### Classification and Voting Concepts\n\nThe voting mechanisms transform neighbor information into final predictions, representing the democratic decision-making process at the heart of KNN classification.\n\n![Classification Voting Process](./diagrams/voting-process.svg)\n\n| Term | Definition | Implementation Approach | Advantages and Limitations |\n|------|------------|------------------------|---------------------------|\n| **Majority Voting** | Classification strategy assigning the class that appears most frequently among K neighbors | Count occurrences of each class; return class with maximum count | Simple and interpretable but ignores distance information; vulnerable to ties |\n| **Weighted Voting** | Voting strategy where closer neighbors have proportionally more influence on the final decision | Weight each vote by 1/(distance + ε) where ε prevents division by zero | More sophisticated than majority voting but requires careful epsilon tuning; sensitive to distance scale |\n| **Democratic Decision Making** | Aggregation process combining multiple neighbor opinions through structured voting mechanisms | Collect neighbor classes, apply voting weights, resolve ties systematically | Mirrors human group decision processes; requires tie-breaking strategies |\n| **Tie-Breaking** | Resolution mechanism for situations where multiple classes receive equal votes in majority voting | Use nearest neighbor class, weighted voting, or random selection with fixed seed | Critical for deterministic behavior; choice affects edge case performance |\n| **Confidence Scoring** | Quantification of prediction certainty based on neighbor agreement and distance patterns | Ratio of winning votes to total votes, or inverse of average neighbor distance | Enables uncertainty quantification; useful for rejecting low-confidence predictions |\n\n### Evaluation and Optimization Terminology\n\nThese concepts enable rigorous assessment and optimization of KNN performance, ensuring reliable model evaluation and hyperparameter selection.\n\n| Term | Definition | Statistical Foundation | Practical Application |\n|------|------------|----------------------|----------------------|\n| **Cross-Validation** | Statistical method for reliable performance estimation using multiple train/test splits | Partitions data into K folds; trains on K-1, tests on 1; averages results | Provides unbiased performance estimates; essential for small datasets |\n| **Stratified Sampling** | Sampling approach that preserves class distribution proportions across data splits | Each fold maintains same class ratio as original dataset | Prevents evaluation bias from unbalanced splits; critical for imbalanced datasets |\n| **Hyperparameter Optimization** | Systematic search process for optimal model configuration parameters like K value | Grid search evaluates all combinations; random search samples parameter space | Finds best K value through principled evaluation; prevents manual guessing |\n| **Grid Search** | Exhaustive evaluation approach testing all combinations of specified hyperparameter values | For K ∈ [1,3,5,7,9]: evaluate each K with cross-validation, select best | Thorough but computationally expensive; guarantees finding global optimum in search space |\n| **Statistical Significance** | Mathematical confidence that observed performance differences are not due to random chance | Use paired t-tests or Wilcoxon tests to compare CV scores across parameter settings | Distinguishes real improvements from noise; essential for reliable parameter selection |\n\n### Data Structure and Type System\n\nThe type system provides the structural foundation for all KNN operations, defining how data flows through the system and ensuring type safety throughout the pipeline.\n\n| Type Name | Fields and Structure | Primary Usage | Type Constraints |\n|-----------|---------------------|---------------|------------------|\n| **FeatureVector** | 1D numpy array of float64 values | Single data point representation | Must be float64 for numerical stability; fixed length per dataset |\n| **FeatureMatrix** | 2D numpy array shape (n_samples, n_features) | Batch data storage | All rows must have identical feature count; no missing values allowed |\n| **ClassLabel** | Union[int, str] for class identifiers | Class identification | Must be hashable for voting; consistent type within dataset |\n| **TrainingData** | features: FeatureMatrix, labels: List[ClassLabel], n_samples: int, n_features: int | Complete training dataset | Labels length must match features rows; dimensions must be consistent |\n| **PredictionResult** | predicted_class: ClassLabel, neighbor_indices: NeighborIndices, neighbor_distances: DistanceArray, confidence: float, voting_details: Dict | Rich prediction information | Indices must be valid for training data; distances must be non-negative |\n\n### Algorithm Implementation Terminology\n\nThese terms describe the concrete algorithmic approaches and implementation strategies used throughout the KNN system.\n\n| Term | Definition | Implementation Strategy | Performance Characteristics |\n|------|------------|------------------------|---------------------------|\n| **Linear Search** | Brute-force neighbor finding algorithm computing distances to all training points | Calculate distances to every training sample; sort and select top K | O(n) per query; simple implementation; works with any distance metric |\n| **Spatial Indexing** | Data structures that organize feature space to accelerate neighbor finding operations | KD-trees, Ball trees, or LSH partition space for faster searches | O(log n) average case; complex implementation; metric-dependent performance |\n| **Locality-Sensitive Hashing** | Approximation technique using similarity-preserving hash functions for fast neighbor finding | Hash similar points to same buckets; search only within relevant buckets | Sub-linear query time; approximate results; tunable accuracy/speed tradeoff |\n| **Numerical Stability** | Robustness of calculations against floating-point precision errors and edge cases | Use epsilon for comparisons; handle overflow/underflow; validate intermediate results | Prevents subtle bugs; essential for reliable distance calculations |\n| **Graceful Degradation** | System behavior that maintains partial functionality when full operation becomes impossible | Return best-effort results with warnings; fallback to simpler algorithms | Improves user experience; enables debugging of complex failure modes |\n\n### Performance and Quality Metrics\n\nThese metrics quantify system performance and prediction quality, enabling objective assessment and optimization of KNN implementations.\n\n| Metric Name | Mathematical Definition | Interpretation Guidelines | Typical Value Ranges |\n|-------------|------------------------|---------------------------|---------------------|\n| **Precision** | True Positives / (True Positives + False Positives) per class | Fraction of predicted positives that are actually positive | 0.0 to 1.0; higher is better |\n| **Recall** | True Positives / (True Positives + False Negatives) per class | Fraction of actual positives correctly identified | 0.0 to 1.0; higher is better |\n| **F1-Score** | 2 * (Precision * Recall) / (Precision + Recall) harmonic mean | Balanced measure combining precision and recall | 0.0 to 1.0; higher is better |\n| **Macro Averaging** | Compute metrics by averaging across classes with equal weight regardless of frequency | Treats all classes equally; good for balanced evaluation | Can be dominated by rare class performance |\n| **Weighted Averaging** | Compute metrics by averaging across classes weighted by their support (frequency) | Reflects overall performance weighted by class importance | More representative for imbalanced datasets |\n\n### Advanced Concepts and Extensions\n\nThese concepts represent sophisticated enhancements and theoretical foundations that extend beyond basic KNN implementation.\n\n| Concept | Definition | Theoretical Foundation | Implementation Complexity |\n|---------|------------|----------------------|--------------------------|\n| **Metric Learning** | Optimization of distance functions based on training data to improve classification | Learn distance function that minimizes classification error on training set | High; requires additional optimization algorithms |\n| **Ensemble Methods** | Combining multiple KNN models with different parameters for improved predictions | Bagging: train on different data subsets; Boosting: weight misclassified examples | Medium; requires model combination strategies |\n| **Online Learning** | Adapting KNN models to new data without complete retraining of the entire system | Incrementally add new training points; maintain efficiency with streaming updates | High; requires efficient data structure updates |\n| **Concept Drift** | Changes in underlying data distribution over time affecting model performance | Statistical tests detect distribution changes; trigger model updates or retraining | High; requires change detection and adaptation mechanisms |\n| **Streaming KNN** | Handling continuous data streams with memory constraints and real-time requirements | Sliding windows, reservoir sampling, or approximate data structures | Very High; requires specialized algorithms and careful memory management |\n\n### Error Handling and Robustness\n\nThese concepts ensure reliable system operation under various failure modes and edge conditions.\n\n| Error Category | Definition | Detection Strategy | Recovery Approach |\n|----------------|------------|-------------------|-------------------|\n| **Input Validation** | Verification that data meets system requirements before processing begins | Check array shapes, data types, value ranges, and missing data | Raise descriptive errors with specific requirements |\n| **Numerical Error Handling** | Management of floating-point precision issues and mathematical edge cases | Monitor for NaN/infinity values; check for division by zero | Use epsilon comparisons; provide fallback calculations |\n| **Edge Case Handling** | Management of boundary conditions like empty datasets or extreme parameter values | Validate parameters against dataset constraints; check for degenerate cases | Provide meaningful defaults or graceful failure modes |\n| **Information Leakage** | Contamination where training information inappropriately influences validation results | Ensure strict separation between training and validation data | Use stratified splitting with proper randomization |\n| **Multiple Testing Correction** | Statistical adjustment for increased false positive risk when testing many hypotheses | Apply Bonferroni correction or False Discovery Rate control | Adjust significance thresholds based on number of tests |\n\n### Implementation and Debugging Support\n\nThese practical concepts support the development and troubleshooting process throughout KNN implementation.\n\n| Support Category | Definition | Application Context | Expected Outcome |\n|------------------|------------|-------------------|------------------|\n| **Unit Testing Strategy** | Testing individual components in isolation to verify correctness | Test each distance function, voting mechanism, and evaluation metric separately | High confidence in component correctness |\n| **Integration Testing Strategy** | Testing component interactions and end-to-end workflows | Verify complete prediction pipeline from input to output | Confidence in system integration |\n| **Milestone Checkpoints** | Verification steps after each implementation phase to ensure progress | Test distance calculation, then neighbor finding, then classification | Incremental validation of implementation progress |\n| **Performance Profiling** | Systematic measurement of computational bottlenecks and resource usage | Identify slowest components and memory-intensive operations | Targeted optimization opportunities |\n| **Symptom-Based Debugging** | Diagnostic approach mapping observed problems to likely root causes | Match error symptoms to known failure patterns | Faster problem resolution |\n\n### Mathematical and Statistical Foundations\n\nThese mathematical concepts underpin the theoretical validity of KNN algorithms and their statistical properties.\n\n| Mathematical Concept | Definition | Theoretical Importance | Practical Implications |\n|---------------------|------------|----------------------|----------------------|\n| **Metric Properties** | Mathematical requirements for valid distance functions: non-negativity, symmetry, triangle inequality | Ensures distance function behaves predictably and supports geometric reasoning | Invalid metrics can produce counterintuitive neighbor relationships |\n| **Convergence Properties** | Behavior of KNN as dataset size approaches infinity | Under certain conditions, KNN error approaches Bayes optimal error | Provides theoretical justification for KNN effectiveness |\n| **Consistency** | Property that algorithm performance improves with more training data | KNN is statistically consistent under mild regularity conditions | Guarantees that more data leads to better performance |\n| **Curse of Dimensionality** | Phenomenon where distance-based methods degrade in high-dimensional spaces | All points become approximately equidistant as dimensionality increases | Requires dimensionality reduction or specialized techniques |\n| **Concentration of Measure** | Statistical phenomenon where random variables concentrate around their mean in high dimensions | High-dimensional distance distributions have low variance | Distance becomes less discriminative; affects neighbor selection quality |\n\n### System Architecture and Design Patterns\n\nThese architectural concepts organize the KNN system into maintainable, testable, and extensible components.\n\n| Design Pattern | Definition | Application in KNN | Benefits and Trade-offs |\n|----------------|------------|-------------------|------------------------|\n| **Strategy Pattern** | Design pattern allowing algorithm selection at runtime | Different distance metrics and voting strategies | Flexibility at cost of complexity |\n| **Factory Pattern** | Creational pattern for object creation without specifying exact classes | Create distance calculators and spatial indices | Extensibility with consistent interfaces |\n| **Observer Pattern** | Behavioral pattern for event notification between components | Progress updates during cross-validation | Loose coupling but potential performance overhead |\n| **Template Method** | Behavioral pattern defining algorithm skeleton with customizable steps | Cross-validation framework with pluggable evaluation metrics | Code reuse but inheritance complexity |\n| **Dependency Injection** | Design principle providing dependencies from external sources | Inject distance metrics and evaluation strategies | Testability and flexibility |\n\n### Implementation Guidance\n\nThis implementation guidance bridges the gap between theoretical understanding and practical coding, providing concrete tools and structures for building a robust KNN system.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| **Distance Calculation** | Pure NumPy with manual loops | Scipy spatial.distance with optimized C implementations |\n| **Neighbor Search** | Linear search with numpy.argsort | Scikit-learn NearestNeighbors with KDTree/BallTree |\n| **Spatial Indexing** | Manual KDTree implementation | FAISS library for approximate nearest neighbors |\n| **Evaluation Framework** | Manual cross-validation loops | Scikit-learn model_selection with stratified K-fold |\n| **Performance Profiling** | Python time module | CProfile and line_profiler for detailed analysis |\n| **Visualization** | Matplotlib scatter plots | Seaborn with statistical plotting and Plotly for interactive exploration |\n\n#### Recommended File Structure\n\nThe modular organization supports incremental development and testing while maintaining clear separation of concerns throughout the KNN implementation.\n\n```\nknn-classifier/\n├── src/\n│   ├── __init__.py\n│   ├── core/\n│   │   ├── __init__.py\n│   │   ├── data_types.py          # FeatureVector, TrainingData, PredictionResult\n│   │   └── exceptions.py          # Custom exception classes\n│   ├── distance/\n│   │   ├── __init__.py\n│   │   ├── base.py                # Abstract distance metric interface\n│   │   ├── euclidean.py           # L2 norm implementation\n│   │   ├── manhattan.py           # L1 norm implementation\n│   │   └── cosine.py              # Cosine similarity implementation\n│   ├── neighbors/\n│   │   ├── __init__.py\n│   │   ├── finder.py              # Core neighbor finding logic\n│   │   ├── linear_search.py       # Brute force implementation\n│   │   └── spatial_index.py       # Advanced indexing structures\n│   ├── classification/\n│   │   ├── __init__.py\n│   │   ├── classifier.py          # Main KNNClassifier class\n│   │   ├── voting.py              # Majority and weighted voting\n│   │   └── confidence.py          # Confidence scoring\n│   ├── evaluation/\n│   │   ├── __init__.py\n│   │   ├── cross_validation.py    # K-fold cross-validation\n│   │   ├── metrics.py             # Precision, recall, F1-score\n│   │   ├── optimization.py        # Hyperparameter tuning\n│   │   └── visualization.py       # Result plotting and analysis\n│   └── utils/\n│       ├── __init__.py\n│       ├── validation.py          # Input validation utilities\n│       ├── numerical.py           # Numerical stability helpers\n│       └── datasets.py            # Dataset loading utilities\n├── tests/\n│   ├── __init__.py\n│   ├── unit/\n│   │   ├── test_distance.py       # Distance calculation tests\n│   │   ├── test_neighbors.py      # Neighbor finding tests\n│   │   ├── test_classification.py # Voting and prediction tests\n│   │   └── test_evaluation.py     # Metrics and validation tests\n│   ├── integration/\n│   │   ├── test_pipeline.py       # End-to-end workflow tests\n│   │   └── test_performance.py    # Performance benchmarking\n│   └── fixtures/\n│       ├── sample_data.py         # Test datasets\n│       └── expected_results.py    # Expected test outcomes\n├── examples/\n│   ├── basic_usage.py             # Simple classification example\n│   ├── iris_classification.py     # Classic dataset demonstration\n│   └── parameter_tuning.py        # Hyperparameter optimization example\n├── requirements.txt               # Python dependencies\n├── setup.py                       # Package configuration\n└── README.md                      # Usage documentation\n```\n\n#### Core Data Types Implementation\n\nThis provides the foundational type system that ensures type safety and clear data flow throughout the KNN pipeline.\n\n```python\n# src/core/data_types.py\nfrom typing import Union, List, Dict, Tuple, Optional\nimport numpy as np\nfrom enum import Enum\n\n# Core data types for KNN system\nFeatureVector = np.ndarray  # 1D array of float64 features\nFeatureMatrix = np.ndarray  # 2D array shape (n_samples, n_features)\nClassLabel = Union[int, str]  # Class identifiers\nDistanceArray = np.ndarray  # 1D array of float64 distances\nNeighborIndices = np.ndarray  # 1D array of int32 indices\n\nclass DistanceMetric(Enum):\n    \"\"\"Enumeration of supported distance metrics.\"\"\"\n    EUCLIDEAN = \"euclidean\"\n    MANHATTAN = \"manhattan\"\n    COSINE = \"cosine\"\n\nclass VotingStrategy(Enum):\n    \"\"\"Enumeration of voting strategies for classification.\"\"\"\n    MAJORITY = \"majority\"\n    WEIGHTED = \"weighted\"\n\nclass TrainingData:\n    \"\"\"Container for complete training dataset with metadata.\"\"\"\n    def __init__(self, features: FeatureMatrix, labels: List[ClassLabel]):\n        self.features = features\n        self.labels = labels\n        self.n_samples = features.shape[0]\n        self.n_features = features.shape[1]\n        \n    def get_sample(self, index: int) -> Tuple[FeatureVector, ClassLabel]:\n        \"\"\"Retrieve single training example by index.\"\"\"\n        # TODO: Validate index bounds\n        # TODO: Return tuple of (feature_vector, class_label)\n        pass\n\nclass PredictionResult:\n    \"\"\"Rich prediction result with neighbor information and confidence.\"\"\"\n    def __init__(self, predicted_class: ClassLabel, neighbor_indices: NeighborIndices,\n                 neighbor_distances: DistanceArray, confidence: float, \n                 voting_details: Dict):\n        self.predicted_class = predicted_class\n        self.neighbor_indices = neighbor_indices\n        self.neighbor_distances = neighbor_distances\n        self.confidence = confidence\n        self.voting_details = voting_details\n\n# Type aliases for evaluation results\nCrossValidationResult = Dict  # Contains mean/std metrics and fold results\nGridSearchResult = Dict  # Contains optimal_k, optimal_metrics, complete_results\nConfusionMatrix = Dict  # Contains matrix and labels\nClassificationMetrics = Dict  # Contains precision, recall, F1-score per class\nFoldIndices = Tuple[np.ndarray, np.ndarray]  # train_indices, val_indices\n```\n\n#### Distance Calculation Infrastructure\n\nThis infrastructure provides the mathematical foundation for all similarity computations in the KNN system.\n\n```python\n# src/distance/base.py\nfrom abc import ABC, abstractmethod\nimport numpy as np\nfrom ..core.data_types import FeatureVector, FeatureMatrix, DistanceArray\n\nclass DistanceCalculator(ABC):\n    \"\"\"Abstract base class for distance metric implementations.\"\"\"\n    \n    @abstractmethod\n    def calculate(self, point1: FeatureVector, point2: FeatureVector) -> float:\n        \"\"\"Compute distance between two feature vectors.\"\"\"\n        pass\n    \n    @abstractmethod\n    def batch_calculate(self, query_point: FeatureVector, \n                       training_matrix: FeatureMatrix) -> DistanceArray:\n        \"\"\"Vectorized distance computation from query to all training samples.\"\"\"\n        pass\n    \n    def validate_compatible_vectors(self, v1: FeatureVector, v2: FeatureVector) -> None:\n        \"\"\"Ensure vectors have matching dimensions.\"\"\"\n        # TODO: Check that both vectors are 1D arrays\n        # TODO: Check that both vectors have same length\n        # TODO: Raise ValueError with descriptive message if incompatible\n        pass\n\n# src/distance/euclidean.py\nfrom .base import DistanceCalculator\nimport numpy as np\n\nclass EuclideanDistance(DistanceCalculator):\n    \"\"\"L2 norm distance calculation with numerical stability.\"\"\"\n    \n    def calculate(self, point1: FeatureVector, point2: FeatureVector) -> float:\n        \"\"\"Compute Euclidean distance between two points.\"\"\"\n        # TODO: Validate input vectors for compatibility\n        # TODO: Calculate squared differences: (point1 - point2) ** 2\n        # TODO: Sum squared differences\n        # TODO: Return square root using safe_sqrt helper\n        pass\n    \n    def batch_calculate(self, query_point: FeatureVector, \n                       training_matrix: FeatureMatrix) -> DistanceArray:\n        \"\"\"Vectorized Euclidean distances using broadcasting.\"\"\"\n        # TODO: Validate query_point shape against training_matrix columns\n        # TODO: Use broadcasting to compute (query_point - training_matrix) ** 2\n        # TODO: Sum along feature axis (axis=1) to get squared distances\n        # TODO: Apply safe square root to get final distances\n        # TODO: Return DistanceArray\n        pass\n\ndef safe_sqrt(values: np.ndarray) -> np.ndarray:\n    \"\"\"Safely compute square root handling negatives.\"\"\"\n    # TODO: Clip negative values to zero with warning\n    # TODO: Return np.sqrt of clipped values\n    pass\n```\n\n#### Neighbor Finding Core Logic\n\nThis component implements the core logic for efficiently identifying the K most similar training examples.\n\n```python\n# src/neighbors/finder.py\nfrom typing import Tuple, List\nimport numpy as np\nfrom ..core.data_types import (FeatureVector, FeatureMatrix, NeighborIndices, \n                               DistanceArray, TrainingData, DistanceMetric)\nfrom ..distance.base import DistanceCalculator\n\nclass NeighborFinder:\n    \"\"\"Core neighbor finding logic with multiple search strategies.\"\"\"\n    \n    def __init__(self, training_data: TrainingData, distance_calculator: DistanceCalculator):\n        self.training_data = training_data\n        self.distance_calculator = distance_calculator\n    \n    def find_k_neighbors(self, query_point: FeatureVector, k: int, \n                        distance_metric: DistanceMetric) -> Tuple[NeighborIndices, DistanceArray]:\n        \"\"\"Find K nearest neighbors to query point.\"\"\"\n        # TODO: Validate k parameter against dataset size\n        # TODO: Calculate distances to all training points using batch_calculate\n        # TODO: Get indices that would sort distances (np.argsort)\n        # TODO: Select top K indices and corresponding distances\n        # TODO: Handle ties in distances using handle_distance_ties\n        # TODO: Return (neighbor_indices, neighbor_distances)\n        pass\n    \n    def validate_k_parameter(self, k: int, dataset_size: int) -> None:\n        \"\"\"Validate K value against dataset constraints.\"\"\"\n        # TODO: Check k > 0\n        # TODO: Check k <= dataset_size\n        # TODO: Raise ValueError with descriptive message if invalid\n        pass\n    \n    def handle_distance_ties(self, distances: DistanceArray, indices: NeighborIndices, \n                           k: int) -> Tuple[NeighborIndices, DistanceArray]:\n        \"\"\"Resolve ties when multiple neighbors have identical distances.\"\"\"\n        # TODO: Identify positions where distances are equal\n        # TODO: For tied distances at boundary, use deterministic tie-breaking\n        # TODO: Return consistent results across multiple calls\n        pass\n```\n\n#### Classification and Voting System\n\nThis system implements the democratic decision-making process that converts neighbor information into final predictions.\n\n```python\n# src/classification/voting.py\nfrom typing import Tuple, Dict, List\nimport numpy as np\nfrom collections import Counter\nfrom ..core.data_types import ClassLabel, NeighborIndices, DistanceArray\n\nclass VotingSystem:\n    \"\"\"Implements majority and weighted voting strategies.\"\"\"\n    \n    def __init__(self, weighted: bool = False, epsilon: float = 1e-10):\n        self.weighted = weighted\n        self.epsilon = epsilon\n    \n    def majority_vote(self, neighbor_labels: List[ClassLabel], k: int) -> Tuple[ClassLabel, float]:\n        \"\"\"Simple majority voting implementation.\"\"\"\n        # TODO: Count occurrences of each class using Counter\n        # TODO: Find class with maximum count\n        # TODO: Calculate confidence as max_count / k\n        # TODO: Handle ties using resolve_ties method\n        # TODO: Return (predicted_class, confidence)\n        pass\n    \n    def weighted_vote(self, neighbor_labels: List[ClassLabel], \n                     neighbor_distances: DistanceArray, k: int, \n                     epsilon: float) -> Tuple[ClassLabel, float]:\n        \"\"\"Distance-weighted voting implementation.\"\"\"\n        # TODO: Calculate weights as 1 / (distance + epsilon)\n        # TODO: Sum weights for each class\n        # TODO: Find class with maximum weighted vote\n        # TODO: Calculate confidence as max_weight / total_weight\n        # TODO: Return (predicted_class, confidence)\n        pass\n    \n    def resolve_ties(self, tied_classes: List[ClassLabel], \n                    neighbor_labels: List[ClassLabel],\n                    neighbor_distances: DistanceArray) -> ClassLabel:\n        \"\"\"Tie-breaking using nearest neighbor.\"\"\"\n        # TODO: Find index of nearest neighbor (minimum distance)\n        # TODO: Return class of nearest neighbor\n        # TODO: If still tied, use lexicographic ordering for determinism\n        pass\n```\n\n#### Evaluation and Metrics Framework\n\nThis framework provides rigorous statistical evaluation capabilities for assessing and optimizing KNN performance.\n\n```python\n# src/evaluation/cross_validation.py\nfrom typing import List, Dict\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom ..core.data_types import (FeatureMatrix, ClassLabel, CrossValidationResult, \n                               FoldIndices, DistanceMetric)\n\nclass CrossValidator:\n    \"\"\"K-fold cross-validation with stratified sampling.\"\"\"\n    \n    def __init__(self, n_folds: int = 5, random_seed: int = 42):\n        self.n_folds = n_folds\n        self.random_seed = random_seed\n    \n    def k_fold_cross_validate(self, X: FeatureMatrix, y: List[ClassLabel],\n                            k_neighbors: int, distance_metric: DistanceMetric,\n                            random_seed: int) -> CrossValidationResult:\n        \"\"\"Perform K-fold cross-validation.\"\"\"\n        # TODO: Create stratified folds using split_stratified_folds\n        # TODO: For each fold, train KNN on train set, evaluate on validation set\n        # TODO: Collect accuracy, precision, recall, F1 scores for each fold\n        # TODO: Calculate mean and standard deviation across folds\n        # TODO: Return CrossValidationResult with fold_results and aggregate_metrics\n        pass\n    \n    def split_stratified_folds(self, X: FeatureMatrix, y: List[ClassLabel],\n                             n_folds: int, random_seed: int) -> List[FoldIndices]:\n        \"\"\"Create stratified train/validation splits.\"\"\"\n        # TODO: Use StratifiedKFold to create balanced splits\n        # TODO: Ensure each fold maintains class distribution\n        # TODO: Return list of (train_indices, val_indices) tuples\n        pass\n\n# src/evaluation/optimization.py\nclass GridSearchOptimizer:\n    \"\"\"Hyperparameter optimization using exhaustive grid search.\"\"\"\n    \n    def grid_search_k(self, X: FeatureMatrix, y: List[ClassLabel],\n                     k_values: List[int], cv_folds: int,\n                     distance_metric: DistanceMetric, \n                     random_seed: int) -> GridSearchResult:\n        \"\"\"Find optimal K through exhaustive search.\"\"\"\n        # TODO: For each K value, perform cross-validation\n        # TODO: Track performance metrics for each K\n        # TODO: Select K with highest mean cross-validation accuracy\n        # TODO: Return GridSearchResult with optimal_k and detailed results\n        pass\n```\n\n#### Milestone Checkpoints\n\nAfter implementing each major component, verify correct behavior using these concrete checkpoints:\n\n**Milestone 1: Distance Calculation Checkpoint**\n```bash\n# Run distance calculation tests\npython -m pytest tests/unit/test_distance.py -v\n\n# Expected: All tests pass, showing correct Euclidean, Manhattan, and cosine calculations\n# Manual verification: Load iris dataset, compute distances between first two samples\n# Should get consistent, positive distance values\n```\n\n**Milestone 2: Classification Checkpoint**\n```bash\n# Run classification pipeline tests\npython -m pytest tests/integration/test_pipeline.py -v\n\n# Expected: End-to-end prediction working with reasonable accuracy\n# Manual verification: Train on iris dataset, predict test samples\n# Should achieve >90% accuracy with K=3\n```\n\n**Milestone 3: Evaluation Checkpoint**\n```bash\n# Run hyperparameter optimization\npython examples/parameter_tuning.py\n\n# Expected: Cross-validation results showing optimal K selection\n# Should demonstrate performance variation across different K values\n```\n\n#### Debugging Tips\n\n| Symptom | Likely Cause | Diagnostic Approach | Resolution |\n|---------|--------------|-------------------|------------|\n| **All distances are NaN** | Numerical overflow in distance calculation | Check input data ranges and data types | Use float64, add epsilon to prevent division by zero |\n| **Predictions always same class** | Majority class dominates in small K | Examine class distribution and K value | Increase K or use stratified sampling |\n| **Cross-validation scores inconsistent** | Random seed not set properly | Check randomization in fold splitting | Set fixed random seeds throughout pipeline |\n| **Performance extremely slow** | Using Python loops instead of vectorization | Profile code to find bottlenecks | Replace loops with NumPy broadcasting operations |\n| **Memory errors with large datasets** | Loading entire distance matrix | Monitor memory usage during computation | Use batch processing or streaming algorithms |\n\nThis glossary provides the comprehensive terminological foundation needed to understand, implement, and debug a robust KNN classification system. Each term builds upon others to create a cohesive knowledge framework that supports successful implementation across all three milestones.\n"}